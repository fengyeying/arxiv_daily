<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Mon 18 Dec 23  to  Tue 19 Dec 23, announced Wed, 20 Dec 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item416">Cross-lists</a></li>
<li><a href="#item461">Replacements</a></li>
</ul>
<small>[ total of 715 entries:  <b>1-715</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Wed, 20 Dec 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11466" title="Abstract">arXiv:2312.11466</a> [<a href="/pdf/2312.11466" title="Download PDF">pdf</a>, <a href="/format/2312.11466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extracting Interpretable Local and Global Representations from Attention  on Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schwenke%2C+L">Leonid Schwenke</a>, 
<a href="/search/cs?searchtype=author&query=Atzmueller%2C+M">Martin Atzmueller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper: 54 Pages excluding references, 19 Figures, 30 Tables + Appendix: 12 Pages, 23 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper targets two transformer attention based interpretability methods
working with local abstraction and global representation, in the context of
time series data. We distinguish local and global contexts, and provide a
comprehensive framework for both general interpretation options. We discuss
their specific instantiation via different methods in detail, also outlining
their respective computational implementation and abstraction variants.
Furthermore, we provide extensive experimentation demonstrating the efficacy of
the presented approaches. In particular, we perform our experiments using a
selection of univariate datasets from the UCR UEA time series repository where
we both assess the performance of the proposed approaches, as well as their
impact on explainability and interpretability/complexity. Here, with an
extensive analysis of hyperparameters, the presented approaches demonstrate an
significant improvement in interpretability/complexity, while capturing many
core decisions of and maintaining a similar performance to the baseline model.
Finally, we draw general conclusions outlining and guiding the application of
the presented methods.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11469" title="Abstract">arXiv:2312.11469</a> [<a href="/pdf/2312.11469" title="Download PDF">pdf</a>, <a href="/ps/2312.11469" title="Download PostScript">ps</a>, <a href="/format/2312.11469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Algebraic Approach to the Longest Path Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khazali%2C+O+A+-">Omar Al - Khazali</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">The Longest Path Problem is a question of finding the maximum length between
pairs of vertices of a graph. In the general case, the problem is NP-hard.
However, there is a small collection of graph classes for which there exists an
efficient solution. Current approaches involve either approximation or
computational enumeration. For Tree-like classes of graphs, there are
approximation and enumeration algorithms which solves the problem efficiently.
We propose a new method of approaching the longest path problem with algebraic
operations and conditions that exactly identify and or approximate the solution
in polynomial time. We next introduce a 'booleanize' mapping on the adjacency
matrix of a graph which we prove identifies the solution for trees, uniform
block graphs, block graphs, and directed acyclic graphs, with approached
conditions. Finally, we display the algorithms to find the solution, in
addition to algorithms that generate all the longest paths.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11470" title="Abstract">arXiv:2312.11470</a> [<a href="/pdf/2312.11470" title="Download PDF">pdf</a>, <a href="/format/2312.11470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anomaly detection for automated inspection of power line insulators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+L">Laya Das</a>, 
<a href="/search/cs?searchtype=author&query=Gjorgiev%2C+B">Blazhe Gjorgiev</a>, 
<a href="/search/cs?searchtype=author&query=Sansavini%2C+G">Giovanni Sansavini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Inspection of insulators is important to ensure reliable operation of the
power system. Deep learning has recently been explored to automate the
inspection process by leveraging aerial images captured by drones along with
powerful object detection models. However, a purely object detection-based
approach exhibits class imbalance-induced poor detection accuracy for faulty
insulators, especially for incipient faults. In order to address this issue in
a data-efficient manner, this article proposes a two-stage approach that
leverages object detection in conjunction with anomaly detection to reliably
detect faults in insulators. The article adopts an explainable deep neural
network-based one-class classifier for anomaly detection, that reduces the
reliance on plentifully available images of faulty insulators, that might be
difficult to obtain in real-life applications. The anomaly detection model is
trained with two datasets -- representing data abundant and data scarce
scenarios -- in unsupervised and semi-supervised manner. The results suggest
that including as few as six real anomalies in the training dataset
significantly improves the performance of the model, and enables reliable
detection of rarely occurring faults in insulators. An analysis of the
explanations provided by the anomaly detection model reveals that the model is
able to accurately identify faulty regions on the insulator disks, while also
exhibiting some false predictions.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11473" title="Abstract">arXiv:2312.11473</a> [<a href="/pdf/2312.11473" title="Download PDF">pdf</a>, <a href="/format/2312.11473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthetic Shifts to Initial Seed Vector Exposes the Brittle Nature of  Latent-Based Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Po-Yuan%2C+M">Mao Po-Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Kotyan%2C+S">Shashank Kotyan</a>, 
<a href="/search/cs?searchtype=author&query=Foong%2C+T+Y">Tham Yik Foong</a>, 
<a href="/search/cs?searchtype=author&query=Vargas%2C+D+V">Danilo Vasconcellos Vargas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advances in Conditional Diffusion Models have led to substantial
capabilities in various domains. However, understanding the impact of
variations in the initial seed vector remains an underexplored area of concern.
Particularly, latent-based diffusion models display inconsistencies in image
generation under standard conditions when initialized with suboptimal initial
seed vectors. To understand the impact of the initial seed vector on generated
samples, we propose a reliability evaluation framework that evaluates the
generated samples of a diffusion model when the initial seed vector is
subjected to various synthetic shifts. Our results indicate that slight
manipulations to the initial seed vector of the state-of-the-art Stable
Diffusion (Rombach et al., 2022) can lead to significant disturbances in the
generated samples, consequently creating images without the effect of
conditioning variables. In contrast, GLIDE (Nichol et al., 2022) stands out in
generating reliable samples even when the initial seed vector is transformed.
Thus, our study sheds light on the importance of the selection and the impact
of the initial seed vector in the latent-based diffusion model.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11475" title="Abstract">arXiv:2312.11475</a> [<a href="/pdf/2312.11475" title="Download PDF">pdf</a>, <a href="/ps/2312.11475" title="Download PostScript">ps</a>, <a href="/format/2312.11475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hybrid SOM and K-means Model for Time Series Energy Consumption  Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Majidi%2C+F">Farideh Majidi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the First National Conference on Data Mining in Engineering and Life Sciences
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Energy consumption analysis plays a pivotal role in addressing the challenges
of sustainability and resource management. This paper introduces a novel
approach to effectively cluster monthly energy consumption patterns by
integrating two powerful techniques: Self-organizing maps and K-means
clustering. The proposed method aims to exploit the benefits of both of these
algorithms to enhance the accuracy and interpretability of clustering results
for a dataset in which finding patterns is difficult. The main focus of this
study is on a selection of time series energy consumption data from the Smart
meters in London dataset. The data was preprocessed and reduced in
dimensionality to capture essential temporal patterns while retaining their
underlying structures. The SOM algorithm was utilized to extract the central
representatives of the consumption patterns for each one of the houses over the
course of each month, effectively reducing the dimensionality of the dataset
and making it easier for analysis. Subsequently, the obtained SOM centroids
were clustered using K-means, a popular centroid-based clustering technique.
The experimental results demonstrated a significant silhouette score of 66%,
indicating strong intra-cluster cohesion and inter-cluster separation which
confirms the effectiveness of the proposed approach in the clustering task.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11479" title="Abstract">arXiv:2312.11479</a> [<a href="/pdf/2312.11479" title="Download PDF">pdf</a>, <a href="/format/2312.11479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards ultra-low-cost smartphone microscopy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Haoran Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+W">Weiyi Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zuo%2C+Z">Zirui Zuo</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+J">Jianlong Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Optics (physics.optics)

</div>
<p class="mathjax">The outbreak of COVID-19 exposed the inadequacy of our technical tools for
home health surveillance, and recent studies have shown the potential of
smartphones as a universal optical microscopic imaging platform for such
applications. However, most of them use laboratory-grade optomechanical
components and transmitted illuminations to ensure focus tuning capability and
imaging quality, which keeps the cost of the equipment high. Here we propose an
ultra-low-cost solution for smartphone microscopy. To realize focus tunability,
we designed a seesaw-like structure capable of converting large displacements
on one side into small displacements on the other (reduced to ~9.1%), which
leverages the intrinsic flexibility of 3D printing materials. We achieved a
focus-tuning accuracy of ~5 micron, which is 40 times higher than the machining
accuracy of the 3D-printed lens holder itself. For microscopic imaging, we use
an off-the-shelf smartphone camera lens as the objective and the built-in
flashlight as the illumination. To compensate for the resulting image quality
degradation, we developed a learning-based image enhancement method. We use the
CycleGAN architecture to establish the mapping from smartphone microscope
images to benchtop microscope images without pairing. We verified the imaging
performance on different biomedical samples. Except for the smartphone, we kept
the full costs of the device under 4 USD. We think these efforts to lower the
costs of smartphone microscopes will benefit their applications in various
scenarios, such as point-of-care testing, on-site diagnosis, and home health
surveillance.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11480" title="Abstract">arXiv:2312.11480</a> [<a href="/pdf/2312.11480" title="Download PDF">pdf</a>, <a href="/format/2312.11480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Smooth Activation for Improved Disease Diagnosis and Organ  Segmentation from Radiology Scans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biswas%2C+K">Koushik Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+D">Debesh Jha</a>, 
<a href="/search/cs?searchtype=author&query=Tomar%2C+N+K">Nikhil Kumar Tomar</a>, 
<a href="/search/cs?searchtype=author&query=Durak%2C+G">Gorkem Durak</a>, 
<a href="/search/cs?searchtype=author&query=Medetalibeyoglu%2C+A">Alpay Medetalibeyoglu</a>, 
<a href="/search/cs?searchtype=author&query=Antalek%2C+M">Matthew Antalek</a>, 
<a href="/search/cs?searchtype=author&query=Velichko%2C+Y">Yury Velichko</a>, 
<a href="/search/cs?searchtype=author&query=Ladner%2C+D">Daniela Ladner</a>, 
<a href="/search/cs?searchtype=author&query=Bohrani%2C+A">Amir Bohrani</a>, 
<a href="/search/cs?searchtype=author&query=Bagci%2C+U">Ulas Bagci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">In this study, we propose a new activation function, called Adaptive Smooth
Activation Unit (ASAU), tailored for optimized gradient propagation, thereby
enhancing the proficiency of convolutional networks in medical image analysis.
We apply this new activation function to two important and commonly used
general tasks in medical image analysis: automatic disease diagnosis and organ
segmentation in CT and MRI. Our rigorous evaluation on the RadImageNet
abdominal/pelvis (CT and MRI) dataset and Liver Tumor Segmentation Benchmark
(LiTS) 2017 demonstrates that our ASAU-integrated frameworks not only achieve a
substantial (4.80\%) improvement over ReLU in classification accuracy (disease
detection) on abdominal CT and MRI but also achieves 1\%-3\% improvement in
dice coefficient compared to widely used activations for `healthy liver tissue'
segmentation. These improvements offer new baselines for developing a
diagnostic tool, particularly for complex, challenging pathologies. The
superior performance and adaptability of ASAU highlight its potential for
integration into a wide range of image classification and segmentation tasks.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11485" title="Abstract">arXiv:2312.11485</a> [<a href="/pdf/2312.11485" title="Download PDF">pdf</a>, <a href="/format/2312.11485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coffea-Casa: Building composable analysis facilities for the HL-LHC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Albin%2C+S">Sam Albin</a> (1), 
<a href="/search/cs?searchtype=author&query=Attebury%2C+G">Garhan Attebury</a> (1), 
<a href="/search/cs?searchtype=author&query=Bloom%2C+K">Kenneth Bloom</a> (1), 
<a href="/search/cs?searchtype=author&query=Bockelman%2C+B">Brian Bockelman</a> (2), 
<a href="/search/cs?searchtype=author&query=Lundstedt%2C+C">Carl Lundstedt</a> (1), 
<a href="/search/cs?searchtype=author&query=Shadura%2C+O">Oksana Shadura</a> (1), 
<a href="/search/cs?searchtype=author&query=Thiltges%2C+J">John Thiltges</a> (1) ((1) University of Nebraska-Lincoln, (2) Morgridge Institute for Research)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted as proceedings for CHEP 2023 conference to The European Physical Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; High Energy Physics - Experiment (hep-ex)

</div>
<p class="mathjax">The large data volumes expected from the High Luminosity LHC (HL-LHC) present
challenges to existing paradigms and facilities for end-user data analysis.
Modern cyberinfrastructure tools provide a diverse set of services that can be
composed into a system that provides physicists with powerful tools that give
them straightforward access to large computing resources, with low barriers to
entry. The Coffea-Casa analysis facility (AF) provides an environment for end
users enabling the execution of increasingly complex analyses such as those
demonstrated by the Analysis Grand Challenge (AGC) and capturing the features
that physicists will need for the HL-LHC.
<br />We describe the development progress of the Coffea-Casa facility featuring
its modularity while demonstrating the ability to port and customize the
facility software stack to other locations. The facility also facilitates the
support of batch systems while staying Kubernetes-native. We present the
evolved architecture of the facility, such as the integration of advanced data
delivery services (e.g. ServiceX) and making data caching services (e.g.
XCache) available to end users of the facility. We also highlight the
composability of modern cyberinfrastructure tools. To enable machine learning
pipelines at coffee-casa analysis facilities, a set of industry ML solutions
adopted for HEP columnar analysis were integrated on top of existing facility
services. These services also feature transparent access for user workflows to
GPUs available at a facility via inference servers while using Kubernetes as
enabling technology.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11486" title="Abstract">arXiv:2312.11486</a> [<a href="/pdf/2312.11486" title="Download PDF">pdf</a>, <a href="/format/2312.11486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preference and Concurrence Aware Bayesian Graph Neural Networks for  Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hongjian Gu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yaochen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingxue Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Graph-based collaborative filtering methods have prevailing performance for
recommender systems since they can capture high-order information between users
and items, in which the graphs are constructed from the observed user-item
interactions that might miss links or contain spurious positive interactions in
industrial scenarios. The Bayesian Graph Neural Network framework approaches
this issue with generative models for the interaction graphs. The critical
problem is to devise a proper family of graph generative models tailored to
recommender systems. We propose an efficient generative model that jointly
considers the preferences of users, the concurrence of items and some important
graph structure information. Experiments on four popular benchmark datasets
demonstrate the effectiveness of our proposed graph generative methods for
recommender systems.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11488" title="Abstract">arXiv:2312.11488</a> [<a href="/pdf/2312.11488" title="Download PDF">pdf</a>, <a href="/format/2312.11488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Latency ML Inference by Grouping Correlated Data Objects and  Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garrett%2C+T">Thiago Garrett</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+W">Weijia Song</a>, 
<a href="/search/cs?searchtype=author&query=Vitenberg%2C+R">Roman Vitenberg</a>, 
<a href="/search/cs?searchtype=author&query=Birman%2C+K">Ken Birman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">ML inference workflows often require low latency and high throughput, yet we
lack good options for addressing this need. Techniques that reduce latency in
other streaming settings (such as caching and optimization-driven scheduling)
are of limited value because ML data dependencies are often very large and can
change dramatically depending on the triggering event. In this work, we propose
a novel correlation grouping mechanism that makes it easier for developers to
express application-specific data access correlations, enabling coordinated
management of data objects in server clusters hosting streaming inference
tasks. Experiments based on a latency-sensitive ML-based application confirm
the limitations of standard techniques while showing that our solution yields
dramatically better performance. The proposed mechanism is able to maintain
significantly lower and more consistent latency, achieves higher node
utilization as workload and scale-out increase, and yet requires only minor
changes to the code implementing the application.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11489" title="Abstract">arXiv:2312.11489</a> [<a href="/pdf/2312.11489" title="Download PDF">pdf</a>, <a href="/format/2312.11489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agglomerative Federated Learning: Empowering Larger Model Training via  End-Edge-Cloud Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Sheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Min Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+B">Bo Gao</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Q">Quyang Pan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tianliu He</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xuefeng Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by International Conference on Computer Communications (INFOCOM), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated Learning (FL) enables training Artificial Intelligence (AI) models
over end devices without compromising their privacy. As computing tasks are
increasingly performed by a combination of cloud, edge, and end devices, FL can
benefit from this End-Edge-Cloud Collaboration (EECC) paradigm to achieve
collaborative device-scale expansion with real-time access. Although
Hierarchical Federated Learning (HFL) supports multi-tier model aggregation
suitable for EECC, prior works assume the same model structure on all computing
nodes, constraining the model scale by the weakest end devices. To address this
issue, we propose Agglomerative Federated Learning (FedAgg), which is a novel
EECC-empowered FL framework that allows the trained models from end, edge, to
cloud to grow larger in size and stronger in generalization ability. FedAgg
recursively organizes computing nodes among all tiers based on Bridge Sample
Based Online Distillation Protocol (BSBODP), which enables every pair of
parent-child computing nodes to mutually transfer and distill knowledge
extracted from generated bridge samples. This design enhances the performance
by exploiting the potential of larger models, with privacy constraints of FL
and flexibility requirements of EECC both satisfied. Experiments under various
settings demonstrate that FedAgg outperforms state-of-the-art methods by an
average of 4.53\% accuracy gains and remarkable improvements in convergence
rate.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11492" title="Abstract">arXiv:2312.11492</a> [<a href="/pdf/2312.11492" title="Download PDF">pdf</a>, <a href="/format/2312.11492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploration-Exploitation Model of Moth-Inspired Olfactory Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lazebnik%2C+T">Teddy Lazebnik</a>, 
<a href="/search/cs?searchtype=author&query=Golov%2C+Y">Yiftach Golov</a>, 
<a href="/search/cs?searchtype=author&query=Gurka%2C+R">Roi Gurka</a>, 
<a href="/search/cs?searchtype=author&query=Harari%2C+A">Ally Harari</a>, 
<a href="/search/cs?searchtype=author&query=Liberzon%2C+A">Alex Liberzon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Retrieval (cs.IR); Robotics (cs.RO); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Navigation of male moths toward females during the mating search offers a
unique perspective on the exploration-exploitation (EE) model in
decision-making. This study uses the EE model to explain male moth
pheromone-driven flight paths. We leverage wind tunnel measurements and 3D
tracking using infrared cameras to gain insights into male moth behavior.
During the experiments in the wind tunnel, we add disturbance to the airflow
and analyze the effect of increased fluctuations on moth flights in the context
of the proposed EE model. We separate the exploration and exploitation phases
by applying a genetic algorithm to the dataset of moth 3D trajectories. First,
we demonstrate that the exploration-to-exploitation rate (EER) increases with
distance from the source of the female pheromone, which can be explained in the
context of the EE model. Furthermore, our findings reveal a compelling
relationship between EER and increased flow fluctuations near the pheromone
source. Using the open-source pheromone plume simulation and our moth-inspired
navigation model, we explain why male moths exhibit an enhanced EER as
turbulence levels increase, emphasizing the agent's adaptation to dynamically
changing environments. This research extends our understanding of optimal
navigation strategies based on general biological EE models and supports the
development of advanced, theoretically supported bio-inspired navigation
algorithms. We provide important insights into the potential of bio-inspired
navigation models for addressing complex decision-making challenges.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11497" title="Abstract">arXiv:2312.11497</a> [<a href="/pdf/2312.11497" title="Download PDF">pdf</a>, <a href="/format/2312.11497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Public Algorithms Survey in Allegheny County
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yu-Ru Lin</a>, 
<a href="/search/cs?searchtype=author&query=Schwanke%2C+B">Beth Schwanke</a>, 
<a href="/search/cs?searchtype=author&query=Farzan%2C+R">Rosta Farzan</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+B">Bonnie Fan</a>, 
<a href="/search/cs?searchtype=author&query=Eslami%2C+M">Motahhare Eslami</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Hong Shen</a>, 
<a href="/search/cs?searchtype=author&query=Fox%2C+S">Sarah Fox</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">This survey study focuses on public opinion regarding the use of algorithmic
decision-making in government sectors, specifically in Allegheny County,
Pennsylvania. Algorithms are becoming increasingly prevalent in various public
domains, including both routine and high-stakes government functions. Despite
their growing use, public sentiment remains divided, with concerns about
privacy and accuracy juxtaposed against perceptions of fairness when compared
to human decision-making. In April 2021, a survey was conducted among nearly
1,500 county residents to explore their awareness, experiences, and attitudes
towards these algorithms. The study highlights diverse viewpoints influenced by
factors such as race, age, education, gender, income, and urban or suburban
living. The results demonstrate the complexity of public sentiment towards
algorithmic governance and emphasize the need for a nuanced understanding and
approach in policy and implementation.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11498" title="Abstract">arXiv:2312.11498</a> [<a href="/pdf/2312.11498" title="Download PDF">pdf</a>, <a href="/format/2312.11498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recommending Influencers to Merchants using Matching Game Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gomes%2C+J+M">Jos&#xe9; Marcos Gomes</a>, 
<a href="/search/cs?searchtype=author&query=Dias%2C+L+A+V">Luis Alberto Vieira Dias</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">The goal of this work was to apply the ``Gale-Shapley'' algorithm to a
real-world problem. We analyzed the pairing of influencers with merchants, and
after a detailed specification of the variables involved, we conducted
experiments to observe the validity of the approach. We conducted an analysis
of the problem of aligning the interests of merchants to have digital
influencers promote their products and services. We propose applying the
matching algorithm approach to address this issue. We demonstrate that it is
possible to apply the algorithm and still achieve corporate objectives by
translating performance indicators into the desired ranking of influencers and
product campaigns to be advertised by merchants.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11500" title="Abstract">arXiv:2312.11500</a> [<a href="/pdf/2312.11500" title="Download PDF">pdf</a>, <a href="/format/2312.11500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Red Teaming Framework for Securing AI in Maritime Autonomous Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Walter%2C+M+J">Mathew J. Walter</a>, 
<a href="/search/cs?searchtype=author&query=Barrett%2C+A">Aaron Barrett</a>, 
<a href="/search/cs?searchtype=author&query=Tam%2C+K">Kimberly Tam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Artificial intelligence (AI) is being ubiquitously adopted to automate
processes in science and industry. However, due to its often intricate and
opaque nature, AI has been shown to possess inherent vulnerabilities which can
be maliciously exploited with adversarial AI, potentially putting AI users and
developers at both cyber and physical risk. In addition, there is insufficient
comprehension of the real-world effects of adversarial AI and an inadequacy of
AI security examinations; therefore, the growing threat landscape is unknown
for many AI solutions. To mitigate this issue, we propose one of the first red
team frameworks for evaluating the AI security of maritime autonomous systems.
The framework provides operators with a proactive (secure by design) and
reactive (post-deployment evaluation) response to securing AI technology today
and in the future. This framework is a multi-part checklist, which can be
tailored to different systems and requirements. We demonstrate this framework
to be highly effective for a red team to use to uncover numerous
vulnerabilities within a real-world maritime autonomous systems AI, ranging
from poisoning to adversarial patch attacks. The lessons learned from
systematic AI red teaming can help prevent MAS-related catastrophic events in a
world with increasing uptake and reliance on mission-critical AI.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11501" title="Abstract">arXiv:2312.11501</a> [<a href="/pdf/2312.11501" title="Download PDF">pdf</a>, <a href="/format/2312.11501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SYNC+SYNC: Software Cache Write Covert Channels Exploiting Memory-disk  Synchronization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Congcong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jinhua Cui</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+G">Gang Qu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiliang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This manuscript was first submitted to the 33rd USENIX Security Symposium on June 6, 2023 (Summer Review Cycle)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Memory-disk synchronization is a critical technology for ensuring data
correctness, integrity, and security, especially in systems that handle
sensitive information like financial transactions and medical records. We
propose SYNC+SYNC, a group of attacks that exploit the memory-disk
synchronization primitives. SYNC+SYNC works by subtly varying the timing of
synchronization on the write buffer, offering several advantages: 1)
implemented purely in software, enabling deployment on any hardware devices; 2)
resilient against existing cache partitioning and randomization techniques; 3)
unaffected by prefetching techniques and cache replacement strategies. We
present the principles of SYNC+SYNC through the implementation of two write
covert channel protocols, using either a single file or page, and introduce
three enhanced strategies that utilize multiple files and pages. The
feasibility of these channels is demonstrated in both cross-process and
cross-sandbox scenarios across diverse operating systems (OSes). Experimental
results show that, the average rate can reach 2.036 Kb/s (with a peak rate of
14.762 Kb/s) and the error rate is 0% on Linux; when running on macOS, the
average rate achieves 10.211 Kb/s (with a peak rate of 253.022 Kb/s) and the
error rate is 0.004%. To the best of our knowledge, SYNC+SYNC is the first
high-speed write covert channel for software cache.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11502" title="Abstract">arXiv:2312.11502</a> [<a href="/pdf/2312.11502" title="Download PDF">pdf</a>, <a href="/format/2312.11502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Labrador: Exploring the Limits of Masked Language Modeling for  Laboratory Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bellamy%2C+D+R">David R. Bellamy</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+B">Bhawesh Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cindy Wang</a>, 
<a href="/search/cs?searchtype=author&query=Beam%2C+A">Andrew Beam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this work we introduce Labrador, a pre-trained Transformer model for
laboratory data. Labrador and BERT were pre-trained on a corpus of 100 million
lab test results from electronic health records (EHRs) and evaluated on various
downstream outcome prediction tasks. Both models demonstrate mastery of the
pre-training task but neither consistently outperform XGBoost on downstream
supervised tasks. Our ablation studies reveal that transfer learning shows
limited effectiveness for BERT and achieves marginal success with Labrador. We
explore the reasons for the failure of transfer learning and suggest that the
data generating process underlying each patient cannot be characterized
sufficiently using labs alone, among other factors. We encourage future work to
focus on joint modeling of multiple EHR data categories and to include
tree-based baselines in their evaluations.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11503" title="Abstract">arXiv:2312.11503</a> [<a href="/pdf/2312.11503" title="Download PDF">pdf</a>, <a href="/ps/2312.11503" title="Download PostScript">ps</a>, <a href="/format/2312.11503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speech and Text-Based Emotion Recognizer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+V">Varun Sharma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages 9 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Affective computing is a field of study that focuses on developing systems
and technologies that can understand, interpret, and respond to human emotions.
Speech Emotion Recognition (SER), in particular, has got a lot of attention
from researchers in the recent past. However, in many cases, the publicly
available datasets, used for training and evaluation, are scarce and imbalanced
across the emotion labels. In this work, we focused on building a balanced
corpus from these publicly available datasets by combining these datasets as
well as employing various speech data augmentation techniques. Furthermore, we
experimented with different architectures for speech emotion recognition. Our
best system, a multi-modal speech, and text-based model, provides a performance
of UA(Unweighed Accuracy) + WA (Weighed Accuracy) of 157.57 compared to the
baseline algorithm performance of 119.66
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11504" title="Abstract">arXiv:2312.11504</a> [<a href="/pdf/2312.11504" title="Download PDF">pdf</a>, <a href="/ps/2312.11504" title="Download PostScript">ps</a>, <a href="/format/2312.11504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The performance of multiple language models in identifying offensive  language on social media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Bennett%2C+B">Brandon Bennett</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Master of Science Thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Text classification is an important topic in the field of natural language
processing. It has been preliminarily applied in information retrieval, digital
library, automatic abstracting, text filtering, word semantic discrimination
and many other fields. The aim of this research is to use a variety of
algorithms to test the ability to identify offensive posts and evaluate their
performance against a variety of assessment methods. The motivation for this
project is to reduce the harm of these languages to human censors by automating
the screening of offending posts. The field is a new one, and despite much
interest in the past two years, there has been no focus on the object of the
offence. Through the experiment of this project, it should inspire future
research on identification methods as well as identification content.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11505" title="Abstract">arXiv:2312.11505</a> [<a href="/pdf/2312.11505" title="Download PDF">pdf</a>, <a href="/ps/2312.11505" title="Download PostScript">ps</a>, <a href="/format/2312.11505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Biscari Network. Tutti gli uomini del principe
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spina%2C+S">Salvatore Spina</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Italian language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Thanks to its heterogeneity, the Biscari Archive, one of the most
representative family's archives in Sicily, in a new digital historical study,
became a valuable set of computable data that can lead historians to
reconstruct the history of the city of Catania and Sicily. Ignazio Paterno'
Castello and his wife Anna, princes of Biscari, were the promoters of the
city's reconstruction after the 1693 earthquake, both politically and
culturally. How could the digital historical methodology fulfil the traditional
Historiography gap about how this noble family built its mighty? As we know,
Humanities cannot easily be encapsulated in a few understandable numbers and
names. However, historians, boosting Artificial Intelligence, such as
Transkribus, and applying Historical Networks Analysis could help computers
infer computable meaning from the digitised historical primary source. The
Turing Machine became the most powerful tool to help historians understand what
happened in the Past and identify the actors in cities and places' cultural and
political renewal.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11507" title="Abstract">arXiv:2312.11507</a> [<a href="/pdf/2312.11507" title="Download PDF">pdf</a>, <a href="/format/2312.11507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explain To Decide: A Human-Centric Review on the Role of Explainable  Artificial Intelligence in AI-assisted Decision Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rogha%2C+M">Milad Rogha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The unprecedented performance of machine learning models in recent years,
particularly Deep Learning and transformer models, has resulted in their
application in various domains such as finance, healthcare, and education.
However, the models are error-prone and cannot be used autonomously, especially
in decision-making scenarios where, technically or ethically, the cost of error
is high. Moreover, because of the black-box nature of these models, it is
frequently difficult for the end user to comprehend the models' outcomes and
underlying processes to trust and use the model outcome to make a decision.
Explainable Artificial Intelligence (XAI) aids end-user understanding of the
model by utilizing approaches, including visualization techniques, to explain
and interpret the inner workings of the model and how it arrives at a result.
Although numerous research studies have been conducted recently focusing on the
performance of models and the XAI approaches, less work has been done on the
impact of explanations on human-AI team performance. This paper surveyed the
recent empirical studies on XAI's impact on human-AI decision-making,
identified the challenges, and proposed future research directions.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11508" title="Abstract">arXiv:2312.11508</a> [<a href="/pdf/2312.11508" title="Download PDF">pdf</a>, <a href="/format/2312.11508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variety and Quality over Quantity: Towards Versatile Instruction  Curation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yongqiang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yufan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+M">Mengnan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Maoquan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+B">Bin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Sundaresan%2C+N">Neel Sundaresan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Instruction fine-tuning, involving the refinement of pre-trained LLMs using
datasets accompanied by natural instructions, is a powerful approach. However,
its effectiveness is hindered by the redundancy and deficiencies in
LLM-generated instruction datasets. In this paper, we introduce a highly
effective and versatile paradigm for selecting diverse and high-quality
instruction-following data from fine-tuning datasets. We first employ the
dataset enhancement and expansion to augment the dataset with more diverse and
high-quality data, then we apply variety compression and quality compression
sequentially to curate the desired dataset. Our experimental results showcase
that, even with a limited quantity of high-quality instruction data, LLMs
consistently maintain robust performance across both natural language
understanding tasks and code generation tasks. Notably, they outperform models
trained on significantly larger instruction datasets in certain instances.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11509" title="Abstract">arXiv:2312.11509</a> [<a href="/pdf/2312.11509" title="Download PDF">pdf</a>, <a href="/format/2312.11509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward A Reinforcement-Learning-Based System for Adjusting Medication to  Minimize Speech Disfluency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Constas%2C+P">Pavlos Constas</a>, 
<a href="/search/cs?searchtype=author&query=Rawal%2C+V">Vikram Rawal</a>, 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+M+H">Matthew Honorio Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Constas%2C+A">Andreas Constas</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Aditya Khan</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+K">Kaison Cheung</a>, 
<a href="/search/cs?searchtype=author&query=Sultani%2C+N">Najma Sultani</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Carrie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Altomare%2C+M">Micol Altomare</a>, 
<a href="/search/cs?searchtype=author&query=Akzam%2C+M">Michael Akzam</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiacheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+V">Vhea He</a>, 
<a href="/search/cs?searchtype=author&query=Altomare%2C+L">Lauren Altomare</a>, 
<a href="/search/cs?searchtype=author&query=Murqi%2C+H">Heraa Murqi</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Asad Khan</a>, 
<a href="/search/cs?searchtype=author&query=Bhanshali%2C+N+A">Nimit Amikumar Bhanshali</a>, 
<a href="/search/cs?searchtype=author&query=Rachad%2C+Y">Youssef Rachad</a>, 
<a href="/search/cs?searchtype=author&query=Guerzhoy%2C+M">Michael Guerzhoy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proc. Machine Learning for Cognitive and Mental Health Workshop (ML4CMH) at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We propose a Reinforcement-Learning-based system that would automatically
prescribe a hypothetical patient medications that may help the patient with
their mental-health-related speech disfluency, and adjust the medication and
the dosages in response to data from the patient. We demonstrate the components
of the system: a module that detects and evaluates speech disfluency on a large
dataset we built, and a Reinforcement Learning algorithm that automatically
finds good combinations of medications. To support the two modules, we collect
data on the effect of psychiatric medications for speech disfluency from the
literature, and build a plausible patient simulation system. We demonstrate
that the Reinforcement Learning system is, under some circumstances, able to
converge to a good medication regime. We collect and label a dataset of people
with possible speech disfluency and demonstrate our methods using that dataset.
Our work is a proof of concept: we show that there is promise in the idea of
using automatic data collection to address disfluency.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11510" title="Abstract">arXiv:2312.11510</a> [<a href="/pdf/2312.11510" title="Download PDF">pdf</a>, <a href="/format/2312.11510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QuadAttack: A Quadratic Programming Approach to Ordered Top-K Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paniagua%2C+T">Thomas Paniagua</a>, 
<a href="/search/cs?searchtype=author&query=Grainger%2C+R">Ryan Grainger</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianfu Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The adversarial vulnerability of Deep Neural Networks (DNNs) has been
well-known and widely concerned, often under the context of learning top-$1$
attacks (e.g., fooling a DNN to classify a cat image as dog). This paper shows
that the concern is much more serious by learning significantly more aggressive
ordered top-$K$ clear-box~\footnote{ This is often referred to as
white/black-box attacks in the literature. We choose to adopt neutral
terminology, clear/opaque-box attacks in this paper, and omit the prefix
clear-box for simplicity.} targeted attacks proposed in Adversarial
Distillation. We propose a novel and rigorous quadratic programming (QP) method
of learning ordered top-$K$ attacks with low computing cost, dubbed as
\textbf{QuadAttac$K$}. Our QuadAttac$K$ directly solves the QP to satisfy the
attack constraint in the feature embedding space (i.e., the input space to the
final linear classifier), which thus exploits the semantics of the feature
embedding space (i.e., the principle of class coherence). With the optimized
feature embedding vector perturbation, it then computes the adversarial
perturbation in the data space via the vanilla one-step back-propagation. In
experiments, the proposed QuadAttac$K$ is tested in the ImageNet-1k
classification using ResNet-50, DenseNet-121, and Vision Transformers (ViT-B
and DEiT-S). It successfully pushes the boundary of successful ordered top-$K$
attacks from $K=10$ up to $K=20$ at a cheap budget ($1\times 60$) and further
improves attack success rates for $K=5$ for all tested models, while retaining
the performance for $K=1$.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11511" title="Abstract">arXiv:2312.11511</a> [<a href="/pdf/2312.11511" title="Download PDF">pdf</a>, <a href="/format/2312.11511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ComplexityNet: Increasing LLM Inference Efficiency by Learning Task  Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bae%2C+H">Henry Bae</a>, 
<a href="/search/cs?searchtype=author&query=Deeb%2C+A">Aghyad Deeb</a>, 
<a href="/search/cs?searchtype=author&query=Fleury%2C+A">Alex Fleury</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Kehang Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present ComplexityNet, a streamlined language model designed for assessing
task complexity. This model predicts the likelihood of accurate output by
various language models, each with different capabilities. Our initial
application of ComplexityNet involves the Mostly Basic Python Problems (MBPP)
dataset. We pioneered the creation of the first set of labels to define task
complexity. ComplexityNet achieved a notable 79% accuracy in determining task
complexity, a significant improvement over the 34% accuracy of the original,
non fine-tuned model. Furthermore, ComplexityNet effectively reduces
computational resource usage by 90% compared to using the highest complexity
model, while maintaining a high code generation accuracy of 86.7%. This study
demonstrates that fine-tuning smaller models to categorize tasks based on their
complexity can lead to a more balanced trade-off between accuracy and
efficiency in the use of Large Language Models. Our findings suggest a
promising direction for optimizing LLM applications, especially in
resource-constrained environments.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11512" title="Abstract">arXiv:2312.11512</a> [<a href="/pdf/2312.11512" title="Download PDF">pdf</a>, <a href="/format/2312.11512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Path Signature Representation of Patient-Clinician Interactions as a  Predictor for Neuropsychological Tests Outcomes in Children: A Proof of  Concept
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Falcioni%2C+G">Giulio Falcioni</a>, 
<a href="/search/cs?searchtype=author&query=Georgescu%2C+A">Alexandra Georgescu</a>, 
<a href="/search/cs?searchtype=author&query=Molimpakis%2C+E">Emilia Molimpakis</a>, 
<a href="/search/cs?searchtype=author&query=Gottlieb%2C+L">Lev Gottlieb</a>, 
<a href="/search/cs?searchtype=author&query=Kuhn%2C+T">Taylor Kuhn</a>, 
<a href="/search/cs?searchtype=author&query=Goria%2C+S">Stefano Goria</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted in IEEE MedAI 2023 conference proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This research report presents a proof-of-concept study on the application of
machine learning techniques to video and speech data collected during
diagnostic cognitive assessments of children with a neurodevelopmental
disorder. The study utilised a dataset of 39 video recordings, capturing
extensive sessions where clinicians administered, among other things, four
cognitive assessment tests. From the first 40 minutes of each clinical session,
covering the administration of the Wechsler Intelligence Scale for Children
(WISC-V), we extracted head positions and speech turns of both clinician and
child. Despite the limited sample size and heterogeneous recording styles, the
analysis successfully extracted path signatures as features from the recorded
data, focusing on patient-clinician interactions. Importantly, these features
quantify the interpersonal dynamics of the assessment process (dialogue and
movement patterns). Results suggest that these features exhibit promising
potential for predicting all cognitive tests scores of the entire session
length and for prototyping a predictive model as a clinical decision support
tool. Overall, this proof of concept demonstrates the feasibility of leveraging
machine learning techniques for clinical video and speech data analysis in
order to potentially enhance the efficiency of cognitive assessments for
neurodevelopmental disorders in children.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11513" title="Abstract">arXiv:2312.11513</a> [<a href="/pdf/2312.11513" title="Download PDF">pdf</a>, <a href="/format/2312.11513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maatphor: Automated Variant Analysis for Prompt Injection Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salem%2C+A">Ahmed Salem</a>, 
<a href="/search/cs?searchtype=author&query=Paverd%2C+A">Andrew Paverd</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6pf%2C+B">Boris K&#xf6;pf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Prompt injection has emerged as a serious security threat to large language
models (LLMs). At present, the current best-practice for defending against
newly-discovered prompt injection techniques is to add additional guardrails to
the system (e.g., by updating the system prompt or using classifiers on the
input and/or output of the model.) However, in the same way that variants of a
piece of malware are created to evade anti-virus software, variants of a prompt
injection can be created to evade the LLM's guardrails. Ideally, when a new
prompt injection technique is discovered, candidate defenses should be tested
not only against the successful prompt injection, but also against possible
variants.
<br />In this work, we present, a tool to assist defenders in performing automated
variant analysis of known prompt injection attacks. This involves solving two
main challenges: (1) automatically generating variants of a given prompt
according, and (2) automatically determining whether a variant was effective
based only on the output of the model. This tool can also assist in generating
datasets for jailbreak and prompt injection attacks, thus overcoming the
scarcity of data in this domain.
<br />We evaluate Maatphor on three different types of prompt injection tasks.
Starting from an ineffective (0%) seed prompt, Maatphor consistently generates
variants that are at least 60% effective within the first 40 iterations.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11514" title="Abstract">arXiv:2312.11514</a> [<a href="/pdf/2312.11514" title="Download PDF">pdf</a>, <a href="/format/2312.11514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM in a flash: Efficient Large Language Model Inference with Limited  Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alizadeh%2C+K">Keivan Alizadeh</a>, 
<a href="/search/cs?searchtype=author&query=Mirzadeh%2C+I">Iman Mirzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Belenko%2C+D">Dmitry Belenko</a>, 
<a href="/search/cs?searchtype=author&query=Khatamifard%2C+K">Karen Khatamifard</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+M">Minsik Cho</a>, 
<a href="/search/cs?searchtype=author&query=Del+Mundo%2C+C+C">Carlo C Del Mundo</a>, 
<a href="/search/cs?searchtype=author&query=Rastegari%2C+M">Mohammad Rastegari</a>, 
<a href="/search/cs?searchtype=author&query=Farajtabar%2C+M">Mehrdad Farajtabar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) are central to modern natural language
processing, delivering exceptional performance in various tasks. However, their
intensive computational and memory requirements present challenges, especially
for devices with limited DRAM capacity. This paper tackles the challenge of
efficiently running LLMs that exceed the available DRAM capacity by storing the
model parameters on flash memory but bringing them on demand to DRAM. Our
method involves constructing an inference cost model that harmonizes with the
flash memory behavior, guiding us to optimize in two critical areas: reducing
the volume of data transferred from flash and reading data in larger, more
contiguous chunks. Within this flash memory-informed framework, we introduce
two principal techniques. First, "windowing'" strategically reduces data
transfer by reusing previously activated neurons, and second, "row-column
bundling", tailored to the sequential data access strengths of flash memory,
increases the size of data chunks read from flash memory. These methods
collectively enable running models up to twice the size of the available DRAM,
with a 4-5x and 20-25x increase in inference speed compared to naive loading
approaches in CPU and GPU, respectively. Our integration of sparsity awareness,
context-adaptive loading, and a hardware-oriented design paves the way for
effective inference of LLMs on devices with limited memory.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11517" title="Abstract">arXiv:2312.11517</a> [<a href="/pdf/2312.11517" title="Download PDF">pdf</a>, <a href="/format/2312.11517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unlocking Musculoskeletal Disorder Risk Factors: NLP-Based  Classification and Mode-Based Ranking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jahin%2C+M+A">Md Abrar Jahin</a>, 
<a href="/search/cs?searchtype=author&query=Talapatra%2C+S">Subrata Talapatra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This research delves into the intricate landscape of Musculoskeletal Disorder
(MSD) risk factors, employing a novel fusion of Natural Language Processing
(NLP) techniques and mode-based ranking methodologies. The primary objective is
to advance the comprehension of MSD risk factors, their classification, and
their relative severity, facilitating more targeted preventive and management
interventions. The study utilizes eight diverse models, integrating pre-trained
transformers, cosine similarity, and various distance metrics to classify risk
factors into personal, biomechanical, workplace, psychological, and
organizational classes. Key findings reveal that the BERT model with cosine
similarity attains an overall accuracy of 28\%, while the sentence transformer,
coupled with Euclidean, Bray-Curtis, and Minkowski distances, achieves a
flawless accuracy score of 100\%. In tandem with the classification efforts,
the research employs a mode-based ranking approach on survey data to discern
the severity hierarchy of MSD risk factors. Intriguingly, the rankings align
precisely with the previous literature, reaffirming the consistency and
reliability of the approach. ``Working posture" emerges as the most severe risk
factor, emphasizing the critical role of proper posture in preventing MSDs. The
collective perceptions of survey participants underscore the significance of
factors like ``Job insecurity," ``Effort reward imbalance," and ``Poor employee
facility" in contributing to MSD risks. The convergence of rankings provides
actionable insights for organizations aiming to reduce the prevalence of MSDs.
The study concludes with implications for targeted interventions,
recommendations for improving workplace conditions, and avenues for future
research.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11518" title="Abstract">arXiv:2312.11518</a> [<a href="/pdf/2312.11518" title="Download PDF">pdf</a>, <a href="/format/2312.11518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User Modeling in the Era of Large Language Models: Current Research and  Future Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhaoxuan Tan</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Meng Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Data Engineering Bulletin 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">User modeling (UM) aims to discover patterns or learn representations from
user data about the characteristics of a specific user, such as profile,
preference, and personality. The user models enable personalization and
suspiciousness detection in many online applications such as recommendation,
education, and healthcare. Two common types of user data are text and graph, as
the data usually contain a large amount of user-generated content (UGC) and
online interactions. The research of text and graph mining is developing
rapidly, contributing many notable solutions in the past two decades. Recently,
large language models (LLMs) have shown superior performance on generating,
understanding, and even reasoning over text data. The approaches of user
modeling have been equipped with LLMs and soon become outstanding. This article
summarizes existing research about how and why LLMs are great tools of modeling
and understanding UGC. Then it reviews a few categories of large language
models for user modeling (LLM-UM) approaches that integrate the LLMs with text
and graph-based methods in different ways. Then it introduces specific LLM-UM
techniques for a variety of UM applications. Finally, it presents remaining
challenges and future directions in the LLM-UM research. We maintain the
reading list at: https://github.com/TamSiuhin/LLM-UM-Reading
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11519" title="Abstract">arXiv:2312.11519</a> [<a href="/pdf/2312.11519" title="Download PDF">pdf</a>, <a href="/ps/2312.11519" title="Download PostScript">ps</a>, <a href="/format/2312.11519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysing user sentiment data for architectural interior spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M+K">Mi Kyoung Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">This study aims to develop a data driven system to enhance the analysis and
improvement of user experiences in interior spaces, acknowledging the
significant impact of design on individuals health, productivity, and quality
of life.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11520" title="Abstract">arXiv:2312.11520</a> [<a href="/pdf/2312.11520" title="Download PDF">pdf</a>, <a href="/ps/2312.11520" title="Download PostScript">ps</a>, <a href="/format/2312.11520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implementing biosensing based user preference visualisation in  architectural spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M+K">Mi Kyoung Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">This study delves into the interplay between architectural spaces and human
emotions, leveraging the emergent field of neuroarchitecture. It examines the
functional and aesthetic influence of architectural design on individual users,
with a focus on biosensing data such as brainwave and eye tracking information
to understand user preferences.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11521" title="Abstract">arXiv:2312.11521</a> [<a href="/pdf/2312.11521" title="Download PDF">pdf</a>, <a href="/format/2312.11521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models are Complex Table Parsers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bowen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+C">Changkai Ji</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuejie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+W">Wen He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yingwen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+R">Rui Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaobo Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Main
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the Generative Pre-trained Transformer 3.5 (GPT-3.5) exhibiting
remarkable reasoning and comprehension abilities in Natural Language Processing
(NLP), most Question Answering (QA) research has primarily centered around
general QA tasks based on GPT, neglecting the specific challenges posed by
Complex Table QA. In this paper, we propose to incorporate GPT-3.5 to address
such challenges, in which complex tables are reconstructed into tuples and
specific prompt designs are employed for dialogues. Specifically, we encode
each cell's hierarchical structure, position information, and content as a
tuple. By enhancing the prompt template with an explanatory description of the
meaning of each tuple and the logical reasoning process of the task, we
effectively improve the hierarchical structure awareness capability of GPT-3.5
to better parse the complex tables. Extensive experiments and results on
Complex Table QA datasets, i.e., the open-domain dataset HiTAB and the aviation
domain dataset AIT-QA show that our approach significantly outperforms previous
work on both datasets, leading to state-of-the-art (SOTA) performance.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11522" title="Abstract">arXiv:2312.11522</a> [<a href="/pdf/2312.11522" title="Download PDF">pdf</a>, <a href="/format/2312.11522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing SATNet&#x27;s Ability to Solve the Symbol Grounding Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+O">Oscar Chang</a>, 
<a href="/search/cs?searchtype=author&query=Flokas%2C+L">Lampros Flokas</a>, 
<a href="/search/cs?searchtype=author&query=Lipson%2C+H">Hod Lipson</a>, 
<a href="/search/cs?searchtype=author&query=Spranger%2C+M">Michael Spranger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">SATNet is an award-winning MAXSAT solver that can be used to infer logical
rules and integrated as a differentiable layer in a deep neural network. It had
been shown to solve Sudoku puzzles visually from examples of puzzle digit
images, and was heralded as an impressive achievement towards the longstanding
AI goal of combining pattern recognition with logical reasoning. In this paper,
we clarify SATNet's capabilities by showing that in the absence of intermediate
labels that identify individual Sudoku digit images with their logical
representations, SATNet completely fails at visual Sudoku (0% test accuracy).
More generally, the failure can be pinpointed to its inability to learn to
assign symbols to perceptual phenomena, also known as the symbol grounding
problem, which has long been thought to be a prerequisite for intelligent
agents to perform real-world logical reasoning. We propose an MNIST based test
as an easy instance of the symbol grounding problem that can serve as a sanity
check for differentiable symbolic solvers in general. Naive applications of
SATNet on this test lead to performance worse than that of models without
logical reasoning capabilities. We report on the causes of SATNet's failure and
how to prevent them.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11523" title="Abstract">arXiv:2312.11523</a> [<a href="/pdf/2312.11523" title="Download PDF">pdf</a>, <a href="/format/2312.11523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ToViLaG: Your Visual-Language Generative Model is Also An Evildoer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+X">Xiaoyuan Yi</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Han Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shanlin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhihua Wei</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP 2023 (Main Conference), Oral Presentation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Warning: this paper includes model outputs showing offensive content. Recent
large-scale Visual-Language Generative Models (VLGMs) have achieved
unprecedented improvement in multimodal image/text generation. However, these
models might also generate toxic content, e.g., offensive text and pornography
images, raising significant ethical risks. Despite exhaustive studies on toxic
degeneration of language models, this problem remains largely unexplored within
the context of visual-language generation. This work delves into the propensity
for toxicity generation and susceptibility to toxic data across various VLGMs.
For this purpose, we built ToViLaG, a dataset comprising 32K
co-toxic/mono-toxic text-image pairs and 1K innocuous but evocative text that
tends to stimulate toxicity. Furthermore, we propose WInToRe, a novel toxicity
metric tailored to visual-language generation, which theoretically reflects
different aspects of toxicity considering both input and output. On such a
basis, we benchmarked the toxicity of a diverse spectrum of VLGMs and
discovered that some models do more evil than expected while some are more
vulnerable to infection, underscoring the necessity of VLGMs detoxification.
Therefore, we develop an innovative bottleneck-based detoxification method. Our
method could reduce toxicity while maintaining comparable generation quality,
providing a promising initial solution to this line of research.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11524" title="Abstract">arXiv:2312.11524</a> [<a href="/pdf/2312.11524" title="Download PDF">pdf</a>, <a href="/format/2312.11524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing GPT4-V on Structured Reasoning Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+M">Mukul Singh</a>, 
<a href="/search/cs?searchtype=author&query=Cambronero%2C+J">Jos&#xe9; Cambronero</a>, 
<a href="/search/cs?searchtype=author&query=Gulwani%2C+S">Sumit Gulwani</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+V">Vu Le</a>, 
<a href="/search/cs?searchtype=author&query=Verbruggen%2C+G">Gust Verbruggen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Multi-modality promises to unlock further uses for large language models.
Recently, the state-of-the-art language model GPT-4 was enhanced with vision
capabilities. We carry out a prompting evaluation of GPT-4V and five other
baselines on structured reasoning tasks, such as mathematical reasoning, visual
data analysis, and code generation. We show that visual Chain-of-Thought, an
extension of Chain-of-Thought to multi-modal LLMs, yields significant
improvements over the vanilla model. We also present a categorized analysis of
scenarios where these models perform well and where they struggle, highlighting
challenges associated with coherent multimodal reasoning.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11525" title="Abstract">arXiv:2312.11525</a> [<a href="/pdf/2312.11525" title="Download PDF">pdf</a>, <a href="/format/2312.11525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synocene, Beyond the Anthropocene: De-Anthropocentralising  Human-Nature-AI Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hupont%2C+I">Isabelle Hupont</a>, 
<a href="/search/cs?searchtype=author&query=Wainer%2C+M">Marina Wainer</a>, 
<a href="/search/cs?searchtype=author&query=Nester%2C+S">Sam Nester</a>, 
<a href="/search/cs?searchtype=author&query=Tissot%2C+S">Sylvie Tissot</a>, 
<a href="/search/cs?searchtype=author&query=Iglesias-Blanco%2C+L">Luc&#xed;a Iglesias-Blanco</a>, 
<a href="/search/cs?searchtype=author&query=Baldassarri%2C+S">Sandra Baldassarri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent publications explore AI biases in detecting objects and people in the
environment. However, there is no research tackling how AI examines nature.
This case study presents a pioneering exploration into the AI attitudes
(ecocentric, anthropocentric and antipathetic) toward nature. Experiments with
a Large Language Model (LLM) and an image captioning algorithm demonstrate the
presence of anthropocentric biases in AI. Moreover, to delve deeper into these
biases and Human-Nature-AI interaction, we conducted a real-life experiment in
which participants underwent an immersive de-anthropocentric experience in a
forest and subsequently engaged with ChatGPT to co-create narratives. By
creating fictional AI chatbot characters with ecocentric attributes, emotions
and views, we successfully amplified ecocentric exchanges. We encountered some
difficulties, mainly that participants deviated from narrative co-creation to
short dialogues and questions and answers, possibly due to the novelty of
interacting with LLMs. To solve this problem, we recommend providing
preliminary guidelines on interacting with LLMs and allowing participants to
get familiar with the technology. We plan to repeat this experiment in various
countries and forests to expand our corpus of ecocentric materials.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11526" title="Abstract">arXiv:2312.11526</a> [<a href="/pdf/2312.11526" title="Download PDF">pdf</a>, <a href="/format/2312.11526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ABiMed: An intelligent and visual clinical decision support system for  medication reviews and polypharmacy management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mouazer%2C+A">Abdelmalek Mouazer</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%A9guillon%2C+R">Romain L&#xe9;guillon</a>, 
<a href="/search/cs?searchtype=author&query=Boudegzdame%2C+N">Nada Boudegzdame</a>, 
<a href="/search/cs?searchtype=author&query=Levrard%2C+T">Thibaud Levrard</a>, 
<a href="/search/cs?searchtype=author&query=Bars%2C+Y+L">Yoann Le Bars</a>, 
<a href="/search/cs?searchtype=author&query=Simon%2C+C">Christian Simon</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A9roussi%2C+B">Brigitte S&#xe9;roussi</a>, 
<a href="/search/cs?searchtype=author&query=Grosjean%2C+J">Julien Grosjean</a>, 
<a href="/search/cs?searchtype=author&query=Lelong%2C+R">Romain Lelong</a>, 
<a href="/search/cs?searchtype=author&query=Letord%2C+C">Catherine Letord</a>, 
<a href="/search/cs?searchtype=author&query=Darmoni%2C+S">St&#xe9;fan Darmoni</a>, 
<a href="/search/cs?searchtype=author&query=Schuers%2C+M">Matthieu Schuers</a>, 
<a href="/search/cs?searchtype=author&query=Sedki%2C+K">Karima Sedki</a>, 
<a href="/search/cs?searchtype=author&query=Dubois%2C+S">Sophie Dubois</a>, 
<a href="/search/cs?searchtype=author&query=Falcoff%2C+H">Hector Falcoff</a>, 
<a href="/search/cs?searchtype=author&query=Tsopra%2C+R">Rosy Tsopra</a>, 
<a href="/search/cs?searchtype=author&query=Lamy%2C+J">Jean-Baptiste Lamy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Background: Polypharmacy, i.e. taking five drugs or more, is both a public
health and an economic issue. Medication reviews are structured interviews of
the patient by the community pharmacist, aiming at optimizing the drug
treatment and deprescribing useless, redundant or dangerous drugs. However,
they remain difficult to perform and time-consuming. Several clinical decision
support systems were developed for helping clinicians to manage polypharmacy.
However, most were limited to the implementation of clinical practice
guidelines. In this work, our objective is to design an innovative clinical
decision support system for medication reviews and polypharmacy management,
named ABiMed.
<br />Methods: ABiMed associates several approaches: guidelines implementation, but
the automatic extraction of patient data from the GP's electronic health record
and its transfer to the pharmacist, and the visual presentation of
contextualized drug knowledge using visual analytics. We performed an ergonomic
assessment and qualitative evaluations involving pharmacists and GPs during
focus groups and workshops.
<br />Results: We describe the proposed architecture, which allows a collaborative
multi-user usage. We present the various screens of ABiMed for entering or
verifying patient data, for accessing drug knowledge (posology, adverse
effects, interactions), for viewing STOPP/START rules and for suggesting
modification to the treatment. Qualitative evaluations showed that health
professionals were highly interested by our approach, associating the automatic
guidelines execution with the visual presentation of drug knowledge.
<br />Conclusions: The association of guidelines implementation with visual
presentation of knowledge is a promising approach for managing polypharmacy.
Future works will focus on the improvement and the evaluation of ABiMed.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11527" title="Abstract">arXiv:2312.11527</a> [<a href="/pdf/2312.11527" title="Download PDF">pdf</a>, <a href="/format/2312.11527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simulated Annealing-Based Multiobjective Optimization Algorithm for  Minimum Weight Minimum Connected Dominating Set Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dahmri%2C+H">Hayet Dahmri</a>, 
<a href="/search/cs?searchtype=author&query=Bouamama%2C+S">Salim Bouamama</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Minimum connected dominating set problem is an NP-hard combinatorial
optimization problem in graph theory. Finding connected dominating set is of
high interest in various domains such as wireless sensor networks, optical
networks, and systems biology. Its weighted variant named minimum weight
connected dominating set is also useful in such applications. In this paper, we
propose a simulated annealing algorithm based on a greedy heuristic for
tackling a variant of the minimum connected dominating set problem and that by
exploiting two objectives together namely the cardinality and the total weight
of the connected dominating set. Experimental results compared to those
obtained by a recent proposed research show the superiority of our approach.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11529" title="Abstract">arXiv:2312.11529</a> [<a href="/pdf/2312.11529" title="Download PDF">pdf</a>, <a href="/format/2312.11529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient and Scalable Graph Generation through Iterative Local  Expansion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bergmeister%2C+A">Andreas Bergmeister</a>, 
<a href="/search/cs?searchtype=author&query=Martinkus%2C+K">Karolis Martinkus</a>, 
<a href="/search/cs?searchtype=author&query=Perraudin%2C+N">Nathana&#xeb;l Perraudin</a>, 
<a href="/search/cs?searchtype=author&query=Wattenhofer%2C+R">Roger Wattenhofer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the realm of generative models for graphs, extensive research has been
conducted. However, most existing methods struggle with large graphs due to the
complexity of representing the entire joint distribution across all node pairs
and capturing both global and local graph structures simultaneously. To
overcome these issues, we introduce a method that generates a graph by
progressively expanding a single node to a target graph. In each step, nodes
and edges are added in a localized manner through denoising diffusion, building
first the global structure, and then refining the local details. The local
generation avoids modeling the entire joint distribution over all node pairs,
achieving substantial computational savings with subquadratic runtime relative
to node count while maintaining high expressivity through multiscale
generation. Our experiments show that our model achieves state-of-the-art
performance on well-established benchmark datasets while successfully scaling
to graphs with at least 5000 nodes. Our method is also the first to
successfully extrapolate to graphs outside of the training distribution,
showcasing a much better generalization capability over existing methods.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11532" title="Abstract">arXiv:2312.11532</a> [<a href="/pdf/2312.11532" title="Download PDF">pdf</a>, <a href="/format/2312.11532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topic-VQ-VAE: Leveraging Latent Codebooks for Flexible Topic-Guided  Document Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoo%2C+Y">YoungJoon Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jongwon Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in the 38th annual AAAI conference on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper introduces a novel approach for topic modeling utilizing latent
codebooks from Vector-Quantized Variational Auto-Encoder~(VQ-VAE), discretely
encapsulating the rich information of the pre-trained embeddings such as the
pre-trained language model. From the novel interpretation of the latent
codebooks and embeddings as conceptual bag-of-words, we propose a new
generative topic model called Topic-VQ-VAE~(TVQ-VAE) which inversely generates
the original documents related to the respective latent codebook. The TVQ-VAE
can visualize the topics with various generative distributions including the
traditional BoW distribution and the autoregressive image generation. Our
experimental results on document analysis and image generation demonstrate that
TVQ-VAE effectively captures the topic context which reveals the underlying
structures of the dataset and supports flexible forms of document generation.
Official implementation of the proposed TVQ-VAE is available at
https://github.com/clovaai/TVQ-VAE.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11533" title="Abstract">arXiv:2312.11533</a> [<a href="/pdf/2312.11533" title="Download PDF">pdf</a>, <a href="/ps/2312.11533" title="Download PostScript">ps</a>, <a href="/format/2312.11533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cryptanalysis of PLWE based on zero-trace quadratic roots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barbero-Lucas%2C+B">Beatriz Barbero-Lucas</a>, 
<a href="/search/cs?searchtype=author&query=Blanco-Chac%C3%B3n%2C+I">Iv&#xe1;n Blanco-Chac&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Dur%C3%A1n-D%C3%ADaz%2C+R">Ra&#xfa;l Dur&#xe1;n-D&#xed;az</a>, 
<a href="/search/cs?searchtype=author&query=Nchiwo%2C+R+Y+N">Rahinatou Yuh Njah Nchiwo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages. arXiv admin note: substantial text overlap with <a href="/abs/2209.11962">arXiv:2209.11962</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">We extend two of the attacks on the PLWE problem presented in (Y. Elias, K.
E. Lauter, E. Ozman, and K. E. Stange, Ring-LWE Cryptography for the Number
Theorist, in Directions in Number Theory, E. E. Eischen, L. Long, R. Pries, and
K. E. Stange, eds., vol. 3 of Association for Women in Mathematics Series,
Cham, 2016, Springer International Publishing, pp. 271-290) to a ring
$R_q=\mathbb{F}_q[x]/(f(x))$ where the irreducible monic polynomial
$f(x)\in\mathbb{Z}[x]$ has an irreducible quadratic factor over
$\mathbb{F}_q[x]$ of the form $x^2+\rho$ with $\rho$ of suitable multiplicative
order in $\mathbb{F}_q$. Our attack exploits the fact that the trace of the
root is zero and has overwhelming success probability as a function of the
number of samples taken as input. An implementation in Maple and some examples
of our attack are also provided.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11534" title="Abstract">arXiv:2312.11534</a> [<a href="/pdf/2312.11534" title="Download PDF">pdf</a>, <a href="/ps/2312.11534" title="Download PostScript">ps</a>, <a href="/format/2312.11534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Differentially Private and Lazy Online Convex Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+N">Naman Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Kale%2C+S">Satyen Kale</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+K">Karan Singh</a>, 
<a href="/search/cs?searchtype=author&query=Thakurta%2C+A+G">Abhradeep Guha Thakurta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study the task of $(\epsilon, \delta)$-differentially private online
convex optimization (OCO). In the online setting, the release of each distinct
decision or iterate carries with it the potential for privacy loss. This
problem has a long history of research starting with Jain et al. [2012] and the
best known results for the regime of {\epsilon} being very small are presented
in Agarwal et al. [2023]. In this paper we improve upon the results of Agarwal
et al. [2023] in terms of the dimension factors as well as removing the
requirement of smoothness. Our results are now the best known rates for DP-OCO
in this regime.
<br />Our algorithms builds upon the work of [Asi et al., 2023] which introduced
the idea of explicitly limiting the number of switches via rejection sampling.
The main innovation in our algorithm is the use of sampling from a strongly
log-concave density which allows us to trade-off the dimension factors better
leading to improved results.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11535" title="Abstract">arXiv:2312.11535</a> [<a href="/pdf/2312.11535" title="Download PDF">pdf</a>, <a href="/format/2312.11535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Customize-It-3D: High-Quality 3D Creation from A Single Image Using  Subject-Specific Knowledge Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+N">Nan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Ting Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuhui Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanghang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://nnanhuang.github.io/projects/customize-it-3d/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we present a novel two-stage approach that fully utilizes the
information provided by the reference image to establish a customized knowledge
prior for image-to-3D generation. While previous approaches primarily rely on a
general diffusion prior, which struggles to yield consistent results with the
reference image, we propose a subject-specific and multi-modal diffusion model.
This model not only aids NeRF optimization by considering the shading mode for
improved geometry but also enhances texture from the coarse results to achieve
superior refinement. Both aspects contribute to faithfully aligning the 3D
content with the subject. Extensive experiments showcase the superiority of our
method, Customize-It-3D, outperforming previous works by a substantial margin.
It produces faithful 360-degree reconstructions with impressive visual quality,
making it well-suited for various applications, including text-to-3D creation.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11536" title="Abstract">arXiv:2312.11536</a> [<a href="/pdf/2312.11536" title="Download PDF">pdf</a>, <a href="/format/2312.11536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Decision Boundary based Out-of-Distribution Detector
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Litian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yao Qin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Efficient and effective Out-of-Distribution (OOD) detection is essential for
the safe deployment of AI in latency-critical applications. Recently, studies
have revealed that detecting OOD based on feature space information can be
highly effective. Despite their effectiveness, however, exiting feature space
OOD methods may incur non-negligible computational overhead, given their
reliance on auxiliary models built from training features. In this paper, we
aim to obviate auxiliary models to optimize computational efficiency while
leveraging the rich information embedded in the feature space. We investigate
from the novel perspective of decision boundaries and propose to detect OOD
using the feature distance to decision boundaries. To minimize the cost of
measuring the distance, we introduce an efficient closed-form estimation,
analytically proven to tightly lower bound the distance. We observe that ID
features tend to reside further from the decision boundaries than OOD features.
Our observation aligns with the intuition that models tend to be more decisive
on ID samples, considering that distance to decision boundaries quantifies
model uncertainty. From our understanding, we propose a hyperparameter-free,
auxiliary model-free OOD detector. Our OOD detector matches or surpasses the
effectiveness of state-of-the-art methods across extensive experiments.
Meanwhile, our OOD detector incurs practically negligible overhead in inference
latency. Overall, we significantly enhance the efficiency-effectiveness
trade-off in OOD detection.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11537" title="Abstract">arXiv:2312.11537</a> [<a href="/pdf/2312.11537" title="Download PDF">pdf</a>, <a href="/format/2312.11537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FastSR-NeRF: Improving NeRF Efficiency on Consumer Devices with A Simple  Super-Resolution Pipeline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chien-Yu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Q">Qichen Fu</a>, 
<a href="/search/cs?searchtype=author&query=Merth%2C+T">Thomas Merth</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Karren Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ranjan%2C+A">Anurag Ranjan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Super-resolution (SR) techniques have recently been proposed to upscale the
outputs of neural radiance fields (NeRF) and generate high-quality images with
enhanced inference speeds. However, existing NeRF+SR methods increase training
overhead by using extra input features, loss functions, and/or expensive
training procedures such as knowledge distillation. In this paper, we aim to
leverage SR for efficiency gains without costly training or architectural
changes. Specifically, we build a simple NeRF+SR pipeline that directly
combines existing modules, and we propose a lightweight augmentation technique,
random patch sampling, for training. Compared to existing NeRF+SR methods, our
pipeline mitigates the SR computing overhead and can be trained up to 23x
faster, making it feasible to run on consumer devices such as the Apple
MacBook. Experiments show our pipeline can upscale NeRF outputs by 2-4x while
maintaining high quality, increasing inference speeds by up to 18x on an NVIDIA
V100 GPU and 12.8x on an M1 Pro chip. We conclude that SR can be a simple but
effective technique for improving the efficiency of NeRF models for consumer
devices.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11538" title="Abstract">arXiv:2312.11538</a> [<a href="/pdf/2312.11538" title="Download PDF">pdf</a>, <a href="/format/2312.11538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterative Motion Editing with Natural Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goel%2C+P">Purvi Goel</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kuan-Chieh Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C+K">C. Karen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fatahalian%2C+K">Kayvon Fatahalian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Text-to-motion diffusion models can generate realistic animations from text
prompts, but do not support fine-grained motion editing controls. In this paper
we present a method for using natural language to iteratively specify local
edits to existing character animations, a task that is common in most computer
animation workflows. Our key idea is to represent a space of motion edits using
a set of kinematic motion operators that have well-defined semantics for how to
modify specific frames of a target motion. We provide an algorithm that
leverages pre-existing language models to translate textual descriptions of
motion edits to sequences of motion editing operators (MEOs). Given new
keyframes produced by the MEOs, we use diffusion-based keyframe interpolation
to generate final motions. Through a user study and quantitative evaluation, we
demonstrate that our system can perform motion edits that respect the
animator's editing intent, remain faithful to the original animation (they edit
the original animation, not dramatically change it), and yield realistic
character animation results.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11539" title="Abstract">arXiv:2312.11539</a> [<a href="/pdf/2312.11539" title="Download PDF">pdf</a>, <a href="/format/2312.11539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KGLens: A Parameterized Knowledge Graph Solution to Assess What an LLM  Does and Doesn&#x27;t Know
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shangshang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+H">He Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yizhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yi Su</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+X">Xiaochuan Niu</a>, 
<a href="/search/cs?searchtype=author&query=Jaitly%2C+N">Navdeep Jaitly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Current approaches to evaluating large language models (LLMs) with
pre-existing Knowledge Graphs (KG) mostly ignore the structure of the KG and
make arbitrary choices of which part of the graph to evaluate. In this paper,
we introduce KGLens, a method to evaluate LLMs by generating natural language
questions from a KG in a structure aware manner so that we can characterize its
performance on a more aggregated level. KGLens uses a parameterized KG, where
each edge is augmented with a beta distribution that guides how to sample edges
from the KG for QA testing. As the evaluation proceeds, different edges of the
parameterized KG are sampled and assessed appropriately, converging to a more
global picture of the performance of the LLMs on the KG as a whole. In our
experiments, we construct three domain-specific KGs for knowledge assessment,
comprising over 19,000 edges, 700 relations, and 21,000 entities. The results
demonstrate that KGLens can not only assess overall performance but also
provide topic, temporal, and relation analyses of LLMs. This showcases the
adaptability and customizability of KGLens, emphasizing its ability to focus
the evaluation based on specific criteria.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11540" title="Abstract">arXiv:2312.11540</a> [<a href="/pdf/2312.11540" title="Download PDF">pdf</a>, <a href="/ps/2312.11540" title="Download PostScript">ps</a>, <a href="/format/2312.11540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Trade-off between the Number of Nodes and the Number of Trees in  a Random Forest
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akutsu%2C+T">Tatsuya Akutsu</a>, 
<a href="/search/cs?searchtype=author&query=Melkman%2C+A+A">Avraham A. Melkman</a>, 
<a href="/search/cs?searchtype=author&query=Takasu%2C+A">Atsuhiro Takasu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper, we focus on the prediction phase of a random forest and study
the problem of representing a bag of decision trees using a smaller bag of
decision trees, where we only consider binary decision problems on the binary
domain and simple decision trees in which an internal node is limited to
querying the Boolean value of a single variable. As a main result, we show that
the majority function of $n$ variables can be represented by a bag of $T$ ($&lt;
n$) decision trees each with polynomial size if $n-T$ is a constant, where $n$
and $T$ must be odd (in order to avoid the tie break). We also show that a bag
of $n$ decision trees can be represented by a bag of $T$ decision trees each
with polynomial size if $n-T$ is a constant and a small classification error is
allowed. A related result on the $k$-out-of-$n$ functions is presented too.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11541" title="Abstract">arXiv:2312.11541</a> [<a href="/pdf/2312.11541" title="Download PDF">pdf</a>, <a href="/format/2312.11541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIPSyntel: CLIP and LLM Synergy for Multimodal Question Summarization  in Healthcare
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+A">Akash Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Acharya%2C+A">Arkadeep Acharya</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+R">Raghav Jain</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+S">Sriparna Saha</a>, 
<a href="/search/cs?searchtype=author&query=Chadha%2C+A">Aman Chadha</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+S">Setu Sinha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">In the era of modern healthcare, swiftly generating medical question
summaries is crucial for informed and timely patient care. Despite the
increasing complexity and volume of medical data, existing studies have focused
solely on text-based summarization, neglecting the integration of visual
information. Recognizing the untapped potential of combining textual queries
with visual representations of medical conditions, we introduce the Multimodal
Medical Question Summarization (MMQS) Dataset. This dataset, a major
contribution to our work, pairs medical queries with visual aids, facilitating
a richer and more nuanced understanding of patient needs. We also propose a
framework, utilizing the power of Contrastive Language Image Pretraining(CLIP)
and Large Language Models(LLMs), consisting of four modules that identify
medical disorders, generate relevant context, filter medical concepts, and
craft visually aware summaries. Our comprehensive framework harnesses the power
of CLIP, a multimodal foundation model, and various general-purpose LLMs,
comprising four main modules: the medical disorder identification module, the
relevant context generation module, the context filtration module for
distilling relevant medical concepts and knowledge, and finally, a
general-purpose LLM to generate visually aware medical question summaries.
Leveraging our MMQS dataset, we showcase how visual cues from images enhance
the generation of medically nuanced summaries. This multimodal approach not
only enhances the decision-making process in healthcare but also fosters a more
nuanced understanding of patient queries, laying the groundwork for future
research in personalized and responsive medical care
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11542" title="Abstract">arXiv:2312.11542</a> [<a href="/pdf/2312.11542" title="Download PDF">pdf</a>, <a href="/format/2312.11542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FER-C: Benchmarking Out-of-Distribution Soft Calibration for Facial  Expression Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neo%2C+D">Dexter Neo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tsuhan Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a soft benchmark for calibrating facial expression recognition
(FER). While prior works have focused on identifying affective states, we find
that FER models are uncalibrated. This is particularly true when
out-of-distribution (OOD) shifts further exacerbate the ambiguity of facial
expressions. While most OOD benchmarks provide hard labels, we argue that the
ground-truth labels for evaluating FER models should be soft in order to better
reflect the ambiguity behind facial behaviours. Our framework proposes soft
labels that closely approximates the average information loss based on
different types of OOD shifts. Finally, we show the benefits of calibration on
five state-of-the-art FER algorithms tested on our benchmark.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11543" title="Abstract">arXiv:2312.11543</a> [<a href="/pdf/2312.11543" title="Download PDF">pdf</a>, <a href="/format/2312.11543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graphs, algorithms and applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tuzhilin%2C+M">Mikhail Tuzhilin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO); Metric Geometry (math.MG); Spectral Theory (math.SP)

</div>
<p class="mathjax">This book is result of Sino-Russian collaboration. It collects the lectures
which were given to students of mathematics departments of Moscow State
University and Peking University about graph theory and its applications. The
book's narrative is sequential: earlier theorems and definitions are used in
later material.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11544" title="Abstract">arXiv:2312.11544</a> [<a href="/pdf/2312.11544" title="Download PDF">pdf</a>, <a href="/format/2312.11544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of Nepotism in Bollywood using Personalized PageRank and  Effective Influence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Apoorv Jain</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Bollywood is one of the largest film-producing industries with a large
worldwide audience. In this paper, we will try to find the most important stars
in the era of 1990 to 2014, as well as try to use social network analysis
methods and metrics to analyze the role of blood connections in getting
opportunities in the industry. We created the actor relationship data of around
1000 debutants using OpenAI API and used a novel approach "Effective Influence"
to study the effect of having a blood-related established actor inside the
industry. We found that on an average every actor/director or actor/actor pair
is reachable by a path of length at most 4 and a correlation of 0.6 indicating
the advantage of having a blood connection inside the network in getting a good
co-cast in the debut film.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11545" title="Abstract">arXiv:2312.11545</a> [<a href="/pdf/2312.11545" title="Download PDF">pdf</a>, <a href="/format/2312.11545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Communicative Multi-Agent Reinforcement Learning with Active  Defense
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lebin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yunbo Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Q">Quanming Yao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yuan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xudong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jian Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Communication in multi-agent reinforcement learning (MARL) has been proven to
effectively promote cooperation among agents recently. Since communication in
real-world scenarios is vulnerable to noises and adversarial attacks, it is
crucial to develop robust communicative MARL technique. However, existing
research in this domain has predominantly focused on passive defense
strategies, where agents receive all messages equally, making it hard to
balance performance and robustness. We propose an active defense strategy,
where agents automatically reduce the impact of potentially harmful messages on
the final decision. There are two challenges to implement this strategy, that
are defining unreliable messages and adjusting the unreliable messages' impact
on the final decision properly. To address them, we design an Active Defense
Multi-Agent Communication framework (ADMAC), which estimates the reliability of
received messages and adjusts their impact on the final decision accordingly
with the help of a decomposable decision structure. The superiority of ADMAC
over existing methods is validated by experiments in three
communication-critical tasks under four types of attacks.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11547" title="Abstract">arXiv:2312.11547</a> [<a href="/pdf/2312.11547" title="Download PDF">pdf</a>, <a href="/format/2312.11547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Pre-training and Adaptation Framework for Combinatorial  Optimization on Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+R">Ruibin Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+M">Minglong Lei</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+L">Lingfeng Niu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lan Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Combinatorial optimization (CO) on graphs is a classic topic that has been
extensively studied across many scientific and industrial fields. Recently,
solving CO problems on graphs through learning methods has attracted great
attention. Advanced deep learning methods, e.g., graph neural networks (GNNs),
have been used to effectively assist the process of solving COs. However,
current frameworks based on GNNs are mainly designed for certain CO problems,
thereby failing to consider their transferable and generalizable abilities
among different COs on graphs. Moreover, simply using original graphs to model
COs only captures the direct correlations among objects, which does not
consider the mathematical logicality and properties of COs. In this paper, we
propose a unified pre-training and adaptation framework for COs on graphs with
the help of the maximum satisfiability (Max-SAT) problem. We first use Max-SAT
to bridge different COs on graphs since they can be converted to Max-SAT
problems represented by standard formulas and clauses with logical information.
Then, we further design a pre-training and domain adaptation framework to
extract the transferable and generalizable features so that different COs can
benefit from them. In the pre-training stage, Max-SAT instances are generated
to initialize the parameters of the model. In the fine-tuning stage, instances
from CO and Max-SAT problems are used for adaptation so that the transferable
ability can be further improved. Numerical experiments on several datasets show
that features extracted by our framework exhibit superior transferability and
Max-SAT can boost the ability to solve COs on graphs.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11548" title="Abstract">arXiv:2312.11548</a> [<a href="/pdf/2312.11548" title="Download PDF">pdf</a>, <a href="/format/2312.11548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Interpretable Queries for Explainable Image Classification with  Information Pursuit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kolek%2C+S">Stefan Kolek</a>, 
<a href="/search/cs?searchtype=author&query=Chattopadhyay%2C+A">Aditya Chattopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+K+H+R">Kwan Ho Ryan Chan</a>, 
<a href="/search/cs?searchtype=author&query=Andrade-Loarca%2C+H">Hector Andrade-Loarca</a>, 
<a href="/search/cs?searchtype=author&query=Kutyniok%2C+G">Gitta Kutyniok</a>, 
<a href="/search/cs?searchtype=author&query=Vidal%2C+R">R&#xe9;ne Vidal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Information Pursuit (IP) is an explainable prediction algorithm that greedily
selects a sequence of interpretable queries about the data in order of
information gain, updating its posterior at each step based on observed
query-answer pairs. The standard paradigm uses hand-crafted dictionaries of
potential data queries curated by a domain expert or a large language model
after a human prompt. However, in practice, hand-crafted dictionaries are
limited by the expertise of the curator and the heuristics of prompt
engineering. This paper introduces a novel approach: learning a dictionary of
interpretable queries directly from the dataset. Our query dictionary learning
problem is formulated as an optimization problem by augmenting IP's variational
formulation with learnable dictionary parameters. To formulate learnable and
interpretable queries, we leverage the latent space of large vision and
language models like CLIP. To solve the optimization problem, we propose a new
query dictionary learning algorithm inspired by classical sparse dictionary
learning. Our experiments demonstrate that learned dictionaries significantly
outperform hand-crafted dictionaries generated with large language models.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11549" title="Abstract">arXiv:2312.11549</a> [<a href="/pdf/2312.11549" title="Download PDF">pdf</a>, <a href="/format/2312.11549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Label-Free Multivariate Time Series Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qihang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shibo He</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haoyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+W">Wenchao Meng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2208.02108">arXiv:2208.02108</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Anomaly detection in multivariate time series (MTS) has been widely studied
in one-class classification (OCC) setting. The training samples in OCC are
assumed to be normal, which is difficult to guarantee in practical situations.
Such a case may degrade the performance of OCC-based anomaly detection methods
which fit the training distribution as the normal distribution. In this paper,
we propose MTGFlow, an unsupervised anomaly detection approach for MTS anomaly
detection via dynamic Graph and entity-aware normalizing Flow. MTGFlow first
estimates the density of the entire training samples and then identifies
anomalous instances based on the density of the test samples within the fitted
distribution. This relies on a widely accepted assumption that anomalous
instances exhibit more sparse densities than normal ones, with no reliance on
the clean training dataset. However, it is intractable to directly estimate the
density due to complex dependencies among entities and their diverse inherent
characteristics. To mitigate this, we utilize the graph structure learning
model to learn interdependent and evolving relations among entities, which
effectively captures complex and accurate distribution patterns of MTS. In
addition, our approach incorporates the unique characteristics of individual
entities by employing an entity-aware normalizing flow. This enables us to
represent each entity as a parameterized normal distribution. Furthermore,
considering that some entities present similar characteristics, we propose a
cluster strategy that capitalizes on the commonalities of entities with similar
characteristics, resulting in more precise and detailed density estimation. We
refer to this cluster-aware extension as MTGFlow_cluster. Extensive experiments
are conducted on six widely used benchmark datasets, in which MTGFlow and
MTGFlow cluster demonstrate their superior detection performance.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11550" title="Abstract">arXiv:2312.11550</a> [<a href="/pdf/2312.11550" title="Download PDF">pdf</a>, <a href="/format/2312.11550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study on Transferability of Deep Learning Models for Network Intrusion  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Shreya Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Jameel%2C+A+S+M+M">Abu Shafin Mohammad Mahdee Jameel</a>, 
<a href="/search/cs?searchtype=author&query=Gamal%2C+A+E">Aly El Gamal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A significantly revised version of this manuscript has been accepted for publication. This is a previous version of the manuscript containing results and discussions that could not be included in the accepted version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we explore transferability in learning between different
attack classes in a network intrusion detection setup. We evaluate
transferability of attack classes by training a deep learning model with a
specific attack class and testing it on a separate attack class. We observe the
effects of real and synthetically generated data augmentation techniques on
transferability. We investigate the nature of observed transferability
relationships, which can be either symmetric or asymmetric. We also examine
explainability of the transferability relationships using the recursive feature
elimination algorithm. We study data preprocessing techniques to boost model
performance. The code for this work can be found at
https://github.com/ghosh64/transferability.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11551" title="Abstract">arXiv:2312.11551</a> [<a href="/pdf/2312.11551" title="Download PDF">pdf</a>, <a href="/format/2312.11551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Offline Policy Ranking with Approximate Bayesian  Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Da%2C+L">Longchao Da</a>, 
<a href="/search/cs?searchtype=author&query=Jenkins%2C+P">Porter Jenkins</a>, 
<a href="/search/cs?searchtype=author&query=Schwantes%2C+T">Trevor Schwantes</a>, 
<a href="/search/cs?searchtype=author&query=Dotson%2C+J">Jeffrey Dotson</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Hua Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages with 7 pages main paper, 10 pages appendix. Accepted to AAAI 2024 main track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In practice, it is essential to compare and rank candidate policies offline
before real-world deployment for safety and reliability. Prior work seeks to
solve this offline policy ranking (OPR) problem through value-based methods,
such as Off-policy evaluation (OPE). However, they fail to analyze special
cases performance (e.g., worst or best cases), due to the lack of holistic
characterization of policies performance. It is even more difficult to estimate
precise policy values when the reward is not fully accessible under sparse
settings. In this paper, we present Probabilistic Offline Policy Ranking
(POPR), a framework to address OPR problems by leveraging expert data to
characterize the probability of a candidate policy behaving like experts, and
approximating its entire performance posterior distribution to help with
ranking. POPR does not rely on value estimation, and the derived performance
posterior can be used to distinguish candidates in worst, best, and
average-cases. To estimate the posterior, we propose POPR-EABC, an Energy-based
Approximate Bayesian Computation (ABC) method conducting likelihood-free
inference. POPR-EABC reduces the heuristic nature of ABC by a smooth energy
function, and improves the sampling efficiency by a pseudo-likelihood. We
empirically demonstrate that POPR-EABC is adequate for evaluating policies in
both discrete and continuous action spaces across various experiment
environments, and facilitates probabilistic comparisons of candidate policies
before deployment.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11553" title="Abstract">arXiv:2312.11553</a> [<a href="/pdf/2312.11553" title="Download PDF">pdf</a>, <a href="/format/2312.11553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeGA: Preference-Aware Self-Contrastive Learning with Prompts for  Anomalous User Detection on Twitter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Ying-Ying Chang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei-Yao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wen-Chih Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 Main Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the dynamic and rapidly evolving world of social media, detecting
anomalous users has become a crucial task to address malicious activities such
as misinformation and cyberbullying. As the increasing number of anomalous
users improves the ability to mimic normal users and evade detection, existing
methods only focusing on bot detection are ineffective in terms of capturing
subtle distinctions between users. To address these challenges, we proposed
SeGA, preference-aware self-contrastive learning for anomalous user detection,
which leverages heterogeneous entities and their relations in the Twittersphere
to detect anomalous users with different malicious strategies. SeGA utilizes
the knowledge of large language models to summarize user preferences via posts.
In addition, integrating user preferences with prompts as pseudo-labels for
preference-aware self-contrastive learning enables the model to learn
multifaceted aspects for describing the behaviors of users. Extensive
experiments on the proposed TwBNT benchmark demonstrate that SeGA significantly
outperforms the state-of-the-art methods (+3.5\% ~ 27.6\%) and empirically
validate the effectiveness of the model design and pre-training strategies. Our
code and data are publicly available at https://github.com/ying0409/SeGA.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11554" title="Abstract">arXiv:2312.11554</a> [<a href="/pdf/2312.11554" title="Download PDF">pdf</a>, <a href="/format/2312.11554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deciphering Compatibility Relationships with Textual Descriptions via  Extraction and Explanation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zexue He</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhankui He</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hao Xu</a>, 
<a href="/search/cs?searchtype=author&query=McAuley%2C+J">Julian McAuley</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Understanding and accurately explaining compatibility relationships between
fashion items is a challenging problem in the burgeoning domain of AI-driven
outfit recommendations. Present models, while making strides in this area,
still occasionally fall short, offering explanations that can be elementary and
repetitive. This work aims to address these shortcomings by introducing the
Pair Fashion Explanation (PFE) dataset, a unique resource that has been curated
to illuminate these compatibility relationships. Furthermore, we propose an
innovative two-stage pipeline model that leverages this dataset. This
fine-tuning allows the model to generate explanations that convey the
compatibility relationships between items. Our experiments showcase the model's
potential in crafting descriptions that are knowledgeable, aligned with
ground-truth matching correlations, and that produce understandable and
informative descriptions, as assessed by both automatic metrics and human
evaluation. Our code and data are released at
https://github.com/wangyu-ustc/PairFashionExplanation
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11555" title="Abstract">arXiv:2312.11555</a> [<a href="/pdf/2312.11555" title="Download PDF">pdf</a>, <a href="/format/2312.11555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CR-SFP: Learning Consistent Representation for Soft Filter Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiang%2C+J">Jingyang Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuangzhi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+J">Jianbiao Mei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Siqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Soft filter pruning~(SFP) has emerged as an effective pruning technique for
allowing pruned filters to update and the opportunity for them to regrow to the
network. However, this pruning strategy applies training and pruning in an
alternative manner, which inevitably causes inconsistent representations
between the reconstructed network~(R-NN) at the training and the pruned
network~(P-NN) at the inference, resulting in performance degradation. In this
paper, we propose to mitigate this gap by learning consistent representation
for soft filter pruning, dubbed as CR-SFP. Specifically, for each training
step, CR-SFP optimizes the R-NN and P-NN simultaneously with different
distorted versions of the same training data, while forcing them to be
consistent by minimizing their posterior distribution via the bidirectional
KL-divergence loss. Meanwhile, the R-NN and P-NN share backbone parameters thus
only additional classifier parameters are introduced. After training, we can
export the P-NN for inference. CR-SFP is a simple yet effective training
framework to improve the accuracy of P-NN without introducing any additional
inference cost. It can also be combined with a variety of pruning criteria and
loss functions. Extensive experiments demonstrate our CR-SFP achieves
consistent improvements across various CNN architectures. Notably, on ImageNet,
our CR-SFP reduces more than 41.8\% FLOPs on ResNet18 with 69.2\% top-1
accuracy, improving SFP by 2.1\% under the same training settings. The code
will be publicly available on GitHub.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11556" title="Abstract">arXiv:2312.11556</a> [<a href="/pdf/2312.11556" title="Download PDF">pdf</a>, <a href="/format/2312.11556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StarVector: Generating Scalable Vector Graphics Code from Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+J+A">Juan A. Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+S">Shubham Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Laradji%2C+I+H">Issam H. Laradji</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+P">Pau Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Vazquez%2C+D">David Vazquez</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+C">Christopher Pal</a>, 
<a href="/search/cs?searchtype=author&query=Pedersoli%2C+M">Marco Pedersoli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Scalable Vector Graphics (SVGs) have become integral in modern image
rendering applications due to their infinite scalability in resolution,
versatile usability, and editing capabilities. SVGs are particularly popular in
the fields of web development and graphic design. Existing approaches for SVG
modeling using deep learning often struggle with generating complex SVGs and
are restricted to simpler ones that require extensive processing and
simplification. This paper introduces StarVector, a multimodal SVG generation
model that effectively integrates Code Generation Large Language Models
(CodeLLMs) and vision models. Our approach utilizes a CLIP image encoder to
extract visual representations from pixel-based images, which are then
transformed into visual tokens via an adapter module. These visual tokens are
pre-pended to the SVG token embeddings, and the sequence is modeled by the
StarCoder model using next-token prediction, effectively learning to align the
visual and code tokens. This enables StarVector to generate unrestricted SVGs
that accurately represent pixel images. To evaluate StarVector's performance,
we present SVG-Bench, a comprehensive benchmark for evaluating SVG methods
across multiple datasets and relevant metrics. Within this benchmark, we
introduce novel datasets including SVG-Stack, a large-scale dataset of
real-world SVG examples, and use it to pre-train StarVector as a large
foundation model for SVGs. Our results demonstrate significant enhancements in
visual quality and complexity handling over current methods, marking a notable
advancement in SVG generation technology. Code and models:
https://github.com/joanrod/star-vector
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11557" title="Abstract">arXiv:2312.11557</a> [<a href="/pdf/2312.11557" title="Download PDF">pdf</a>, <a href="/format/2312.11557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAI3D: Segment Any Instance in 3D Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yingda Yin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuzheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yang Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Cohen-Or%2C+D">Daniel Cohen-Or</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jingwei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Baoquan Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Advancements in 3D instance segmentation have traditionally been tethered to
the availability of annotated datasets, limiting their application to a narrow
spectrum of object categories. Recent efforts have sought to harness
vision-language models like CLIP for open-set semantic reasoning, yet these
methods struggle to distinguish between objects of the same categories and rely
on specific prompts that are not universally applicable. In this paper, we
introduce SAI3D, a novel zero-shot 3D instance segmentation approach that
synergistically leverages geometric priors and semantic cues derived from
Segment Anything Model (SAM). Our method partitions a 3D scene into geometric
primitives, which are then progressively merged into 3D instance segmentations
that are consistent with the multi-view SAM masks. Moreover, we design a
hierarchical region-growing algorithm with a dynamic thresholding mechanism,
which largely improves the robustness of finegrained 3D scene parsing.
Empirical evaluations on Scan-Net and the more challenging ScanNet++ datasets
demonstrate the superiority of our approach. Notably, SAI3D outperforms
existing open-vocabulary baselines and even surpasses fully-supervised methods
in class-agnostic segmentation on ScanNet++.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11559" title="Abstract">arXiv:2312.11559</a> [<a href="/pdf/2312.11559" title="Download PDF">pdf</a>, <a href="/format/2312.11559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Android Malware Detection with Unbiased Confidence Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papadopoulos%2C+H">Harris Papadopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Georgiou%2C+N">Nestoras Georgiou</a>, 
<a href="/search/cs?searchtype=author&query=Eliades%2C+C">Charalambos Eliades</a>, 
<a href="/search/cs?searchtype=author&query=Konstantinidis%2C+A">Andreas Konstantinidis</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neurocomputing, Volume 280, Pages 3-12, 2018
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The impressive growth of smartphone devices in combination with the rising
ubiquity of using mobile platforms for sensitive applications such as Internet
banking, have triggered a rapid increase in mobile malware. In recent
literature, many studies examine Machine Learning techniques, as the most
promising approach for mobile malware detection, without however quantifying
the uncertainty involved in their detections. In this paper, we address this
problem by proposing a machine learning dynamic analysis approach that provides
provably valid confidence guarantees in each malware detection. Moreover the
particular guarantees hold for both the malicious and benign classes
independently and are unaffected by any bias in the data. The proposed approach
is based on a novel machine learning framework, called Conformal Prediction,
combined with a random forests classifier. We examine its performance on a
large-scale dataset collected by installing 1866 malicious and 4816 benign
applications on a real android device. We make this collection of dynamic
analysis data available to the research community. The obtained experimental
results demonstrate the empirical validity, usefulness and unbiased nature of
the outputs produced by the proposed approach.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11560" title="Abstract">arXiv:2312.11560</a> [<a href="/pdf/2312.11560" title="Download PDF">pdf</a>, <a href="/format/2312.11560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergence Learning: A Rising Direction from Emergent Abilities and a  Monosemanticity-Based Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiachuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+S">Shimin Di</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+C+W+W">Charles Wang Wai Ng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 4 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">In the past 20 years, artificial neural networks have become dominant in
various areas, continually growing in scale. However, the current analysis of
large models has mainly focused on functionality, overlooking the influence of
scale differences on their properties. To address this, we propose the concept
of Emergence Learning, which emphasizes the significance of scale. By studying
models of different scales, we have identified a key factor in achieving higher
performance in large models: the decrease of monosemantic neurons. Building on
this insight, we propose a proactive approach to inhibit monosemanticity for
improved performance. Our solution involves a two-phase process that includes
monosemantic neuron detection and inhibition, supported by theoretical
analysis. Experimental results on various tasks and neural networks demonstrate
the effectiveness of our proposed method.
<br />Following the idea of Emergence Learning, though drawing inspiration from
scaling phenomena, the applicability of our method is not restricted to large
scale alone. Therefore, the experiment is self-contained. However, extending
this research to very large-scale datasets is appealing yet impossible for
research departments due to limited resources. We are delighted to share the
first co-authorship and eagerly await collaboration from any AI company before
submission.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11561" title="Abstract">arXiv:2312.11561</a> [<a href="/pdf/2312.11561" title="Download PDF">pdf</a>, <a href="/format/2312.11561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COPD-FlowNet: Elevating Non-invasive COPD Diagnosis with CFD Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tyagi%2C+A">Aryan Tyagi</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+A">Aryaman Rao</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+S">Shubhanshu Rao</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+R+K">Raj Kumar Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages 2 tables 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Chronic Obstructive Pulmonary Disorder (COPD) is a prevalent respiratory
disease that significantly impacts the quality of life of affected individuals.
This paper presents COPDFlowNet, a novel deep-learning framework that leverages
a custom Generative Adversarial Network (GAN) to generate synthetic
Computational Fluid Dynamics (CFD) velocity flow field images specific to the
trachea of COPD patients. These synthetic images serve as a valuable resource
for data augmentation and model training. Additionally, COPDFlowNet
incorporates a custom Convolutional Neural Network (CNN) architecture to
predict the location of the obstruction site.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11562" title="Abstract">arXiv:2312.11562</a> [<a href="/pdf/2312.11562" title="Download PDF">pdf</a>, <a href="/format/2312.11562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Reasoning with Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiankai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chuanyang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+E">Enze Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+R">Ruihang Chu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jianing Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiaqi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Mingyu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+M">Mengzhe Geng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junsong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhangyue Yin</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiaozhe Ren</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junxian He</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Wu Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xihui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yu Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Ming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Heng%2C+P+A">Pheng Ann Heng</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jifeng Dai</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingdong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yike Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 Figures, 159 Pages, 740 References, Project Page <a href="https://github.com/reasoning-survey/Awesome-Reasoning-Foundation-Models">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Reasoning, a crucial ability for complex problem-solving, plays a pivotal
role in various real-world settings such as negotiation, medical diagnosis, and
criminal investigation. It serves as a fundamental methodology in the field of
Artificial General Intelligence (AGI). With the ongoing development of
foundation models, there is a growing interest in exploring their abilities in
reasoning tasks. In this paper, we introduce seminal foundation models proposed
or adaptable for reasoning, highlighting the latest advancements in various
reasoning tasks, methods, and benchmarks. We then delve into the potential
future directions behind the emergence of reasoning abilities within foundation
models. We also discuss the relevance of multimodal learning, autonomous
agents, and super alignment in the context of reasoning. By discussing these
future research directions, we hope to inspire researchers in their exploration
of this field, stimulate further advancements in reasoning with foundation
models, and contribute to the development of AGI.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11563" title="Abstract">arXiv:2312.11563</a> [<a href="/pdf/2312.11563" title="Download PDF">pdf</a>, <a href="/ps/2312.11563" title="Download PostScript">ps</a>, <a href="/format/2312.11563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A review-based study on different Text-to-Speech technologies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+M+J+U">Md. Jalal Uddin Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Hussan%2C+A">Ashab Hussan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This research paper presents a comprehensive review-based study on various
Text-to-Speech (TTS) technologies. TTS technology is an important aspect of
human-computer interaction, enabling machines to convert written text into
audible speech. The paper examines the different TTS technologies available,
including concatenative TTS, formant synthesis TTS, and statistical parametric
TTS. The study focuses on comparing the advantages and limitations of these
technologies in terms of their naturalness of voice, the level of complexity of
the system, and their suitability for different applications. In addition, the
paper explores the latest advancements in TTS technology, including neural TTS
and hybrid TTS. The findings of this research will provide valuable insights
for researchers, developers, and users who want to understand the different TTS
technologies and their suitability for specific applications.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11564" title="Abstract">arXiv:2312.11564</a> [<a href="/pdf/2312.11564" title="Download PDF">pdf</a>, <a href="/ps/2312.11564" title="Download PostScript">ps</a>, <a href="/format/2312.11564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-preserving transactive energy systems: Key topics and open  research challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Duguma%2C+D+G">Daniel Gerbi Duguma</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Juliana Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Aboutalebi%2C+M">Meysam Aboutalebi</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+S">Shiliang Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Banet%2C+C">Catherine Banet</a>, 
<a href="/search/eess?searchtype=author&query=Bj%C3%B8rkli%2C+C">Cato Bj&#xf8;rkli</a>, 
<a href="/search/eess?searchtype=author&query=Baramashetru%2C+C">Chinmayi Baramashetru</a>, 
<a href="/search/eess?searchtype=author&query=Eliassen%2C+F">Frank Eliassen</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Hui Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Muringani%2C+J">Jonathan Muringani</a>, 
<a href="/search/eess?searchtype=author&query=Noll%2C+J">Josef Noll</a>, 
<a href="/search/eess?searchtype=author&query=Fostervold%2C+K+I">Knut Inge Fostervold</a>, 
<a href="/search/eess?searchtype=author&query=B%C3%B6cker%2C+L">Lars B&#xf6;cker</a>, 
<a href="/search/eess?searchtype=author&query=Bygrave%2C+L+A">Lee Andrew Bygrave</a>, 
<a href="/search/eess?searchtype=author&query=Bagherpour%2C+M">Matin Bagherpour</a>, 
<a href="/search/eess?searchtype=author&query=Moghadam%2C+M+D">Maunya Doroudi Moghadam</a>, 
<a href="/search/eess?searchtype=author&query=Owe%2C+O">Olaf Owe</a>, 
<a href="/search/eess?searchtype=author&query=Sengupta%2C+P">Poushali Sengupta</a>, 
<a href="/search/eess?searchtype=author&query=Vitenberg%2C+R">Roman Vitenberg</a>, 
<a href="/search/eess?searchtype=author&query=Maharjan%2C+S">Sabita Maharjan</a>, 
<a href="/search/eess?searchtype=author&query=Garrett%2C+T">Thiago Garrett</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yushuai Li</a>, 
<a href="/search/eess?searchtype=author&query=Shan%2C+Z">Zhengyu Shan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">This manuscript aims to formalize and conclude the discussions initiated
during the PriTEM workshop 22-23 March 2023. We present important ideas and
discussion topics in the context of transactive energy systems. Moreover, the
conclusions from the discussions articulate potential aspects to be explored in
future studies on transactive energy management. Particularly, these
conclusions cover research topics in energy technology and energy informatics,
energy law, data law, energy market and socio-psychology that are relevant to
the seamless integration of renewable energy resources and the transactive
energy systems-in smart microgrids-focusing on distributed frameworks such as
peer-to-peer (P2P) energy trading. We clarify issues, identify barriers, and
suggest possible solutions to open questions in diversified topics, such as
block-chain interoperability, consumer privacy and data sharing, and
participation incentivization. Furthermore, we also elaborate challenges
associated with cross-disciplinary collaboration and coordination for
transactive energy systems, and enumerate the lessons learned from our work so
far.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11566" title="Abstract">arXiv:2312.11566</a> [<a href="/pdf/2312.11566" title="Download PDF">pdf</a>, <a href="/format/2312.11566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards AI-driven Integrative Emissions Monitoring &amp; Management for  Nature-Based Climate Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oladeji%2C+O">Olamide Oladeji</a>, 
<a href="/search/cs?searchtype=author&query=Mousavi%2C+S+S">Seyed Shahabeddin Mousavi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">AI has been proposed as an important tool to support several efforts related
to nature-based climate solutions such as the detection of wildfires that
affect forests and vegetation-based offsets. While this and other use-cases
provide important demonstrative value of the power of AI in climate change
mitigation, such efforts have typically been undertaken in silos, without
awareness of the integrative nature of real-world climate policy-making. In
this paper, we propose a novel overarching framework for AI-aided integrated
and comprehensive decision support for various aspects of nature-based climate
decision-making. Focusing on vegetation-based solutions such as forests, we
demonstrate how different AI-aided decision support models such as AI-aided
wildfire detection, AI-aided vegetation carbon stock assessment, reversal risk
mitigation, and disaster response planning can be integrated into a
comprehensive framework. Rather than being disparate elements, we posit that
the exchange of data and analytical results across elements of the framework,
and careful mitigation of uncertainty propagation will provide tremendous value
relative to the status-quo for real-world climate policy-making.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11567" title="Abstract">arXiv:2312.11567</a> [<a href="/pdf/2312.11567" title="Download PDF">pdf</a>, <a href="/format/2312.11567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Students&#x27; Perceptions and Preferences of Generative Artificial  Intelligence Feedback for Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhengdong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zihan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Matsuda%2C+N">Noboru Matsuda</a>, 
<a href="/search/cs?searchtype=author&query=Price%2C+T">Thomas Price</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dongkuan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">The rapid evolution of artificial intelligence (AI), specifically large
language models (LLMs), has opened opportunities for various educational
applications. This paper explored the feasibility of utilizing ChatGPT, one of
the most popular LLMs, for automating feedback for Java programming assignments
in an introductory computer science (CS1) class. Specifically, this study
focused on three questions: 1) To what extent do students view LLM-generated
feedback as formative? 2) How do students see the comparative affordances of
feedback prompts that include their code, vs. those that exclude it? 3) What
enhancements do students suggest for improving AI-generated feedback? To
address these questions, we generated automated feedback using the ChatGPT API
for four lab assignments in the CS1 class. The survey results revealed that
students perceived the feedback as aligning well with formative feedback
guidelines established by Shute. Additionally, students showed a clear
preference for feedback generated by including the students' code as part of
the LLM prompt, and our thematic study indicated that the preference was mainly
attributed to the specificity, clarity, and corrective nature of the feedback.
Moreover, this study found that students generally expected specific and
corrective feedback with sufficient code examples, but had diverged opinions on
the tone of the feedback. This study demonstrated that ChatGPT could generate
Java programming assignment feedback that students perceived as formative. It
also offered insights into the specific improvements that would make the
ChatGPT-generated feedback useful for students.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11568" title="Abstract">arXiv:2312.11568</a> [<a href="/pdf/2312.11568" title="Download PDF">pdf</a>, <a href="/format/2312.11568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VectorTalker: SVG Talking Face Generation with Progressive Vectorisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jingxiang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yanbo Fan</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Caigui Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">High-fidelity and efficient audio-driven talking head generation has been a
key research topic in computer graphics and computer vision. In this work, we
study vector image based audio-driven talking head generation. Compared with
directly animating the raster image that most widely used in existing works,
vector image enjoys its excellent scalability being used for many applications.
There are two main challenges for vector image based talking head generation:
the high-quality vector image reconstruction w.r.t. the source portrait image
and the vivid animation w.r.t. the audio signal. To address these, we propose a
novel scalable vector graphic reconstruction and animation method, dubbed
VectorTalker. Specifically, for the highfidelity reconstruction, VectorTalker
hierarchically reconstructs the vector image in a coarse-to-fine manner. For
the vivid audio-driven facial animation, we propose to use facial landmarks as
intermediate motion representation and propose an efficient landmark-driven
vector image deformation module. Our approach can handle various styles of
portrait images within a unified framework, including Japanese manga, cartoon,
and photorealistic images. We conduct extensive quantitative and qualitative
evaluations and the experimental results demonstrate the superiority of
VectorTalker in both vector graphic reconstruction and audio-driven animation.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11569" title="Abstract">arXiv:2312.11569</a> [<a href="/pdf/2312.11569" title="Download PDF">pdf</a>, <a href="/ps/2312.11569" title="Download PostScript">ps</a>, <a href="/format/2312.11569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Application of AI in Nutrition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramakrishnan%2C+R">Ritu Ramakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+T">Tianxiang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianfeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Ming-Hao Lee</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jinzhu Gao</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Advances in Information Science and Technology, Volume
  1, Issue 1, 2023, Pages 7-12
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">In healthcare, artificial intelligence (AI) has been changing the way doctors
and health experts take care of people. This paper will cover how AI is making
major changes in the health care system, especially with nutrition. Various
machine learning and deep learning algorithms have been developed to extract
valuable information from healthcare data which help doctors, nutritionists,
and health experts to make better decisions and make our lifestyle healthy.
This paper provides an overview of the current state of AI applications in
healthcare with a focus on the utilization of AI-driven recommender systems in
nutrition. It will discuss the positive outcomes and challenges that arise when
AI is used in this field. This paper addresses the challenges to develop AI
recommender systems in healthcare, providing a well-rounded perspective on the
complexities. Real-world examples and research findings are presented to
underscore the tangible and significant impact AI recommender systems have in
the field of healthcare, particularly in nutrition. The ongoing efforts of
applying AI in nutrition lay the groundwork for a future where personalized
recommendations play a pivotal role in guiding individuals toward healthier
lifestyles.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11570" title="Abstract">arXiv:2312.11570</a> [<a href="/pdf/2312.11570" title="Download PDF">pdf</a>, <a href="/format/2312.11570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Multi-modal Prompts of the Pre-trained Vision-Language  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shuailei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Chen-Wei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Ying Wei</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Siyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jiaqi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+X">Xiaoyi Bao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuxin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yun Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Prompt learning has emerged as an efficient alternative for fine-tuning
foundational models, such as CLIP, for various downstream tasks. However, there
is no work that provides a comprehensive explanation for the working mechanism
of the multi-modal prompts. In this paper, we conduct a direct analysis of the
multi-modal prompts by asking the following questions: $(i)$ How do the learned
multi-modal prompts improve the recognition performance? $(ii)$ What do the
multi-modal prompts learn? To answer these questions, we begin by isolating the
component of the formula where the prompt influences the calculation of
self-attention at each layer in two distinct ways, \ie, $(1)$ introducing
prompt embeddings makes the $[cls]$ token focus on foreground objects. $(2)$
the prompts learn a bias term during the update of token embeddings, allowing
the model to adapt to the target domain. Subsequently, we conduct extensive
visualization and statistical experiments on the eleven diverse downstream
recognition datasets. From the experiments, we reveal that the learned prompts
improve the performance mainly through the second way, which acts as the
dataset bias to improve the recognition performance of the pre-trained model on
the corresponding dataset. Based on this finding, we propose the bias tuning
way and demonstrate that directly incorporating the learnable bias outperforms
the learnable prompts in the same parameter settings. In datasets with limited
category information, \ie, EuroSAT, bias tuning surpasses prompt tuning by a
large margin. With a deeper understanding of the multi-modal prompt, we hope
our work can inspire new and solid research in this direction.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11571" title="Abstract">arXiv:2312.11571</a> [<a href="/pdf/2312.11571" title="Download PDF">pdf</a>, <a href="/format/2312.11571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Stealing Attack against Recommender System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhihao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+R">Rui Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenwang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+D">Defu Lian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Enhong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent studies have demonstrated the vulnerability of recommender systems to
data privacy attacks. However, research on the threat to model privacy in
recommender systems, such as model stealing attacks, is still in its infancy.
Some adversarial attacks have achieved model stealing attacks against
recommender systems, to some extent, by collecting abundant training data of
the target model (target data) or making a mass of queries. In this paper, we
constrain the volume of available target data and queries and utilize auxiliary
data, which shares the item set with the target data, to promote model stealing
attacks. Although the target model treats target and auxiliary data
differently, their similar behavior patterns allow them to be fused using an
attention mechanism to assist attacks. Besides, we design stealing functions to
effectively extract the recommendation list obtained by querying the target
model. Experimental results show that the proposed methods are applicable to
most recommender systems and various scenarios and exhibit excellent attack
performance on multiple datasets.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11572" title="Abstract">arXiv:2312.11572</a> [<a href="/pdf/2312.11572" title="Download PDF">pdf</a>, <a href="/format/2312.11572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regularized Conditional Alignment for Multi-Domain Text Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Juntao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuan Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">The most successful multi-domain text classification (MDTC) approaches employ
the shared-private paradigm to facilitate the enhancement of domain-invariant
features through domain-specific attributes. Additionally, they employ
adversarial training to align marginal feature distributions. Nevertheless,
these methodologies encounter two primary challenges: (1) Neglecting
class-aware information during adversarial alignment poses a risk of
misalignment; (2) The limited availability of labeled data across multiple
domains fails to ensure adequate discriminative capacity for the model. To
tackle these issues, we propose a method called Regularized Conditional
Alignment (RCA) to align the joint distributions of domains and classes, thus
matching features within the same category and amplifying the discriminative
qualities of acquired features. Moreover, we employ entropy minimization and
virtual adversarial training to constrain the uncertainty of predictions
pertaining to unlabeled data and enhance the model's robustness. Empirical
results on two benchmark datasets demonstrate that our RCA approach outperforms
state-of-the-art MDTC techniques.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11573" title="Abstract">arXiv:2312.11573</a> [<a href="/pdf/2312.11573" title="Download PDF">pdf</a>, <a href="/ps/2312.11573" title="Download PostScript">ps</a>, <a href="/format/2312.11573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimation of individual causal effects in network setup for multiple  treatments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thorat%2C+A">Abhinav Thorat</a>, 
<a href="/search/cs?searchtype=author&query=Kolla%2C+R">Ravi Kolla</a>, 
<a href="/search/cs?searchtype=author&query=Pedanekar%2C+N">Niranjan Pedanekar</a>, 
<a href="/search/cs?searchtype=author&query=Onoe%2C+N">Naoyuki Onoe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, accepted at AAAI-GCLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
<p class="mathjax">We study the problem of estimation of Individual Treatment Effects (ITE) in
the context of multiple treatments and networked observational data. Leveraging
the network information, we aim to utilize hidden confounders that may not be
directly accessible in the observed data, thereby enhancing the practical
applicability of the strong ignorability assumption. To achieve this, we first
employ Graph Convolutional Networks (GCN) to learn a shared representation of
the confounders. Then, our approach utilizes separate neural networks to infer
potential outcomes for each treatment. We design a loss function as a weighted
combination of two components: representation loss and Mean Squared Error (MSE)
loss on the factual outcomes. To measure the representation loss, we extend
existing metrics such as Wasserstein and Maximum Mean Discrepancy (MMD) from
the binary treatment setting to the multiple treatments scenario. To validate
the effectiveness of our proposed methodology, we conduct a series of
experiments on the benchmark datasets such as BlogCatalog and Flickr. The
experimental results consistently demonstrate the superior performance of our
models when compared to baseline methods.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11575" title="Abstract">arXiv:2312.11575</a> [<a href="/pdf/2312.11575" title="Download PDF">pdf</a>, <a href="/format/2312.11575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blind-Touch: Homomorphic Encryption-Based Distributed Neural Network  Inference for Privacy-Preserving Fingerprint Authentication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+H">Hyunmin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+S">Simon Woo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyoungshick Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 38th Annual AAAI Conference on Artificial Intelligence (AAAI) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Fingerprint authentication is a popular security mechanism for smartphones
and laptops. However, its adoption in web and cloud environments has been
limited due to privacy concerns over storing and processing biometric data on
servers. This paper introduces Blind-Touch, a novel machine learning-based
fingerprint authentication system leveraging homomorphic encryption to address
these privacy concerns. Homomorphic encryption allows computations on encrypted
data without decrypting. Thus, Blind-Touch can keep fingerprint data encrypted
on the server while performing machine learning operations. Blind-Touch
combines three strategies to efficiently utilize homomorphic encryption in
machine learning: (1) It optimizes the feature vector for a distributed
architecture, processing the first fully connected layer (FC-16) in plaintext
on the client side and the subsequent layer (FC-1) post-encryption on the
server, thereby minimizing encrypted computations; (2) It employs a homomorphic
encryptioncompatible data compression technique capable of handling 8,192
authentication results concurrently; and (3) It utilizes a clustered server
architecture to simultaneously process authentication results, thereby
enhancing scalability with increasing user numbers. Blind-Touch achieves high
accuracy on two benchmark fingerprint datasets, with a 93.6% F1- score for the
PolyU dataset and a 98.2% F1-score for the SOKOTO dataset. Moreover,
Blind-Touch can match a fingerprint among 5,000 in about 0.65 seconds. With its
privacyfocused design, high accuracy, and efficiency, Blind-Touch is a
promising alternative to conventional fingerprint authentication for web and
cloud applications.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11576" title="Abstract">arXiv:2312.11576</a> [<a href="/pdf/2312.11576" title="Download PDF">pdf</a>, <a href="/ps/2312.11576" title="Download PostScript">ps</a>, <a href="/format/2312.11576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emotion Based Prediction in the Context of Optimized Trajectory Planning  for Immersive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sungheetha%2C+A">Akey Sungheetha</a>, 
<a href="/search/cs?searchtype=author&query=R%2C+R+S">Rajesh Sharma R</a>, 
<a href="/search/cs?searchtype=author&query=R%2C+C">Chinnaiyan R</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)

</div>
<p class="mathjax">In the virtual elements of immersive learning, the use of Google Expedition
and touch-screen-based emotion are examined. The objective is to investigate
possible ways to combine these technologies to enhance virtual learning
environments and learners emotional engagement. Pedagogical application,
affordances, and cognitive load are the corresponding measures that are
involved. Students will gain insight into the reason behind their significantly
higher post-assessment Prediction Systems scores compared to preassessment
scores through this work that leverages technology. This suggests that it is
effective to include emotional elements in immersive learning scenarios. The
results of this study may help develop new strategies by leveraging the
features of immersive learning technology in educational technologies to
improve virtual reality and augmented reality experiences. Furthermore, the
effectiveness of immersive learning environments can be raised by utilizing
magnetic, optical, or hybrid trackers that considerably improve object
tracking.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11577" title="Abstract">arXiv:2312.11577</a> [<a href="/pdf/2312.11577" title="Download PDF">pdf</a>, <a href="/format/2312.11577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PR-NeuS: A Prior-based Residual Learning Paradigm for Fast Multi-view  Neural Surface Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jianyao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qingshan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+X">Xinyao Liao</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+W">Wanjuan Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ong%2C+Y">Yew-Soon Ong</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+W">Wenbing Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural surfaces learning has shown impressive performance in multi-view
surface reconstruction. However, most existing methods use large multilayer
perceptrons (MLPs) to train their models from scratch, resulting in hours of
training for a single scene. Recently, how to accelerate the neural surfaces
learning has received a lot of attention and remains an open problem. In this
work, we propose a prior-based residual learning paradigm for fast multi-view
neural surface reconstruction. This paradigm consists of two optimization
stages. In the first stage, we propose to leverage generalization models to
generate a basis signed distance function (SDF) field. This initial field can
be quickly obtained by fusing multiple local SDF fields produced by
generalization models. This provides a coarse global geometry prior. Based on
this prior, in the second stage, a fast residual learning strategy based on
hash-encoding networks is proposed to encode an offset SDF field for the basis
SDF field. Moreover, we introduce a prior-guided sampling scheme to help the
residual learning stage converge better, and thus recover finer structures.
With our designed paradigm, experimental results show that our method only
takes about 3 minutes to reconstruct the surface of a single scene, while
achieving competitive surface quality. Our code will be released upon
publication.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11578" title="Abstract">arXiv:2312.11578</a> [<a href="/pdf/2312.11578" title="Download PDF">pdf</a>, <a href="/format/2312.11578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-Based Particle-DETR for BEV Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nachkov%2C+A">Asen Nachkov</a>, 
<a href="/search/cs?searchtype=author&query=Danelljan%2C+M">Martin Danelljan</a>, 
<a href="/search/cs?searchtype=author&query=Paudel%2C+D+P">Danda Pani Paudel</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The Bird-Eye-View (BEV) is one of the most widely-used scene representations
for visual perception in Autonomous Vehicles (AVs) due to its well suited
compatibility to downstream tasks. For the enhanced safety of AVs, modeling
perception uncertainty in BEV is crucial. Recent diffusion-based methods offer
a promising approach to uncertainty modeling for visual perception but fail to
effectively detect small objects in the large coverage of the BEV. Such
degradation of performance can be attributed primarily to the specific network
architectures and the matching strategy used when training. Here, we address
this problem by combining the diffusion paradigm with current state-of-the-art
3D object detectors in BEV. We analyze the unique challenges of this approach,
which do not exist with deterministic detectors, and present a simple technique
based on object query interpolation that allows the model to learn positional
dependencies even in the presence of the diffusion noise. Based on this, we
present a diffusion-based DETR model for object detection that bears
similarities to particle methods. Abundant experimentation on the NuScenes
dataset shows equal or better performance for our generative approach, compared
to deterministic state-of-the-art methods. Our source code will be made
publicly available.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11581" title="Abstract">arXiv:2312.11581</a> [<a href="/pdf/2312.11581" title="Download PDF">pdf</a>, <a href="/format/2312.11581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Protect Your Score: Contact Tracing With Differential Privacy Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Romijnders%2C+R">Rob Romijnders</a>, 
<a href="/search/cs?searchtype=author&query=Louizos%2C+C">Christos Louizos</a>, 
<a href="/search/cs?searchtype=author&query=Asano%2C+Y+M">Yuki M. Asano</a>, 
<a href="/search/cs?searchtype=author&query=Welling%2C+M">Max Welling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to The 38th Annual AAAI Conference on Artificial Intelligence (AAAI 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The pandemic in 2020 and 2021 had enormous economic and societal
consequences, and studies show that contact tracing algorithms can be key in
the early containment of the virus. While large strides have been made towards
more effective contact tracing algorithms, we argue that privacy concerns
currently hold deployment back. The essence of a contact tracing algorithm
constitutes the communication of a risk score. Yet, it is precisely the
communication and release of this score to a user that an adversary can
leverage to gauge the private health status of an individual. We pinpoint a
realistic attack scenario and propose a contact tracing algorithm with
differential privacy guarantees against this attack. The algorithm is tested on
the two most widely used agent-based COVID19 simulators and demonstrates
superior performance in a wide range of settings. Especially for realistic test
scenarios and while releasing each risk score with epsilon=1 differential
privacy, we achieve a two to ten-fold reduction in the infection rate of the
virus. To the best of our knowledge, this presents the first contact tracing
algorithm with differential privacy guarantees when revealing risk scores for
COVID19.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11582" title="Abstract">arXiv:2312.11582</a> [<a href="/pdf/2312.11582" title="Download PDF">pdf</a>, <a href="/format/2312.11582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shapley-PC: Constraint-based Causal Structure Learning with Shapley  Values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Russo%2C+F">Fabrizio Russo</a>, 
<a href="/search/cs?searchtype=author&query=Toni%2C+F">Francesca Toni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages (with appendix)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
<p class="mathjax">Causal Structure Learning (CSL), amounting to extracting causal relations
among the variables in a dataset, is widely perceived as an important step
towards robust and transparent models. Constraint-based CSL leverages
conditional independence tests to perform causal discovery. We propose
Shapley-PC, a novel method to improve constraint-based CSL algorithms by using
Shapley values over the possible conditioning sets to decide which variables
are responsible for the observed conditional (in)dependences. We prove
soundness and asymptotic consistency and demonstrate that it can outperform
state-of-the-art constraint-based, search-based and functional causal
model-based methods, according to standard metrics in CSL.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11583" title="Abstract">arXiv:2312.11583</a> [<a href="/pdf/2312.11583" title="Download PDF">pdf</a>, <a href="/format/2312.11583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-Based Energy Transportation Safety: Pipeline Radial Threat Estimation  Using Intelligent Sensing System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chengyuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kaixiang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haifeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qinmin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C+L+P">C. L. Philip Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 38th Annual AAAI Conference on Artificial Intelligence (AAAI 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The application of artificial intelligence technology has greatly enhanced
and fortified the safety of energy pipelines, particularly in safeguarding
against external threats. The predominant methods involve the integration of
intelligent sensors to detect external vibration, enabling the identification
of event types and locations, thereby replacing manual detection methods.
However, practical implementation has exposed a limitation in current methods -
their constrained ability to accurately discern the spatial dimensions of
external signals, which complicates the authentication of threat events. Our
research endeavors to overcome the above issues by harnessing deep learning
techniques to achieve a more fine-grained recognition and localization process.
This refinement is crucial in effectively identifying genuine threats to
pipelines, thus enhancing the safety of energy transportation. This paper
proposes a radial threat estimation method for energy pipelines based on
distributed optical fiber sensing technology. Specifically, we introduce a
continuous multi-view and multi-domain feature fusion methodology to extract
comprehensive signal features and construct a threat estimation and recognition
network. The utilization of collected acoustic signal data is optimized, and
the underlying principle is elucidated. Moreover, we incorporate the concept of
transfer learning through a pre-trained model, enhancing both recognition
accuracy and training efficiency. Empirical evidence gathered from real-world
scenarios underscores the efficacy of our method, notably in its substantial
reduction of false alarms and remarkable gains in recognition accuracy. More
generally, our method exhibits versatility and can be extrapolated to a broader
spectrum of recognition tasks and scenarios.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11587" title="Abstract">arXiv:2312.11587</a> [<a href="/pdf/2312.11587" title="Download PDF">pdf</a>, <a href="/format/2312.11587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relightable Neural Actor with Intrinsic Decomposition and Pose Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luvizon%2C+D">Diogo Luvizon</a>, 
<a href="/search/cs?searchtype=author&query=Golyanik%2C+V">Vladislav Golyanik</a>, 
<a href="/search/cs?searchtype=author&query=Kortylewski%2C+A">Adam Kortylewski</a>, 
<a href="/search/cs?searchtype=author&query=Habermann%2C+M">Marc Habermann</a>, 
<a href="/search/cs?searchtype=author&query=Theobalt%2C+C">Christian Theobalt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://people.mpi-inf.mpg.de/~dluvizon/relightable-neural-actor/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Creating a digital human avatar that is relightable, drivable, and
photorealistic is a challenging and important problem in Vision and Graphics.
Humans are highly articulated creating pose-dependent appearance effects like
self-shadows and wrinkles, and skin as well as clothing require complex and
space-varying BRDF models. While recent human relighting approaches can recover
plausible material-light decompositions from multi-view video, they do not
generalize to novel poses and still suffer from visual artifacts. To address
this, we propose Relightable Neural Actor, the first video-based method for
learning a photorealistic neural human model that can be relighted, allows
appearance editing, and can be controlled by arbitrary skeletal poses.
Importantly, for learning our human avatar, we solely require a multi-view
recording of the human under a known, but static lighting condition. To achieve
this, we represent the geometry of the actor with a drivable density field that
models pose-dependent clothing deformations and provides a mapping between 3D
and UV space, where normal, visibility, and materials are encoded. To evaluate
our approach in real-world scenarios, we collect a new dataset with four actors
recorded under different light conditions, indoors and outdoors, providing the
first benchmark of its kind for human relighting, and demonstrating
state-of-the-art relighting results for novel human poses.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11589" title="Abstract">arXiv:2312.11589</a> [<a href="/pdf/2312.11589" title="Download PDF">pdf</a>, <a href="/ps/2312.11589" title="Download PostScript">ps</a>, <a href="/format/2312.11589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Moral Uncertainty and the Problem of Fanaticism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Szabo%2C+J">Jazon Szabo</a>, 
<a href="/search/cs?searchtype=author&query=Such%2C+J">Jose Such</a>, 
<a href="/search/cs?searchtype=author&query=Criado%2C+N">Natalia Criado</a>, 
<a href="/search/cs?searchtype=author&query=Modgil%2C+S">Sanjay Modgil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Science and Game Theory (cs.GT); Theoretical Economics (econ.TH)

</div>
<p class="mathjax">While there is universal agreement that agents ought to act ethically, there
is no agreement as to what constitutes ethical behaviour. To address this
problem, recent philosophical approaches to `moral uncertainty' propose
aggregation of multiple ethical theories to guide agent behaviour. However, one
of the foundational proposals for aggregation - Maximising Expected
Choiceworthiness (MEC) - has been criticised as being vulnerable to fanaticism;
the problem of an ethical theory dominating agent behaviour despite low
credence (confidence) in said theory. Fanaticism thus undermines the
`democratic' motivation for accommodating multiple ethical perspectives. The
problem of fanaticism has not yet been mathematically defined. Representing
moral uncertainty as an instance of social welfare aggregation, this paper
contributes to the field of moral uncertainty by 1) formalising the problem of
fanaticism as a property of social welfare functionals and 2) providing
non-fanatical alternatives to MEC, i.e. Highest k-trimmed Mean and Highest
Median.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11590" title="Abstract">arXiv:2312.11590</a> [<a href="/pdf/2312.11590" title="Download PDF">pdf</a>, <a href="/ps/2312.11590" title="Download PostScript">ps</a>, <a href="/format/2312.11590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Diffusive Representations for Enhanced Numerical  Approximation of Fractional Integrals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chaudhary%2C+R">Renu Chaudhary</a>, 
<a href="/search/math?searchtype=author&query=Diethelm%2C+K">Kai Diethelm</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages. arXiv admin note: text overlap with <a href="/abs/2312.11305">arXiv:2312.11305</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This study reexamines diffusive representations for fractional integrals with
the goal of pioneering new variants of such representations. These variants aim
to offer highly efficient numerical algorithms for the approximate computation
of fractional integrals. The approach seamlessly aligns with established
techniques used in addressing problems involving integer-order operators,
contributing to a unified framework for numerical solutions.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11593" title="Abstract">arXiv:2312.11593</a> [<a href="/pdf/2312.11593" title="Download PDF">pdf</a>, <a href="/format/2312.11593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Establishing Dense Correspondence on Multiview Coronary  Angiography: From Point-to-Point to Curve-to-Curve Query Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yifan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jena%2C+R">Rohit Jena</a>, 
<a href="/search/cs?searchtype=author&query=Gulsun%2C+M">Mehmet Gulsun</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+V">Vivek Singh</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+P">Puneet Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Gee%2C+J+C">James C. Gee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Coronary angiography is the gold standard imaging technique for studying and
diagnosing coronary artery disease. However, the resulting 2D X-ray projections
lose 3D information and exhibit visual ambiguities. In this work, we aim to
establish dense correspondence in multi-view angiography, serving as a
fundamental basis for various clinical applications and downstream tasks. To
overcome the challenge of unavailable annotated data, we designed a data
simulation pipeline using 3D Coronary Computed Tomography Angiography (CCTA).
We formulated the problem of dense correspondence estimation as a query
matching task over all points of interest in the given views. We established
point-to-point query matching and advanced it to curve-to-curve correspondence,
significantly reducing errors by minimizing ambiguity and improving topological
awareness. The method was evaluated on a set of 1260 image pairs from different
views across 8 clinically relevant angulation groups, demonstrating compelling
results and indicating the feasibility of establishing dense correspondence in
multi-view angiography.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11595" title="Abstract">arXiv:2312.11595</a> [<a href="/pdf/2312.11595" title="Download PDF">pdf</a>, <a href="/format/2312.11595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TIP: Text-Driven Image Processing with Semantic and Restoration  Instructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+C">Chenyang Qi</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhengzhong Tu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+K">Keren Ye</a>, 
<a href="/search/cs?searchtype=author&query=Delbracio%2C+M">Mauricio Delbracio</a>, 
<a href="/search/cs?searchtype=author&query=Milanfar%2C+P">Peyman Milanfar</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Talebi%2C+H">Hossein Talebi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Webpage: <a href="https://chenyangqiqi.github.io/tip">this https URL</a> ; code will be released soon
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-driven diffusion models have become increasingly popular for various
image editing tasks, including inpainting, stylization, and object replacement.
However, it still remains an open research problem to adopt this
language-vision paradigm for more fine-level image processing tasks, such as
denoising, super-resolution, deblurring, and compression artifact removal. In
this paper, we develop TIP, a Text-driven Image Processing framework that
leverages natural language as a user-friendly interface to control the image
restoration process. We consider the capacity of text information in two
dimensions. First, we use content-related prompts to enhance the semantic
alignment, effectively alleviating identity ambiguity in the restoration
outcomes. Second, our approach is the first framework that supports fine-level
instruction through language-based quantitative specification of the
restoration strength, without the need for explicit task-specific design. In
addition, we introduce a novel fusion mechanism that augments the existing
ControlNet architecture by learning to rescale the generative prior, thereby
achieving better restoration fidelity. Our extensive experiments demonstrate
the superior restoration performance of TIP compared to the state of the arts,
alongside offering the flexibility of text-based control over the restoration
effects.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11598" title="Abstract">arXiv:2312.11598</a> [<a href="/pdf/2312.11598" title="Download PDF">pdf</a>, <a href="/format/2312.11598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SkillDiffuser: Interpretable Hierarchical Planning via Skill  Abstractions in Diffusion-Based Task Execution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zhixuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+Y">Yao Mu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Hengbo Ma</a>, 
<a href="/search/cs?searchtype=author&query=Tomizuka%2C+M">Masayoshi Tomizuka</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Mingyu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion models have demonstrated strong potential for robotic trajectory
planning. However, generating coherent and long-horizon trajectories from
high-level instructions remains challenging, especially for complex tasks
requiring multiple sequential skills. We propose SkillDiffuser, an end-to-end
hierarchical planning framework integrating interpretable skill learning with
conditional diffusion planning to address this problem. At the higher level,
the skill abstraction module learns discrete, human-understandable skill
representations from visual observations and language instructions. These
learned skill embeddings are then used to condition the diffusion model to
generate customized latent trajectories aligned with the skills. It allows for
generating diverse state trajectories that adhere to the learnable skills. By
integrating skill learning with conditional trajectory generation,
SkillDiffuser produces coherent behavior following abstract instructions across
diverse tasks. Experiments on multi-task robotic manipulation benchmarks like
Meta-World and LOReL demonstrate state-of-the-art performance and
human-interpretable skill representations from SkillDiffuser.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11600" title="Abstract">arXiv:2312.11600</a> [<a href="/pdf/2312.11600" title="Download PDF">pdf</a>, <a href="/format/2312.11600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-Channel Extended Kalman Filtering with Intermittent Measurements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Maer%2C+V">Vicu-Mihalis Maer</a>, 
<a href="/search/eess?searchtype=author&query=Lendek%2C+Z">Zsofia Lendek</a>, 
<a href="/search/eess?searchtype=author&query=Pirje%2C+S">Stefan Pirje</a>, 
<a href="/search/eess?searchtype=author&query=Tolic%2C+D">Domagoj Tolic</a>, 
<a href="/search/eess?searchtype=author&query=Djuras%2C+A">Antun Djuras</a>, 
<a href="/search/eess?searchtype=author&query=Prkacin%2C+V">Vicko Prkacin</a>, 
<a href="/search/eess?searchtype=author&query=Palunko%2C+I">Ivana Palunko</a>, 
<a href="/search/eess?searchtype=author&query=Busoniu%2C+L">Lucian Busoniu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">We consider two nonlinear state estimation problems in a setting where an
extended Kalman filter receives measurements from two sets of sensors via two
channels (2C). In the stochastic-2C problem, the channels drop measurements
stochastically, whereas in 2C scheduling, the estimator chooses when to read
each channel. In the first problem, we generalize linear-case 2C analysis to
obtain -- for a given pair of channel arrival rates -- boundedness conditions
for the trace of the error covariance, as well as a worst-case upper bound. For
scheduling, an optimization problem is solved to find arrival rates that
balance low channel usage with low trace bounds, and channels are read
deterministically with the expected periods corresponding to these arrival
rates. We validate both solutions in simulations for linear and nonlinear
dynamics; as well as in a real experiment with an underwater robot whose
position is being intermittently found in a UAV camera image.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11648" title="Abstract">arXiv:2312.11648</a> [<a href="/pdf/2312.11648" title="Download PDF">pdf</a>, <a href="/format/2312.11648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experiment-informed finite-strain inverse design of spinodal  metamaterials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thakolkaran%2C+P">Prakash Thakolkaran</a>, 
<a href="/search/cs?searchtype=author&query=Espinal%2C+M+A">Michael A. Espinal</a>, 
<a href="/search/cs?searchtype=author&query=Dhulipala%2C+S">Somayajulu Dhulipala</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Siddhant Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Portela%2C+C+M">Carlos M. Portela</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">This study presents a novel physics-enhanced machine learning (ML) and
optimization framework tailored to address the challenges of designing
intricate spinodal metamaterials with customized mechanical properties in
scenarios where computational modeling is restricted, and experimental data is
sparse. By utilizing sparse experimental data directly, our approach
facilitates the inverse design of spinodal structures with precise
finite-strain mechanical responses. Leveraging physics-based inductive biases
to compensate for limited data availability, the framework sheds light on
instability-induced pattern formation in periodic metamaterials, attributing it
to nonconvex energetic potentials. Inspired by phase transformation modeling,
the method integrates multiple partial input convex neural networks to create
nonconvex potentials, effectively capturing complex nonlinear stress-strain
behavior, even under extreme deformations.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11651" title="Abstract">arXiv:2312.11651</a> [<a href="/pdf/2312.11651" title="Download PDF">pdf</a>, <a href="/format/2312.11651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Logic and Learning: A Neural-Symbolic Approach for Enhanced  Reasoning in Neural Models (ASPER)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Machot%2C+F+A">Fadi Al Machot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Neural-symbolic learning, an intersection of neural networks and symbolic
reasoning, aims to blend neural networks' learning capabilities with symbolic
AI's interpretability and reasoning. This paper introduces an approach designed
to improve the performance of neural models in learning reasoning tasks. It
achieves this by integrating Answer Set Programming (ASP) solvers and
domain-specific expertise, which is an approach that diverges from traditional
complex neural-symbolic models. In this paper, a shallow artificial neural
network (ANN) is specifically trained to solve Sudoku puzzles with minimal
training data. The model has a unique loss function that integrates losses
calculated using the ASP solver outputs, effectively enhancing its training
efficiency. Most notably, the model shows a significant improvement in solving
Sudoku puzzles using only 12 puzzles for training and testing without
hyperparameter tuning. This advancement indicates that the model's enhanced
reasoning capabilities have practical applications, extending well beyond
Sudoku puzzles to potentially include a variety of other domains. The code can
be found on GitHub: https://github.com/Fadi2200/ASPEN.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11658" title="Abstract">arXiv:2312.11658</a> [<a href="/pdf/2312.11658" title="Download PDF">pdf</a>, <a href="/format/2312.11658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Traces of Memorisation in Large Language Models for Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Al-Kaswan%2C+A">Ali Al-Kaswan</a>, 
<a href="/search/cs?searchtype=author&query=Izadi%2C+M">Maliheh Izadi</a>, 
<a href="/search/cs?searchtype=author&query=van+Deursen%2C+A">Arie van Deursen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICSE 2024 Research Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
<p class="mathjax">Large language models have gained significant popularity because of their
ability to generate human-like text and potential applications in various
fields, such as Software Engineering. Large language models for code are
commonly trained on large unsanitised corpora of source code scraped from the
internet. The content of these datasets is memorised and can be extracted by
attackers with data extraction attacks. In this work, we explore memorisation
in large language models for code and compare the rate of memorisation with
large language models trained on natural language. We adopt an existing
benchmark for natural language and construct a benchmark for code by
identifying samples that are vulnerable to attack. We run both benchmarks
against a variety of models, and perform a data extraction attack. We find that
large language models for code are vulnerable to data extraction attacks, like
their natural language counterparts. From the training data that was identified
to be potentially extractable we were able to extract 47% from a
CodeGen-Mono-16B code completion model. We also observe that models memorise
more, as their parameter count grows, and that their pre-training data are also
vulnerable to attack. We also find that data carriers are memorised at a higher
rate than regular code or documentation and that different model architectures
memorise different samples. Data leakage has severe outcomes, so we urge the
research community to further investigate the extent of this phenomenon using a
wider range of models and extraction techniques in order to build safeguards to
mitigate this issue.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11663" title="Abstract">arXiv:2312.11663</a> [<a href="/pdf/2312.11663" title="Download PDF">pdf</a>, <a href="/format/2312.11663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eliciting Kemeny Rankings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=George%2C+A">Anne-Marie George</a>, 
<a href="/search/cs?searchtype=author&query=Dimitrakakis%2C+C">Christos Dimitrakakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a long version of the AAAI'24 publication under the same title
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We formulate the problem of eliciting agents' preferences with the goal of
finding a Kemeny ranking as a Dueling Bandits problem. Here the bandits' arms
correspond to alternatives that need to be ranked and the feedback corresponds
to a pairwise comparison between alternatives by a randomly sampled agent. We
consider both sampling with and without replacement, i.e., the possibility to
ask the same agent about some comparison multiple times or not.
<br />We find approximation bounds for Kemeny rankings dependant on confidence
intervals over estimated winning probabilities of arms. Based on these we state
algorithms to find Probably Approximately Correct (PAC) solutions and elaborate
on their sample complexity for sampling with or without replacement.
Furthermore, if all agents' preferences are strict rankings over the
alternatives, we provide means to prune confidence intervals and thereby guide
a more efficient elicitation. We formulate several adaptive sampling methods
that use look-aheads to estimate how much confidence intervals (and thus
approximation guarantees) might be tightened. All described methods are
compared on synthetic data.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11666" title="Abstract">arXiv:2312.11666</a> [<a href="/pdf/2312.11666" title="Download PDF">pdf</a>, <a href="/format/2312.11666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HAAR: Text-Conditioned Generative Model of 3D Strand-based Human  Hairstyles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sklyarova%2C+V">Vanessa Sklyarova</a>, 
<a href="/search/cs?searchtype=author&query=Zakharov%2C+E">Egor Zakharov</a>, 
<a href="/search/cs?searchtype=author&query=Hilliges%2C+O">Otmar Hilliges</a>, 
<a href="/search/cs?searchtype=author&query=Black%2C+M+J">Michael J. Black</a>, 
<a href="/search/cs?searchtype=author&query=Thies%2C+J">Justus Thies</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> For more results please refer to the project page <a href="https://haar.is.tue.mpg.de/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We present HAAR, a new strand-based generative model for 3D human hairstyles.
Specifically, based on textual inputs, HAAR produces 3D hairstyles that could
be used as production-level assets in modern computer graphics engines. Current
AI-based generative models take advantage of powerful 2D priors to reconstruct
3D content in the form of point clouds, meshes, or volumetric functions.
However, by using the 2D priors, they are intrinsically limited to only
recovering the visual parts. Highly occluded hair structures can not be
reconstructed with those methods, and they only model the ''outer shell'',
which is not ready to be used in physics-based rendering or simulation
pipelines. In contrast, we propose a first text-guided generative method that
uses 3D hair strands as an underlying representation. Leveraging 2D visual
question-answering (VQA) systems, we automatically annotate synthetic hair
models that are generated from a small set of artist-created hairstyles. This
allows us to train a latent diffusion model that operates in a common hairstyle
UV space. In qualitative and quantitative studies, we demonstrate the
capabilities of the proposed model and compare it to existing hairstyle
generation approaches.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11669" title="Abstract">arXiv:2312.11669</a> [<a href="/pdf/2312.11669" title="Download PDF">pdf</a>, <a href="/format/2312.11669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prediction and Control in Continual Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anand%2C+N">Nishanth Anand</a>, 
<a href="/search/cs?searchtype=author&query=Precup%2C+D">Doina Precup</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Temporal difference (TD) learning is often used to update the estimate of the
value function which is used by RL agents to extract useful policies. In this
paper, we focus on value function estimation in continual reinforcement
learning. We propose to decompose the value function into two components which
update at different timescales: a permanent value function, which holds general
knowledge that persists over time, and a transient value function, which allows
quick adaptation to new situations. We establish theoretical results showing
that our approach is well suited for continual learning and draw connections to
the complementary learning systems (CLS) theory from neuroscience. Empirically,
this approach improves performance significantly on both prediction and control
problems.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11671" title="Abstract">arXiv:2312.11671</a> [<a href="/pdf/2312.11671" title="Download PDF">pdf</a>, <a href="/format/2312.11671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Language-Model Agents on Realistic Autonomous Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kinniment%2C+M">Megan Kinniment</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+L+J+K">Lucas Jun Koba Sato</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Haoxing Du</a>, 
<a href="/search/cs?searchtype=author&query=Goodrich%2C+B">Brian Goodrich</a>, 
<a href="/search/cs?searchtype=author&query=Hasin%2C+M">Max Hasin</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+L">Lawrence Chan</a>, 
<a href="/search/cs?searchtype=author&query=Miles%2C+L+H">Luke Harold Miles</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+T+R">Tao R. Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wijk%2C+H">Hjalmar Wijk</a>, 
<a href="/search/cs?searchtype=author&query=Burget%2C+J">Joel Burget</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+A">Aaron Ho</a>, 
<a href="/search/cs?searchtype=author&query=Barnes%2C+E">Elizabeth Barnes</a>, 
<a href="/search/cs?searchtype=author&query=Christiano%2C+P">Paul Christiano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this report, we explore the ability of language model agents to acquire
resources, create copies of themselves, and adapt to novel challenges they
encounter in the wild. We refer to this cluster of capabilities as "autonomous
replication and adaptation" or ARA. We believe that systems capable of ARA
could have wide-reaching and hard-to-anticipate consequences, and that
measuring and forecasting ARA may be useful for informing measures around
security, monitoring, and alignment. Additionally, once a system is capable of
ARA, placing bounds on a system's capabilities may become significantly more
difficult.
<br />We construct four simple example agents that combine language models with
tools that allow them to take actions in the world. We then evaluate these
agents on 12 tasks relevant to ARA. We find that these language model agents
can only complete the easiest tasks from this list, although they make some
progress on the more challenging tasks. Unfortunately, these evaluations are
not adequate to rule out the possibility that near-future agents will be
capable of ARA. In particular, we do not think that these evaluations provide
good assurance that the ``next generation'' of language models (e.g. 100x
effective compute scaleup on existing models) will not yield agents capable of
ARA, unless intermediate evaluations are performed during pretraining.
Relatedly, we expect that fine-tuning of the existing models could produce
substantially more competent agents, even if the fine-tuning is not directly
targeted at ARA.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11675" title="Abstract">arXiv:2312.11675</a> [<a href="/pdf/2312.11675" title="Download PDF">pdf</a>, <a href="/format/2312.11675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PRP Rebooted: Advancing the State of the Art in FOND Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muise%2C+C">Christian Muise</a>, 
<a href="/search/cs?searchtype=author&query=McIlraith%2C+S+A">Sheila A. McIlraith</a>, 
<a href="/search/cs?searchtype=author&query=Beck%2C+J+C">J. Christopher Beck</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures, AAAI conference paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Fully Observable Non-Deterministic (FOND) planning is a variant of classical
symbolic planning in which actions are nondeterministic, with an action's
outcome known only upon execution. It is a popular planning paradigm with
applications ranging from robot planning to dialogue-agent design and reactive
synthesis. Over the last 20 years, a number of approaches to FOND planning have
emerged. In this work, we establish a new state of the art, following in the
footsteps of some of the most powerful FOND planners to date. Our planner, \us,
decisively outperforms the four leading FOND planners, at times by a large
margin, in 17 of 18 domains that represent a comprehensive benchmark suite.
Ablation studies demonstrate the empirical impact of various techniques we
introduce, with the largest improvement coming from our novel FOND-aware
heuristic.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11678" title="Abstract">arXiv:2312.11678</a> [<a href="/pdf/2312.11678" title="Download PDF">pdf</a>, <a href="/format/2312.11678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Misinformation as a harm: structured approaches for fact-checking  prioritization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sehat%2C+C+M">Connie Moon Sehat</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ryan Li</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+P">Peipei Nie</a>, 
<a href="/search/cs?searchtype=author&query=Prabhakar%2C+T">Tarunima Prabhakar</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A+X">Amy X. Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CSCW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In this work, we examined how fact-checkers prioritize which claims to
inspect for further investigation and publishing, and what tools may assist
them in their efforts. Specifically, through a series of interviews with 23
professional fact-checkers from around the world, we validated that harm
assessment is a central component of how fact-checkers triage their work.
First, we clarify what aspects of misinformation they considered to create
urgency or importance. These often revolved around the potential for the claim
to harm others. We also clarify the processes behind collective fact-checking
decisions and gather suggestions for tools that could help with these
processes.
<br />In addition, to address the needs articulated by these fact-checkers and
others, we present a five-dimension framework of questions to help
fact-checkers negotiate the priority of claims. Our FABLE Framework of
Misinformation Harms incorporates five dimensions of magnitude -- (social)
Fragmentation, Actionability, Believability, Likelihood of spread, and
Exploitativeness -- that can help determine the potential urgency of a specific
message or post when considering misinformation as harm. This effort was
further validated by additional interviews with expert fact-checkers. The
result is a questionnaire, a practical and conceptual tool to support
fact-checkers and other content moderators as they make strategic decisions to
prioritize their efforts.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11681" title="Abstract">arXiv:2312.11681</a> [<a href="/pdf/2312.11681" title="Download PDF">pdf</a>, <a href="/format/2312.11681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing LLM Chains by Adapting Techniques from Crowdsourcing Workflows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grunde-McLaughlin%2C+M">Madeleine Grunde-McLaughlin</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+M+S">Michelle S. Lam</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+R">Ranjay Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Weld%2C+D+S">Daniel S. Weld</a>, 
<a href="/search/cs?searchtype=author&query=Heer%2C+J">Jeffrey Heer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">LLM chains enable complex tasks by decomposing work into a sequence of
sub-tasks. Crowdsourcing workflows similarly decompose complex tasks into
smaller tasks for human crowdworkers. Chains address LLM errors analogously to
the way crowdsourcing workflows address human error. To characterize
opportunities for LLM chaining, we survey 107 papers across the crowdsourcing
and chaining literature to construct a design space for chain development. The
design space connects an LLM designer's objectives to strategies they can use
to achieve those objectives, and tactics to implement each strategy. To explore
how techniques from crowdsourcing may apply to chaining, we adapt crowdsourcing
workflows to implement LLM chains across three case studies: creating a
taxonomy, shortening text, and writing a short story. From the design space and
our case studies, we identify which techniques transfer from crowdsourcing to
LLM chaining and raise implications for future research and development.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11682" title="Abstract">arXiv:2312.11682</a> [<a href="/pdf/2312.11682" title="Download PDF">pdf</a>, <a href="/format/2312.11682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Phase-Time Arrays: A Paradigm for Frequency-Dependent Analog  Beamforming in 6G
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ratnam%2C+V+V">Vishnu V. Ratnam</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+J">Jianhua Mo</a>, 
<a href="/search/cs?searchtype=author&query=AlAmmouri%2C+A">Ahmad AlAmmouri</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+B+L">Boon L. Ng</a>, 
<a href="/search/cs?searchtype=author&query=Jianzhong">Jianzhong</a> (Charlie)
<a href="/search/cs?searchtype=author&query=Zhang">Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Molisch%2C+A+F">Andreas F. Molisch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper is a revised version of the IEEE Access paper, that includes the full operation of Algorithms 1-3 to help curtail incorrect implementations
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Access, vol. 10, pp. 73364-73377, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Hybrid beamforming is an attractive solution to build cost-effective and
energy-efficient transceivers for millimeter-wave and terahertz systems.
However, conventional hybrid beamforming techniques rely on analog components
that generate a frequency flat response such as phase-shifters and switches,
which limits the flexibility of the achievable beam patterns. As a novel
alternative, this paper proposes a new class of hybrid beamforming called Joint
phase-time arrays (JPTA), that additionally use true-time delay elements in the
analog beamforming to create frequency-dependent analog beams. Using as an
example two important frequency-dependent beam behaviors, the numerous benefits
of such flexibility are exemplified. Subsequently, the JPTA beamformer design
problem to generate any desired beam behavior is formulated and near-optimal
algorithms to the problem are proposed. Simulations show that the proposed
algorithms can outperform heuristics solutions for JPTA beamformer update.
Furthermore, it is shown that JPTA can achieve the two exemplified beam
behaviors with one radio-frequency chain, while conventional hybrid beamforming
requires the radio-frequency chains to scale with the number of antennas to
achieve similar performance. Finally, a wide range of problems to further tap
into the potential of JPTA are also listed as future directions.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11688" title="Abstract">arXiv:2312.11688</a> [<a href="/pdf/2312.11688" title="Download PDF">pdf</a>, <a href="/format/2312.11688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bilinear Expectation Propagation for Distributed Semi-Blind Joint  Channel Estimation and Data Detection in Cell-Free Massive MIMO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karataev%2C+A">Alexander Karataev</a>, 
<a href="/search/cs?searchtype=author&query=Forsch%2C+C">Christian Forsch</a>, 
<a href="/search/cs?searchtype=author&query=Cottatellucci%2C+L">Laura Cottatellucci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures, to be printed in IEEE Open Journal of Signal Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">We consider a cell-free massive multiple-input multiple-output (CF-MaMIMO)
communication system in the uplink transmission and propose a novel algorithm
for blind or semi-blind joint channel estimation and data detection (JCD). We
formulate the problem in the framework of bilinear inference and develop a
solution based on the expectation propagation (EP) method for both channel
estimation and data detection. We propose a new approximation of the joint a
posteriori distribution of the channel and data whose representation as a
factor graph enables the application of the EP approach using the
message-passing technique, local low-complexity computations at the nodes, and
an effective modeling of channel-data interplay. The derived algorithm, called
bilinear-EP JCD, allows for a distributed implementation among access points
(APs) and the central processing unit (CPU) and has polynomial complexity. Our
simulation results show that it outperforms other EP-based state-of-the-art
polynomial time algorithms.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11690" title="Abstract">arXiv:2312.11690</a> [<a href="/pdf/2312.11690" title="Download PDF">pdf</a>, <a href="/format/2312.11690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agent-based Learning of Materials Datasets from Scientific Literature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ansari%2C+M">Mehrad Ansari</a>, 
<a href="/search/cs?searchtype=author&query=Moosavi%2C+S+M">Seyed Mohamad Moosavi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Advancements in machine learning and artificial intelligence are transforming
materials discovery. Yet, the availability of structured experimental data
remains a bottleneck. The vast corpus of scientific literature presents a
valuable and rich resource of such data. However, manual dataset creation from
these resources is challenging due to issues in maintaining quality and
consistency, scalability limitations, and the risk of human error and bias.
Therefore, in this work, we develop a chemist AI agent, powered by large
language models (LLMs), to overcome these challenges by autonomously creating
structured datasets from natural language text, ranging from sentences and
paragraphs to extensive scientific research articles. Our chemist AI agent,
Eunomia, can plan and execute actions by leveraging the existing knowledge from
decades of scientific research articles, scientists, the Internet and other
tools altogether. We benchmark the performance of our approach in three
different information extraction tasks with various levels of complexity,
including solid-state impurity doping, metal-organic framework (MOF) chemical
formula, and property relations. Our results demonstrate that our zero-shot
agent, with the appropriate tools, is capable of attaining performance that is
either superior or comparable to the state-of-the-art fine-tuned materials
information extraction methods. This approach simplifies compilation of machine
learning-ready datasets for various materials discovery applications, and
significantly ease the accessibility of advanced natural language processing
tools for novice users in natural language. The methodology in this work is
developed as an open-source software on https://github.com/AI4ChemS/Eunomia.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11701" title="Abstract">arXiv:2312.11701</a> [<a href="/pdf/2312.11701" title="Download PDF">pdf</a>, <a href="/ps/2312.11701" title="Download PostScript">ps</a>, <a href="/format/2312.11701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Opportunities and Challenges of Applying Large Language Models in  Building Energy Efficiency and Decarbonization Studies: An Exploratory  Overview
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Liang Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Z">Zhelun Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">In recent years, the rapid advancement and impressive capabilities of Large
Language Models (LLMs) have been evident across various domains. This paper
explores the application, implications, and potential of LLMs in building
energy efficiency and decarbonization studies. The wide-ranging capabilities of
LLMs are examined in the context of the building energy field, including
intelligent control systems, code generation, data infrastructure, knowledge
extraction, and education. Despite the promising potential of LLMs, challenges
including complex and expensive computation, data privacy, security and
copyright, complexity in fine-tuned LLMs, and self-consistency are discussed.
The paper concludes with a call for future research focused on the enhancement
of LLMs for domain-specific tasks, multi-modal LLMs, and collaborative research
between AI and energy experts.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11703" title="Abstract">arXiv:2312.11703</a> [<a href="/pdf/2312.11703" title="Download PDF">pdf</a>, <a href="/format/2312.11703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shaping Political Discourse using multi-source News Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajan%2C+C">Charles Rajan</a>, 
<a href="/search/cs?searchtype=author&query=Asnani%2C+N">Nishit Asnani</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Shreya Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Multi-document summarization is the process of automatically generating a
concise summary of multiple documents related to the same topic. This summary
can help users quickly understand the key information from a large collection
of documents. Multi-document summarization systems are more complex than
single-document summarization systems due to the need to identify and combine
information from multiple sources. In this paper, we have developed a machine
learning model that generates a concise summary of a topic from multiple news
documents. The model is designed to be unbiased by sampling its input equally
from all the different aspects of the topic, even if the majority of the news
sources lean one way.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11707" title="Abstract">arXiv:2312.11707</a> [<a href="/pdf/2312.11707" title="Download PDF">pdf</a>, <a href="/format/2312.11707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified framework for diffusion generative models in SO(3): applications  in computer vision and astrophysics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jagvaral%2C+Y">Yesukhei Jagvaral</a>, 
<a href="/search/cs?searchtype=author&query=Lanusse%2C+F">Francois Lanusse</a>, 
<a href="/search/cs?searchtype=author&query=Mandelbaum%2C+R">Rachel Mandelbaum</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI-2024 Main Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Diffusion-based generative models represent the current state-of-the-art for
image generation. However, standard diffusion models are based on Euclidean
geometry and do not translate directly to manifold-valued data. In this work,
we develop extensions of both score-based generative models (SGMs) and
Denoising Diffusion Probabilistic Models (DDPMs) to the Lie group of 3D
rotations, SO(3). SO(3) is of particular interest in many disciplines such as
robotics, biochemistry and astronomy/cosmology science. Contrary to more
general Riemannian manifolds, SO(3) admits a tractable solution to heat
diffusion, and allows us to implement efficient training of diffusion models.
We apply both SO(3) DDPMs and SGMs to synthetic densities on SO(3) and
demonstrate state-of-the-art results. Additionally, we demonstrate the
practicality of our model on pose estimation tasks and in predicting correlated
galaxy orientations for astrophysics/cosmology.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11709" title="Abstract">arXiv:2312.11709</a> [<a href="/pdf/2312.11709" title="Download PDF">pdf</a>, <a href="/format/2312.11709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extended Regge complex for linearized Riemann-Cartan geometry and  cohomology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Christiansen%2C+S+H">Snorre H. Christiansen</a>, 
<a href="/search/math?searchtype=author&query=Hu%2C+K">Kaibo Hu</a>, 
<a href="/search/math?searchtype=author&query=Lin%2C+T">Ting Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph); Differential Geometry (math.DG)

</div>
<p class="mathjax">We show that the cohomology of the Regge complex in three dimensions is
isomorphic to $\mathcal{H}^{{\scriptscriptstyle
\bullet}}_{dR}(\Omega)\otimes\mathcal{RM}$, the
infinitesimal-rigid-body-motion-valued de~Rham cohomology. Based on an
observation that the twisted de~Rham complex extends the elasticity (Riemannian
deformation) complex to the linearized version of coframes, connection 1-forms,
curvature and Cartan's torsion, we construct a discrete version of linearized
Riemann-Cartan geometry on any triangulation and determine its cohomology.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11712" title="Abstract">arXiv:2312.11712</a> [<a href="/pdf/2312.11712" title="Download PDF">pdf</a>, <a href="/format/2312.11712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple and Practical Method for Reducing the Disparate Impact of  Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rosenblatt%2C+L">Lucas Rosenblatt</a>, 
<a href="/search/cs?searchtype=author&query=Stoyanovich%2C+J">Julia Stoyanovich</a>, 
<a href="/search/cs?searchtype=author&query=Musco%2C+C">Christopher Musco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Differentially private (DP) mechanisms have been deployed in a variety of
high-impact social settings (perhaps most notably by the U.S. Census). Since
all DP mechanisms involve adding noise to results of statistical queries, they
are expected to impact our ability to accurately analyze and learn from data,
in effect trading off privacy with utility. Alarmingly, the impact of DP on
utility can vary significantly among different sub-populations. A simple way to
reduce this disparity is with stratification. First compute an independent
private estimate for each group in the data set (which may be the intersection
of several protected classes), then, to compute estimates of global statistics,
appropriately recombine these group estimates. Our main observation is that
naive stratification often yields high-accuracy estimates of population-level
statistics, without the need for additional privacy budget. We support this
observation theoretically and empirically. Our theoretical results center on
the private mean estimation problem, while our empirical results center on
extensive experiments on private data synthesis to demonstrate the
effectiveness of stratification on a variety of private mechanisms. Overall, we
argue that this straightforward approach provides a strong baseline against
which future work on reducing utility disparities of DP mechanisms should be
compared.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11713" title="Abstract">arXiv:2312.11713</a> [<a href="/pdf/2312.11713" title="Download PDF">pdf</a>, <a href="/format/2312.11713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Indoor and Outdoor 3D Scene Graph Generation via Language-Enabled  Spatial Ontologies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Strader%2C+J">Jared Strader</a>, 
<a href="/search/cs?searchtype=author&query=Hughes%2C+N">Nathan Hughes</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">William Chen</a>, 
<a href="/search/cs?searchtype=author&query=Speranzon%2C+A">Alberto Speranzon</a>, 
<a href="/search/cs?searchtype=author&query=Carlone%2C+L">Luca Carlone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures, submitted to Robotics and Automation Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper proposes an approach to build 3D scene graphs in arbitrary (indoor
and outdoor) environments. Such extension is challenging; the hierarchy of
concepts that describe an outdoor environment is more complex than for indoors,
and manually defining such hierarchy is time-consuming and does not scale.
Furthermore, the lack of training data prevents the straightforward application
of learning-based tools used in indoor settings. To address these challenges,
we propose two novel extensions. First, we develop methods to build a spatial
ontology defining concepts and relations relevant for indoor and outdoor robot
operation. In particular, we use a Large Language Model (LLM) to build such an
ontology, thus largely reducing the amount of manual effort required. Second,
we leverage the spatial ontology for 3D scene graph construction using Logic
Tensor Networks (LTN) to add logical rules, or axioms (e.g., "a beach contains
sand"), which provide additional supervisory signals at training time thus
reducing the need for labelled data, providing better predictions, and even
allowing predicting concepts unseen at training time. We test our approach in a
variety of datasets, including indoor, rural, and coastal environments, and
show that it leads to a significant increase in the quality of the 3D scene
graph generation with sparsely annotated data.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11714" title="Abstract">arXiv:2312.11714</a> [<a href="/pdf/2312.11714" title="Download PDF">pdf</a>, <a href="/format/2312.11714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Transformer: Integrating Local and Global Features for Better Time  Series Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuansan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wijewickrema%2C+S">Sudanthi Wijewickrema</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Ang Li</a>, 
<a href="/search/cs?searchtype=author&query=Bester%2C+C">Christofer Bester</a>, 
<a href="/search/cs?searchtype=author&query=O%27Leary%2C+S">Stephen O&#x27;Leary</a>, 
<a href="/search/cs?searchtype=author&query=Bailey%2C+J">James Bailey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures and 16 tables. SDM24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generating time series data is a promising approach to address data
deficiency problems. However, it is also challenging due to the complex
temporal properties of time series data, including local correlations as well
as global dependencies. Most existing generative models have failed to
effectively learn both the local and global properties of time series data. To
address this open problem, we propose a novel time series generative model
named 'Time-Transformer AAE', which consists of an adversarial autoencoder
(AAE) and a newly designed architecture named 'Time-Transformer' within the
decoder. The Time-Transformer first simultaneously learns local and global
features in a layer-wise parallel design, combining the abilities of Temporal
Convolutional Networks and Transformer in extracting local features and global
dependencies respectively. Second, a bidirectional cross attention is proposed
to provide complementary guidance across the two branches and achieve proper
fusion between local and global features. Experimental results demonstrate that
our model can outperform existing state-of-the-art models in 5 out of 6
datasets, specifically on those with data containing both global and local
properties. Furthermore, we highlight our model's advantage on handling this
kind of data via an artificial dataset. Finally, we show our model's ability to
address a real-world problem: data augmentation to support learning with small
datasets and imbalanced datasets.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11716" title="Abstract">arXiv:2312.11716</a> [<a href="/pdf/2312.11716" title="Download PDF">pdf</a>, <a href="/format/2312.11716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Squeezed Edge YOLO: Onboard Object Detection on Edge Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Humes%2C+E">Edward Humes</a>, 
<a href="/search/cs?searchtype=author&query=Navardi%2C+M">Mozhgan Navardi</a>, 
<a href="/search/cs?searchtype=author&query=Mohsenin%2C+T">Tinoosh Mohsenin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ML with New Compute Paradigms (MLNCP) Workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Demand for efficient onboard object detection is increasing due to its key
role in autonomous navigation. However, deploying object detection models such
as YOLO on resource constrained edge devices is challenging due to the high
computational requirements of such models. In this paper, an compressed object
detection model named Squeezed Edge YOLO is examined. This model is compressed
and optimized to kilobytes of parameters in order to fit onboard such edge
devices. To evaluate Squeezed Edge YOLO, two use cases - human and shape
detection - are used to show the model accuracy and performance. Moreover, the
model is deployed onboard a GAP8 processor with 8 RISC-V cores and an NVIDIA
Jetson Nano with 4GB of memory. Experimental results show Squeezed Edge YOLO
model size is optimized by a factor of 8x which leads to 76% improvements in
energy efficiency and 3.3x faster throughout.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11718" title="Abstract">arXiv:2312.11718</a> [<a href="/pdf/2312.11718" title="Download PDF">pdf</a>, <a href="/format/2312.11718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-Machine Teaming for UAVs: An Experimentation Platform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moujtahid%2C+L+E">Laila El Moujtahid</a>, 
<a href="/search/cs?searchtype=author&query=Gottipati%2C+S+K">Sai Krishna Gottipati</a>, 
<a href="/search/cs?searchtype=author&query=Mars%2C+C">Clod&#xe9;ric Mars</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+M+E">Matthew E. Taylor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures Presented at Conference on Artificial Intelligence for Defense (CAID) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Applications (stat.AP)

</div>
<p class="mathjax">Full automation is often not achievable or desirable in critical systems with
high-stakes decisions. Instead, human-AI teams can achieve better results. To
research, develop, evaluate, and validate algorithms suited for such teaming,
lightweight experimentation platforms that enable interactions between humans
and multiple AI agents are necessary. However, there are limited examples of
such platforms for defense environments. To address this gap, we present the
Cogment human-machine teaming experimentation platform, which implements
human-machine teaming (HMT) use cases that features heterogeneous multi-agent
systems and can involve learning AI agents, static AI agents, and humans. It is
built on the Cogment platform and has been used for academic research,
including work presented at the ALA workshop at AAMAS this year [1]. With this
platform, we hope to facilitate further research on human-machine teaming in
critical systems and defense environments.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11719" title="Abstract">arXiv:2312.11719</a> [<a href="/pdf/2312.11719" title="Download PDF">pdf</a>, <a href="/format/2312.11719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Far Are We? The Triumphs and Trials of Generative AI in Learning  Software Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choudhuri%2C+R">Rudrajit Choudhuri</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dylan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Steinmacher%2C+I">Igor Steinmacher</a>, 
<a href="/search/cs?searchtype=author&query=Gerosa%2C+M">Marco Gerosa</a>, 
<a href="/search/cs?searchtype=author&query=Sarma%2C+A">Anita Sarma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, ICSE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Conversational Generative AI (convo-genAI) is revolutionizing Software
Engineering (SE) as engineers and academics embrace this technology in their
work. However, there is a gap in understanding the current potential and
pitfalls of this technology, specifically in supporting students in SE tasks.
In this work, we evaluate through a between-subjects study (N=22) the
effectiveness of ChatGPT, a convo-genAI platform, in assisting students in SE
tasks. Our study did not find statistical differences in participants'
productivity or self-efficacy when using ChatGPT as compared to traditional
resources, but we found significantly increased frustration levels. Our study
also revealed 5 distinct faults arising from violations of Human-AI interaction
guidelines, which led to 7 different (negative) consequences on participants.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11720" title="Abstract">arXiv:2312.11720</a> [<a href="/pdf/2312.11720" title="Download PDF">pdf</a>, <a href="/format/2312.11720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing Logical Reasoning Capabilities of Encoder-Only Transformer  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pirozelli%2C+P">Paulo Pirozelli</a>, 
<a href="/search/cs?searchtype=author&query=Jos%C3%A9%2C+M+M">Marcos M. Jos&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=de+Tarso+P.+Filho%2C+P">Paulo de Tarso P. Filho</a>, 
<a href="/search/cs?searchtype=author&query=Brand%C3%A3o%2C+A+A+F">Anarosa A. F. Brand&#xe3;o</a>, 
<a href="/search/cs?searchtype=author&query=Cozman%2C+F+G">Fabio G. Cozman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Logical reasoning is central to complex human activities, such as thinking,
debating, and planning; it is also a central component of many AI systems as
well. In this paper, we investigate the extent to which encoder-only
transformer language models (LMs) can reason according to logical rules. We ask
whether those LMs can deduce theorems in propositional calculus and first-order
logic; if their relative success in these problems reflects general logical
capabilities; and which layers contribute the most to the task. First, we show
for several encoder-only LMs that they can be trained, to a reasonable degree,
to determine logical validity on various datasets. Next, by cross-probing
fine-tuned models on these datasets, we show that LMs have difficulty in
transferring their putative logical reasoning ability, which suggests that they
may have learned dataset-specific features, instead of a general capability.
Finally, we conduct a layerwise probing experiment, which shows that the
hypothesis classification task is mostly solved through higher layers.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11725" title="Abstract">arXiv:2312.11725</a> [<a href="/pdf/2312.11725" title="Download PDF">pdf</a>, <a href="/ps/2312.11725" title="Download PostScript">ps</a>, <a href="/format/2312.11725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A review of Energy Efficient Routing Protocols in Underwater Internet of  Things
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tarif%2C+M">Mehran Tarif</a>, 
<a href="/search/cs?searchtype=author&query=Moghadam%2C+B+N">Babak Nouri Moghadam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 figure, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Oceans, covering 70% of Earth's surface, arelargely unexplored, with about
95% remaining a mystery.Underwater wireless communication is pivotal in various
domains,such as real-time aquatic data collection, marine surveillance,disaster
prevention, archaeological exploration, andenvironmental monitoring. The
Internet of Things has openednew avenues in underwater exploration through the
underwaterInternet of Things concept. This innovative technology
facilitatessmart ocean research, from small case studies to
large-scaleoperations. UIoT networks utilise underwater equipment andsensors to
gather and transmit data in aquatic environments.However, the dynamic nature of
these environments poseschallenges to the network's structure and
communication,necessitating efficient routing solutions.
Quality-of-service-awarerouting is vital as it minimises energy usage, extends
battery life,and enhances network performance. This paper delves into
thechallenges and limitations of UIoT networks, highlighting recentrouting
methodologies. It also proposes a comparison frameworkfor routing methods,
focusing on the quality of service inunderwater IoT networks, to foster more
optimal route selectionand better resource management.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11730" title="Abstract">arXiv:2312.11730</a> [<a href="/pdf/2312.11730" title="Download PDF">pdf</a>, <a href="/format/2312.11730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stronger Graph Transformer with Regularized Attention Scores
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ku%2C+E">Eugene Ku</a>, 
<a href="/search/cs?searchtype=author&query=Arunraj%2C+S">Swetha Arunraj</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph Neural Networks are notorious for its memory consumption. A recent
Transformer based GNN called Graph Transformer are shown to obtain superior
performances when long range dependencies exist. However, combining graph data
and Transformer architecture led to a combinationally worse memory issue. We
propose a novel version of "edge regularization technique" that alleviates the
need for Positional Encoding and ultimately alleviate GT's out of memory issue.
We observe that it is not clear whether having an edge regularization on top of
positional encoding is helpful. However, it seems evident when no positional
encoding is applied, edge regularization technique indeed stably improves GT's
performance.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11733" title="Abstract">arXiv:2312.11733</a> [<a href="/pdf/2312.11733" title="Download PDF">pdf</a>, <a href="/ps/2312.11733" title="Download PostScript">ps</a>, <a href="/format/2312.11733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An abstract framework for heterogeneous coupling: stability,  approximation and applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bertoluzza%2C+S">Silvia Bertoluzza</a>, 
<a href="/search/math?searchtype=author&query=Burman%2C+E">Erik Burman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Introducing a coupling framework reminiscent of FETI methods, but here on
abstract form, we establish conditions for stability and minimal requirements
for well-posedness on the continuous level, as well as conditions on local
solvers for the approximation of subproblems. We then discuss stability of the
resulting Lagrange multiplier methods and show stability under a mesh
conditions between the local discretizations and the mortar space. If this
condition is not satisfied we show how a stabilization, acting only on the
multiplier can be used to achieve stability. The design of preconditioners of
the Schur complement system is discussed in the unstabilized case. Finally we
discuss some applications that enter the framework.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11735" title="Abstract">arXiv:2312.11735</a> [<a href="/pdf/2312.11735" title="Download PDF">pdf</a>, <a href="/format/2312.11735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiple Hypothesis Dropout: Estimating the Parameters of Multi-Modal  Output Distributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+D">David D. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Liebowitz%2C+D">David Liebowitz</a>, 
<a href="/search/cs?searchtype=author&query=Nepal%2C+S">Surya Nepal</a>, 
<a href="/search/cs?searchtype=author&query=Kanhere%2C+S+S">Salil S. Kanhere</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in Proceedings of the 38th AAAI Conference on Artificial Intelligence (AAAI-24). 13 pages (9 main, 4 appendix)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In many real-world applications, from robotics to pedestrian trajectory
prediction, there is a need to predict multiple real-valued outputs to
represent several potential scenarios. Current deep learning techniques to
address multiple-output problems are based on two main methodologies: (1)
mixture density networks, which suffer from poor stability at high dimensions,
or (2) multiple choice learning (MCL), an approach that uses $M$ single-output
functions, each only producing a point estimate hypothesis. This paper presents
a Mixture of Multiple-Output functions (MoM) approach using a novel variant of
dropout, Multiple Hypothesis Dropout. Unlike traditional MCL-based approaches,
each multiple-output function not only estimates the mean but also the variance
for its hypothesis. This is achieved through a novel stochastic winner-take-all
loss which allows each multiple-output function to estimate variance through
the spread of its subnetwork predictions. Experiments on supervised learning
problems illustrate that our approach outperforms existing solutions for
reconstructing multimodal output distributions. Additional studies on
unsupervised learning problems show that estimating the parameters of latent
posterior distributions within a discrete autoencoder significantly improves
codebook efficiency, sample quality, precision and recall.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11739" title="Abstract">arXiv:2312.11739</a> [<a href="/pdf/2312.11739" title="Download PDF">pdf</a>, <a href="/format/2312.11739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TPTO: A Transformer-PPO based Task Offloading Solution for Edge  Computing Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gholipour%2C+N">Niloofar Gholipour</a>, 
<a href="/search/cs?searchtype=author&query=de+Assuncao%2C+M+D">Marcos Dias de Assuncao</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+P">Pranav Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=gascon-samson%2C+j">julien gascon-samson</a>, 
<a href="/search/cs?searchtype=author&query=Buyya%2C+R">Rajkumar Buyya</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE 29nd International Conferance on Parallel and
  Distributed System(ICPADS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Emerging applications in healthcare, autonomous vehicles, and wearable
assistance require interactive and low-latency data analysis services.
Unfortunately, cloud-centric architectures cannot fulfill the low-latency
demands of these applications, as user devices are often distant from cloud
data centers. Edge computing aims to reduce the latency by enabling processing
tasks to be offloaded to resources located at the network's edge. However,
determining which tasks must be offloaded to edge servers to reduce the latency
of application requests is not trivial, especially if the tasks present
dependencies. This paper proposes a DRL approach called TPTO, which leverages
Transformer Networks and PPO to offload dependent tasks of IoT applications in
edge computing. We consider users with various preferences, where devices can
offload computation to an edge server via wireless channels. Performance
evaluation results demonstrate that under fat application graphs, TPTO is more
effective than state-of-the-art methods, such as Greedy, HEFT, and MRLCO, by
reducing latency by 30.24%, 29.61%, and 12.41%, respectively. In addition, TPTO
presents a training time approximately 2.5 times faster than an existing DRL
approach.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11740" title="Abstract">arXiv:2312.11740</a> [<a href="/pdf/2312.11740" title="Download PDF">pdf</a>, <a href="/format/2312.11740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Composable Design of Multiphase Fluid Dynamics Solvers in Flash-X
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhruv%2C+A">Akash Dhruv</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Multiphysics incompressible fluid dynamics simulations play a crucial role in
understanding intricate behaviors of many complex engineering systems that
involve interactions between solids, fluids, and various phases like liquid and
gas. Numerical modeling of these interactions has generated significant
research interest in recent decades and has led to the development of open
source simulation tools and commercial software products targeting specific
applications or general problem classes in computational fluid dynamics. As the
demand increases for these simulations to adapt to platform heterogeneity,
ensure composability between different physics models, and effectively utilize
inheritance within partial differentiation systems, a fundamental
reconsideration of numerical solver design becomes imperative. The discussion
presented in this paper emphasizes the importance of these considerations and
introduces the Flash-X approach as a potential solution. The software design
strategies outlined in the article serve as a guide for Flash-X developers,
providing insights into complexities associated with performance portability,
composability, and sustainable development. These strategies provide a
foundation for improving design of both new and existing simulation tools
grappling with these challenges. By incorporating the principles outlined in
the Flash-X approach, engineers and researchers can enhance the adaptability,
efficiency, and overall effectiveness of their numerical solvers in the
ever-evolving field of multiphysics simulations.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11742" title="Abstract">arXiv:2312.11742</a> [<a href="/pdf/2312.11742" title="Download PDF">pdf</a>, <a href="/format/2312.11742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ACCL+: an FPGA-Based Collective Engine for Distributed Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhenhao He</a>, 
<a href="/search/cs?searchtype=author&query=Korolija%2C+D">Dario Korolija</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ramhorst%2C+B">Benjamin Ramhorst</a>, 
<a href="/search/cs?searchtype=author&query=Laan%2C+T">Tristan Laan</a>, 
<a href="/search/cs?searchtype=author&query=Petrica%2C+L">Lucian Petrica</a>, 
<a href="/search/cs?searchtype=author&query=Blott%2C+M">Michaela Blott</a>, 
<a href="/search/cs?searchtype=author&query=Alonso%2C+G">Gustavo Alonso</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Hardware Architecture (cs.AR); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">FPGAs are increasingly prevalent in cloud deployments, serving as Smart NICs
or network-attached accelerators. Despite their potential, developing
distributed FPGA-accelerated applications remains cumbersome due to the lack of
appropriate infrastructure and communication abstractions. To facilitate the
development of distributed applications with FPGAs, in this paper we propose
ACCL+, an open-source versatile FPGA-based collective communication library.
Portable across different platforms and supporting UDP, TCP, as well as RDMA,
ACCL+ empowers FPGA applications to initiate direct FPGA-to-FPGA collective
communication. Additionally, it can serve as a collective offload engine for
CPU applications, freeing the CPU from networking tasks. It is user-extensible,
allowing new collectives to be implemented and deployed without having to
re-synthesize the FPGA circuit. We evaluated ACCL+ on an FPGA cluster with 100
Gb/s networking, comparing its performance against software MPI over RDMA. The
results demonstrate ACCL+'s significant advantages for FPGA-based distributed
applications and highly competitive performance for CPU applications. We
showcase ACCL+'s dual role with two use cases: seamlessly integrating as a
collective offload engine to distribute CPU-based vector-matrix multiplication,
and serving as a crucial and efficient component in designing fully FPGA-based
distributed deep-learning recommendation inference.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11747" title="Abstract">arXiv:2312.11747</a> [<a href="/pdf/2312.11747" title="Download PDF">pdf</a>, <a href="/ps/2312.11747" title="Download PostScript">ps</a>, <a href="/format/2312.11747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Stochastic Graph Generator for Counterfactual Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prado-Romero%2C+M+A">Mario Alfonso Prado-Romero</a>, 
<a href="/search/cs?searchtype=author&query=Prenkaj%2C+B">Bardh Prenkaj</a>, 
<a href="/search/cs?searchtype=author&query=Stilo%2C+G">Giovanni Stilo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in AAAI'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Counterfactual Explanation (CE) techniques have garnered attention as a means
to provide insights to the users engaging with AI systems. While extensively
researched in domains such as medical imaging and autonomous vehicles, Graph
Counterfactual Explanation (GCE) methods have been comparatively
under-explored. GCEs generate a new graph similar to the original one, with a
different outcome grounded on the underlying predictive model. Among these GCE
techniques, those rooted in generative mechanisms have received relatively
limited investigation despite demonstrating impressive accomplishments in other
domains, such as artistic styles and natural language modelling. The preference
for generative explainers stems from their capacity to generate counterfactual
instances during inference, leveraging autonomously acquired perturbations of
the input graph. Motivated by the rationales above, our study introduces
RSGG-CE, a novel Robust Stochastic Graph Generator for Counterfactual
Explanations able to produce counterfactual examples from the learned latent
space considering a partially ordered generation sequence. Furthermore, we
undertake quantitative and qualitative analyses to compare RSGG-CE's
performance against SoA generative explainers, highlighting its increased
ability to engendering plausible counterfactual candidates.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11750" title="Abstract">arXiv:2312.11750</a> [<a href="/pdf/2312.11750" title="Download PDF">pdf</a>, <a href="/ps/2312.11750" title="Download PostScript">ps</a>, <a href="/format/2312.11750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Heterogeneous Chiplet Architecture for Accelerating End-to-End  Transformer Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+H">Harsh Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Dhingra%2C+P">Pratyush Dhingra</a>, 
<a href="/search/cs?searchtype=author&query=Doppa%2C+J+R">Janardhan Rao Doppa</a>, 
<a href="/search/cs?searchtype=author&query=Ogras%2C+U">Umit Ogras</a>, 
<a href="/search/cs?searchtype=author&query=Pande%2C+P+P">Partha Pratim Pande</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint for a Heterogeneous Chiplet Architecture for Accelerating End-to-End Transformer Models
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Transformers have revolutionized deep learning and generative modeling,
enabling unprecedented advancements in natural language processing tasks.
However, the size of transformer models is increasing continuously, driven by
enhanced capabilities across various deep-learning tasks. This trend of
ever-increasing model size has given rise to new challenges in terms of memory
and computing requirements. Conventional computing platforms, including GPUs,
suffer from suboptimal performance due to the memory demands imposed by models
with millions/billions of parameters. The emerging chiplet-based platforms
provide a new avenue for compute- and data-intensive machine learning (ML)
applications enabled by a Network-on-Interposer (NoI). However, designing
suitable hardware accelerators for executing Transformer inference workloads is
challenging due to a wide variety of complex computing kernels in the
Transformer architecture. In this paper, we leverage chiplet-based
heterogeneous integration (HI) to design a high-performance and
energy-efficient multi-chiplet platform to accelerate transformer workloads. We
demonstrate that the proposed NoI architecture caters to the data access
patterns inherent in a transformer model. The optimized placement of the
chiplets and the associated NoI links and routers enable superior performance
compared to the state-of-the-art hardware accelerators. The proposed NoI-based
architecture demonstrates scalability across varying transformer models and
improves latency and energy efficiency by up to 22.8x and 5.36x respectively.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11751" title="Abstract">arXiv:2312.11751</a> [<a href="/pdf/2312.11751" title="Download PDF">pdf</a>, <a href="/format/2312.11751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equilibrium Computation in Multi-Stage Auctions and Contests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pieroth%2C+F+R">Fabian R. Pieroth</a>, 
<a href="/search/cs?searchtype=author&query=Kohring%2C+N">Nils Kohring</a>, 
<a href="/search/cs?searchtype=author&query=Bichler%2C+M">Martin Bichler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages (main text), 42 pages (total)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We compute equilibrium strategies in multi-stage games with continuous signal
and action spaces as they are widely used in the management sciences and
economics. Examples include sequential sales via auctions, multi-stage
elimination contests, and Stackelberg competitions. In sequential auctions,
analysts are required to derive not just single bids but bid functions for all
possible signals or values that a bidder might have in multiple stages. Due to
the continuity of the signal and action spaces, these bid functions come from
an infinite dimensional space. While such models are fundamental to game theory
and its applications, equilibrium strategies are rarely known. The resulting
system of non-linear differential equations is considered intractable for all
but elementary models. This has been limiting progress in game theory and is a
barrier to its adoption in the field. We show that Deep Reinforcement Learning
and self-play can learn equilibrium bidding strategies for various multi-stage
games without making parametric assumptions on the bid function. We find
equilibrium in models that have not yet been explored analytically and new
asymmetric equilibrium bid functions for established models of sequential
auctions. The verification of equilibrium is challenging in such games due to
the continuous signal and action spaces. We introduce a verification algorithm
and prove that the error of this verifier decreases when considering Lipschitz
continuous strategies with increasing levels of discretization and sample
sizes.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11752" title="Abstract">arXiv:2312.11752</a> [<a href="/pdf/2312.11752" title="Download PDF">pdf</a>, <a href="/format/2312.11752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning a Diffusion Model Policy from Rewards via Q-Score Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Psenka%2C+M">Michael Psenka</a>, 
<a href="/search/cs?searchtype=author&query=Escontrela%2C+A">Alejandro Escontrela</a>, 
<a href="/search/cs?searchtype=author&query=Abbeel%2C+P">Pieter Abbeel</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yi Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Diffusion models have become a popular choice for representing actor policies
in behavior cloning and offline reinforcement learning. This is due to their
natural ability to optimize an expressive class of distributions over a
continuous space. However, previous works fail to exploit the score-based
structure of diffusion models, and instead utilize a simple behavior cloning
term to train the actor, limiting their ability in the actor-critic setting. In
this paper, we focus on off-policy reinforcement learning and propose a new
method for learning a diffusion model policy that exploits the linked structure
between the score of the policy and the action gradient of the Q-function. We
denote this method Q-score matching and provide theoretical justification for
this approach. We conduct experiments in simulated environments to demonstrate
the effectiveness of our proposed method and compare to popular baselines.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11753" title="Abstract">arXiv:2312.11753</a> [<a href="/pdf/2312.11753" title="Download PDF">pdf</a>, <a href="/ps/2312.11753" title="Download PostScript">ps</a>, <a href="/format/2312.11753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Poker Hand History File Format Specification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Juho Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This paper introduces the Poker Hand History (PHH) file format, designed to
standardize the recording of poker hands across different game variants.
Despite poker's widespread popularity in the mainstream culture as a mind sport
and its prominence in the field of artificial intelligence (AI) research as a
benchmark for imperfect information AI agents, it lacks a consistent format
that humans can use to document poker hands across different variants that can
also easily be parsed by machines. To address this gap in the literature, we
propose the PHH format which provides a concise human-readable machine-friendly
representation of hand history that comprehensively captures various details of
the hand, ranging from initial game parameters and actions to contextual
parameters including but not limited to the venue, players, and time control
information. In the supplementary, we provide over 10,000 hands covering 11
different variants in the PHH format. Building on our previous work on
PokerKit, a premier poker hand simulation tool, we demonstrate the usages of
our open-source Python implementation of the PHH parser. The source code of the
parser is available on GitHub: https://github.com/uoftcprg/pokerkit
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11754" title="Abstract">arXiv:2312.11754</a> [<a href="/pdf/2312.11754" title="Download PDF">pdf</a>, <a href="/format/2312.11754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Bayesian Spatial Model to Correct Under-Reporting in Urban  Crowdsourcing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agostini%2C+G">Gabriel Agostini</a>, 
<a href="/search/cs?searchtype=author&query=Pierson%2C+E">Emma Pierson</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+N">Nikhil Garg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the 38th Annual AAAI Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">Decision-makers often observe the occurrence of events through a reporting
process. City governments, for example, rely on resident reports to find and
then resolve urban infrastructural problems such as fallen street trees,
flooded basements, or rat infestations. Without additional assumptions, there
is no way to distinguish events that occur but are not reported from events
that truly did not occur--a fundamental problem in settings with
positive-unlabeled data. Because disparities in reporting rates correlate with
resident demographics, addressing incidents only on the basis of reports leads
to systematic neglect in neighborhoods that are less likely to report events.
We show how to overcome this challenge by leveraging the fact that events are
spatially correlated. Our framework uses a Bayesian spatial latent variable
model to infer event occurrence probabilities and applies it to storm-induced
flooding reports in New York City, further pooling results across multiple
storms. We show that a model accounting for under-reporting and spatial
correlation predicts future reports more accurately than other models, and
further induces a more equitable set of inspections: its allocations better
reflect the population and provide equitable service to non-white, less
traditionally educated, and lower-income residents. This finding reflects
heterogeneous reporting behavior learned by the model: reporting rates are
higher in Census tracts with higher populations, proportions of white
residents, and proportions of owner-occupied households. Our work lays the
groundwork for more equitable proactive government services, even with
disparate reporting behavior.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11761" title="Abstract">arXiv:2312.11761</a> [<a href="/pdf/2312.11761" title="Download PDF">pdf</a>, <a href="/format/2312.11761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MineObserver 2.0: A Deep Learning &amp; In-Game Framework for Assessing  Natural Language Descriptions of Minecraft Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahajan%2C+J">Jay Mahajan</a>, 
<a href="/search/cs?searchtype=author&query=Hum%2C+S">Samuel Hum</a>, 
<a href="/search/cs?searchtype=author&query=Henhapl%2C+J">Jack Henhapl</a>, 
<a href="/search/cs?searchtype=author&query=Yunus%2C+D">Diya Yunus</a>, 
<a href="/search/cs?searchtype=author&query=Gadbury%2C+M">Matthew Gadbury</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+E">Emi Brown</a>, 
<a href="/search/cs?searchtype=author&query=Ginger%2C+J">Jeff Ginger</a>, 
<a href="/search/cs?searchtype=author&query=Lane%2C+H+C">H. Chad Lane</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">MineObserver 2.0 is an AI framework that uses Computer Vision and Natural
Language Processing for assessing the accuracy of learner-generated
descriptions of Minecraft images that include some scientifically relevant
content. The system automatically assesses the accuracy of participant
observations, written in natural language, made during science learning
activities that take place in Minecraft. We demonstrate our system working in
real-time and describe a teacher support dashboard to showcase observations,
both of which advance our previous work. We present the results of a study
showing that MineObserver 2.0 improves over its predecessor both in perceived
accuracy of the system's generated descriptions as well as in usefulness of the
system's feedback. In future work we intend improve system-generated
descriptions, give teachers more control and upgrade the system to perform
continuous learning to more effectively and rapidly respond to novel
observations made by learners.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11763" title="Abstract">arXiv:2312.11763</a> [<a href="/pdf/2312.11763" title="Download PDF">pdf</a>, <a href="/format/2312.11763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ADMM-MM Algorithm for General Tensor Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mukai%2C+M">Manabu Mukai</a>, 
<a href="/search/cs?searchtype=author&query=Hontani%2C+H">Hidekata Hontani</a>, 
<a href="/search/cs?searchtype=author&query=Yokota%2C+T">Tatsuya Yokota</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Signal Processing (eess.SP); Machine Learning (stat.ML)

</div>
<p class="mathjax">In this paper, we propose a new unified optimization algorithm for general
tensor decomposition which is formulated as an inverse problem for low-rank
tensors in the general linear observation models. The proposed algorithm
supports three basic loss functions ($\ell_2$-loss, $\ell_1$-loss and KL
divergence) and various low-rank tensor decomposition models (CP, Tucker, TT,
and TR decompositions). We derive the optimization algorithm based on
hierarchical combination of the alternating direction method of multiplier
(ADMM) and majorization-minimization (MM). We show that wide-range applications
can be solved by the proposed algorithm, and can be easily extended to any
established tensor decomposition models in a {plug-and-play} manner.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11768" title="Abstract">arXiv:2312.11768</a> [<a href="/pdf/2312.11768" title="Download PDF">pdf</a>, <a href="/format/2312.11768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curriculum Learning for Cooperation in Multi-Agent Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhati%2C+R">Rupali Bhati</a>, 
<a href="/search/cs?searchtype=author&query=Gottipati%2C+S+K">Sai Krishna Gottipati</a>, 
<a href="/search/cs?searchtype=author&query=Mars%2C+C">Clod&#xe9;ric Mars</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+M+E">Matthew E. Taylor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures. Presented at Agent Learning in Open-Endedness Workshop at Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">While there has been significant progress in curriculum learning and
continuous learning for training agents to generalize across a wide variety of
environments in the context of single-agent reinforcement learning, it is
unclear if these algorithms would still be valid in a multi-agent setting. In a
competitive setting, a learning agent can be trained by making it compete with
a curriculum of increasingly skilled opponents. However, a general intelligent
agent should also be able to learn to act around other agents and cooperate
with them to achieve common goals. When cooperating with other agents, the
learning agent must (a) learn how to perform the task (or subtask), and (b)
increase the overall team reward. In this paper, we aim to answer the question
of what kind of cooperative teammate, and a curriculum of teammates should a
learning agent be trained with to achieve these two objectives. Our results on
the game Overcooked show that a pre-trained teammate who is less skilled is the
best teammate for overall team reward but the worst for the learning of the
agent. Moreover, somewhat surprisingly, a curriculum of teammates with
decreasing skill levels performs better than other types of curricula.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11769" title="Abstract">arXiv:2312.11769</a> [<a href="/pdf/2312.11769" title="Download PDF">pdf</a>, <a href="/format/2312.11769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clustering Mixtures of Bounded Covariance Distributions Under Optimal  Separation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diakonikolas%2C+I">Ilias Diakonikolas</a>, 
<a href="/search/cs?searchtype=author&query=Kane%2C+D+M">Daniel M. Kane</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+C+H">Jasper C. H. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Pittas%2C+T">Thanasis Pittas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Information Theory (cs.IT); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study the clustering problem for mixtures of bounded covariance
distributions, under a fine-grained separation assumption. Specifically, given
samples from a $k$-component mixture distribution $D = \sum_{i =1}^k w_i P_i$,
where each $w_i \ge \alpha$ for some known parameter $\alpha$, and each $P_i$
has unknown covariance $\Sigma_i \preceq \sigma^2_i \cdot I_d$ for some unknown
$\sigma_i$, the goal is to cluster the samples assuming a pairwise mean
separation in the order of $(\sigma_i+\sigma_j)/\sqrt{\alpha}$ between every
pair of components $P_i$ and $P_j$. Our contributions are as follows:
<br />For the special case of nearly uniform mixtures, we give the first poly-time
algorithm for this clustering task. Prior work either required separation
scaling with the maximum cluster standard deviation (i.e. $\max_i \sigma_i$)
[DKK+22b] or required both additional structural assumptions and mean
separation scaling as a large degree polynomial in $1/\alpha$ [BKK22].
<br />For general-weight mixtures, we point out that accurate clustering is
information-theoretically impossible under our fine-grained mean separation
assumptions. We introduce the notion of a clustering refinement -- a list of
not-too-small subsets satisfying a similar separation, and which can be merged
into a clustering approximating the ground truth -- and show that it is
possible to efficiently compute an accurate clustering refinement of the
samples. Furthermore, under a variant of the "no large sub-cluster'' condition
from in prior work [BKK22], we show that our algorithm outputs an accurate
clustering, not just a refinement, even for general-weight mixtures. As a
corollary, we obtain efficient clustering algorithms for mixtures of
well-conditioned high-dimensional log-concave distributions.
<br />Moreover, our algorithm is robust to $\Omega(\alpha)$-fraction of adversarial
outliers.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11770" title="Abstract">arXiv:2312.11770</a> [<a href="/pdf/2312.11770" title="Download PDF">pdf</a>, <a href="/ps/2312.11770" title="Download PostScript">ps</a>, <a href="/format/2312.11770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging the Gap: Generalising State-of-the-Art U-Net Models to  Sub-Saharan African Populations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amod%2C+A+R">Alyssa R. Amod</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+A">Alexandra Smith</a>, 
<a href="/search/cs?searchtype=author&query=Joubert%2C+P">Pearly Joubert</a>, 
<a href="/search/cs?searchtype=author&query=Raymond%2C+C">Confidence Raymond</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Anazodo%2C+U+C">Udunna C. Anazodo</a>, 
<a href="/search/cs?searchtype=author&query=Motchon%2C+D">Dodzi Motchon</a>, 
<a href="/search/cs?searchtype=author&query=Mutsvangwa%2C+T+E+M">Tinashe E.M. Mutsvangwa</a>, 
<a href="/search/cs?searchtype=author&query=Quetin%2C+S">S&#xe9;bastien Quetin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">A critical challenge for tumour segmentation models is the ability to adapt
to diverse clinical settings, particularly when applied to poor-quality
neuroimaging data. The uncertainty surrounding this adaptation stems from the
lack of representative datasets, leaving top-performing models without exposure
to common artifacts found in MRI data throughout Sub-Saharan Africa (SSA). We
replicated a framework that secured the 2nd position in the 2022 BraTS
competition to investigate the impact of dataset composition on model
performance and pursued four distinct approaches through training a model with:
1) BraTS-Africa data only (train_SSA, N=60), 2) BraTS-Adult Glioma data only
(train_GLI, N=1251), 3) both datasets together (train_ALL, N=1311), and 4)
through further training the train_GLI model with BraTS-Africa data
(train_ftSSA). Notably, training on a smaller low-quality dataset alone
(train_SSA) yielded subpar results, and training on a larger high-quality
dataset alone (train_GLI) struggled to delineate oedematous tissue in the
low-quality validation set. The most promising approach (train_ftSSA) involved
pre-training a model on high-quality neuroimages and then fine-tuning it on the
smaller, low-quality dataset. This approach outperformed the others, ranking
second in the MICCAI BraTS Africa global challenge external testing phase.
These findings underscore the significance of larger sample sizes and broad
exposure to data in improving segmentation performance. Furthermore, we
demonstrated that there is potential for improving such models by fine-tuning
them with a wider range of data locally.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11772" title="Abstract">arXiv:2312.11772</a> [<a href="/pdf/2312.11772" title="Download PDF">pdf</a>, <a href="/format/2312.11772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAManim: Animating end-to-end network activation maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaczmarek%2C+E">Emily Kaczmarek</a>, 
<a href="/search/cs?searchtype=author&query=Miguel%2C+O+X">Olivier X. Miguel</a>, 
<a href="/search/cs?searchtype=author&query=Bowie%2C+A+C">Alexa C. Bowie</a>, 
<a href="/search/cs?searchtype=author&query=Ducharme%2C+R">Robin Ducharme</a>, 
<a href="/search/cs?searchtype=author&query=Dingwall-Harvey%2C+A+L+J">Alysha L.J. Dingwall-Harvey</a>, 
<a href="/search/cs?searchtype=author&query=Hawken%2C+S">Steven Hawken</a>, 
<a href="/search/cs?searchtype=author&query=Armour%2C+C+M">Christine M. Armour</a>, 
<a href="/search/cs?searchtype=author&query=Walker%2C+M+C">Mark C. Walker</a>, 
<a href="/search/cs?searchtype=author&query=Dick%2C+K">Kevin Dick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep neural networks have been widely adopted in numerous domains due to
their high performance and accessibility to developers and application-specific
end-users. Fundamental to image-based applications is the development of
Convolutional Neural Networks (CNNs), which possess the ability to
automatically extract features from data. However, comprehending these complex
models and their learned representations, which typically comprise millions of
parameters and numerous layers, remains a challenge for both developers and
end-users. This challenge arises due to the absence of interpretable and
transparent tools to make sense of black-box models. There exists a growing
body of Explainable Artificial Intelligence (XAI) literature, including a
collection of methods denoted Class Activation Maps (CAMs), that seek to
demystify what representations the model learns from the data, how it informs a
given prediction, and why it, at times, performs poorly in certain tasks. We
propose a novel XAI visualization method denoted CAManim that seeks to
simultaneously broaden and focus end-user understanding of CNN predictions by
animating the CAM-based network activation maps through all layers, effectively
depicting from end-to-end how a model progressively arrives at the final layer
activation. Herein, we demonstrate that CAManim works with any CAM-based method
and various CNN architectures. Beyond qualitative model assessments, we
additionally propose a novel quantitative assessment that expands upon the
Remove and Debias (ROAD) metric, pairing the qualitative end-to-end network
visual explanations assessment with our novel quantitative "yellow brick ROAD"
assessment (ybROAD). This builds upon prior research to address the increasing
demand for interpretable, robust, and transparent model assessment methodology,
ultimately improving an end-user's trust in a given model's predictions.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11774" title="Abstract">arXiv:2312.11774</a> [<a href="/pdf/2312.11774" title="Download PDF">pdf</a>, <a href="/format/2312.11774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text-Image Conditioned Diffusion for Consistent Text-to-3D Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuze He</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yushi Bai</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Matthieu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+J">Jenny Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yubin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yu-Hui Wen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong-Jin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">By lifting the pre-trained 2D diffusion models into Neural Radiance Fields
(NeRFs), text-to-3D generation methods have made great progress. Many
state-of-the-art approaches usually apply score distillation sampling (SDS) to
optimize the NeRF representations, which supervises the NeRF optimization with
pre-trained text-conditioned 2D diffusion models such as Imagen. However, the
supervision signal provided by such pre-trained diffusion models only depends
on text prompts and does not constrain the multi-view consistency. To inject
the cross-view consistency into diffusion priors, some recent works finetune
the 2D diffusion model with multi-view data, but still lack fine-grained view
coherence. To tackle this challenge, we incorporate multi-view image conditions
into the supervision signal of NeRF optimization, which explicitly enforces
fine-grained view consistency. With such stronger supervision, our proposed
text-to-3D method effectively mitigates the generation of floaters (due to
excessive densities) and completely empty spaces (due to insufficient
densities). Our quantitative evaluations on the T$^3$Bench dataset demonstrate
that our method achieves state-of-the-art performance over existing text-to-3D
methods. We will make the code publicly available.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11779" title="Abstract">arXiv:2312.11779</a> [<a href="/pdf/2312.11779" title="Download PDF">pdf</a>, <a href="/format/2312.11779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are you talking to [&#x27;xem&#x27;] or [&#x27;x&#x27;, &#x27;em&#x27;]? On Tokenization and  Addressing Misgendering in LLMs with Pronoun Tokenization Parity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ovalle%2C+A">Anaelia Ovalle</a>, 
<a href="/search/cs?searchtype=author&query=Mehrabi%2C+N">Ninareh Mehrabi</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+P">Palash Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Dhamala%2C+J">Jwala Dhamala</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kai-Wei Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zemel%2C+R">Richard Zemel</a>, 
<a href="/search/cs?searchtype=author&query=Galstyan%2C+A">Aram Galstyan</a>, 
<a href="/search/cs?searchtype=author&query=Pinter%2C+Y">Yuval Pinter</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+R">Rahul Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to 2023 Neurips Queer in AI workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">A large body of NLP research has documented the ways gender biases manifest
and amplify within large language models (LLMs), though this research has
predominantly operated within a gender binary-centric context. A growing body
of work has identified the harmful limitations of this gender-exclusive
framing; many LLMs cannot correctly and consistently refer to persons outside
the gender binary, especially if they use neopronouns. While data scarcity has
been identified as a possible culprit, the precise mechanisms through which it
influences LLM misgendering remain underexplored. Our work addresses this gap
by studying data scarcity's role in subword tokenization and, consequently, the
formation of LLM word representations. We uncover how the Byte-Pair Encoding
(BPE) tokenizer, a backbone for many popular LLMs, contributes to neopronoun
misgendering through out-of-vocabulary behavior. We introduce pronoun
tokenization parity (PTP), a novel approach to reduce LLM neopronoun
misgendering by preserving a token's functional structure. We evaluate PTP's
efficacy using pronoun consistency-based metrics and a novel syntax-based
metric. Through several controlled experiments, finetuning LLMs with PTP
improves neopronoun consistency from 14.5% to 58.4%, highlighting the
significant role tokenization plays in LLM pronoun consistency.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11781" title="Abstract">arXiv:2312.11781</a> [<a href="/pdf/2312.11781" title="Download PDF">pdf</a>, <a href="/format/2312.11781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can IKEA effect promote empathy for agents?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsumura%2C+T">Takahiro Tsumura</a>, 
<a href="/search/cs?searchtype=author&query=Yamada%2C+S">Seiji Yamada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 9 figures, 4 tables, submitted Computers in Human Behavior
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Cooperative relationships between humans and agents are becoming more
important for the social coexistence of anthropomorphic agents, including
virtual agents and robots. One way to improve the relationship between humans
and agents is for humans to empathize with the agents. Empathy can help humans
become more accepting of agents. In this study, we focus on the IKEA effect in
creating agents and investigate human empathy toward agents through
relationships with others in the same space. For this reason, this study used a
robot assembly task in which two participants cooperatively build the same
robot or individually their own robot. We conducted experiments to examine the
relationship between participants, the IKEA effect in creating an agent, and
the influence of the empathy object on human empathy. The results showed that
the IKEA effect promoted empathy toward the agent regardless of the
relationship between participants. On the other hand, there was no significant
difference in empathy from one participant to another before and after the
task. These results indicate that regardless of the relationship between
participants in the same space, the creation of an agent can promote empathy
toward the agent.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11782" title="Abstract">arXiv:2312.11782</a> [<a href="/pdf/2312.11782" title="Download PDF">pdf</a>, <a href="/format/2312.11782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Object State Changes in Videos: An Open-World Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+Z">Zihui Xue</a>, 
<a href="/search/cs?searchtype=author&query=Ashutosh%2C+K">Kumar Ashutosh</a>, 
<a href="/search/cs?searchtype=author&query=Grauman%2C+K">Kristen Grauman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="https://vision.cs.utexas.edu/projects/VidOSC/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Object State Changes (OSCs) are pivotal for video understanding. While humans
can effortlessly generalize OSC understanding from familiar to unknown objects,
current approaches are confined to a closed vocabulary. Addressing this gap, we
introduce a novel open-world formulation for the video OSC problem. The goal is
to temporally localize the three stages of an OSC -- the object's initial
state, its transitioning state, and its end state -- whether or not the object
has been observed during training. Towards this end, we develop VidOSC, a
holistic learning approach that: (1) leverages text and vision-language models
for supervisory signals to obviate manually labeling OSC training data, and (2)
abstracts fine-grained shared state representations from objects to enhance
generalization. Furthermore, we present HowToChange, the first open-world
benchmark for video OSC localization, which offers an order of magnitude
increase in the label space and annotation volume compared to the best existing
benchmark. Experimental results demonstrate the efficacy of our approach, in
both traditional closed-world and open-world scenarios.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11785" title="Abstract">arXiv:2312.11785</a> [<a href="/pdf/2312.11785" title="Download PDF">pdf</a>, <a href="/format/2312.11785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Fact-Checking with Semantic Triples and Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhangdie Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Vlachos%2C+A">Andreas Vlachos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Despite progress in automated fact-checking, most systems require a
significant amount of labeled training data, which is expensive. In this paper,
we propose a novel zero-shot method, which instead of operating directly on the
claim and evidence sentences, decomposes them into semantic triples augmented
using external knowledge graphs, and uses large language models trained for
natural language inference. This allows it to generalize to adversarial
datasets and domains that supervised models require specific training data for.
Our empirical results show that our approach outperforms previous zero-shot
approaches on FEVER, FEVER-Symmetric, FEVER 2.0, and Climate-FEVER, while being
comparable or better than supervised models on the adversarial and the
out-of-domain datasets.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11788" title="Abstract">arXiv:2312.11788</a> [<a href="/pdf/2312.11788" title="Download PDF">pdf</a>, <a href="/format/2312.11788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Convergence with Multiway Preferences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saha%2C+A">Aadirupa Saha</a>, 
<a href="/search/cs?searchtype=author&query=Feldman%2C+V">Vitaly Feldman</a>, 
<a href="/search/cs?searchtype=author&query=Koren%2C+T">Tomer Koren</a>, 
<a href="/search/cs?searchtype=author&query=Mansour%2C+Y">Yishay Mansour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We address the problem of convex optimization with preference feedback, where
the goal is to minimize a convex function given a weaker form of comparison
queries. Each query consists of two points and the dueling feedback returns a
(noisy) single-bit binary comparison of the function values of the two queried
points. Here we consider the sign-function-based comparison feedback model and
analyze the convergence rates with batched and multiway (argmin of a set
queried points) comparisons. Our main goal is to understand the improved
convergence rates owing to parallelization in sign-feedback-based optimization
problems. Our work is the first to study the problem of convex optimization
with multiway preferences and analyze the optimal convergence rates. Our first
contribution lies in designing efficient algorithms with a convergence rate of
$\smash{\widetilde O}(\frac{d}{\min\{m,d\} \epsilon})$ for $m$-batched
preference feedback where the learner can query $m$-pairs in parallel. We next
study a $m$-multiway comparison (`battling') feedback, where the learner can
get to see the argmin feedback of $m$-subset of queried points and show a
convergence rate of $\smash{\widetilde O}(\frac{d}{ \min\{\log m,d\}\epsilon
})$. We show further improved convergence rates with an additional assumption
of strong convexity. Finally, we also study the convergence lower bounds for
batched preferences and multiway feedback optimization showing the optimality
of our convergence rates w.r.t. $m$.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11790" title="Abstract">arXiv:2312.11790</a> [<a href="/pdf/2312.11790" title="Download PDF">pdf</a>, <a href="/ps/2312.11790" title="Download PostScript">ps</a>, <a href="/format/2312.11790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improvement of inter-protocol fairness for BBR congestion control using  machine learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mhaske%2C+V">Vaishnavi Mhaske</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+K">Khushi Jain</a>, 
<a href="/search/cs?searchtype=author&query=Thatikonda%2C+S+K">Sai Karthik Thatikonda</a>, 
<a href="/search/cs?searchtype=author&query=Kunwar%2C+A">Asif Kunwar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Google's BBR (Bottleneck Bandwidth and Round-trip Propagation Time) approach
is used to enhance internet network transmission. It is particularly intended
to efficiently handle enormous amounts of data. Traditional TCP (Transmission
Control Protocol) algorithms confront the most difficulty in calculating the
proper quantity of data to send in order to prevent congestion and bottlenecks.
This wastes bandwidth and causes network delays. BBR addresses this issue by
adaptively assessing the available bandwidth (also known as bottleneck
bandwidth) along the network channel and calculating the round-trip time (RTT)
between the sender and receiver. Although when several flows compete for
bandwidth, BBR may supply more bandwidth to one flow at the expense of another,
resulting in unequal resource distribution. This paper proposes to integrate
machine learning with BBR to enhance fairness in resource allocation. This
novel strategy can improve bandwidth allocation and provide a more equal
distribution of resources among competing flows by using historical BBR data to
train an ML model. Further we also implemented a classifier model that is
graphic neural network in the congestion control method.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11791" title="Abstract">arXiv:2312.11791</a> [<a href="/pdf/2312.11791" title="Download PDF">pdf</a>, <a href="/format/2312.11791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Double Oracle Algorithm for Game-Theoretic Robot Allocation on Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+Z">Zijian An</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Lifeng Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We study the problem of game-theoretic robot allocation where two players
strategically allocate robots to compete for multiple sites of interest. Robots
possess offensive or defensive capabilities to interfere and weaken their
opponents to take over a competing site. This problem belongs to the
conventional Colonel Blotto Game. Considering the robots' heterogeneous
capabilities and environmental factors, we generalize the conventional Blotto
game by incorporating heterogeneous robot types and graph constraints that
capture the robot transitions between sites. Then we employ the Double Oracle
Algorithm (DOA) to solve for the Nash equilibrium of the generalized Blotto
game. Particularly, for cyclic-dominance-heterogeneous (CDH) robots that
inhibit each other, we define a new transformation rule between any two robot
types. Building on the transformation, we design a novel utility function to
measure the game's outcome quantitatively. Moreover, we rigorously prove the
correctness of the designed utility function. Finally, we conduct extensive
simulations to demonstrate the effectiveness of DOA on computing Nash
equilibrium for homogeneous, linear heterogeneous, and CDH robot allocation on
graphs.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11792" title="Abstract">arXiv:2312.11792</a> [<a href="/pdf/2312.11792" title="Download PDF">pdf</a>, <a href="/format/2312.11792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COOPER: Coordinating Specialized Agents towards a Complex Dialogue Goal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenge Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Leong%2C+C+T">Chak Tou Leong</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+Y">Yi Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yefeng Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In recent years, there has been a growing interest in exploring dialogues
with more complex goals, such as negotiation, persuasion, and emotional
support, which go beyond traditional service-focused dialogue systems. Apart
from the requirement for much more sophisticated strategic reasoning and
communication skills, a significant challenge of these tasks lies in the
difficulty of objectively measuring the achievement of their goals in a
quantifiable way, making it difficult for existing research to directly
optimize the dialogue procedure towards them. In our work, we emphasize the
multifaceted nature of complex dialogue goals and argue that it is more
feasible to accomplish them by comprehensively considering and jointly
promoting their different aspects. To this end, we propose a novel dialogue
framework, Cooper, which coordinates multiple specialized agents, each
dedicated to a specific dialogue goal aspect separately, to approach the
complex objective. Through this divide-and-conquer manner, we make complex
dialogue goals more approachable and elicit greater intelligence via the
collaboration of individual agents. Experiments on persuasion and emotional
support dialogues demonstrate the superiority of our method over a set of
competitive baselines.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11793" title="Abstract">arXiv:2312.11793</a> [<a href="/pdf/2312.11793" title="Download PDF">pdf</a>, <a href="/format/2312.11793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An effective image copy-move forgery detection using entropy image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhaowei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Li Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computers and Society (cs.CY); Multimedia (cs.MM)

</div>
<p class="mathjax">Image forensics has become increasingly important in our daily lives. As a
fundamental type of forgeries, Copy-Move Forgery Detection (CMFD) has received
significant attention in the academic community. Keypoint-based algorithms,
particularly those based on SIFT, have achieved good results in CMFD. However,
the most of keypoint detection algorithms often fail to generate sufficient
matches when tampered patches are present in smooth areas. To tackle this
problem, we introduce entropy images to determine the coordinates and scales of
keypoints, resulting significantly increasing the number of keypoints.
Furthermore, we develop an entropy level clustering algorithm to avoid
increased matching complexity caused by non-ideal distribution of grayscale
values in keypoints. Experimental results demonstrate that our algorithm
achieves a good balance between performance and time efficiency.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11795" title="Abstract">arXiv:2312.11795</a> [<a href="/pdf/2312.11795" title="Download PDF">pdf</a>, <a href="/format/2312.11795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MELO: Enhancing Model Editing with Neuron-Indexed Dynamic LoRA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Liang He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of The 38th Annual AAAI Conference on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have shown great success in various Natural
Language Processing (NLP) tasks, whist they still need updates after deployment
to fix errors or keep pace with the changing knowledge in the world.
Researchers formulate such problem as Model Editing and have developed various
editors focusing on different axes of editing properties. However, current
editors can hardly support all properties and rely on heavy computational
resources. In this paper, we propose a plug-in Model Editing method based on
neuron-indexed dynamic LoRA (MELO), which alters the behavior of language
models by dynamically activating certain LoRA blocks according to the index
built in an inner vector database. Our method satisfies various editing
properties with high efficiency and can be easily integrated into multiple LLM
backbones. Experimental results show that our proposed MELO achieves
state-of-the-art editing performance on three sequential editing tasks
(document classification, question answering and hallucination correction),
while requires the least trainable parameters and computational cost.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11796" title="Abstract">arXiv:2312.11796</a> [<a href="/pdf/2312.11796" title="Download PDF">pdf</a>, <a href="/format/2312.11796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QuanShield: Protecting against Side-Channels Attacks using  Self-Destructing Enclaves
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shujie Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haohua Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Vilanova%2C+L">Llu&#xed;s Vilanova</a>, 
<a href="/search/cs?searchtype=author&query=Pietzuch%2C+P">Peter Pietzuch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15pages, 5 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Trusted Execution Environments (TEEs) allow user processes to create enclaves
that protect security-sensitive computation against access from the OS kernel
and the hypervisor. Recent work has shown that TEEs are vulnerable to
side-channel attacks that allow an adversary to learn secrets shielded in
enclaves. The majority of such attacks trigger exceptions or interrupts to
trace the control or data flow of enclave execution.
<br />We propose QuanShield, a system that protects enclaves from side-channel
attacks that interrupt enclave execution. The main idea behind QuanShield is to
strengthen resource isolation by creating an interrupt-free environment on a
dedicated CPU core for running enclaves in which enclaves terminate when
interrupts occur. QuanShield avoids interrupts by exploiting the tickless
scheduling mode supported by recent OS kernels. QuanShield then uses the save
area (SA) of the enclave, which is used by the hardware to support interrupt
handling, as a second stack. Through an LLVM-based compiler pass, QuanShield
modifies enclave instructions to store/load memory references, such as function
frame base addresses, to/from the SA. When an interrupt occurs, the hardware
overwrites the data in the SA with CPU state, thus ensuring that enclave
execution fails. Our evaluation shows that QuanShield significantly raises the
bar for interrupt-based attacks with practical overhead.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11800" title="Abstract">arXiv:2312.11800</a> [<a href="/pdf/2312.11800" title="Download PDF">pdf</a>, <a href="/format/2312.11800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Excludable Bilateral Trade Between Groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y+E">Yixuan Even Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Conitzer%2C+V">Vincent Conitzer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 2 figures, 1 table, aaai 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Bilateral trade is one of the most natural and important forms of economic
interaction: A seller has a single, indivisible item for sale, and a buyer is
potentially interested. The two parties typically have different, privately
known valuations for the item, and ideally, they would like to trade if the
buyer values the item more than the seller. The celebrated impossibility result
by Myerson and Satterthwaite shows that any mechanism for this setting must
violate at least one important desideratum. In this paper, we investigate a
richer paradigm of bilateral trade, with many self-interested buyers and
sellers on both sides of a single trade who cannot be excluded from the trade.
We show that this allows for more positive results. In fact, we establish a
dichotomy in the possibility of trading efficiently. If in expectation, the
buyers value the item more, we can achieve efficiency in the limit. If this is
not the case, then efficiency cannot be achieved in general. En route, we
characterize trading mechanisms that encourage truth-telling, which may be of
independent interest. We also evaluate our trading mechanisms experimentally,
and the experiments align with our theoretical results.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11802" title="Abstract">arXiv:2312.11802</a> [<a href="/pdf/2312.11802" title="Download PDF">pdf</a>, <a href="/ps/2312.11802" title="Download PostScript">ps</a>, <a href="/format/2312.11802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IKT-BT: Indirect Knowledge Transfer Behavior Tree Framework for  Multi-Robot Systems Through Communication Eavesdropping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oruganti%2C+S">Sanjay Oruganti</a>, 
<a href="/search/cs?searchtype=author&query=Parasuraman%2C+R">Ramviyas Parasuraman</a>, 
<a href="/search/cs?searchtype=author&query=Pidaparti%2C+R">Ramana Pidaparti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Multi-agent and multi-robot systems (MRS) often rely on direct communication
for information sharing. This work explores an alternative approach inspired by
eavesdropping mechanisms in nature that involves casual observation of agent
interactions to enhance decentralized knowledge dissemination. We achieve this
through a novel IKT-BT framework tailored for a behavior-based MRS,
encapsulating knowledge and control actions in Behavior Trees (BT). We present
two new BT-based modalities - eavesdrop-update (EU) and eavesdrop-buffer-update
(EBU) - incorporating unique eavesdropping strategies and efficient episodic
memory management suited for resource-limited swarm robots. We theoretically
analyze the IKT-BT framework for an MRS and validate the performance of the
proposed modalities through extensive experiments simulating a search and
rescue mission. Our results reveal improvements in both global mission
performance outcomes and agent-level knowledge dissemination with a reduced
need for direct communication.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11803" title="Abstract">arXiv:2312.11803</a> [<a href="/pdf/2312.11803" title="Download PDF">pdf</a>, <a href="/format/2312.11803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing Guiding Principles for NLP for Healthcare: A Case Study of  Maternal Health
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Antoniak%2C+M">Maria Antoniak</a>, 
<a href="/search/cs?searchtype=author&query=Naik%2C+A">Aakanksha Naik</a>, 
<a href="/search/cs?searchtype=author&query=Alvarado%2C+C+S">Carla S. Alvarado</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L+L">Lucy Lu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+I+Y">Irene Y. Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Objective: An ethical framework for the use of large language models (LLMs)
is urgently needed to shape how natural language processing (NLP) tools are
used for healthcare applications. Drawing directly from the voices of those
most affected, we propose a set of guiding principles for the use of NLP in
healthcare, with examples based on applications in maternal health.
<br />Materials and Methods: We led an interactive session centered on an LLM-based
chatbot demonstration during a full-day workshop with 39 participants, and
additionally surveyed 30 healthcare workers and 30 birthing people about their
values, needs, and perceptions of AI and LLMs. We conducted quantitative and
qualitative analyses of the interactive discussions to consolidate our findings
into a set of guiding principles.
<br />Results: Using the case study of maternal health, we propose nine principles
for ethical use of LLMs, grouped into three categories: (i) contextual
significance, (ii) measurements, and (iii) who/what is valued. We describe
rationales underlying these principles and provide practical advice.
<br />Discussion: Healthcare faces existing challenges including the balance of
power in clinician-patient relationships, systemic health disparities,
historical injustices, and economic constraints. Our principles serve as a
framework for surfacing key considerations when deploying LLMs in medicine, as
well as providing a methodological pattern for other researchers to follow.
<br />Conclusion: This set of principles can serve as a resource to practitioners
working on maternal health and other healthcare fields to emphasize the
importance of technical nuance, historical context, and inclusive design when
developing LLMs for use in clinical settings.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11804" title="Abstract">arXiv:2312.11804</a> [<a href="/pdf/2312.11804" title="Download PDF">pdf</a>, <a href="/format/2312.11804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gravity-aware Grasp Generation with Implicit Grasp Mode Selection for  Underactuated Hands
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ko%2C+T">Tianyi Ko</a>, 
<a href="/search/cs?searchtype=author&query=Ikeda%2C+T">Takuya Ikeda</a>, 
<a href="/search/cs?searchtype=author&query=Stewart%2C+T">Thomas Stewart</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+R">Robert Lee</a>, 
<a href="/search/cs?searchtype=author&query=Nishiwaki%2C+K">Koichi Nishiwaki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">To overcome the mechanical limitation of parallel-jaw grippers, in this
paper, we present a gravity-aware grasp generation that supports both precision
grasp and power grasp of underactuated hands. We propose a novel approach to
generate a large-scale dataset with a gravity-rejection score and
experimentally confirm that the combination of that score and classical
success/fail binary classification is powerful: the former encourages stable
grasps, such as power grasps or grasping the center of mass, while the latter
rejects invalid grasps, such as colliding with other objects or attempting to
grasp parts that are too large for the gripper. We also propose a rotation
representation that is continuous on SO(3) and considers the grasp's physical
meaning. Our simulation and real robot evaluation experiments demonstrate
significant improvements from the baseline works, especially for heavy objects.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11805" title="Abstract">arXiv:2312.11805</a> [<a href="/pdf/2312.11805" title="Download PDF">pdf</a>, <a href="/format/2312.11805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gemini: A Family of Highly Capable Multimodal Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gemini+Team">Gemini Team Google</a>: 
<a href="/search/cs?searchtype=author&query=Anil%2C+R">Rohan Anil</a>, 
<a href="/search/cs?searchtype=author&query=Borgeaud%2C+S">Sebastian Borgeaud</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yonghui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Alayrac%2C+J">Jean-Baptiste Alayrac</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiahui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Soricut%2C+R">Radu Soricut</a>, 
<a href="/search/cs?searchtype=author&query=Schalkwyk%2C+J">Johan Schalkwyk</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+A+M">Andrew M. Dai</a>, 
<a href="/search/cs?searchtype=author&query=Hauth%2C+A">Anja Hauth</a>, 
<a href="/search/cs?searchtype=author&query=Millican%2C+K">Katie Millican</a>, 
<a href="/search/cs?searchtype=author&query=Silver%2C+D">David Silver</a>, 
<a href="/search/cs?searchtype=author&query=Petrov%2C+S">Slav Petrov</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+M">Melvin Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Antonoglou%2C+I">Ioannis Antonoglou</a>, 
<a href="/search/cs?searchtype=author&query=Schrittwieser%2C+J">Julian Schrittwieser</a>, 
<a href="/search/cs?searchtype=author&query=Glaese%2C+A">Amelia Glaese</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jilin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pitler%2C+E">Emily Pitler</a>, 
<a href="/search/cs?searchtype=author&query=Lillicrap%2C+T">Timothy Lillicrap</a>, 
<a href="/search/cs?searchtype=author&query=Lazaridou%2C+A">Angeliki Lazaridou</a>, 
<a href="/search/cs?searchtype=author&query=Firat%2C+O">Orhan Firat</a>, 
<a href="/search/cs?searchtype=author&query=Molloy%2C+J">James Molloy</a>, 
<a href="/search/cs?searchtype=author&query=Isard%2C+M">Michael Isard</a>, 
<a href="/search/cs?searchtype=author&query=Barham%2C+P+R">Paul R. Barham</a>, 
<a href="/search/cs?searchtype=author&query=Hennigan%2C+T">Tom Hennigan</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B">Benjamin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Viola%2C+F">Fabio Viola</a>, 
<a href="/search/cs?searchtype=author&query=Reynolds%2C+M">Malcolm Reynolds</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuanzhong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Doherty%2C+R">Ryan Doherty</a>, 
<a href="/search/cs?searchtype=author&query=Collins%2C+E">Eli Collins</a>, 
<a href="/search/cs?searchtype=author&query=Meyer%2C+C">Clemens Meyer</a>, 
<a href="/search/cs?searchtype=author&query=Rutherford%2C+E">Eliza Rutherford</a>, 
<a href="/search/cs?searchtype=author&query=Moreira%2C+E">Erica Moreira</a>, 
<a href="/search/cs?searchtype=author&query=Ayoub%2C+K">Kareem Ayoub</a>, 
<a href="/search/cs?searchtype=author&query=Goel%2C+M">Megha Goel</a>, 
<a href="/search/cs?searchtype=author&query=Tucker%2C+G">George Tucker</a>, 
<a href="/search/cs?searchtype=author&query=Piqueras%2C+E">Enrique Piqueras</a>, 
<a href="/search/cs?searchtype=author&query=Krikun%2C+M">Maxim Krikun</a>, 
<a href="/search/cs?searchtype=author&query=Barr%2C+I">Iain Barr</a>, 
<a href="/search/cs?searchtype=author&query=Savinov%2C+N">Nikolay Savinov</a>, 
<a href="/search/cs?searchtype=author&query=Danihelka%2C+I">Ivo Danihelka</a>, 
<a href="/search/cs?searchtype=author&query=Roelofs%2C+B">Becca Roelofs</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+A">Ana&#xef;s White</a>, 
<a href="/search/cs?searchtype=author&query=Andreassen%2C+A">Anders Andreassen</a>, 
<a href="/search/cs?searchtype=author&query=von+Glehn%2C+T">Tamara von Glehn</a>, 
<a href="/search/cs?searchtype=author&query=Yagati%2C+L">Lakshman Yagati</a>, 
<a href="/search/cs?searchtype=author&query=Kazemi%2C+M">Mehran Kazemi</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+L">Lucas Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Khalman%2C+M">Misha Khalman</a>, 
<a href="/search/cs?searchtype=author&query=Sygnowski%2C+J">Jakub Sygnowski</a>,  et al. (890 additional authors not shown)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This report introduces a new family of multimodal models, Gemini, that
exhibit remarkable capabilities across image, audio, video, and text
understanding. The Gemini family consists of Ultra, Pro, and Nano sizes,
suitable for applications ranging from complex reasoning tasks to on-device
memory-constrained use-cases. Evaluation on a broad range of benchmarks shows
that our most-capable Gemini Ultra model advances the state of the art in 30 of
32 of these benchmarks - notably being the first model to achieve human-expert
performance on the well-studied exam benchmark MMLU, and improving the state of
the art in every one of the 20 multimodal benchmarks we examined. We believe
that the new capabilities of Gemini models in cross-modal reasoning and
language understanding will enable a wide variety of use cases and we discuss
our approach toward deploying them responsibly to users.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11812" title="Abstract">arXiv:2312.11812</a> [<a href="/pdf/2312.11812" title="Download PDF">pdf</a>, <a href="/format/2312.11812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancements and Challenges in Arabic Optical Character Recognition: A  Comprehensive Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kasem%2C+M+S">Mahmoud SalahEldin Kasem</a>, 
<a href="/search/cs?searchtype=author&query=Mahmoud%2C+M">Mohamed Mahmoud</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+H">Hyun-Soo Kang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Optical character recognition (OCR) is a vital process that involves the
extraction of handwritten or printed text from scanned or printed images,
converting it into a format that can be understood and processed by machines.
This enables further data processing activities such as searching and editing.
The automatic extraction of text through OCR plays a crucial role in digitizing
documents, enhancing productivity, improving accessibility, and preserving
historical records. This paper seeks to offer an exhaustive review of
contemporary applications, methodologies, and challenges associated with Arabic
Optical Character Recognition (OCR). A thorough analysis is conducted on
prevailing techniques utilized throughout the OCR process, with a dedicated
effort to discern the most efficacious approaches that demonstrate enhanced
outcomes. To ensure a thorough evaluation, a meticulous keyword-search
methodology is adopted, encompassing a comprehensive analysis of articles
relevant to Arabic OCR, including both backward and forward citation reviews.
In addition to presenting cutting-edge techniques and methods, this paper
critically identifies research gaps within the realm of Arabic OCR. By
highlighting these gaps, we shed light on potential areas for future
exploration and development, thereby guiding researchers toward promising
avenues in the field of Arabic OCR. The outcomes of this study provide valuable
insights for researchers, practitioners, and stakeholders involved in Arabic
OCR, ultimately fostering advancements in the field and facilitating the
creation of more accurate and efficient OCR systems for the Arabic language.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11813" title="Abstract">arXiv:2312.11813</a> [<a href="/pdf/2312.11813" title="Download PDF">pdf</a>, <a href="/format/2312.11813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Urban Generative Intelligence (UGI): A Foundational Platform for Agents  in Embodied City Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Fengli Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chen Gao</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jie Feng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Urban environments, characterized by their complex, multi-layered networks
encompassing physical, social, economic, and environmental dimensions, face
significant challenges in the face of rapid urbanization. These challenges,
ranging from traffic congestion and pollution to social inequality, call for
advanced technological interventions. Recent developments in big data,
artificial intelligence, urban computing, and digital twins have laid the
groundwork for sophisticated city modeling and simulation. However, a gap
persists between these technological capabilities and their practical
implementation in addressing urban challenges in an systemic-intelligent way.
This paper proposes Urban Generative Intelligence (UGI), a novel foundational
platform integrating Large Language Models (LLMs) into urban systems to foster
a new paradigm of urban intelligence. UGI leverages CityGPT, a foundation model
trained on city-specific multi-source data, to create embodied agents for
various urban tasks. These agents, operating within a textual urban environment
emulated by city simulator and urban knowledge graph, interact through a
natural language interface, offering an open platform for diverse intelligent
and embodied agent development. This platform not only addresses specific urban
issues but also simulates complex urban systems, providing a multidisciplinary
approach to understand and manage urban complexity. This work signifies a
transformative step in city science and urban intelligence, harnessing the
power of LLMs to unravel and address the intricate dynamics of urban systems.
The code repository with demonstrations will soon be released here
https://github.com/tsinghua-fib-lab/UGI.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11816" title="Abstract">arXiv:2312.11816</a> [<a href="/pdf/2312.11816" title="Download PDF">pdf</a>, <a href="/format/2312.11816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Dual-way Enhanced Framework from Text Matching Point of View for  Multimodal Entity Linking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shezheng Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+T">Tianwei Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shasha Li</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+X">Xiaoguang Mao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Meng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Multimodal Entity Linking (MEL) aims at linking ambiguous mentions with
multimodal information to entity in Knowledge Graph (KG) such as Wikipedia,
which plays a key role in many applications. However, existing methods suffer
from shortcomings, including modality impurity such as noise in raw image and
ambiguous textual entity representation, which puts obstacles to MEL. We
formulate multimodal entity linking as a neural text matching problem where
each multimodal information (text and image) is treated as a query, and the
model learns the mapping from each query to the relevant entity from candidate
entities. This paper introduces a dual-way enhanced (DWE) framework for MEL:
(1) our model refines queries with multimodal data and addresses semantic gaps
using cross-modal enhancers between text and image information. Besides, DWE
innovatively leverages fine-grained image attributes, including facial
characteristic and scene feature, to enhance and refine visual features. (2)By
using Wikipedia descriptions, DWE enriches entity semantics and obtains more
comprehensive textual representation, which reduces between textual
representation and the entities in KG. Extensive experiments on three public
benchmarks demonstrate that our method achieves state-of-the-art (SOTA)
performance, indicating the superiority of our model. The code is released on
https://github.com/season1blue/DWE
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11817" title="Abstract">arXiv:2312.11817</a> [<a href="/pdf/2312.11817" title="Download PDF">pdf</a>, <a href="/ps/2312.11817" title="Download PostScript">ps</a>, <a href="/format/2312.11817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Users Approach on Providing Feedback for Smart Home Devices Phase I
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pogaku%2C+S">Santhosh Pogaku</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Smart home technology is part of our everyday lives, and this technology is
fast-evolving compared to other technologies. The user's feedback is gathered
in this paper by conducting expert interviews on how collecting the feedback
from the smart home devices will be helpful to improve the devices. We are yet
to know about the feedback system of the smart home devices and how provided
feedback will support increasing the devices' requirements. Today, we present
our analysis from our exploratory interview method with the student of a
certain group, and we try to study the attitude of providing feedback. The
results suggested that the users are ready to give their feedback very actively
to better their usage as every user has their own needs to fulfill.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11818" title="Abstract">arXiv:2312.11818</a> [<a href="/pdf/2312.11818" title="Download PDF">pdf</a>, <a href="/format/2312.11818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Root Cause Explanation of Outliers under Noisy Mechanisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+P">Phuoc Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+T">Truyen Tran</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Sunil Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thin Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Venkatesh%2C+S">Svetha Venkatesh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Identifying root causes of anomalies in causal processes is vital across
disciplines. Once identified, one can isolate the root causes and implement
necessary measures to restore the normal operation. Causal processes are often
modelled as graphs with entities being nodes and their paths/interconnections
as edge. Existing work only consider the contribution of nodes in the
generative process, thus can not attribute the outlier score to the edges of
the mechanism if the anomaly occurs in the connections. In this paper, we
consider both individual edge and node of each mechanism when identifying the
root causes. We introduce a noisy functional causal model to account for this
purpose. Then, we employ Bayesian learning and inference methods to infer the
noises of the nodes and edges. We then represent the functional form of a
target outlier leaf as a function of the node and edge noises. Finally, we
propose an efficient gradient-based attribution method to compute the anomaly
attribution scores which scales linearly with the number of nodes and edges.
Experiments on simulated datasets and two real-world scenario datasets show
better anomaly attribution performance of the proposed method compared to the
baselines. Our method scales to larger graphs with more nodes and edges.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11819" title="Abstract">arXiv:2312.11819</a> [<a href="/pdf/2312.11819" title="Download PDF">pdf</a>, <a href="/format/2312.11819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Adaptive Placement and Parallelism Framework for Accelerating RLHF  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Youshao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Weichang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhenglei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+F">Fagui Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shangchun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+L">Lin Ju</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+L">Lei Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaolu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jun Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Recently, ChatGPT or InstructGPT like large language models (LLM) has made a
significant impact in the AI world. These models are incredibly versatile,
capable of performing language tasks on par or even exceeding the capabilities
of human experts. Many works have attempted to reproduce the complex
InstructGPT's RLHF (Reinforcement Learning with Human Feedback) training
pipeline. However, the mainstream distributed RLHF training methods typically
adopt a fixed model placement strategy, referred to as the Flattening strategy.
This strategy treats all four models involved in RLHF as a single entity and
places them on all devices, regardless of their differences. Unfortunately,
this strategy exacerbates the generation bottlenecks in the RLHF training and
degrades the overall training efficiency. To address these issues, we propose
an adaptive model placement framework that offers two flexible model placement
strategies. These strategies allow for the agile allocation of models across
devices in a fine-grained manner. The Interleaving strategy helps reduce memory
redundancy and communication costs during RLHF training. On the other hand, the
Separation strategy improves the throughput of model training by separating the
training and generation stages of the RLHF pipeline. Notably, this framework
seamlessly integrates with other mainstream techniques for acceleration and
enables automatic hyperparameter search. Extensive experiments have
demonstrated that our Interleaving and Separation strategies can achieve
notable improvements up to 11x, compared to the current state-of-the-art (SOTA)
approaches. These experiments encompassed a wide range of training scenarios,
involving models of varying sizes and devices of different scales. The results
highlight the effectiveness and superiority of our approaches in accelerating
the training of distributed RLHF.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11820" title="Abstract">arXiv:2312.11820</a> [<a href="/pdf/2312.11820" title="Download PDF">pdf</a>, <a href="/format/2312.11820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoC-Tuner: An Importance-guided Exploration Framework for DNN-targeting  SoC Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shixin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Su Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+C">Chen Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenqian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+S">Shuo Yin</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yang Bai</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bei Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ASP-DAC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Designing a system-on-chip (SoC) for deep neural network (DNN) acceleration
requires balancing multiple metrics such as latency, power, and area. However,
most existing methods ignore the interactions among different SoC components
and rely on inaccurate and error-prone evaluation tools, leading to inferior
SoC design. In this paper, we present SoC-Tuner, a DNN-targeting exploration
framework to find the Pareto optimal set of SoC configurations efficiently. Our
framework constructs a thorough SoC design space of all components and divides
the exploration into three phases. We propose an importance-based analysis to
prune the design space, a sampling algorithm to select the most representative
initialization points, and an information-guided multi-objective optimization
method to balance multiple design metrics of SoC design. We validate our
framework with the actual very-large-scale-integration (VLSI) flow on various
DNN benchmarks and show that it outperforms previous methods. To the best of
our knowledge, this is the first work to construct an exploration framework of
SoCs for DNN acceleration.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11823" title="Abstract">arXiv:2312.11823</a> [<a href="/pdf/2312.11823" title="Download PDF">pdf</a>, <a href="/format/2312.11823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Singular Control of (Reflected) Brownian Motion: A Computational Method  Suitable for Queueing Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ata%2C+B">Baris Ata</a>, 
<a href="/search/eess?searchtype=author&query=Harrison%2C+J+M">J. Michael Harrison</a>, 
<a href="/search/eess?searchtype=author&query=Si%2C+N">Nian Si</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Motivated by applications in queueing theory, we consider a class of singular
stochastic control problems whose state space is the $d$%-dimensional positive
orthant. The original problem is approximated by a drift control problem, to
which we apply a recently developed computational method that is feasible for
dimensions up to $d=30$ or more. To show that nearly optimal solutions are
obtainable using this method, we present computational results for a variety of
examples, including queueing network examples that have appeared previously in
the literature.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11825" title="Abstract">arXiv:2312.11825</a> [<a href="/pdf/2312.11825" title="Download PDF">pdf</a>, <a href="/format/2312.11825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MossFormer2: Combining Transformer and RNN-Free Recurrent Network for  Enhanced Time-Domain Monaural Speech Separation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shengkui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yukun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+C">Chongjia Ni</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+H">Trung Hieu Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yip%2C+J">Jiaqi Yip</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+D">Dianwen Ng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+B">Bin Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Our previously proposed MossFormer has achieved promising performance in
monaural speech separation. However, it predominantly adopts a
self-attention-based MossFormer module, which tends to emphasize longer-range,
coarser-scale dependencies, with a deficiency in effectively modelling
finer-scale recurrent patterns. In this paper, we introduce a novel hybrid
model that provides the capabilities to model both long-range, coarse-scale
dependencies and fine-scale recurrent patterns by integrating a recurrent
module into the MossFormer framework. Instead of applying the recurrent neural
networks (RNNs) that use traditional recurrent connections, we present a
recurrent module based on a feedforward sequential memory network (FSMN), which
is considered "RNN-free" recurrent network due to the ability to capture
recurrent patterns without using recurrent connections. Our recurrent module
mainly comprises an enhanced dilated FSMN block by using gated convolutional
units (GCU) and dense connections. In addition, a bottleneck layer and an
output layer are also added for controlling information flow. The recurrent
module relies on linear projections and convolutions for seamless, parallel
processing of the entire sequence. The integrated MossFormer2 hybrid model
demonstrates remarkable enhancements over MossFormer and surpasses other
state-of-the-art methods in WSJ0-2/3mix, Libri2Mix, and WHAM!/WHAMR!
benchmarks.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11826" title="Abstract">arXiv:2312.11826</a> [<a href="/pdf/2312.11826" title="Download PDF">pdf</a>, <a href="/format/2312.11826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoupled Textual Embeddings for Customized Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yufei Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yuxiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Z">Zhilong Ji</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jinfeng Bai</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+H">Hu Han</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+W">Wangmeng Zuo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Customized text-to-image generation, which aims to learn user-specified
concepts with a few images, has drawn significant attention recently. However,
existing methods usually suffer from overfitting issues and entangle the
subject-unrelated information (e.g., background and pose) with the learned
concept, limiting the potential to compose concept into new scenes. To address
these issues, we propose the DETEX, a novel approach that learns the
disentangled concept embedding for flexible customized text-to-image
generation. Unlike conventional methods that learn a single concept embedding
from the given images, our DETEX represents each image using multiple word
embeddings during training, i.e., a learnable image-shared subject embedding
and several image-specific subject-unrelated embeddings. To decouple irrelevant
attributes (i.e., background and pose) from the subject embedding, we further
present several attribute mappers that encode each image as several
image-specific subject-unrelated embeddings. To encourage these unrelated
embeddings to capture the irrelevant information, we incorporate them with
corresponding attribute words and propose a joint training strategy to
facilitate the disentanglement. During inference, we only use the subject
embedding for image generation, while selectively using image-specific
embeddings to retain image-specified attributes. Extensive experiments
demonstrate that the subject embedding obtained by our method can faithfully
represent the target concept, while showing superior editability compared to
the state-of-the-art methods. Our code will be made published available.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11828" title="Abstract">arXiv:2312.11828</a> [<a href="/pdf/2312.11828" title="Download PDF">pdf</a>, <a href="/format/2312.11828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TESS: A Multi-intent Parser for Conversational Multi-Agent Systems with  Decentralized Natural Language Understanding Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aksar%2C+B">Burak Aksar</a>, 
<a href="/search/cs?searchtype=author&query=Rizk%2C+Y">Yara Rizk</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborti%2C+T">Tathagata Chakraborti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Chatbots have become one of the main pathways for the delivery of business
automation tools. Multi-agent systems offer a framework for designing chatbots
at scale, making it easier to support complex conversations that span across
multiple domains as well as enabling developers to maintain and expand their
capabilities incrementally over time. However, multi-agent systems complicate
the natural language understanding (NLU) of user intents, especially when they
rely on decentralized NLU models: some utterances (termed single intent) may
invoke a single agent while others (termed multi-intent) may explicitly invoke
multiple agents. Without correctly parsing multi-intent inputs, decentralized
NLU approaches will not achieve high prediction accuracy. In this paper, we
propose an efficient parsing and orchestration pipeline algorithm to service
multi-intent utterances from the user in the context of a multi-agent system.
Our proposed approach achieved comparable performance to competitive deep
learning models on three different datasets while being up to 48 times faster.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11829" title="Abstract">arXiv:2312.11829</a> [<a href="/pdf/2312.11829" title="Download PDF">pdf</a>, <a href="/format/2312.11829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RadOcc: Learning Cross-Modality Occupancy Knowledge through Rendering  Assisted Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+D">Dongfeng Bai</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jiantao Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bingbing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shuguang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhen Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D occupancy prediction is an emerging task that aims to estimate the
occupancy states and semantics of 3D scenes using multi-view images. However,
image-based scene perception encounters significant challenges in achieving
accurate prediction due to the absence of geometric priors. In this paper, we
address this issue by exploring cross-modal knowledge distillation in this
task, i.e., we leverage a stronger multi-modal model to guide the visual model
during training. In practice, we observe that directly applying features or
logits alignment, proposed and widely used in bird's-eyeview (BEV) perception,
does not yield satisfactory results. To overcome this problem, we introduce
RadOcc, a Rendering assisted distillation paradigm for 3D Occupancy prediction.
By employing differentiable volume rendering, we generate depth and semantic
maps in perspective views and propose two novel consistency criteria between
the rendered outputs of teacher and student models. Specifically, the depth
consistency loss aligns the termination distributions of the rendered rays,
while the semantic consistency loss mimics the intra-segment similarity guided
by vision foundation models (VLMs). Experimental results on the nuScenes
dataset demonstrate the effectiveness of our proposed method in improving
various 3D occupancy prediction approaches, e.g., our proposed methodology
enhances our baseline by 2.2% in the metric of mIoU and achieves 50% in Occ3D
benchmark.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11831" title="Abstract">arXiv:2312.11831</a> [<a href="/pdf/2312.11831" title="Download PDF">pdf</a>, <a href="/format/2312.11831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Locally-Minimal Probabilistic Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Izza%2C+Y">Yacine Izza</a>, 
<a href="/search/cs?searchtype=author&query=Meel%2C+K+S">Kuldeep S. Meel</a>, 
<a href="/search/cs?searchtype=author&query=Marques-Silva%2C+J">Joao Marques-Silva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Formal abductive explanations offer crucial guarantees of rigor and so are of
interest in high-stakes uses of machine learning (ML). One drawback of
abductive explanations is explanation size, justified by the cognitive limits
of human decision-makers. Probabilistic abductive explanations (PAXps) address
this limitation, but their theoretical and practical complexity makes their
exact computation most often unrealistic. This paper proposes novel efficient
algorithms for the computation of locally-minimal PXAps, which offer
high-quality approximations of PXAps in practice. The experimental results
demonstrate the practical efficiency of the proposed algorithms.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11832" title="Abstract">arXiv:2312.11832</a> [<a href="/pdf/2312.11832" title="Download PDF">pdf</a>, <a href="/ps/2312.11832" title="Download PostScript">ps</a>, <a href="/format/2312.11832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Validity of a Machine Learning-Based Video Game in the Objective  Screening of Attention Deficit Hyperactivity Disorder in Children Aged 5 to  12 Years
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zakani%2C+Z">Zeinab Zakani</a>, 
<a href="/search/cs?searchtype=author&query=Moradi%2C+H">Hadi Moradi</a>, 
<a href="/search/cs?searchtype=author&query=Ghasemzadeh%2C+S">Sogand Ghasemzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Riazi%2C+M">Maryam Riazi</a>, 
<a href="/search/cs?searchtype=author&query=Mortazavi%2C+F">Fatemeh Mortazavi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 4 figures, 11 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Objective: Early identification of ADHD is necessary to provide the
opportunity for timely treatment. However, screening the symptoms of ADHD on a
large scale is not easy. This study aimed to validate a video game (FishFinder)
for the screening of ADHD using objective measurement of the core symptoms of
this disorder. Method: The FishFinder measures attention and impulsivity
through in-game performance and evaluates the child's hyperactivity using
smartphone motion sensors. This game was tested on 26 children with ADHD and 26
healthy children aged 5 to 12 years. A Support Vector Machine was employed to
detect children with ADHD. results: This system showed 92.3% accuracy, 90%
sensitivity, and 93.7% specificity using a combination of in-game and movement
features. Conclusions: The FishFinder demonstrated a strong ability to identify
ADHD in children. So, this game can be used as an affordable, accessible, and
enjoyable method for the objective screening of ADHD.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11834" title="Abstract">arXiv:2312.11834</a> [<a href="/pdf/2312.11834" title="Download PDF">pdf</a>, <a href="/format/2312.11834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-agent reinforcement learning using echo-state network and its  application to pedestrian dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Komatsu%2C+H">Hisato Komatsu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">In recent years, simulations of pedestrians using the multi-agent
reinforcement learning (MARL) have been studied. This study considered the
roads on a grid-world environment, and implemented pedestrians as MARL agents
using an echo-state network and the least squares policy iteration method.
Under this environment, the ability of these agents to learn to move forward by
avoiding other agents was investigated. Specifically, we considered two types
of tasks: the choice between a narrow direct route and a broad detour, and the
bidirectional pedestrian flow in a corridor. The simulations results indicated
that the learning was successful when the density of the agents was not that
high.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11835" title="Abstract">arXiv:2312.11835</a> [<a href="/pdf/2312.11835" title="Download PDF">pdf</a>, <a href="/format/2312.11835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably Convergent Federated Trilevel Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiao%2C+Y">Yang Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tiancheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jian%2C+C">Chengtao Jian</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jianwei Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Trilevel learning, also called trilevel optimization (TLO), has been
recognized as a powerful modelling tool for hierarchical decision process and
widely applied in many machine learning applications, such as robust neural
architecture search, hyperparameter optimization, and domain adaptation.
Tackling TLO problems has presented a great challenge due to their nested
decision-making structure. In addition, existing works on TLO face the
following key challenges: 1) they all focus on the non-distributed setting,
which may lead to privacy breach; 2) they do not offer any non-asymptotic
convergence analysis which characterizes how fast an algorithm converges. To
address the aforementioned challenges, this paper proposes an asynchronous
federated trilevel optimization method to solve TLO problems. The proposed
method utilizes $\mu$-cuts to construct a hyper-polyhedral approximation for
the TLO problem and solve it in an asynchronous manner. We demonstrate that the
proposed $\mu$-cuts are applicable to not only convex functions but also a wide
range of non-convex functions that meet the $\mu$-weakly convex assumption.
Furthermore, we theoretically analyze the non-asymptotic convergence rate for
the proposed method by showing its iteration complexity to obtain
$\epsilon$-stationary point is upper bounded by
$\mathcal{O}(\frac{1}{\epsilon^2})$. Extensive experiments on real-world
datasets have been conducted to elucidate the superiority of the proposed
method, e.g., it has a faster convergence rate with a maximum acceleration of
approximately 80$\%$.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11836" title="Abstract">arXiv:2312.11836</a> [<a href="/pdf/2312.11836" title="Download PDF">pdf</a>, <a href="/ps/2312.11836" title="Download PostScript">ps</a>, <a href="/format/2312.11836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An All-Analog in-Memory Computing Architecture for Multi-Bit and  Large-Scale Vector Matrix Multiplication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xuan%2C+Z">Zihao Xuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Song Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yi Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Analog in-memory computing (AiMC) is an emerging technology that shows
fantastic performance superiority for neural network acceleration. However, as
the computational bit-width and scale increase, high-precision data conversion
and long-distance data routing will result in unacceptable energy and latency
overheads in the AiMC system. In this work, we focus on the potential of
in-charge computing and in-time interconnection and show an innovative AiMC
architecture, named AiDAC, with three key contributions: (1) AiDAC enhances
multibit computing efficiency and reduces data conversion times by grouping
capacitors technology; (2) AiDAC first adopts row drivers and column time
accumulators to achieve large-scale AiMC arrays integration while minimizing
the energy cost of data movements. (3) AiDAC is the first work to support
large-scale all-analog multibit vector-matrix multiplication (VMM) operations.
The evaluation shows that AiDAC maintains high-precision calculation (less than
0.79% total computing error) while also possessing excellent performance
features, such as high parallelism (up to 26.2TOPS), low latency (&lt;20ns/VMM),
and high energy efficiency (123.8TOPS/W), for 8bits VMM with 1024 input
channels.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11837" title="Abstract">arXiv:2312.11837</a> [<a href="/pdf/2312.11837" title="Download PDF">pdf</a>, <a href="/format/2312.11837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regulating Intermediate 3D Features for Vision-Centric Autonomous  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Junkai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+L">Liang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Haoran Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Linxuan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+D">Dan Deng</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+W">Wei Qian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenxiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Deng Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-camera perception tasks have gained significant attention in the field
of autonomous driving. However, existing frameworks based on Lift-Splat-Shoot
(LSS) in the multi-camera setting cannot produce suitable dense 3D features due
to the projection nature and uncontrollable densification process. To resolve
this problem, we propose to regulate intermediate dense 3D features with the
help of volume rendering. Specifically, we employ volume rendering to process
the dense 3D features to obtain corresponding 2D features (e.g., depth maps,
semantic maps), which are supervised by associated labels in the training. This
manner regulates the generation of dense 3D features on the feature level,
providing appropriate dense and unified features for multiple perception tasks.
Therefore, our approach is termed Vampire, stands for "Volume rendering As
Multi-camera Perception Intermediate feature REgulator". Experimental results
on the Occ3D and nuScenes datasets demonstrate that Vampire facilitates
fine-grained and appropriate extraction of dense 3D features, and is
competitive with existing SOTA methods across diverse downstream perception
tasks like 3D occupancy prediction, LiDAR segmentation and 3D objection
detection, while utilizing moderate GPU resources. We provide a video
demonstration in the supplementary materials and Codes are available at
github.com/cskkxjk/Vampire.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11838" title="Abstract">arXiv:2312.11838</a> [<a href="/pdf/2312.11838" title="Download PDF">pdf</a>, <a href="/ps/2312.11838" title="Download PostScript">ps</a>, <a href="/format/2312.11838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Almost Uniform Sampling of Independent Sets in Polynomial Time --  Implying NP=RP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farago%2C+A">Andras Farago</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2008.00601">arXiv:2008.00601</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">We prove the unexpected result that almost uniform sampling of independent
sets in graphs is possible via a probabilistic polynomial time algorithm. Note
that our sampling algorithm (if correct) has extremely surprising consequences;
the most important one being no less than the unlikely collapse NP=RP.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11839" title="Abstract">arXiv:2312.11839</a> [<a href="/pdf/2312.11839" title="Download PDF">pdf</a>, <a href="/format/2312.11839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual parametric and state estimation for partial differential equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mowlavi%2C+S">Saviz Mowlavi</a>, 
<a href="/search/eess?searchtype=author&query=Benosman%2C+M">Mouhacine Benosman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at IEEE CDC 2023. arXiv admin note: text overlap with <a href="/abs/2302.01189">arXiv:2302.01189</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Dynamical Systems (math.DS); Optimization and Control (math.OC); Computational Physics (physics.comp-ph); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Designing estimation algorithms for systems governed by partial differential
equations (PDEs) such as fluid flows is challenging due to the high-dimensional
and oftentimes nonlinear nature of the dynamics, as well as their dependence on
unobserved physical parameters. In this paper, we propose two different
lightweight and effective methodologies for real-time state estimation of PDEs
in the presence of parametric uncertainties. Both approaches combine a Kalman
filter with a data-driven polytopic linear reduced-order model obtained by
dynamic mode decomposition (DMD). Using examples involving the nonlinear
Burgers and Navier-Stokes equations, we demonstrate accurate estimation of both
the state and the unknown physical parameter along system trajectories
corresponding to various physical parameter values.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11841" title="Abstract">arXiv:2312.11841</a> [<a href="/pdf/2312.11841" title="Download PDF">pdf</a>, <a href="/format/2312.11841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MixRT: Mixed Neural Representations For Real-Time NeRF Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chaojian Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bichen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Vajda%2C+P">Peter Vajda</a>, 
<a href="/search/cs?searchtype=author&query=Yingyan">Yingyan</a> (Celine)Lin
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 3DV'24. Project Page: <a href="https://licj15.github.io/MixRT/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural Radiance Field (NeRF) has emerged as a leading technique for novel
view synthesis, owing to its impressive photorealistic reconstruction and
rendering capability. Nevertheless, achieving real-time NeRF rendering in
large-scale scenes has presented challenges, often leading to the adoption of
either intricate baked mesh representations with a substantial number of
triangles or resource-intensive ray marching in baked representations. We
challenge these conventions, observing that high-quality geometry, represented
by meshes with substantial triangles, is not necessary for achieving
photorealistic rendering quality. Consequently, we propose MixRT, a novel NeRF
representation that includes a low-quality mesh, a view-dependent displacement
map, and a compressed NeRF model. This design effectively harnesses the
capabilities of existing graphics hardware, thus enabling real-time NeRF
rendering on edge devices. Leveraging a highly-optimized WebGL-based rendering
framework, our proposed MixRT attains real-time rendering speeds on edge
devices (over 30 FPS at a resolution of 1280 x 720 on a MacBook M1 Pro laptop),
better rendering quality (0.2 PSNR higher in indoor scenes of the Unbounded-360
datasets), and a smaller storage size (less than 80% compared to
state-of-the-art methods).
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11843" title="Abstract">arXiv:2312.11843</a> [<a href="/pdf/2312.11843" title="Download PDF">pdf</a>, <a href="/format/2312.11843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Social Decision-Making of Autonomous Vehicles: A  Mixed-Strategy Game Approach With Interaction Orientation Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xiao Qi</a>, 
<a href="/search/cs?searchtype=author&query=Hang%2C+P">Peng Hang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jian Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The integration of Autonomous Vehicles (AVs) into existing human-driven
traffic systems poses considerable challenges, especially within environments
where human and machine interactions are frequent and complex, such as at
unsignalized intersections. Addressing these challenges, we introduce a novel
framework predicated on dynamic and socially-aware decision-making game theory
to augment the social decision-making prowess of AVs in mixed driving
environments.This comprehensive framework is delineated into three primary
modules: Social Tendency Recognition, Mixed-Strategy Game Modeling, and Expert
Mode Learning. We introduce 'Interaction Orientation' as a metric to evaluate
the social decision-making tendencies of various agents, incorporating both
environmental factors and trajectory data. The mixed-strategy game model
developed as part of this framework considers the evolution of future traffic
scenarios and includes a utility function that balances safety, operational
efficiency, and the unpredictability of environmental conditions. To adapt to
real-world driving complexities, our framework utilizes dynamic optimization
techniques for assimilating and learning from expert human driving strategies.
These strategies are compiled into a comprehensive library, serving as a
reference for future decision-making processes. Our approach is validated
through extensive driving datasets, and the results demonstrate marked
enhancements in decision timing, precision.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11845" title="Abstract">arXiv:2312.11845</a> [<a href="/pdf/2312.11845" title="Download PDF">pdf</a>, <a href="/ps/2312.11845" title="Download PostScript">ps</a>, <a href="/format/2312.11845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Summary of Privacy-Preserving Data Publishing in the Local Setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Wenjun Lin</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+J">Jiahao Qian</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenwen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lang Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The exponential growth of collected, processed, and shared data has given
rise to concerns about individuals' privacy. Consequently, various laws and
regulations have been established to oversee how organizations handle and
safeguard data. One such method is Statistical Disclosure Control, which aims
to minimize the risk of exposing confidential information by de-identifying it.
This de-identification is achieved through specific privacy-preserving
techniques. However, a trade-off exists: de-identified data can often lead to a
loss of information, which might impact the accuracy of data analysis and the
predictive capability of models. The overarching goal remains to safeguard
individual privacy while preserving the data's interpretability, meaning its
overall usefulness. Despite advances in Statistical Disclosure Control, the
field continues to evolve, with no definitive solution that strikes an optimal
balance between privacy and utility. This survey delves into the intricate
processes of de-identification. We outline the current privacy-preserving
techniques employed in microdata de-identification, delve into privacy measures
tailored for various disclosure scenarios, and assess metrics for information
loss and predictive performance. Herein, we tackle the primary challenges posed
by privacy constraints, overview predominant strategies to mitigate these
challenges, categorize privacy-preserving techniques, offer a theoretical
assessment of current comparative research, and highlight numerous unresolved
issues in the domain.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11846" title="Abstract">arXiv:2312.11846</a> [<a href="/pdf/2312.11846" title="Download PDF">pdf</a>, <a href="/format/2312.11846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Initializing Services in Interactive ML Systems for Diverse Users
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bose%2C+A">Avinandan Bose</a>, 
<a href="/search/cs?searchtype=author&query=Curmei%2C+M">Mihaela Curmei</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D+L">Daniel L. Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Morgenstern%2C+J">Jamie Morgenstern</a>, 
<a href="/search/cs?searchtype=author&query=Dean%2C+S">Sarah Dean</a>, 
<a href="/search/cs?searchtype=author&query=Ratliff%2C+L+J">Lillian J.Ratliff</a>, 
<a href="/search/cs?searchtype=author&query=Fazel%2C+M">Maryam Fazel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper studies ML systems that interactively learn from users across
multiple subpopulations with heterogeneous data distributions. The primary
objective is to provide specialized services for different user groups while
also predicting user preferences. Once the users select a service based on how
well the service anticipated their preference, the services subsequently adapt
and refine themselves based on the user data they accumulate, resulting in an
iterative, alternating minimization process between users and services
(learning dynamics). Employing such tailored approaches has two main
challenges: (i) Unknown user preferences: Typically, data on user preferences
are unavailable without interaction, and uniform data collection across a large
and diverse user base can be prohibitively expensive. (ii) Suboptimal Local
Solutions: The total loss (sum of loss functions across all users and all
services) landscape is not convex even if the individual losses on a single
service are convex, making it likely for the learning dynamics to get stuck in
local minima. The final outcome of the aforementioned learning dynamics is thus
strongly influenced by the initial set of services offered to users, and is not
guaranteed to be close to the globally optimal outcome. In this work, we
propose a randomized algorithm to adaptively select very few users to collect
preference data from, while simultaneously initializing a set of services. We
prove that under mild assumptions on the loss functions, the expected total
loss achieved by the algorithm right after initialization is within a factor of
the globally optimal total loss with complete user preference data, and this
factor scales only logarithmically in the number of services. Our theory is
complemented by experiments on real as well as semi-synthetic datasets.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11849" title="Abstract">arXiv:2312.11849</a> [<a href="/pdf/2312.11849" title="Download PDF">pdf</a>, <a href="/ps/2312.11849" title="Download PostScript">ps</a>, <a href="/format/2312.11849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active contours driven by local and global intensity fitting energy with  application to SAR image segmentation and its fast solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guangming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jing Liang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Quanying Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages,28 figures. arXiv admin note: substantial text overlap with <a href="/abs/2312.08376">arXiv:2312.08376</a>, <a href="/abs/2312.09365">arXiv:2312.09365</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we propose a novel variational active contour model based on
Aubert-Aujol (AA) denoising model, which hybrides geodesic active contour (GAC)
model with active contours without edges (ACWE) model and can be used to
segment images corrupted by multiplicative gamma noise. We transform the
proposed model into classic ROF model by adding a proximity term. Inspired by a
fast denosing algorithm proposed by Jia-Zhao recently, we propose two fast
fixed point algorithms to solve SAR image segmentation question. Experimental
results for real SAR images show that the proposed image segmentation model can
efficiently stop the contours at weak or blurred edges, and can automatically
detect the exterior and interior boundaries of images with multiplicative gamma
noise. The proposed fast fixed point algorithms are robustness to
initialization contour, and can further reduce about 15% of the time needed for
algorithm proposed by Goldstein-Osher.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11850" title="Abstract">arXiv:2312.11850</a> [<a href="/pdf/2312.11850" title="Download PDF">pdf</a>, <a href="/format/2312.11850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GCNext: Towards the Unity of Graph Convolutions for Human Motion  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinshun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Q">Qiongjie Cui</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mengyuan Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to be published in the 38th Annual AAAI Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The past few years has witnessed the dominance of Graph Convolutional
Networks (GCNs) over human motion prediction.Various styles of graph
convolutions have been proposed, with each one meticulously designed and
incorporated into a carefully-crafted network architecture. This paper breaks
the limits of existing knowledge by proposing Universal Graph Convolution
(UniGC), a novel graph convolution concept that re-conceptualizes different
graph convolutions as its special cases. Leveraging UniGC on network-level, we
propose GCNext, a novel GCN-building paradigm that dynamically determines the
best-fitting graph convolutions both sample-wise and layer-wise. GCNext offers
multiple use cases, including training a new GCN from scratch or refining a
preexisting GCN. Experiments on Human3.6M, AMASS, and 3DPW datasets show that,
by incorporating unique module-to-network designs, GCNext yields up to 9x lower
computational cost than existing GCN methods, on top of achieving
state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11851" title="Abstract">arXiv:2312.11851</a> [<a href="/pdf/2312.11851" title="Download PDF">pdf</a>, <a href="/format/2312.11851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Semi-global Output Feedback Formation Maneuver Control of  High-order Multi-agent Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fang%2C+X">Xu Fang</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+L">Lihua Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper addresses the formation maneuver control problem of
leader-follower multi-agent systems with high-order integrator dynamics. A
distributed output feedback formation maneuver controller is proposed to
achieve desired maneuvers so that the scale, orientation, translation, and
shape of formation can be manipulated continuously, where the followers do not
need to know or estimate the time-varying maneuver parameters only known to the
leaders. Compared with existing relative-measurement-based formation maneuver
control, the advantages of the proposed method are that it is output (relative
output) feedback based and shows how to realize different types of formation
shape. In addition, it can be applied to non-generic and non-convex nominal
configurations and the leaders are allowed to be maneuvered. It is worth noting
that the proposed method can also be extended to general linear multi-agent
systems under some additional conditions. The theoretical results are
demonstrated by a simulation example.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11852" title="Abstract">arXiv:2312.11852</a> [<a href="/pdf/2312.11852" title="Download PDF">pdf</a>, <a href="/format/2312.11852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Human Translation Difficulty with Neural Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lim%2C+Z+W">Zheng Wei Lim</a>, 
<a href="/search/cs?searchtype=author&query=Vylomova%2C+E">Ekaterina Vylomova</a>, 
<a href="/search/cs?searchtype=author&query=Kemp%2C+C">Charles Kemp</a>, 
<a href="/search/cs?searchtype=author&query=Cohn%2C+T">Trevor Cohn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Human translators linger on some words and phrases more than others, and
predicting this variation is a step towards explaining the underlying cognitive
processes. Using data from the CRITT Translation Process Research Database, we
evaluate the extent to which surprisal and attentional features derived from a
Neural Machine Translation (NMT) model account for reading and production times
of human translators. We find that surprisal and attention are complementary
predictors of translation difficulty, and that surprisal derived from a NMT
model is the single most successful predictor of production duration. Our
analyses draw on data from hundreds of translators operating across 13 language
pairs, and represent the most comprehensive investigation of human translation
difficulty to date.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11854" title="Abstract">arXiv:2312.11854</a> [<a href="/pdf/2312.11854" title="Download PDF">pdf</a>, <a href="/format/2312.11854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Outer Channel of DNA-Based Data Storage: Capacity and Efficient Coding  Schemes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xuan He</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yi Ding</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+K">Kui Cai</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+G">Guanghui Song</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bin Dai</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiaohu Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been submitted to IEEE Trans. Inf. Theory
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we consider the outer channel for DNA-based data storage,
where each DNA string is either correctly transmitted, or being erased, or
being corrupted by uniformly distributed random substitution errors, and all
strings are randomly shuffled with each other. We first derive the capacity of
the outer channel, which surprisingly implies that the uniformly distributed
random substitution errors are only as harmful as the erasure errors. Next, we
propose efficient coding schemes which encode the bits at the same position of
different strings into a codeword. We compute the soft/hard information of each
bit, which allows us to independently decode the bits within a codeword,
leading to an independent decoding scheme. To improve the decoding performance,
we measure the reliability of each string based on the independent decoding
result, and perform a further step of decoding over the most reliable strings,
leading to a joint decoding scheme. Simulations with low-density parity-check
codes confirm that the joint decoding scheme can reduce the frame error rate by
more than 3 orders of magnitude compared to the independent decoding scheme,
and it can outperform the state-of-the-art decoding scheme in the literature in
a wide parameter regions.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11856" title="Abstract">arXiv:2312.11856</a> [<a href="/pdf/2312.11856" title="Download PDF">pdf</a>, <a href="/format/2312.11856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Learning for Enhancing Geometrical Modeling in 3D-Aware  Generative Adversarial Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiarong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaogang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hengshuang Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 12 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D-aware Generative Adversarial Networks (3D-GANs) currently exhibit
artifacts in their 3D geometrical modeling, such as mesh imperfections and
holes. These shortcomings are primarily attributed to the limited availability
of annotated 3D data, leading to a constrained "valid latent area" for
satisfactory modeling. To address this, we present a Self-Supervised Learning
(SSL) technique tailored as an auxiliary loss for any 3D-GAN, designed to
improve its 3D geometrical modeling capabilities. Our approach pioneers an
inversion technique for 3D-GANs, integrating an encoder that performs adaptive
spatially-varying range operations. Utilizing this inversion, we introduce the
Cyclic Generative Constraint (CGC), aiming to densify the valid latent space.
The CGC operates via augmented local latent vectors that maintain the same
geometric form, and it imposes constraints on the cycle path outputs,
specifically the generator-encoder-generator sequence. This SSL methodology
seamlessly integrates with the inherent GAN loss, ensuring the integrity of
pre-existing 3D-GAN architectures without necessitating alterations. We
validate our approach with comprehensive experiments across various datasets
and architectures, underscoring its efficacy. Our project website:
https://3dgan-ssl.github.io
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11858" title="Abstract">arXiv:2312.11858</a> [<a href="/pdf/2312.11858" title="Download PDF">pdf</a>, <a href="/format/2312.11858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SimCalib: Graph Neural Network Calibration based on Similarity between  Nodes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+B">Boshi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiyong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xixin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qiaochu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+S">Shun Lei</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+H">Helen Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graph neural networks (GNNs) have exhibited impressive performance in
modeling graph data as exemplified in various applications. Recently, the GNN
calibration problem has attracted increasing attention, especially in
cost-sensitive scenarios. Previous work has gained empirical insights on the
issue, and devised effective approaches for it, but theoretical supports still
fall short. In this work, we shed light on the relationship between GNN
calibration and nodewise similarity via theoretical analysis. A novel
calibration framework, named SimCalib, is accordingly proposed to consider
similarity between nodes at global and local levels. At the global level, the
Mahalanobis distance between the current node and class prototypes is
integrated to implicitly consider similarity between the current node and all
nodes in the same class. At the local level, the similarity of node
representation movement dynamics, quantified by nodewise homophily and relative
degree, is considered. Informed about the application of nodewise movement
patterns in analyzing nodewise behavior on the over-smoothing problem, we
empirically present a possible relationship between over-smoothing and GNN
calibration problem. Experimentally, we discover a correlation between nodewise
similarity and model calibration improvement, in alignment with our theoretical
results. Additionally, we conduct extensive experiments investigating different
design factors and demonstrate the effectiveness of our proposed SimCalib
framework for GNN calibration by achieving state-of-the-art performance on 14
out of 16 benchmarks.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11862" title="Abstract">arXiv:2312.11862</a> [<a href="/pdf/2312.11862" title="Download PDF">pdf</a>, <a href="/format/2312.11862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topo-MLP : A Simplicial Network Without Message Passing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramamurthy%2C+K+N">Karthikeyan Natesan Ramamurthy</a>, 
<a href="/search/cs?searchtype=author&query=Guzm%C3%A1n-S%C3%A1enz%2C+A">Aldo Guzm&#xe1;n-S&#xe1;enz</a>, 
<a href="/search/cs?searchtype=author&query=Hajij%2C+M">Mustafa Hajij</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
<p class="mathjax">Due to their ability to model meaningful higher order relations among a set
of entities, higher order network models have emerged recently as a powerful
alternative for graph-based network models which are only capable of modeling
binary relationships. Message passing paradigm is still dominantly used to
learn representations even for higher order network models. While powerful,
message passing can have disadvantages during inference, particularly when the
higher order connectivity information is missing or corrupted. To overcome such
limitations, we propose Topo-MLP, a purely MLP-based simplicial neural network
algorithm to learn the representation of elements in a simplicial complex
without explicitly relying on message passing. Our framework utilizes a novel
Higher Order Neighborhood Contrastive (HONC) loss which implicitly incorporates
the simplicial structure into representation learning. Our proposed model's
simplicity makes it faster during inference. Moreover, we show that our model
is robust when faced with missing or corrupted connectivity structure.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11863" title="Abstract">arXiv:2312.11863</a> [<a href="/pdf/2312.11863" title="Download PDF">pdf</a>, <a href="/format/2312.11863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Network Approximation for Pessimistic Offline Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Di Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+Y">Yuling Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Haizhao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiliang Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of the paper accepted to the 38th Annual AAAI Conference on Artificial Intelligence (AAAI 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Deep reinforcement learning (RL) has shown remarkable success in specific
offline decision-making scenarios, yet its theoretical guarantees are still
under development. Existing works on offline RL theory primarily emphasize a
few trivial settings, such as linear MDP or general function approximation with
strong assumptions and independent data, which lack guidance for practical use.
The coupling of deep learning and Bellman residuals makes this problem
challenging, in addition to the difficulty of data dependence. In this paper,
we establish a non-asymptotic estimation error of pessimistic offline RL using
general neural network approximation with $\mathcal{C}$-mixing data regarding
the structure of networks, the dimension of datasets, and the concentrability
of data coverage, under mild assumptions. Our result shows that the estimation
error consists of two parts: the first converges to zero at a desired rate on
the sample size with partially controllable concentrability, and the second
becomes negligible if the residual constraint is tight. This result
demonstrates the explicit efficiency of deep adversarial offline RL frameworks.
We utilize the empirical process tool for $\mathcal{C}$-mixing sequences and
the neural network approximation theory for the H\"{o}lder class to achieve
this. We also develop methods to bound the Bellman estimation error caused by
function approximation with empirical Bellman constraint perturbations.
Additionally, we present a result that lessens the curse of dimensionality
using data with low intrinsic dimensionality and function classes with low
complexity. Our estimation provides valuable insights into the development of
deep offline RL and guidance for algorithm model design.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11865" title="Abstract">arXiv:2312.11865</a> [<a href="/pdf/2312.11865" title="Download PDF">pdf</a>, <a href="/format/2312.11865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models Play StarCraft II: Benchmarks and A Chain of  Summarization Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Weiyu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+Q">Qirui Mi</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xue Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuqiao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+R">Runji Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haifeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">StarCraft II is a challenging benchmark for AI agents due to the necessity of
both precise micro level operations and strategic macro awareness. Previous
works, such as Alphastar and SCC, achieve impressive performance on tackling
StarCraft II , however, still exhibit deficiencies in long term strategic
planning and strategy interpretability. Emerging large language model (LLM)
agents, such as Voyage and MetaGPT, presents the immense potential in solving
intricate tasks. Motivated by this, we aim to validate the capabilities of LLMs
on StarCraft II, a highly complex RTS game.To conveniently take full advantage
of LLMs` reasoning abilities, we first develop textual StratCraft II
environment, called TextStarCraft II, which LLM agent can interact. Secondly,
we propose a Chain of Summarization method, including single frame
summarization for processing raw observations and multi frame summarization for
analyzing game information, providing command recommendations, and generating
strategic decisions. Our experiment consists of two parts: first, an evaluation
by human experts, which includes assessing the LLMs`s mastery of StarCraft II
knowledge and the performance of LLM agents in the game; second, the in game
performance of LLM agents, encompassing aspects like win rate and the impact of
Chain of Summarization.Experiment results demonstrate that: 1. LLMs possess the
relevant knowledge and complex planning abilities needed to address StarCraft
II scenarios; 2. Human experts consider the performance of LLM agents to be
close to that of an average player who has played StarCraft II for eight years;
3. LLM agents are capable of defeating the built in AI at the Harder(Lv5)
difficulty level. We have open sourced the code and released demo videos of LLM
agent playing StarCraft II.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11866" title="Abstract">arXiv:2312.11866</a> [<a href="/pdf/2312.11866" title="Download PDF">pdf</a>, <a href="/format/2312.11866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Tracking and Perching for Quadrotor in Dynamic Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yuman Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Jialin Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qianhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+R">Rui Jin</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+Z">Zhimeng Shang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yanjun Cao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Shaojie Shen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+F">Fei Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Perching on the moving platforms is a promising solution to enhance the
endurance and operational range of quadrotors, which could benefit the
efficiency of a variety of air-ground cooperative tasks. To ensure robust
perching, tracking with a steady relative state and reliable perception is a
prerequisite. This paper presents an adaptive dynamic tracking and perching
scheme for autonomous quadrotors to achieve tight integration with moving
platforms. For reliable perception of dynamic targets, we introduce elastic
visibility-aware planning to actively avoid occlusion and target loss.
Additionally, we propose a flexible terminal adjustment method that adapts the
changes in flight duration and the coupled terminal states, ensuring full-state
synchronization with the time-varying perching surface at various angles. A
relaxation strategy is developed by optimizing the tangential relative speed to
address the dynamics and safety violations brought by hard boundary conditions.
Moreover, we take SE(3) motion planning into account to ensure no collision
between the quadrotor and the platform until the contact moment. Furthermore,
we propose an efficient spatiotemporal trajectory optimization framework
considering full state dynamics for tracking and perching. The proposed method
is extensively tested through benchmark comparisons and ablation studies. To
facilitate the application of academic research to industry and to validate the
efficiency of our scheme under strictly limited computational resources, we
deploy our system on a commercial drone (DJI-MAVIC3) with a full-size
sport-utility vehicle (SUV). We conduct extensive real-world experiments, where
the drone successfully tracks and perches at 30~km/h (8.3~m/s) on the top of
the SUV, and at 3.5~m/s with 60{\deg} inclined into the trunk of the SUV.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11867" title="Abstract">arXiv:2312.11867</a> [<a href="/pdf/2312.11867" title="Download PDF">pdf</a>, <a href="/format/2312.11867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point Cloud Part Editing: Segmentation, Generation, Assembly, and  Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaiyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Ximing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weizhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Cheng Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 7 figures, AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Ideal part editing should guarantee the diversity of edited parts, the
fidelity to the remaining parts, and the quality of the results. However,
previous methods do not disentangle each part completely, which means the
edited parts will affect the others, resulting in poor diversity and fidelity.
In addition, some methods lack constraints between parts, which need manual
selections of edited results to ensure quality. Therefore, we propose a
four-stage process for point cloud part editing: Segmentation, Generation,
Assembly, and Selection. Based on this process, we introduce SGAS, a model for
part editing that employs two strategies: feature disentanglement and
constraint. By independently fitting part-level feature distributions, we
realize the feature disentanglement. By explicitly modeling the transformation
from object-level distribution to part-level distributions, we realize the
feature constraint. Considerable experiments on different datasets demonstrate
the efficiency and effectiveness of SGAS on point cloud part editing. In
addition, SGAS can be pruned to realize unsupervised part-aware point cloud
generation and achieves state-of-the-art results.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11868" title="Abstract">arXiv:2312.11868</a> [<a href="/pdf/2312.11868" title="Download PDF">pdf</a>, <a href="/format/2312.11868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Loco-manipulation on HECTOR: Humanoid for Enhanced ConTrol and  Open-source Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Junchao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Kolt%2C+O">Omar Kolt</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+M">Manas Shah</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q">Quan Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Despite their remarkable advancement in locomotion and manipulation, humanoid
robots remain challenged by a lack of synchronized loco-manipulation control,
hindering their full dynamic potential. In this work, we introduce a versatile
and effective approach to controlling and generalizing dynamic locomotion and
loco-manipulation on humanoid robots via a Force-and-moment-based Model
Predictive Control (MPC). Specifically, we proposed a simplified rigid body
dynamics (SRBD) model to take into account both humanoid and object dynamics
for humanoid loco-manipulation. This linear dynamics model allows us to
directly solve for ground reaction forces and moments via an MPC problem to
achieve highly dynamic real-time control. Our proposed framework is highly
versatile and generalizable. We introduce HECTOR (Humanoid for Enhanced ConTrol
and Open-source Research) platform to demonstrate its effectiveness in hardware
experiments. With the proposed framework, HECTOR can maintain exceptional
balance during double-leg stance mode, even when subjected to external force
disturbances to the body or foot location. In addition, it can execute 3-D
dynamic walking on a variety of uneven terrains, including wet grassy surfaces,
slopes, randomly placed wood slats, and stacked wood slats up to 6 cm high with
the speed of 0.6 m/s. In addition, we have demonstrated dynamic humanoid
loco-manipulation over uneven terrain, carrying 2.5 kg load. HECTOR
simulations, along with the proposed control framework, are made available as
an open-source project. (https://github.com/DRCL-USC/Hector_Simulation).
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11870" title="Abstract">arXiv:2312.11870</a> [<a href="/pdf/2312.11870" title="Download PDF">pdf</a>, <a href="/ps/2312.11870" title="Download PostScript">ps</a>, <a href="/format/2312.11870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Revisit of Fake News Dataset with Augmented Fact-checking by ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zizhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haopeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiawei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The proliferation of fake news has emerged as a critical issue in recent
years, requiring significant efforts to detect it. However, the existing fake
news detection datasets are sourced from human journalists, which are likely to
have inherent bias limitations due to the highly subjective nature of this
task. In this paper, we revisit the existing fake news dataset verified by
human journalists with augmented fact-checking by large language models
(ChatGPT), and we name the augmented fake news dataset ChatGPT-FC. We
quantitatively analyze the distinctions and resemblances between human
journalists and LLM in assessing news subject credibility, news creator
credibility, time-sensitive, and political framing. Our findings highlight
LLM's potential to serve as a preliminary screening method, offering a
promising avenue to mitigate the inherent biases of human journalists and
enhance fake news detection.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11871" title="Abstract">arXiv:2312.11871</a> [<a href="/pdf/2312.11871" title="Download PDF">pdf</a>, <a href="/format/2312.11871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meili: Enabling SmartNIC as a Service in the Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+Q">Qiang Su</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shaofeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Z">Zhixiong Niu</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+R">Ran Shu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Peng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yongqiang Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+C+J">Chun Jason Xue</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zaoxing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hong Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">SmartNICs are touted as an attractive substrate for network application
offloading, offering benefits in programmability, host resource saving, and
energy efficiency. The current usage restricts offloading to local hosts and
confines SmartNIC ownership to individual application teams, resulting in poor
resource efficiency and scalability. This paper presents Meili, a novel system
that realizes SmartNIC as a service to address these issues. Meili organizes
heterogeneous SmartNIC resources as a pool and offers a unified one-NIC
abstraction to application developers. This allows developers to focus solely
on the application logic while dynamically optimizing their performance needs.
Our evaluation on NVIDIA BlueField series and AMD Pensando SmartNICs
demonstrates that Meili achieves scalable single-flow throughput with a maximum
8 {\mu}s latency overhead and enhances resource efficiency by 3.07$\times$
compared to standalone deployments and 1.44$\times$ compared to
state-of-the-art microservice deployments.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11872" title="Abstract">arXiv:2312.11872</a> [<a href="/pdf/2312.11872" title="Download PDF">pdf</a>, <a href="/format/2312.11872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Prototypes: Semantic Anchor Regularization for Better  Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yanqi Ge</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Q">Qiang Nie</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Ye Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+F">Feng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wen Li</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+L">Lixin Duan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">One of the ultimate goals of representation learning is to achieve
compactness within a class and well-separability between classes. Many
outstanding metric-based and prototype-based methods following the
Expectation-Maximization paradigm, have been proposed for this objective.
However, they inevitably introduce biases into the learning process,
particularly with long-tail distributed training data. In this paper, we reveal
that the class prototype is not necessarily to be derived from training
features and propose a novel perspective to use pre-defined class anchors
serving as feature centroid to unidirectionally guide feature learning.
However, the pre-defined anchors may have a large semantic distance from the
pixel features, which prevents them from being directly applied. To address
this issue and generate feature centroid independent from feature learning, a
simple yet effective Semantic Anchor Regularization (SAR) is proposed. SAR
ensures the interclass separability of semantic anchors in the semantic space
by employing a classifier-aware auxiliary cross-entropy loss during training
via disentanglement learning. By pulling the learned features to these semantic
anchors, several advantages can be attained: 1) the intra-class compactness and
naturally inter-class separability, 2) induced bias or errors from feature
learning can be avoided, and 3) robustness to the long-tailed problem. The
proposed SAR can be used in a plug-and-play manner in the existing models.
Extensive experiments demonstrate that the SAR performs better than previous
sophisticated prototype-based methods. The implementation is available at
https://github.com/geyanqi/SAR.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11873" title="Abstract">arXiv:2312.11873</a> [<a href="/pdf/2312.11873" title="Download PDF">pdf</a>, <a href="/ps/2312.11873" title="Download PostScript">ps</a>, <a href="/format/2312.11873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Algorithms for Internal Dictionary Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jiangqi Dai</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Q">Qingyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tingqiang Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">In this paper, we consider the problem of preprocessing a text $T$ of length
$n$ and a dictionary $\mathcal{D}$ to answer multiple types of pattern queries.
Inspired by [Charalampopoulos-Kociumaka-Mohamed-Radoszewski-Rytter-Wale\'n
ISAAC 2019], we consider the Internal Dictionary, where the dictionary is
interval in the sense that every pattern is given as a fragment of $T$.
Therefore, the size of $\mathcal{D}$ is proportional to the number of patterns
instead of their total length, which could be $\Theta(n \cdot |\mathcal{D}|)$.
We propose a new technique to preprocess $T$ and organize the substring
structure. In this way, we are able to develop algorithms to answer queries
more efficiently than in previous works.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11875" title="Abstract">arXiv:2312.11875</a> [<a href="/pdf/2312.11875" title="Download PDF">pdf</a>, <a href="/format/2312.11875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse is Enough in Fine-tuning Pre-trained Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+W">Weixi Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zuchao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lefei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+B">Bo Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">With the prevalence of pre-training-fine-tuning paradigm, how to efficiently
adapt the pre-trained model to the downstream tasks has been an intriguing
issue. Parameter-Efficient Fine-Tuning (PEFT) methods have been proposed for
low-cost adaptation, including Adapters, Bia-only, and the recently widely used
Low-Rank Adaptation. Although these methods have demonstrated their
effectiveness to some extent and have been widely applied, the underlying
principles are still unclear. In this paper, we reveal the transition of loss
landscape in the downstream domain from random initialization to pre-trained
initialization, that is, from low-amplitude oscillation to high-amplitude
oscillation. The parameter gradients exhibit a property akin to sparsity, where
a small fraction of components dominate the total gradient norm, for instance,
1% of the components account for 99% of the gradient. This property ensures
that the pre-trained model can easily find a flat minimizer which guarantees
the model's ability to generalize even with a low number of trainable
parameters. Based on this, we propose a gradient-based sparse fine-tuning
algorithm, named Sparse Increment Fine-Tuning (SIFT), and validate its
effectiveness on a range of tasks including the GLUE Benchmark and
Instruction-tuning. The code is accessible at https://github.com/song-wx/SIFT/.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11880" title="Abstract">arXiv:2312.11880</a> [<a href="/pdf/2312.11880" title="Download PDF">pdf</a>, <a href="/format/2312.11880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point Cloud Segmentation Using Transfer Learning with RandLA-Net: A Case  Study on Urban Areas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bayar%2C+A+E">Alperen Enes Bayar</a>, 
<a href="/search/cs?searchtype=author&query=Uyan%2C+U">Ufuk Uyan</a>, 
<a href="/search/cs?searchtype=author&query=Toprak%2C+E">Elif Toprak</a>, 
<a href="/search/cs?searchtype=author&query=Yuheng%2C+C">Cao Yuheng</a>, 
<a href="/search/cs?searchtype=author&query=Juncheng%2C+T">Tang Juncheng</a>, 
<a href="/search/cs?searchtype=author&query=Kindiroglu%2C+A+A">Ahmet Alp Kindiroglu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Urban environments are characterized by complex structures and diverse
features, making accurate segmentation of point cloud data a challenging task.
This paper presents a comprehensive study on the application of RandLA-Net, a
state-of-the-art neural network architecture, for the 3D segmentation of
large-scale point cloud data in urban areas. The study focuses on three major
Chinese cities, namely Chengdu, Jiaoda, and Shenzhen, leveraging their unique
characteristics to enhance segmentation performance.
<br />To address the limited availability of labeled data for these specific urban
areas, we employed transfer learning techniques. We transferred the learned
weights from the Sensat Urban and Toronto 3D datasets to initialize our
RandLA-Net model. Additionally, we performed class remapping to adapt the model
to the target urban areas, ensuring accurate segmentation results.
<br />The experimental results demonstrate the effectiveness of the proposed
approach achieving over 80\% F1 score for each areas in 3D point cloud
segmentation. The transfer learning strategy proves to be crucial in overcoming
data scarcity issues, providing a robust solution for urban point cloud
analysis. The findings contribute to the advancement of point cloud
segmentation methods, especially in the context of rapidly evolving Chinese
urban areas.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11881" title="Abstract">arXiv:2312.11881</a> [<a href="/pdf/2312.11881" title="Download PDF">pdf</a>, <a href="/format/2312.11881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Punctuation restoration Model and Spacing Model for Korean Ancient  Document
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jang%2C+T">Taehong Jang</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+J">Joonmo Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S+L">Sojung Lucia Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 Pages, 2 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In Korean ancient documents, there is no spacing or punctuation, and they are
written in classical Chinese characters. This makes it challenging for modern
individuals and translation models to accurately interpret and translate them.
While China has models predicting punctuation and spacing, applying them
directly to Korean texts is problematic due to data differences. Therefore, we
developed the first models which predict punctuation and spacing for Korean
historical texts and evaluated their performance. Our punctuation restoration
model achieved an F1 score of 0.84, and Spacing model achieved a score of 0.96.
It has the advantage of enabling inference on low-performance GPUs with less
VRAM while maintaining quite high accuracy.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11882" title="Abstract">arXiv:2312.11882</a> [<a href="/pdf/2312.11882" title="Download PDF">pdf</a>, <a href="/format/2312.11882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConsistentEE: A Consistent and Hardness-Guided Early Exiting Method for  Accelerating Language Models Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Ziqian Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yihuai Hong</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Hongliang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+H">Huiping Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cen Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Early Exiting is one of the most popular methods to achieve efficient
inference. Current early exiting methods adopt the (weighted) sum of the cross
entropy loss of all internal classifiers during training, imposing all these
classifiers to predict all instances correctly. However, during inference, as
long as one internal classifier predicts an instance correctly, it can
accelerate without losing accuracy. Thus, there is a notable gap between
training and inference. We propose ConsistentEE, an early exiting method that
is consistent in training and inference. ConsistentEE formulates the early
exiting process as a reinforcement learning problem. A policy network is added
to decide whether an instance should exit or continue. The training objective
of ConsistentEE only require each instance to be predicted correctly by one
internal classifier. Additionally, we introduce the concept Memorize Layer to
measure the hardness of an instance. We incorporate memorized layer into reward
function design, which allows ``easy'' instances to focus more on acceleration
while ``hard'' instances to focus more on accuracy. Experimental results show
that our method outperforms other baselines on various natural language
understanding and generation tasks.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11884" title="Abstract">arXiv:2312.11884</a> [<a href="/pdf/2312.11884" title="Download PDF">pdf</a>, <a href="/format/2312.11884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teaching Software Ethics to Future Software Engineers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pant%2C+A">Aastha Pant</a>, 
<a href="/search/cs?searchtype=author&query=Spiegler%2C+S+V">Simone V. Spiegler</a>, 
<a href="/search/cs?searchtype=author&query=Hoda%2C+R">Rashina Hoda</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+J">Jeremy Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Yusuf%2C+N">Nabeeb Yusuf</a>, 
<a href="/search/cs?searchtype=author&query=Er%2C+T">Tian Er</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shenyi Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The importance of teaching software ethics to software engineering (SE)
students is more critical now than ever before as software related ethical
issues continue to impact society at an alarming rate. Traditional classroom
methods, vignettes, role-play games, and quizzes have been employed over the
years to teach SE students about software ethics. Recognising the significance
of incorporating software ethics knowledge in SE education and the continued
need for more efforts in the area of the teaching and learning of SE ethics, we
developed an interactive, scenario-based Software Ethics Quiz. Our goal was to
teach SE students about ethics in a comprehensive, open, and engaging manner
through a combined approach of an online lecture followed by an interactive
workshop with the quiz and a debriefing session. The anonymous quiz responses
collected showed promising results regarding the engagement and efficacy of the
lecture and quiz, with a slightly better rating for the interactive quiz. The
voluntary student feedback collected suggested that a majority of the
participants found the debrief discussion on the quiz scenarios to be very
beneficial for learning about software ethics. In this experience report, we
share our experiences, related educational resources including the quiz, and
recommendations from lessons learned with the wider education community to keep
driving this critical topic forward
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11885" title="Abstract">arXiv:2312.11885</a> [<a href="/pdf/2312.11885" title="Download PDF">pdf</a>, <a href="/ps/2312.11885" title="Download PostScript">ps</a>, <a href="/format/2312.11885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Large-Scale Dataset of Search Interests Related to Disease X  Originating from Different Geographic Regions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thakur%2C+N">Nirmalya Thakur</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shuqi Cui</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+K+A">Kesha A. Patel</a>, 
<a href="/search/cs?searchtype=author&query=Hall%2C+I">Isabella Hall</a>, 
<a href="/search/cs?searchtype=author&query=Duggal%2C+Y+N">Yuvraj Nihal Duggal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">The World Health Organization added Disease X to their shortlist of blueprint
priority diseases to represent a hypothetical, unknown pathogen that could
cause a future epidemic. During different virus outbreaks of the past, such as
COVID-19, Influenza, Lyme Disease, and Zika virus, researchers from various
disciplines utilized Google Trends to mine multimodal components of web
behavior to study, investigate, and analyze the global awareness, preparedness,
and response associated with these respective virus outbreaks. As the world
prepares for Disease X, a dataset on web behavior related to Disease X would be
crucial to contribute towards the timely advancement of research in this field.
Furthermore, none of the prior works in this field have focused on the
development of a dataset to compile relevant web behavior data, which would
help to prepare for Disease X. To address these research challenges, this work
presents a dataset of web behavior related to Disease X, which emerged from
different geographic regions of the world, between February 2018 and August
2023. Specifically, this dataset presents the search interests related to
Disease X from 94 geographic regions. The dataset was developed by collecting
data using Google Trends. The relevant search interests for all these regions
for each month in this time range are available in this dataset. This paper
also discusses the compliance of this dataset with the FAIR principles of
scientific data management. Finally, an analysis of this dataset is presented
to uphold the applicability, relevance, and usefulness of this dataset for the
investigation of different research questions in the interrelated fields of Big
Data, Data Mining, Healthcare, Epidemiology, and Data Analysis with a specific
focus on Disease X.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11888" title="Abstract">arXiv:2312.11888</a> [<a href="/pdf/2312.11888" title="Download PDF">pdf</a>, <a href="/format/2312.11888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Angle-Displacement Rigidity Theory with Application to Distributed  Network Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fang%2C+X">Xu Fang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiaolei Li</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+L">Lihua Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">This paper investigates the localization problem of a network in 2-D and 3-D
spaces given the positions of anchor nodes in a global frame and inter-node
relative measurements in local coordinate frames. It is assumed that the local
frames of different nodes have different unknown orientations. First, an
angle-displacement rigidity theory is developed, which can be used to localize
all the free nodes by the known positions of the anchor nodes and local
relative measurements (local relative position, distance, local relative
bearing, angle, or ratio-of-distance measurements). Then, necessary and
sufficient conditions for network localizability are given. Finally, a
distributed network localization protocol is proposed, which can globally
estimate the locations of all the free nodes of a network if the network is
infinitesimally angle-displacement rigid. The proposed method unifies
local-relative-position-based, distance-based, local-relative-bearing-based,
angle-based, and ratio-of-distance-based distributed network localization
approaches. The novelty of this work is that the proposed method can be applied
in both generic and non-generic configurations with an unknown global
coordinate frame in both 2-D and 3-D spaces.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11889" title="Abstract">arXiv:2312.11889</a> [<a href="/pdf/2312.11889" title="Download PDF">pdf</a>, <a href="/format/2312.11889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Line-Level Defects by Capturing Code Contexts with  Hierarchical Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahbub%2C+P">Parvez Mahbub</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+M">Mohammad Masudur Rahman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Software defects consume 40% of the total budget in software development and
cost the global economy billions of dollars every year. Unfortunately, despite
the use of many software quality assurance (SQA) practices in software
development (e.g., code review, continuous integration), defects may still
exist in the official release of a software product. Therefore, prioritizing
SQA efforts for the vulnerable areas of the codebase is essential to ensure the
high quality of a software release. Predicting software defects at the line
level could help prioritize the SQA effort but is a highly challenging task
given that only ~3% of lines of a codebase could be defective. Existing works
on line-level defect prediction often fall short and cannot fully leverage the
line-level defect information. In this paper, we propose Bugsplorer, a novel
deep-learning technique for line-level defect prediction. It leverages a
hierarchical structure of transformer models to represent two types of code
elements: code tokens and code lines. Unlike the existing techniques that are
optimized for file-level defect prediction, Bugsplorer is optimized for a
line-level defect prediction objective. Our evaluation with five performance
metrics shows that Bugsplorer has a promising capability of predicting
defective lines with 26-72% better accuracy than that of the state-of-the-art
technique. It can rank the first 20% defective lines within the top 1-3%
suspicious lines. Thus, Bugsplorer has the potential to significantly reduce
SQA costs by ranking defective lines higher.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11890" title="Abstract">arXiv:2312.11890</a> [<a href="/pdf/2312.11890" title="Download PDF">pdf</a>, <a href="/format/2312.11890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Difficulty-Focused Contrastive Learning for Knowledge Tracing with a  Large Language Model-Based Difficulty Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+U">Unggi Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S">Sungjun Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+J+S">Joon Seo Yun</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+K">Kyoungsoo Park</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+Y">YoungHoon Jung</a>, 
<a href="/search/cs?searchtype=author&query=Stratton%2C+D">Damji Stratton</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyeoncheol Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">This paper presents novel techniques for enhancing the performance of
knowledge tracing (KT) models by focusing on the crucial factor of question and
concept difficulty level. Despite the acknowledged significance of difficulty,
previous KT research has yet to exploit its potential for model optimization
and has struggled to predict difficulty from unseen data. To address these
problems, we propose a difficulty-centered contrastive learning method for KT
models and a Large Language Model (LLM)-based framework for difficulty
prediction. These innovative methods seek to improve the performance of KT
models and provide accurate difficulty estimates for unseen data. Our ablation
study demonstrates the efficacy of these techniques by demonstrating enhanced
KT model performance. Nonetheless, the complex relationship between language
and difficulty merits further investigation.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11891" title="Abstract">arXiv:2312.11891</a> [<a href="/pdf/2312.11891" title="Download PDF">pdf</a>, <a href="/format/2312.11891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical and Incremental Structural Entropy Minimization for  Unsupervised Social Event Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yuwei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhengtao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">As a trending approach for social event detection, graph neural network
(GNN)-based methods enable a fusion of natural language semantics and the
complex social network structural information, thus showing SOTA performance.
However, GNN-based methods can miss useful message correlations. Moreover, they
require manual labeling for training and predetermining the number of events
for prediction. In this work, we address social event detection via graph
structural entropy (SE) minimization. While keeping the merits of the GNN-based
methods, the proposed framework, HISEvent, constructs more informative message
graphs, is unsupervised, and does not require the number of events given a
priori. Specifically, we incrementally explore the graph neighborhoods using
1-dimensional (1D) SE minimization to supplement the existing message graph
with edges between semantically related messages. We then detect events from
the message graph by hierarchically minimizing 2-dimensional (2D) SE. Our
proposed 1D and 2D SE minimization algorithms are customized for social event
detection and effectively tackle the efficiency problem of the existing SE
minimization algorithms. Extensive experiments show that HISEvent consistently
outperforms GNN-based methods and achieves the new SOTA for social event
detection under both closed- and open-set settings while being efficient and
robust.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11894" title="Abstract">arXiv:2312.11894</a> [<a href="/pdf/2312.11894" title="Download PDF">pdf</a>, <a href="/format/2312.11894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D-LFM: Lifting Foundation Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dabhi%2C+M">Mosam Dabhi</a>, 
<a href="/search/cs?searchtype=author&query=Jeni%2C+L+A">Laszlo A. Jeni</a>, 
<a href="/search/cs?searchtype=author&query=Lucey%2C+S">Simon Lucey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page is available at <a href="https://3dlfm.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The lifting of 3D structure and camera from 2D landmarks is at the
cornerstone of the entire discipline of computer vision. Traditional methods
have been confined to specific rigid objects, such as those in
Perspective-n-Point (PnP) problems, but deep learning has expanded our
capability to reconstruct a wide range of object classes (e.g. C3PDO and PAUL)
with resilience to noise, occlusions, and perspective distortions. All these
techniques, however, have been limited by the fundamental need to establish
correspondences across the 3D training data -- significantly limiting their
utility to applications where one has an abundance of "in-correspondence" 3D
data. Our approach harnesses the inherent permutation equivariance of
transformers to manage varying number of points per 3D data instance,
withstands occlusions, and generalizes to unseen categories. We demonstrate
state of the art performance across 2D-3D lifting task benchmarks. Since our
approach can be trained across such a broad class of structures we refer to it
simply as a 3D Lifting Foundation Model (3D-LFM) -- the first of its kind.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11895" title="Abstract">arXiv:2312.11895</a> [<a href="/pdf/2312.11895" title="Download PDF">pdf</a>, <a href="/ps/2312.11895" title="Download PostScript">ps</a>, <a href="/format/2312.11895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Public Reactions, Perceptions, and Attitudes during the MPox  Outbreak: Findings from Topic Modeling of Tweets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thakur%2C+N">Nirmalya Thakur</a>, 
<a href="/search/cs?searchtype=author&query=Duggal%2C+Y+N">Yuvraj Nihal Duggal</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zihui Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY)

</div>
<p class="mathjax">The recent outbreak of the MPox virus has resulted in a tremendous increase
in the usage of Twitter. Prior works in this area of research have primarily
focused on the sentiment analysis and content analysis of these Tweets, and the
few works that have focused on topic modeling have multiple limitations. This
paper aims to address this research gap and makes two scientific contributions
to this field. First, it presents the results of performing Topic Modeling on
601,432 Tweets about the 2022 Mpox outbreak that were posted on Twitter between
7 May 2022 and 3 March 2023. The results indicate that the conversations on
Twitter related to Mpox during this time range may be broadly categorized into
four distinct themes - Views and Perspectives about Mpox, Updates on Cases and
Investigations about Mpox, Mpox and the LGBTQIA+ Community, and Mpox and
COVID-19. Second, the paper presents the findings from the analysis of these
Tweets. The results show that the theme that was most popular on Twitter (in
terms of the number of Tweets posted) during this time range was Views and
Perspectives about Mpox. This was followed by the theme of Mpox and the
LGBTQIA+ Community, which was followed by the themes of Mpox and COVID-19 and
Updates on Cases and Investigations about Mpox, respectively. Finally, a
comparison with related studies in this area of research is also presented to
highlight the novelty and significance of this research work.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11896" title="Abstract">arXiv:2312.11896</a> [<a href="/pdf/2312.11896" title="Download PDF">pdf</a>, <a href="/format/2312.11896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable Relay Learning Optimization Approach for Fast Power System  Production Cost Minimization Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Guo%2C+Z">Zishan Guo</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+Q">Qinran Hu</a>, 
<a href="/search/eess?searchtype=author&query=Qian%2C+T">Tao Qian</a>, 
<a href="/search/eess?searchtype=author&query=Fang%2C+X">Xin Fang</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+R">Renjie Hu</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Z">Zaijun Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transactions on Power Systems on December 15, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Production cost minimization (PCM) simulation is commonly employed for
assessing the operational efficiency, economic viability, and reliability,
providing valuable insights for power system planning and operations. However,
solving a PCM problem is time-consuming, consisting of numerous binary
variables for simulation horizon extending over months and years. This hinders
rapid assessment of modern energy systems with diverse planning requirements.
Existing methods for accelerating PCM tend to sacrifice accuracy for speed. In
this paper, we propose a stable relay learning optimization (s-RLO) approach
within the Branch and Bound (B&amp;B) algorithm. The proposed approach offers rapid
and stable performance, and ensures optimal solutions. The two-stage s-RLO
involves an imitation learning (IL) phase for accurate policy initialization
and a reinforcement learning (RL) phase for time-efficient fine-tuning. When
implemented on the popular SCIP solver, s-RLO returns the optimal solution up
to 2 times faster than the default relpscost rule and 1.4 times faster than IL,
or exhibits a smaller gap at the predefined time limit. The proposed approach
shows stable performance, reducing fluctuations by approximately 50% compared
with IL. The efficacy of the proposed s-RLO approach is supported by numerical
results.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11897" title="Abstract">arXiv:2312.11897</a> [<a href="/pdf/2312.11897" title="Download PDF">pdf</a>, <a href="/format/2312.11897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text-Conditioned Resampler For Long Form Video Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Korbar%2C+B">Bruno Korbar</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+Y">Yongqin Xian</a>, 
<a href="/search/cs?searchtype=author&query=Tonioni%2C+A">Alessio Tonioni</a>, 
<a href="/search/cs?searchtype=author&query=Zisserman%2C+A">Andrew Zisserman</a>, 
<a href="/search/cs?searchtype=author&query=Tombari%2C+F">Federico Tombari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Videos are highly redundant data source and it is often enough to identify a
few key moments to solve any given task. In this paper, we present a
text-conditioned video resampler (TCR) module that uses a pre-trained and
frozen visual encoder and large language model (LLM) to process long video
sequences for a task. TCR localises relevant visual features from the video
given a text condition and provides them to a LLM to generate a text response.
Due to its lightweight design and use of cross-attention, TCR can process more
than 100 frames at a time allowing the model to use much longer chunks of video
than earlier works. We make the following contributions: (i) we design a
transformer-based sampling architecture that can process long videos
conditioned on a task, together with a training method that enables it to
bridge pre-trained visual and language models; (ii) we empirically validate its
efficacy on a wide variety of evaluation tasks, and set a new state-of-the-art
on NextQA, EgoSchema, and the EGO4D-LTA challenge; and (iii) we determine tasks
which require longer video contexts and that can thus be used effectively for
further evaluation of long-range video models.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11898" title="Abstract">arXiv:2312.11898</a> [<a href="/pdf/2312.11898" title="Download PDF">pdf</a>, <a href="/format/2312.11898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Short-Term Multi-Horizon Line Loss Rate Forecasting of a Distribution  Network Using Attention-GCN-LSTM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yijia Cao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yixiu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+W">Wei Deng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Accurately predicting line loss rates is vital for effective line loss
management in distribution networks, especially over short-term multi-horizons
ranging from one hour to one week. In this study, we propose
Attention-GCN-LSTM, a novel method that combines Graph Convolutional Networks
(GCN), Long Short-Term Memory (LSTM), and a three-level attention mechanism to
address this challenge. By capturing spatial and temporal dependencies, our
model enables accurate forecasting of line loss rates across multiple horizons.
Through comprehensive evaluation using real-world data from 10KV feeders, our
Attention-GCN-LSTM model consistently outperforms existing algorithms,
exhibiting superior performance in terms of prediction accuracy and
multi-horizon forecasting. This model holds significant promise for enhancing
line loss management in distribution networks.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11905" title="Abstract">arXiv:2312.11905</a> [<a href="/pdf/2312.11905" title="Download PDF">pdf</a>, <a href="/format/2312.11905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence Visualizer of Decentralized Federated Distillation with  Reduced Communication Costs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taya%2C+A">Akihito Taya</a>, 
<a href="/search/cs?searchtype=author&query=Nishiyama%2C+Y">Yuuki Nishiyama</a>, 
<a href="/search/cs?searchtype=author&query=Sezaki%2C+K">Kaoru Sezaki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> (c) 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc. IEEE Global Communications 2023 (GLOBECOM), Kuala Lumpur,
  Malaysia, Dec. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated learning (FL) achieves collaborative learning without the need for
data sharing, thus preventing privacy leakage. To extend FL into a fully
decentralized algorithm, researchers have applied distributed optimization
algorithms to FL by considering machine learning (ML) tasks as parameter
optimization problems. Conversely, the consensus-based multi-hop federated
distillation (CMFD) proposed in the authors' previous work makes neural network
(NN) models get close with others in a function space rather than in a
parameter space. Hence, this study solves two unresolved challenges of CMFD:
(1) communication cost reduction and (2) visualization of model convergence.
Based on a proposed dynamic communication cost reduction method (DCCR), the
amount of data transferred in a network is reduced; however, with a slight
degradation in the prediction accuracy. In addition, a technique for
visualizing the distance between the NN models in a function space is also
proposed. The technique applies a dimensionality reduction technique by
approximating infinite-dimensional functions as numerical vectors to visualize
the trajectory of how the models change by the distributed learning algorithm.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11911" title="Abstract">arXiv:2312.11911</a> [<a href="/pdf/2312.11911" title="Download PDF">pdf</a>, <a href="/format/2312.11911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EVI-SAM: Robust, Real-time, Tightly-coupled Event-Visual-Inertial State  Estimation and 3D Dense Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+W">Weipeng Guan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peiyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Huibin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+P">Peng Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Event cameras are bio-inspired, motion-activated sensors that demonstrate
substantial potential in handling challenging situations, such as motion blur
and high-dynamic range. In this paper, we proposed EVI-SAM to tackle the
problem of 6 DoF pose tracking and 3D reconstruction using monocular event
camera. A novel event-based hybrid tracking framework is designed to estimate
the pose, leveraging the robustness of feature matching and the precision of
direct alignment. Specifically, we develop an event-based 2D-2D alignment to
construct the photometric constraint, and tightly integrate it with the
event-based reprojection constraint. The mapping module recovers the dense and
colorful depth of the scene through the image-guided event-based mapping
method. Subsequently, the appearance, texture, and surface mesh of the 3D scene
can be reconstructed by fusing the dense depth map from multiple viewpoints
using truncated signed distance function (TSDF) fusion. To the best of our
knowledge, this is the first non-learning work to realize event-based dense
mapping. Numerical evaluations are performed on both publicly available and
self-collected datasets, which qualitatively and quantitatively demonstrate the
superior performance of our method. Our EVI-SAM effectively balances accuracy
and robustness while maintaining computational efficiency, showcasing superior
pose tracking and dense mapping performance in challenging scenarios. Video
Demo: https://youtu.be/Nn40U4e5Si8.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11913" title="Abstract">arXiv:2312.11913</a> [<a href="/pdf/2312.11913" title="Download PDF">pdf</a>, <a href="/format/2312.11913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning flow functions of spiking systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Aguiar%2C+M">Miguel Aguiar</a>, 
<a href="/search/eess?searchtype=author&query=Das%2C+A">Amritam Das</a>, 
<a href="/search/eess?searchtype=author&query=Johansson%2C+K+H">Karl H. Johansson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">We propose a framework for surrogate modelling of spiking systems. These
systems are often described by stiff differential equations with high-amplitude
oscillations and multi-timescale dynamics, making surrogate models an
attractive tool for system design and simulation. We parameterise the flow
function of a spiking system using a recurrent neural network architecture,
allowing for a direct continuous-time representation of the state trajectories.
The spiking nature of the signals makes for a data-heavy and computationally
hard training process; thus, we describe two methods to mitigate these
difficulties. We demonstrate our framework on two conductance-based models of
biological neurons, showing that we are able to train surrogate models which
accurately replicate the spiking behaviour.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11914" title="Abstract">arXiv:2312.11914</a> [<a href="/pdf/2312.11914" title="Download PDF">pdf</a>, <a href="/format/2312.11914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Role of Likes: How Online Feedback Impacts Users&#x27; Mental Health
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Voggenreiter%2C+A">Angelina Voggenreiter</a> (1), 
<a href="/search/cs?searchtype=author&query=Brandt%2C+S">Sophie Brandt</a> (1), 
<a href="/search/cs?searchtype=author&query=Putterer%2C+F">Fabian Putterer</a> (1), 
<a href="/search/cs?searchtype=author&query=Frings%2C+A">Andreas Frings</a> (1), 
<a href="/search/cs?searchtype=author&query=Pfeffer%2C+J">Juergen Pfeffer</a> (1) ((1) School of Social Sciences and Technology, Technical University of Munich)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Social media usage has been shown to have both positive and negative
consequences for users' mental health. Several studies indicated that peer
feedback plays an important role in the relationship between social media use
and mental health. In this research, we analyse the impact of receiving online
feedback on users' emotional experience, social connectedness and self-esteem.
In an experimental study, we let users interact with others on a Facebook-like
system over the course of a week while controlling for the amount of positive
reactions they receive from their peers. We find that experiencing little to no
reaction from others does not only elicit negative emotions and stress amongst
users, but also induces low levels of self-esteem. In contrast, receiving much
positive online feedback, evokes feelings of social connectedness and reduces
overall loneliness. On a societal level, our study can help to better
understand the mechanisms through which social media use impacts mental health
in a positive or negative way. On a methodological level, we provide a new
open-source tool for designing and conducting social media experiments.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11918" title="Abstract">arXiv:2312.11918</a> [<a href="/pdf/2312.11918" title="Download PDF">pdf</a>, <a href="/format/2312.11918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Case Study in CUDA Kernel Fusion: Implementing FlashAttention-2 on  NVIDIA Hopper Architecture using the CUTLASS Library
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bikshandi%2C+G">Ganesh Bikshandi</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+J">Jay Shah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, comments welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">We provide an optimized implementation of the forward pass of
FlashAttention-2, a popular memory-aware scaled dot-product attention
algorithm, as a custom fused CUDA kernel targeting NVIDIA Hopper architecture
and written using the open-source CUTLASS library. In doing so, we explain the
challenges and techniques involved in fusing online-softmax with back-to-back
GEMM kernels, utilizing the Hopper-specific Tensor Memory Accelerator (TMA) and
Warpgroup Matrix-Multiply-Accumulate (WGMMA) instructions, defining and
transforming CUTLASS Layouts and Tensors, overlapping copy and GEMM operations,
and choosing optimal tile sizes for the Q, K and V attention matrices while
balancing the register pressure and shared memory utilization. In head-to-head
benchmarks on a single H100 PCIe GPU for some common choices of
hyperparameters, we observe 20-50% higher FLOPs/s over a version of
FlashAttention-2 optimized for last-generation NVIDIA Ampere architecture.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11920" title="Abstract">arXiv:2312.11920</a> [<a href="/pdf/2312.11920" title="Download PDF">pdf</a>, <a href="/format/2312.11920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> External Knowledge Augmented Polyphone Disambiguation Using Large  Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">One of the key issues in Mandarin Chinese text-to-speech (TTS) systems is
polyphone disambiguation when doing grapheme-to-phoneme (G2P) conversion. In
this paper, we introduce a novel method to solve the problem as a generation
task. Following the trending research of large language models (LLM) and prompt
learning, the proposed method consists of three modules. Retrieval module
incorporates external knowledge which is a multi-level semantic dictionary of
Chinese polyphonic characters to format the sentence into a prompt. Generation
module adopts the decoder-only Transformer architecture to induce the target
text. Postprocess module corrects the generated text into a valid result if
needed. Experimental results show that our method outperforms the existing
methods on a public dataset called CPP. We also empirically study the impacts
of different templates of the prompt, different sizes of training data, and
whether to incorporate external knowledge.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11922" title="Abstract">arXiv:2312.11922</a> [<a href="/pdf/2312.11922" title="Download PDF">pdf</a>, <a href="/format/2312.11922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relation-Aware Question Answering for Heterogeneous Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Haowei Du</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Quzhe Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongyan Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP2023 (Long)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multi-hop Knowledge Base Question Answering(KBQA) aims to find the answer
entity in a knowledge graph (KG), which requires multiple steps of reasoning.
Existing retrieval-based approaches solve this task by concentrating on the
specific relation at different hops and predicting the intermediate entity
within the reasoning path. During the reasoning process of these methods, the
representation of relations are fixed but the initial relation representation
may not be optimal. We claim they fail to utilize information from head-tail
entities and the semantic connection between relations to enhance the current
relation representation, which undermines the ability to capture information of
relations in KGs. To address this issue, we construct a \textbf{dual relation
graph} where each node denotes a relation in the original KG (\textbf{primal
entity graph}) and edges are constructed between relations sharing same head or
tail entities. Then we iteratively do primal entity graph reasoning, dual
relation graph information propagation, and interaction between these two
graphs. In this way, the interaction between entity and relation is enhanced,
and we derive better entity and relation representations. Experiments on two
public datasets, WebQSP and CWQ, show that our approach achieves a significant
performance gain over the prior state-of-the-art. Our code is available on
\url{https://github.com/yanmenxue/RAH-KBQA}.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11923" title="Abstract">arXiv:2312.11923</a> [<a href="/pdf/2312.11923" title="Download PDF">pdf</a>, <a href="/format/2312.11923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IPAD: Iterative, Parallel, and Diffusion-based Network for Scene Text  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaomeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Z">Zhi Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiping Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Nowadays, scene text recognition has attracted more and more attention due to
its diverse applications. Most state-of-the-art methods adopt an
encoder-decoder framework with the attention mechanism, autoregressively
generating text from left to right. Despite the convincing performance, this
sequential decoding strategy constrains inference speed. Conversely,
non-autoregressive models provide faster, simultaneous predictions but often
sacrifice accuracy. Although utilizing an explicit language model can improve
performance, it burdens the computational load. Besides, separating linguistic
knowledge from vision information may harm the final prediction. In this paper,
we propose an alternative solution, using a parallel and iterative decoder that
adopts an easy-first decoding strategy. Furthermore, we regard text recognition
as an image-based conditional text generation task and utilize the discrete
diffusion strategy, ensuring exhaustive exploration of bidirectional contextual
information. Extensive experiments demonstrate that the proposed approach
achieves superior results on the benchmark datasets, including both Chinese and
English text images.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11925" title="Abstract">arXiv:2312.11925</a> [<a href="/pdf/2312.11925" title="Download PDF">pdf</a>, <a href="/format/2312.11925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GLL-based Context-Free Path Querying for Neo4j
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abzalov%2C+V">Vadim Abzalov</a>, 
<a href="/search/cs?searchtype=author&query=Pogozhelskaya%2C+V">Vlada Pogozhelskaya</a>, 
<a href="/search/cs?searchtype=author&query=Kutuev%2C+V">Vladimir Kutuev</a>, 
<a href="/search/cs?searchtype=author&query=Grigorev%2C+S">Semyon Grigorev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">We propose GLL-based context-free path querying algorithm which handles
queries in Extended Backus-Naur Form (EBNF) using Recursive State Machines
(RSM). Utilization of EBNF allows one to combine traditional regular
expressions and mutually recursive patterns in constraints natively. The
proposed algorithm solves both the reachability-only and the all-paths problems
for the all-pairs and the multiple sources cases. The evaluation on realworld
graphs demonstrates that utilization of RSMs increases performance of query
evaluation. Being implemented as a stored procedure for Neo4j, our solution
demonstrates better performance than a similar solution for RedisGraph.
Performance of our solution of regular path queries is comparable with
performance of native Neo4j solution, and in some cases our solution requires
significantly less memory.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11926" title="Abstract">arXiv:2312.11926</a> [<a href="/pdf/2312.11926" title="Download PDF">pdf</a>, <a href="/format/2312.11926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Big Learning Expectation Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cong%2C+Y">Yulai Cong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sijia Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">Mixture models serve as one fundamental tool with versatile applications.
However, their training techniques, like the popular Expectation Maximization
(EM) algorithm, are notoriously sensitive to parameter initialization and often
suffer from bad local optima that could be arbitrarily worse than the optimal.
To address the long-lasting bad-local-optima challenge, we draw inspiration
from the recent ground-breaking foundation models and propose to leverage their
underlying big learning principle to upgrade the EM. Specifically, we present
the Big Learning EM (BigLearn-EM), an EM upgrade that simultaneously performs
joint, marginal, and orthogonally transformed marginal matchings between data
and model distributions. Through simulated experiments, we empirically show
that the BigLearn-EM is capable of delivering the optimal with high
probability; comparisons on benchmark clustering datasets further demonstrate
its effectiveness and advantages over existing techniques. The code is
available at
https://github.com/YulaiCong/Big-Learning-Expectation-Maximization.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11927" title="Abstract">arXiv:2312.11927</a> [<a href="/pdf/2312.11927" title="Download PDF">pdf</a>, <a href="/format/2312.11927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empowering Dual-Level Graph Self-Supervised Pretraining with Motif  Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+P">Pengwei Yan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kaisong Song</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhuoren Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yangyang Kang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+T">Tianqianjin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Changlong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaozhong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures, accepted by AAAI'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI); Methodology (stat.ME)

</div>
<p class="mathjax">While self-supervised graph pretraining techniques have shown promising
results in various domains, their application still experiences challenges of
limited topology learning, human knowledge dependency, and incompetent
multi-level interactions. To address these issues, we propose a novel solution,
Dual-level Graph self-supervised Pretraining with Motif discovery (DGPM), which
introduces a unique dual-level pretraining structure that orchestrates
node-level and subgraph-level pretext tasks. Unlike prior approaches, DGPM
autonomously uncovers significant graph motifs through an edge pooling module,
aligning learned motif similarities with graph kernel-based similarities. A
cross-matching task enables sophisticated node-motif interactions and novel
representation learning. Extensive experiments on 15 datasets validate DGPM's
effectiveness and generalizability, outperforming state-of-the-art methods in
unsupervised representation learning and transfer learning settings. The
autonomously discovered motifs demonstrate the potential of DGPM to enhance
robustness and interpretability.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11929" title="Abstract">arXiv:2312.11929</a> [<a href="/pdf/2312.11929" title="Download PDF">pdf</a>, <a href="/ps/2312.11929" title="Download PostScript">ps</a>, <a href="/format/2312.11929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer Network for Multi-Person Tracking and Re-Identification in  Unconstrained Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mukhtar%2C+H">Hamza Mukhtar</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+U+G">Muhammad Usman Ghani Khan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Multi-object tracking (MOT) has profound applications in a variety of fields,
including surveillance, sports analytics, self-driving, and cooperative
robotics. Despite considerable advancements, existing MOT methodologies tend to
falter when faced with non-uniform movements, occlusions, and
appearance-reappearance scenarios of the objects. Recognizing this inadequacy,
we put forward an integrated MOT method that not only marries object detection
and identity linkage within a singular, end-to-end trainable framework but also
equips the model with the ability to maintain object identity links over long
periods of time. Our proposed model, named STMMOT, is built around four key
modules: 1) candidate proposal generation, which generates object proposals via
a vision-transformer encoder-decoder architecture that detects the object from
each frame in the video; 2) scale variant pyramid, a progressive pyramid
structure to learn the self-scale and cross-scale similarities in multi-scale
feature maps; 3) spatio-temporal memory encoder, extracting the essential
information from the memory associated with each object under tracking; and 4)
spatio-temporal memory decoder, simultaneously resolving the tasks of object
detection and identity association for MOT. Our system leverages a robust
spatio-temporal memory module that retains extensive historical observations
and effectively encodes them using an attention-based aggregator. The
uniqueness of STMMOT lies in representing objects as dynamic query embeddings
that are updated continuously, which enables the prediction of object states
with attention mechanisms and eradicates the need for post-processing.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11930" title="Abstract">arXiv:2312.11930</a> [<a href="/pdf/2312.11930" title="Download PDF">pdf</a>, <a href="/format/2312.11930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collision-Free Navigation of Wheeled Mobile Robots: An Integrated Path  Planning and Tube-Following Control Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+X">Xiaodong Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+J+G">Jose Guadalupe Romero</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+B">Bowen Fan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qinglei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Navarro-Alarcon%2C+D">David Navarro-Alarcon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In this paper, an integrated path planning and tube-following control scheme
is proposed for collision-free navigation of a wheeled mobile robot (WMR) in a
compact convex workspace cluttered with sufficiently separated spherical
obstacles. An analytical path planning algorithm is developed based on
Bouligand's tangent cones and Nagumo's invariance theorem, which enables the
WMR to navigate towards a designated goal location from almost all initial
positions in the free space, without entering into augmented obstacle regions
with safety margins. We further construct a virtual "safe tube" around the
reference trajectory, ensuring that its radius does not exceed the size of the
safety margin. Subsequently, a saturated adaptive controller is designed to
achieve safe trajectory tracking in the presence of disturbances. It is shown
that this tube-following controller guarantees that the WMR tracks the
reference trajectory within the predefined tube, while achieving uniform
ultimate boundedness of both the position tracking and parameter estimation
errors. This indicates that the WMR will not collide with any obstacles along
the way. Finally, we report simulation and experimental results to validate the
effectiveness of the proposed method.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11932" title="Abstract">arXiv:2312.11932</a> [<a href="/pdf/2312.11932" title="Download PDF">pdf</a>, <a href="/ps/2312.11932" title="Download PostScript">ps</a>, <a href="/format/2312.11932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unravelling Expressive Delegations: Complexity and Normative Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tyrovolas%2C+G">Giannis Tyrovolas</a>, 
<a href="/search/cs?searchtype=author&query=Constantinescu%2C+A">Andrei Constantinescu</a>, 
<a href="/search/cs?searchtype=author&query=Elkind%2C+E">Edith Elkind</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in AAAI'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We consider binary group decision-making under a rich model of liquid
democracy recently proposed by Colley, Grandi, and Novaro (2022): agents submit
ranked delegation options, where each option may be a function of multiple
agents' votes; e.g., "I vote yes if a majority of my friends vote yes." Such
ballots are unravelled into a profile of direct votes by selecting one entry
from each ballot so as not to introduce cyclic dependencies. We study
delegation via monotonic Boolean functions, and two unravelling procedures:
MinSum, which minimises the sum of the ranks of the chosen entries, and its
egalitarian counterpart, MinMax. We provide complete computational dichotomies:
MinSum is hard to compute (and approximate) as soon as any non-trivial
functions are permitted, and polynomial otherwise; for MinMax the easiness
results extend to arbitrary-arity logical ORs and ANDs taken in isolation, but
not beyond. For the classic model of delegating to individual agents, we give
asymptotically near-tight algorithms for carrying out the two procedures and
efficient algorithms for finding optimal unravellings with the highest vote
count for a given alternative. These algorithms inspire novel tie-breaking
rules for the setup of voting to change a status quo. We then introduce a new
axiom, which can be viewed as a variant of the participation axiom, and use
algorithmic techniques developed earlier in the paper to show that it is
satisfied by MinSum and a lexicographic refinement of MinMax (but not MinMax
itself).
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11933" title="Abstract">arXiv:2312.11933</a> [<a href="/pdf/2312.11933" title="Download PDF">pdf</a>, <a href="/format/2312.11933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Frequency Domain Graph Convolutional Network for Traffic  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yujie Li</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Zezhi Shao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yongjun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Q">Qiang Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhaogang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Complex spatial dependencies in transportation networks make traffic
prediction extremely challenging. Much existing work is devoted to learning
dynamic graph structures among sensors, and the strategy of mining spatial
dependencies from traffic data, known as data-driven, tends to be an intuitive
and effective approach. However, Time-Shift of traffic patterns and noise
induced by random factors hinder data-driven spatial dependence modeling. In
this paper, we propose a novel dynamic frequency domain graph convolution
network (DFDGCN) to capture spatial dependencies. Specifically, we mitigate the
effects of time-shift by Fourier transform, and introduce the identity
embedding of sensors and time embedding when capturing data for graph learning
since traffic data with noise is not entirely reliable. The graph is combined
with static predefined and self-adaptive graphs during graph convolution to
predict future traffic data through classical causal convolutions. Extensive
experiments on four real-world datasets demonstrate that our model is effective
and outperforms the baselines.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11934" title="Abstract">arXiv:2312.11934</a> [<a href="/pdf/2312.11934" title="Download PDF">pdf</a>, <a href="/format/2312.11934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identification of Causal Structure with Latent Variables Based on Higher  Order Cumulants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhiyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+R">Ruichu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Z">Zhifeng Hao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
<p class="mathjax">Causal discovery with latent variables is a crucial but challenging task.
Despite the emergence of numerous methods aimed at addressing this challenge,
they are not fully identified to the structure that two observed variables are
influenced by one latent variable and there might be a directed edge in
between. Interestingly, we notice that this structure can be identified through
the utilization of higher-order cumulants. By leveraging the higher-order
cumulants of non-Gaussian data, we provide an analytical solution for
estimating the causal coefficients or their ratios. With the estimated (ratios
of) causal coefficients, we propose a novel approach to identify the existence
of a causal edge between two observed variables subject to latent variable
influence. In case when such a causal edge exits, we introduce an asymmetry
criterion to determine the causal direction. The experimental results
demonstrate the effectiveness of our proposed method.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11935" title="Abstract">arXiv:2312.11935</a> [<a href="/pdf/2312.11935" title="Download PDF">pdf</a>, <a href="/format/2312.11935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameterized Decision-making with Multi-modal Perception for Autonomous  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yuyang Xia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuncheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Quanlin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+L">Liwei Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">You Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Han Su</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+K">Kai Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE International Conference on Data Engineering (ICDE2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Autonomous driving is an emerging technology that has advanced rapidly over
the last decade. Modern transportation is expected to benefit greatly from a
wise decision-making framework of autonomous vehicles, including the
improvement of mobility and the minimization of risks and travel time. However,
existing methods either ignore the complexity of environments only fitting
straight roads, or ignore the impact on surrounding vehicles during
optimization phases, leading to weak environmental adaptability and incomplete
optimization objectives. To address these limitations, we propose a
parameterized decision-making framework with multi-modal perception based on
deep reinforcement learning, called AUTO. We conduct a comprehensive perception
to capture the state features of various traffic participants around the
autonomous vehicle, based on which we design a graph-based model to learn a
state representation of the multi-modal semantic features. To distinguish
between lane-following and lane-changing, we decompose an action of the
autonomous vehicle into a parameterized action structure that first decides
whether to change lanes and then computes an exact action to execute. A hybrid
reward function takes into account aspects of safety, traffic efficiency,
passenger comfort, and impact to guide the framework to generate optimal
actions. In addition, we design a regularization term and a multi-worker
paradigm to enhance the training. Extensive experiments offer evidence that
AUTO can advance state-of-the-art in terms of both macroscopic and microscopic
effectiveness.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11936" title="Abstract">arXiv:2312.11936</a> [<a href="/pdf/2312.11936" title="Download PDF">pdf</a>, <a href="/format/2312.11936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact ASP Counting with Compact Encodings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kabir%2C+M">Mohimenul Kabir</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+S">Supratik Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Meel%2C+K+S">Kuldeep S Meel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Answer Set Programming (ASP) has emerged as a promising paradigm in knowledge
representation and automated reasoning owing to its ability to model hard
combinatorial problems from diverse domains in a natural way. Building on
advances in propositional SAT solving, the past two decades have witnessed the
emergence of well-engineered systems for solving the answer set satisfiability
problem, i.e., finding models or answer sets for a given answer set program. In
recent years, there has been growing interest in problems beyond
satisfiability, such as model counting, in the context of ASP. Akin to the
early days of propositional model counting, state-of-the-art exact answer set
counters do not scale well beyond small instances. Exact ASP counters struggle
with handling larger input formulas. The primary contribution of this paper is
a new ASP counting framework, called sharpASP, which counts answer sets
avoiding larger input formulas. This relies on an alternative way of defining
answer sets that allows for the lifting of key techniques developed in the
context of propositional model counting. Our extensive empirical analysis over
1470 benchmarks demonstrates significant performance gain over current
state-of-the-art exact answer set counters. Specifically, by using sharpASP, we
were able to solve 1062 benchmarks with PAR2 score of 3082 whereas using prior
state-of-the-art, we could only solve 895 benchmarks with a PAR2 score of 4205,
all other experimental conditions being the same.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11938" title="Abstract">arXiv:2312.11938</a> [<a href="/pdf/2312.11938" title="Download PDF">pdf</a>, <a href="/format/2312.11938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DMT: Comprehensive Distillation with Multiple Self-supervised Teachers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Numerous self-supervised learning paradigms, such as contrastive learning and
masked image modeling, have been proposed to acquire powerful and general
representations from unlabeled data. However, these models are commonly
pretrained within their specific framework alone, failing to consider the
complementary nature of visual representations. To tackle this issue, we
introduce Comprehensive Distillation with Multiple Self-supervised Teachers
(DMT) for pretrained model compression, which leverages the strengths of
multiple off-the-shelf self-supervised models. Our experimental results on
prominent benchmark datasets exhibit that the proposed method significantly
surpasses state-of-the-art competitors while retaining favorable efficiency
metrics. On classification tasks, our DMT framework utilizing three different
self-supervised ViT-Base teachers enhances the performance of both small/tiny
models and the base model itself. For dense tasks, DMT elevates the AP/mIoU of
standard SSL models on MS-COCO and ADE20K datasets by 4.0%.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11939" title="Abstract">arXiv:2312.11939</a> [<a href="/pdf/2312.11939" title="Download PDF">pdf</a>, <a href="/format/2312.11939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Series Contrastive Learning against False Negatives and Class  Imbalance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xiyuan Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Youfang Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As an exemplary self-supervised approach for representation learning,
time-series contrastive learning has exhibited remarkable advancements in
contemporary research. While recent contrastive learning strategies have
focused on how to construct appropriate positives and negatives, in this study,
we conduct theoretical analysis and find they have overlooked the fundamental
issues: false negatives and class imbalance inherent in the InfoNCE loss-based
framework. Therefore, we introduce a straightforward modification grounded in
the SimCLR framework, universally adaptable to models engaged in the instance
discrimination task. By constructing instance graphs to facilitate interactive
learning among instances, we emulate supervised contrastive learning via the
multiple-instances discrimination task, mitigating the harmful impact of false
negatives. Moreover, leveraging the graph structure and few-labeled data, we
perform semi-supervised consistency classification and enhance the
representative ability of minority classes. We compared our method with the
most popular time-series contrastive learning methods on four real-world
time-series datasets and demonstrated our significant advantages in overall
performance.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11943" title="Abstract">arXiv:2312.11943</a> [<a href="/pdf/2312.11943" title="Download PDF">pdf</a>, <a href="/format/2312.11943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability of Multi-Agent Learning in Competitive Networks: Delaying the  Onset of Chaos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hussain%2C+A">Aamal Hussain</a>, 
<a href="/search/cs?searchtype=author&query=Belardinelli%2C+F">Francesco Belardinelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Dynamical Systems (math.DS)

</div>
<p class="mathjax">The behaviour of multi-agent learning in competitive network games is often
studied within the context of zero-sum games, in which convergence guarantees
may be obtained. However, outside of this class the behaviour of learning is
known to display complex behaviours and convergence cannot be always
guaranteed. Nonetheless, in order to develop a complete picture of the
behaviour of multi-agent learning in competitive settings, the zero-sum
assumption must be lifted. Motivated by this we study the Q-Learning dynamics,
a popular model of exploration and exploitation in multi-agent learning, in
competitive network games. We determine how the degree of competition,
exploration rate and network connectivity impact the convergence of Q-Learning.
To study generic competitive games, we parameterise network games in terms of
correlations between agent payoffs and study the average behaviour of the
Q-Learning dynamics across all games drawn from a choice of this parameter.
This statistical approach establishes choices of parameters for which
Q-Learning dynamics converge to a stable fixed point. Differently to previous
works, we find that the stability of Q-Learning is explicitly dependent only on
the network connectivity rather than the total number of agents. Our
experiments validate these findings and show that, under certain network
structures, the total number of agents can be increased without increasing the
likelihood of unstable or chaotic behaviours.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11944" title="Abstract">arXiv:2312.11944</a> [<a href="/pdf/2312.11944" title="Download PDF">pdf</a>, <a href="/format/2312.11944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FPT Approximation using Treewidth: Capacitated Vertex Cover, Target Set  Selection and Vector Dominating Set
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Bingkai Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+H">Huairui Chu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 1 figure, accepted by ISAAC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">Treewidth is a useful tool in designing graph algorithms. Although many
NP-hard graph problems can be solved in linear time when the input graphs have
small treewidth, there are problems which remain hard on graphs of bounded
treewidth. In this paper, we consider three vertex selection problems that are
W[1]-hard when parameterized by the treewidth of the input graph, namely the
capacitated vertex cover problem, the target set selection problem and the
vector dominating set problem. We provide two new methods to obtain FPT
approximation algorithms for these problems. For the capacitated vertex cover
problem and the vector dominating set problem, we obtain
$(1+o(1))$-approximation FPT algorithms. For the target set selection problem,
we give an FPT algorithm providing a tradeoff between its running time and the
approximation ratio.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11945" title="Abstract">arXiv:2312.11945</a> [<a href="/pdf/2312.11945" title="Download PDF">pdf</a>, <a href="/format/2312.11945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Granularity Information Interaction Framework for Incomplete  Utterance Rewriting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Haowei Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dingyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongyan Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP2023 (short)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent approaches in Incomplete Utterance Rewriting (IUR) fail to capture the
source of important words, which is crucial to edit the incomplete utterance,
and introduce words from irrelevant utterances. We propose a novel and
effective multi-task information interaction framework including context
selection, edit matrix construction, and relevance merging to capture the
multi-granularity of semantic information. Benefiting from fetching the
relevant utterance and figuring out the important words, our approach
outperforms existing state-of-the-art models on two benchmark datasets
Restoration-200K and CANAND in this field. Code will be provided on
\url{https://github.com/yanmenxue/QR}.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11947" title="Abstract">arXiv:2312.11947</a> [<a href="/pdf/2312.11947" title="Download PDF">pdf</a>, <a href="/format/2312.11947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emotion Rendering for Conversational Speech Synthesis with Heterogeneous  Graph-Based Context Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Rui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yifan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yi Ren</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xiang Yin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haizhou Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures, Accepted by AAAI'2024, Code and audio samples: <a href="https://github.com/walker-hyf/ECSS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Conversational Speech Synthesis (CSS) aims to accurately express an utterance
with the appropriate prosody and emotional inflection within a conversational
setting. While recognising the significance of CSS task, the prior studies have
not thoroughly investigated the emotional expressiveness problems due to the
scarcity of emotional conversational datasets and the difficulty of stateful
emotion modeling. In this paper, we propose a novel emotional CSS model, termed
ECSS, that includes two main components: 1) to enhance emotion understanding,
we introduce a heterogeneous graph-based emotional context modeling mechanism,
which takes the multi-source dialogue history as input to model the dialogue
context and learn the emotion cues from the context; 2) to achieve emotion
rendering, we employ a contrastive learning-based emotion renderer module to
infer the accurate emotion style for the target utterance. To address the issue
of data scarcity, we meticulously create emotional labels in terms of category
and intensity, and annotate additional emotional information on the existing
conversational dataset (DailyTalk). Both objective and subjective evaluations
suggest that our model outperforms the baseline models in understanding and
rendering emotions. These evaluations also underscore the importance of
comprehensive emotional annotations. Code and audio samples can be found at:
https://github.com/walker-hyf/ECSS.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11949" title="Abstract">arXiv:2312.11949</a> [<a href="/pdf/2312.11949" title="Download PDF">pdf</a>, <a href="/format/2312.11949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CreativeConnect: Supporting Reference Recombination for Graphic Design  Ideation with Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+D">DaEun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Sumin Hong</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jeongeon Park</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+J+J+Y">John Joon Young Chung</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Juho Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Graphic designers often get inspiration through the recombination of
references. Our formative study (N=6) reveals that graphic designers focus on
conceptual keywords during this process, and want support for discovering the
keywords, expanding them, and exploring diverse recombination options of them,
while still having room for their creativity. We propose CreativeConnect, a
system with generative AI pipelines that helps users discover useful elements
from the reference image using keywords, recommends relevant keywords,
generates diverse recombination options with user-selected keywords, and shows
recombinations as sketches with text descriptions. Our user study (N=16) showed
that CreativeConnect helped users discover keywords from the reference and
generate multiple ideas based on them, ultimately helping users produce more
design ideas and higher self-reported creativity, compared to the baseline
system without generative pipelines. While CreativeConnect was effective in
ideation, we discussed how CreativeConnect can be extended to support other
types of tasks in creativity support.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11952" title="Abstract">arXiv:2312.11952</a> [<a href="/pdf/2312.11952" title="Download PDF">pdf</a>, <a href="/format/2312.11952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Parameter Selection for Non-Redundant Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leiber%2C+C">Collin Leiber</a>, 
<a href="/search/cs?searchtype=author&query=Mautz%2C+D">Dominik Mautz</a>, 
<a href="/search/cs?searchtype=author&query=Plant%2C+C">Claudia Plant</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%B6hm%2C+C">Christian B&#xf6;hm</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 2022 SIAM International Conference on Data
  Mining (SDM) (pp. 226-234). Society for Industrial and Applied Mathematics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">High-dimensional datasets often contain multiple meaningful clusterings in
different subspaces. For example, objects can be clustered either by color,
weight, or size, revealing different interpretations of the given dataset. A
variety of approaches are able to identify such non-redundant clusterings.
However, most of these methods require the user to specify the expected number
of subspaces and clusters for each subspace. Stating these values is a
non-trivial problem and usually requires detailed knowledge of the input
dataset. In this paper, we propose a framework that utilizes the Minimum
Description Length Principle (MDL) to detect the number of subspaces and
clusters per subspace automatically. We describe an efficient procedure that
greedily searches the parameter space by splitting and merging subspaces and
clusters within subspaces. Additionally, an encoding strategy is introduced
that allows us to detect outliers in each subspace. Extensive experiments show
that our approach is highly competitive to state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11953" title="Abstract">arXiv:2312.11953</a> [<a href="/pdf/2312.11953" title="Download PDF">pdf</a>, <a href="/ps/2312.11953" title="Download PostScript">ps</a>, <a href="/format/2312.11953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Competition among Pairwise Lottery Contests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+X">Xiaotie Deng</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+H">Hangxin Gan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Ningyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weian Li</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Q">Qi Qi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We investigate a two-stage competitive model involving multiple contests. In
this model, each contest designer chooses two participants from a pool of
candidate contestants and determines the biases. Contestants strategically
distribute their efforts across various contests within their budget. We first
show the existence of a pure strategy Nash equilibrium (PNE) for the
contestants, and propose a polynomial-time algorithm to compute an
$\epsilon$-approximate PNE. In the scenario where designers simultaneously
decide the participants and biases, the subgame perfect equilibrium (SPE) may
not exist. Nonetheless, when designers' decisions are made in two substages,
the existence of SPE is established. In the scenario where designers can hold
multiple contests, we show that the SPE always exists under mild conditions and
can be computed efficiently.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11954" title="Abstract">arXiv:2312.11954</a> [<a href="/pdf/2312.11954" title="Download PDF">pdf</a>, <a href="/format/2312.11954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial AutoMixup
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Huafeng Qin</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=El-Yacoubi%2C+M+A">Mounim A. El-Yacoubi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinbo Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Data mixing augmentation has been widely applied to improve the
generalization ability of deep neural networks. Recently, offline data mixing
augmentation, e.g. handcrafted and saliency information-based mixup, has been
gradually replaced by automatic mixing approaches. Through minimizing two
sub-tasks, namely, mixed sample generation and mixup classification in an
end-to-end way, AutoMix significantly improves accuracy on image classification
tasks. However, as the optimization objective is consistent for the two
sub-tasks, this approach is prone to generating consistent instead of diverse
mixed samples, which results in overfitting for target task training. In this
paper, we propose AdAutomixup, an adversarial automatic mixup augmentation
approach that generates challenging samples to train a robust classifier for
image classification, by alternatively optimizing the classifier and the mixup
sample generator. AdAutomixup comprises two modules, a mixed example generator,
and a target classifier. The mixed sample generator aims to produce hard mixed
examples to challenge the target classifier while the target classifier`s aim
is to learn robust features from hard mixed examples to improve generalization.
To prevent the collapse of the inherent meanings of images, we further
introduce an exponential moving average (EMA) teacher and cosine similarity to
train AdAutomixup in an end-to-end way. Extensive experiments on seven image
benchmarks consistently prove that our approach outperforms the state of the
art in various classification scenarios.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11955" title="Abstract">arXiv:2312.11955</a> [<a href="/pdf/2312.11955" title="Download PDF">pdf</a>, <a href="/format/2312.11955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vertical Symbolic Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+N">Nan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Nasim%2C+M">Md Nasim</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Y">Yexiang Xue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2306.08057">arXiv:2306.08057</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Automating scientific discovery has been a grand goal of Artificial
Intelligence (AI) and will bring tremendous societal impact. Learning symbolic
expressions from experimental data is a vital step in AI-driven scientific
discovery. Despite exciting progress, most endeavors have focused on the
horizontal discovery paths, i.e., they directly search for the best expression
in the full hypothesis space involving all the independent variables.
Horizontal paths are challenging due to the exponentially large hypothesis
space involving all the independent variables. We propose Vertical Symbolic
Regression (VSR) to expedite symbolic regression. The VSR starts by fitting
simple expressions involving a few independent variables under controlled
experiments where the remaining variables are held constant. It then extends
the expressions learned in previous rounds by adding new independent variables
and using new control variable experiments allowing these variables to vary.
The first few steps in vertical discovery are significantly cheaper than the
horizontal path, as their search is in reduced hypothesis spaces involving a
small set of variables. As a consequence, vertical discovery has the potential
to supercharge state-of-the-art symbolic regression approaches in handling
complex equations with many contributing factors. Theoretically, we show that
the search space of VSR can be exponentially smaller than that of horizontal
approaches when learning a class of expressions. Experimentally, VSR
outperforms several baselines in learning symbolic expressions involving many
independent variables.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11958" title="Abstract">arXiv:2312.11958</a> [<a href="/pdf/2312.11958" title="Download PDF">pdf</a>, <a href="/format/2312.11958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Traffic Load Prediction and Power Consumption Reduction for Multi-band  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diouf%2C+N">Ndolane Diouf</a>, 
<a href="/search/cs?searchtype=author&query=Anamuro%2C+C+V">Cesar Vargas Anamuro</a> (ADOPNET, IMT Atlantique - SRCD), 
<a href="/search/cs?searchtype=author&query=Gueguen%2C+C">C&#xe9;dric Gueguen</a> (UR, IRISA), 
<a href="/search/cs?searchtype=author&query=Ndong%2C+M">Massa Ndong</a>, 
<a href="/search/cs?searchtype=author&query=Talla%2C+K">Kharouna Talla</a>, 
<a href="/search/cs?searchtype=author&query=Lagrange%2C+X">Xavier Lagrange</a> (ADOPNET, IRISA-D2, IMT Atlantique - SRCD)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Symposium On Wireless Personal Multimedia Communications, Nov 2023, Tampa, United States
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Energy is a major expense issue for mobile operators. In the case of wireless
networks, base stations have been identified as the main source of energy
consumption. In this paper, we study the energy consumption reduction problem
based on real measurements for a commercial multi-band LTE network.
Specifically, we are interested in sleep modes to turn off certain frequency
bands during low traffic periods and consequently reduce power consumption. We
determine the number of frequency bands really needed at each time period. The
frequency bands that are not needed can be disabled to reduce energy
consumption. In order to allow the operator to predict how many bands can be
switched off without major impact on the quality of service, we propose to use
a deep learning algorithm, such as Long-Short Term Memory (LSTM). Based on the
captured data traces, we have shown that the proposed LSTM model can save an
average of 8% to 21% of the energy consumption during working days.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11960" title="Abstract">arXiv:2312.11960</a> [<a href="/pdf/2312.11960" title="Download PDF">pdf</a>, <a href="/ps/2312.11960" title="Download PostScript">ps</a>, <a href="/format/2312.11960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Offensive Alliances in Signed Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhidan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Fernau%2C+H">Henning Fernau</a>, 
<a href="/search/cs?searchtype=author&query=Mann%2C+K">Kevin Mann</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xingqin Qi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">Signed graphs have been introduced to enrich graph structures expressing
relationships between persons or general social entities, introducing edge
signs to reflect the nature of the relationship, e.g., friendship or enmity.
Independently, offensive alliances have been defined and studied for
undirected, unsigned graphs. We join both lines of research and define
offensive alliances in signed graphs, hence considering the nature of
relationships. Apart from some combinatorial results, mainly on k-balanced and
k-anti-balanced signed graphs (where the latter is a newly introduced family of
signed graphs), we focus on the algorithmic complexity of finding smallest
offensive alliances, looking at a number of parameterizations. While the
parameter solution size leads to an FPT result for unsigned graphs, we obtain
W[2]-completeness for the signed setting. We introduce new parameters for
signed graphs, e.g., distance to weakly balanced signed graphs, that could be
of independent interest. We show that these parameters yield FPT results. Here,
we make use of the recently introduced parameter neighborhood diversity for
signed graphs.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11963" title="Abstract">arXiv:2312.11963</a> [<a href="/pdf/2312.11963" title="Download PDF">pdf</a>, <a href="/ps/2312.11963" title="Download PostScript">ps</a>, <a href="/format/2312.11963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enumerating Defensive Alliances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhidan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Fernau%2C+H">Henning Fernau</a>, 
<a href="/search/cs?searchtype=author&query=Mann%2C+K">Kevin Mann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">In this paper, we study the task of enumerating (and counting) locally and
globally minimal defensive alliances in graphs. We consider general graphs as
well as special graph classes. From an input-sensitive perspective, our
presented algorithms are mostly optimal.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11967" title="Abstract">arXiv:2312.11967</a> [<a href="/pdf/2312.11967" title="Download PDF">pdf</a>, <a href="/format/2312.11967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context Disentangling and Prototype Inheriting for Robust Visual  Grounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wei Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuejing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Lu Jin</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jinhui Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zechao Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual grounding (VG) aims to locate a specific target in an image based on a
given language query. The discriminative information from context is important
for distinguishing the target from other objects, particularly for the targets
that have the same category as others. However, most previous methods
underestimate such information. Moreover, they are usually designed for the
standard scene (without any novel object), which limits their generalization to
the open-vocabulary scene. In this paper, we propose a novel framework with
context disentangling and prototype inheriting for robust visual grounding to
handle both scenes. Specifically, the context disentangling disentangles the
referent and context features, which achieves better discrimination between
them. The prototype inheriting inherits the prototypes discovered from the
disentangled visual features by a prototype bank to fully utilize the seen
data, especially for the open-vocabulary scene. The fused features, obtained by
leveraging Hadamard product on disentangled linguistic and visual features of
prototypes to avoid sharp adjusting the importance between the two types of
features, are then attached with a special token and feed to a vision
Transformer encoder for bounding box regression. Extensive experiments are
conducted on both standard and open-vocabulary scenes. The performance
comparisons indicate that our method outperforms the state-of-the-art methods
in both scenarios. {The code is available at
https://github.com/WayneTomas/TransCP.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11969" title="Abstract">arXiv:2312.11969</a> [<a href="/pdf/2312.11969" title="Download PDF">pdf</a>, <a href="/format/2312.11969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GroupMixNorm Layer for Learning Fair Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pandey%2C+A">Anubha Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Rai%2C+A">Aditi Rai</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+M">Maneet Singh</a>, 
<a href="/search/cs?searchtype=author&query=Bhatt%2C+D">Deepak Bhatt</a>, 
<a href="/search/cs?searchtype=author&query=Bhowmik%2C+T">Tanmoy Bhowmik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures, Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Recent research has identified discriminatory behavior of automated
prediction algorithms towards groups identified on specific protected
attributes (e.g., gender, ethnicity, age group, etc.). When deployed in
real-world scenarios, such techniques may demonstrate biased predictions
resulting in unfair outcomes. Recent literature has witnessed algorithms for
mitigating such biased behavior mostly by adding convex surrogates of fairness
metrics such as demographic parity or equalized odds in the loss function,
which are often not easy to estimate. This research proposes a novel
in-processing based GroupMixNorm layer for mitigating bias from deep learning
models. The GroupMixNorm layer probabilistically mixes group-level feature
statistics of samples across different groups based on the protected attribute.
The proposed method improves upon several fairness metrics with minimal impact
on overall accuracy. Analysis on benchmark tabular and image datasets
demonstrates the efficacy of the proposed method in achieving state-of-the-art
performance. Further, the experimental analysis also suggests the robustness of
the GroupMixNorm layer against new protected attributes during inference and
its utility in eliminating bias from a pre-trained network.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11970" title="Abstract">arXiv:2312.11970</a> [<a href="/pdf/2312.11970" title="Download PDF">pdf</a>, <a href="/format/2312.11970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models Empowered Agent-based Modeling and Simulation: A  Survey and Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chen Gao</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+X">Xiaochong Lan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Nian Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jingtao Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhilun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Fengli Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Agent-based modeling and simulation has evolved as a powerful tool for
modeling complex systems, offering insights into emergent behaviors and
interactions among diverse agents. Integrating large language models into
agent-based modeling and simulation presents a promising avenue for enhancing
simulation capabilities. This paper surveys the landscape of utilizing large
language models in agent-based modeling and simulation, examining their
challenges and promising future directions. In this survey, since this is an
interdisciplinary field, we first introduce the background of agent-based
modeling and simulation and large language model-empowered agents. We then
discuss the motivation for applying large language models to agent-based
simulation and systematically analyze the challenges in environment perception,
human alignment, action generation, and evaluation. Most importantly, we
provide a comprehensive overview of the recent works of large language
model-empowered agent-based modeling and simulation in multiple scenarios,
which can be divided into four domains: cyber, physical, social, and hybrid,
covering simulation of both real-world and virtual environments. Finally, since
this area is new and quickly evolving, we discuss the open problems and
promising future directions.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11972" title="Abstract">arXiv:2312.11972</a> [<a href="/pdf/2312.11972" title="Download PDF">pdf</a>, <a href="/format/2312.11972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expressive Forecasting of 3D Whole-body Human Motions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+P">Pengxiang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Q">Qiongjie Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mengyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haofan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Donglin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human motion forecasting, with the goal of estimating future human behavior
over a period of time, is a fundamental task in many real-world applications.
However, existing works typically concentrate on predicting the major joints of
the human body without considering the delicate movements of the human hands.
In practical applications, hand gesture plays an important role in human
communication with the real world, and expresses the primary intention of human
beings. In this work, we are the first to formulate a whole-body human pose
forecasting task, which jointly predicts the future body and hand activities.
Correspondingly, we propose a novel Encoding-Alignment-Interaction (EAI)
framework that aims to predict both coarse (body joints) and fine-grained
(gestures) activities collaboratively, enabling expressive and
cross-facilitated forecasting of 3D whole-body human motions. Specifically, our
model involves two key constituents: cross-context alignment (XCA) and
cross-context interaction (XCI). Considering the heterogeneous information
within the whole-body, XCA aims to align the latent features of various human
components, while XCI focuses on effectively capturing the context interaction
among the human components. We conduct extensive experiments on a
newly-introduced large-scale benchmark and achieve state-of-the-art
performance. The code is public for research purposes at
https://github.com/Dingpx/EAI.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11973" title="Abstract">arXiv:2312.11973</a> [<a href="/pdf/2312.11973" title="Download PDF">pdf</a>, <a href="/format/2312.11973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Learning: Forget-free Winning Subnetworks for Video  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+H">Haeyong Kang</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+J">Jaehong Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+S+J">Sung Ju Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+C+D">Chang D. Yoo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2303.14962">arXiv:2303.14962</a>, <a href="/abs/2306.11305">arXiv:2306.11305</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Inspired by the Regularized Lottery Ticket Hypothesis (RLTH), which
highlights the presence of competitive subnetworks within dense networks for
continual learning tasks, we introduce Winning Subnetworks (WSN). This approach
utilizes reused weights in dense networks to enhance learning in Task
Incremental Learning (TIL) scenarios. To mitigate overfitting in Few-Shot Class
Incremental Learning (FSCIL), we have developed WSN variants referred to as the
Soft subnetwork (SoftNet). Furthermore, addressing WSN's limitation of sparse
reused weights in Video Incremental Learning (VIL), we propose the Fourier
Subneural Operator (FSO). The FSO, operating in Fourier space, adaptively and
compactly encodes videos, discovering reusable subnetworks with diverse
bandwidths. We have applied FSO's Fourier representations to various continual
learning contexts, including VIL, TIL, and FSCIL. Our extensive experiments
across these scenarios demonstrate FSO's remarkable efficacy in continual
learning, significantly enhancing task performance at various convolutional
representational levels: it boosts performance in the higher layers for TIL and
FSCIL and the lower layers for VIL.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11974" title="Abstract">arXiv:2312.11974</a> [<a href="/pdf/2312.11974" title="Download PDF">pdf</a>, <a href="/format/2312.11974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ms-senet: Enhancing Speech Emotion Recognition Through Multi-scale  Feature Fusion With Squeeze-and-excitation Blocks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengbo Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yulun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dichucheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yuanzhong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaoxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+H">Haojun Fei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Human-Computer Interaction (cs.HC); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Speech Emotion Recognition (SER) has become a growing focus of research in
human-computer interaction. Spatiotemporal features play a crucial role in SER,
yet current research lacks comprehensive spatiotemporal feature learning. This
paper focuses on addressing this gap by proposing a novel approach. In this
paper, we employ Convolutional Neural Network (CNN) with varying kernel sizes
for spatial and temporal feature extraction. Additionally, we introduce
Squeeze-and-Excitation (SE) modules to capture and fuse multi-scale features,
facilitating effective information fusion for improved emotion recognition and
a deeper understanding of the temporal evolution of speech emotion. Moreover,
we employ skip connections and Spatial Dropout (SD) layers to prevent
overfitting and increase the model's depth. Our method outperforms the previous
state-of-the-art method, achieving an average UAR and WAR improvement of 1.62%
and 1.32%, respectively, across six benchmark SER datasets. Further experiments
demonstrated that our method can fully extract spatiotemporal features in
low-resource conditions.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11976" title="Abstract">arXiv:2312.11976</a> [<a href="/pdf/2312.11976" title="Download PDF">pdf</a>, <a href="/format/2312.11976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Model Meets New Normals: Test-time Adaptation for Unsupervised  Time-series Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dongmin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sunghyun Park</a>, 
<a href="/search/cs?searchtype=author&query=Choo%2C+J">Jaegul Choo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024, 17 pages, <a href="https://github.com/carrtesy/M2N2">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Time-series anomaly detection deals with the problem of detecting anomalous
timesteps by learning normality from the sequence of observations. However, the
concept of normality evolves over time, leading to a "new normal problem",
where the distribution of normality can be changed due to the distribution
shifts between training and test data. This paper highlights the prevalence of
the new normal problem in unsupervised time-series anomaly detection studies.
To tackle this issue, we propose a simple yet effective test-time adaptation
strategy based on trend estimation and a self-supervised approach to learning
new normalities during inference. Extensive experiments on real-world
benchmarks demonstrate that incorporating the proposed strategy into the
anomaly detector consistently improves the model's performance compared to the
baselines, leading to robustness to the distribution shifts.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11983" title="Abstract">arXiv:2312.11983</a> [<a href="/pdf/2312.11983" title="Download PDF">pdf</a>, <a href="/format/2312.11983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fluctuation-based Adaptive Structured Pruning for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+Y">Yongqi An</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+M">Ming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinqiao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Network Pruning is a promising way to address the huge computing resource
demands of the deployment and inference of Large Language Models (LLMs).
Retraining-free is important for LLMs' pruning methods. However, almost all of
the existing retraining-free pruning approaches for LLMs focus on unstructured
pruning, which requires specific hardware support for acceleration. In this
paper, we propose a novel retraining-free structured pruning framework for
LLMs, named FLAP (FLuctuation-based Adaptive Structured Pruning). It is
hardware-friendly by effectively reducing storage and enhancing inference
speed. For effective structured pruning of LLMs, we highlight three critical
elements that demand the utmost attention: formulating structured importance
metrics, adaptively searching the global compressed model, and implementing
compensation mechanisms to mitigate performance loss. First, FLAP determines
whether the output feature map is easily recoverable when a column of weight is
removed, based on the fluctuation pruning metric. Then it standardizes the
importance scores to adaptively determine the global compressed model
structure. At last, FLAP adds additional bias terms to recover the output
feature maps using the baseline values. We thoroughly evaluate our approach on
a variety of language benchmarks. Without any retraining, our method
significantly outperforms the state-of-the-art methods, including LLM-Pruner
and the extension of Wanda in structured pruning. The code is released at
https://github.com/CASIA-IVA-Lab/FLAP.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11985" title="Abstract">arXiv:2312.11985</a> [<a href="/pdf/2312.11985" title="Download PDF">pdf</a>, <a href="/format/2312.11985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Climate Change from Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hongyin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+P">Prayag Tiwari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Climate change presents significant challenges to the global community, and
it is imperative to raise widespread awareness of the climate crisis and
educate users about low-carbon living. Artificial intelligence, particularly
large language models (LLMs), have emerged as powerful tools in mitigating the
climate crisis, leveraging their extensive knowledge, broad user base, and
natural language interaction capabilities. However, despite the growing body of
research on climate change, there is a lack of comprehensive assessments of
climate crisis knowledge within LLMs. This paper aims to resolve this gap by
proposing an automatic evaluation framework. We employ a hybrid approach to
data acquisition that combines data synthesis and manual collection to compile
a diverse set of questions related to the climate crisis. These questions cover
various aspects of climate change, including its causes, impacts, mitigation
strategies, and adaptation measures. We then evaluate the model knowledge
through prompt engineering based on the collected questions and generated
answers. We propose a set of comprehensive metrics to evaluate the climate
crisis knowledge, incorporating indicators from 10 different perspectives.
Experimental results show that our method is effective in evaluating the
knowledge of LLMs regarding the climate crisis. We evaluate several
state-of-the-art LLMs and find that their knowledge falls short in terms of
timeliness.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11988" title="Abstract">arXiv:2312.11988</a> [<a href="/pdf/2312.11988" title="Download PDF">pdf</a>, <a href="/format/2312.11988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Xpert: Empowering Incident Management with Query Recommendations via  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuxuan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaoyun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shilin He</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhihao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+M">Minghua Ma</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+S">Si Qin</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yu Kang</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+Y">Yingnong Dang</a>, 
<a href="/search/cs?searchtype=author&query=Rajmohan%2C+S">Saravan Rajmohan</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qingwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a reseach paper at ICSE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Programming Languages (cs.PL)

</div>
<p class="mathjax">Large-scale cloud systems play a pivotal role in modern IT infrastructure.
However, incidents occurring within these systems can lead to service
disruptions and adversely affect user experience. To swiftly resolve such
incidents, on-call engineers depend on crafting domain-specific language (DSL)
queries to analyze telemetry data. However, writing these queries can be
challenging and time-consuming. This paper presents a thorough empirical study
on the utilization of queries of KQL, a DSL employed for incident management in
a large-scale cloud management system at Microsoft. The findings obtained
underscore the importance and viability of KQL queries recommendation to
enhance incident management.
<br />Building upon these valuable insights, we introduce Xpert, an end-to-end
machine learning framework that automates KQL recommendation process. By
leveraging historical incident data and large language models, Xpert generates
customized KQL queries tailored to new incidents. Furthermore, Xpert
incorporates a novel performance metric called Xcore, enabling a thorough
evaluation of query quality from three comprehensive perspectives. We conduct
extensive evaluations of Xpert, demonstrating its effectiveness in offline
settings. Notably, we deploy Xpert in the real production environment of a
large-scale incident management system in Microsoft, validating its efficiency
in supporting incident management. To the best of our knowledge, this paper
represents the first empirical study of its kind, and Xpert stands as a
pioneering DSL query recommendation framework designed for incident management.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11994" title="Abstract">arXiv:2312.11994</a> [<a href="/pdf/2312.11994" title="Download PDF">pdf</a>, <a href="/format/2312.11994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Diffusion Noise Can Serve As Universal Motion Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karunratanakul%2C+K">Korrawe Karunratanakul</a>, 
<a href="/search/cs?searchtype=author&query=Preechakul%2C+K">Konpat Preechakul</a>, 
<a href="/search/cs?searchtype=author&query=Aksan%2C+E">Emre Aksan</a>, 
<a href="/search/cs?searchtype=author&query=Beeler%2C+T">Thabo Beeler</a>, 
<a href="/search/cs?searchtype=author&query=Suwajanakorn%2C+S">Supasorn Suwajanakorn</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Siyu Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://korrawe.github.io/dno-project/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose Diffusion Noise Optimization (DNO), a new method that effectively
leverages existing motion diffusion models as motion priors for a wide range of
motion-related tasks. Instead of training a task-specific diffusion model for
each new task, DNO operates by optimizing the diffusion latent noise of an
existing pre-trained text-to-motion model. Given the corresponding latent noise
of a human motion, it propagates the gradient from the target criteria defined
on the motion space through the whole denoising process to update the diffusion
latent noise. As a result, DNO supports any use cases where criteria can be
defined as a function of motion. In particular, we show that, for motion
editing and control, DNO outperforms existing methods in both achieving the
objective and preserving the motion content. DNO accommodates a diverse range
of editing modes, including changing trajectory, pose, joint locations, or
avoiding newly added obstacles. In addition, DNO is effective in motion
denoising and completion, producing smooth and realistic motion from noisy and
partial inputs. DNO achieves these results at inference time without the need
for model retraining, offering great versatility for any defined reward or loss
function on the motion representation.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11995" title="Abstract">arXiv:2312.11995</a> [<a href="/pdf/2312.11995" title="Download PDF">pdf</a>, <a href="/ps/2312.11995" title="Download PostScript">ps</a>, <a href="/format/2312.11995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Infinite families of MDS and almost MDS codes from BCH codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haojie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xiwang Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, the sufficient and necessary condition for the minimum
distance of the BCH codes over $\mathbb{F}_q$ with length $q+1$ and designed
distance 3 to be 3 and 4 are provided. Let $d$ be the minimum distance of the
BCH code $\mathcal{C}_{(q,q+1,3,h)}$. We prove that (1) for any $q$, $d=3$ if
and only if $\gcd(2h+1,q+1)&gt;1$; (2) for $q$ odd, $d=4$ if and only if
$\gcd(2h+1,q+1)=1$. By combining these conditions with the dimensions of these
codes, the parameters of this BCH code are determined completely when $q$ is
odd. Moreover, several infinite families of MDS and almost MDS (AMDS) codes are
shown. Furthermore, the sufficient conditions for these AMDS codes to be
distance-optimal and dimension-optimal locally repairable codes are presented.
Based on these conditions, several examples are also given.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11996" title="Abstract">arXiv:2312.11996</a> [<a href="/pdf/2312.11996" title="Download PDF">pdf</a>, <a href="/format/2312.11996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Responsible AI Use: Considerations for Sustainability Impact  Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thelisson%2C+E">Eva Thelisson</a>, 
<a href="/search/cs?searchtype=author&query=Mika%2C+G">Grzegorz Mika</a>, 
<a href="/search/cs?searchtype=author&query=Schneiter%2C+Q">Quentin Schneiter</a>, 
<a href="/search/cs?searchtype=author&query=Padh%2C+K">Kirtan Padh</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+H">Himanshu Verma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">As AI/ML models, including Large Language Models, continue to scale with
massive datasets, so does their consumption of undeniably limited natural
resources, and impact on society. In this collaboration between AI,
Sustainability, HCI and legal researchers, we aim to enable a transition to
sustainable AI development by enabling stakeholders across the AI value chain
to assess and quantitfy the environmental and societal impact of AI. We present
the ESG Digital and Green Index (DGI), which offers a dashboard for assessing a
company's performance in achieving sustainability targets. This includes
monitoring the efficiency and sustainable use of limited natural resources
related to AI technologies (water, electricity, etc). It also addresses the
societal and governance challenges related to AI. The DGI creates incentives
for companies to align their pathway with the Sustainable Development Goals
(SDGs). The value, challenges and limitations of our methodology and findings
are discussed in the paper.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11997" title="Abstract">arXiv:2312.11997</a> [<a href="/pdf/2312.11997" title="Download PDF">pdf</a>, <a href="/format/2312.11997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coreference Graph Guidance for Mind-Map Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhuowei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+M">Mengting Hu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yinhao Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhen Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures. Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Mind-map generation aims to process a document into a hierarchical structure
to show its central idea and branches. Such a manner is more conducive to
understanding the logic and semantics of the document than plain text.
Recently, a state-of-the-art method encodes the sentences of a document
sequentially and converts them to a relation graph via sequence-to-graph.
Though this method is efficient to generate mind-maps in parallel, its
mechanism focuses more on sequential features while hardly capturing structural
information. Moreover, it's difficult to model long-range semantic relations.
In this work, we propose a coreference-guided mind-map generation network
(CMGN) to incorporate external structure knowledge. Specifically, we construct
a coreference graph based on the coreference semantic relationship to introduce
the graph structure information. Then we employ a coreference graph encoder to
mine the potential governing relations between sentences. In order to exclude
noise and better utilize the information of the coreference graph, we adopt a
graph enhancement module in a contrastive learning manner. Experimental results
demonstrate that our model outperforms all the existing methods. The case study
further proves that our model can more accurately and concisely reveal the
structure and semantics of a document. Code and data are available at
https://github.com/Cyno2232/CMGN.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12000" title="Abstract">arXiv:2312.12000</a> [<a href="/pdf/2312.12000" title="Download PDF">pdf</a>, <a href="/format/2312.12000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusing More Objects for Semi-Supervised Domain Adaptation with Less  Labeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+den+Heuvel%2C+L">Leander van den Heuvel</a>, 
<a href="/search/cs?searchtype=author&query=Burghouts%2C+G">Gertjan Burghouts</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D+W">David W. Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Englebienne%2C+G">Gwenn Englebienne</a>, 
<a href="/search/cs?searchtype=author&query=van+Rooij%2C+S+B">Sabina B. van Rooij</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, Workshop on DiffusionModels, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">For object detection, it is possible to view the prediction of bounding boxes
as a reverse diffusion process. Using a diffusion model, the random bounding
boxes are iteratively refined in a denoising step, conditioned on the image. We
propose a stochastic accumulator function that starts each run with random
bounding boxes and combines the slightly different predictions. We empirically
verify that this improves detection performance. The improved detections are
leveraged on unlabelled images as weighted pseudo-labels for semi-supervised
learning. We evaluate the method on a challenging out-of-domain test set. Our
method brings significant improvements and is on par with human-selected
pseudo-labels, while not requiring any human involvement.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12002" title="Abstract">arXiv:2312.12002</a> [<a href="/pdf/2312.12002" title="Download PDF">pdf</a>, <a href="/format/2312.12002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling and Vanquishing Goroutine Leaks in Enterprise Microservices: A  Dynamic Analysis Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saioc%2C+G">Georgian-Vlad Saioc</a>, 
<a href="/search/cs?searchtype=author&query=Shirchenko%2C+D">Dmitriy Shirchenko</a>, 
<a href="/search/cs?searchtype=author&query=Chabbi%2C+M">Milind Chabbi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures, to be published in CGO 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Performance (cs.PF); Programming Languages (cs.PL)

</div>
<p class="mathjax">Go is a modern programming language gaining popularity in enterprise
microservice systems. Concurrency is a first-class citizen in Go with
lightweight ``goroutines'' as the building blocks of concurrent execution. Go
advocates message-passing to communicate and synchronize among goroutines.
Improper use of message passing in Go can result in ``partial deadlocks'' , a
subtle concurrency bug where a blocked sender (receiver) never finds a
corresponding receiver (sender), causing the blocked goroutine to leak memory,
via its call stack and objects reachable from the stack.
<br />In this paper, we systematically study the prevalence of message passing and
the resulting partial deadlocks in 75 million lines of Uber's Go monorepo
hosting over 2500 microservices. We develop two lightweight, dynamic analysis
tools: Goleak and LeakProf, designed to identify partial deadlocks. Goleak
detects partial deadlocks during unit testing and prevents the introduction of
new bugs. Conversely, LeakProf uses goroutine profiles obtained from services
deployed in production to pinpoint intricate bugs arising from complex control
flow, unexplored interleavings, or the absence of test coverage. We share our
experience and insights deploying these tools in developer workflows in a large
industrial setting. Using Goleak we unearthed 857 pre-existing goroutine leaks
in the legacy code and prevented the introduction of around 260 new leaks over
one year period. Using LeakProf we found 24 and fixed 21 goroutine leaks, which
resulted in up to 34% speedup and 9.2x memory reduction in some of our
production services.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12006" title="Abstract">arXiv:2312.12006</a> [<a href="/pdf/2312.12006" title="Download PDF">pdf</a>, <a href="/ps/2312.12006" title="Download PostScript">ps</a>, <a href="/format/2312.12006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can ChatGPT be Your Personal Medical Assistant?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biswas%2C+M+R">Md. Rafiul Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+A">Ashhadul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+Z">Zubair Shah</a>, 
<a href="/search/cs?searchtype=author&query=Zaghouani%2C+W">Wajdi Zaghouani</a>, 
<a href="/search/cs?searchtype=author&query=Belhaouari%2C+S+B">Samir Brahim Belhaouari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 7 figures, two tables, Accepted on The International Symposium on Foundation and Large Language Models (FLLM2023)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The International Symposium on Foundation and Large Language
  Models (FLLM2023) https://fllm-conference.org/2023/
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">The advanced large language model (LLM) ChatGPT has shown its potential in
different domains and remains unbeaten due to its characteristics compared to
other LLMs. This study aims to evaluate the potential of using a fine-tuned
ChatGPT model as a personal medical assistant in the Arabic language. To do so,
this study uses publicly available online questions and answering datasets in
Arabic language. There are almost 430K questions and answers for 20
disease-specific categories. GPT-3.5-turbo model was fine-tuned with a portion
of this dataset. The performance of this fine-tuned model was evaluated through
automated and human evaluation. The automated evaluations include perplexity,
coherence, similarity, and token count. Native Arabic speakers with medical
knowledge evaluated the generated text by calculating relevance, accuracy,
precision, logic, and originality. The overall result shows that ChatGPT has a
bright future in medical assistance.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12009" title="Abstract">arXiv:2312.12009</a> [<a href="/pdf/2312.12009" title="Download PDF">pdf</a>, <a href="/format/2312.12009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Preference Inference using Language Models and Probabilistic  Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Piriyakulkij%2C+T">Top Piriyakulkij</a>, 
<a href="/search/cs?searchtype=author&query=Kuleshov%2C+V">Volodymyr Kuleshov</a>, 
<a href="/search/cs?searchtype=author&query=Ellis%2C+K">Kevin Ellis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Actively inferring user preferences, for example by asking good questions, is
important for any human-facing decision-making system. Active inference allows
such systems to adapt and personalize themselves to nuanced individual
preferences. To enable this ability for instruction-tuned large language models
(LLMs), one may prompt them to ask users questions to infer their preferences,
transforming the language models into more robust, interactive systems.
However, out of the box, these models are not efficient at extracting
preferences: the questions they generate are not informative, requiring a high
number of user interactions and impeding the usability of the downstream
system. In this work, we introduce an inference-time algorithm that helps LLMs
quickly infer preferences by using more informative questions. Our algorithm
uses a probabilistic model whose conditional distributions are defined by
prompting an LLM, and returns questions that optimize expected entropy and
expected model change. Results in a simplified interactive web shopping setting
with real product items show that an LLM equipped with our entropy reduction
algorithm outperforms baselines with the same underlying LLM on task
performance while using fewer user interactions.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12010" title="Abstract">arXiv:2312.12010</a> [<a href="/pdf/2312.12010" title="Download PDF">pdf</a>, <a href="/format/2312.12010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flexible categorization using formal concept analysis and  Dempster-Shafer theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boersma%2C+M">Marcel Boersma</a>, 
<a href="/search/cs?searchtype=author&query=Manoorkar%2C+K">Krishna Manoorkar</a>, 
<a href="/search/cs?searchtype=author&query=Palmigiano%2C+A">Alessandra Palmigiano</a>, 
<a href="/search/cs?searchtype=author&query=Panettiere%2C+M">Mattia Panettiere</a>, 
<a href="/search/cs?searchtype=author&query=Tzimoulis%2C+A">Apostolos Tzimoulis</a>, 
<a href="/search/cs?searchtype=author&query=Wijnberg%2C+N">Nachoem Wijnberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Categorization of business processes is an important part of auditing. Large
amounts of transactional data in auditing can be represented as transactions
between financial accounts using weighted bipartite graphs. We view such
bipartite graphs as many-valued formal contexts, which we use to obtain
explainable categorization of these business processes in terms of financial
accounts involved in a business process by using methods in formal concept
analysis. We use Dempster-Shafer mass functions to represent agendas showing
different interest in different set of financial accounts. We also model some
possible deliberation scenarios between agents with different interrogative
agendas to reach an aggregated agenda and categorization. The framework
developed in this paper provides a formal ground to obtain and study
explainable categorizations from the data represented as bipartite graphs
according to the agendas of different agents in an organization (e.g. an audit
firm), and interaction between these through deliberation. We use this
framework to describe a machine-leaning meta algorithm for outlier detection
and classification which can provide local and global explanations of its
result and demonstrate it through an outlier detection algorithm.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12012" title="Abstract">arXiv:2312.12012</a> [<a href="/pdf/2312.12012" title="Download PDF">pdf</a>, <a href="/format/2312.12012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient and Private Federated Trajectory Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yuxiang Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zimu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+Y">Yongxin Tong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Federated Trajectory Matching (FTM) is gaining increasing importance in big
trajectory data analytics, supporting diverse applications such as public
health, law enforcement, and emergency response. FTM retrieves trajectories
that match with a query trajectory from a large-scale trajectory database,
while safeguarding the privacy of trajectories in both the query and the
database. A naive solution to FTM is to process the query through Secure
Multi-Party Computation (SMC) across the entire database, which is inherently
secure yet inevitably slow due to the massive secure operations. A promising
acceleration strategy is to filter irrelevant trajectories from the database
based on the query, thus reducing the SMC operations. However, a key challenge
is how to publish the query in a way that both preserves privacy and enables
efficient trajectory filtering. In this paper, we design GIST, a novel
framework for efficient Federated Trajectory Matching. GIST is grounded in
Geo-Indistinguishability, a privacy criterion dedicated to locations. It
employs a new privacy mechanism for the query that facilitates efficient
trajectory filtering. We theoretically prove the privacy guarantee of the
mechanism and the accuracy of the filtering strategy of GIST. Extensive
evaluations on five real datasets show that GIST is significantly faster and
incurs up to 3 orders of magnitude lower communication cost than the
state-of-the-arts.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12013" title="Abstract">arXiv:2312.12013</a> [<a href="/pdf/2312.12013" title="Download PDF">pdf</a>, <a href="/ps/2312.12013" title="Download PostScript">ps</a>, <a href="/format/2312.12013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A final value problem with a non-local and a source term: regularization  by truncation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mondal%2C+S">Subhankar Mondal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Comments are welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">This paper is concerned with recovering the solution of a final value problem
associated with a parabolic equation involving a non linear source and a
non-local term, which to the best of our knowledge has not been studied
earlier. It is shown that the considered problem is ill-posed, and thus, some
regularization method has to be employed in order to obtain stable
approximations. In this regard, we obtain regularized approximations by solving
some non linear integral equations which is derived by considering a truncated
version of the Fourier expansion of the sought solution. Under different Gevrey
smoothness assumptions on the exact solution, we provide parameter choice
strategies and obtain the error estimates. A key tool in deriving such
estimates is a version of Gr{\"o}nwalls' inequality for iterated integrals,
which perhaps, is proposed and analysed for the first time.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12014" title="Abstract">arXiv:2312.12014</a> [<a href="/pdf/2312.12014" title="Download PDF">pdf</a>, <a href="/format/2312.12014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Students&#x27; and Professionals&#x27; Perceived Creativity In Software  Engineering: A Comparative Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Groeneveld%2C+W">Wouter Groeneveld</a>, 
<a href="/search/cs?searchtype=author&query=Luyten%2C+L">Laurens Luyten</a>, 
<a href="/search/cs?searchtype=author&query=Vennekens%2C+J">Joost Vennekens</a>, 
<a href="/search/cs?searchtype=author&query=Aerts%2C+K">Kris Aerts</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> European Journal of Engineering Education, 19 December 2023, page
  1-18
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Creativity is a critical skill that professional software engineers leverage
to tackle difficult problems. In higher education, multiple efforts have been
made to spark creative skills of engineering students. However, creativity is a
vague concept that is open to interpretation. Furthermore, studies have shown
that there is a gap in perception and implementation of creativity between
industry and academia. To better understand the role of creativity in software
engineering (SE), we interviewed 33 professionals via four focus groups and 10
SE students. Our results reveal 45 underlying topics related to creativity.
When comparing the perception of students versus professionals, we discovered
fundamental differences, grouped into five themes: the creative environment,
application of techniques, creative collaboration, nature vs nurture, and the
perceived value of creativity. As our aim is to use these findings to install
and further encourage creative problem solving in higher education, we have
included a list of implications for educational practice.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12016" title="Abstract">arXiv:2312.12016</a> [<a href="/pdf/2312.12016" title="Download PDF">pdf</a>, <a href="/ps/2312.12016" title="Download PostScript">ps</a>, <a href="/format/2312.12016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Potentials of ChatGPT for Annotating Vaccine Related Tweets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biswas%2C+M+R">Md. Rafiul Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Mohsen%2C+F">Farida Mohsen</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+Z">Zubair Shah</a>, 
<a href="/search/cs?searchtype=author&query=Zaghouani%2C+W">Wajdi Zaghouani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures, two tables, accepted on The International Symposium on Foundation and Large Language Models (FLLM2023)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> https://fllm-conference.org/2023/
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">This study evaluates ChatGPT's performance in annotating vaccine-related
Arabic tweets by comparing its annotations with human annotations. A dataset of
2,100 tweets representing various factors contributing to vaccine hesitancy was
examined. Two domain experts annotated the data, with a third resolving
conflicts. ChatGPT was then employed to annotate the same dataset using
specific prompts for each factor. The ChatGPT annotations were evaluated
through zero-shot, one-shot, and few-shot learning tests, with an average
accuracy of 82.14%, 83.85%, and 85.57%, respectively. Precision averaged around
86%, minimizing false positives. The average recall and F1-score ranged from
0.74 to 0.80 and 0.65 to 0.93, respectively. AUC for zero-shot, one-shot, and
few-shot learning was 0.79, 0.80, and 0.83. In cases of ambiguity, both human
annotators and ChatGPT faced challenges. These findings suggest that ChatGPT
holds promise as a tool for annotating vaccine-related tweets.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12021" title="Abstract">arXiv:2312.12021</a> [<a href="/pdf/2312.12021" title="Download PDF">pdf</a>, <a href="/format/2312.12021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synergistic Anchored Contrastive Pre-training for Few-Shot Relation  Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=DaLuo">DaLuo</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Y">Yanglei Gan</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+R">Rui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+R">Run Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yuxiang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Wannian Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Few-shot Relation Extraction (FSRE) aims to extract relational facts from a
sparse set of labeled corpora. Recent studies have shown promising results in
FSRE by employing Pre-trained Language Models (PLMs) within the framework of
supervised contrastive learning, which considers both instances and label
facts. However, how to effectively harness massive instance-label pairs to
encompass the learned representation with semantic richness in this learning
paradigm is not fully explored. To address this gap, we introduce a novel
synergistic anchored contrastive pre-training framework. This framework is
motivated by the insight that the diverse viewpoints conveyed through
instance-label pairs capture incomplete yet complementary intrinsic textual
semantics. Specifically, our framework involves a symmetrical contrastive
objective that encompasses both sentence-anchored and label-anchored
contrastive losses. By combining these two losses, the model establishes a
robust and uniform representation space. This space effectively captures the
reciprocal alignment of feature distributions among instances and relational
facts, simultaneously enhancing the maximization of mutual information across
diverse perspectives within the same relation. Experimental results demonstrate
that our framework achieves significant performance enhancements compared to
baseline models in downstream FSRE tasks. Furthermore, our approach exhibits
superior adaptability to handle the challenges of domain shift and zero-shot
relation extraction. Our code is available online at
https://github.com/AONE-NLP/FSRE-SaCon.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12026" title="Abstract">arXiv:2312.12026</a> [<a href="/pdf/2312.12026" title="Download PDF">pdf</a>, <a href="/format/2312.12026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Approximate Skolem Function Counter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaw%2C+A">Arijit Shaw</a>, 
<a href="/search/cs?searchtype=author&query=Juba%2C+B">Brendan Juba</a>, 
<a href="/search/cs?searchtype=author&query=Meel%2C+K+S">Kuldeep S. Meel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">One approach to probabilistic inference involves counting the number of
models of a given Boolean formula. Here, we are interested in inferences
involving higher-order objects, i.e., functions. We study the following task:
Given a Boolean specification between a set of inputs and outputs, count the
number of functions of inputs such that the specification is met. Such
functions are called Skolem functions.
<br />Our study is motivated by the recent development of scalable approaches to
Boolean function synthesis. This stands in relation to our problem analogously
to the relationship between Boolean satisfiability and the model counting
problem. Yet, counting Skolem functions poses considerable new challenges. From
the complexity-theoretic standpoint, counting Skolem functions is not only
$\#P$-hard; it is quite unlikely to have an FPRAS (Fully Polynomial Randomized
Approximation Scheme) as the problem of even synthesizing one Skolem function
remains challenging, even given access to an NP oracle.
<br />The primary contribution of this work is the first algorithm,
$\mathsf{SkolemFC}$, that computes the number of Skolem functions.
$\mathsf{SkolemFC}$ relies on technical connections between counting functions
and propositional model counting: our algorithm makes a linear number of calls
to an approximate model counter and computes an estimate of the number of
Skolem functions with theoretical guarantees. Our prototype displays impressive
scalability, handling benchmarks comparably to state-of-the-art Skolem function
synthesis engines, even though counting all such functions ostensibly poses a
greater challenge than synthesizing a single function.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12028" title="Abstract">arXiv:2312.12028</a> [<a href="/pdf/2312.12028" title="Download PDF">pdf</a>, <a href="/format/2312.12028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EyePreserve: Identity-Preserving Iris Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+S+K">Siamul Karim Khan</a>, 
<a href="/search/cs?searchtype=author&query=Tinsley%2C+P">Patrick Tinsley</a>, 
<a href="/search/cs?searchtype=author&query=Mitcheff%2C+M">Mahsa Mitcheff</a>, 
<a href="/search/cs?searchtype=author&query=Flynn%2C+P">Patrick Flynn</a>, 
<a href="/search/cs?searchtype=author&query=Bowyer%2C+K+W">Kevin W. Bowyer</a>, 
<a href="/search/cs?searchtype=author&query=Czajka%2C+A">Adam Czajka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Synthesis of same-identity biometric iris images, both for existing and
non-existing identities while preserving the identity across a wide range of
pupil sizes, is complex due to intricate iris muscle constriction mechanism,
requiring a precise model of iris non-linear texture deformations to be
embedded into the synthesis pipeline. This paper presents the first method of
fully data-driven, identity-preserving, pupil size-varying s ynthesis of iris
images. This approach is capable of synthesizing images of irises with
different pupil sizes representing non-existing identities as well as
non-linearly deforming the texture of iris images of existing subjects given
the segmentation mask of the target iris image. Iris recognition experiments
suggest that the proposed deformation model not only preserves the identity
when changing the pupil size but offers better similarity between same-identity
iris samples with significant differences in pupil size, compared to
state-of-the-art linear and non-linear (bio-mechanical-based) iris deformation
models. Two immediate applications of the proposed approach are: (a) synthesis
of, or enhancement of the existing biometric datasets for iris recognition,
mimicking those acquired with iris sensors, and (b) helping forensic human
experts in examining iris image pairs with significant differences in pupil
dilation. Source codes and weights of the models are made available with the
paper.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12030" title="Abstract">arXiv:2312.12030</a> [<a href="/pdf/2312.12030" title="Download PDF">pdf</a>, <a href="/format/2312.12030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Accurate Guided Diffusion Sampling through Symplectic Adjoint  Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jiachun Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hanshu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Liew%2C+J+H">Jun Hao Liew</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiashi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+V+Y+F">Vincent Y. F. Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Training-free guided sampling in diffusion models leverages off-the-shelf
pre-trained networks, such as an aesthetic evaluation model, to guide the
generation process. Current training-free guided sampling algorithms obtain the
guidance energy function based on a one-step estimate of the clean image.
However, since the off-the-shelf pre-trained networks are trained on clean
images, the one-step estimation procedure of the clean image may be inaccurate,
especially in the early stages of the generation process in diffusion models.
This causes the guidance in the early time steps to be inaccurate. To overcome
this problem, we propose Symplectic Adjoint Guidance (SAG), which calculates
the gradient guidance in two inner stages. Firstly, SAG estimates the clean
image via $n$ function calls, where $n$ serves as a flexible hyperparameter
that can be tailored to meet specific image quality requirements. Secondly, SAG
uses the symplectic adjoint method to obtain the gradients accurately and
efficiently in terms of the memory requirements. Extensive experiments
demonstrate that SAG generates images with higher qualities compared to the
baselines in both guided image and video generation tasks.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12036" title="Abstract">arXiv:2312.12036</a> [<a href="/pdf/2312.12036" title="Download PDF">pdf</a>, <a href="/format/2312.12036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LHManip: A Dataset for Long-Horizon Language-Grounded Manipulation Tasks  in Cluttered Tabletop Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ceola%2C+F">Federico Ceola</a>, 
<a href="/search/cs?searchtype=author&query=Natale%2C+L">Lorenzo Natale</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%BCnderhauf%2C+N">Niko S&#xfc;nderhauf</a>, 
<a href="/search/cs?searchtype=author&query=Rana%2C+K">Krishan Rana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IJRR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Instructing a robot to complete an everyday task within our homes has been a
long-standing challenge for robotics. While recent progress in
language-conditioned imitation learning and offline reinforcement learning has
demonstrated impressive performance across a wide range of tasks, they are
typically limited to short-horizon tasks -- not reflective of those a home
robot would be expected to complete. While existing architectures have the
potential to learn these desired behaviours, the lack of the necessary
long-horizon, multi-step datasets for real robotic systems poses a significant
challenge. To this end, we present the Long-Horizon Manipulation (LHManip)
dataset comprising 200 episodes, demonstrating 20 different manipulation tasks
via real robot teleoperation. The tasks entail multiple sub-tasks, including
grasping, pushing, stacking and throwing objects in highly cluttered
environments. Each task is paired with a natural language instruction and
multi-camera viewpoints for point-cloud or NeRF reconstruction. In total, the
dataset comprises 176,278 observation-action pairs which form part of the Open
X-Embodiment dataset. The full LHManip dataset is made publicly available
\href{https://github.com/fedeceola/LHManip}{here}.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12037" title="Abstract">arXiv:2312.12037</a> [<a href="/pdf/2312.12037" title="Download PDF">pdf</a>, <a href="/format/2312.12037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Founder-GPT: Self-play to evaluate the Founder-Idea fit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+S">Sichao Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Ihlamur%2C+Y">Yigit Ihlamur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">This research introduces an innovative evaluation method for the
"founder-idea" fit in early-stage startups, utilizing advanced large language
model techniques to assess founders' profiles against their startup ideas to
enhance decision-making. Embeddings, self-play, tree-of-thought, and
critique-based refinement techniques show early promising results that each
idea's success patterns are unique and they should be evaluated based on the
context of the founder's background.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12042" title="Abstract">arXiv:2312.12042</a> [<a href="/pdf/2312.12042" title="Download PDF">pdf</a>, <a href="/format/2312.12042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pose2Gaze: Generating Realistic Human Gaze Behaviour from Full-body  Poses using an Eye-body Coordination Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhiming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiahui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Schmitt%2C+S">Syn Schmitt</a>, 
<a href="/search/cs?searchtype=author&query=Bulling%2C+A">Andreas Bulling</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While generating realistic body movements, e.g., for avatars in virtual
reality, is widely studied in computer vision and graphics, the generation of
eye movements that exhibit realistic coordination with the body remains
under-explored. We first report a comprehensive analysis of the coordination of
human eye and full-body movements during everyday activities based on data from
the MoGaze and GIMO datasets. We show that eye gaze has strong correlations
with head directions and also full-body motions and there exists a noticeable
time delay between body and eye movements. Inspired by the analyses, we then
present Pose2Gaze -- a novel eye-body coordination model that first uses a
convolutional neural network and a spatio-temporal graph convolutional neural
network to extract features from head directions and full-body poses
respectively and then applies a convolutional neural network to generate
realistic eye movements. We compare our method with state-of-the-art methods
that predict eye gaze only from head movements for three different generation
tasks and demonstrate that Pose2Gaze significantly outperforms these baselines
on both datasets with an average improvement of 26.4% and 21.6% in mean angular
error, respectively. Our findings underline the significant potential of
cross-modal human gaze behaviour analysis and modelling.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12044" title="Abstract">arXiv:2312.12044</a> [<a href="/pdf/2312.12044" title="Download PDF">pdf</a>, <a href="/format/2312.12044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XLand-MiniGrid: Scalable Meta-Reinforcement Learning Environments in JAX
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nikulin%2C+A">Alexander Nikulin</a>, 
<a href="/search/cs?searchtype=author&query=Kurenkov%2C+V">Vladislav Kurenkov</a>, 
<a href="/search/cs?searchtype=author&query=Zisman%2C+I">Ilya Zisman</a>, 
<a href="/search/cs?searchtype=author&query=Agarkov%2C+A">Artem Agarkov</a>, 
<a href="/search/cs?searchtype=author&query=Sinii%2C+V">Viacheslav Sinii</a>, 
<a href="/search/cs?searchtype=author&query=Kolesnikov%2C+S">Sergey Kolesnikov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023, Workshop, Source code: <a href="https://github.com/corl-team/xland-minigrid">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We present XLand-MiniGrid, a suite of tools and grid-world environments for
meta-reinforcement learning research inspired by the diversity and depth of
XLand and the simplicity and minimalism of MiniGrid. XLand-Minigrid is written
in JAX, designed to be highly scalable, and can potentially run on GPU or TPU
accelerators, democratizing large-scale experimentation with limited resources.
To demonstrate the generality of our library, we have implemented some
well-known single-task environments as well as new meta-learning environments
capable of generating $10^8$ distinct tasks. We have empirically shown that the
proposed environments can scale up to $2^{13}$ parallel instances on the GPU,
reaching tens of millions of steps per second.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12045" title="Abstract">arXiv:2312.12045</a> [<a href="/pdf/2312.12045" title="Download PDF">pdf</a>, <a href="/format/2312.12045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Plane Wave Discontinuous Galerkin methods for scattering by periodic  structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Monforte%2C+A+M">Armando Maria Monforte</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This thesis explores the application of Plane Wave Discontinuous Galerkin
(PWDG) methods for the numerical simulation of electromagnetic scattering by
periodic structures. Periodic structures play a pivotal role in various
engineering and scientific applications, including antenna design, metamaterial
characterization, and photonic crystal analysis. Understanding and accurately
predicting the scattering behavior of electromagnetic waves from such
structures is crucial in optimizing their performance and advancing
technological advancements.
<br />The thesis commences with an overview of the theoretical foundations of
electromagnetic scattering by periodic structures. This theoretical
dissertation serves as the basis for formulating the PWDG method within the
context of wave equation. The DtN operator is presented and it is used to
derive a suitable boundary condition.
<br />The numerical implementation of PWDG methods is discussed in detail,
emphasizing key aspects such as basis function selection and boundary
conditions. The algorithm's efficiency is assessed through numerical
experiments.
<br />We then present the DtN-PWDG method, which is discussed in detail and is used
to derive numerical solutions of the scattering problem. A comparison with the
finite element method (FEM) is presented.
<br />In conclusion, this thesis demonstrates that PWDG methods are a powerful tool
for simulating electromagnetic scattering by periodic structures.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12049" title="Abstract">arXiv:2312.12049</a> [<a href="/pdf/2312.12049" title="Download PDF">pdf</a>, <a href="/format/2312.12049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EncryIP: A Practical Encryption-Based Framework for Model Intellectual  Property Protection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mu%2C+X">Xin Mu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhengan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+J">Junzuo Lai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yehong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yue Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the rapidly growing digital economy, protecting intellectual property (IP)
associated with digital products has become increasingly important. Within this
context, machine learning (ML) models, being highly valuable digital assets,
have gained significant attention for IP protection. This paper introduces a
practical encryption-based framework called \textit{EncryIP}, which seamlessly
integrates a public-key encryption scheme into the model learning process. This
approach enables the protected model to generate randomized and confused
labels, ensuring that only individuals with accurate secret keys, signifying
authorized users, can decrypt and reveal authentic labels. Importantly, the
proposed framework not only facilitates the protected model to multiple
authorized users without requiring repetitive training of the original ML model
with IP protection methods but also maintains the model's performance without
compromising its accuracy. Compared to existing methods like watermark-based,
trigger-based, and passport-based approaches, \textit{EncryIP} demonstrates
superior effectiveness in both training protected models and efficiently
detecting the unauthorized spread of ML models.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12050" title="Abstract">arXiv:2312.12050</a> [<a href="/pdf/2312.12050" title="Download PDF">pdf</a>, <a href="/format/2312.12050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extension of the Dip-test Repertoire -- Efficient and Differentiable  p-value Calculation for Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bauer%2C+L+G+M">Lena G. M. Bauer</a>, 
<a href="/search/cs?searchtype=author&query=Leiber%2C+C">Collin Leiber</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%B6hm%2C+C">Christian B&#xf6;hm</a>, 
<a href="/search/cs?searchtype=author&query=Plant%2C+C">Claudia Plant</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 2023 SIAM International Conference on Data
  Mining (SDM) (pp. 109-117). Society for Industrial and Applied Mathematics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Over the last decade, the Dip-test of unimodality has gained increasing
interest in the data mining community as it is a parameter-free statistical
test that reliably rates the modality in one-dimensional samples. It returns a
so called Dip-value and a corresponding probability for the sample's
unimodality (Dip-p-value). These two values share a sigmoidal relationship.
However, the specific transformation is dependent on the sample size. Many
Dip-based clustering algorithms use bootstrapped look-up tables translating
Dip- to Dip-p-values for a certain limited amount of sample sizes. We propose a
specifically designed sigmoid function as a substitute for these
state-of-the-art look-up tables. This accelerates computation and provides an
approximation of the Dip- to Dip-p-value transformation for every single sample
size. Further, it is differentiable and can therefore easily be integrated in
learning schemes using gradient descent. We showcase this by exploiting our
function in a novel subspace clustering algorithm called Dip'n'Sub. We
highlight in extensive experiments the various benefits of our proposal.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12053" title="Abstract">arXiv:2312.12053</a> [<a href="/pdf/2312.12053" title="Download PDF">pdf</a>, <a href="/ps/2312.12053" title="Download PostScript">ps</a>, <a href="/format/2312.12053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asynchronous multiplicative coarse-space correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gbikpi-Benissan%2C+G">Guillaume Gbikpi-Benissan</a>, 
<a href="/search/math?searchtype=author&query=Magoul%C3%A8s%2C+F">Fr&#xe9;d&#xe9;ric Magoul&#xe8;s</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper introduces the multiplicative variant of the recently proposed
asynchronous additive coarse-space correction method. Definition of an
asynchronous extension of multiplicative correction is not straightforward,
however, our analysis allows for usual asynchronous programming approaches.
General asynchronous iterative models are explicitly devised both for shared or
replicated coarse problems and for centralized or distributed ones. Convergence
conditions are derived and shown to be satisfied for M-matrices, as also done
for the additive case. Implementation aspects are discussed, which reveal the
need for non-blocking synchronization for building the successive
right-hand-side vectors of the coarse problem. Optionally, a parameter allows
for applying each coarse solution a maximum number of times, which has an
impact on the algorithm efficiency. Numerical results on a high-speed
homogeneous cluster confirm the practical efficiency of the asynchronous
two-level method over its synchronous counterpart, even when it is not the case
for the underlying one-level methods.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12056" title="Abstract">arXiv:2312.12056</a> [<a href="/pdf/2312.12056" title="Download PDF">pdf</a>, <a href="/format/2312.12056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Word Closure-Based Metamorphic Testing for Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaoyuan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shuo Jin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Songqiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+S">Shing-Chi Cheung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Due to the limitation "The abstract field cannot be longer than 1,920 characters", the abstract here is shorter than that in the PDF file
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">With the wide application of machine translation, the testing of Machine
Translation Systems (MTSs) has attracted much attention. Recent works apply
Metamorphic Testing (MT) to address the oracle problem in MTS testing. Existing
MT methods for MTS generally follow the workflow of input transformation and
output relation comparison, which generates a follow-up input sentence by
mutating the source input and compares the source and follow-up output
translations to detect translation errors, respectively. These methods use
various input transformations to generate test case pairs and have successfully
triggered numerous translation errors. However, they have limitations in
performing fine-grained and rigorous output relation comparison and thus may
report false alarms and miss true errors. In this paper, we propose a word
closure-based output comparison method to address the limitations of the
existing MTS MT methods. Specifically, we first build a new comparison unit
called word closure, where each closure includes a group of correlated input
and output words in the test case pair. Word closures suggest the linkages
between the appropriate fragment in the source output translation and its
counterpart in the follow-up output for comparison. Next, we compare the
semantics on the level of word closure to identify the translation errors. In
this way, we perform a fine-grained and rigorous semantic comparison for the
outputs and thus realize more effective violation identification. We evaluate
our method with the test cases generated by five existing input transformations
and translation outputs from three popular MTSs. Results show that our method
significantly outperforms the existing works in violation identification by
improving the precision and recall and achieving an average increase of 29.8%
in F1 score. It also helps to increase the F1 score of translation error
localization by 35.9%.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12057" title="Abstract">arXiv:2312.12057</a> [<a href="/pdf/2312.12057" title="Download PDF">pdf</a>, <a href="/format/2312.12057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monitoring Auditable Claims in the Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sorokin%2C+L">Lev Sorokin</a>, 
<a href="/search/cs?searchtype=author&query=Schoepp%2C+U">Ulrich Schoepp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">When deploying mission-critical systems in the cloud, where deviations may
have severe consequences, the assurance of critical decisions becomes
essential. Typical cloud systems are operated by third parties and are built on
complex software stacks consisting of e.g., Kubernetes, Istio, or Kafka, which
due to their size are difficult to be verified. Nevertheless, one needs to make
sure that mission-critical choices are made correctly. We propose a flexible
runtime monitoring approach that is independent of the implementation of the
observed system that allows to monitor safety and data-related properties. Our
approach is based on combining distributed Datalog-based programs with
tamper-proof storage based on Trillian to verify the premises of
safety-critical actions. The approach can be seen as a generalization of the
Certificate Transparency project. We apply our approach to an industrial use
case that uses a cloud infrastructure for orchestrating unmanned air vehicles.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12063" title="Abstract">arXiv:2312.12063</a> [<a href="/pdf/2312.12063" title="Download PDF">pdf</a>, <a href="/format/2312.12063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource-efficient Generative Mobile Edge Networks in 6G Era:  Fundamentals, Framework and Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+B">Bingkun Lai</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Jinbo Wen</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiawen Kang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Hongyang Du</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+J">Jiangtian Nie</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+C">Changyan Yi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D+I">Dong In Kim</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shengli Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">As the next-generation wireless communication system, Sixth-Generation (6G)
technologies are emerging, enabling various mobile edge networks that can
revolutionize wireless communication and connectivity. By integrating
Generative Artificial Intelligence (GAI) with mobile edge networks, generative
mobile edge networks possess immense potential to enhance the intelligence and
efficiency of wireless communication networks. In this article, we propose the
concept of generative mobile edge networks and overview widely adopted GAI
technologies and their applications in mobile edge networks. We then discuss
the potential challenges faced by generative mobile edge networks in
resource-constrained scenarios. To address these challenges, we develop a
universal resource-efficient generative incentive mechanism framework, in which
we design resource-efficient methods for network overhead reduction, formulate
appropriate incentive mechanisms for the resource allocation problem, and
utilize Generative Diffusion Models (GDMs) to find the optimal incentive
mechanism solutions. Furthermore, we conduct a case study on
resource-constrained mobile edge networks, employing model partition for
efficient AI task offloading and proposing a GDM-based Stackelberg model to
motivate edge devices to contribute computing resources for mobile edge
intelligence. Finally, we propose several open directions that could contribute
to the future popularity of generative mobile edge networks.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12064" title="Abstract">arXiv:2312.12064</a> [<a href="/pdf/2312.12064" title="Download PDF">pdf</a>, <a href="/ps/2312.12064" title="Download PostScript">ps</a>, <a href="/format/2312.12064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MPI Planar Correction of Pulse Based ToF Cameras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pop%2C+M">Marian-Leontin Pop</a>, 
<a href="/search/cs?searchtype=author&query=Tamas%2C+L">Levente Tamas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Time-of-Flight (ToF) cameras are becoming popular in a wide span of areas
ranging from consumer-grade electronic devices to safety-critical industrial
robots. This is mainly due to their high frame rate, relative good precision
and the lowered costs. Although ToF cameras are in continuous development,
especially pulse-based variants, they still face different problems, including
spurious noise over the points or multipath inference (MPI). The latter can
cause deformed surfaces to manifest themselves on curved surfaces instead of
planar ones, making standard spatial data preprocessing, such as plane
extraction, difficult. In this paper, we focus on the MPI reduction problem
using Feature Pyramid Networks (FPN) which allow the mitigation of this type of
artifact for pulse-based ToF cameras. With our end-to-end network, we managed
to attenuate the MPI effect on planar surfaces using a learning-based method on
real ToF data. Both the custom dataset used for our model training as well as
the code is available on the author's Github homepage.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12065" title="Abstract">arXiv:2312.12065</a> [<a href="/pdf/2312.12065" title="Download PDF">pdf</a>, <a href="/format/2312.12065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PPO-Clip Attains Global Optimality: Towards Deeper Understandings of  Clipping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+N">Nai-Chieh Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+P">Ping-Chun Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+K">Kuo-Hao Ho</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+I">I-Chen Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Proximal Policy Optimization algorithm employing a clipped surrogate
objective (PPO-Clip) is a prominent exemplar of the policy optimization
methods. However, despite its remarkable empirical success, PPO-Clip lacks
theoretical substantiation to date. In this paper, we contribute to the field
by establishing the first global convergence results of a PPO-Clip variant in
both tabular and neural function approximation settings. Our findings highlight
the $O(1/\sqrt{T})$ min-iterate convergence rate specifically in the context of
neural function approximation. We tackle the inherent challenges in analyzing
PPO-Clip through three central concepts: (i) We introduce a generalized version
of the PPO-Clip objective, illuminated by its connection with the hinge loss.
(ii) Employing entropic mirror descent, we establish asymptotic convergence for
tabular PPO-Clip with direct policy parameterization. (iii) Inspired by the
tabular analysis, we streamline convergence analysis by introducing a two-step
policy improvement approach. This decouples policy search from complex neural
policy parameterization using a regression-based update scheme. Furthermore, we
gain deeper insights into the efficacy of PPO-Clip by interpreting these
generalized objectives. Our theoretical findings also mark the first
characterization of the influence of the clipping mechanism on PPO-Clip
convergence. Importantly, the clipping range affects only the pre-constant of
the convergence rate.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12067" title="Abstract">arXiv:2312.12067</a> [<a href="/pdf/2312.12067" title="Download PDF">pdf</a>, <a href="/format/2312.12067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimistic Policy Gradient in Multi-Player Markov Games with a Single  Controller: Convergence Beyond the Minty Property
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anagnostides%2C+I">Ioannis Anagnostides</a>, 
<a href="/search/cs?searchtype=author&query=Panageas%2C+I">Ioannis Panageas</a>, 
<a href="/search/cs?searchtype=author&query=Farina%2C+G">Gabriele Farina</a>, 
<a href="/search/cs?searchtype=author&query=Sandholm%2C+T">Tuomas Sandholm</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Policy gradient methods enjoy strong practical performance in numerous tasks
in reinforcement learning. Their theoretical understanding in multiagent
settings, however, remains limited, especially beyond two-player competitive
and potential Markov games. In this paper, we develop a new framework to
characterize optimistic policy gradient methods in multi-player Markov games
with a single controller. Specifically, under the further assumption that the
game exhibits an equilibrium collapse, in that the marginals of coarse
correlated equilibria (CCE) induce Nash equilibria (NE), we show convergence to
stationary $\epsilon$-NE in $O(1/\epsilon^2)$ iterations, where $O(\cdot)$
suppresses polynomial factors in the natural parameters of the game. Such an
equilibrium collapse is well-known to manifest itself in two-player zero-sum
Markov games, but also occurs even in a class of multi-player Markov games with
separable interactions, as established by recent work. As a result, we bypass
known complexity barriers for computing stationary NE when either of our
assumptions fails. Our approach relies on a natural generalization of the
classical Minty property that we introduce, which we anticipate to have further
applications beyond Markov games.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12068" title="Abstract">arXiv:2312.12068</a> [<a href="/pdf/2312.12068" title="Download PDF">pdf</a>, <a href="/format/2312.12068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PICNN: A Pathway towards Interpretable Convolutional Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wengang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiayi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Huilin Yin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qijun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+W">Wei Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Convolutional Neural Networks (CNNs) have exhibited great performance in
discriminative feature learning for complex visual tasks. Besides
discrimination power, interpretability is another important yet under-explored
property for CNNs. One difficulty in the CNN interpretability is that filters
and image classes are entangled. In this paper, we introduce a novel pathway to
alleviate the entanglement between filters and image classes. The proposed
pathway groups the filters in a late conv-layer of CNN into class-specific
clusters. Clusters and classes are in a one-to-one relationship. Specifically,
we use the Bernoulli sampling to generate the filter-cluster assignment matrix
from a learnable filter-class correspondence matrix. To enable end-to-end
optimization, we develop a novel reparameterization trick for handling the
non-differentiable Bernoulli sampling. We evaluate the effectiveness of our
method on ten widely used network architectures (including nine CNNs and a ViT)
and five benchmark datasets. Experimental results have demonstrated that our
method PICNN (the combination of standard CNNs with our proposed pathway)
exhibits greater interpretability than standard CNNs while achieving higher or
comparable discrimination power.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12069" title="Abstract">arXiv:2312.12069</a> [<a href="/pdf/2312.12069" title="Download PDF">pdf</a>, <a href="/format/2312.12069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low Dispersion Optimized High-Order Schemes for Discretization of  Non-Linear Straight and Mixed Second Derivative Terms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chandravamsi%2C+H">Hemanth Chandravamsi</a>, 
<a href="/search/math?searchtype=author&query=Frankel%2C+S+H">Steven H. Frankel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">In this paper, we propose a new set of midpoint-based high-order
discretization schemes for computing straight and mixed nonlinear second
derivative terms that appear in the compressible Navier-Stokes equations.
Firstly, we detail a set of conventional fourth and sixth-order baseline
schemes that utilize central midpoint derivatives for the calculation of second
derivatives terms. To enhance the spectral properties of the baseline schemes,
an optimization procedure is proposed that adjusts the order and truncation
error of the midpoint derivative approximation while still constraining the
same overall stencil width and scheme order. A new filter penalty term is
introduced into the midpoint derivative calculation to help achieve high
wavenumber accuracy and high-frequency damping in the mixed derivative
discretization. Fourier analysis performed on the both straight and mixed
second derivative terms show high spectral efficiency and minimal numerical
viscosity with no odd-even decoupling effect. Numerical validation of the
resulting optimized schemes is performed through various benchmark test cases
assessing their theoretical order of accuracy and solution resolution. The
results highlight that the present optimized schemes efficiently utilize the
inherent viscosity of the governing equations to achieve improved simulation
stability - a feature attributed to their superior spectral resolution in the
high wavenumber range. The method is also tested and applied to non-uniform
structured meshes in curvilinear coordinates, employing a supersonic impinging
jet test case.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12073" title="Abstract">arXiv:2312.12073</a> [<a href="/pdf/2312.12073" title="Download PDF">pdf</a>, <a href="/ps/2312.12073" title="Download PostScript">ps</a>, <a href="/format/2312.12073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing Cybersecurity Awareness Solutions for the Young People in  Rural Developing Countries: The Need for Diversity and Inclusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Quayyum%2C+F">Farzana Quayyum</a>, 
<a href="/search/cs?searchtype=author&query=Freberg%2C+G+N">Giske Naper Freberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Cybersecurity challenges and the need for awareness are well-recognized in
developed countries, but this still needs attention in less-developed
countries. With the expansion of technology, security concerns are also
becoming more prevalent worldwide. This paper presents a design and creation
research study exploring which factors we should consider when designing
cybersecurity awareness solutions for young people in developing countries. We
have developed prototypes of mini-cybersecurity awareness applications and
conducted a pilot study with eight participants (aged 16-30) from Gambia,
Eritrea, and Syria. Our findings show that factors like the influence of
culture and social constructs, literacy, and language competence, the way of
introducing cybersecurity terms and concepts, and the need for reflection are
essential to consider when designing and developing cybersecurity awareness
solutions for target users in developing countries. The findings of this study
will guide future researchers to design more inclusive cybersecurity awareness
solutions for users in developing countries.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12075" title="Abstract">arXiv:2312.12075</a> [<a href="/pdf/2312.12075" title="Download PDF">pdf</a>, <a href="/format/2312.12075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Property-Preserving Database Encryption Techniques in the  Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koppenwallner%2C+J">Johannes Koppenwallner</a>, 
<a href="/search/cs?searchtype=author&query=Schikuta%2C+E">Erich Schikuta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Databases (cs.DB)

</div>
<p class="mathjax">Outsourcing a relational database to the cloud offers several benefits,
including scalability, availability, and cost-effectiveness. However, there are
concerns about the security and confidentiality of the outsourced data. A
general approach here would be to encrypt the data with a standardized
encryption algorithm and then store the data only encrypted in the cloud. The
problem with this approach, however, is that with encryption, important
properties of the data such as sorting, format or comparability, which are
essential for the functioning of database queries, are lost. One solution to
this problem is the use of encryption algorithms, which also preserve these
properties in the encrypted data, thus enabling queries to encrypted data.
These algorithms range from simple algorithms like Caesar encryption to secure
algorithms like mOPE. The report at hand presents a survey on common encryption
techniques used for storing data in relation Cloud database services. It
presents the applied methods and identifies their characteristics.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12080" title="Abstract">arXiv:2312.12080</a> [<a href="/pdf/2312.12080" title="Download PDF">pdf</a>, <a href="/format/2312.12080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Subject-Aware Cropping by Outpainting Professional Photos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">James Hong</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Lu Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Gharbi%2C+M">Micha&#xeb;l Gharbi</a>, 
<a href="/search/cs?searchtype=author&query=Fisher%2C+M">Matthew Fisher</a>, 
<a href="/search/cs?searchtype=author&query=Fatahalian%2C+K">Kayvon Fatahalian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 24. Extended version with supplemental materials
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">How to frame (or crop) a photo often depends on the image subject and its
context; e.g., a human portrait. Recent works have defined the subject-aware
image cropping task as a nuanced and practical version of image cropping. We
propose a weakly-supervised approach (GenCrop) to learn what makes a
high-quality, subject-aware crop from professional stock images. Unlike
supervised prior work, GenCrop requires no new manual annotations beyond the
existing stock image collection. The key challenge in learning from this data,
however, is that the images are already cropped and we do not know what regions
were removed. Our insight is combine a library of stock images with a modern,
pre-trained text-to-image diffusion model. The stock image collection provides
diversity and its images serve as pseudo-labels for a good crop, while the
text-image diffusion model is used to out-paint (i.e., outward inpainting)
realistic uncropped images. Using this procedure, we are able to automatically
generate a large dataset of cropped-uncropped training pairs to train a
cropping model. Despite being weakly-supervised, GenCrop is competitive with
state-of-the-art supervised methods and significantly better than comparable
weakly-supervised baselines on quantitative and qualitative evaluation metrics.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12090" title="Abstract">arXiv:2312.12090</a> [<a href="/pdf/2312.12090" title="Download PDF">pdf</a>, <a href="/format/2312.12090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GazeMoDiff: Gaze-guided Diffusion Model for Stochastic Human Motion  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Haodong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhiming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Schmitt%2C+S">Syn Schmitt</a>, 
<a href="/search/cs?searchtype=author&query=Bulling%2C+A">Andreas Bulling</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human motion prediction is important for virtual reality (VR) applications,
e.g., for realistic avatar animation. Existing methods have synthesised body
motion only from observed past motion, despite the fact that human gaze is
known to correlate strongly with body movements and is readily available in
recent VR headsets. We present GazeMoDiff -- a novel gaze-guided denoising
diffusion model to generate stochastic human motions. Our method first uses a
graph attention network to learn the spatio-temporal correlations between eye
gaze and human movements and to fuse them into cross-modal gaze-motion
features. These cross-modal features are injected into a noise prediction
network via a cross-attention mechanism and progressively denoised to generate
realistic human full-body motions. Experimental results on the MoGaze and GIMO
datasets demonstrate that our method outperforms the state-of-the-art methods
by a large margin in terms of average displacement error (15.03% on MoGaze and
9.20% on GIMO). We further conducted an online user study to compare our method
with state-of-the-art methods and the responses from 23 participants validate
that the motions generated by our method are more realistic than those from
other methods. Taken together, our work makes a first important step towards
gaze-guided stochastic human motion prediction and guides future work on this
important topic in VR research.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12091" title="Abstract">arXiv:2312.12091</a> [<a href="/pdf/2312.12091" title="Download PDF">pdf</a>, <a href="/format/2312.12091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-Heterogeneous Federated Learning for Internet of Things: Enabling  Technologies and Future Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+B">Boyu Fan</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Siyang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+X">Xiang Su</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+P">Pan Hui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Internet of Things (IoT) interconnects a massive amount of devices,
generating heterogeneous data with diverse characteristics. IoT data emerges as
a vital asset for data-intensive IoT applications, such as healthcare, smart
city and predictive maintenance, harnessing the vast volume of heterogeneous
data to its maximum advantage. These applications leverage different Artificial
Intelligence (AI) algorithms to discover new insights. While machine learning
effectively uncovers implicit patterns through model training, centralizing IoT
data for training poses significant privacy and security concerns. Federated
Learning (FL) offers an promising solution, allowing IoT devices to conduct
local learning without sharing raw data with third parties. Model-heterogeneous
FL empowers clients to train models with varying complexities based on their
hardware capabilities, aligning with heterogeneity of devices in real-world IoT
environments. In this article, we review the state-of-the-art
model-heterogeneous FL methods and provide insights into their merits and
limitations. Moreover, we showcase their applicability to IoT and identify the
open problems and future directions. To the best of our knowledge, this is the
first article that focuses on the topic of model-heterogeneous FL for IoT.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12095" title="Abstract">arXiv:2312.12095</a> [<a href="/pdf/2312.12095" title="Download PDF">pdf</a>, <a href="/format/2312.12095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cautiously-Optimistic Knowledge Sharing for Cooperative Multi-Agent  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ba%2C+Y">Yanwen Ba</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinning Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kenli Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shigeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 19 figures, 6 tables, to be published in AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">While decentralized training is attractive in multi-agent reinforcement
learning (MARL) for its excellent scalability and robustness, its inherent
coordination challenges in collaborative tasks result in numerous interactions
for agents to learn good policies. To alleviate this problem, action advising
methods make experienced agents share their knowledge about what to do, while
less experienced agents strictly follow the received advice. However, this
method of sharing and utilizing knowledge may hinder the team's exploration of
better states, as agents can be unduly influenced by suboptimal or even adverse
advice, especially in the early stages of learning. Inspired by the fact that
humans can learn not only from the success but also from the failure of others,
this paper proposes a novel knowledge sharing framework called
Cautiously-Optimistic kNowledge Sharing (CONS). CONS enables each agent to
share both positive and negative knowledge and cautiously assimilate knowledge
from others, thereby enhancing the efficiency of early-stage exploration and
the agents' robustness to adverse advice. Moreover, considering the continuous
improvement of policies, agents value negative knowledge more in the early
stages of learning and shift their focus to positive knowledge in the later
stages. Our framework can be easily integrated into existing Q-learning based
methods without introducing additional training costs. We evaluate CONS in
several challenging multi-agent tasks and find it excels in environments where
optimal behavioral patterns are difficult to discover, surpassing the baselines
in terms of convergence rate and final performance.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12096" title="Abstract">arXiv:2312.12096</a> [<a href="/pdf/2312.12096" title="Download PDF">pdf</a>, <a href="/format/2312.12096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DLCA-Recon: Dynamic Loose Clothing Avatar Reconstruction from Monocular  Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Chunjie Luo</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+F">Fei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yusen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+E">Enxu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chunxia Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Reconstructing a dynamic human with loose clothing is an important but
difficult task. To address this challenge, we propose a method named DLCA-Recon
to create human avatars from monocular videos. The distance from loose clothing
to the underlying body rapidly changes in every frame when the human freely
moves and acts. Previous methods lack effective geometric initialization and
constraints for guiding the optimization of deformation to explain this
dramatic change, resulting in the discontinuous and incomplete reconstruction
surface. To model the deformation more accurately, we propose to initialize an
estimated 3D clothed human in the canonical space, as it is easier for
deformation fields to learn from the clothed human than from SMPL. With both
representations of explicit mesh and implicit SDF, we utilize the physical
connection information between consecutive frames and propose a dynamic
deformation field (DDF) to optimize deformation fields. DDF accounts for
contributive forces on loose clothing to enhance the interpretability of
deformations and effectively capture the free movement of loose clothing.
Moreover, we propagate SMPL skinning weights to each individual and refine pose
and skinning weights during the optimization to improve skinning
transformation. Based on more reasonable initialization and DDF, we can
simulate real-world physics more accurately. Extensive experiments on public
and our own datasets validate that our method can produce superior results for
humans with loose clothing compared to the SOTA methods.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12098" title="Abstract">arXiv:2312.12098</a> [<a href="/pdf/2312.12098" title="Download PDF">pdf</a>, <a href="/format/2312.12098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Generalization in LiDAR Semantic Segmentation Leveraged by  Density Discriminative Feature Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jaeyeul Kim</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+J">Jungwan Woo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jeonghoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Im%2C+S">Sunghoon Im</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While significant progress has been achieved in LiDAR-based perception,
domain generalization continues to present challenges, often resulting in
reduced performance when encountering unfamiliar datasets due to domain
discrepancies. One of the primary hurdles stems from the variability of LiDAR
sensors, leading to inconsistencies in point cloud density distribution. Such
inconsistencies can undermine the effectiveness of perception models. We
address this challenge by introducing a new approach that acknowledges a
fundamental characteristic of LiDAR: the variation in point density due to the
distance from the LiDAR to the scene, and the number of beams relative to the
field of view. Understanding this, we view each LiDAR's point cloud at various
distances as having distinct density distributions, which can be consistent
across different LiDAR models. With this insight, we propose the Density
Discriminative Feature Embedding (DDFE) module, crafted to specifically extract
features related to density while ensuring domain invariance across different
LiDAR sensors. In addition, we introduce a straightforward but effective
density augmentation technique, designed to broaden the density spectrum and
enhance the capabilities of the DDFE. The proposed DDFE stands out as a
versatile and lightweight domain generalization module. It can be seamlessly
integrated into various 3D backbone networks, consistently outperforming
existing state-of-the-art domain generalization approaches. We commit to
releasing the source code publicly to foster community collaboration and
advancement.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12100" title="Abstract">arXiv:2312.12100</a> [<a href="/pdf/2312.12100" title="Download PDF">pdf</a>, <a href="/format/2312.12100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VITA: &#x27;Carefully Chosen and Weighted Less&#x27; Is Better in Medication  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taeri Kim</a>, 
<a href="/search/cs?searchtype=author&query=Heo%2C+J">Jiho Heo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hongil Kim</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+K">Kijung Shin</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sang-Wook Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We address the medication recommendation problem, which aims to recommend
effective medications for a patient's current visit by utilizing information
(e.g., diagnoses and procedures) given at the patient's current and past
visits. While there exist a number of recommender systems designed for this
problem, we point out that they are challenged in accurately capturing the
relation (spec., the degree of relevance) between the current and each of the
past visits for the patient when obtaining her current health status, which is
the basis for recommending medications. To address this limitation, we propose
a novel medication recommendation framework, named VITA, based on the following
two novel ideas: (1) relevant-Visit selectIon; (2) Target-aware Attention.
Through extensive experiments using real-world datasets, we demonstrate the
superiority of VITA (spec., up to 5.56% higher accuracy, in terms of Jaccard,
than the best competitor) and the effectiveness of its two core ideas. The code
is available at https://github.com/jhheo0123/VITA.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12102" title="Abstract">arXiv:2312.12102</a> [<a href="/pdf/2312.12102" title="Download PDF">pdf</a>, <a href="/format/2312.12102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> I-CEE: Tailoring Explanations of Image Classifications Models to User  Expertise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rong%2C+Y">Yao Rong</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+P">Peizhu Qian</a>, 
<a href="/search/cs?searchtype=author&query=Unhelkar%2C+V">Vaibhav Unhelkar</a>, 
<a href="/search/cs?searchtype=author&query=Kasneci%2C+E">Enkelejda Kasneci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Effectively explaining decisions of black-box machine learning models is
critical to responsible deployment of AI systems that rely on them. Recognizing
their importance, the field of explainable AI (XAI) provides several techniques
to generate these explanations. Yet, there is relatively little emphasis on the
user (the explainee) in this growing body of work and most XAI techniques
generate "one-size-fits-all" explanations. To bridge this gap and achieve a
step closer towards human-centered XAI, we present I-CEE, a framework that
provides Image Classification Explanations tailored to User Expertise. Informed
by existing work, I-CEE explains the decisions of image classification models
by providing the user with an informative subset of training data (i.e.,
example images), corresponding local explanations, and model decisions.
However, unlike prior work, I-CEE models the informativeness of the example
images to depend on user expertise, resulting in different examples for
different users. We posit that by tailoring the example set to user expertise,
I-CEE can better facilitate users' understanding and simulatability of the
model. To evaluate our approach, we conduct detailed experiments in both
simulation and with human participants (N = 100) on multiple datasets.
Experiments with simulated users show that I-CEE improves users' ability to
accurately predict the model's decisions (simulatability) compared to
baselines, providing promising preliminary results. Experiments with human
participants demonstrate that our method significantly improves user
simulatability accuracy, highlighting the importance of human-centered XAI
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12105" title="Abstract">arXiv:2312.12105</a> [<a href="/pdf/2312.12105" title="Download PDF">pdf</a>, <a href="/format/2312.12105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preserving Data Secrecy in Decentralized Inter-organizational Process  Mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goretti%2C+V">Valerio Goretti</a>, 
<a href="/search/cs?searchtype=author&query=Basile%2C+D">Davide Basile</a>, 
<a href="/search/cs?searchtype=author&query=Barbaro%2C+L">Luca Barbaro</a>, 
<a href="/search/cs?searchtype=author&query=Di+Ciccio%2C+C">Claudio Di Ciccio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Inter-organizational business processes involve multiple independent
organizations collaborating to achieve mutual interests. Process mining
techniques have the potential to allow these organizations to enhance
operational efficiency, improve performance, and deepen the understanding of
their business based on the recorded process event data. However,
inter-organizational process mining faces substantial challenges, including
topical secrecy concerns: The involved organizations may not be willing to
expose their own data to run mining algorithms jointly with their counterparts
or third parties. In this paper, we introduce CONFINE, a novel approach that
unlocks process mining on multiple actors' process event data while
safeguarding the secrecy and integrity of the original records in an
inter-organizational business setting. To ensure that the phases of the
presented interaction protocol are secure and that the processed information is
hidden from involved and external actors alike, our approach resorts to a
decentralized architecture comprised of trusted applications running in Trusted
Execution Environments (TEEs). We show the feasibility of our solution by
showcasing its application to a healthcare scenario and evaluating our
implementation in terms of memory usage and scalability on real-world event
logs.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12107" title="Abstract">arXiv:2312.12107</a> [<a href="/pdf/2312.12107" title="Download PDF">pdf</a>, <a href="/format/2312.12107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphScope Flex: LEGO-like Graph Computing Stack
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tao He</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shuxian Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+L">Longbin Lai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongze Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Neng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xue Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lexiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiaojian Luo</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+B">Binqing Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+K">Ke Meng</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Sijie Shen</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+L">Li Su</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jingbo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenyuan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Weibin Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Siyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaoli Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Diwen Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Databases (cs.DB)

</div>
<p class="mathjax">Graph computing has become increasingly crucial in processing large-scale
graph data, with numerous systems developed for this purpose. Two years ago, we
introduced GraphScope as a system addressing a wide array of graph computing
needs, including graph traversal, analytics, and learning in one system. Since
its inception, GraphScope has achieved significant technological advancements
and gained widespread adoption across various industries. However, one key
lesson from this journey has been understanding the limitations of a
"one-size-fits-all" approach, especially when dealing with the diversity of
programming interfaces, applications, and data storage formats in graph
computing. In response to these challenges, we present GraphScope Flex, the
next iteration of GraphScope. GraphScope Flex is designed to be both
resource-efficient and cost-effective, while also providing flexibility and
user-friendliness through its LEGO-like modularity. This paper explores the
architectural innovations and fundamental design principles of GraphScope Flex,
all of which are direct outcomes of the lessons learned during our ongoing
development process. We validate the adaptability and efficiency of GraphScope
Flex with extensive evaluations on synthetic and real-world datasets. The
results show that GraphScope Flex achieves 2.4X throughput and up to 55.7X
speedup over other systems on the LDBC Social Network and Graphalytics
benchmarks, respectively. Furthermore, GraphScope Flex accomplishes up to a
2,400X performance gain in real-world applications, demonstrating its
proficiency across a wide range of graph computing scenarios with increased
effectiveness.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12108" title="Abstract">arXiv:2312.12108</a> [<a href="/pdf/2312.12108" title="Download PDF">pdf</a>, <a href="/format/2312.12108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Graph Error Detection with Contrastive Confidence Adaption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiangyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wei Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the 38th AAAI Conference on Artificial Intelligence (AAAI 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Knowledge graphs (KGs) often contain various errors. Previous works on
detecting errors in KGs mainly rely on triplet embedding from graph structure.
We conduct an empirical study and find that these works struggle to
discriminate noise from semantically-similar correct triplets. In this paper,
we propose a KG error detection model CCA to integrate both textual and graph
structural information from triplet reconstruction for better distinguishing
semantics. We design interactive contrastive learning to capture the
differences between textual and structural patterns. Furthermore, we construct
realistic datasets with semantically-similar noise and adversarial noise.
Experimental results demonstrate that CCA outperforms state-of-the-art
baselines, especially in detecting semantically-similar noise and adversarial
noise.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12111" title="Abstract">arXiv:2312.12111</a> [<a href="/pdf/2312.12111" title="Download PDF">pdf</a>, <a href="/format/2312.12111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing and Evaluating General-Purpose User Representations Based on  Behavioral Logs from a Measurement Process Perspective: A Case Study with  Snapchat
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+Q">Qixiang Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhihan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Barbieri%2C+F">Francesco Barbieri</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yozen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Neves%2C+L">Leonardo Neves</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D">Dong Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Oberski%2C+D+L">Daniel L. Oberski</a>, 
<a href="/search/cs?searchtype=author&query=Bos%2C+M+W">Maarten W. Bos</a>, 
<a href="/search/cs?searchtype=author&query=Dotsch%2C+R">Ron Dotsch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">In human-computer interaction, understanding user behaviors and tailoring
systems accordingly is pivotal. To this end, general-purpose user
representation learning based on behavior logs is emerging as a powerful tool
in user modeling, offering adaptability to various downstream tasks such as
item recommendations and ad conversion prediction, without the need to
fine-tune the upstream user model. While this methodology has shown promise in
contexts like search engines and e-commerce platforms, its fit for instant
messaging apps, a cornerstone of modern digital communication, remains largely
uncharted. These apps, with their distinct interaction patterns, data
structures, and user expectations, necessitate specialized attention. We
explore this user modeling approach with Snapchat data as a case study.
Furthermore, we introduce a novel design and evaluation framework rooted in the
principles of the Measurement Process Framework from social science research
methodology. Using this new framework, we design a Transformer-based user model
that can produce high-quality general-purpose user representations for instant
messaging platforms like Snapchat.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12112" title="Abstract">arXiv:2312.12112</a> [<a href="/pdf/2312.12112" title="Download PDF">pdf</a>, <a href="/format/2312.12112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curated LLM: Synergy of LLMs and Data Curation for tabular augmentation  in ultra low-data regimes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seedat%2C+N">Nabeel Seedat</a>, 
<a href="/search/cs?searchtype=author&query=Huynh%2C+N">Nicolas Huynh</a>, 
<a href="/search/cs?searchtype=author&query=van+Breugel%2C+B">Boris van Breugel</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Schaar%2C+M">Mihaela van der Schaar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> *Seedat &amp; Huynh contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Machine Learning (ML) in low-data settings remains an underappreciated yet
crucial problem. This challenge is pronounced in low-to-middle income countries
where access to large datasets is often limited or even absent. Hence, data
augmentation methods to increase the sample size of datasets needed for ML are
key to unlocking the transformative potential of ML in data-deprived regions
and domains. Unfortunately, the limited training set constrains traditional
tabular synthetic data generators in their ability to generate a large and
diverse augmented dataset needed for ML tasks. To address this technical
challenge, we introduce CLLM, which leverages the prior knowledge of Large
Language Models (LLMs) for data augmentation in the low-data regime. While
diverse, not all the data generated by LLMs will help increase utility for a
downstream task, as for any generative model. Consequently, we introduce a
principled curation process, leveraging learning dynamics, coupled with
confidence and uncertainty metrics, to obtain a high-quality dataset.
Empirically, on multiple real-world datasets, we demonstrate the superior
performance of LLMs in the low-data regime compared to conventional generators.
We further show our curation mechanism improves the downstream performance for
all generators, including LLMs. Additionally, we provide insights and
understanding into the LLM generation and curation mechanism, shedding light on
the features that enable them to output high-quality augmented datasets. CLLM
paves the way for wider usage of ML in data scarce domains and regions, by
allying the strengths of LLMs with a robust data-centric approach.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12115" title="Abstract">arXiv:2312.12115</a> [<a href="/pdf/2312.12115" title="Download PDF">pdf</a>, <a href="/format/2312.12115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shaping Up SHAP: Enhancing Stability through Layer-Wise Neighbor  Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kelodjou%2C+G">Gwladys Kelodjou</a>, 
<a href="/search/cs?searchtype=author&query=Roz%C3%A9%2C+L">Laurence Roz&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Masson%2C+V">V&#xe9;ronique Masson</a>, 
<a href="/search/cs?searchtype=author&query=Gal%C3%A1rraga%2C+L">Luis Gal&#xe1;rraga</a>, 
<a href="/search/cs?searchtype=author&query=Gaudel%2C+R">Romaric Gaudel</a>, 
<a href="/search/cs?searchtype=author&query=Tchuente%2C+M">Maurice Tchuente</a>, 
<a href="/search/cs?searchtype=author&query=Termier%2C+A">Alexandre Termier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Machine learning techniques, such as deep learning and ensemble methods, are
widely used in various domains due to their ability to handle complex
real-world tasks. However, their black-box nature has raised multiple concerns
about the fairness, trustworthiness, and transparency of computer-assisted
decision-making. This has led to the emergence of local post-hoc explainability
methods, which offer explanations for individual decisions made by black-box
algorithms. Among these methods, Kernel SHAP is widely used due to its
model-agnostic nature and its well-founded theoretical framework. Despite these
strengths, Kernel SHAP suffers from high instability: different executions of
the method with the same inputs can lead to significantly different
explanations, which diminishes the utility of post-hoc explainability. The
contribution of this paper is two-fold. On the one hand, we show that Kernel
SHAP's instability is caused by its stochastic neighbor selection procedure,
which we adapt to achieve full stability without compromising explanation
fidelity. On the other hand, we show that by restricting the neighbors
generation to perturbations of size 1 -- which we call the coalitions of Layer
1 -- we obtain a novel feature-attribution method that is fully stable,
efficient to compute, and still meaningful.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12116" title="Abstract">arXiv:2312.12116</a> [<a href="/pdf/2312.12116" title="Download PDF">pdf</a>, <a href="/format/2312.12116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Length 3 Check Digit Codes with Grouped Tags and Disjoint Coding  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dunning%2C+L+A">Larry A. Dunning</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> As of December 2023 no usable html version of this document is available
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In 1969 J. Verhoeff provided the first examples of a decimal error detecting
code using a single check digit to provide protection against all single,
transposition, and adjacent twin errors. The three codes he presented are
length 3-digit codes with 2 information digits. To date, the existence of a
length 4-digit code with 3 information digits having these properties remains
an open question. Existence of a 4-digit code would imply the existence of 10
disjoint 3-digit codes. Apparently, no pair of such disjoint 3-digit codes is
known. Phonetic errors, where 2-digit pairs of the forms X0 and 1X are
interchanged, are language dependent, but can often be eliminated.
<br />Alternate 3-digit codes are developed here which enhance the level of
protection beyond Verhoeff's codes while still optionally providing protection
against phonetic errors. Through almost-disjoint coding schemes, it is shown
how copies of these new codes can fill in the gap between such 3 and 4-digit
codes. The results are extended to other useful alphabet sizes such as 26 and
36 with stronger permutation of digits error detection, and to "tag codes"
where digits are grouped.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12118" title="Abstract">arXiv:2312.12118</a> [<a href="/pdf/2312.12118" title="Download PDF">pdf</a>, <a href="/format/2312.12118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iteration-Dependent Scaled Min-Sum Decoding for Low-Complexity Key  Reconciliation in CV-QKD
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cil%2C+E+E">Erdem Eray Cil</a>, 
<a href="/search/cs?searchtype=author&query=Schmalen%2C+L">Laurent Schmalen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted and to be presented at the Optical Fiber Communication Conference (OFC) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">We introduce an iteration-dependent scaled min-sum decoding for low-rate LDPC
codes in CV-QKD, achieving near-sum product algorithm performance with reduced
complexity, and facilitating CV-QKD hardware implementation.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12119" title="Abstract">arXiv:2312.12119</a> [<a href="/pdf/2312.12119" title="Download PDF">pdf</a>, <a href="/format/2312.12119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mindful Explanations: Prevalence and Impact of Mind Attribution in XAI  Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hindennach%2C+S">Susanne Hindennach</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Lei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Mileti%C4%87%2C+F">Filip Mileti&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Bulling%2C+A">Andreas Bulling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 6 figures, to be published in PACM HCI (CSCW '24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">When users perceive AI systems as mindful, independent agents, they hold them
responsible instead of the AI experts who created and designed these systems.
So far, it has not been studied whether explanations support this shift in
responsibility through the use of mind-attributing verbs like "to think". To
better understand the prevalence of mind-attributing explanations we analyse AI
explanations in 3,533 explainable AI (XAI) research articles from the Semantic
Scholar Open Research Corpus (S2ORC). Using methods from semantic shift
detection, we identify three dominant types of mind attribution: (1)
metaphorical (e.g. "to learn" or "to predict"), (2) awareness (e.g. "to
consider"), and (3) agency (e.g. "to make decisions"). We then analyse the
impact of mind-attributing explanations on awareness and responsibility in a
vignette-based experiment with 199 participants. We find that participants who
were given a mind-attributing explanation were more likely to rate the AI
system as aware of the harm it caused. Moreover, the mind-attributing
explanation had a responsibility-concealing effect: Considering the AI experts'
involvement lead to reduced ratings of AI responsibility for participants who
were given a non-mind-attributing or no explanation. In contrast, participants
who read the mind-attributing explanation still held the AI system responsible
despite considering the AI experts' involvement. Taken together, our work
underlines the need to carefully phrase explanations about AI systems in
scientific writing to reduce mind attribution and clearly communicate human
responsibility.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12121" title="Abstract">arXiv:2312.12121</a> [<a href="/pdf/2312.12121" title="Download PDF">pdf</a>, <a href="/format/2312.12121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Learning-Based Gyrocompassing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Engelsman%2C+D">Daniel Engelsman</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+I">Itzik Klein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Inertial navigation systems (INS) are widely used in both manned and
autonomous platforms. One of the most critical tasks prior to their operation
is to accurately determine their initial alignment while stationary, as it
forms the cornerstone for the entire INS operational trajectory. While
low-performance accelerometers can easily determine roll and pitch angles
(leveling), establishing the heading angle (gyrocompassing) with
low-performance gyros proves to be a challenging task without additional
sensors. This arises from the limited signal strength of Earth's rotation rate,
often overridden by gyro noise itself. To circumvent this deficiency, in this
study we present a practical deep learning framework to effectively compensate
for the inherent errors in low-performance gyroscopes. The resulting capability
enables gyrocompassing, thereby eliminating the need for subsequent prolonged
filtering phase (fine alignment). Through the development of theory and
experimental validation, we demonstrate that the improved initial conditions
establish a new lower error bound, bringing affordable gyros one step closer to
being utilized in high-end tactical tasks.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12122" title="Abstract">arXiv:2312.12122</a> [<a href="/pdf/2312.12122" title="Download PDF">pdf</a>, <a href="/format/2312.12122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZS-SRT: An Efficient Zero-Shot Super-Resolution Training Method for  Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xiang Feng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yongbo He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yubo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengkai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+Z">Zhenzhong Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jiajun Ding</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+F">Feiwei Qin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jianping Fan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Neural Radiance Fields (NeRF) have achieved great success in the task of
synthesizing novel views that preserve the same resolution as the training
views. However, it is challenging for NeRF to synthesize high-quality
high-resolution novel views with low-resolution training data. To solve this
problem, we propose a zero-shot super-resolution training framework for NeRF.
This framework aims to guide the NeRF model to synthesize high-resolution novel
views via single-scene internal learning rather than requiring any external
high-resolution training data. Our approach consists of two stages. First, we
learn a scene-specific degradation mapping by performing internal learning on a
pretrained low-resolution coarse NeRF. Second, we optimize a super-resolution
fine NeRF by conducting inverse rendering with our mapping function so as to
backpropagate the gradients from low-resolution 2D space into the
super-resolution 3D sampling space. Then, we further introduce a temporal
ensemble strategy in the inference phase to compensate for the scene estimation
errors. Our method is featured on two points: (1) it does not consume
high-resolution views or additional scene data to train super-resolution NeRF;
(2) it can speed up the training process by adopting a coarse-to-fine strategy.
By conducting extensive experiments on public datasets, we have qualitatively
and quantitatively demonstrated the effectiveness of our method.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12123" title="Abstract">arXiv:2312.12123</a> [<a href="/pdf/2312.12123" title="Download PDF">pdf</a>, <a href="/format/2312.12123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Prediction of Longitudinal Trajectory Considering Driving  Heterogeneity with Interpretability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuli Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+K">Kun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lanfang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lei Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Automated vehicles are envisioned to navigate safely in complex mixed-traffic
scenarios alongside human-driven vehicles. To promise a high degree of safety,
accurately predicting the maneuvers of surrounding vehicles and their future
positions is a critical task and attracts much attention. However, most
existing studies focused on reasoning about positional information based on
objective historical trajectories without fully considering the heterogeneity
of driving behaviors. Therefore, this study proposes a trajectory prediction
framework that combines Mixture Density Networks (MDN) and considers the
driving heterogeneity to provide probabilistic and personalized predictions.
Specifically, based on a certain length of historical trajectory data, the
situation-specific driving preferences of each driver are identified, where key
driving behavior feature vectors are extracted to characterize heterogeneity in
driving behavior among different drivers. With the inputs of the short-term
historical trajectory data and key driving behavior feature vectors, a
probabilistic LSTMMD-DBV model combined with LSTM-based encoder-decoder
networks and MDN layers is utilized to carry out personalized predictions.
Finally, the SHapley Additive exPlanations (SHAP) method is employed to
interpret the trained model for predictions. The proposed framework is tested
based on a wide-range vehicle trajectory dataset. The results indicate that the
proposed model can generate probabilistic future trajectories with remarkably
improved predictions compared to existing benchmark models. Moreover, the
results confirm that the additional input of driving behavior feature vectors
representing the heterogeneity of driving behavior could provide more
information and thus contribute to improving the prediction accuracy.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12131" title="Abstract">arXiv:2312.12131</a> [<a href="/pdf/2312.12131" title="Download PDF">pdf</a>, <a href="/format/2312.12131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Elliptic Curve Pairing Stealth Address Protocols
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mikic%2C+M">Marija Mikic</a>, 
<a href="/search/cs?searchtype=author&query=Srbakoski%2C+M">Mihajlo Srbakoski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The protection of transactions privacy is extremely important for the user.
With stealth address protocols (SAP), users can receive assets on stealth
addresses that they do not link to their stealth meta-addresses. SAP can be
generated using various cryptographic approaches. DKSAP uses elliptic curve
multiplication and hashing of the resulting shared secret. Another approach is
to use a bilinear mapping. The paper presents two SA protocols that use
elliptic curve pairing as a cryptographic solution. ECPDKSAP is a pairing-based
protocol that includes viewing key and spending key, while ECPSKSAP is a
pairing-based protocol that uses a single key with which spending and the
viewing key are derived. The expected efficiency of the proposed protocols is
similar to that of DKSAP with a view tag.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12133" title="Abstract">arXiv:2312.12133</a> [<a href="/pdf/2312.12133" title="Download PDF">pdf</a>, <a href="/format/2312.12133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object-Aware Domain Generalization for Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+W">Wooju Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+D">Dasol Hong</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+H">Hyungtae Lim</a>, 
<a href="/search/cs?searchtype=author&query=Myung%2C+H">Hyun Myung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-24. The first two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Single-domain generalization (S-DG) aims to generalize a model to unseen
environments with a single-source domain. However, most S-DG approaches have
been conducted in the field of classification. When these approaches are
applied to object detection, the semantic features of some objects can be
damaged, which can lead to imprecise object localization and misclassification.
To address these problems, we propose an object-aware domain generalization
(OA-DG) method for single-domain generalization in object detection. Our method
consists of data augmentation and training strategy, which are called OA-Mix
and OA-Loss, respectively. OA-Mix generates multi-domain data with multi-level
transformation and object-aware mixing strategy. OA-Loss enables models to
learn domain-invariant representations for objects and backgrounds from the
original and OA-Mixed images. Our proposed method outperforms state-of-the-art
works on standard benchmarks. Our code is available at
https://github.com/WoojuLee24/OA-DG.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12137" title="Abstract">arXiv:2312.12137</a> [<a href="/pdf/2312.12137" title="Download PDF">pdf</a>, <a href="/format/2312.12137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Best Arm Identification with Fixed Budget: A Large Deviation Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Po-An Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tzeng%2C+R">Ruo-Chun Tzeng</a>, 
<a href="/search/cs?searchtype=author&query=Proutiere%2C+A">Alexandre Proutiere</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been published in NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We consider the problem of identifying the best arm in stochastic Multi-Armed
Bandits (MABs) using a fixed sampling budget. Characterizing the minimal
instance-specific error probability for this problem constitutes one of the
important remaining open problems in MABs. When arms are selected using a
static sampling strategy, the error probability decays exponentially with the
number of samples at a rate that can be explicitly derived via Large Deviation
techniques. Analyzing the performance of algorithms with adaptive sampling
strategies is however much more challenging. In this paper, we establish a
connection between the Large Deviation Principle (LDP) satisfied by the
empirical proportions of arm draws and that satisfied by the empirical arm
rewards. This connection holds for any adaptive algorithm, and is leveraged (i)
to improve error probability upper bounds of some existing algorithms, such as
the celebrated \sr (Successive Rejects) algorithm \citep{audibert2010best}, and
(ii) to devise and analyze new algorithms. In particular, we present \sred
(Continuous Rejects), a truly adaptive algorithm that can reject arms in {\it
any} round based on the observed empirical gaps between the rewards of various
arms. Applying our Large Deviation results, we prove that \sred enjoys better
performance guarantees than existing algorithms, including \sr. Extensive
numerical experiments confirm this observation.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12141" title="Abstract">arXiv:2312.12141</a> [<a href="/pdf/2312.12141" title="Download PDF">pdf</a>, <a href="/format/2312.12141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Residual Stream of Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zeping Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kailai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ananiadou%2C+S">Sophia Ananiadou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Transformer-based models have achieved great breakthroughs in recent years.
However, there are many significant questions that have not been answered in
the field of explaining the reason why the models have powerful outputs. We do
not know how to locate the models' important parameters storing the knowledge
for predicting the next word, and whether these parameters are stored on the
same layer/module or different ones. Moreover, we do not understand the
mechanism to merge the knowledge into the final embedding for next word
prediction. In this paper, we explore the residual stream of transformers to
increase the interpretability. We find the mechanism behind residual connection
is a direct addition function on before-softmax values, so the probabilities of
tokens with larger before-softmax values will increase. Moreover, we prove that
using log probability increase as contribution scores is reasonable, and based
on this we can locate important parameters. Besides, we propose a method to
analyze how previous layers affect upper layers by comparing the inner
products. The experimental results and case study show that our research can
increase the interpretability of transformer-based models. We will release our
code on https://github.com/zepingyu0512/residualstream.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12142" title="Abstract">arXiv:2312.12142</a> [<a href="/pdf/2312.12142" title="Download PDF">pdf</a>, <a href="/format/2312.12142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FontDiffuser: One-Shot Font Generation via Denoising Diffusion with  Multi-Scale Content Aggregation and Style Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhenhua Yang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+D">Dezhi Peng</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Y">Yuxin Kong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+C">Cong Yao</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Lianwen Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024; Github Page: <a href="https://github.com/yeungchenwa/FontDiffuser">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 38th AAAI Conference on Artificial Intelligence (AAAI2024),
  Vancouver, BC, Canada, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Automatic font generation is an imitation task, which aims to create a font
library that mimics the style of reference images while preserving the content
from source images. Although existing font generation methods have achieved
satisfactory performance, they still struggle with complex characters and large
style variations. To address these issues, we propose FontDiffuser, a
diffusion-based image-to-image one-shot font generation method, which
innovatively models the font imitation task as a noise-to-denoise paradigm. In
our method, we introduce a Multi-scale Content Aggregation (MCA) block, which
effectively combines global and local content cues across different scales,
leading to enhanced preservation of intricate strokes of complex characters.
Moreover, to better manage the large variations in style transfer, we propose a
Style Contrastive Refinement (SCR) module, which is a novel structure for style
representation learning. It utilizes a style extractor to disentangle styles
from images, subsequently supervising the diffusion model via a meticulously
designed style contrastive loss. Extensive experiments demonstrate
FontDiffuser's state-of-the-art performance in generating diverse characters
and styles. It consistently excels on complex characters and large style
changes compared to previous methods. The code is available at
https://github.com/yeungchenwa/FontDiffuser.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12143" title="Abstract">arXiv:2312.12143</a> [<a href="/pdf/2312.12143" title="Download PDF">pdf</a>, <a href="/format/2312.12143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating Human Vision Perception in Vision Transformers for  Classifying Waste Items
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+A+K">Akshat Kishore Shrivastava</a>, 
<a href="/search/cs?searchtype=author&query=Gandhi%2C+T+K">Tapan Kumar Gandhi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">In this paper, we propose an novel methodology aimed at simulating the
learning phenomenon of nystagmus through the application of differential
blurring on datasets. Nystagmus is a biological phenomenon that influences
human vision throughout life, notably by diminishing head shake from infancy to
adulthood. Leveraging this concept, we address the issue of waste
classification, a pressing global concern. The proposed framework comprises two
modules, with the second module closely resembling the original Vision
Transformer, a state of the art model model in classification tasks. The
primary motivation behind our approach is to enhance the model's precision and
adaptability, mirroring the real world conditions that the human visual system
undergoes. This novel methodology surpasses the standard Vision Transformer
model in waste classification tasks, exhibiting an improvement with a margin of
2%. This improvement underscores the potential of our methodology in improving
model precision by drawing inspiration from human vision perception. Further
research in the proposed methodology could yield greater performance results,
and can extrapolated to other global tasks.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12144" title="Abstract">arXiv:2312.12144</a> [<a href="/pdf/2312.12144" title="Download PDF">pdf</a>, <a href="/format/2312.12144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M-BEV: Masked BEV Perception for Robust Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siran Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yue Ma</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yali Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Github repository: <a href="https://github.com/Sranc3/M-BEV">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D perception is a critical problem in autonomous driving. Recently, the
Bird-Eye-View (BEV) approach has attracted extensive attention, due to low-cost
deployment and desirable vision detection capacity. However, the existing
models ignore a realistic scenario during the driving procedure, i.e., one or
more view cameras may be failed, which largely deteriorates the performance. To
tackle this problem, we propose a generic Masked BEV (M-BEV) perception
framework, which can effectively improve robustness to this challenging
scenario, by random masking and reconstructing camera views in the end-to-end
training. More specifically, we develop a novel Masked View Reconstruction
(MVR) module for M-BEV. It mimics various missing cases by randomly masking
features of different camera views, then leverages the original features of
these views as self-supervision, and reconstructs the masked ones with the
distinct spatio-temporal context across views. Via such a plug-and-play MVR,
our M-BEV is capable of learning the missing views from the resting ones, and
thus well generalized for robust view recovery and accurate perception in the
testing. We perform extensive experiments on the popular NuScenes benchmark,
where our framework can significantly boost 3D perception performance of the
state-of-the-art models on various missing view cases, e.g., for the absence of
back view, our M-BEV promotes the PETRv2 model with 10.3% mAP gain.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12145" title="Abstract">arXiv:2312.12145</a> [<a href="/pdf/2312.12145" title="Download PDF">pdf</a>, <a href="/format/2312.12145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OVD-Explorer:Optimism Should Not Be the Sole Pursuit of Exploration in  Noisy Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jianye Hao</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+C">Chenjia Bai</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Junjie Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Piao%2C+H">Haiyin Piao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yang Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024, with appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In reinforcement learning, the optimism in the face of uncertainty (OFU) is a
mainstream principle for directing exploration towards less explored areas,
characterized by higher uncertainty. However, in the presence of environmental
stochasticity (noise), purely optimistic exploration may lead to excessive
probing of high-noise areas, consequently impeding exploration efficiency.
Hence, in exploring noisy environments, while optimism-driven exploration
serves as a foundation, prudent attention to alleviating unnecessary
over-exploration in high-noise areas becomes beneficial. In this work, we
propose Optimistic Value Distribution Explorer (OVD-Explorer) to achieve a
noise-aware optimistic exploration for continuous control. OVD-Explorer
proposes a new measurement of the policy's exploration ability considering
noise in optimistic perspectives, and leverages gradient ascent to drive
exploration. Practically, OVD-Explorer can be easily integrated with continuous
control RL algorithms. Extensive evaluations on the MuJoCo and GridChaos tasks
demonstrate the superiority of OVD-Explorer in achieving noise-aware optimistic
exploration.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12147" title="Abstract">arXiv:2312.12147</a> [<a href="/pdf/2312.12147" title="Download PDF">pdf</a>, <a href="/format/2312.12147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LoKit (revisited): A Toolkit for Building Distributed Collaborative  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borghoff%2C+U+M">Uwe M. Borghoff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 3 figures, 1 table. This paper is a reprint of an unpublished report on the occasion of the (fictitious) 30th anniversary of the Xerox Research Centre Europe, now Naver Labs, Grenoble, France
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Symbolic Computation (cs.SC)

</div>
<p class="mathjax">LoKit is a toolkit based on the coordination language LO. It allows to build
distributed collaborative applications by providing a set of generic tools.
This paper briefly introduces the concept of the toolkit, presents a subset of
the LoKit tools, and finally demonstrates its power by discussing a sample
application built with the toolkit.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12148" title="Abstract">arXiv:2312.12148</a> [<a href="/pdf/2312.12148" title="Download PDF">pdf</a>, <a href="/format/2312.12148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameter-Efficient Fine-Tuning Methods for Pretrained Language Models:  A Critical Review and Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lingling Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Haoran Xie</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+S+J">Si-Zhao Joe Qin</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+X">Xiaohui Tao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F+L">Fu Lee Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With the continuous growth in the number of parameters of transformer-based
pretrained language models (PLMs), particularly the emergence of large language
models (LLMs) with billions of parameters, many natural language processing
(NLP) tasks have demonstrated remarkable success. However, the enormous size
and computational demands of these models pose significant challenges for
adapting them to specific downstream tasks, especially in environments with
limited computational resources. Parameter Efficient Fine-Tuning (PEFT) offers
an effective solution by reducing the number of fine-tuning parameters and
memory usage while achieving comparable performance to full fine-tuning. The
demands for fine-tuning PLMs, especially LLMs, have led to a surge in the
development of PEFT methods, as depicted in Fig. 1. In this paper, we present a
comprehensive and systematic review of PEFT methods for PLMs. We summarize
these PEFT methods, discuss their applications, and outline future directions.
Furthermore, we conduct experiments using several representative PEFT methods
to better understand their effectiveness in parameter efficiency and memory
efficiency. By offering insights into the latest advancements and practical
applications, this survey serves as an invaluable resource for researchers and
practitioners seeking to navigate the challenges and opportunities presented by
PEFT in the context of PLMs.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12153" title="Abstract">arXiv:2312.12153</a> [<a href="/pdf/2312.12153" title="Download PDF">pdf</a>, <a href="/format/2312.12153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noise robust distillation of self-supervised speech models via  correlation metrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ritter-Gutierrez%2C+F">Fabian Ritter-Gutierrez</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kuan-Po Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+D">Dianwen Ng</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+J+H+M">Jeremy H.M. Wong</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hung-yi Lee</a>, 
<a href="/search/cs?searchtype=author&query=Chng%2C+E+S">Eng Siong Chng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N+F">Nancy F. Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Compared to large speech foundation models, small distilled models exhibit
degraded noise robustness. The student's robustness can be improved by
introducing noise at the inputs during pre-training. Despite this, using the
standard distillation loss still yields a student with degraded performance.
Thus, this paper proposes improving student robustness via distillation with
correlation metrics. Teacher behavior is learned by maximizing the teacher and
student cross-correlation matrix between their representations towards
identity. Noise robustness is encouraged via the student's self-correlation
minimization. The proposed method is agnostic of the teacher model and
consistently outperforms the previous approach. This work also proposes an
heuristic to weigh the importance of the two correlation terms automatically.
Experiments show consistently better clean and noise generalization on Intent
Classification, Keyword Spotting, and Automatic Speech Recognition tasks on
SUPERB Challenge.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12155" title="Abstract">arXiv:2312.12155</a> [<a href="/pdf/2312.12155" title="Download PDF">pdf</a>, <a href="/format/2312.12155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Balanced Alignment: Modal-Enhanced Semantic Modeling for Video  Moment Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhihang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Hongtao Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pandeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+J">Jiannan Ge</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sun-Ao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+G">Guoqing Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video Moment Retrieval (VMR) aims to retrieve temporal segments in untrimmed
videos corresponding to a given language query by constructing cross-modal
alignment strategies. However, these existing strategies are often sub-optimal
since they ignore the modality imbalance problem, \textit{i.e.}, the semantic
richness inherent in videos far exceeds that of a given limited-length
sentence. Therefore, in pursuit of better alignment, a natural idea is
enhancing the video modality to filter out query-irrelevant semantics, and
enhancing the text modality to capture more segment-relevant knowledge. In this
paper, we introduce Modal-Enhanced Semantic Modeling (MESM), a novel framework
for more balanced alignment through enhancing features at two levels. First, we
enhance the video modality at the frame-word level through word reconstruction.
This strategy emphasizes the portions associated with query words in
frame-level features while suppressing irrelevant parts. Therefore, the
enhanced video contains less redundant semantics and is more balanced with the
textual modality. Second, we enhance the textual modality at the
segment-sentence level by learning complementary knowledge from context
sentences and ground-truth segments. With the knowledge added to the query, the
textual modality thus maintains more meaningful semantics and is more balanced
with the video modality. By implementing two levels of MESM, the semantic
information from both modalities is more balanced to align, thereby bridging
the modality gap. Experiments on three widely used benchmarks, including the
out-of-distribution settings, show that the proposed framework achieves a new
start-of-the-art performance with notable generalization ability (e.g., 4.42%
and 7.69% average gains of R1@0.7 on Charades-STA and Charades-CG). The code
will be available at https://github.com/lntzm/MESM.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12161" title="Abstract">arXiv:2312.12161</a> [<a href="/pdf/2312.12161" title="Download PDF">pdf</a>, <a href="/format/2312.12161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards an in-depth detection of malware using distributed QCNN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Quertier%2C+T">Tony Quertier</a>, 
<a href="/search/cs?searchtype=author&query=Barru%C3%A9%2C+G">Gr&#xe9;goire Barru&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Quantum Physics (quant-ph)

</div>
<p class="mathjax">Malware detection is an important topic of current cybersecurity, and Machine
Learning appears to be one of the main considered solutions even if certain
problems to generalize to new malware remain. In the aim of exploring the
potential of quantum machine learning on this domain, our previous work showed
that quantum neural networks do not perform well on image-based malware
detection when using a few qubits. In order to enhance the performances of our
quantum algorithms for malware detection using images, without increasing the
resources needed in terms of qubits, we implement a new preprocessing of our
dataset using Grayscale method, and we couple it with a model composed of five
distributed quantum convolutional networks and a scoring function. We get an
increase of around 20 \% of our results, both on the accuracy of the test and
its F1-score.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12162" title="Abstract">arXiv:2312.12162</a> [<a href="/pdf/2312.12162" title="Download PDF">pdf</a>, <a href="/format/2312.12162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PEPT: Expert Finding Meets Personalized Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+Q">Qiyao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongtao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongyan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yinghui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjun Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Finding appropriate experts is essential in Community Question Answering
(CQA) platforms as it enables the effective routing of questions to potential
users who can provide relevant answers. The key is to personalized learning
expert representations based on their historical answered questions, and
accurately matching them with target questions. There have been some
preliminary works exploring the usability of PLMs in expert finding, such as
pre-training expert or question representations. However, these models usually
learn pure text representations of experts from histories, disregarding
personalized and fine-grained expert modeling. For alleviating this, we present
a personalized pre-training and fine-tuning paradigm, which could effectively
learn expert interest and expertise simultaneously. Specifically, in our
pre-training framework, we integrate historical answered questions of one
expert with one target question, and regard it as a candidate aware
expert-level input unit. Then, we fuse expert IDs into the pre-training for
guiding the model to model personalized expert representations, which can help
capture the unique characteristics and expertise of each individual expert.
Additionally, in our pre-training task, we design: 1) a question-level masked
language model task to learn the relatedness between histories, enabling the
modeling of question-level expert interest; 2) a vote-oriented task to capture
question-level expert expertise by predicting the vote score the expert would
receive. Through our pre-training framework and tasks, our approach could
holistically learn expert representations including interests and expertise.
Our method has been extensively evaluated on six real-world CQA datasets, and
the experimental results consistently demonstrate the superiority of our
approach over competitive baseline methods.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12170" title="Abstract">arXiv:2312.12170</a> [<a href="/pdf/2312.12170" title="Download PDF">pdf</a>, <a href="/format/2312.12170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust algorithms for limit load and shear strength reduction methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sysala%2C+S">Stanislav Sysala</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper is focused on continuation techniques and Newton-like methods
suggested for numerical determination of safety factors within stability
assessment. Especially, we are interested in the stability of slopes and
related limit load and shear strength reduction methods. We build on
computational plasticity and the finite element method, but we mainly work on
an algebraic level to be the topic understandable for broader class of
scientists and our algorithms more transparent. The presented algorithms are
based on the associated plasticity to be more robust. For non-associated
models, we use Davis-type approximations enabling us to apply the associated
approach. A particular attention is devoted to the Mohr-Coulomb
elastic-perfectly plastic constitutive problem. On this example, we explain
some important features of the presented methods which are beyond the algebraic
settings of the problems. We also summarize the Mohr-Coulomb constitutive
solution and some implementation details.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12174" title="Abstract">arXiv:2312.12174</a> [<a href="/pdf/2312.12174" title="Download PDF">pdf</a>, <a href="/format/2312.12174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Consumption Partial Transcoding by HEVC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdoli%2C+M">Mohsen Abdoli</a>, 
<a href="/search/cs?searchtype=author&query=Henry%2C+F">F&#xe9;lix Henry</a>, 
<a href="/search/cs?searchtype=author&query=Clare%2C+G">Gordon Clare</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">A transcoding scheme for the High Efficiency Video Coding (HEVC) is proposed
that allows any partial frame modification to be followed by a partial
re-compression of only the modified areas, while guaranteeing identical
reconstruction of non-modified areas. To this end, first, syntax elements of
all Coding Units (CU) in the frame are parsed and decoded according to their
scan order. Then CUs that are collocated with a replaced area are re-encoded
with new content to generate a partial set of new syntax elements. In order to
avoid spatial propagation of the decoding mismatch due to the new content, CUs
on the border of the replaced area are losslessly coded such that
reconstruction of immediately neighboring CUs in the scan order are protected
from the modification. The proposed method has been implemented on top of the
HEVC test Model (HM) in All-Intra (AI) coding configuration and experiments
show that, depending on the test parameters, it can offer both a bitrate saving
(up to 4% in terms of BD-BR) and a transcoding acceleration (up to 83%)
compared to a full transcoding scheme.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12176" title="Abstract">arXiv:2312.12176</a> [<a href="/pdf/2312.12176" title="Download PDF">pdf</a>, <a href="/format/2312.12176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> All for One, and One for All: UrbanSyn Dataset, the third Musketeer of  Synthetic Driving Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez%2C+J+L">Jose L. G&#xf3;mez</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+M">Manuel Silva</a>, 
<a href="/search/cs?searchtype=author&query=Seoane%2C+A">Antonio Seoane</a>, 
<a href="/search/cs?searchtype=author&query=Borr%C3%A1s%2C+A">Agn&#xe8;s Borr&#xe1;s</a>, 
<a href="/search/cs?searchtype=author&query=Noriega%2C+M">Mario Noriega</a>, 
<a href="/search/cs?searchtype=author&query=Ros%2C+G">Germ&#xe1;n Ros</a>, 
<a href="/search/cs?searchtype=author&query=Iglesias-Guitian%2C+J+A">Jose A. Iglesias-Guitian</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+A+M">Antonio M. L&#xf3;pez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The UrbanSyn Dataset is available in <a href="http://urbansyn.org/">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce UrbanSyn, a photorealistic dataset acquired through
semi-procedurally generated synthetic urban driving scenarios. Developed using
high-quality geometry and materials, UrbanSyn provides pixel-level ground
truth, including depth, semantic segmentation, and instance segmentation with
object bounding boxes and occlusion degree. It complements GTAV and Synscapes
datasets to form what we coin as the 'Three Musketeers'. We demonstrate the
value of the Three Musketeers in unsupervised domain adaptation for image
semantic segmentation. Results on real-world datasets, Cityscapes, Mapillary
Vistas, and BDD100K, establish new benchmarks, largely attributed to UrbanSyn.
We make UrbanSyn openly and freely accessible (www.urbansyn.org).
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12181" title="Abstract">arXiv:2312.12181</a> [<a href="/pdf/2312.12181" title="Download PDF">pdf</a>, <a href="/format/2312.12181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StyleSpeech: Self-supervised Style Enhancing with VQ-VAE-based  Pre-training for Expressive Audiobook Speech Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xueyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaofei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Lei He</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiyong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xixin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+H">Helen Meng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The expressive quality of synthesized speech for audiobooks is limited by
generalized model architecture and unbalanced style distribution in the
training data. To address these issues, in this paper, we propose a
self-supervised style enhancing method with VQ-VAE-based pre-training for
expressive audiobook speech synthesis. Firstly, a text style encoder is
pre-trained with a large amount of unlabeled text-only data. Secondly, a
spectrogram style extractor based on VQ-VAE is pre-trained in a self-supervised
manner, with plenty of audio data that covers complex style variations. Then a
novel architecture with two encoder-decoder paths is specially designed to
model the pronunciation and high-level style expressiveness respectively, with
the guidance of the style extractor. Both objective and subjective evaluations
demonstrate that our proposed method can effectively improve the naturalness
and expressiveness of the synthesized speech in audiobook synthesis especially
for the role and out-of-domain scenarios.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12183" title="Abstract">arXiv:2312.12183</a> [<a href="/pdf/2312.12183" title="Download PDF">pdf</a>, <a href="/format/2312.12183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Poincar&#xe9; Differential Privacy for Hierarchy-aware Graph Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yuecen Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Haonan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xingcheng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qingyun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xianxian Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chunming Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Hierarchy is an important and commonly observed topological property in
real-world graphs that indicate the relationships between supervisors and
subordinates or the organizational behavior of human groups. As hierarchy is
introduced as a new inductive bias into the Graph Neural Networks (GNNs) in
various tasks, it implies latent topological relations for attackers to improve
their inference attack performance, leading to serious privacy leakage issues.
In addition, existing privacy-preserving frameworks suffer from reduced
protection ability in hierarchical propagation due to the deficiency of
adaptive upper-bound estimation of the hierarchical perturbation boundary. It
is of great urgency to effectively leverage the hierarchical property of data
while satisfying privacy guarantees. To solve the problem, we propose the
Poincar\'e Differential Privacy framework, named PoinDP, to protect the
hierarchy-aware graph embedding based on hyperbolic geometry. Specifically,
PoinDP first learns the hierarchy weights for each entity based on the
Poincar\'e model in hyperbolic space. Then, the Personalized Hierarchy-aware
Sensitivity is designed to measure the sensitivity of the hierarchical
structure and adaptively allocate the privacy protection strength. Besides, the
Hyperbolic Gaussian Mechanism (HGM) is proposed to extend the Gaussian
mechanism in Euclidean space to hyperbolic space to realize random
perturbations that satisfy differential privacy under the hyperbolic space
metric. Extensive experiment results on five real-world datasets demonstrate
the proposed PoinDP's advantages of effective privacy protection while
maintaining good performance on the node classification task.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12186" title="Abstract">arXiv:2312.12186</a> [<a href="/pdf/2312.12186" title="Download PDF">pdf</a>, <a href="/format/2312.12186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social Learning in Community Structured Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shumovskaia%2C+V">Valentina Shumovskaia</a>, 
<a href="/search/cs?searchtype=author&query=Kayaalp%2C+M">Mert Kayaalp</a>, 
<a href="/search/cs?searchtype=author&query=Sayed%2C+A+H">Ali H. Sayed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Multiagent Systems (cs.MA); Signal Processing (eess.SP)

</div>
<p class="mathjax">Traditional social learning frameworks consider environments with a
homogeneous state, where each agent receives observations conditioned on that
true state of nature. In this work, we relax this assumption and study the
distributed hypothesis testing problem in a heterogeneous environment, where
each agent can receive observations conditioned on their own personalized state
of nature (or truth). This situation arises in many scenarios, such as when
sensors are spatially distributed, or when individuals in a social network have
differing views or opinions. In these heterogeneous contexts, the graph
topology admits a block structure. We study social learning under personalized
(or multitask) models and examine their convergence behavior.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12190" title="Abstract">arXiv:2312.12190</a> [<a href="/pdf/2312.12190" title="Download PDF">pdf</a>, <a href="/format/2312.12190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralised and collaborative machine learning framework for IoT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A1lez-Soto%2C+M">Mart&#xed;n Gonz&#xe1;lez-Soto</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz-Redondo%2C+R+P">Rebeca P. D&#xed;az-Redondo</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Veiga%2C+M">Manuel Fern&#xe1;ndez-Veiga</a>, 
<a href="/search/cs?searchtype=author&query=Rodr%C3%ADguez-Castro%2C+B">Bruno Rodr&#xed;guez-Castro</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Vilas%2C+A">Ana Fern&#xe1;ndez-Vilas</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Networks. Volume 239, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Decentralised machine learning has recently been proposed as a potential
solution to the security issues of the canonical federated learning approach.
In this paper, we propose a decentralised and collaborative machine learning
framework specially oriented to resource-constrained devices, usual in IoT
deployments. With this aim we propose the following construction blocks. First,
an incremental learning algorithm based on prototypes that was specifically
implemented to work in low-performance computing elements. Second, two
random-based protocols to exchange the local models among the computing
elements in the network. Finally, two algorithmics approaches for prediction
and prototype creation. This proposal was compared to a typical centralized
incremental learning approach in terms of accuracy, training time and
robustness with very promising results.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12191" title="Abstract">arXiv:2312.12191</a> [<a href="/pdf/2312.12191" title="Download PDF">pdf</a>, <a href="/format/2312.12191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CUDC: A Curiosity-Driven Unsupervised Data Collection Method with  Adaptive Temporal Distances for Offline Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chenyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+H">Hangwei Qian</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+C">Chunyan Miao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Offline reinforcement learning (RL) aims to learn an effective policy from a
pre-collected dataset. Most existing works are to develop sophisticated
learning algorithms, with less emphasis on improving the data collection
process. Moreover, it is even challenging to extend the single-task setting and
collect a task-agnostic dataset that allows an agent to perform multiple
downstream tasks. In this paper, we propose a Curiosity-driven Unsupervised
Data Collection (CUDC) method to expand feature space using adaptive temporal
distances for task-agnostic data collection and ultimately improve learning
efficiency and capabilities for multi-task offline RL. To achieve this, CUDC
estimates the probability of the k-step future states being reachable from the
current states, and adapts how many steps into the future that the dynamics
model should predict. With this adaptive reachability mechanism in place, the
feature representation can be diversified, and the agent can navigate itself to
collect higher-quality data with curiosity. Empirically, CUDC surpasses
existing unsupervised methods in efficiency and learning performance in various
downstream offline RL tasks of the DeepMind control suite.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12193" title="Abstract">arXiv:2312.12193</a> [<a href="/pdf/2312.12193" title="Download PDF">pdf</a>, <a href="/format/2312.12193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian process learning of nonlinear dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+D">Dongwei Ye</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Mengwu Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); Numerical Analysis (math.NA)

</div>
<p class="mathjax">One of the pivotal tasks in scientific machine learning is to represent
underlying dynamical systems from time series data. Many methods for such
dynamics learning explicitly require the derivatives of state data, which are
not directly available and can be approximated conventionally by finite
differences. However, the discrete approximations of time derivatives may
result in a poor estimation when state data are scarce and/or corrupted by
noise, thus compromising the predictiveness of the learned dynamical models. To
overcome this technical hurdle, we propose a new method that learns nonlinear
dynamics through a Bayesian inference of characterizing model parameters. This
method leverages a Gaussian process representation of states, and constructs a
likelihood function using the correlation between state data and their
derivatives, yet prevents explicit evaluations of time derivatives. Through a
Bayesian scheme, a probabilistic estimate of the model parameters is given by
the posterior distribution, and thus a quantification is facilitated for
uncertainties from noisy state data and the learning process. Specifically, we
will discuss the applicability of the proposed method to two typical scenarios
for dynamical systems: parameter identification and estimation with an affine
structure of the system, and nonlinear parametric approximation without prior
knowledge.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12198" title="Abstract">arXiv:2312.12198</a> [<a href="/pdf/2312.12198" title="Download PDF">pdf</a>, <a href="/format/2312.12198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mask Grounding for Referring Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chng%2C+Y+X">Yong Xien Chng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Henry Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yizeng Han</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xuchong Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gao Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Referring Image Segmentation (RIS) is a challenging task that requires an
algorithm to segment objects referred by free-form language expressions.
Despite significant progress in recent years, most state-of-the-art (SOTA)
methods still suffer from considerable language-image modality gap at the pixel
and word level. These methods generally 1) rely on sentence-level language
features for language-image alignment and 2) lack explicit training supervision
for fine-grained visual grounding. Consequently, they exhibit weak object-level
correspondence between visual and language features. Without well-grounded
features, prior methods struggle to understand complex expressions that require
strong reasoning over relationships among multiple objects, especially when
dealing with rarely used or ambiguous clauses. To tackle this challenge, we
introduce a novel Mask Grounding auxiliary task that significantly improves
visual grounding within language features, by explicitly teaching the model to
learn fine-grained correspondence between masked textual tokens and their
matching visual objects. Mask Grounding can be directly used on prior RIS
methods and consistently bring improvements. Furthermore, to holistically
address the modality gap, we also design a cross-modal alignment loss and an
accompanying alignment module. These additions work synergistically with Mask
Grounding. With all these techniques, our comprehensive approach culminates in
MagNet Mask-grounded Network), an architecture that significantly outperforms
prior arts on three key benchmarks (RefCOCO, RefCOCO+ and G-Ref), demonstrating
our method's effectiveness in addressing current limitations of RIS algorithms.
Our code and pre-trained weights will be released.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12204" title="Abstract">arXiv:2312.12204</a> [<a href="/pdf/2312.12204" title="Download PDF">pdf</a>, <a href="/format/2312.12204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced Unscented Kalman Filter-Based SLAM in Dynamic Environments:  Euclidean Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dorvash%2C+M">Masoud Dorvash</a>, 
<a href="/search/cs?searchtype=author&query=Eslamian%2C+A">Ali Eslamian</a>, 
<a href="/search/cs?searchtype=author&query=Ahmadzadeh%2C+M+R">Mohammad Reza Ahmadzadeh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper introduces an innovative approach to Simultaneous Localization and
Mapping (SLAM) using the Unscented Kalman Filter (UKF) in a dynamic
environment. The UKF is proven to be a robust estimator and demonstrates lower
sensitivity to sensor data errors compared to alternative SLAM algorithms.
However, conventional algorithms are primarily concerned with stationary
landmarks, which might prevent localization in dynamic environments. This paper
proposes an Euclidean-based method for handling moving landmarks, calculating
and estimating distances between the robot and each moving landmark, and
addressing sensor measurement conflicts. The approach is evaluated through
simulations in MATLAB and comparing results with the conventional UKF-SLAM
algorithm. We also introduce a dataset for filter-based algorithms in dynamic
environments, which can be used as a benchmark for evaluating of future
algorithms. The outcomes of the proposed algorithm underscore that this simple
yet effective approach mitigates the disruptive impact of moving landmarks, as
evidenced by a thorough examination involving parameters such as the number of
moving and stationary landmarks, waypoints, and computational efficiency. We
also evaluated our algorithms in a realistic simulation of a real-world mapping
task. This approach allowed us to assess our methods in practical conditions
and gain insights for future enhancements. Our algorithm surpassed the
performance of all competing methods in the evaluation, showcasing its ability
to excel in real-world mapping scenarios.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12206" title="Abstract">arXiv:2312.12206</a> [<a href="/pdf/2312.12206" title="Download PDF">pdf</a>, <a href="/format/2312.12206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identification of Causal Structure in the Presence of Missing Data with  Additive Noise Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiao%2C+J">Jie Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhengming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jianhua Yu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+R">Ruichu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Z">Zhifeng Hao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
<p class="mathjax">Missing data are an unavoidable complication frequently encountered in many
causal discovery tasks. When a missing process depends on the missing values
themselves (known as self-masking missingness), the recovery of the joint
distribution becomes unattainable, and detecting the presence of such
self-masking missingness remains a perplexing challenge. Consequently, due to
the inability to reconstruct the original distribution and to discern the
underlying missingness mechanism, simply applying existing causal discovery
methods would lead to wrong conclusions. In this work, we found that the recent
advances additive noise model has the potential for learning causal structure
under the existence of the self-masking missingness. With this observation, we
aim to investigate the identification problem of learning causal structure from
missing data under an additive noise model with different missingness
mechanisms, where the `no self-masking missingness' assumption can be
eliminated appropriately. Specifically, we first elegantly extend the scope of
identifiability of causal skeleton to the case with weak self-masking
missingness (i.e., no other variable could be the cause of self-masking
indicators except itself). We further provide the sufficient and necessary
identification conditions of the causal direction under additive noise model
and show that the causal structure can be identified up to an IN-equivalent
pattern. We finally propose a practical algorithm based on the above
theoretical results on learning the causal skeleton and causal direction.
Extensive experiments on synthetic and real data demonstrate the efficiency and
effectiveness of the proposed algorithms.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12213" title="Abstract">arXiv:2312.12213</a> [<a href="/pdf/2312.12213" title="Download PDF">pdf</a>, <a href="/format/2312.12213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantitative convergence of a discretization of dynamic optimal  transport using the dual formulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ishida%2C+S">Sadashige Ishida</a>, 
<a href="/search/math?searchtype=author&query=Lavenant%2C+H">Hugo Lavenant</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We present a discretization of the dynamic optimal transport problem for
which we can obtain the convergence rate for the value of the transport cost to
its continuous value when the temporal and spatial stepsize vanish. This
convergence result does not require any regularity assumption on the measures,
though experiments suggest that the rate is not sharp. Via an analysis of the
duality gap we also obtain the convergence rates for the gradient of the
optimal potentials and the velocity field under mild regularity assumptions. To
obtain such rates we discretize the dual formulation of the dynamic optimal
transport problem and use the mature literature related to the error due to
discretizing the Hamilton-Jacobi equation.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12216" title="Abstract">arXiv:2312.12216</a> [<a href="/pdf/2312.12216" title="Download PDF">pdf</a>, <a href="/ps/2312.12216" title="Download PostScript">ps</a>, <a href="/format/2312.12216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sharing is CAIRing: Characterizing Principles and Assessing Properties  of Universal Privacy Evaluation for Synthetic Tabular Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hyrup%2C+T">Tobias Hyrup</a>, 
<a href="/search/cs?searchtype=author&query=Lautrup%2C+A+D">Anton Danholt Lautrup</a>, 
<a href="/search/cs?searchtype=author&query=Zimek%2C+A">Arthur Zimek</a>, 
<a href="/search/cs?searchtype=author&query=Schneider-Kamp%2C+P">Peter Schneider-Kamp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computers and Society (cs.CY)

</div>
<p class="mathjax">Data sharing is a necessity for innovative progress in many domains,
especially in healthcare. However, the ability to share data is hindered by
regulations protecting the privacy of natural persons. Synthetic tabular data
provide a promising solution to address data sharing difficulties but does not
inherently guarantee privacy. Still, there is a lack of agreement on
appropriate methods for assessing the privacy-preserving capabilities of
synthetic data, making it difficult to compare results across studies. To the
best of our knowledge, this is the first work to identify properties that
constitute good universal privacy evaluation metrics for synthetic tabular
data. The goal of such metrics is to enable comparability across studies and to
allow non-technical stakeholders to understand how privacy is protected. We
identify four principles for the assessment of metrics: Comparability,
Applicability, Interpretability, and Representativeness (CAIR). To quantify and
rank the degree to which evaluation metrics conform to the CAIR principles, we
design a rubric using a scale of 1-4. Each of the four properties is scored on
four parameters, yielding 16 total dimensions. We study the applicability and
usefulness of the CAIR principles and rubric by assessing a selection of
metrics popular in other studies. The results provide granular insights into
the strengths and weaknesses of existing metrics that not only rank the metrics
but highlight areas of potential improvements. We expect that the CAIR
principles will foster agreement among researchers and organizations on which
universal privacy evaluation metrics are appropriate for synthetic tabular
data.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12218" title="Abstract">arXiv:2312.12218</a> [<a href="/pdf/2312.12218" title="Download PDF">pdf</a>, <a href="/format/2312.12218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An exact divergence-free spectral method for incompressible and  resistive magneto-hydrodynamic equations in two and three dimensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Qin%2C+L">Lechang Qin</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+H">Huiyuan Li</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+Z">Zhiguo Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we present exact divergence-free spectral method for solving
the incompressible and resistive magneto-hydrodynamic (MHD) equations in two
and three dimensions, as well as the efficient solution algorithm and
unconditionally energy-stable fully-discretized numerical schemes. We introduce
new ideas of constructing two families of exact divergence-free vectorial
spectral basis functions on domains diffeomorphic to squares or cubes. These
bases are obtained with the help of orthogonality and derivative relation of
generalised Jacobi polynomials, several de Rham complexes, as well as the
property of contravariant Piola transformation. They are well-suited for
discretizing the velocity and magnetic fields, respectively, thereby ensuring
point-wise preservation of the incompressibility condition and the magnetic
Gauss's law. With the aid of these bases, we propose a family of exact
divergence-free implicit-explicit $k$-step backward differentiation formula
(DF-BDF-$k$) fully-discretized schemes for the MHD system. These schemes
naturally decouple the pressure field from the velocity field. Consequently,
the stability of the space-time fully-discretized numerical schemes based on
these bases are significantly enhanced. These schemes exhibit unconditional
stability for $k=1,2$, and demonstrate exceptional stability and accuracy for
$k=3,4$, verified with extensive numerical results for long time simulations
using large time step sizes. Furthermore, we present efficient solution
algorithms for these two decoupled equations for the velocity and magnetic
fields, respectively, by exploiting the sparsity and structure of the resultant
linear algebraic systems. Ample numerical examples in two and three dimensions
are provided to demonstrate the distinctive accuracy, efficiency and stability
of our proposed method.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12222" title="Abstract">arXiv:2312.12222</a> [<a href="/pdf/2312.12222" title="Download PDF">pdf</a>, <a href="/format/2312.12222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EarthVQA: Towards Queryable Earth via Relational Reasoning-Based Remote  Sensing Visual Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junjue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhuo Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zihang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+A">Ailong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yanfei Zhong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted By AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Earth vision research typically focuses on extracting geospatial object
locations and categories but neglects the exploration of relations between
objects and comprehensive reasoning. Based on city planning needs, we develop a
multi-modal multi-task VQA dataset (EarthVQA) to advance relational
reasoning-based judging, counting, and comprehensive analysis. The EarthVQA
dataset contains 6000 images, corresponding semantic masks, and 208,593 QA
pairs with urban and rural governance requirements embedded. As objects are the
basis for complex relational reasoning, we propose a Semantic OBject Awareness
framework (SOBA) to advance VQA in an object-centric way. To preserve refined
spatial locations and semantics, SOBA leverages a segmentation network for
object semantics generation. The object-guided attention aggregates object
interior features via pseudo masks, and bidirectional cross-attention further
models object external relations hierarchically. To optimize object counting,
we propose a numerical difference loss that dynamically adds difference
penalties, unifying the classification and regression tasks. Experimental
results show that SOBA outperforms both advanced general and remote sensing
methods. We believe this dataset and framework provide a strong benchmark for
Earth vision's complex analysis. The project page is at
https://Junjue-Wang.github.io/homepage/EarthVQA.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12223" title="Abstract">arXiv:2312.12223</a> [<a href="/pdf/2312.12223" title="Download PDF">pdf</a>, <a href="/format/2312.12223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Detection of Perfect and Partial Input-Dependent  Symmetries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Urbano%2C+A">Alonso Urbano</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+D+W">David W. Romero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Group equivariance ensures consistent responses to group transformations of
the input, leading to more robust models and enhanced generalization
capabilities. However, this property can lead to overly constrained models if
the symmetries considered in the group differ from those observed in data.
While common methods address this by determining the appropriate level of
symmetry at the dataset level, they are limited to supervised settings and
ignore scenarios in which multiple levels of symmetry co-exist in the same
dataset. For instance, pictures of cars and planes exhibit different levels of
rotation, yet both are included in the CIFAR-10 dataset. In this paper, we
propose a method able to detect the level of symmetry of each input without the
need for labels. To this end, we derive a sufficient and necessary condition to
learn the distribution of symmetries in the data. Using the learned
distribution, we generate pseudo-labels that allow us to learn the levels of
symmetry of each input in a self-supervised manner. We validate the
effectiveness of our approach on synthetic datasets with different per-class
levels of symmetries e.g. MNISTMultiple, in which digits are uniformly rotated
within a class-dependent interval. We demonstrate that our method can be used
for practical applications such as the generation of standardized datasets in
which the symmetries are not present, as well as the detection of
out-of-distribution symmetries during inference. By doing so, both the
generalization and robustness of non-equivariant models can be improved. Our
code is publicly available at https://github.com/aurban0/ssl-sym.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12226" title="Abstract">arXiv:2312.12226</a> [<a href="/pdf/2312.12226" title="Download PDF">pdf</a>, <a href="/format/2312.12226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Parameterization of Second-Order Optimization Effective Towards  the Infinite Width
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ishikawa%2C+S">Satoki Ishikawa</a>, 
<a href="/search/cs?searchtype=author&query=Karakida%2C+R">Ryo Karakida</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Second-order optimization has been developed to accelerate the training of
deep neural networks and it is being applied to increasingly larger-scale
models. In this study, towards training on further larger scales, we identify a
specific parameterization for second-order optimization that promotes feature
learning in a stable manner even if the network width increases significantly.
Inspired by a maximal update parameterization, we consider a one-step update of
the gradient and reveal the appropriate scales of hyperparameters including
random initialization, learning rates, and damping terms. Our approach covers
two major second-order optimization algorithms, K-FAC and Shampoo, and we
demonstrate that our parameterization achieves higher generalization
performance in feature learning. In particular, it enables us to transfer the
hyperparameters across models with different widths.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12227" title="Abstract">arXiv:2312.12227</a> [<a href="/pdf/2312.12227" title="Download PDF">pdf</a>, <a href="/format/2312.12227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HuTuMotion: Human-Tuned Navigation of Latent Motion Diffusion Models  with Minimal Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+G">Gaoge Han</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shaoli Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+M">Mingming Gong</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jinglei Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024 Main Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We introduce HuTuMotion, an innovative approach for generating natural human
motions that navigates latent motion diffusion models by leveraging few-shot
human feedback. Unlike existing approaches that sample latent variables from a
standard normal prior distribution, our method adapts the prior distribution to
better suit the characteristics of the data, as indicated by human feedback,
thus enhancing the quality of motion generation. Furthermore, our findings
reveal that utilizing few-shot feedback can yield performance levels on par
with those attained through extensive human feedback. This discovery emphasizes
the potential and efficiency of incorporating few-shot human-guided
optimization within latent diffusion models for personalized and style-aware
human motion generation applications. The experimental results show the
significantly superior performance of our method over existing state-of-the-art
approaches.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12232" title="Abstract">arXiv:2312.12232</a> [<a href="/pdf/2312.12232" title="Download PDF">pdf</a>, <a href="/format/2312.12232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brush Your Text: Synthesize Any Scene Text on Images via Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lingjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaohui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yue Lu</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024. Code: <a href="https://github.com/ecnuljzhang/brush-your-text">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, diffusion-based image generation methods are credited for their
remarkable text-to-image generation capabilities, while still facing challenges
in accurately generating multilingual scene text images. To tackle this
problem, we propose Diff-Text, which is a training-free scene text generation
framework for any language. Our model outputs a photo-realistic image given a
text of any language along with a textual description of a scene. The model
leverages rendered sketch images as priors, thus arousing the potential
multilingual-generation ability of the pre-trained Stable Diffusion. Based on
the observation from the influence of the cross-attention map on object
placement in generated images, we propose a localized attention constraint into
the cross-attention layer to address the unreasonable positioning problem of
scene text. Additionally, we introduce contrastive image-level prompts to
further refine the position of the textual region and achieve more accurate
scene text generation. Experiments demonstrate that our method outperforms the
existing method in both the accuracy of text recognition and the naturalness of
foreground-background blending.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12236" title="Abstract">arXiv:2312.12236</a> [<a href="/pdf/2312.12236" title="Download PDF">pdf</a>, <a href="/ps/2312.12236" title="Download PostScript">ps</a>, <a href="/format/2312.12236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalization Analysis of Machine Learning Algorithms via the  Worst-Case Data-Generating Probability Measure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xinying Zou</a>, 
<a href="/search/cs?searchtype=author&query=Perlaza%2C+S+M">Samir M. Perlaza</a>, 
<a href="/search/cs?searchtype=author&query=Esnaola%2C+I">I&#xf1;aki Esnaola</a>, 
<a href="/search/cs?searchtype=author&query=Altman%2C+E">Eitan Altman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the Proceedings of the AAAI Conference on Artificial Intelligence (7 + 2 pages)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Statistics Theory (math.ST)

</div>
<p class="mathjax">In this paper, the worst-case probability measure over the data is introduced
as a tool for characterizing the generalization capabilities of machine
learning algorithms. More specifically, the worst-case probability measure is a
Gibbs probability measure and the unique solution to the maximization of the
expected loss under a relative entropy constraint with respect to a reference
probability measure. Fundamental generalization metrics, such as the
sensitivity of the expected loss, the sensitivity of the empirical risk, and
the generalization gap are shown to have closed-form expressions involving the
worst-case data-generating probability measure. Existing results for the Gibbs
algorithm, such as characterizing the generalization gap as a sum of mutual
information and lautum information, up to a constant factor, are recovered. A
novel parallel is established between the worst-case data-generating
probability measure and the Gibbs algorithm. Specifically, the Gibbs
probability measure is identified as a fundamental commonality of the model
space and the data space for machine learning algorithms.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12237" title="Abstract">arXiv:2312.12237</a> [<a href="/pdf/2312.12237" title="Download PDF">pdf</a>, <a href="/format/2312.12237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Roll With the Punches: Expansion and Shrinkage of Soft Label Selection  for Semi-supervised Fine-Grained Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yue Duan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+L">Lei Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Luping Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yinghuan Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">While semi-supervised learning (SSL) has yielded promising results, the more
realistic SSL scenario remains to be explored, in which the unlabeled data
exhibits extremely high recognition difficulty, e.g., fine-grained visual
classification in the context of SSL (SS-FGVC). The increased recognition
difficulty on fine-grained unlabeled data spells disaster for pseudo-labeling
accuracy, resulting in poor performance of the SSL model. To tackle this
challenge, we propose Soft Label Selection with Confidence-Aware Clustering
based on Class Transition Tracking (SoC) by reconstructing the pseudo-label
selection process by jointly optimizing Expansion Objective and Shrinkage
Objective, which is based on a soft label manner. Respectively, the former
objective encourages soft labels to absorb more candidate classes to ensure the
attendance of ground-truth class, while the latter encourages soft labels to
reject more noisy classes, which is theoretically proved to be equivalent to
entropy minimization. In comparisons with various state-of-the-art methods, our
approach demonstrates its superior performance in SS-FGVC. Checkpoints and
source code are available at https://github.com/NJUyued/SoC4SS-FGVC.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12241" title="Abstract">arXiv:2312.12241</a> [<a href="/pdf/2312.12241" title="Download PDF">pdf</a>, <a href="/format/2312.12241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GeomVerse: A Systematic Evaluation of Large Models for Geometric  Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kazemi%2C+M">Mehran Kazemi</a>, 
<a href="/search/cs?searchtype=author&query=Alvari%2C+H">Hamidreza Alvari</a>, 
<a href="/search/cs?searchtype=author&query=Anand%2C+A">Ankit Anand</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jialin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Soricut%2C+R">Radu Soricut</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models have shown impressive results for multi-hop
mathematical reasoning when the input question is only textual. Many
mathematical reasoning problems, however, contain both text and image. With the
ever-increasing adoption of vision language models (VLMs), understanding their
reasoning abilities for such problems is crucial. In this paper, we evaluate
the reasoning capabilities of VLMs along various axes through the lens of
geometry problems. We procedurally create a synthetic dataset of geometry
questions with controllable difficulty levels along multiple axes, thus
enabling a systematic evaluation. The empirical results obtained using our
benchmark for state-of-the-art VLMs indicate that these models are not as
capable in subjects like geometry (and, by generalization, other topics
requiring similar reasoning) as suggested by previous benchmarks. This is made
especially clear by the construction of our benchmark at various depth levels,
since solving higher-depth problems requires long chains of reasoning rather
than additional memorized knowledge. We release the dataset for further
research in this area.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12243" title="Abstract">arXiv:2312.12243</a> [<a href="/pdf/2312.12243" title="Download PDF">pdf</a>, <a href="/ps/2312.12243" title="Download PostScript">ps</a>, <a href="/format/2312.12243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Binary Labeling Problems in High-Degree Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lievonen%2C+H">Henrik Lievonen</a>, 
<a href="/search/cs?searchtype=author&query=Picavet%2C+T">Timoth&#xe9; Picavet</a>, 
<a href="/search/cs?searchtype=author&query=Suomela%2C+J">Jukka Suomela</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Balliu et al. (DISC 2020) classified the hardness of solving binary labeling
problems with distributed graph algorithms; in these problems the task is to
select a subset of edges in a $2$-colored tree in which white nodes of degree
$d$ and black nodes of degree $\delta$ have constraints on the number of
selected incident edges. They showed that the deterministic round complexity of
any such problem is $O_{d,\delta}(1)$, $\Theta_{d,\delta}(\log n)$, or
$\Theta_{d,\delta}(n)$, or the problem is unsolvable. However, their
classification only addresses complexity as a function of $n$; here
$O_{d,\delta}$ hides constants that may depend on parameters $d$ and $\delta$.
<br />In this work we study the complexity of binary labeling problems as a
function of all three parameters: $n$, $d$, and $\delta$. To this end, we
introduce the family of structurally simple problems, which includes, among
others, all binary labeling problems in which cardinality constraints can be
represented with a context-free grammar. We classify possible complexities of
structurally simple problems. As our main result, we show that if the
complexity of a problem falls in the broad class of $\Theta_{d,\delta}(\log
n)$, then the complexity for each $d$ and $\delta$ is always either
$\Theta(\log_d n)$, $\Theta(\log_\delta n)$, or $\Theta(\log n)$.
<br />To prove our upper bounds, we introduce a new, more aggressive version of the
rake-and-compress technique that benefits from high-degree nodes.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12244" title="Abstract">arXiv:2312.12244</a> [<a href="/pdf/2312.12244" title="Download PDF">pdf</a>, <a href="/format/2312.12244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Protecting Massive MIMO-Radar Coexistence: Precoding Design and Power  Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elfiatoure%2C+M">Mohamed Elfiatoure</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadi%2C+M">Mohammadali Mohammadi</a>, 
<a href="/search/cs?searchtype=author&query=Ngo%2C+H+Q">Hien Quoc Ngo</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+P+J">Peter J. Smith</a>, 
<a href="/search/cs?searchtype=author&query=Matthaiou%2C+M">Michail Matthaiou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 Figures, IEEE Open Journal of the Communication society
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper studies the coexistence between a downlink multiuser massive
multi-input-multi-output (MIMO) communication system and MIMO radar. The
performance of the massive MIMO system with maximum ratio ($\MR$), zero-forcing
($\ZF$), and protective $\ZF$ ($\PZF$) precoding designs is characterized in
terms of spectral efficiency (SE) and by taking the channel estimation errors
and power control into account. The idea of $\PZF$ precoding relies on the
projection of the information-bearing signal onto the null space of the radar
channel to protect the radar against communication signals. We further derive
closed-form expressions for the detection probability of the radar system for
the considered precoding designs. By leveraging the closed-form expressions for
the SE and detection probability, we formulate a power control problem at the
radar and base station (BS) to maximize the detection probability while
satisfying the per-user SE requirements. This optimization problem can be
efficiently tackled via the bisection method by solving a linear feasibility
problem. Our analysis and simulations show that the $\PZF$ design has the
highest detection probability performance among all designs, with intermediate
SE performance compared to the other two designs. Moreover, by optimally
selecting the power control coefficients at the BS and radar, the detection
probability improves significantly.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12246" title="Abstract">arXiv:2312.12246</a> [<a href="/pdf/2312.12246" title="Download PDF">pdf</a>, <a href="/format/2312.12246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MDD-UNet: Domain Adaptation for Medical Image Segmentation with  Theoretical Guarantees, a Proof of Concept
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Munk%2C+A">Asbj&#xf8;rn Munk</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+A">Ao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Nielsen%2C+M">Mads Nielsen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at NLDL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The current state-of-the art techniques for image segmentation are often
based on U-Net architectures, a U-shaped encoder-decoder networks with skip
connections. Despite the powerful performance, the architecture often does not
perform well when used on data which has different characteristics than the
data it was trained on. Many techniques for improving performance in the
presence of domain shift have been developed, however typically only have loose
connections to the theory of domain adaption. In this work, we propose an
unsupervised domain adaptation framework for U-Nets with theoretical guarantees
based on the Margin Disparity Discrepancy [1] called the MDD-UNet. We evaluate
the proposed technique on the task of hippocampus segmentation, and find that
the MDD-UNet is able to learn features which are domain-invariant with no
knowledge about the labels in the target domain. The MDD-UNet improves
performance over the standard U-Net on 11 out of 12 combinations of datasets.
This work serves as a proof of concept by demonstrating an improvement on the
U-Net in it's standard form without modern enhancements, which opens up a new
avenue of studying domain adaptation for models with very large hypothesis
spaces from both methodological and practical perspectives. Code is available
at https://github.com/asbjrnmunk/mdd-unet.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12250" title="Abstract">arXiv:2312.12250</a> [<a href="/pdf/2312.12250" title="Download PDF">pdf</a>, <a href="/format/2312.12250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ST(OR)2: Spatio-Temporal Object Level Reasoning for Activity Recognition  in the Operating Room
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamoud%2C+I">Idris Hamoud</a>, 
<a href="/search/cs?searchtype=author&query=Jamal%2C+M+A">Muhammad Abdullah Jamal</a>, 
<a href="/search/cs?searchtype=author&query=Srivastav%2C+V">Vinkle Srivastav</a>, 
<a href="/search/cs?searchtype=author&query=Mutter%2C+D">Didier Mutter</a>, 
<a href="/search/cs?searchtype=author&query=Padoy%2C+N">Nicolas Padoy</a>, 
<a href="/search/cs?searchtype=author&query=Mohareri%2C+O">Omid Mohareri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Surgical robotics holds much promise for improving patient safety and
clinician experience in the Operating Room (OR). However, it also comes with
new challenges, requiring strong team coordination and effective OR management.
Automatic detection of surgical activities is a key requirement for developing
AI-based intelligent tools to tackle these challenges. The current
state-of-the-art surgical activity recognition methods however operate on
image-based representations and depend on large-scale labeled datasets whose
collection is time-consuming and resource-expensive. This work proposes a new
sample-efficient and object-based approach for surgical activity recognition in
the OR. Our method focuses on the geometric arrangements between clinicians and
surgical devices, thus utilizing the significant object interaction dynamics in
the OR. We conduct experiments in a low-data regime study for long video
activity recognition. We also benchmark our method againstother object-centric
approaches on clip-level action classification and show superior performance.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12251" title="Abstract">arXiv:2312.12251</a> [<a href="/pdf/2312.12251" title="Download PDF">pdf</a>, <a href="/ps/2312.12251" title="Download PostScript">ps</a>, <a href="/format/2312.12251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fairness and Consensus in a Gossip Model of Social Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Betancourt%2C+J+S">Joan S. Betancourt</a>, 
<a href="/search/cs?searchtype=author&query=Aranda%2C+J">Jes&#xfa;s Aranda</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz%2C+J+F">Juan Fco. D&#xed;az</a>, 
<a href="/search/cs?searchtype=author&query=Valencia%2C+F">Frank Valencia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages total, 2 for references and 6 for a proof appendix. 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">We present a new formal model for opinion learning in social networks. Our
model is based on DeGroot, but it allows for asynchronous interaction between
agents. We show that our model might not reach consensus under standard weak
fairness assumption for distributed systems. However, we show that it reaches
consensus under strong-connectedness, absence of puppet agents and a new
condition called bounded wait. We study several notions of fairness and their
implications for consensus, introducing bounded fairness and $m$-consecutive
bounded fairness. As an important corollary, we obtain consensus for random
executions of the model. We also show that our model can be generalized to
allow for dynamic influence between agents, where consensus with connectivity
and bounded wait holds as long as the influence is bounded.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12253" title="Abstract">arXiv:2312.12253</a> [<a href="/pdf/2312.12253" title="Download PDF">pdf</a>, <a href="/format/2312.12253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geo-located Aspect Based Sentiment Analysis (ABSA) for Crowdsourced  Evaluation of Urban Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tas%2C+D">Demircan Tas</a>, 
<a href="/search/cs?searchtype=author&query=Sanatani%2C+R+P">Rohit Priyadarshi Sanatani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Created for 6.8610, Quantitative Methods for Natural Language Processing at MIT Fall 2022. 5 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Sentiment analysis methods are rapidly being adopted by the field of Urban
Design and Planning, for the crowdsourced evaluation of urban environments.
However, most models used within this domain are able to identify positive or
negative sentiment associated with a textual appraisal as a whole, without
inferring information about specific urban aspects contained within it, or the
sentiment associated with them. While Aspect Based Sentiment Analysis (ABSA) is
becoming increasingly popular, most existing ABSA models are trained on
non-urban themes such as restaurants, electronics, consumer goods and the like.
This body of research develops an ABSA model capable of extracting urban
aspects contained within geo-located textual urban appraisals, along with
corresponding aspect sentiment classification. We annotate a dataset of 2500
crowdsourced reviews of public parks, and train a Bidirectional Encoder
Representations from Transformers (BERT) model with Local Context Focus (LCF)
on this data. Our model achieves significant improvement in prediction accuracy
on urban reviews, for both Aspect Term Extraction (ATE) and Aspect Sentiment
Classification (ASC) tasks. For demonstrative analysis, positive and negative
urban aspects across Boston are spatially visualized. We hope that this model
is useful for designers and planners for fine-grained urban sentiment
evaluation.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12255" title="Abstract">arXiv:2312.12255</a> [<a href="/pdf/2312.12255" title="Download PDF">pdf</a>, <a href="/format/2312.12255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TaskFlex Solver for Multi-Agent Pursuit via Automatic Curriculum  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiayu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guosheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Botian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Huazhong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">This paper addresses the problem of multi-agent pursuit, where slow pursuers
cooperate to capture fast evaders in a confined environment with obstacles.
Existing heuristic algorithms often lack expressive coordination strategies and
are highly sensitive to task conditions, requiring extensive hyperparameter
tuning. In contrast, reinforcement learning (RL) has been applied to this
problem and is capable of obtaining cooperative pursuit strategies. However,
RL-based methods face challenges in training for complex scenarios due to the
vast amount of training data and limited adaptability to varying task
conditions, such as different scene sizes, varying numbers and speeds of
obstacles, and flexible speed ratios of the evader to the pursuer. In this
work, we combine RL and curriculum learning to introduce a flexible solver for
multiagent pursuit problems, named TaskFlex Solver (TFS), which is capable of
solving multi-agent pursuit problems with diverse and dynamically changing task
conditions in both 2-dimensional and 3-dimensional scenarios. TFS utilizes a
curriculum learning method that constructs task distributions based on training
progress, enhancing training efficiency and final performance. Our algorithm
consists of two main components: the Task Evaluator, which evaluates task
success rates and selects tasks of moderate difficulty to maintain a curriculum
archive, and the Task Sampler, which constructs training distributions by
sampling tasks from the curriculum archive to maximize policy improvement.
Experiments show that TFS produces much stronger performance than baselines and
achieves close to 100% capture rates in both 2-dimensional and 3-dimensional
multi-agent pursuit problems with diverse and dynamically changing scenes. The
project website is at https://sites.google.com/view/tfs-2023.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12258" title="Abstract">arXiv:2312.12258</a> [<a href="/pdf/2312.12258" title="Download PDF">pdf</a>, <a href="/format/2312.12258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring the relationship between soil temperature and the normalized  difference vegetation index with machine learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mortier%2C+S">Steven Mortier</a>, 
<a href="/search/cs?searchtype=author&query=Hamedpour%2C+A">Amir Hamedpour</a>, 
<a href="/search/cs?searchtype=author&query=Bussmann%2C+B">Bart Bussmann</a>, 
<a href="/search/cs?searchtype=author&query=Wandji%2C+R+P+T">Ruth Phoebe Tchana Wandji</a>, 
<a href="/search/cs?searchtype=author&query=Latr%C3%A9%2C+S">Steven Latr&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Sigurdsson%2C+B+D">Bjarni D. Sigurdsson</a>, 
<a href="/search/cs?searchtype=author&query=De+Schepper%2C+T">Tom De Schepper</a>, 
<a href="/search/cs?searchtype=author&query=Verdonck%2C+T">Tim Verdonck</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 7 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Changes in climate can greatly affect the phenology of plants, which can have
important feedback effects, such as altering the carbon cycle. These
phenological feedback effects are often induced by a shift in the start or end
dates of the growing season of plants. The normalized difference vegetation
index (NDVI) serves as a straightforward indicator for assessing the presence
of green vegetation and can also provide an estimation of the plants' growing
season. In this study, we investigated the effect of soil temperature on the
timing of the start of the season (SOS), timing of the peak of the season
(POS), and the maximum annual NDVI value (PEAK) in subarctic grassland
ecosystems between 2014 and 2019. We also explored the impact of other
meteorological variables, including air temperature, precipitation, and
irradiance, on the inter-annual variation in vegetation phenology. Using
machine learning (ML) techniques and SHapley Additive exPlanations (SHAP)
values, we analyzed the relative importance and contribution of each variable
to the phenological predictions. Our results reveal a significant relationship
between soil temperature and SOS and POS, indicating that higher soil
temperatures lead to an earlier start and peak of the growing season. However,
the Peak NDVI values showed just a slight increase with higher soil
temperatures. The analysis of other meteorological variables demonstrated their
impacts on the inter-annual variation of the vegetation phenology. Ultimately,
this study contributes to our knowledge of the relationships between soil
temperature, meteorological variables, and vegetation phenology, providing
valuable insights for predicting vegetation phenology characteristics and
managing subarctic grasslands in the face of climate change. Additionally, this
work provides a solid foundation for future ML-based vegetation phenology
studies.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12263" title="Abstract">arXiv:2312.12263</a> [<a href="/pdf/2312.12263" title="Download PDF">pdf</a>, <a href="/format/2312.12263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedDiv: Collaborative Noise Filtering for Federated Learning with Noisy  Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jichang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hui Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Z">Zicheng Liao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yizhou Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in AAAI-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Federated learning with noisy labels (F-LNL) aims at seeking an optimal
server model via collaborative distributed learning by aggregating multiple
client models trained with local noisy or clean samples. On the basis of a
federated learning framework, recent advances primarily adopt label noise
filtering to separate clean samples from noisy ones on each client, thereby
mitigating the negative impact of label noise. However, these prior methods do
not learn noise filters by exploiting knowledge across all clients, leading to
sub-optimal and inferior noise filtering performance and thus damaging training
stability. In this paper, we present FedDiv to tackle the challenges of F-LNL.
Specifically, we propose a global noise filter called Federated Noise Filter
for effectively identifying samples with noisy labels on every client, thereby
raising stability during local training sessions. Without sacrificing data
privacy, this is achieved by modeling the global distribution of label noise
across all clients. Then, in an effort to make the global model achieve higher
performance, we introduce a Predictive Consistency based Sampler to identify
more credible local data for local model training, thus preventing noise
memorization and further boosting the training stability. Extensive experiments
on CIFAR-10, CIFAR-100, and Clothing1M demonstrate that \texttt{FedDiv}
achieves superior performance over state-of-the-art F-LNL methods under
different label noise settings for both IID and non-IID data partitions. Source
code is publicly available at https://github.com/lijichang/FLNL-FedDiv.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12267" title="Abstract">arXiv:2312.12267</a> [<a href="/pdf/2312.12267" title="Download PDF">pdf</a>, <a href="/format/2312.12267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Power Flow Pursuit via Feedback-based Safe Gradient Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Colot%2C+A">Antonin Colot</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yiting Chen</a>, 
<a href="/search/eess?searchtype=author&query=Cornelusse%2C+B">Bertrand Cornelusse</a>, 
<a href="/search/eess?searchtype=author&query=Cortes%2C+J">Jorge Cortes</a>, 
<a href="/search/eess?searchtype=author&query=Dall%27Anese%2C+E">Emiliano Dall&#x27;Anese</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper considers the problem of controlling the operation of
inverter-interfaced distributed energy resources (DERs) in a distribution grid,
to achieve operational and performance goals with limited system-level
information. We develop an online feedback optimization method to drive the
DERs' power setpoints to solutions of an AC optimal power flow (OPF) problem
based only on voltage measurements (and without requiring measurements of the
power consumption of non-controllable assets). The proposed method - grounded
on the theory of control barrier functions - is based on a continuous
approximation of the projected gradient flow, appropriately modified to
accommodate measurements from the power network. We provide results in terms of
local exponential stability, and assess the robustness to errors in the
measurements and in the system Jacobian matrix. We show that the proposed
method ensures anytime satisfaction of the voltage constraints when no model
and measurement errors are present; if these errors are present and are small,
the voltage violation is practically negligible. We also discuss extensions of
the framework to virtual power plant setups. Numerical experiments on a 93-bus
distribution system and with realistic load and production profiles show a
superior performance in terms of voltage regulation relative to existing
methods.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12268" title="Abstract">arXiv:2312.12268</a> [<a href="/pdf/2312.12268" title="Download PDF">pdf</a>, <a href="/ps/2312.12268" title="Download PostScript">ps</a>, <a href="/format/2312.12268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Web 3.0 and a Decentralized Approach to Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Flanery%2C+S+A">Sarah A. Flanery</a>, 
<a href="/search/cs?searchtype=author&query=Mohanasundar%2C+K">Kamalesh Mohanasundar</a>, 
<a href="/search/cs?searchtype=author&query=Chamon%2C+C">Christiana Chamon</a>, 
<a href="/search/cs?searchtype=author&query=Kotikela%2C+S+D">Srujan D. Kotikela</a>, 
<a href="/search/cs?searchtype=author&query=Quek%2C+F+K">Francis K. Quek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">With the natural evolution of the web, the need for decentralization has
rendered the current centralized education system out of date. The student does
not "own" their credentials, as the only way their accomplishments are directly
linked to their person and considered valuable is by verification through a
stamp of an expensive, prestigious institution. However, going to a university
is no longer the only way to acquire an education; open-source learning
material is widely available and accessible through the internet. However, our
society does not deem these methods of education as verifiable if they do not
include a degree or certificate. Additionally, a valid certificate for the vast
majority of open-source courses costs a few hundred dollars to obtain. The
centralized nature of education inadvertently places students in
underprivileged communities at a disadvantage in comparison to students in
economically advantaged communities, thus a decentralized approach to education
would eliminate the vast majority of such discrepancies. In the present paper,
we integrate Decentralized Identity (DID) with Web 3.0 to upload credentials
linked directly to the user. Each credential is appended to an Ethereum
blockchain that, by design, cannot be altered once uploaded. We include DID
document based access controls to display the candidate's upload and
verification history. Finally, we utilize TLS protocols to provide a secure
connection to the internet for ensuring non-fungibility of credentials and
authentication of users.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12269" title="Abstract">arXiv:2312.12269</a> [<a href="/pdf/2312.12269" title="Download PDF">pdf</a>, <a href="/ps/2312.12269" title="Download PostScript">ps</a>, <a href="/format/2312.12269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated speech audiometry: Can it work using open-source pre-trained  Kaldi-NL automatic speech recognition?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Araiza-Illan%2C+G">Gloria Araiza-Illan</a>, 
<a href="/search/cs?searchtype=author&query=Meyer%2C+L">Luke Meyer</a>, 
<a href="/search/cs?searchtype=author&query=Truong%2C+K+P">Khiet P. Truong</a>, 
<a href="/search/cs?searchtype=author&query=Baskent%2C+D">Deniz Baskent</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages (double spaced), 5 figures, 3 tables, 54 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">A practical speech audiometry tool is the digits-in-noise (DIN) test for
hearing screening of populations of varying ages and hearing status. The test
is usually conducted by a human supervisor (e.g., clinician), who scores the
responses spoken by the listener, or online, where a software scores the
responses entered by the listener. The test has 24 digit-triplets presented in
an adaptive staircase procedure, resulting in a speech reception threshold
(SRT). We propose an alternative automated DIN test setup that can evaluate
spoken responses whilst conducted without a human supervisor, using the
open-source automatic speech recognition toolkit, Kaldi-NL. Thirty
self-reported normal-hearing Dutch adults (19-64 years) completed one
DIN+Kaldi-NL test. Their spoken responses were recorded, and used for
evaluating the transcript of decoded responses by Kaldi-NL. Study 1 evaluated
the Kaldi-NL performance through its word error rate (WER), percentage of
summed decoding errors regarding only digits found in the transcript compared
to the total number of digits present in the spoken responses. Average WER
across participants was 5.0% (range 0 - 48%, SD = 8.8%), with average decoding
errors in three triplets per participant. Study 2 analysed the effect that
triplets with decoding errors from Kaldi-NL had on the DIN test output (SRT),
using bootstrapping simulations. Previous research indicated 0.70 dB as the
typical within-subject SRT variability for normal-hearing adults. Study 2
showed that up to four triplets with decoding errors produce SRT variations
within this range, suggesting that our proposed setup could be feasible for
clinical applications.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12270" title="Abstract">arXiv:2312.12270</a> [<a href="/pdf/2312.12270" title="Download PDF">pdf</a>, <a href="/format/2312.12270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sketch Vision: Artificial Intelligence with Sight for Imagination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tas%2C+D">Demircan Tas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Written for 4.453 Creative Machine Learning at MIT, Spring 2023. 9 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">Visual design relies on seeing things in different ways, acting on them, and
seeing results to act again. Parametric design tools are often not robust to
design changes that result from sketching over the visualization of their
output. We propose a sketch to 3d workflow as an experiment medium for
evaluating neural networks and their latent spaces as a representation that is
robust to overlay sketching.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12273" title="Abstract">arXiv:2312.12273</a> [<a href="/pdf/2312.12273" title="Download PDF">pdf</a>, <a href="/format/2312.12273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VQA4CIR: Boosting Composed Image Retrieval with Visual Question  Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chun-Mei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yang Bai</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+T">Tao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhen Li</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Salman Khan</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+W">Wangmeng Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xinxing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Goh%2C+R+S+M">Rick Siow Mong Goh</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Albeit progress has been made in Composed Image Retrieval (CIR), we
empirically find that a certain percentage of failure retrieval results are not
consistent with their relative captions. To address this issue, this work
provides a Visual Question Answering (VQA) perspective to boost the performance
of CIR. The resulting VQA4CIR is a post-processing approach and can be directly
plugged into existing CIR methods. Given the top-C retrieved images by a CIR
method, VQA4CIR aims to decrease the adverse effect of the failure retrieval
results being inconsistent with the relative caption. To find the retrieved
images inconsistent with the relative caption, we resort to the "QA generation
to VQA" self-verification pipeline. For QA generation, we suggest fine-tuning
LLM (e.g., LLaMA) to generate several pairs of questions and answers from each
relative caption. We then fine-tune LVLM (e.g., LLaVA) to obtain the VQA model.
By feeding the retrieved image and question to the VQA model, one can find the
images inconsistent with relative caption when the answer by VQA is
inconsistent with the answer in the QA pair. Consequently, the CIR performance
can be boosted by modifying the ranks of inconsistently retrieved images.
Experimental results show that our proposed method outperforms state-of-the-art
CIR methods on the CIRR and Fashion-IQ datasets.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12274" title="Abstract">arXiv:2312.12274</a> [<a href="/pdf/2312.12274" title="Download PDF">pdf</a>, <a href="/format/2312.12274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intrinsic Image Diffusion for Single-view Material Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kocsis%2C+P">Peter Kocsis</a> (1), 
<a href="/search/cs?searchtype=author&query=Sitzmann%2C+V">Vincent Sitzmann</a> (2), 
<a href="/search/cs?searchtype=author&query=Nie%C3%9Fner%2C+M">Matthias Nie&#xdf;ner</a> (1) ((1) Technical University of Munich, (2) MIT EECS)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://peter-kocsis.github.io/IntrinsicImageDiffusion/">this https URL</a> Video: <a href="https://youtu.be/lz0meJlj5cA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">We present Intrinsic Image Diffusion, a generative model for appearance
decomposition of indoor scenes. Given a single input view, we sample multiple
possible material explanations represented as albedo, roughness, and metallic
maps. Appearance decomposition poses a considerable challenge in computer
vision due to the inherent ambiguity between lighting and material properties
and the lack of real datasets. To address this issue, we advocate for a
probabilistic formulation, where instead of attempting to directly predict the
true material properties, we employ a conditional generative model to sample
from the solution space. Furthermore, we show that utilizing the strong learned
prior of recent diffusion models trained on large-scale real-world images can
be adapted to material estimation and highly improves the generalization to
real images. Our method produces significantly sharper, more consistent, and
more detailed materials, outperforming state-of-the-art methods by $1.5dB$ on
PSNR and by $45\%$ better FID score on albedo prediction. We demonstrate the
effectiveness of our approach through experiments on both synthetic and
real-world datasets.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12275" title="Abstract">arXiv:2312.12275</a> [<a href="/pdf/2312.12275" title="Download PDF">pdf</a>, <a href="/format/2312.12275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergence of In-Context Reinforcement Learning from Noise Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zisman%2C+I">Ilya Zisman</a>, 
<a href="/search/cs?searchtype=author&query=Kurenkov%2C+V">Vladislav Kurenkov</a>, 
<a href="/search/cs?searchtype=author&query=Nikulin%2C+A">Alexander Nikulin</a>, 
<a href="/search/cs?searchtype=author&query=Sinii%2C+V">Viacheslav Sinii</a>, 
<a href="/search/cs?searchtype=author&query=Kolesnikov%2C+S">Sergey Kolesnikov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint, work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In-Context Reinforcement Learning is an emerging field with great potential
for advancing Artificial Intelligence. Its core capability lies in generalizing
to unseen tasks through interaction with the environment. To master these
capabilities, an agent must be trained on specifically curated data that
includes a policy improvement that an algorithm seeks to extract and then apply
in context in the environment. However, for numerous tasks, training RL agents
may be unfeasible, while obtaining human demonstrations can be relatively easy.
Additionally, it is rare to be given the optimal policy, typically, only
suboptimal demonstrations are available. We propose $AD^{\epsilon}$, a method
that leverages demonstrations without policy improvement and enables multi-task
in-context learning in the presence of a suboptimal demonstrator. This is
achieved by artificially creating a history of incremental improvement, wherein
noise is systematically introduced into the demonstrator's policy.
Consequently, each successive transition illustrates a marginally better
trajectory than the previous one. Our approach was tested on the Dark Room and
Dark Key-to-Door environments, resulting in over a $\textbf{2}$x improvement
compared to the best available policy in the data.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12276" title="Abstract">arXiv:2312.12276</a> [<a href="/pdf/2312.12276" title="Download PDF">pdf</a>, <a href="/format/2312.12276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt-based Domain Discrimination for Multi-source Time Series Domain  Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+G">Guangji Bai</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+W">Wei Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhengzhang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Liang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haifeng Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Undergoing work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Time series domain adaptation stands as a pivotal and intricate challenge
with diverse applications, including but not limited to human activity
recognition, sleep stage classification, and machine fault diagnosis. Despite
the numerous domain adaptation techniques proposed to tackle this complex
problem, their primary focus has been on the common representations of time
series data. This concentration might inadvertently lead to the oversight of
valuable domain-specific information originating from different source domains.
To bridge this gap, we introduce POND, a novel prompt-based deep learning model
designed explicitly for multi-source time series domain adaptation. POND is
tailored to address significant challenges, notably: 1) The unavailability of a
quantitative relationship between meta-data information and time series
distributions, and 2) The dearth of exploration into extracting domain-specific
meta-data information. In this paper, we present an instance-level prompt
generator and a fidelity loss mechanism to facilitate the faithful learning of
meta-data information. Additionally, we propose a domain discrimination
technique to discern domain-specific meta-data information from multiple source
domains. Our approach involves a simple yet effective meta-learning algorithm
to optimize the objective efficiently. Furthermore, we augment the model's
performance by incorporating the Mixture of Expert (MoE) technique. The
efficacy and robustness of our proposed POND model are extensively validated
through experiments across 50 scenarios encompassing five datasets, which
demonstrates that our proposed POND model outperforms the state-of-the-art
methods by up to $66\%$ on the F1-score.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12278" title="Abstract">arXiv:2312.12278</a> [<a href="/pdf/2312.12278" title="Download PDF">pdf</a>, <a href="/ps/2312.12278" title="Download PostScript">ps</a>, <a href="/format/2312.12278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Hardness of Local Certification of Finite-State Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maldonado%2C+D">Diego Maldonado</a>, 
<a href="/search/cs?searchtype=author&query=Montealegre%2C+P">Pedro Montealegre</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%ADos-Wilson%2C+M">Mart&#xed;n R&#xed;os-Wilson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Finite-State Dynamics (FSD) is one of the simplest and constrained
distributed systems. An FSD is defined by an $n$-node network, with each node
maintaining an internal state selected from a finite set. At each time-step,
these nodes synchronously update their internal states based solely on the
states of their neighboring nodes.
<br />Rather than focusing on specific types of local functions, in this article,
our primary focus is on the problem of determining the maximum time required
for an FSD to reach a stable global state. This global state can be seen as the
acceptance state or as the output of a distributed computation. For fixed $k$
and $q$, we define the problem $\text{convergence}(k,q)$, which consists of
deciding if a $q$-state FSD converges in at most $k$ time-steps.
<br />Our main focus is to study the problem $\text{convergence}$ from the
perspective of distributed certification, with a focus on the model of
proof-labeling schemes (PLS). First, we study the problem $\text{convergence}$
on arbitrary graphs and show that every PLS has certificates of size
$\Theta(n^2)$ (up to logarithmic factors). Then, we turn to the restriction of
the problem on graphs of maximum degree $\Delta$. Roughly, we show that the
problem admits a PLS with certificates of size $\Delta^{k+1}$, while every PLS
requires certificates of size at least $2^{k/6} \cdot 6/k$ on graphs of maximum
degree 3.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12282" title="Abstract">arXiv:2312.12282</a> [<a href="/pdf/2312.12282" title="Download PDF">pdf</a>, <a href="/format/2312.12282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallel iterative solvers for discretized reduced optimality systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Langer%2C+U">Ulrich Langer</a>, 
<a href="/search/math?searchtype=author&query=L%C3%B6scher%2C+R">Richard L&#xf6;scher</a>, 
<a href="/search/math?searchtype=author&query=Steinbach%2C+O">Olaf Steinbach</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+H">Huidong Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose, analyze, and test new iterative solvers for large-scale systems
of linear algebraic equations arising from the finite element discretization of
reduced optimality systems defining the finite element approximations to the
solution of elliptic tracking-type distributed optimal control problems with
both the standard $L_2$ and the more general energy regularizations. If we aim
at an approximation of the given desired state $y_d$ by the computed finite
element state $y_h$ that asymptotically differs from $y_d$ in the order of the
best $L_2$ approximation under acceptable costs for the control, then the
optimal choice of the regularization parameter $\varrho$ is linked to the
mesh-size $h$ by the relations $\varrho=h^4$ and $\varrho=h^2$ for the $L_2$
and the energy regularization, respectively. For this setting, we can construct
efficient parallel iterative solvers for the reduced finite element optimality
systems. These results can be generalized to variable regularization parameters
adapted to the local behavior of the mesh-size that can heavily change in case
of adaptive mesh refinement. Similar results can be obtained for the space-time
finite element discretization of the corresponding parabolic and hyperbolic
optimal control problems.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12288" title="Abstract">arXiv:2312.12288</a> [<a href="/pdf/2312.12288" title="Download PDF">pdf</a>, <a href="/ps/2312.12288" title="Download PostScript">ps</a>, <a href="/format/2312.12288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Qutrit Codes from Pure and Bordered Multidimensional Circulant  Construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seneviratne%2C+P">Padmapani Seneviratne</a>, 
<a href="/search/cs?searchtype=author&query=Cuff%2C+H">Hannah Cuff</a>, 
<a href="/search/cs?searchtype=author&query=Koletsos%2C+A">Alexandra Koletsos</a>, 
<a href="/search/cs?searchtype=author&query=Seekamp%2C+K">Kerry Seekamp</a>, 
<a href="/search/cs?searchtype=author&query=Thananopavarn%2C+A">Adrian Thananopavarn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">We use multidimensional circulant approach to construct new qutrit stabilizer
$\dsb{\ell, 0, d}$ codes with parameters $(\ell, d) \in \{(51, 16), (52, 16),
(54, 17), (55, 17), (57, 17)\}$ through symplectic self-dual additive codes
over $\F_9$. In addition to these five new codes, we use bordered construction
to derive two more qutrit codes with parameters $(\ell, d) \in \{(53, 16), (56,
17)\}$ that improve upon previously best known parameters.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12290" title="Abstract">arXiv:2312.12290</a> [<a href="/pdf/2312.12290" title="Download PDF">pdf</a>, <a href="/format/2312.12290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward enriched Cognitive Learning with XAI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suffian%2C+M">Muhammad Suffian</a>, 
<a href="/search/cs?searchtype=author&query=Kuhl%2C+U">Ulrike Kuhl</a>, 
<a href="/search/cs?searchtype=author&query=Alonso-Moral%2C+J+M">Jose M. Alonso-Moral</a>, 
<a href="/search/cs?searchtype=author&query=Bogliolo%2C+A">Alessandro Bogliolo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">As computational systems supported by artificial intelligence (AI) techniques
continue to play an increasingly pivotal role in making high-stakes
recommendations and decisions across various domains, the demand for
explainable AI (XAI) has grown significantly, extending its impact into
cognitive learning research. Providing explanations for novel concepts is
recognised as a fundamental aid in the learning process, particularly when
addressing challenges stemming from knowledge deficiencies and skill
application. Addressing these difficulties involves timely explanations and
guidance throughout the learning process, prompting the interest of AI experts
in developing explainer models. In this paper, we introduce an intelligent
system (CL-XAI) for Cognitive Learning which is supported by XAI, focusing on
two key research objectives: exploring how human learners comprehend the
internal mechanisms of AI models using XAI tools and evaluating the
effectiveness of such tools through human feedback. The use of CL-XAI is
illustrated with a game-inspired virtual use case where learners tackle
combinatorial problems to enhance problem-solving skills and deepen their
understanding of complex concepts, highlighting the potential for
transformative advances in cognitive learning and co-learning.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12295" title="Abstract">arXiv:2312.12295</a> [<a href="/pdf/2312.12295" title="Download PDF">pdf</a>, <a href="/format/2312.12295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Describing Robots from Design to Learning: Towards an Interactive  Lifecycle Representation of Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+N">Nuofan Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+F">Fang Wan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Chaoyang Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures, 2 tables, submitted to ICRA2024 for review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The robot development process is divided into several stages, which create
barriers to the exchange of information between these different stages. We
advocate for an interactive lifecycle representation, extending from robot
morphology design to learning, and introduce the role of robot description
formats in facilitating information transfer throughout this pipeline. We
analyzed the relationship between design and simulation, enabling us to employ
robot process automation methods for transferring information from the design
phase to the learning phase in simulation. As part of this effort, we have
developed an open-source plugin called ACDC4Robot for Fusion 360, which
automates this process and transforms Fusion 360 into a user-friendly graphical
interface for creating and editing robot description formats. Additionally, we
offer an out-of-the-box robot model library to streamline and reduce repetitive
tasks. All codes are hosted open-source.
(\url{https://github.com/bionicdl-sustech/ACDC4Robot})
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12299" title="Abstract">arXiv:2312.12299</a> [<a href="/pdf/2312.12299" title="Download PDF">pdf</a>, <a href="/format/2312.12299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instruct-SCTG: Guiding Sequential Controlled Text Generation through  Instructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yinhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yixuan Su</a>, 
<a href="/search/cs?searchtype=author&query=Shareghi%2C+E">Ehsan Shareghi</a>, 
<a href="/search/cs?searchtype=author&query=Collier%2C+N">Nigel Collier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Instruction-tuned large language models have shown remarkable performance in
aligning generated text with user intentions across various tasks. However,
maintaining human-like discourse structure in the generated text remains a
challenging research question. In this paper, we propose Instruct-SCTG, a
flexible and effective sequential framework that harnesses instruction-tuned
language models to generate structurally coherent text in both fine-tuned and
zero-shot setups. Our framework generates articles in a section-by-section
manner, aligned with the desired human structure using natural language
instructions. Furthermore, we introduce a new automatic metric that measures
discourse divergence in a fuzzy manner. Extensive experiments on three datasets
from representative domains of news and recipes demonstrate the
state-of-the-art performance of our framework in imposing discourse structure
during text generation, as verified by both automatic and human evaluation. Our
code will be available on Github.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12303" title="Abstract">arXiv:2312.12303</a> [<a href="/pdf/2312.12303" title="Download PDF">pdf</a>, <a href="/format/2312.12303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Peer Neighborhood Mechanisms: A Framework for Mechanism Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Richardson%2C+A">Adam Richardson</a>, 
<a href="/search/cs?searchtype=author&query=Faltings%2C+B">Boi Faltings</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full paper with technical Appendix to reference from AAAI conference paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Peer prediction incentive mechanisms for crowdsourcing are generally limited
to eliciting samples from categorical distributions. Prior work on extending
peer prediction to arbitrary distributions has largely relied on assumptions on
the structures of the distributions or known properties of the data providers.
We introduce a novel class of incentive mechanisms that extend peer prediction
mechanisms to arbitrary distributions by replacing the notion of an exact match
with a concept of neighborhood matching. We present conditions on the belief
updates of the data providers that guarantee incentive-compatibility for
rational data providers, and admit a broad class of possible reasonable
updates.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12309" title="Abstract">arXiv:2312.12309</a> [<a href="/pdf/2312.12309" title="Download PDF">pdf</a>, <a href="/format/2312.12309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TeamCAD -- A Multimodal Interface for Remote Computer Aided Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tas%2C+D">Demircan Tas</a>, 
<a href="/search/cs?searchtype=author&query=Chatzinikolis%2C+D">Dimitrios Chatzinikolis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Created for 6.835, Intelligent Multimodal User Interfaces at MIT, Spring 2022. Submitted to CHI 2024. 10 pages, 6 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Remote collaboration is a common reality of spatial design processes, but
tools for computer aided design were made for single users. Via TeamCAD, we
introduce a user experience where online remote collaboration experience is
more like working on a table. Using speech and gesture recognition based on
state of the art machine learning through webcam and microphone input, TeamCAD
plugs into existing software through API's, keybindings, and mouse input. We
share results from user studies conducted on graduate students from &lt;removed
for double blind review&gt;. Our user tests were run on Blender animation
software, making simultaneous use of both modalities for given tasks. We
mitigated challenges in terms of robustness and latency in readily available
voice recognition models. Our prototype has proven to be an intuitive
interface, providing a suitable denominator for collaborators with or without
previous experience in three-dimensional modeling applications.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12312" title="Abstract">arXiv:2312.12312</a> [<a href="/pdf/2312.12312" title="Download PDF">pdf</a>, <a href="/format/2312.12312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bioinspired Soft Robotics: state of the art, challenges, and future  directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hammond%2C+M">Maxwell Hammond</a>, 
<a href="/search/cs?searchtype=author&query=Cichella%2C+V">Venanzio Cichella</a>, 
<a href="/search/cs?searchtype=author&query=Lamuta%2C+C">Caterina Lamuta</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Current Robotics Reports, 4(3), 65-80 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Purpose of Review: This review provides an overview of the state of the art
in bioinspired soft robotics with by examining advancements in actuation,
functionality, modeling, and control. Recent Findings: Recent research into
actuation methods, such as artificial muscles, have expanded the functionality
and potential use of bioinspired soft robots. Additionally, the application of
finite dimensional models has improved computational efficiency for modeling
soft continuum systems, and garnered interest as a basis for controller
formulation. Summary: Bioinspiration in the field of soft robotics has led to
diverse approaches to problems in a range of task spaces. In particular, new
capabilities in system simplification, miniaturization, and untethering have
each contributed to the field's growth. There is still significant room for
improvement in the streamlining of design and manufacturing for these systems,
as well as in their control.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12314" title="Abstract">arXiv:2312.12314</a> [<a href="/pdf/2312.12314" title="Download PDF">pdf</a>, <a href="/format/2312.12314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> First qualitative observations on deep learning vision model YOLO and  DETR for automated driving in Austria
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schoder%2C+S">Stefan Schoder</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> draft
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This study investigates the application of single and two-stage 2D-object
detection algorithms like You Only Look Once (YOLO), Real-Time DEtection
TRansformer (RT-DETR) algorithm for automated object detection to enhance road
safety for autonomous driving on Austrian roads. The YOLO algorithm is a
state-of-the-art real-time object detection system known for its efficiency and
accuracy. In the context of driving, its potential to rapidly identify and
track objects is crucial for advanced driver assistance systems (ADAS) and
autonomous vehicles. The research focuses on the unique challenges posed by the
road conditions and traffic scenarios in Austria. The country's diverse
landscape, varying weather conditions, and specific traffic regulations
necessitate a tailored approach for reliable object detection. The study
utilizes a selective dataset comprising images and videos captured on Austrian
roads, encompassing urban, rural, and alpine environments.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12318" title="Abstract">arXiv:2312.12318</a> [<a href="/pdf/2312.12318" title="Download PDF">pdf</a>, <a href="/format/2312.12318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Alternate View on Optimal Filtering in an RKHS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Colburn%2C+B">Benjamin Colburn</a>, 
<a href="/search/cs?searchtype=author&query=Principe%2C+J+C">Jose C. Principe</a>, 
<a href="/search/cs?searchtype=author&query=Giraldo%2C+L+G+S">Luis G. Sanchez Giraldo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Kernel Adaptive Filtering (KAF) are mathematically principled methods which
search for a function in a Reproducing Kernel Hilbert Space. While they work
well for tasks such as time series prediction and system identification they
are plagued by a linear relationship between number of training samples and
model size, hampering their use on the very large data sets common in today's
data saturated world. Previous methods try to solve this issue by
sparsification. We describe a novel view of optimal filtering which may provide
a route towards solutions in a RKHS which do not necessarily have this linear
growth in model size. We do this by defining a RKHS in which the time structure
of a stochastic process is still present. Using correntropy [11], an extension
of the idea of a covariance function, we create a time based functional which
describes some potentially nonlinear desired mapping function. This form of a
solution may provide a fruitful line of research for creating more efficient
representations of functionals in a RKHS, while theoretically providing
computational complexity in the test set similar to Wiener solution.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12321" title="Abstract">arXiv:2312.12321</a> [<a href="/pdf/2312.12321" title="Download PDF">pdf</a>, <a href="/format/2312.12321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bypassing the Safety Training of Open-Source LLMs with Priming Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vega%2C+J">Jason Vega</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhary%2C+I">Isha Chaudhary</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Changming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+G">Gagandeep Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">With the recent surge in popularity of LLMs has come an ever-increasing need
for LLM safety training. In this paper, we show that SOTA open-source LLMs are
vulnerable to simple, optimization-free attacks we refer to as $\textit{priming
attacks}$, which are easy to execute and effectively bypass alignment from
safety training. Our proposed attack improves the Attack Success Rate on
Harmful Behaviors, as measured by Llama Guard, by up to $3.3\times$ compared to
baselines. Source code and data are available at
https://github.com/uiuc-focal-lab/llm-priming-attacks .
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12325" title="Abstract">arXiv:2312.12325</a> [<a href="/pdf/2312.12325" title="Download PDF">pdf</a>, <a href="/format/2312.12325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Local Satisfaction of Long-Run Average Objectives in Markov  Decision Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kla%C5%A1ka%2C+D">David Kla&#x161;ka</a>, 
<a href="/search/cs?searchtype=author&query=Ku%C4%8Dera%2C+A">Anton&#xed;n Ku&#x10d;era</a>, 
<a href="/search/cs?searchtype=author&query=K%C5%AFr%2C+V">Vojt&#x11b;ch K&#x16f;r</a>, 
<a href="/search/cs?searchtype=author&query=Musil%2C+V">V&#xed;t Musil</a>, 
<a href="/search/cs?searchtype=author&query=%C5%98eh%C3%A1k%2C+V">Vojt&#x11b;ch &#x158;eh&#xe1;k</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Long-run average optimization problems for Markov decision processes (MDPs)
require constructing policies with optimal steady-state behavior, i.e., optimal
limit frequency of visits to the states. However, such policies may suffer from
local instability, i.e., the frequency of states visited in a bounded time
horizon along a run differs significantly from the limit frequency. In this
work, we propose an efficient algorithmic solution to this problem.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12333" title="Abstract">arXiv:2312.12333</a> [<a href="/pdf/2312.12333" title="Download PDF">pdf</a>, <a href="/format/2312.12333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Path Planning for Continuum Rods Using Bernstein Surfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hammond%2C+M">Maxwell Hammond</a>, 
<a href="/search/cs?searchtype=author&query=Cichella%2C+V">Venanzio Cichella</a>, 
<a href="/search/cs?searchtype=author&query=Golestaneh%2C+A+F">Amirreza F. Golestaneh</a>, 
<a href="/search/cs?searchtype=author&query=Lamuta%2C+C">Caterina Lamuta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper presents a method for optimal motion planning of continuum robots
by employing Bernstein surfaces to approximate the system's dynamics and impose
complex constraints, including collision avoidance. The main contribution is
the approximation of infinite-dimensional continuous problems into their
discrete counterparts, facilitating their solution using standard optimization
solvers. This discretization leverages the unique properties of Bernstein
surface, providing a framework that extends previous works which focused on
ODEs approximated by Bernstein polynomials. Numerical validations are conducted
through several numerical scenarios. The presented methodology offers a
promising direction for solving complex optimal control problems in the realm
of soft robotics.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12334" title="Abstract">arXiv:2312.12334</a> [<a href="/pdf/2312.12334" title="Download PDF">pdf</a>, <a href="/format/2312.12334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PowMix: A Versatile Regularizer for Multimodal Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Georgiou%2C+E">Efthymios Georgiou</a>, 
<a href="/search/cs?searchtype=author&query=Avrithis%2C+Y">Yannis Avrithis</a>, 
<a href="/search/cs?searchtype=author&query=Potamianos%2C+A">Alexandros Potamianos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Multimodal sentiment analysis (MSA) leverages heterogeneous data sources to
interpret the complex nature of human sentiments. Despite significant progress
in multimodal architecture design, the field lacks comprehensive regularization
methods. This paper introduces PowMix, a versatile embedding space regularizer
that builds upon the strengths of unimodal mixing-based regularization
approaches and introduces novel algorithmic components that are specifically
tailored to multimodal tasks. PowMix is integrated before the fusion stage of
multimodal architectures and facilitates intra-modal mixing, such as mixing
text with text, to act as a regularizer. PowMix consists of five components: 1)
a varying number of generated mixed examples, 2) mixing factor reweighting, 3)
anisotropic mixing, 4) dynamic mixing, and 5) cross-modal label mixing.
Extensive experimentation across benchmark MSA datasets and a broad spectrum of
diverse architectural designs demonstrate the efficacy of PowMix, as evidenced
by consistent performance improvements over baselines and existing mixing
methods. An in-depth ablation study highlights the critical contribution of
each PowMix component and how they synergistically enhance performance.
Furthermore, algorithmic analysis demonstrates how PowMix behaves in different
scenarios, particularly comparing early versus late fusion architectures.
Notably, PowMix enhances overall performance without sacrificing model
robustness or magnifying text dominance. It also retains its strong performance
in situations of limited data. Our findings position PowMix as a promising
versatile regularization strategy for MSA. Code will be made available.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12337" title="Abstract">arXiv:2312.12337</a> [<a href="/pdf/2312.12337" title="Download PDF">pdf</a>, <a href="/format/2312.12337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> pixelSplat: 3D Gaussian Splats from Image Pairs for Scalable  Generalizable 3D Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Charatan%2C+D">David Charatan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sizhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Tagliasacchi%2C+A">Andrea Tagliasacchi</a>, 
<a href="/search/cs?searchtype=author&query=Sitzmann%2C+V">Vincent Sitzmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://pixelsplat.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce pixelSplat, a feed-forward model that learns to reconstruct 3D
radiance fields parameterized by 3D Gaussian primitives from pairs of images.
Our model features real-time and memory-efficient rendering for scalable
training as well as fast 3D reconstruction at inference time. To overcome local
minima inherent to sparse and locally supported representations, we predict a
dense probability distribution over 3D and sample Gaussian means from that
probability distribution. We make this sampling operation differentiable via a
reparameterization trick, allowing us to back-propagate gradients through the
Gaussian splatting representation. We benchmark our method on wide-baseline
novel view synthesis on the real-world RealEstate10k and ACID datasets, where
we outperform state-of-the-art light field transformers and accelerate
rendering by 2.5 orders of magnitude while reconstructing an interpretable and
editable 3D radiance field.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12338" title="Abstract">arXiv:2312.12338</a> [<a href="/pdf/2312.12338" title="Download PDF">pdf</a>, <a href="/format/2312.12338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smart Connected Farms and Networked Farmers to Tackle Climate Challenges  Impacting Agricultural Production
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balabaygloo%2C+B+J">Behzad J. Balabaygloo</a>, 
<a href="/search/cs?searchtype=author&query=Bekee%2C+B">Barituka Bekee</a>, 
<a href="/search/cs?searchtype=author&query=Blair%2C+S+W">Samuel W. Blair</a>, 
<a href="/search/cs?searchtype=author&query=Fey%2C+S">Suzanne Fey</a>, 
<a href="/search/cs?searchtype=author&query=Fotouhi%2C+F">Fateme Fotouhi</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Ashish Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Menke%2C+K">Kevin Menke</a>, 
<a href="/search/cs?searchtype=author&query=Vangala%2C+A">Anusha Vangala</a>, 
<a href="/search/cs?searchtype=author&query=Palomares%2C+J+C+M">Jorge C. M. Palomares</a>, 
<a href="/search/cs?searchtype=author&query=Prestholt%2C+A">Aaron Prestholt</a>, 
<a href="/search/cs?searchtype=author&query=Tanwar%2C+V+K">Vishesh K. Tanwar</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+X">Xu Tao</a>, 
<a href="/search/cs?searchtype=author&query=Carroll%2C+M+E">Matthew E. Carroll</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Sajal Das</a>, 
<a href="/search/cs?searchtype=author&query=Depaula%2C+G">Gil Depaula</a>, 
<a href="/search/cs?searchtype=author&query=Kyveryga%2C+P">Peter Kyveryga</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S">Soumik Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Segovia%2C+M">Michelle Segovia</a>, 
<a href="/search/cs?searchtype=author&query=Sylvestri%2C+S">Simone Sylvestri</a>, 
<a href="/search/cs?searchtype=author&query=Valdivia%2C+C">Corinne Valdivia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">To meet the grand challenges of agricultural production including climate
change impacts on crop production, a tight integration of social science,
technology and agriculture experts including farmers are needed. There are
rapid advances in information and communication technology, precision
agriculture and data analytics, which are creating a fertile field for the
creation of smart connected farms (SCF) and networked farmers. A network and
coordinated farmer network provides unique advantages to farmers to enhance
farm production and profitability, while tackling adverse climate events. The
aim of this article is to provide a comprehensive overview of the state of the
art in SCF including the advances in engineering, computer sciences, data
sciences, social sciences and economics including data privacy, sharing and
technology adoption.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12339" title="Abstract">arXiv:2312.12339</a> [<a href="/pdf/2312.12339" title="Download PDF">pdf</a>, <a href="/format/2312.12339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Value Explicit Pretraining for Goal-Based Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lekkala%2C+K">Kiran Lekkala</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+H">Henghui Bao</a>, 
<a href="/search/cs?searchtype=author&query=Sontakke%2C+S">Sumedh Sontakke</a>, 
<a href="/search/cs?searchtype=author&query=Itti%2C+L">Laurent Itti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CoRL 2023 Workshop on PRL
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">We propose a method that allows for learning task-agnostic representations
based on value function estimates from a sequence of observations where the
last frame corresponds to a goal. These representations would learn to relate
states across different tasks, based on the temporal distance to the goal
state, irrespective of the appearance changes and dynamics. This method could
be used to transfer learnt policies/skills to unseen related tasks.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12340" title="Abstract">arXiv:2312.12340</a> [<a href="/pdf/2312.12340" title="Download PDF">pdf</a>, <a href="/format/2312.12340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Geometric Fracture Assembly via Co-creation Space among  Assemblers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruiyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaxiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zexi Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chao Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Geometric fracture assembly presents a challenging practical task in
archaeology and 3D computer vision. Previous methods have focused solely on
assembling fragments based on semantic information, which has limited the
quantity of objects that can be effectively assembled. Therefore, there is a
need to develop a scalable framework for geometric fracture assembly without
relying on semantic information. To improve the effectiveness of assembling
geometric fractures without semantic information, we propose a co-creation
space comprising several assemblers capable of gradually and unambiguously
assembling fractures. Additionally, we introduce a novel loss function, i.e.,
the geometric-based collision loss, to address collision issues during the
fracture assembly process and enhance the results. Our framework exhibits
better performance on both PartNet and Breaking Bad datasets compared to
existing state-of-the-art frameworks. Extensive experiments and quantitative
comparisons demonstrate the effectiveness of our proposed framework, which
features linear computational complexity, enhanced abstraction, and improved
generalization. Our code is publicly available at
https://github.com/Ruiyuan-Zhang/CCS.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12341" title="Abstract">arXiv:2312.12341</a> [<a href="/pdf/2312.12341" title="Download PDF">pdf</a>, <a href="/format/2312.12341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Engineering an Exact Pseudo-Boolean Model Counter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Suwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Meel%2C+K+S">Kuldeep S. Meel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures. To appear in AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Model counting, a fundamental task in computer science, involves determining
the number of satisfying assignments to a Boolean formula, typically
represented in conjunctive normal form (CNF). While model counting for CNF
formulas has received extensive attention with a broad range of applications,
the study of model counting for Pseudo-Boolean (PB) formulas has been
relatively overlooked. Pseudo-Boolean formulas, being more succinct than
propositional Boolean formulas, offer greater flexibility in representing
real-world problems. Consequently, there is a crucial need to investigate
efficient techniques for model counting for PB formulas.
<br />In this work, we propose the first exact Pseudo-Boolean model counter,
PBCount, that relies on knowledge compilation approach via algebraic decision
diagrams. Our extensive empirical evaluation shows that PBCount can compute
counts for 1513 instances while the current state-of-the-art approach could
only handle 1013 instances. Our work opens up several avenues for future work
in the context of model counting for PB formulas, such as the development of
preprocessing techniques and exploration of approaches other than knowledge
compilation.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12343" title="Abstract">arXiv:2312.12343</a> [<a href="/pdf/2312.12343" title="Download PDF">pdf</a>, <a href="/format/2312.12343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Avoiding Data Contamination in Language Model Evaluation: Dynamic Test  Construction with Latest Materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yucheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Geurin%2C+F">Frank Geurin</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chenghua Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Data contamination in evaluation is getting increasingly prevalent with the
emerge of language models pre-trained on super large, automatically-crawled
corpora. This problem leads to significant challenges in accurate assessment of
model capabilities and generalisations. In this paper, we propose LatestEval,
an automatic method leverages the most recent texts to create uncontaminated
reading comprehension evaluations. LatestEval avoids data contamination by only
using texts published within a recent time window, ensuring no overlap with the
training corpora of pre-trained language models. We develop LatestEval
automated pipeline to 1) gather latest texts; 2) identify key information, and
3) construct questions targeting the information while removing the existing
answers from the context. This encourages models to infer the answers
themselves based on the remaining context, rather than just copy-paste. Our
experiments demonstrate that language models exhibit negligible memorisation
behaviours on LatestEval as opposed to previous benchmarks, suggesting a
significantly reduced risk of data contamination and leading to a more robust
evaluation. Data and code are publicly available at:
https://github.com/liyucheng09/LatestEval.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12345" title="Abstract">arXiv:2312.12345</a> [<a href="/pdf/2312.12345" title="Download PDF">pdf</a>, <a href="/format/2312.12345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Effectiveness of Retrieval, Alignment, and Replay in Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di+Palo%2C+N">Norman Di Palo</a>, 
<a href="/search/cs?searchtype=author&query=Johns%2C+E">Edward Johns</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in IEEE Robotics and Automation Letters (RA-L). (Accepted December 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Imitation learning with visual observations is notoriously inefficient when
addressed with end-to-end behavioural cloning methods. In this paper, we
explore an alternative paradigm which decomposes reasoning into three phases.
First, a retrieval phase, which informs the robot what it can do with an
object. Second, an alignment phase, which informs the robot where to interact
with the object. And third, a replay phase, which informs the robot how to
interact with the object. Through a series of real-world experiments on
everyday tasks, such as grasping, pouring, and inserting objects, we show that
this decomposition brings unprecedented learning efficiency, and effective
inter- and intra-class generalisation. Videos are available at
https://www.robot-learning.uk/retrieval-alignment-replay.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12347" title="Abstract">arXiv:2312.12347</a> [<a href="/pdf/2312.12347" title="Download PDF">pdf</a>, <a href="/format/2312.12347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SMC-NCA: Semantic-guided Multi-level Contrast for Semi-supervised Action  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Feixiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zheheng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Huiyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuelong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semi-supervised action segmentation aims to perform frame-wise classification
in long untrimmed videos, where only a fraction of videos in the training set
have labels. Recent studies have shown the potential of contrastive learning in
unsupervised representation learning using unlabelled data. However, learning
the representation of each frame by unsupervised contrastive learning for
action segmentation remains an open and challenging problem. In this paper, we
propose a novel Semantic-guided Multi-level Contrast scheme with a
Neighbourhood-Consistency-Aware unit (SMC-NCA) to extract strong frame-wise
representations for semi-supervised action segmentation. Specifically, for
representation learning, SMC is firstly used to explore intra- and
inter-information variations in a unified and contrastive way, based on dynamic
clustering process of the original input, encoded semantic and temporal
features. Then, the NCA module, which is responsible for enforcing spatial
consistency between neighbourhoods centered at different frames to alleviate
over-segmentation issues, works alongside SMC for semi-supervised learning. Our
SMC outperforms the other state-of-the-art methods on three benchmarks,
offering improvements of up to 17.8% and 12.6% in terms of edit distance and
accuracy, respectively. Additionally, the NCA unit results in significant
better segmentation performance against the others in the presence of only 5%
labelled videos. We also demonstrate the effectiveness of the proposed method
on our Parkinson's Disease Mouse Behaviour (PDMB) dataset. The code and
datasets will be made publicly available.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12353" title="Abstract">arXiv:2312.12353</a> [<a href="/pdf/2312.12353" title="Download PDF">pdf</a>, <a href="/format/2312.12353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamical approximation and sensor placement for filtering problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mula%2C+O">Olga Mula</a>, 
<a href="/search/math?searchtype=author&query=Pagliantini%2C+C">Cecilia Pagliantini</a>, 
<a href="/search/math?searchtype=author&query=Vismara%2C+F">Federico Vismara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider the inverse problem of reconstructing an unknown function $u$
from a finite set of measurements, under the assumption that $u$ is the
trajectory of a transport-dominated problem with unknown input parameters. We
propose an algorithm based on the Parameterized Background Data-Weak method
(PBDW) where dynamical sensor placement is combined with approximation spaces
that evolve in time. We prove that the method ensures an accurate
reconstruction at all times and allows to incorporate relevant physical
properties in the reconstructed solutions by suitably evolving the dynamical
approximation space. As an application of this strategy we consider Hamiltonian
systems modeling wave-type phenomena, where preservation of the geometric
structure of the flow plays a crucial role in the accuracy and stability of the
reconstructed trajectory.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12354" title="Abstract">arXiv:2312.12354</a> [<a href="/pdf/2312.12354" title="Download PDF">pdf</a>, <a href="/format/2312.12354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to apply tree decomposition ideas in large networks?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carmesin%2C+J">Johannes Carmesin</a>, 
<a href="/search/cs?searchtype=author&query=Frenkel%2C+S">Sarah Frenkel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">Graph decompositions are the natural generalisation of tree decompositions
where the decomposition tree is replaced by a genuine graph. Recently they
found theoretical applications in the theory of sparsity, topological graph
theory, structural graph theory and geometric group theory.
<br />We demonstrate applicability of graph decompositions on large networks by
implementing an efficient algorithm and testing it on road networks.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12355" title="Abstract">arXiv:2312.12355</a> [<a href="/pdf/2312.12355" title="Download PDF">pdf</a>, <a href="/format/2312.12355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformed Primal-Dual Methods with Variable-Preconditioners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+L">Long Chen</a>, 
<a href="/search/math?searchtype=author&query=Guo%2C+R">Ruchi Guo</a>, 
<a href="/search/math?searchtype=author&query=Wei%2C+J">Jingrong Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper introduces a novel Transformed Primal-Dual with
variable-metric/preconditioner (TPDv) algorithm, designed to efficiently solve
affine constrained optimization problems common in nonlinear partial
differential equations (PDEs). Diverging from traditional methods, TPDv
iteratively updates time-evolving preconditioning operators, enhancing
adaptability. The algorithm is derived and analyzed, demonstrating global
linear convergence rates under mild assumptions. Numerical experiments on
challenging nonlinear PDEs, including the Darcy-Forchheimer model and a
nonlinear electromagnetic problem, showcase the algorithm's superiority over
existing methods in terms of iteration numbers and computational efficiency.
The paper concludes with a comprehensive convergence analysis.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12358" title="Abstract">arXiv:2312.12358</a> [<a href="/pdf/2312.12358" title="Download PDF">pdf</a>, <a href="/format/2312.12358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Localization and Discrete Beamforming with a Large Reconfigurable  Intelligent Surface
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Baojia Luo</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yili Deng</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+M">Miaomiao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhongyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+W">Wei Han</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+B">Bo Bai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In millimeter-wave (mmWave) cellular systems, reconfigurable intelligent
surfaces (RISs) are foreseeably deployed with a large number of reflecting
elements to achieve high beamforming gains. The large-sized RIS will make radio
links fall in the near-field localization regime with spatial non-stationarity
issues. Moreover, the discrete phase restriction on the RIS reflection
coefficient incurs exponential complexity for discrete beamforming. It remains
an open problem to find the optimal RIS reflection coefficient design in
polynomial time. To address these issues, we propose a scalable
partitioned-far-field protocol that considers both the near-filed
non-stationarity and discrete beamforming. The protocol approximates near-field
signal propagation using a partitioned-far-field representation to inherit the
sparsity from the sophisticated far-field and facilitate the near-field
localization scheme. To improve the theoretical localization performance, we
propose a fast passive beamforming (FPB) algorithm that optimally solves the
discrete RIS beamforming problem, reducing the search complexity from
exponential order to linear order. Furthermore, by exploiting the partitioned
structure of RIS, we introduce a two-stage coarse-to-fine localization
algorithm that leverages both the time delay and angle information. Numerical
results demonstrate that centimeter-level localization precision is achieved
under medium and high signal-to-noise ratios (SNR), revealing that RISs can
provide support for low-cost and high-precision localization in future cellular
systems.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12359" title="Abstract">arXiv:2312.12359</a> [<a href="/pdf/2312.12359" title="Download PDF">pdf</a>, <a href="/format/2312.12359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIP-DINOiser: Teaching CLIP a few DINO tricks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wysocza%C5%84ska%2C+M">Monika Wysocza&#x144;ska</a>, 
<a href="/search/cs?searchtype=author&query=Sim%C3%A9oni%2C+O">Oriane Sim&#xe9;oni</a>, 
<a href="/search/cs?searchtype=author&query=Ramamonjisoa%2C+M">Micha&#xeb;l Ramamonjisoa</a>, 
<a href="/search/cs?searchtype=author&query=Bursuc%2C+A">Andrei Bursuc</a>, 
<a href="/search/cs?searchtype=author&query=Trzci%C5%84ski%2C+T">Tomasz Trzci&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+P">Patrick P&#xe9;rez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The popular CLIP model displays impressive zero-shot capabilities thanks to
its seamless interaction with arbitrary text prompts. However, its lack of
spatial awareness makes it unsuitable for dense computer vision tasks, e.g.,
semantic segmentation, without an additional fine-tuning step that often uses
annotations and can potentially suppress its original open-vocabulary
properties. Meanwhile, self-supervised representation methods have demonstrated
good localization properties without human-made annotations nor explicit
supervision. In this work, we take the best of both worlds and propose a
zero-shot open-vocabulary semantic segmentation method, which does not require
any annotations. We propose to locally improve dense MaskCLIP features,
computed with a simple modification of CLIP's last pooling layer, by
integrating localization priors extracted from self-supervised features. By
doing so, we greatly improve the performance of MaskCLIP and produce smooth
outputs. Moreover, we show that the used self-supervised feature properties can
directly be learnt from CLIP features therefore allowing us to obtain the best
results with a single pass through CLIP model. Our method CLIP-DINOiser needs
only a single forward pass of CLIP and two light convolutional layers at
inference, no extra supervision nor extra memory and reaches state-of-the-art
results on challenging and fine-grained benchmarks such as COCO, Pascal
Context, Cityscapes and ADE20k. The code to reproduce our results is available
at https://github.com/wysoczanska/clip_dinoiser.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12362" title="Abstract">arXiv:2312.12362</a> [<a href="/pdf/2312.12362" title="Download PDF">pdf</a>, <a href="/ps/2312.12362" title="Download PostScript">ps</a>, <a href="/format/2312.12362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auditable Algorithms for Approximate Model Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meel%2C+K+S">Kuldeep S. Meel</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+S">Supratik Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Akshay%2C+S">S. Akshay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of conference paper accepted at AAAI'24. The authors decided to forgo the old convention of alphabetical ordering of authors in favor of a randomized ordering. The publicly verifiable record of the randomization is available at <a href="https://www.aeaweb.org/journals/policies/random-author-order/search">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Model counting, or counting the satisfying assignments of a Boolean formula,
is a fundamental problem with diverse applications. Given #P-hardness of the
problem, developing algorithms for approximate counting is an important
research area. Building on the practical success of SAT-solvers, the focus has
recently shifted from theory to practical implementations of approximate
counting algorithms. This has brought to focus new challenges, such as the
design of auditable approximate counters that not only provide an approximation
of the model count, but also a certificate that a verifier with limited
computational power can use to check if the count is indeed within the promised
bounds of approximation.
<br />Towards generating certificates, we start by examining the best-known
deterministic approximate counting algorithm that uses polynomially many calls
to a $\Sigma_2^P$ oracle. We show that this can be audited via a $\Sigma_2^P$
oracle with the query constructed over $n^2 \log^2 n$ variables, where the
original formula has $n$ variables. Since $n$ is often large, we ask if the
count of variables in the certificate can be reduced -- a crucial question for
potential implementation. We show that this is indeed possible with a tradeoff
in the counting algorithm's complexity. Specifically, we develop new
deterministic approximate counting algorithms that invoke a $\Sigma_3^P$
oracle, but can be certified using a $\Sigma_2^P$ oracle using certificates on
far fewer variables: our final algorithm uses only $n \log n$ variables. Our
study demonstrates that one can simplify auditing significantly if we allow the
counting algorithm to access a slightly more powerful oracle. This shows for
the first time how audit complexity can be traded for complexity of approximate
counting.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12364" title="Abstract">arXiv:2312.12364</a> [<a href="/pdf/2312.12364" title="Download PDF">pdf</a>, <a href="/ps/2312.12364" title="Download PostScript">ps</a>, <a href="/format/2312.12364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpokesBiz -- an Open Corpus of Conversational Polish
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=P%C4%99zik%2C+P">Piotr P&#x119;zik</a>, 
<a href="/search/cs?searchtype=author&query=Karasi%C5%84ska%2C+S">Sylwia Karasi&#x144;ska</a>, 
<a href="/search/cs?searchtype=author&query=Cichosz%2C+A">Anna Cichosz</a>, 
<a href="/search/cs?searchtype=author&query=Ja%C5%82owiecki%2C+%C5%81">&#x141;ukasz Ja&#x142;owiecki</a>, 
<a href="/search/cs?searchtype=author&query=Kaczy%C5%84ski%2C+K">Konrad Kaczy&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Krawentek%2C+M">Ma&#x142;gorzata Krawentek</a>, 
<a href="/search/cs?searchtype=author&query=Walkusz%2C+K">Karolina Walkusz</a>, 
<a href="/search/cs?searchtype=author&query=Wilk%2C+P">Pawe&#x142; Wilk</a>, 
<a href="/search/cs?searchtype=author&query=Kle%C4%87%2C+M">Mariusz Kle&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Szklanny%2C+K">Krzysztof Szklanny</a>, 
<a href="/search/cs?searchtype=author&query=Marsza%C5%82kowski%2C+S">Szymon Marsza&#x142;kowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This paper announces the early release of SpokesBiz, a freely available
corpus of conversational Polish developed within the CLARIN-BIZ project and
comprising over 650 hours of recordings. The transcribed recordings have been
diarized and manually annotated for punctuation and casing. We outline the
general structure and content of the corpus, showcasing selected applications
in linguistic research, evaluation and improvement of automatic speech
recognition (ASR) systems
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12369" title="Abstract">arXiv:2312.12369</a> [<a href="/pdf/2312.12369" title="Download PDF">pdf</a>, <a href="/format/2312.12369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chasing Fairness in Graphs: A GNN Architecture Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhimeng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaotian Han</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zirui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+N">Na Zou</a>, 
<a href="/search/cs?searchtype=author&query=Mostafavi%2C+A">Ali Mostafavi</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xia Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI Conference on Artificial Intelligence (AAAI) 2024. arXiv admin note: substantial text overlap with <a href="/abs/2202.04187">arXiv:2202.04187</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">There has been significant progress in improving the performance of graph
neural networks (GNNs) through enhancements in graph data, model architecture
design, and training strategies. For fairness in graphs, recent studies achieve
fair representations and predictions through either graph data pre-processing
(e.g., node feature masking, and topology rewiring) or fair training strategies
(e.g., regularization, adversarial debiasing, and fair contrastive learning).
How to achieve fairness in graphs from the model architecture perspective is
less explored. More importantly, GNNs exhibit worse fairness performance
compared to multilayer perception since their model architecture (i.e.,
neighbor aggregation) amplifies biases. To this end, we aim to achieve fairness
via a new GNN architecture. We propose \textsf{F}air \textsf{M}essage
\textsf{P}assing (FMP) designed within a unified optimization framework for
GNNs. Notably, FMP \textit{explicitly} renders sensitive attribute usage in
\textit{forward propagation} for node classification task using cross-entropy
loss without data pre-processing. In FMP, the aggregation is first adopted to
utilize neighbors' information and then the bias mitigation step explicitly
pushes demographic group node presentation centers together. In this way, FMP
scheme can aggregate useful information from neighbors and mitigate bias to
achieve better fairness and prediction tradeoff performance. Experiments on
node classification tasks demonstrate that the proposed FMP outperforms several
baselines in terms of fairness and accuracy on three real-world datasets. The
code is available in {\url{https://github.com/zhimengj0326/FMP}}.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12379" title="Abstract">arXiv:2312.12379</a> [<a href="/pdf/2312.12379" title="Download PDF">pdf</a>, <a href="/format/2312.12379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixture of Cluster-conditional LoRA Experts for Vision-language  Instruction Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gou%2C+Y">Yunhao Gou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhili Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Lanqing Hong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Aoxue Li</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+D">Dit-Yan Yeung</a>, 
<a href="/search/cs?searchtype=author&query=Kwok%2C+J+T">James T. Kwok</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Instruction tuning of the Large Vision-language Models (LVLMs) has
revolutionized the development of versatile models with zero-shot
generalization across a wide range of downstream vision-language tasks.
However, diversity of training tasks of different sources and formats would
lead to inevitable task conflicts, where different tasks conflicts for the same
set of model parameters, resulting in sub-optimal instruction-following
abilities. To address that, we propose the Mixture of Cluster-conditional LoRA
Experts (MoCLE), a novel Mixture of Experts (MoE) architecture designed to
activate the task-customized model parameters based on the instruction
clusters. A separate universal expert is further incorporated to improve the
generalization capabilities of MoCLE for novel instructions. Extensive
experiments on 10 zero-shot tasks demonstrate the effectiveness of MoCLE.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12381" title="Abstract">arXiv:2312.12381</a> [<a href="/pdf/2312.12381" title="Download PDF">pdf</a>, <a href="/format/2312.12381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blockchain-Based Identity Authentication Oriented to Multi-Cluster UAV  Networking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zesong Dong</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+W">Wei Tong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jian Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Weidong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yulong Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Unmanned Aerial Vehicle (UAV) networking is increasingly used in field
environments such as power inspection, agricultural plant protection, and
emergency rescue. To guarantee UAV networking security, UAV identity
authentication attracts wide attention, especially in the field environment
without perfect infrastructure. Some blockchain-based UAV identity
authentication solutions are proposed to establish decentralized and trusted
authentication systems without relying on infrastructure. However, these
solutions do not support disconnected UAV reconnection or even disband a
cluster directly after its head UAV disconnection, which compromises cluster
robustness and task result integrity. In this paper, we propose a
blockchain-based identity authentication solution oriented to multi-cluster UAV
networking with a UAV disconnection mechanism and a task result backup
mechanism. Specifically, we build a blockchain maintained by head UAVs of all
clusters, managing identity information to guarantee the security of
decentralized identity management. The UAV disconnection mechanism permits a
verified distributed UAV reconnection to ensure the robustness of the UAV
cluster, and on this basis, the task result backup mechanism ensures the
integrity of the task results stored in a cluster even any UAV disconnection.
Finally, extensive experimental results prove the superiority of our solutions
in terms of robustness, integrity, delay, and energy consumption.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12383" title="Abstract">arXiv:2312.12383</a> [<a href="/pdf/2312.12383" title="Download PDF">pdf</a>, <a href="/ps/2312.12383" title="Download PostScript">ps</a>, <a href="/format/2312.12383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual AI and Linguistic Intelligence Through Steerability and  Composability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Noever%2C+D">David Noever</a>, 
<a href="/search/cs?searchtype=author&query=Noever%2C+S+E+M">Samantha Elizabeth Miller Noever</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This study explores the capabilities of multimodal large language models
(LLMs) in handling challenging multistep tasks that integrate language and
vision, focusing on model steerability, composability, and the application of
long-term memory and context understanding. The problem addressed is the LLM's
ability (Nov 2023 GPT-4 Vision Preview) to manage tasks that require
synthesizing visual and textual information, especially where stepwise
instructions and sequential logic are paramount. The research presents a series
of 14 creatively and constructively diverse tasks, ranging from AI Lego
Designing to AI Satellite Image Analysis, designed to test the limits of
current LLMs in contexts that previously proved difficult without extensive
memory and contextual understanding. Key findings from evaluating 800 guided
dialogs include notable disparities in task completion difficulty. For
instance, 'Image to Ingredient AI Bartender' (Low difficulty) contrasted
sharply with 'AI Game Self-Player' (High difficulty), highlighting the LLM's
varying proficiency in processing complex visual data and generating coherent
instructions. Tasks such as 'AI Genetic Programmer' and 'AI Negotiator' showed
high completion difficulty, emphasizing challenges in maintaining context over
multiple steps. The results underscore the importance of developing LLMs that
combine long-term memory and contextual awareness to mimic human-like thought
processes in complex problem-solving scenarios.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12385" title="Abstract">arXiv:2312.12385</a> [<a href="/pdf/2312.12385" title="Download PDF">pdf</a>, <a href="/format/2312.12385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Input Compression with Positional Consistency for Efficient Training and  Inference of Transformer Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nagarajan%2C+A">Amrit Nagarajan</a>, 
<a href="/search/cs?searchtype=author&query=Raghunathan%2C+A">Anand Raghunathan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Transformers have rapidly increased in popularity in recent years, achieving
state-of-the-art performance in processing text, images, audio and video.
However, Transformers present large computational requirements for both
training and inference, and are prone to overfitting during training. To
address these challenges, we present Input Compression with Positional
Consistency (ICPC), a new data augmentation method that, unlike prior
augmentation techniques, simultaneously improves both generalization and
training efficiency. ICPC applies varying levels of compression to each
training sample in each epoch. This leads to smaller input sequences being
processed by the Transformer, and hence faster training, while also alleviating
overfitting by presenting each input with different compression levels. We
introduce a consistency-aware position selection method in ICPC that enables
accurate processing of compressed inputs without any changes to the underlying
Transformer architecture. We detail compression-based augmentation methods for
four different modalities -- insignificant word pruning for text, resolution
modulation for images, spatio-temporal resolution modulation for videos, and
spectogram size modulation for audio. ICPC also enables efficient
variable-effort inference, where samples are first inferred at high compression
levels, and progressively re-evaluated with lower compression for more
challenging inputs. On 9 diverse tasks spanning 4 different modalities, ICPC
improves accuracy by up to 1%, while also accelerating training and inference
by up to 2.9X and 2.6X, respectively. Code is available at
https://github.com/amrnag/ICPC.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12391" title="Abstract">arXiv:2312.12391</a> [<a href="/pdf/2312.12391" title="Download PDF">pdf</a>, <a href="/format/2312.12391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> vTrain: A Simulation Framework for Evaluating Cost-effective and  Compute-optimal Large Language Model Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bang%2C+J">Jehyeon Bang</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yujeong Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Myeongwoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yongdeok Kim</a>, 
<a href="/search/cs?searchtype=author&query=Rhu%2C+M">Minsoo Rhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)

</div>
<p class="mathjax">As large language models (LLMs) become widespread in various application
domains, a critical challenge the AI community is facing is how to train these
large AI models in a cost-effective manner. Existing LLM training plans
typically employ a heuristic based parallel training strategy which is based on
empirical observations rather than grounded upon a thorough examination of the
search space of LLM parallelization. Such limitation renders existing systems
to leave significant performance left on the table, wasting millions of dollars
worth of training cost. This paper presents our profiling-driven simulator
called vTrain, providing AI practitioners a fast yet accurate software
framework to determine an efficient and cost-effective LLM training system
configuration. We demonstrate vTrain's practicality through several case
studies, e.g., effectively evaluating optimal training parallelization
strategies that balances training time and its associated training cost,
efficient multi-tenant GPU cluster schedulers targeting multiple LLM training
jobs, and determining a compute-optimal LLM model architecture given a fixed
compute budget.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12392" title="Abstract">arXiv:2312.12392</a> [<a href="/pdf/2312.12392" title="Download PDF">pdf</a>, <a href="/format/2312.12392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recursive Camera Painting: A Method for Real-Time Painterly Renderings  of 3D Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akleman%2C+E">Ergun Akleman</a>, 
<a href="/search/cs?searchtype=author&query=Mullins%2C+C">Cassie Mullins</a>, 
<a href="/search/cs?searchtype=author&query=Morrison%2C+C">Christopher Morrison</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+D">David Oh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">In this work, we present the recursive camera-painting approach to obtain
painterly smudging in real-time rendering applications. We have implemented
recursive camera painting as both a GPU-based ray-tracing and in a Virtual
Reality game environment. Using this approach, we can obtain dynamic 3D
Paintings in real-time. In a camera painting, each pixel has a separate
associated camera whose parameters are computed from a corresponding image of
the same size. In recursive camera painting, we use the rendered images to
compute new camera parameters. When we apply this process a few times, it
creates painterly images that can be viewed as real-time 3D dynamic paintings.
These visual results are not surprising since multi-view techniques help to
obtain painterly effects.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12399" title="Abstract">arXiv:2312.12399</a> [<a href="/pdf/2312.12399" title="Download PDF">pdf</a>, <a href="/ps/2312.12399" title="Download PostScript">ps</a>, <a href="/format/2312.12399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Virtual Reality-Assisted Physiotherapy for Visuospatial Neglect  Rehabilitation: A Proof-of-Concept Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Danso%2C+A">Andrew Danso</a>, 
<a href="/search/cs?searchtype=author&query=Nijhuis%2C+P">Patti Nijhuis</a>, 
<a href="/search/cs?searchtype=author&query=Ansani%2C+A">Alessandro Ansani</a>, 
<a href="/search/cs?searchtype=author&query=Hartmann%2C+M">Martin Hartmann</a>, 
<a href="/search/cs?searchtype=author&query=Minkkinen%2C+G">Gulnara Minkkinen</a>, 
<a href="/search/cs?searchtype=author&query=Luck%2C+G">Geoff Luck</a>, 
<a href="/search/cs?searchtype=author&query=Bamford%2C+J+S">Joshua S. Bamford</a>, 
<a href="/search/cs?searchtype=author&query=Faber%2C+S">Sarah Faber</a>, 
<a href="/search/cs?searchtype=author&query=Agres%2C+K">Kat Agres</a>, 
<a href="/search/cs?searchtype=author&query=Glasser%2C+S">Solange Glasser</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A4rk%C3%A4m%C3%B6%2C+T">Teppo S&#xe4;rk&#xe4;m&#xf6;</a>, 
<a href="/search/cs?searchtype=author&query=Rousi%2C+R">Rebekah Rousi</a>, 
<a href="/search/cs?searchtype=author&query=Thompson%2C+M+R">Marc R. Thompson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 8 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This study explores a VR-based intervention for Visuospatial neglect (VSN), a
post-stroke condition. It aims to develop a VR task utilizing interactive
visual-audio cues to improve sensory-motor training and assess its impact on
VSN patients' engagement and performance. Collaboratively designed with
physiotherapists, the VR task uses directional and auditory stimuli to alert
and direct patients, tested over 12 sessions with two individuals. Results show
a consistent decrease in task completion variability and positive patient
feedback, highlighting the VR task's potential for enhancing engagement and
suggesting its feasibility in rehabilitation. The study underlines the
significance of collaborative design in healthcare technology and advocates for
further research with a larger sample size to confirm the benefits of VR in VSN
treatment, as well as its applicability to other multimodal disorders.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12400" title="Abstract">arXiv:2312.12400</a> [<a href="/pdf/2312.12400" title="Download PDF">pdf</a>, <a href="/format/2312.12400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New classes of the greedy-applicable arm feature distributions in the  sparse linear bandit problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ichikawa%2C+K">Koji Ichikawa</a>, 
<a href="/search/cs?searchtype=author&query=Ito%2C+S">Shinji Ito</a>, 
<a href="/search/cs?searchtype=author&query=Hatano%2C+D">Daisuke Hatano</a>, 
<a href="/search/cs?searchtype=author&query=Sumita%2C+H">Hanna Sumita</a>, 
<a href="/search/cs?searchtype=author&query=Fukunaga%2C+T">Takuro Fukunaga</a>, 
<a href="/search/cs?searchtype=author&query=Kakimura%2C+N">Naonori Kakimura</a>, 
<a href="/search/cs?searchtype=author&query=Kawarabayashi%2C+K">Ken-ichi Kawarabayashi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We consider the sparse contextual bandit problem where arm feature affects
reward through the inner product of sparse parameters. Recent studies have
developed sparsity-agnostic algorithms based on the greedy arm selection
policy. However, the analysis of these algorithms requires strong assumptions
on the arm feature distribution to ensure that the greedily selected samples
are sufficiently diverse; One of the most common assumptions, relaxed symmetry,
imposes approximate origin-symmetry on the distribution, which cannot allow
distributions that has origin-asymmetric support. In this paper, we show that
the greedy algorithm is applicable to a wider range of the arm feature
distributions from two aspects. Firstly, we show that a mixture distribution
that has a greedy-applicable component is also greedy-applicable. Second, we
propose new distribution classes, related to Gaussian mixture, discrete, and
radial distribution, for which the sample diversity is guaranteed. The proposed
classes can describe distributions with origin-asymmetric support and, in
conjunction with the first claim, provide theoretical guarantees of the greedy
policy for a very wide range of the arm feature distributions.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12403" title="Abstract">arXiv:2312.12403</a> [<a href="/pdf/2312.12403" title="Download PDF">pdf</a>, <a href="/format/2312.12403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Alternating-time Temporal Logic, Hyperproperties, and Strategy  Sharing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beutner%2C+R">Raven Beutner</a>, 
<a href="/search/cs?searchtype=author&query=Finkbeiner%2C+B">Bernd Finkbeiner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Alternating-time temporal logic (ATL$^*$) is a well-established framework for
formal reasoning about multi-agent systems. However, while ATL$^*$ can reason
about the strategic ability of agents (e.g., some coalition $A$ can ensure that
a goal is reached eventually), we cannot compare multiple strategic
interactions, nor can we require multiple agents to follow the same strategy.
For example, we cannot state that coalition $A$ can reach a goal sooner (or
more often) than some other coalition $A'$. In this paper, we propose
HyperATLS$^*_S$, an extension of ATL$^*$ in which we can (1) compare the
outcome of multiple strategic interactions w.r.t. a hyperproperty, i.e., a
property that refers to multiple paths at the same time, and (2) enforce that
some agents share the same strategy. We show that HyperATL$^*_S$ is a rich
specification language that captures important AI-related properties that were
out of reach of existing logics. We prove that model checking of HyperATL$^*_S$
on concurrent game structures is decidable. We implement our model-checking
algorithm in a tool we call HyMASMC and evaluate it on a range of benchmarks.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12404" title="Abstract">arXiv:2312.12404</a> [<a href="/pdf/2312.12404" title="Download PDF">pdf</a>, <a href="/format/2312.12404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Automatic Support of Software Model Evolution with Large  Language~Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tinnes%2C+C">Christof Tinnes</a>, 
<a href="/search/cs?searchtype=author&query=Fuch%C3%9F%2C+T">Thomas Fuch&#xdf;</a>, 
<a href="/search/cs?searchtype=author&query=Hohenstein%2C+U">Uwe Hohenstein</a>, 
<a href="/search/cs?searchtype=author&query=Apel%2C+S">Sven Apel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Modeling structure and behavior of software systems plays a crucial role, in
various areas of software engineering. As with other software engineering
artifacts, software models are subject to evolution. Supporting modelers in
evolving models by model completion facilities and providing high-level edit
operations such as frequently occurring editing patterns is still an open
problem. Recently, large language models (i.e., generative neural networks)
have garnered significant attention in various research areas, including
software engineering. In this paper, we explore the potential of large language
models in supporting the evolution of software models in software engineering.
We propose an approach that utilizes large language models for model completion
and discovering editing patterns in model histories of software systems.
Through controlled experiments using simulated model repositories, we conduct
an evaluation of the potential of large language models for these two tasks. We
have found that large language models are indeed a promising technology for
supporting software model evolution, and that it is worth investigating further
in the area of software model evolution.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12411" title="Abstract">arXiv:2312.12411</a> [<a href="/pdf/2312.12411" title="Download PDF">pdf</a>, <a href="/format/2312.12411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Future-proofing geotechnics workflows: accelerating problem-solving with  large language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Stephen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Otake%2C+Y">Yu Otake</a>, 
<a href="/search/cs?searchtype=author&query=Mizutani%2C+D">Daijiro Mizutani</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Asano%2C+K">Kotaro Asano</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+N">Nana Sato</a>, 
<a href="/search/cs?searchtype=author&query=Baba%2C+H">Hidetoshi Baba</a>, 
<a href="/search/cs?searchtype=author&query=Fukunaga%2C+Y">Yusuke Fukunaga</a>, 
<a href="/search/cs?searchtype=author&query=Higo%2C+Y">Yosuke Higo</a>, 
<a href="/search/cs?searchtype=author&query=Kamura%2C+A">Akiyoshi Kamura</a>, 
<a href="/search/cs?searchtype=author&query=Kodama%2C+S">Shinnosuke Kodama</a>, 
<a href="/search/cs?searchtype=author&query=Metoki%2C+M">Masataka Metoki</a>, 
<a href="/search/cs?searchtype=author&query=Nakamura%2C+T">Tomoka Nakamura</a>, 
<a href="/search/cs?searchtype=author&query=Nakazato%2C+Y">Yuto Nakazato</a>, 
<a href="/search/cs?searchtype=author&query=Saito%2C+T">Taiga Saito</a>, 
<a href="/search/cs?searchtype=author&query=Shioi%2C+A">Akihiro Shioi</a>, 
<a href="/search/cs?searchtype=author&query=Takenobu%2C+M">Masahiro Takenobu</a>, 
<a href="/search/cs?searchtype=author&query=Tsukioka%2C+K">Keigo Tsukioka</a>, 
<a href="/search/cs?searchtype=author&query=Yoshikawa%2C+R">Ryo Yoshikawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Supplementary information will be available upon request
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The integration of Large Language Models (LLMs) like ChatGPT into the
workflows of geotechnical engineering has a high potential to transform how the
discipline approaches problem-solving and decision-making. This paper delves
into the innovative application of LLMs in geotechnical engineering, as
explored in a hands-on workshop held in Tokyo, Japan. The event brought
together a diverse group of 20 participants, including students, researchers,
and professionals from academia, industry, and government sectors, to
investigate practical uses of LLMs in addressing specific geotechnical
challenges. The workshop facilitated the creation of solutions for four
different practical geotechnical problems as illustrative examples, culminating
in the development of an academic paper. The paper discusses the potential of
LLMs to transform geotechnical engineering practices, highlighting their
proficiency in handling a range of tasks from basic data analysis to complex,
multimodal problem-solving. It also addresses the challenges in implementing
LLMs, particularly in achieving high precision and accuracy in specialized
tasks, and underscores the need for expert oversight. The findings demonstrate
LLMs' effectiveness in enhancing efficiency, data processing, and
decision-making in geotechnical engineering, suggesting a paradigm shift
towards more integrated, data-driven approaches in this field. This study not
only showcases the potential of LLMs in a specific engineering domain, but also
sets a precedent for their broader application in interdisciplinary research
and practice, where the synergy of human expertise and artificial intelligence
redefines the boundaries of problem-solving.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12414" title="Abstract">arXiv:2312.12414</a> [<a href="/pdf/2312.12414" title="Download PDF">pdf</a>, <a href="/ps/2312.12414" title="Download PostScript">ps</a>, <a href="/format/2312.12414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Translating Natural Language Queries to SQL Using the T5 Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wong%2C+A">Albert Wong</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+L">Lien Pham</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Young Lee</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+S">Shek Chan</a>, 
<a href="/search/cs?searchtype=author&query=Sadaya%2C+R">Razel Sadaya</a>, 
<a href="/search/cs?searchtype=author&query=Khmelevsky%2C+Y">Youry Khmelevsky</a>, 
<a href="/search/cs?searchtype=author&query=Clement%2C+M">Mathias Clement</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+F+W+Y">Florence Wing Yau Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Mahony%2C+J">Joe Mahony</a>, 
<a href="/search/cs?searchtype=author&query=Ferri%2C+M">Michael Ferri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper presents the development process of a natural language to SQL
model using the T5 model as the basis. The models, developed in August 2022 for
an online transaction processing system and a data warehouse, have a 73\% and
84\% exact match accuracy respectively. These models, in conjunction with other
work completed in the research project, were implemented for several companies
and used successfully on a daily basis. The approach used in the model
development could be implemented in a similar fashion for other database
environments and with a more powerful pre-trained language model.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12416" title="Abstract">arXiv:2312.12416</a> [<a href="/pdf/2312.12416" title="Download PDF">pdf</a>, <a href="/format/2312.12416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompting Hard or Hardly Prompting: Prompt Inversion for Text-to-Image  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahajan%2C+S">Shweta Mahajan</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+T">Tanzila Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+K+M">Kwang Moo Yi</a>, 
<a href="/search/cs?searchtype=author&query=Sigal%2C+L">Leonid Sigal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The quality of the prompts provided to text-to-image diffusion models
determines how faithful the generated content is to the user's intent, often
requiring `prompt engineering'. To harness visual concepts from target images
without prompt engineering, current approaches largely rely on embedding
inversion by optimizing and then mapping them to pseudo-tokens. However,
working with such high-dimensional vector representations is challenging
because they lack semantics and interpretability, and only allow simple vector
operations when using them. Instead, this work focuses on inverting the
diffusion model to obtain interpretable language prompts directly. The
challenge of doing this lies in the fact that the resulting optimization
problem is fundamentally discrete and the space of prompts is exponentially
large; this makes using standard optimization techniques, such as stochastic
gradient descent, difficult. To this end, we utilize a delayed projection
scheme to optimize for prompts representative of the vocabulary space in the
model. Further, we leverage the findings that different timesteps of the
diffusion process cater to different levels of detail in an image. The later,
noisy, timesteps of the forward diffusion process correspond to the semantic
information, and therefore, prompt inversion in this range provides tokens
representative of the image semantics. We show that our approach can identify
semantically interpretable and meaningful prompts for a target image which can
be used to synthesize diverse images with similar content. We further
illustrate the application of the optimized prompts in evolutionary image
generation and concept removal.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12417" title="Abstract">arXiv:2312.12417</a> [<a href="/pdf/2312.12417" title="Download PDF">pdf</a>, <a href="/ps/2312.12417" title="Download PostScript">ps</a>, <a href="/format/2312.12417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Device Scheduling for Relay-assisted Over-the-Air Aggregation in  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jining Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kunlun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wen Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Federated learning (FL) leverages data distributed at the edge of the network
to enable intelligent applications. The efficiency of FL can be improved by
using over-the-air computation (AirComp) technology in the process of gradient
aggregation. In this paper, we propose a relay-assisted large-scale FL
framework, and investigate the device scheduling problem in relay-assisted FL
systems under the constraints of power consumption and mean squared error
(MSE). we formulate a joint device scheduling, and power allocation problem to
maximize the number of scheduled devices. We solve the resultant non-convex
optimization problem by transforming the optimization problem into multiple
sparse optimization problems. By the proposed device scheduling algorithm,
these sparse sub-problems are solved and the maximum number of federated
learning edge devices is obtained. The simulation results demonstrate the
effectiveness of the proposed scheme as compared with other benchmark schemes.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12418" title="Abstract">arXiv:2312.12418</a> [<a href="/pdf/2312.12418" title="Download PDF">pdf</a>, <a href="/format/2312.12418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LASA: Instance Reconstruction from Real Scans using A Large-scale  Aligned Shape Annotation Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haolin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+C">Chongjie Ye</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Y">Yinyu Nie</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yingfan He</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaoguang Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> homepage: <a href="https://gap-lab-cuhk-sz.github.io/LASA/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Instance shape reconstruction from a 3D scene involves recovering the full
geometries of multiple objects at the semantic instance level. Many methods
leverage data-driven learning due to the intricacies of scene complexity and
significant indoor occlusions. Training these methods often requires a
large-scale, high-quality dataset with aligned and paired shape annotations
with real-world scans. Existing datasets are either synthetic or misaligned,
restricting the performance of data-driven methods on real data. To this end,
we introduce LASA, a Large-scale Aligned Shape Annotation Dataset comprising
10,412 high-quality CAD annotations aligned with 920 real-world scene scans
from ArkitScenes, created manually by professional artists. On this top, we
propose a novel Diffusion-based Cross-Modal Shape Reconstruction (DisCo)
method. It is empowered by a hybrid feature aggregation design to fuse
multi-modal inputs and recover high-fidelity object geometries. Besides, we
present an Occupancy-Guided 3D Object Detection (OccGOD) method and demonstrate
that our shape annotations provide scene occupancy clues that can further
improve 3D object detection. Supported by LASA, extensive experiments show that
our methods achieve state-of-the-art performance in both instance-level scene
reconstruction and 3D object detection tasks.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12419" title="Abstract">arXiv:2312.12419</a> [<a href="/pdf/2312.12419" title="Download PDF">pdf</a>, <a href="/format/2312.12419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scene-Conditional 3D Object Stylization and Composition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jinghao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jakab%2C+T">Tomas Jakab</a>, 
<a href="/search/cs?searchtype=author&query=Torr%2C+P">Philip Torr</a>, 
<a href="/search/cs?searchtype=author&query=Rupprecht%2C+C">Christian Rupprecht</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, 3D generative models have made impressive progress, enabling the
generation of almost arbitrary 3D assets from text or image inputs. However,
these approaches generate objects in isolation without any consideration for
the scene where they will eventually be placed. In this paper, we propose a
framework that allows for the stylization of an existing 3D asset to fit into a
given 2D scene, and additionally produce a photorealistic composition as if the
asset was placed within the environment. This not only opens up a new level of
control for object stylization, for example, the same assets can be stylized to
reflect changes in the environment, such as summer to winter or fantasy versus
futuristic settings-but also makes the object-scene composition more
controllable. We achieve this by combining modeling and optimizing the object's
texture and environmental lighting through differentiable ray tracing with
image priors from pre-trained text-to-image diffusion models. We demonstrate
that our method is applicable to a wide variety of indoor and outdoor scenes
and arbitrary objects.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12422" title="Abstract">arXiv:2312.12422</a> [<a href="/pdf/2312.12422" title="Download PDF">pdf</a>, <a href="/format/2312.12422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Terrapin Attack: Breaking SSH Channel Integrity By Sequence Number  Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%A4umer%2C+F">Fabian B&#xe4;umer</a>, 
<a href="/search/cs?searchtype=author&query=Brinkmann%2C+M">Marcus Brinkmann</a>, 
<a href="/search/cs?searchtype=author&query=Schwenk%2C+J">J&#xf6;rg Schwenk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The SSH protocol provides secure access to network services, particularly
remote terminal login and file transfer within organizational networks and to
over 15 million servers on the open internet. SSH uses an authenticated key
exchange to establish a secure channel between a client and a server, which
protects the confidentiality and integrity of messages sent in either
direction. The secure channel prevents message manipulation, replay, insertion,
deletion, and reordering. In this paper, we show that as new encryption
algorithms and mitigations were added to SSH, the SSH Binary Packet Protocol is
no longer a secure channel: SSH channel integrity (INT-PST) is broken for three
widely used encryption modes. This allows prefix truncation attacks where some
encrypted packets at the beginning of the SSH channel can be deleted without
the client or server noticing it. We demonstrate several real-world
applications of this attack. We show that we can fully break SSH extension
negotiation (RFC 8308), such that an attacker can downgrade the public key
algorithms for user authentication or turn off a new countermeasure against
keystroke timing attacks introduced in OpenSSH 9.5. We also identified an
implementation flaw in AsyncSSH that, together with prefix truncation, allows
an attacker to redirect the victim's login into a shell controlled by the
attacker. In an internet-wide scan for vulnerable encryption modes and support
for extension negotiation, we find that 77% of SSH servers support an
exploitable encryption mode, while 57% even list it as their preferred choice.
We identify two root causes that enable these attacks: First, the SSH handshake
supports optional messages that are not authenticated. Second, SSH does not
reset message sequence numbers when encryption is enabled. Based on this
analysis, we propose effective and backward-compatible changes to SSH that
mitigate our attacks.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12423" title="Abstract">arXiv:2312.12423</a> [<a href="/pdf/2312.12423" title="Download PDF">pdf</a>, <a href="/format/2312.12423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jack of All Tasks, Master of Many: Designing General-purpose  Coarse-to-Fine Vision-Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pramanick%2C+S">Shraman Pramanick</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+G">Guangxing Han</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+R">Rui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Nag%2C+S">Sayan Nag</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Ser-Nam Lim</a>, 
<a href="/search/cs?searchtype=author&query=Ballas%2C+N">Nicolas Ballas</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chellappa%2C+R">Rama Chellappa</a>, 
<a href="/search/cs?searchtype=author&query=Almahairi%2C+A">Amjad Almahairi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages including references and supplementary
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The ability of large language models (LLMs) to process visual inputs has
given rise to general-purpose vision systems, unifying various vision-language
(VL) tasks by instruction tuning. However, due to the enormous diversity in
input-output formats in the vision domain, existing general-purpose models fail
to successfully integrate segmentation and multi-image inputs with coarse-level
tasks into a single framework. In this work, we introduce VistaLLM, a powerful
visual system that addresses coarse- and fine-grained VL tasks over single and
multiple input images using a unified framework. VistaLLM utilizes an
instruction-guided image tokenizer that filters global embeddings using task
descriptions to extract compressed and refined features from numerous images.
Moreover, VistaLLM employs a gradient-aware adaptive sampling technique to
represent binary segmentation masks as sequences, significantly improving over
previously used uniform sampling. To bolster the desired capability of
VistaLLM, we curate CoinIt, a comprehensive coarse-to-fine instruction tuning
dataset with 6.8M samples. We also address the lack of multi-image grounding
datasets by introducing a novel task, AttCoSeg (Attribute-level
Co-Segmentation), which boosts the model's reasoning and grounding capability
over multiple input images. Extensive experiments on a wide range of V- and VL
tasks demonstrate the effectiveness of VistaLLM by achieving consistent
state-of-the-art performance over strong baselines across all downstream tasks.
Our project page can be found at https://shramanpramanick.github.io/VistaLLM/.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12425" title="Abstract">arXiv:2312.12425</a> [<a href="/pdf/2312.12425" title="Download PDF">pdf</a>, <a href="/format/2312.12425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SegRefiner: Towards Model-Agnostic Segmentation Refinement with Discrete  Diffusion Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Henghui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Liew%2C+J+H">Jun Hao Liew</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiajun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yunchao Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023, Code: <a href="https://github.com/MengyuWang826/SegRefiner">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we explore a principal way to enhance the quality of object
masks produced by different segmentation models. We propose a model-agnostic
solution called SegRefiner, which offers a novel perspective on this problem by
interpreting segmentation refinement as a data generation process. As a result,
the refinement process can be smoothly implemented through a series of
denoising diffusion steps. Specifically, SegRefiner takes coarse masks as
inputs and refines them using a discrete diffusion process. By predicting the
label and corresponding states-transition probabilities for each pixel,
SegRefiner progressively refines the noisy masks in a conditional denoising
manner. To assess the effectiveness of SegRefiner, we conduct comprehensive
experiments on various segmentation tasks, including semantic segmentation,
instance segmentation, and dichotomous image segmentation. The results
demonstrate the superiority of our SegRefiner from multiple aspects. Firstly,
it consistently improves both the segmentation metrics and boundary metrics
across different types of coarse masks. Secondly, it outperforms previous
model-agnostic refinement methods by a significant margin. Lastly, it exhibits
a strong capability to capture extremely fine details when refining
high-resolution images. The source code and trained models are available at
https://github.com/MengyuWang826/SegRefiner.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12429" title="Abstract">arXiv:2312.12429</a> [<a href="/pdf/2312.12429" title="Download PDF">pdf</a>, <a href="/format/2312.12429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Endoscapes Dataset for Surgical Scene Segmentation, Object  Detection, and Critical View of Safety Assessment: Official Splits and  Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Murali%2C+A">Aditya Murali</a>, 
<a href="/search/cs?searchtype=author&query=Alapatt%2C+D">Deepak Alapatt</a>, 
<a href="/search/cs?searchtype=author&query=Mascagni%2C+P">Pietro Mascagni</a>, 
<a href="/search/cs?searchtype=author&query=Vardazaryan%2C+A">Armine Vardazaryan</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+A">Alain Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Okamoto%2C+N">Nariaki Okamoto</a>, 
<a href="/search/cs?searchtype=author&query=Costamagna%2C+G">Guido Costamagna</a>, 
<a href="/search/cs?searchtype=author&query=Mutter%2C+D">Didier Mutter</a>, 
<a href="/search/cs?searchtype=author&query=Marescaux%2C+J">Jacques Marescaux</a>, 
<a href="/search/cs?searchtype=author&query=Dallemagne%2C+B">Bernard Dallemagne</a>, 
<a href="/search/cs?searchtype=author&query=Padoy%2C+N">Nicolas Padoy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages; 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This technical report provides a detailed overview of Endoscapes, a dataset
of laparoscopic cholecystectomy (LC) videos with highly intricate annotations
targeted at automated assessment of the Critical View of Safety (CVS).
Endoscapes comprises 201 LC videos with frames annotated sparsely but regularly
with segmentation masks, bounding boxes, and CVS assessment by three different
clinical experts. Altogether, there are 11090 frames annotated with CVS and
1933 frames annotated with tool and anatomy bounding boxes from the 201 videos,
as well as an additional 422 frames from 50 of the 201 videos annotated with
tool and anatomy segmentation masks. In this report, we provide detailed
dataset statistics (size, class distribution, dataset splits, etc.) and a
comprehensive performance benchmark for instance segmentation, object
detection, and CVS prediction. The dataset and model checkpoints are publically
available at https://github.com/CAMMA-public/Endoscapes.
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12430" title="Abstract">arXiv:2312.12430</a> [<a href="/pdf/2312.12430" title="Download PDF">pdf</a>, <a href="/format/2312.12430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Title Reranker for Fast and Improved Knowledge-Intense NLP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Ziyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+H">Heyi Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+D">Daqian Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jize Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Jun%2C+Y">Yang Jun</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yuxiang Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce Efficient Title Reranker via Broadcasting Query Encoder, a novel
title reranking technique to achieve efficient title reranking 20x-40x faster
than vanilla passage reranker. However, one of the challenges with the training
of Efficient Title Reranker is the instability. Analyzing the issue, we found
some very difficult ground truths might act as noisy labels causing accuracy to
drop as well as some extreme values in model probability output causing nan. To
address these issues, we introduce the Sigmoid Trick, a novel technique that
reduces the gradient update of both cases resulting in better retrieval
efficacy. Experiments showed the effectiveness of ETR and sigmoid trick as we
achieved four state-of-the-art positions on the kilt knowledge benchmark.
</p>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12431" title="Abstract">arXiv:2312.12431</a> [<a href="/pdf/2312.12431" title="Download PDF">pdf</a>, <a href="/format/2312.12431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Inference Stability for Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V">Viet Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+G">Giang Vu</a>, 
<a href="/search/cs?searchtype=author&query=Thanh%2C+T+N">Tung Nguyen Thanh</a>, 
<a href="/search/cs?searchtype=author&query=Than%2C+K">Khoat Than</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+T">Toan Tran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Denoising Probabilistic Models (DPMs) represent an emerging domain of
generative models that excel in generating diverse and high-quality images.
However, most current training methods for DPMs often neglect the correlation
between timesteps, limiting the model's performance in generating images
effectively. Notably, we theoretically point out that this issue can be caused
by the cumulative estimation gap between the predicted and the actual
trajectory. To minimize that gap, we propose a novel \textit{sequence-aware}
loss that aims to reduce the estimation gap to enhance the sampling quality.
Furthermore, we theoretically show that our proposed loss function is a tighter
upper bound of the estimation loss in comparison with the conventional loss in
DPMs. Experimental results on several benchmark datasets including CIFAR10,
CelebA, and CelebA-HQ consistently show a remarkable improvement of our
proposed method regarding the image generalization quality measured by FID and
Inception Score compared to several DPM baselines. Our code and pre-trained
checkpoints are available at \url{https://github.com/viettmab/SA-DPM}.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12433" title="Abstract">arXiv:2312.12433</a> [<a href="/pdf/2312.12433" title="Download PDF">pdf</a>, <a href="/format/2312.12433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tracking Any Object Amodally
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+C">Cheng-Yen Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Khurana%2C+T">Tarasha Khurana</a>, 
<a href="/search/cs?searchtype=author&query=Dave%2C+A">Achal Dave</a>, 
<a href="/search/cs?searchtype=author&query=Ramanan%2C+D">Deva Ramanan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://tao-amodal.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Amodal perception, the ability to comprehend complete object structures from
partial visibility, is a fundamental skill, even for infants. Its significance
extends to applications like autonomous driving, where a clear understanding of
heavily occluded objects is essential. However, modern detection and tracking
algorithms often overlook this critical capability, perhaps due to the
prevalence of modal annotations in most datasets. To address the scarcity of
amodal data, we introduce the TAO-Amodal benchmark, featuring 880 diverse
categories in thousands of video sequences. Our dataset includes amodal and
modal bounding boxes for visible and occluded objects, including objects that
are partially out-of-frame. To enhance amodal tracking with object permanence,
we leverage a lightweight plug-in module, the amodal expander, to transform
standard, modal trackers into amodal ones through fine-tuning on a few hundred
video sequences with data augmentation. We achieve a 3.3\% and 1.6\%
improvement on the detection and tracking of occluded objects on TAO-Amodal.
When evaluated on people, our method produces dramatic improvements of 2x
compared to state-of-the-art modal baselines.
</p>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12436" title="Abstract">arXiv:2312.12436</a> [<a href="/pdf/2312.12436" title="Download PDF">pdf</a>, <a href="/format/2312.12436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Challenger to GPT-4V? Early Explorations of Gemini in Visual Expertise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Chaoyou Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Renrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Haojia Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+T">Timin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yongdong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yubo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhengye Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Longtian Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+G">Gaoxiang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yunhang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengdan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peixian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sirui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiawu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shaohui Lin</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Deqiang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Di Yin</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Peng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Ke Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+R">Rongrong Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Total 120 pages. See our project at <a href="https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multimedia (cs.MM)

</div>
<p class="mathjax">The surge of interest towards Multi-modal Large Language Models (MLLMs),
e.g., GPT-4V(ision) from OpenAI, has marked a significant trend in both
academia and industry. They endow Large Language Models (LLMs) with powerful
capabilities in visual understanding, enabling them to tackle diverse
multi-modal tasks. Very recently, Google released Gemini, its newest and most
capable MLLM built from the ground up for multi-modality. In light of the
superior reasoning capabilities, can Gemini challenge GPT-4V's leading position
in multi-modal learning? In this paper, we present a preliminary exploration of
Gemini Pro's visual understanding proficiency, which comprehensively covers
four domains: fundamental perception, advanced cognition, challenging vision
tasks, and various expert capacities. We compare Gemini Pro with the
state-of-the-art GPT-4V to evaluate its upper limits, along with the latest
open-sourced MLLM, Sphinx, which reveals the gap between manual efforts and
black-box systems. The qualitative samples indicate that, while GPT-4V and
Gemini showcase different answering styles and preferences, they can exhibit
comparable visual reasoning capabilities, and Sphinx still trails behind them
concerning domain generalizability. Specifically, GPT-4V tends to elaborate
detailed explanations and intermediate steps, and Gemini prefers to output a
direct and concise answer. The quantitative evaluation on the popular MME
benchmark also demonstrates the potential of Gemini to be a strong challenger
to GPT-4V. Our early investigation of Gemini also observes some common issues
of MLLMs, indicating that there still remains a considerable distance towards
artificial general intelligence. Our project for tracking the progress of MLLM
is released at
https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models.
</p>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12437" title="Abstract">arXiv:2312.12437</a> [<a href="/pdf/2312.12437" title="Download PDF">pdf</a>, <a href="/format/2312.12437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly Supervised Open-Vocabulary Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jianghang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yunhang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bingquan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shaohui Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Ke Li</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Liujuan Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite weakly supervised object detection (WSOD) being a promising step
toward evading strong instance-level annotations, its capability is confined to
closed-set categories within a single training dataset. In this paper, we
propose a novel weakly supervised open-vocabulary object detection framework,
namely WSOVOD, to extend traditional WSOD to detect novel concepts and utilize
diverse datasets with only image-level annotations. To achieve this, we explore
three vital strategies, including dataset-level feature adaptation, image-level
salient object localization, and region-level vision-language alignment. First,
we perform data-aware feature extraction to produce an input-conditional
coefficient, which is leveraged into dataset attribute prototypes to identify
dataset bias and help achieve cross-dataset generalization. Second, a
customized location-oriented weakly supervised region proposal network is
proposed to utilize high-level semantic layouts from the category-agnostic
segment anything model to distinguish object boundaries. Lastly, we introduce a
proposal-concept synchronized multiple-instance network, i.e., object mining
and refinement with visual-semantic alignment, to discover objects matched to
the text embeddings of concepts. Extensive experiments on Pascal VOC and MS
COCO demonstrate that the proposed WSOVOD achieves new state-of-the-art
compared with previous WSOD methods in both close-set object localization and
detection tasks. Meanwhile, WSOVOD enables cross-dataset and open-vocabulary
learning to achieve on-par or even better performance than well-established
fully-supervised open-vocabulary object detection (FSOVOD).
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Wed, 20 Dec 23</h3>
<dl>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14345" title="Abstract">arXiv:2310.14345</a> (cross-list from quant-ph) [<a href="/pdf/2310.14345" title="Download PDF">pdf</a>, <a href="/format/2310.14345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Walk Search in Motion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Sahu%2C+H">Himanshu Sahu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sen%2C+K">Kallol Sen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">In quantum computing, the quantum walk search algorithm is designed for
locating fixed marked nodes within a graph. However, when multiple marked nodes
exist, the conventional search algorithm lacks the capacity to simultaneously
amplify the marked nodes as well as identify the correct chronological ordering
between the marked nodes, if any. To address this limitation, we explore a
potential extension of the algorithm by introducing additional quantum states
to label the marked nodes. The labels resolve the ambiguity of simultaneous
amplification of the marked nodes. Additionally, by associating the label
states with a chronological ordering, we can extend the algorithm to track a
moving particle on a two-dimensional surface. Our algorithm efficiently
searches for the trajectory of the particle and is supported by a proposed
quantum circuit. This concept holds promise for a range of applications, from
real-time object tracking to network management and routing.
</p>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11467" title="Abstract">arXiv:2312.11467</a> (cross-list from eess.IV) [<a href="/pdf/2312.11467" title="Download PDF">pdf</a>, <a href="/format/2312.11467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Glioblastoma Tumor Segmentation using an Ensemble of Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+H">Huafeng Liu</a> (1), 
<a href="/search/eess?searchtype=author&query=Dowdell%2C+B">Benjamin Dowdell</a> (1), 
<a href="/search/eess?searchtype=author&query=Engelder%2C+T">Todd Engelder</a> (1), 
<a href="/search/eess?searchtype=author&query=Pulmano%2C+Z">Zarah Pulmano</a> (1), 
<a href="/search/eess?searchtype=author&query=Osa%2C+N">Nicolas Osa</a> (1), 
<a href="/search/eess?searchtype=author&query=Barman%2C+A">Arko Barman</a> (1) ((1) Rice University)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Glioblastoma is one of the most aggressive and deadliest types of brain
cancer, with low survival rates compared to other types of cancer. Analysis of
Magnetic Resonance Imaging (MRI) scans is one of the most effective methods for
the diagnosis and treatment of brain cancers such as glioblastoma. Accurate
tumor segmentation in MRI images is often required for treatment planning and
risk assessment of treatment methods. Here, we propose a novel pipeline, Brain
Radiology Aided by Intelligent Neural NETworks (BRAINNET), which leverages
MaskFormer, a vision transformer model, and generates robust tumor segmentation
maks. We use an ensemble of nine predictions from three models separately
trained on each of the three orthogonal 2D slice directions (axial, sagittal,
and coronal) of a 3D brain MRI volume. We train and test our models on the
publicly available UPenn-GBM dataset, consisting of 3D multi-parametric MRI
(mpMRI) scans from 611 subjects. Using Dice coefficient (DC) and 95% Hausdorff
distance (HD) for evaluation, our models achieved state-of-the-art results in
segmenting all three different tumor regions -- tumor core (DC = 0.894, HD =
2.308), whole tumor (DC = 0.891, HD = 3.552), and enhancing tumor (DC = 0.812,
HD = 1.608).
</p>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11468" title="Abstract">arXiv:2312.11468</a> (cross-list from physics.med-ph) [<a href="/pdf/2312.11468" title="Download PDF">pdf</a>, <a href="/format/2312.11468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unbiased Neural Networks for Parameter Estimation in Quantitative MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Mao%2C+A">Andrew Mao</a>, 
<a href="/search/physics?searchtype=author&query=Flassbeck%2C+S">Sebastian Flassbeck</a>, 
<a href="/search/physics?searchtype=author&query=Assl%C3%A4nder%2C+J">Jakob Assl&#xe4;nder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Purpose: To develop neural-network (NN)-based quantitative MRI parameter
estimators with minimal bias and a variance close to the theoretical minimum,
the Cram\'er-Rao bound.
<br />Theory and Methods: We explicitly penalize the bias of the NN's estimates
during training, which involves averaging over multiple noise realizations of
the same measurements. Bias and variance properties of the resulting NNs are
studied for two quantitative neuroimaging applications.
<br />Results: In simulation, the proposed strategy reduces the estimates' bias
throughout parameter space and achieves a variance close to the Cram\'er-Rao
bound. In vivo, we observe good concordance between parameter maps estimated
with the proposed NNs and traditional estimators, such as non-linear
least-squares fitting, while state-of-the-art NNs show larger deviations.
<br />Conclusion: NNs trained with the proposed strategy are approximately minimum
variance unbiased estimators and offer significantly improved computational
efficiency over traditional estimators with comparable or better accuracy.
</p>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11476" title="Abstract">arXiv:2312.11476</a> (cross-list from physics.geo-ph) [<a href="/pdf/2312.11476" title="Download PDF">pdf</a>, <a href="/ps/2312.11476" title="Download PostScript">ps</a>, <a href="/format/2312.11476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The geometry of flow: Advancing predictions of river geometry with  multi-model machine learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Chang%2C+S+Y">Shuyu Y Chang</a>, 
<a href="/search/physics?searchtype=author&query=Ghahremani%2C+Z">Zahra Ghahremani</a>, 
<a href="/search/physics?searchtype=author&query=Manuel%2C+L">Laura Manuel</a>, 
<a href="/search/physics?searchtype=author&query=Erfani%2C+M">Mohammad Erfani</a>, 
<a href="/search/physics?searchtype=author&query=Shen%2C+C">Chaopeng Shen</a>, 
<a href="/search/physics?searchtype=author&query=Cohen%2C+S">Sagy Cohen</a>, 
<a href="/search/physics?searchtype=author&query=Van+Meter%2C+K">Kimberly Van Meter</a>, 
<a href="/search/physics?searchtype=author&query=Pierce%2C+J+L">Jennifer L Pierce</a>, 
<a href="/search/physics?searchtype=author&query=Meselhe%2C+E+A">Ehab A Meselhe</a>, 
<a href="/search/physics?searchtype=author&query=Goharian%2C+E">Erfan Goharian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Hydraulic geometry parameters describing river hydrogeomorphic is important
for flood forecasting. Although well-established, power-law hydraulic geometry
curves have been widely used to understand riverine systems and mapping
flooding inundation worldwide for the past 70 years, we have become
increasingly aware of the limitations of these approaches. In the present
study, we have moved beyond these traditional power-law relationships for river
geometry, testing the ability of machine-learning models to provide improved
predictions of river width and depth. For this work, we have used an
unprecedentedly large river measurement dataset (HYDRoSWOT) as well as a suite
of watershed predictor data to develop novel data-driven approaches to better
estimate river geometries over the contiguous United States (CONUS). Our Random
Forest, XGBoost, and neural network models out-performed the traditional,
regionalized power law-based hydraulic geometry equations for both width and
depth, providing R-squared values of as high as 0.75 for width and as high as
0.67 for depth, compared with R-squared values of 0.57 for width and 0.18 for
depth from the regional hydraulic geometry equations. Our results also show
diverse performance outcomes across stream orders and geographical regions for
the different machine-learning models, demonstrating the value of using
multi-model approaches to maximize the predictability of river geometry. The
developed models have been used to create the newly publicly available
STREAM-geo dataset, which provides river width, depth, width/depth ratio, and
river and stream surface area (%RSSA) for nearly 2.7 million NHDPlus stream
reaches across the rivers and streams across the contiguous US.
</p>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11477" title="Abstract">arXiv:2312.11477</a> (cross-list from physics.bio-ph) [<a href="/pdf/2312.11477" title="Download PDF">pdf</a>, <a href="/format/2312.11477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstructing relaxed configurations in elastic bodies: Mathematical  formulation and numerical methods for cardiac modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Barnafi%2C+N+A">N. A. Barnafi</a>, 
<a href="/search/physics?searchtype=author&query=Regazzoni%2C+F">F. Regazzoni</a>, 
<a href="/search/physics?searchtype=author&query=Riccobelli%2C+D">D. Riccobelli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biological Physics (physics.bio-ph)</span>; Soft Condensed Matter (cond-mat.soft); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Modeling the behavior of biological tissues and organs often necessitates the
knowledge of their shape in the absence of external loads. However, when their
geometry is acquired in-vivo through imaging techniques, bodies are typically
subject to mechanical deformation due to the presence of external forces, and
the load-free configuration needs to be reconstructed. This paper addresses
this crucial and frequently overlooked topic, known as the inverse elasticity
problem (IEP), by delving into both theoretical and numerical aspects, with a
particular focus on cardiac mechanics. In this work, we extend Shield's seminal
work to determine the structure of the IEP with arbitrary material
inhomogeneities and in the presence of both body and active forces. These
aspects are fundamental in computational cardiology, and we show that they may
break the variational structure of the inverse problem. In addition, we show
that the inverse problem might be ill-posed, even in the presence of constant
Neumann boundary conditions and a polyconvex strain energy functional. We then
present the results of extensive numerical tests to validate our theoretical
framework, and to characterize the computational challenges associated with a
direct numerical approximation of the IEP. Specifically, we show that this
framework outperforms existing approaches both in terms of robustness and
optimality, such as Sellier's iterative procedure, even when the latter is
improved with acceleration techniques. A notable discovery is that multigrid
preconditioners are, in contrast to standard elasticity, not efficient, and
domain decomposition methods provide a much more reliable alternative. Finally,
we successfully address the IEP for a full-heart geometry, demonstrating that
the IEP formulation can compute the stress-free configuration in real-life
scenarios where Sellier's algorithm proves inadequate.
</p>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11487" title="Abstract">arXiv:2312.11487</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2312.11487" title="Download PDF">pdf</a>, <a href="/format/2312.11487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symbolic Learning for Material Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Cunnington%2C+D">Daniel Cunnington</a>, 
<a href="/search/cond-mat?searchtype=author&query=Cipcigan%2C+F">Flaviu Cipcigan</a>, 
<a href="/search/cond-mat?searchtype=author&query=Ferreira%2C+R+N+B">Rodrigo Neumann Barros Ferreira</a>, 
<a href="/search/cond-mat?searchtype=author&query=Booth%2C+J">Jonathan Booth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the AI for Accelerated Materials Discovery Workshop, NeurIPS2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Discovering new materials is essential to solve challenges in climate change,
sustainability and healthcare. A typical task in materials discovery is to
search for a material in a database which maximises the value of a function.
That function is often expensive to evaluate, and can rely upon a simulation or
an experiment. Here, we introduce SyMDis, a sample efficient optimisation
method based on symbolic learning, that discovers near-optimal materials in a
large database. SyMDis performs comparably to a state-of-the-art optimiser,
whilst learning interpretable rules to aid physical and chemical verification.
Furthermore, the rules learned by SyMDis generalise to unseen datasets and
return high performing candidates in a zero-shot evaluation, which is difficult
to achieve with other approaches.
</p>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11530" title="Abstract">arXiv:2312.11530</a> (cross-list from q-fin.ST) [<a href="/pdf/2312.11530" title="Download PDF">pdf</a>, <a href="/format/2312.11530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Twitter Permeability to financial events: an experiment towards a model  for sensing irregularities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Vilas%2C+A+F">Ana Fern&#xe1;ndez Vilas</a>, 
<a href="/search/q-fin?searchtype=author&query=Redondo%2C+R+P+D">Rebeca P. D&#xed;az Redondo</a>, 
<a href="/search/q-fin?searchtype=author&query=Crockett%2C+K">Keeley Crockett</a>, 
<a href="/search/q-fin?searchtype=author&query=Owda%2C+M">Majdi Owda</a>, 
<a href="/search/q-fin?searchtype=author&query=Evans%2C+L">Lewis Evans</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Multimed Tools Appl 78, 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">There is a general consensus of the good sensing and novelty characteristics
of Twitter as an information media for the complex financial market. This paper
investigates the permeability of Twittersphere, the total universe of Twitter
users and their habits, towards relevant events in the financial market.
Analysis shows that a general purpose social media is permeable to
financial-specific events and establishes Twitter as a relevant feeder for
taking decisions regarding the financial market and event fraudulent activities
in that market. However, the provenance of contributions, their different
levels of credibility and quality and even the purpose or intention behind them
should to be considered and carefully contemplated if Twitter is used as a
single source for decision taking. With the overall aim of this research, to
deploy an architecture for real-time monitoring of irregularities in the
financial market, this paper conducts a series of experiments on the level of
permeability and the permeable features of Twitter in the event of one of these
irregularities. To be precise, Twitter data is collected concerning an event
comprising of a specific financial action on the 27th January 2017:{~ }the
announcement about the merge of two companies Tesco PLC and Booker Group PLC,
listed in the main market of the London Stock Exchange (LSE), to create the
UK's Leading Food Business. The experiment attempts to answer five key research
questions which aim to characterize the features of Twitter permeability to the
financial market. The experimental results confirm that a far-impacting
financial event, such as the merger considered, caused apparent disturbances in
all the features considered, that is, information volume, content and sentiment
as well as geographical provenance. Analysis shows that despite, Twitter not
being a specific financial forum, it is permeable to financial events.
</p>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11531" title="Abstract">arXiv:2312.11531</a> (cross-list from q-fin.ST) [<a href="/pdf/2312.11531" title="Download PDF">pdf</a>, <a href="/format/2312.11531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The irruption of cryptocurrencies into Twitter cashtags: a classifying  solution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Vilas%2C+A+F">Ana Fern&#xe1;ndez Vilas</a>, 
<a href="/search/q-fin?searchtype=author&query=Redondo%2C+R+D">Rebeca D&#xed;az Redondo</a>, 
<a href="/search/q-fin?searchtype=author&query=Garc%C3%ADa%2C+A+L">Ant&#xf3;n Lorenzo Garc&#xed;a</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EEE Access, vol. 8, 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">There is a consensus about the good sensing characteristics of Twitter to
mine and uncover knowledge in financial markets, being considered a relevant
feeder for taking decisions about buying or holding stock shares and even for
detecting stock manipulation. Although Twitter hashtags allow to aggregate
topic-related content, a specific mechanism for financial information also
exists: Cashtag. However, the irruption of cryptocurrencies has resulted in a
significant degradation on the cashtag-based aggregation of posts.
Unfortunately, Twitter' users may use homonym tickers to refer to
cryptocurrencies and to companies in stock markets, which means that filtering
by cashtag may result on both posts referring to stock companies and
cryptocurrencies. This research proposes automated classifiers to distinguish
conflicting cashtags and, so, their container tweets by analyzing the
distinctive features of tweets referring to stock companies and
cryptocurrencies. As experiment, this paper analyses the interference between
cryptocurrencies and company tickers in the London Stock Exchange (LSE),
specifically, companies in the main and alternative market indices FTSE-100 and
AIM-100. Heuristic-based as well as supervised classifiers are proposed and
their advantages and drawbacks, including their ability to self-adapt to
Twitter usage changes, are discussed. The experiment confirms a significant
distortion in collected data when colliding or homonym cashtags exist, i.e.,
the same \$ acronym to refer to company tickers and cryptocurrencies. According
to our results, the distinctive features of posts including cryptocurrencies or
company tickers support accurate classification of colliding tweets (homonym
cashtags) and Independent Models, as the most detached classifiers from
training data, have the potential to be trans-applicability (in different stock
markets) while retaining performance.
</p>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11580" title="Abstract">arXiv:2312.11580</a> (cross-list from eess.IV) [<a href="/pdf/2312.11580" title="Download PDF">pdf</a>, <a href="/format/2312.11580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PlaNet-S: Automatic Semantic Segmentation of Placenta
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yamamoto%2C+S">Shinnosuke Yamamoto</a>, 
<a href="/search/eess?searchtype=author&query=Saito%2C+I">Isso Saito</a>, 
<a href="/search/eess?searchtype=author&query=Takaya%2C+E">Eichi Takaya</a>, 
<a href="/search/eess?searchtype=author&query=Harigai%2C+A">Ayaka Harigai</a>, 
<a href="/search/eess?searchtype=author&query=Sato%2C+T">Tomomi Sato</a>, 
<a href="/search/eess?searchtype=author&query=Kobayashi%2C+T">Tomoya Kobayashi</a>, 
<a href="/search/eess?searchtype=author&query=Takase%2C+K">Kei Takase</a>, 
<a href="/search/eess?searchtype=author&query=Ueda%2C+T">Takuya Ueda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures, Shinnosuke Yamamoto and Isso Saito equally contributed to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">[Purpose] To develop a fully automated semantic placenta segmentation model
that integrates the U-Net and SegNeXt architectures through ensemble learning.
[Methods] A total of 218 pregnant women with suspected placental anomalies who
underwent magnetic resonance imaging (MRI) were enrolled, yielding 1090
annotated images for developing a deep learning model for placental
segmentation. The images were standardized and divided into training and test
sets. The performance of PlaNet-S, which integrates U-Net and SegNeXt within an
ensemble framework, was assessed using Intersection over Union (IoU) and
counting connected components (CCC) against the U-Net model. [Results] PlaNet-S
had significantly higher IoU (0.73 +/- 0.13) than that of U-Net (0.78 +/-
0.010) (p&lt;0.01). The CCC for PlaNet-S was significantly higher than that for
U-Net (p&lt;0.01), matching the ground truth in 86.0\% and 56.7\% of the cases,
respectively. [Conclusion]PlaNet-S performed better than the traditional U-Net
in placental segmentation tasks. This model addresses the challenges of
time-consuming physician-assisted manual segmentation and offers the potential
for diverse applications in placental imaging analyses.
</p>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11584" title="Abstract">arXiv:2312.11584</a> (cross-list from q-bio.QM) [<a href="/pdf/2312.11584" title="Download PDF">pdf</a>, <a href="/format/2312.11584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ContraNovo: A Contrastive Learning Approach to Enhance De Novo Peptide  Sequencing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Jin%2C+Z">Zhi Jin</a>, 
<a href="/search/q-bio?searchtype=author&query=Xu%2C+S">Sheng Xu</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+X">Xiang Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Ling%2C+T">Tianze Ling</a>, 
<a href="/search/q-bio?searchtype=author&query=Dong%2C+N">Nanqing Dong</a>, 
<a href="/search/q-bio?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>, 
<a href="/search/q-bio?searchtype=author&query=Gao%2C+Z">Zhiqiang Gao</a>, 
<a href="/search/q-bio?searchtype=author&query=Chang%2C+C">Cheng Chang</a>, 
<a href="/search/q-bio?searchtype=author&query=Sun%2C+S">Siqi Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">De novo peptide sequencing from mass spectrometry (MS) data is a critical
task in proteomics research. Traditional de novo algorithms have encountered a
bottleneck in accuracy due to the inherent complexity of proteomics data. While
deep learning-based methods have shown progress, they reduce the problem to a
translation task, potentially overlooking critical nuances between spectra and
peptides. In our research, we present ContraNovo, a pioneering algorithm that
leverages contrastive learning to extract the relationship between spectra and
peptides and incorporates the mass information into peptide decoding, aiming to
address these intricacies more efficiently. Through rigorous evaluations on two
benchmark datasets, ContraNovo consistently outshines contemporary
state-of-the-art solutions, underscoring its promising potential in enhancing
de novo peptide sequencing. The source code is available at
https://github.com/BEAM-Labs/ContraNovo.
</p>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11629" title="Abstract">arXiv:2312.11629</a> (cross-list from hep-ph) [<a href="/pdf/2312.11629" title="Download PDF">pdf</a>, <a href="/format/2312.11629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Residual ANODE
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ph?searchtype=author&query=Das%2C+R">Ranit Das</a>, 
<a href="/search/hep-ph?searchtype=author&query=Kasieczka%2C+G">Gregor Kasieczka</a>, 
<a href="/search/hep-ph?searchtype=author&query=Shih%2C+D">David Shih</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Phenomenology (hep-ph)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">We present R-ANODE, a new method for data-driven, model-agnostic resonant
anomaly detection that raises the bar for both performance and
interpretability. The key to R-ANODE is to enhance the inductive bias of the
anomaly detection task by fitting a normalizing flow directly to the small and
unknown signal component, while holding fixed a background model (also a
normalizing flow) learned from sidebands. In doing so, R-ANODE is able to
outperform all classifier-based, weakly-supervised approaches, as well as the
previous ANODE method which fit a density estimator to all of the data in the
signal region instead of just the signal. We show that the method works equally
well whether the unknown signal fraction is learned or fixed, and is even
robust to signal fraction misspecification. Finally, with the learned signal
model we can sample and gain qualitative insights into the underlying anomaly,
which greatly enhances the interpretability of resonant anomaly detection and
offers the possibility of simultaneously discovering and characterizing the new
physics that could be hiding in the data.
</p>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11706" title="Abstract">arXiv:2312.11706</a> (cross-list from math.CO) [<a href="/pdf/2312.11706" title="Download PDF">pdf</a>, <a href="/format/2312.11706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Some Fibonacci-Related Sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cloitre%2C+B">Benoit Cloitre</a>, 
<a href="/search/math?searchtype=author&query=Shallit%2C+J">Jeffrey Shallit</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">We discuss an interesting sequence defined recursively; namely, sequence
A105774 from the On-Line Encyclopedia of Integer Sequences, and study some of
its properties. Our main tools are Fibonacci representation, finite automata,
and the Walnut theorem-prover. We also prove two new results about synchronized
sequences.
</p>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11708" title="Abstract">arXiv:2312.11708</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2312.11708" title="Download PDF">pdf</a>, <a href="/ps/2312.11708" title="Download PostScript">ps</a>, <a href="/format/2312.11708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating the prediction of inorganic surfaces with machine learning  interatomic potentials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Noordhoek%2C+K">Kyle Noordhoek</a>, 
<a href="/search/cond-mat?searchtype=author&query=Bartel%2C+C+J">Christopher J. Bartel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The surface properties of solid-state materials often dictate their
functionality, especially for applications where nanoscale effects become
important. The relevant surface(s) and their properties are determined, in
large part, by the materials synthesis or operating conditions. These
conditions dictate thermodynamic driving forces and kinetic rates responsible
for yielding the observed surface structure and morphology. Computational
surface science methods have long been applied to connect thermochemical
conditions to surface phase stability, particularly in the heterogeneous
catalysis and thin film growth communities. This review provides a brief
introduction to first-principles approaches to compute surface phase diagrams
before introducing emerging data-driven approaches. The remainder of the review
focuses on the application of machine learning, predominantly in the form of
learned interatomic potentials, to study complex surfaces. As machine learning
algorithms and large datasets on which to train them become more commonplace in
materials science, computational methods are poised to become even more
predictive and powerful for modeling the complexities of inorganic surfaces at
the nanoscale.
</p>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11723" title="Abstract">arXiv:2312.11723</a> (cross-list from math.CO) [<a href="/pdf/2312.11723" title="Download PDF">pdf</a>, <a href="/ps/2312.11723" title="Download PostScript">ps</a>, <a href="/format/2312.11723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Uniquely Decodable Codes in Binary Adder Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Balogh%2C+J">J&#xf3;zsef Balogh</a>, 
The <a href="/search/math?searchtype=author&query=Nguyen">Nguyen</a>, 
<a href="/search/math?searchtype=author&query=Ostergard%2C+P+R+J">Patric R.J. Ostergard</a>, 
<a href="/search/math?searchtype=author&query=White%2C+E+P">Ethan Patrick White</a>, 
<a href="/search/math?searchtype=author&query=Wigal%2C+M">Michael Wigal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">We present a general method to modify existing uniquely decodable codes in
the $T$-user binary adder channel. If at least one of the original constituent
codes does not have average weight exactly half of the dimension, then our
method produces a new set of constituent codes in a higher dimension, with a
strictly higher rate. Using our method we improve the highest known rate for
the $T$-user binary adder channel for all $T \geq 2$. This information theory
problem is equivalent to co-Sidon problems initiated by Lindstr{\"o}m in the
1960s, and also the multi-set union-free problem. Our results improve the known
lower bounds in these settings as well.
</p>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11729" title="Abstract">arXiv:2312.11729</a> (cross-list from hep-ex) [<a href="/pdf/2312.11729" title="Download PDF">pdf</a>, <a href="/format/2312.11729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RenderCore -- a new WebGPU-based rendering engine for ROOT-EVE
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ex?searchtype=author&query=Bohak%2C+C">Ciril Bohak</a>, 
<a href="/search/hep-ex?searchtype=author&query=Kovalskyi%2C+D">Dmytro Kovalskyi</a>, 
<a href="/search/hep-ex?searchtype=author&query=Linev%2C+S">Sergey Linev</a>, 
<a href="/search/hep-ex?searchtype=author&query=Tadel%2C+A+M">Alja Mrak Tadel</a>, 
<a href="/search/hep-ex?searchtype=author&query=Strban%2C+S">Sebastien Strban</a>, 
<a href="/search/hep-ex?searchtype=author&query=Tadel%2C+M">Matevz Tadel</a>, 
<a href="/search/hep-ex?searchtype=author&query=Yagil%2C+A">Avi Yagil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Experiment (hep-ex)</span>; Graphics (cs.GR); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">ROOT-Eve (REve), the new generation of the ROOT event-display module, uses a
web server-client model to guarantee exact data translation from the
experiments' data analysis frameworks to users' browsers. Data is then
displayed in various views, including high-precision 2D and 3D graphics views,
currently driven by THREE.js rendering engine based on WebGL technology.
RenderCore, a computer graphics research-oriented rendering engine, has been
integrated into REve to optimize rendering performance and enable the use of
state-of-the-art techniques for object highlighting and object selection. It
also allowed for the implementation of optimized instanced rendering through
the usage of custom shaders and rendering pipeline modifications. To further
the impact of this investment and ensure the long-term viability of REve,
RenderCore is being refactored on top of WebGPU, the next-generation GPU
interface for browsers that supports compute shaders, storage textures and
introduces significant improvements in GPU utilization. This has led to
optimization of interchange data formats, decreased server-client traffic, and
improved offloading of data visualization algorithms to the GPU. FireworksWeb,
a physics analysis-oriented event display of the CMS experiment, is used to
demonstrate the results, focusing on high-granularity calorimeters and
targeting high data-volume events of heavy-ion collisions and High-Luminosity
LHC. The next steps and directions are also discussed.
</p>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11748" title="Abstract">arXiv:2312.11748</a> (cross-list from eess.IV) [<a href="/pdf/2312.11748" title="Download PDF">pdf</a>, <a href="/format/2312.11748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultrasound Image Enhancement using CycleGAN and Perceptual Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Athreya%2C+S">Shreeram Athreya</a>, 
<a href="/search/eess?searchtype=author&query=Radhachandran%2C+A">Ashwath Radhachandran</a>, 
<a href="/search/eess?searchtype=author&query=Ivezi%C4%87%2C+V">Vedrana Ivezi&#x107;</a>, 
<a href="/search/eess?searchtype=author&query=Sant%2C+V">Vivek Sant</a>, 
<a href="/search/eess?searchtype=author&query=Arnold%2C+C+W">Corey W. Arnold</a>, 
<a href="/search/eess?searchtype=author&query=Speier%2C+W">William Speier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Purpose: The objective of this work is to introduce an advanced framework
designed to enhance ultrasound images, especially those captured by portable
hand-held devices, which often produce lower quality images due to hardware
constraints. Additionally, this framework is uniquely capable of effectively
handling non-registered input ultrasound image pairs, addressing a common
challenge in medical imaging. Materials and Methods: In this retrospective
study, we utilized an enhanced generative adversarial network (CycleGAN) model
for ultrasound image enhancement across five organ systems. Perceptual loss,
derived from deep features of pretrained neural networks, is applied to ensure
the human-perceptual quality of the enhanced images. These images are compared
with paired images acquired from high resolution devices to demonstrate the
model's ability to generate realistic high-quality images across organ systems.
Results: Preliminary validation of the framework reveals promising performance
metrics. The model generates images that result in a Structural Similarity
Index (SSI) score of 0.722, Locally Normalized Cross-Correlation (LNCC) score
of 0.902 and 28.802 for the Peak Signal-to-Noise Ratio (PSNR) metric.
Conclusion: This work presents a significant advancement in medical imaging
through the development of a CycleGAN model enhanced with Perceptual Loss (PL),
effectively bridging the quality gap between ultrasound images from varied
devices. By training on paired images, the model not only improves image
quality but also ensures the preservation of vital anatomic structural content.
This approach may improve equity in access to healthcare by enhancing portable
device capabilities, although further validation and optimizations are
necessary for broader clinical application.
</p>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11775" title="Abstract">arXiv:2312.11775</a> (cross-list from eess.IV) [<a href="/pdf/2312.11775" title="Download PDF">pdf</a>, <a href="/ps/2312.11775" title="Download PostScript">ps</a>, <a href="/format/2312.11775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards SAMBA: Segment Anything Model for Brain Tumor Segmentation in  Sub-Sharan African Populations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Barakat%2C+M">Mohannad Barakat</a>, 
<a href="/search/eess?searchtype=author&query=Magdy%2C+N">Noha Magdy</a>, 
<a href="/search/eess?searchtype=author&query=William%2C+J+G">Jjuuko George William</a>, 
<a href="/search/eess?searchtype=author&query=Phiri%2C+E">Ethel Phiri</a>, 
<a href="/search/eess?searchtype=author&query=Confidence%2C+R">Raymond Confidence</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+D">Dong Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Anazodo%2C+U+C">Udunna C Anazodo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Gliomas, the most prevalent primary brain tumors, require precise
segmentation for diagnosis and treatment planning. However, this task poses
significant challenges, particularly in the African population, were limited
access to high-quality imaging data hampers algorithm performance. In this
study, we propose an innovative approach combining the Segment Anything Model
(SAM) and a voting network for multi-modal glioma segmentation. By fine-tuning
SAM with bounding box-guided prompts (SAMBA), we adapt the model to the
complexities of African datasets. Our ensemble strategy, utilizing multiple
modalities and views, produces a robust consensus segmentation, addressing
intra-tumoral heterogeneity. Although the low quality of scans presents
difficulties, our methodology has the potential to profoundly impact clinical
practice in resource-limited settings such as Africa, improving treatment
decisions and advancing neuro-oncology research. Furthermore, successful
application to other brain tumor types and lesions in the future holds promise
for a broader transformation in neurological imaging, improving healthcare
outcomes across all settings. This study was conducted on the Brain Tumor
Segmentation (BraTS) Challenge Africa (BraTS-Africa) dataset, which provides a
valuable resource for addressing challenges specific to resource-limited
settings, particularly the African population, and facilitating the development
of effective and more generalizable segmentation algorithms. To illustrate our
approach's potential, our experiments on the BraTS-Africa dataset yielded
compelling results, with SAM attaining a Dice coefficient of 86.6 for binary
segmentation and 60.4 for multi-class segmentation.
</p>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11797" title="Abstract">arXiv:2312.11797</a> (cross-list from q-fin.PM) [<a href="/pdf/2312.11797" title="Download PDF">pdf</a>, <a href="/format/2312.11797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Merton&#x27;s Strategies in an Incomplete Market: Recursive Entropy  Regularization and Biased Gaussian Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Dai%2C+M">Min Dai</a>, 
<a href="/search/q-fin?searchtype=author&query=Dong%2C+Y">Yuchao Dong</a>, 
<a href="/search/q-fin?searchtype=author&query=Jia%2C+Y">Yanwei Jia</a>, 
<a href="/search/q-fin?searchtype=author&query=Zhou%2C+X+Y">Xun Yu Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages, 5 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Portfolio Management (q-fin.PM)</span>; Machine Learning (cs.LG); Computational Finance (q-fin.CP)

</div>
<p class="mathjax">We study Merton's expected utility maximization problem in an incomplete
market, characterized by a factor process in addition to the stock price
process, where all the model primitives are unknown. We take the reinforcement
learning (RL) approach to learn optimal portfolio policies directly by
exploring the unknown market, without attempting to estimate the model
parameters. Based on the entropy-regularization framework for general
continuous-time RL formulated in Wang et al. (2020), we propose a recursive
weighting scheme on exploration that endogenously discounts the current
exploration reward by the past accumulative amount of exploration. Such a
recursive regularization restores the optimality of Gaussian exploration.
However, contrary to the existing results, the optimal Gaussian policy turns
out to be biased in general, due to the interwinding needs for hedging and for
exploration. We present an asymptotic analysis of the resulting errors to show
how the level of exploration affects the learned policies. Furthermore, we
establish a policy improvement theorem and design several RL algorithms to
learn Merton's optimal strategies. At last, we carry out both simulation and
empirical studies with a stochastic volatility environment to demonstrate the
efficiency and robustness of the RL algorithms in comparison to the
conventional plug-in method.
</p>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11801" title="Abstract">arXiv:2312.11801</a> (cross-list from math.OC) [<a href="/pdf/2312.11801" title="Download PDF">pdf</a>, <a href="/format/2312.11801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast, Scalable, Warm-Start Semidefinite Programming with Spectral  Bundling and Sketching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Angell%2C+R">Rico Angell</a>, 
<a href="/search/math?searchtype=author&query=McCallum%2C+A">Andrew McCallum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">While semidefinite programming (SDP) has traditionally been limited to
moderate-sized problems, recent algorithms augmented with matrix sketching
techniques have enabled solving larger SDPs. However, these methods achieve
scalability at the cost of an increase in the number of necessary iterations,
resulting in slower convergence as the problem size grows. Furthermore, they
require iteration-dependent parameter schedules that prohibit effective
utilization of warm-start initializations important in practical applications
with incrementally-arriving data or mixed-integer programming. We present
SpecBM, a provably correct, fast and scalable algorithm for solving massive
SDPs that can leverage a warm-start initialization to further accelerate
convergence. Our proposed algorithm is a spectral bundle method for solving
general SDPs containing both equality and inequality constraints. Moveover,
when augmented with an optional matrix sketching technique, our algorithm
achieves the dramatically improved scalability of previous work while
sustaining convergence speed. We empirically demonstrate the effectiveness of
our method, both with and without warm-starting, across multiple applications
with large instances. For example, on a problem with 600 million decision
variables, SpecBM achieved a solution of standard accuracy in less than 7
minutes, where the previous state-of-the-art scalable SDP solver requires more
than 16 hours. Our method solves an SDP with more than 10^13 decision variables
on a single machine with 16 cores and no more than 128GB RAM; the previous
state-of-the-art method had not achieved an accurate solution after 72 hours on
the same instance. We make our implementation in pure JAX publicly available.
</p>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11822" title="Abstract">arXiv:2312.11822</a> (cross-list from cond-mat.soft) [<a href="/pdf/2312.11822" title="Download PDF">pdf</a>, <a href="/format/2312.11822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification of complex local environments in systems of particle  shapes through shape-symmetry encoded data augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Shih-Kuang">Shih-Kuang</a> (Alex)Lee, 
<a href="/search/cond-mat?searchtype=author&query=Tsai%2C+S">Sun-Ting Tsai</a>, 
<a href="/search/cond-mat?searchtype=author&query=Glotzer%2C+S">Sharon Glotzer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Soft Condensed Matter (cond-mat.soft)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Detecting and analyzing the local environment is crucial for investigating
the dynamical processes of crystal nucleation and shape colloidal particle
self-assembly. Recent developments in machine learning provide a promising
avenue for better order parameters in complex systems that are challenging to
study using traditional approaches. However, the application of machine
learning to self-assembly on systems of particle shapes is still underexplored.
To address this gap, we propose a simple, physics-agnostic, yet powerful
approach that involves training a multilayer perceptron (MLP) as a local
environment classifier for systems of particle shapes, using input features
such as particle distances and orientations. Our MLP classifier is trained in a
supervised manner with a shape symmetry-encoded data augmentation technique
without the need for any conventional roto-translations invariant symmetry
functions. We evaluate the performance of our classifiers on four different
scenarios involving self-assembly of cubic structures, 2-dimensional and
3-dimensional patchy particle shape systems, hexagonal bipyramids with varying
aspect ratios, and truncated shapes with different degrees of truncation. The
proposed training process and data augmentation technique are both
straightforward and flexible, enabling easy application of the classifier to
other processes involving particle orientations. Our work thus presents a
valuable tool for investigating self-assembly processes on systems of particle
shapes, with potential applications in structure identification of any
particle-based or molecular system where orientations can be defined.
</p>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11861" title="Abstract">arXiv:2312.11861</a> (cross-list from math.OC) [<a href="/pdf/2312.11861" title="Download PDF">pdf</a>, <a href="/format/2312.11861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MG-Skip: Random Multi-Gossip Skipping Method for Nonsmooth Distributed  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Guo%2C+L">Luyao Guo</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+L">Luqing Wang</a>, 
<a href="/search/math?searchtype=author&query=Shi%2C+X">Xinli Shi</a>, 
<a href="/search/math?searchtype=author&query=Cao%2C+J">Jinde Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Distributed optimization methods with probabilistic local updates have
recently gained attention for their provable ability to communication
acceleration. Nevertheless, this capability is effective only when the loss
function is smooth and the network is sufficiently well-connected. In this
paper, we propose the first linear convergent method MG-Skip with probabilistic
local updates for nonsmooth distributed optimization. Without any extra
condition for the network connectivity, MG-Skip allows for the multiple-round
gossip communication to be skipped in most iterations, while its iteration
complexity is $\mathcal{O}\left(\kappa \log \frac{1}{\epsilon}\right)$ and
communication complexity is only
$\mathcal{O}\left(\sqrt{\frac{\kappa}{(1-\rho)}} \log
\frac{1}{\epsilon}\right)$, where $\kappa$ is the condition number of the loss
function and $\rho$ reflects the connectivity of the network topology. To the
best of our knowledge, MG-Skip achieves the best communication complexity when
the loss function has the smooth (strongly convex)+nonsmooth (convex) composite
form.
</p>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11876" title="Abstract">arXiv:2312.11876</a> (cross-list from math.CO) [<a href="/pdf/2312.11876" title="Download PDF">pdf</a>, <a href="/ps/2312.11876" title="Download PostScript">ps</a>, <a href="/format/2312.11876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On recognition algorithms and structure of graphs with restricted  induced cycles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cook%2C+L">Linda Cook</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD Thesis, May 2021, Princeton University, Advisor: Paul Seymour
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">This is my PhD thesis which was defended in May 2021.
<br />We call an induced cycle of length at least four a hole. The parity of a hole
is the parity of its length. Forbidding holes of certain types in a graph has
deep structural implications. In 2006, Chudnovksy, Seymour, Robertson, and
Thomas famously proved that a graph is perfect if and only if it does not
contain an odd hole or a complement of an odd hole. In 2002, Conforti,
Cornu\'{e}jols, Kapoor and Vu\v{s}kov\'{i}c provided a structural description
of the class of even-hole-free graphs. In Chapter 3, we provide a structural
description of all graphs that contain only holes of length $\ell$ for every
$\ell \geq 7$.
<br />Analysis of how holes interact with graph structure has yielded detection
algorithms for holes of various lengths and parities. In 1991, Bienstock showed
it is NP-Hard to test whether a graph G has an even (or odd) hole containing a
specified vertex $v \in V(G)$. In 2002, Conforti, Cornu\'{e}jols, Kapoor and
Vu\v{s}kov\'{i}c gave a polynomial-time algorithm to recognize even-hole-free
graphs using their structure theorem. In 2003, Chudnovsky, Kawarabayashi and
Seymour provided a simpler and slightly faster algorithm to test whether a
graph contains an even hole. In 2019, Chudnovsky, Scott, Seymour and Spirkl
provided a polynomial-time algorithm to test whether a graph contains an odd
hole. Later that year, Chudnovsky, Scott and Seymour strengthened this result
by providing a polynomial-time algorithm to test whether a graph contains an
odd hole of length at least $\ell$ for any fixed integer $\ell \geq 5$. In
Chapter 2, we provide a polynomial-time algorithm to test whether a graph
contains an even hole of length at least $\ell$ for any fixed integer $\ell
\geq 4$.
</p>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11903" title="Abstract">arXiv:2312.11903</a> (cross-list from eess.SP) [<a href="/pdf/2312.11903" title="Download PDF">pdf</a>, <a href="/format/2312.11903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sign Language Conversation Interpretation Using Wearable Sensors and  Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kalandar%2C+B">Basma Kalandar</a>, 
<a href="/search/eess?searchtype=author&query=Dworakowski%2C+Z">Ziemowit Dworakowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The count of people suffering from various levels of hearing loss reached
1.57 billion in 2019. This huge number tends to suffer on many personal and
professional levels and strictly needs to be included with the rest of society
healthily. This paper presents a proof of concept of an automatic sign language
recognition system based on data obtained using a wearable device of 3 flex
sensors. The system is designed to interpret a selected set of American Sign
Language (ASL) dynamic words by collecting data in sequences of the performed
signs and using machine learning methods. The built models achieved
high-quality performances, such as Random Forest with 99% accuracy, Support
Vector Machine (SVM) with 99%, and two K-Nearest Neighbor (KNN) models with
98%. This indicates many possible paths toward the development of a full-scale
system.
</p>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11942" title="Abstract">arXiv:2312.11942</a> (cross-list from econ.GN) [<a href="/pdf/2312.11942" title="Download PDF">pdf</a>, <a href="/ps/2312.11942" title="Download PostScript">ps</a>, <a href="/format/2312.11942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Skills or Degree? The Rise of Skill-Based Hiring for AI and Green Jobs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Ehlinger%2C+E+G">Eugenia Gonzalez Ehlinger</a>, 
<a href="/search/econ?searchtype=author&query=Stephany%2C+F">Fabian Stephany</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 13 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">For emerging professions, such as jobs in the field of Artificial
Intelligence (AI) or sustainability (green), labour supply does not meet
industry demand. In this scenario of labour shortages, our work aims to
understand whether employers have started focusing on individual skills rather
than on formal qualifications in their recruiting. By analysing a large time
series dataset of around one million online job vacancies between 2019 and 2022
from the UK and drawing on diverse literature on technological change and
labour market signalling, we provide evidence that employers have started
so-called "skill-based hiring" for AI and green roles, as more flexible hiring
practices allow them to increase the available talent pool. In our observation
period the demand for AI roles grew twice as much as average labour demand. At
the same time, the mention of university education for AI roles declined by
23%, while AI roles advertise five times as many skills as job postings on
average. Our regression analysis also shows that university degrees no longer
show an educational premium for AI roles, while for green positions the
educational premium persists. In contrast, AI skills have a wage premium of
16%, similar to having a PhD (17%). Our work recommends making use of
alternative skill building formats such as apprenticeships, on-the-job
training, MOOCs, vocational education and training, micro-certificates, and
online bootcamps to use human capital to its full potential and to tackle
talent shortages.
</p>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11950" title="Abstract">arXiv:2312.11950</a> (cross-list from math.AP) [<a href="/pdf/2312.11950" title="Download PDF">pdf</a>, <a href="/format/2312.11950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boundary stabilization of the Korteweg-de Vries-Burgers equation with an  infinite memory-type control and applications: a qualitative and numerical  analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chentouf%2C+B">Boumedi&#xe8;ne Chentouf</a>, 
<a href="/search/math?searchtype=author&query=Guesmia%2C+A">Aissa Guesmia</a> (IECL), 
<a href="/search/math?searchtype=author&query=Cortes%2C+M+A+S">Mauricio A Sepulveda Cortes</a>, 
<a href="/search/math?searchtype=author&query=V%C3%A9jar%2C+R">Rodrigo V&#xe9;jar</a> (USERENA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">This article is intended to present a qualitative and numerical analysis of
well-posedness and boundary stabilization problems of the well-known
Korteweg-de Vries-Burgers equation. Assuming that the boundary control is of
memory type, the history approach is adopted in order to deal with the memory
term. Under sufficient conditions on the physical parameters of the system and
the memory kernel of the control, the system is shown to be well-posed by
combining the semigroups approach of linear operators and the fixed point
theory. Then, energy decay estimates are provided by applying the multiplier
method. An application to the Kuramoto-Sivashinsky equation will be also given.
Moreover, we present a numerical analysis based on a finite differences method
and provide numerical examples illustrating our theoretical results.
</p>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12003" title="Abstract">arXiv:2312.12003</a> (cross-list from stat.ML) [<a href="/pdf/2312.12003" title="Download PDF">pdf</a>, <a href="/format/2312.12003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modelling and characterization of fine Particulate Matter dynamics in  Bujumbura using low cost sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ndamuzi%2C+E">Egide Ndamuzi</a>, 
<a href="/search/stat?searchtype=author&query=Akimana%2C+R">Rachel Akimana</a>, 
<a href="/search/stat?searchtype=author&query=Gahungu%2C+P">Paterne Gahungu</a>, 
<a href="/search/stat?searchtype=author&query=Bimenyimana%2C+E">Elie Bimenyimana</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Air pollution is a result of multiple sources including both natural and
anthropogenic activities. The rapid urbanization of the cities such as
Bujumbura economic capital of Burundi, is one of these factors. The very first
characterization of the spatio-temporal variability of PM2.5 in Bujumbura and
the forecasting of PM2.5 concentration have been conducted in this paper using
data collected during a year, from august 2022 to august 2023, by low cost
sensors installed in Bujumbura city. For each commune, an hourly, daily and
seasonal analysis were carried out and the results showed that the mass
concentrations of PM2.5 in the three municipalities differ from one commune to
another. The average hourly and annual PM2.5 concentrations exceed the World
Health Organization standards. The range is between 28.3 and 35.0 microgram/m3
. In order to make prediction of PM2.5 concentration, an investigation of RNN
with Long Short Term Memory (LSTM) has been undertaken.
</p>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12022" title="Abstract">arXiv:2312.12022</a> (cross-list from stat.ML) [<a href="/pdf/2312.12022" title="Download PDF">pdf</a>, <a href="/format/2312.12022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LightGCNet: A Lightweight Geometric Constructive Neural Network for  Data-Driven Soft sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Nan%2C+J">Jing Nan</a>, 
<a href="/search/stat?searchtype=author&query=Qin%2C+Y">Yan Qin</a>, 
<a href="/search/stat?searchtype=author&query=Dai%2C+W">Wei Dai</a>, 
<a href="/search/stat?searchtype=author&query=Yuen%2C+C">Chau Yuen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2307.00185">arXiv:2307.00185</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Data-driven soft sensors provide a potentially cost-effective and more
accurate modeling approach to measure difficult-to-measure indices in
industrial processes compared to mechanistic approaches. Artificial
intelligence (AI) techniques, such as deep learning, have become a popular soft
sensors modeling approach in the area of machine learning and big data.
However, soft sensors models based deep learning potentially lead to complex
model structures and excessive training time. In addition, industrial processes
often rely on distributed control systems (DCS) characterized by resource
constraints. Herein, guided by spatial geometric, a lightweight geometric
constructive neural network, namely LightGCNet, is proposed, which utilizes
compact angle constraint to assign the hidden parameters from dynamic
intervals. At the same time, a node pool strategy and spatial geometric
relationships are used to visualize and optimize the process of assigning
hidden parameters, enhancing interpretability. In addition, the universal
approximation property of LightGCNet is proved by spatial geometric analysis.
Two versions algorithmic implementations of LightGCNet are presented in this
article. Simulation results concerning both benchmark datasets and the ore
grinding process indicate remarkable merits of LightGCNet in terms of small
network size, fast learning speed, and sound generalization.
</p>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12023" title="Abstract">arXiv:2312.12023</a> (cross-list from eess.IV) [<a href="/pdf/2312.12023" title="Download PDF">pdf</a>, <a href="/format/2312.12023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Progressive Frequency-Aware Network for Laparoscopic Image Desmoking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jiale Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+W">Wenfeng Huang</a>, 
<a href="/search/eess?searchtype=author&query=Liao%2C+X">Xiangyun Liao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Q">Qiong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Laparoscopic surgery offers minimally invasive procedures with better patient
outcomes, but smoke presence challenges visibility and safety. Existing
learning-based methods demand large datasets and high computational resources.
We propose the Progressive Frequency-Aware Network (PFAN), a lightweight GAN
framework for laparoscopic image desmoking, combining the strengths of CNN and
Transformer for progressive information extraction in the frequency domain.
PFAN features CNN-based Multi-scale Bottleneck-Inverting (MBI) Blocks for
capturing local high-frequency information and Locally-Enhanced Axial Attention
Transformers (LAT) for efficiently handling global low-frequency information.
PFAN efficiently desmokes laparoscopic images even with limited training data.
Our method outperforms state-of-the-art approaches in PSNR, SSIM, CIEDE2000,
and visual quality on the Cholec80 dataset and retains only 629K parameters.
Our code and models are made publicly available at:
https://github.com/jlzcode/PFAN.
</p>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12113" title="Abstract">arXiv:2312.12113</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2312.12113" title="Download PDF">pdf</a>, <a href="/format/2312.12113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Mode Decomposition-Based Nonstationary Coherent Structure  Analysis for Spatiotemporal Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Ohmichi%2C+Y">Yuya Ohmichi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Machine Learning (cs.LG); Dynamical Systems (math.DS)

</div>
<p class="mathjax">The modal analysis techniques face difficulties in handling nonstationary
phenomena. This paper presents a variational mode decomposition-based
nonstationary coherent structure (VMD-NCS) analysis that enables the extraction
and analysis of coherent structures in case of nonstationary phenomena from
high-dimensional spatiotemporal data. The VMD-NCS analysis decomposes the input
spatiotemporal data into intrinsic coherent structures (ICSs) that represent
nonstationary spatiotemporal patterns and exhibit coherence in both the spatial
and temporal directions. Furthermore, unlike many conventional modal analysis
techniques, the proposed method accounts for the temporal changes in the
spatial distribution with time. The performance of the VMD-NCS analysis was
validated based on the transient growth phenomena in the flow around a
cylinder. It was confirmed that the temporal changes in the spatial
distribution, depicting the transient growth of vortex shedding where
fluctuations arising in the far-wake region gradually approach the near-wake
region, were represented as a single ICS. Further, in the analysis of the
quasi-periodic flow field around a pitching airfoil, the temporal changes in
the spatial distribution and the amplitude of vortex shedding behind the
airfoil, influenced by the pitching motion of the airfoil, were captured as a
single ICS. Additionally, the impact of two parameters, adjusting the number of
ICSs ($K$) and the penalty factor related to the temporal coherence ($\alpha$),
was investigated. The results revealed that $K$ has a significant impact on the
VMD-NCS analysis results. In the case of a relatively high $K$, the VMD-NCS
analysis tends to extract more periodic spatiotemporal patterns resembling the
results of dynamic mode decomposition, whereas in the case of a small $K$, the
analysis tends to extract more nonstationary spatiotemporal patterns.
</p>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12135" title="Abstract">arXiv:2312.12135</a> (cross-list from eess.IV) [<a href="/pdf/2312.12135" title="Download PDF">pdf</a>, <a href="/ps/2312.12135" title="Download PostScript">ps</a>, <a href="/format/2312.12135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object Detection for Automated Coronary Artery Using Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Keshavarz%2C+H">Hadis Keshavarz</a>, 
<a href="/search/eess?searchtype=author&query=Sadr%2C+H">Hossein Sadr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the era of digital medicine, medical imaging serves as a widespread
technique for early disease detection, with a substantial volume of images
being generated and stored daily in electronic patient records. X-ray
angiography imaging is a standard and one of the most common methods for
rapidly diagnosing coronary artery diseases. The notable achievements of recent
deep learning algorithms align with the increased use of electronic health
records and diagnostic imaging. Deep neural networks, leveraging abundant data,
advanced algorithms, and powerful computational capabilities, prove highly
effective in the analysis and interpretation of images. In this context, Object
detection methods have become a promising approach, particularly through
convolutional neural networks (CNN), streamlining medical image analysis by
eliminating manual feature extraction. This allows for direct feature
extraction from images, ensuring high accuracy in results. Therefore, in our
paper, we utilized the object detection method on X-ray angiography images to
precisely identify the location of coronary artery stenosis. As a result, this
model enables automatic and real-time detection of stenosis locations,
assisting in the crucial and sensitive decision-making process for healthcare
professionals.
</p>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12150" title="Abstract">arXiv:2312.12150</a> (cross-list from eess.IV) [<a href="/pdf/2312.12150" title="Download PDF">pdf</a>, <a href="/ps/2312.12150" title="Download PostScript">ps</a>, <a href="/format/2312.12150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Study of Hardware and Software Power Measurements in Video  Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Katsenou%2C+A">Angeliki Katsenou</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xinyi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Schien%2C+D">Daniel Schien</a>, 
<a href="/search/eess?searchtype=author&query=Bull%2C+D">David Bull</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">The environmental impact of video streaming services has been discussed as
part of the strategies towards sustainable information and communication
technologies. A first step towards that is the energy profiling and assessment
of energy consumption of existing video technologies. This paper presents a
comprehensive study of power measurement techniques in video compression,
comparing the use of hardware and software power meters. An experimental
methodology to ensure reliability of measurements is introduced. Key findings
demonstrate the high correlation of hardware and software based energy
measurements for two video codecs across different spatial and temporal
resolutions at a lower computational overhead.
</p>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12151" title="Abstract">arXiv:2312.12151</a> (cross-list from eess.IV) [<a href="/pdf/2312.12151" title="Download PDF">pdf</a>, <a href="/format/2312.12151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoftCTM: Cell detection by soft instance segmentation and consideration  of cell-tissue interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Schoenpflug%2C+L+A">Lydia A. Schoenpflug</a>, 
<a href="/search/eess?searchtype=author&query=Koelzer%2C+V+H">Viktor H. Koelzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Detecting and classifying cells in histopathology H\&amp;E stained whole-slide
images is a core task in computational pathology, as it provides valuable
insight into the tumor microenvironment. In this work we investigate the impact
of ground truth formats on the models performance. Additionally, cell-tissue
interactions are considered by providing tissue segmentation predictions as
input to the cell detection model. We find that a "soft", probability-map
instance segmentation ground truth leads to best model performance. Combined
with cell-tissue interaction and test-time augmentation our Soft
Cell-Tissue-Model (SoftCTM) achieves 0.7172 mean F1-Score on the Overlapped
Cell On Tissue (OCELOT) test set, achieving the third best overall score in the
OCELOT 2023 Challenge. The source code for our approach is made publicly
available at https://github.com/lely475/ocelot23algo.
</p>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12166" title="Abstract">arXiv:2312.12166</a> (cross-list from math.DS) [<a href="/pdf/2312.12166" title="Download PDF">pdf</a>, <a href="/format/2312.12166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backtracking New Q-Newton&#x27;s method, Schr&#xf6;der&#x27;s theorem, and Linear  Conjugacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fornaess%2C+J+E">John Erik Fornaess</a>, 
<a href="/search/math?searchtype=author&query=Hu%2C+M">Mi Hu</a>, 
<a href="/search/math?searchtype=author&query=Truong%2C+T+T">Tuyen Trung Truong</a>, 
<a href="/search/math?searchtype=author&query=Watanabe%2C+T">Takayuki Watanabe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages. Comments are welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Complex Variables (math.CV); Numerical Analysis (math.NA); Optimization and Control (math.OC)

</div>
<p class="mathjax">A new variant of Newton's method - named Backtracking New Q-Newton's method
(BNQN) - which has strong theoretical guarantee, is easy to implement, and has
good experimental performance, was recently introduced by the third author.
<br />Experiments performed previously showed some remarkable properties of the
basins of attractions for finding roots of polynomials and meromorphic
functions using BNQN. In particular, it seems that for finding roots of
polynomials of degree 2, the basins of attraction of the dynamics for BNQN are
the same as that for Newton's method (the latter is the classical Schr\"oder's
result in Complex Dynamics).
<br />In this paper, we show that indeed the picture we obtain when finding roots
of polynomials of degree 2 is the same as that in Sch\"oder's result, with a
remarkable difference: on the boundary line of the basins, the dynamics of
Newton's method is chaotic, while the dynamics of BNQN is more smooth. On the
way to proving the result, we show that BNQN (in any dimension) is invariant
under conjugation by linear operators of the form $A=cR$, where $R$ is unitary
and $c&gt;0$ a constant. This again illustrates the similarity-difference relation
between BNQN and Newton's method.
</p>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12171" title="Abstract">arXiv:2312.12171</a> (cross-list from math.DS) [<a href="/pdf/2312.12171" title="Download PDF">pdf</a>, <a href="/format/2312.12171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equivariant divergence formula for chaotic flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ni%2C+A">Angxiu Ni</a>, 
<a href="/search/math?searchtype=author&query=Tong%2C+Y">Yao Tong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> comments are welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Numerical Analysis (math.NA); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">We prove the equivariant divergence formula for the axiom A flow attractors,
which is a recursive formula for perturbation of transfer operators of physical
measures along center-unstable manifolds. Hence the linear response acquires an
`ergodic theorem', which means that it can be sampled by recursively computing
only $2u$ many vectors on one orbit, where $u$ is the unstable dimension.
</p>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12173" title="Abstract">arXiv:2312.12173</a> (cross-list from math.OC) [<a href="/pdf/2312.12173" title="Download PDF">pdf</a>, <a href="/ps/2312.12173" title="Download PostScript">ps</a>, <a href="/format/2312.12173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Globally Convergent Policy Gradient Method for Linear Quadratic  Gaussian (LQG) Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sadamoto%2C+T">Tomonori Sadamoto</a>, 
<a href="/search/math?searchtype=author&query=Nakamata%2C+F">Fumiya Nakamata</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We present a model-based globally convergent policy gradient method (PGM) for
linear quadratic Gaussian (LQG) control. Firstly, we establish equivalence
between optimizing dynamic output feedback controllers and designing a static
feedback gain for a system represented by a finite-length input-output history
(IOH). This IOH-based approach allows us to explore LQG controllers within a
parameter space defined by IOH gains. Secondly, by considering a control law
comprising the IOH gain and a sufficiently small random perturbation,we show
that the cost function, evaluated through the control law over IOH gains, is
gradient-dominant and locally smooth,ensuring the global linear convergence of
the PGM.
</p>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12189" title="Abstract">arXiv:2312.12189</a> (cross-list from eess.IV) [<a href="/pdf/2312.12189" title="Download PDF">pdf</a>, <a href="/format/2312.12189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teeth Localization and Lesion Segmentation in CBCT Images using  SpatialConfiguration-Net and U-Net
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hadzic%2C+A">Arnela Hadzic</a>, 
<a href="/search/eess?searchtype=author&query=Kirnbauer%2C+B">Barbara Kirnbauer</a>, 
<a href="/search/eess?searchtype=author&query=Stern%2C+D">Darko Stern</a>, 
<a href="/search/eess?searchtype=author&query=Urschler%2C+M">Martin Urschler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for VISIGRAPP 2024 (Track: VISAPP), 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The localization of teeth and segmentation of periapical lesions in cone-beam
computed tomography (CBCT) images are crucial tasks for clinical diagnosis and
treatment planning, which are often time-consuming and require a high level of
expertise. However, automating these tasks is challenging due to variations in
shape, size, and orientation of lesions, as well as similar topologies among
teeth. Moreover, the small volumes occupied by lesions in CBCT images pose a
class imbalance problem that needs to be addressed. In this study, we propose a
deep learning-based method utilizing two convolutional neural networks: the
SpatialConfiguration-Net (SCN) and a modified version of the U-Net. The SCN
accurately predicts the coordinates of all teeth present in an image, enabling
precise cropping of teeth volumes that are then fed into the U-Net which
detects lesions via segmentation. To address class imbalance, we compare the
performance of three reweighting loss functions. After evaluation on 144 CBCT
images, our method achieves a 97.3% accuracy for teeth localization, along with
a promising sensitivity and specificity of 0.97 and 0.88, respectively, for
subsequent lesion detection.
</p>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12192" title="Abstract">arXiv:2312.12192</a> (cross-list from math.OC) [<a href="/pdf/2312.12192" title="Download PDF">pdf</a>, <a href="/ps/2312.12192" title="Download PostScript">ps</a>, <a href="/format/2312.12192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Improvements of Multi-Objective Branch and Bound
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bau%C3%9Fm%2C+J">Julius Bau&#xdf;m</a>, 
<a href="/search/math?searchtype=author&query=Parragh%2C+S+N">Sophie N. Parragh</a>, 
<a href="/search/math?searchtype=author&query=Stiglmayr%2C+M">Michael Stiglmayr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Discrete Mathematics (cs.DM); Mathematical Software (cs.MS)

</div>
<p class="mathjax">Branch and bound methods which are based on the principle "divide and
conquer" are a well established solution approach in single-objective integer
programming. In multi-objective optimization branch and bound algorithms are
increasingly attracting interest. However, the larger number of objectives
raises additional difficulties for implicit enumeration approaches like branch
and bound. Since bounding and pruning is considerably weaker in multiple
objectives, many branches have to be (partially) searched and may not be pruned
directly. The adaptive use of objective space information can guide the search
in promising directions to determine a good approximation of the Pareto front
already in early stages of the algorithm. In particular we focus in this
article on improving the branching and queuing of subproblems and the handling
of lower bound sets.
<br />In our numerical test we evaluate the impact of the proposed methods in
comparison to a standard implementation of multiobjective branch and bound on
knapsack problems, generalized assignment problems and (un)capacitated facility
location problems.
</p>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12230" title="Abstract">arXiv:2312.12230</a> (cross-list from math.OC) [<a href="/pdf/2312.12230" title="Download PDF">pdf</a>, <a href="/format/2312.12230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> It&#x27;s All in the Mix: Wasserstein Machine Learning with Mixed Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Belbasi%2C+R">Reza Belbasi</a>, 
<a href="/search/math?searchtype=author&query=Selvi%2C+A">Aras Selvi</a>, 
<a href="/search/math?searchtype=author&query=Wiesemann%2C+W">Wolfram Wiesemann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages (31 main + proofs), 7 tables, 2 colored plots, an early version appeared in NeurIPS 2022 main track (arXiv <a href="/abs/2205.13501">2205.13501</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Problem definition: The recent advent of data-driven and end-to-end
decision-making across different areas of operations management has led to an
ever closer integration of prediction models from machine learning and
optimization models from operations research. A key challenge in this context
is the presence of estimation errors in the prediction models, which tend to be
amplified by the subsequent optimization model -- a phenomenon that is often
referred to as the Optimizer's Curse or the Error-Maximization Effect of
Optimization.
<br />Methodology/results: A contemporary approach to combat such estimation errors
is offered by distributionally robust problem formulations that consider all
data-generating distributions close to the empirical distribution derived from
historical samples, where `closeness' is determined by the Wasserstein
distance. While those techniques show significant promise in problems where all
input features are continuous, they scale exponentially when binary and/or
categorical features are present. This paper demonstrates that such
mixed-feature problems can indeed be solved in polynomial time. We present a
practically efficient algorithm to solve mixed-feature problems, and we compare
our method against alternative techniques both theoretically and empirically on
standard benchmark instances.
<br />Managerial implications: Data-driven operations management problems often
involve prediction models with discrete features. We develop and analyze a
methodology that faithfully accounts for the presence of discrete features, and
we demonstrate that our approach can significantly outperform existing methods
that are agnostic to the presence of discrete features, both theoretically and
across standard benchmark instances.
</p>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12245" title="Abstract">arXiv:2312.12245</a> (cross-list from math.CO) [<a href="/pdf/2312.12245" title="Download PDF">pdf</a>, <a href="/ps/2312.12245" title="Download PostScript">ps</a>, <a href="/format/2312.12245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On generalized Sidon spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Castello%2C+C">Chiara Castello</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Sidon spaces have been introduced by Bachoc, Serra and Z\'emor as the
$q$-analogue of Sidon sets, classical combinatorial objects introduced by Simon
Szidon. In 2018 Roth, Raviv and Tamo introduced the notion of $r$-Sidon spaces,
as an extension of Sidon spaces, which may be seen as the $q$-analogue of
$B_r$-sets, a generalization of classical Sidon sets. Thanks to their work, the
interest on Sidon spaces has increased quickly because of their connection with
cyclic subspace codes they pointed out. This class of codes turned out to be of
interest since they can be used in random linear network coding. In this work
we focus on a particular class of them, the one-orbit cyclic subspace codes,
through the investigation of some properties of Sidon spaces and $r$-Sidon
spaces, providing some upper and lower bounds on the possible dimension of
their \textit{r-span} and showing explicit constructions in the case in which
the upper bound is achieved. Moreover, we provide further constructions of
$r$-Sidon spaces, arising from algebraic and combinatorial objects, and we show
examples of $B_r$-sets constructed by means of them.
</p>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12260" title="Abstract">arXiv:2312.12260</a> (cross-list from math.CO) [<a href="/pdf/2312.12260" title="Download PDF">pdf</a>, <a href="/format/2312.12260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Connectedness in fair division of circle and star cakes between two  agents with unequal entitlements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hanke%2C+J">Josef Hanke</a>, 
<a href="/search/math?searchtype=author&query=Heggison%2C+A">Alyssa Heggison</a>, 
<a href="/search/math?searchtype=author&query=Pires%2C+A+R">Ana Rita Pires</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Austin's moving knife procedure is used to divide a cake equitably between
two agents: each agent believes that they received exactly half of the cake.
This short note deals with the case when the two agents have unequal (rational)
entitlements to the cake and seek a weighted equitable division -- one where
each agent believes that they received exactly the share that they are entitled
to -- and also minimizes the number of connected components that each agent
receives. First, we adapt Austin's moving knife procedure to produce a weighted
equitable division of a circular cake that gives exactly one connected piece to
each agent (recovering a result of Shishido and Zeng's). Next, we use it to
produce a weighted equitable division of a star graph cake that gives at most
two connected pieces to each agent -- and show that this bound on the number of
connected pieces is tight.
</p>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12262" title="Abstract">arXiv:2312.12262</a> (cross-list from eess.AS) [<a href="/pdf/2312.12262" title="Download PDF">pdf</a>, <a href="/ps/2312.12262" title="Download PostScript">ps</a>, <a href="/format/2312.12262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Speech-in-Speech Perception via a Humanoid Robot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Meyer%2C+L">Luke Meyer</a>, 
<a href="/search/eess?searchtype=author&query=Araiza-Illan%2C+G">Gloria Araiza-Illan</a>, 
<a href="/search/eess?searchtype=author&query=Rachman%2C+L">Laura Rachman</a>, 
<a href="/search/eess?searchtype=author&query=Gaudrain%2C+E">Etienne Gaudrain</a>, 
<a href="/search/eess?searchtype=author&query=Baskent%2C+D">Deniz Baskent</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages (single spaced), 6 figures (at the end of the manuscript), 88 references, under revision with Frontiers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Robotics (cs.RO); Sound (cs.SD)

</div>
<p class="mathjax">Underlying mechanisms of speech perception masked by background speakers, a
common daily listening condition, are often investigated using various and
lengthy psychophysical tests. The presence of a social agent, such as an
interactive humanoid NAO robot, may help maintain engagement and attention.
However, such robots potentially have limited sound quality or processing
speed. As a first step towards the use of NAO in psychophysical testing of
speech-in-speech perception, we compared normal-hearing young adults'
performance when using the standard computer interface to that when using a NAO
robot to introduce the test and present all corresponding stimuli. Target
sentences were presented with colour and number keywords in the presence of
competing masker speech at varying target-to-masker ratios. Sentences were
produced by the same speaker, but voice differences between the target and
masker were introduced using speech synthesis methods. To assess test
performance, speech intelligibility and data collection duration were compared
between the computer and NAO setups. Human-robot interaction was assessed using
the Negative Attitude Towards Robot Scale (NARS) and quantification of
behavioural cues (backchannels). Speech intelligibility results showed
functional similarity between the computer and NAO setups. Data collection
durations were longer when using NAO. NARS results showed participants had a
more positive attitude toward robots prior to their interaction with NAO. The
presence of more positive backchannels when using NAO suggest higher engagement
with the robot in comparison to the computer. Overall, the study presents the
potential of the NAO for presentingspeech materials and collecting
psychophysical measurements for speech-in-speech perception.
</p>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12296" title="Abstract">arXiv:2312.12296</a> (cross-list from physics.optics) [<a href="/pdf/2312.12296" title="Download PDF">pdf</a>, <a href="/format/2312.12296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weak Kerr Nonlinearity Boosts the Performance of Frequency-Multiplexed  Photonic Extreme Learning Machines: A Multifaceted Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Zajnulina%2C+M">Marina Zajnulina</a>, 
<a href="/search/physics?searchtype=author&query=Lupo%2C+A">Alessandro Lupo</a>, 
<a href="/search/physics?searchtype=author&query=Massar%2C+S">Serge Massar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Emerging Technologies (cs.ET); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">We provide a theoretical, numerical, and experimental investigation of the
Kerr nonlinearity impact on the performance of a frequency-multiplexed Extreme
Learning Machine (ELM). In such ELM, the neuron signals are encoded in the
lines of a frequency comb. The Kerr nonlinearity facilitates the randomized
neuron connections allowing for efficient information mixing. A programmable
spectral filter applies the output weights. The system operates in a
continuous-wave regime. Even at low input peak powers, the resulting weak Kerr
nonlinearity is sufficient to significantly boost the performance on several
tasks. This boost already arises when one uses only the very small Kerr
nonlinearity present in a 20-meter long erbium-doped fiber amplifier. In
contrast, a subsequent propagation in 540 meters of a single-mode fiber
improves the performance only slightly, whereas additional information mixing
with a phase modulator does not result in a further improvement at all. We
introduce a model to show that, in frequency-multiplexed ELMs, the Kerr
nonlinearity mixes information via four-wave mixing, rather than via self- or
cross-phase modulation. At low powers, this effect is quartic in the comb-line
amplitudes. Numerical simulations validate our experimental results and
interpretation.
</p>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12305" title="Abstract">arXiv:2312.12305</a> (cross-list from math.OC) [<a href="/pdf/2312.12305" title="Download PDF">pdf</a>, <a href="/ps/2312.12305" title="Download PostScript">ps</a>, <a href="/format/2312.12305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Root-finding: from Newton to Halley and beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Martin%2C+R+J">Richard J. Martin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA); Computational Finance (q-fin.CP)

</div>
<p class="mathjax">We give a new improvement over Newton's method for root-finding, when the
function in question is doubly differentiable. It generally exhibits faster and
more reliable convergence. It can be also be thought of as a correction to
Halley's method, as this can exhibit undesirable behaviour.
</p>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12315" title="Abstract">arXiv:2312.12315</a> (cross-list from astro-ph.EP) [<a href="/pdf/2312.12315" title="Download PDF">pdf</a>, <a href="/ps/2312.12315" title="Download PostScript">ps</a>, <a href="/format/2312.12315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Celestial Machine Learning: Discovering the Planarity, Heliocentricity,  and Orbital Equation of Mars with AI Feynman
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Khoo%2C+Z">Zi-Yu Khoo</a>, 
<a href="/search/astro-ph?searchtype=author&query=Rajiv%2C+G">Gokul Rajiv</a>, 
<a href="/search/astro-ph?searchtype=author&query=Yang%2C+A">Abel Yang</a>, 
<a href="/search/astro-ph?searchtype=author&query=Low%2C+J+S+C">Jonathan Sze Choong Low</a>, 
<a href="/search/astro-ph?searchtype=author&query=Bressan%2C+S">St&#xe9;phane Bressan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Earth and Planetary Astrophysics (astro-ph.EP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Can a machine or algorithm discover or learn the elliptical orbit of Mars
from astronomical sightings alone? Johannes Kepler required two paradigm shifts
to discover his First Law regarding the elliptical orbit of Mars. Firstly, a
shift from the geocentric to the heliocentric frame of reference. Secondly, the
reduction of the orbit of Mars from a three- to a two-dimensional space. We
extend AI Feynman, a physics-inspired tool for symbolic regression, to discover
the heliocentricity and planarity of Mars' orbit and emulate his discovery of
Kepler's first law.
</p>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12357" title="Abstract">arXiv:2312.12357</a> (cross-list from stat.ML) [<a href="/pdf/2312.12357" title="Download PDF">pdf</a>, <a href="/format/2312.12357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling non-linear Effects with Neural Networks in Relational Event  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Filippi-Mazzola%2C+E">Edoardo Filippi-Mazzola</a>, 
<a href="/search/stat?searchtype=author&query=Wit%2C+E+C">Ernst C. Wit</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Computation (stat.CO); Methodology (stat.ME)

</div>
<p class="mathjax">Dynamic networks offer an insight of how relational systems evolve. However,
modeling these networks efficiently remains a challenge, primarily due to
computational constraints, especially as the number of observed events grows.
This paper addresses this issue by introducing the Deep Relational Event
Additive Model (DREAM) as a solution to the computational challenges presented
by modeling non-linear effects in Relational Event Models (REMs). DREAM relies
on Neural Additive Models to model non-linear effects, allowing each effect to
be captured by an independent neural network. By strategically trading
computational complexity for improved memory management and leveraging the
computational capabilities of Graphic Processor Units (GPUs), DREAM efficiently
captures complex non-linear relationships within data. This approach
demonstrates the capability of DREAM in modeling dynamic networks and scaling
to larger networks. Comparisons with traditional REM approaches showcase DREAM
superior computational efficiency. The model potential is further demonstrated
by an examination of the patent citation network, which contains nearly 8
million nodes and 100 million events.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Wed, 20 Dec 23</h3>
<dl>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1907.06130" title="Abstract">arXiv:1907.06130</a> (replaced) [<a href="/pdf/1907.06130" title="Download PDF">pdf</a>, <a href="/format/1907.06130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying the Vulnerabilities of the Online Public Square to  Adversarial Manipulation Tactics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Truong%2C+B+T">Bao Tran Truong</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+X">Xiaodan Lou</a>, 
<a href="/search/cs?searchtype=author&query=Flammini%2C+A">Alessandro Flammini</a>, 
<a href="/search/cs?searchtype=author&query=Menczer%2C+F">Filippo Menczer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main text: 29 pages, 7 figures, 97 references. Appendix: 3 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Social and Information Networks (cs.SI); Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2003.08433" title="Abstract">arXiv:2003.08433</a> (replaced) [<a href="/pdf/2003.08433" title="Download PDF">pdf</a>, <a href="/format/2003.08433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Fuzzy Extractors: A Secure Way to Use Artificial Neural Networks  for Biometric User Authentication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jana%2C+A">Abhishek Jana</a>, 
<a href="/search/cs?searchtype=author&query=Sarker%2C+M+K">Md Kamruzzaman Sarker</a>, 
<a href="/search/cs?searchtype=author&query=Ebrahimi%2C+M">Monireh Ebrahimi</a>, 
<a href="/search/cs?searchtype=author&query=Hitzler%2C+P">Pascal Hitzler</a>, 
<a href="/search/cs?searchtype=author&query=Amariucai%2C+G+T">George T Amariucai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings on Privacy Enhancing Technologies, 2022, volume 4,
  pages 86-104
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2005.04799" title="Abstract">arXiv:2005.04799</a> (replaced) [<a href="/pdf/2005.04799" title="Download PDF">pdf</a>, <a href="/format/2005.04799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Plurality in Spatial Voting Games with constant $&#x3b2;$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Filtser%2C+A">Arnold Filtser</a>, 
<a href="/search/cs?searchtype=author&query=Filtser%2C+O">Omrit Filtser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.03744" title="Abstract">arXiv:2010.03744</a> (replaced) [<a href="/pdf/2010.03744" title="Download PDF">pdf</a>, <a href="/format/2010.03744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximum Reward Formulation In Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gottipati%2C+S+K">Sai Krishna Gottipati</a>, 
<a href="/search/cs?searchtype=author&query=Pathak%2C+Y">Yashaswi Pathak</a>, 
<a href="/search/cs?searchtype=author&query=Nuttall%2C+R">Rohan Nuttall</a>, 
<a href="/search/cs?searchtype=author&query=Sahir">Sahir</a>, 
<a href="/search/cs?searchtype=author&query=Chunduru%2C+R">Raviteja Chunduru</a>, 
<a href="/search/cs?searchtype=author&query=Touati%2C+A">Ahmed Touati</a>, 
<a href="/search/cs?searchtype=author&query=Subramanian%2C+S+G">Sriram Ganapathi Subramanian</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+M+E">Matthew E. Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Chandar%2C+S">Sarath Chandar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures Update based on reviewer feedback
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.10258" title="Abstract">arXiv:2010.10258</a> (replaced) [<a href="/pdf/2010.10258" title="Download PDF">pdf</a>, <a href="/format/2010.10258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Autoregressive Modeling for Neural Video Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+R">Ruihan Yang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Y">Yibo Yang</a>, 
<a href="/search/eess?searchtype=author&query=Marino%2C+J">Joseph Marino</a>, 
<a href="/search/eess?searchtype=author&query=Mandt%2C+S">Stephan Mandt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper at ICLR 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2101.00153" title="Abstract">arXiv:2101.00153</a> (replaced) [<a href="/pdf/2101.00153" title="Download PDF">pdf</a>, <a href="/format/2101.00153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graphmax for Text Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bin%2C+L">Liu Bin</a>, 
<a href="/search/cs?searchtype=author&query=Guosheng%2C+Y">Yin Guosheng</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Artificial Intelligence Research, vol. 78, pp.823-848,
  Nov. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.11808" title="Abstract">arXiv:2104.11808</a> (replaced) [<a href="/pdf/2104.11808" title="Download PDF">pdf</a>, <a href="/ps/2104.11808" title="Download PostScript">ps</a>, <a href="/format/2104.11808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unifying the Three Algebraic Approaches to the CSP via Minimal Taylor  Algebras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barto%2C+L">Libor Barto</a>, 
<a href="/search/cs?searchtype=author&query=Brady%2C+Z">Zarathustra Brady</a>, 
<a href="/search/cs?searchtype=author&query=Bulatov%2C+A">Andrei Bulatov</a>, 
<a href="/search/cs?searchtype=author&query=Kozik%2C+M">Marcin Kozik</a>, 
<a href="/search/cs?searchtype=author&query=Zhuk%2C+D">Dmitriy Zhuk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.03354" title="Abstract">arXiv:2106.03354</a> (replaced) [<a href="/pdf/2106.03354" title="Download PDF">pdf</a>, <a href="/format/2106.03354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI without networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mitra%2C+P+P">Partha P Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Sire%2C+C">Cl&#xe9;ment Sire</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages with 4 figures + 33 pages supplementary with 7 figures and one table (total 71 pages)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistical Mechanics (cond-mat.stat-mech); Functional Analysis (math.FA); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.03518" title="Abstract">arXiv:2106.03518</a> (replaced) [<a href="/pdf/2106.03518" title="Download PDF">pdf</a>, <a href="/format/2106.03518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Position Bias Mitigation: A Knowledge-Aware Graph Model for Emotion  Cause Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hanqi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+L">Lin Gui</a>, 
<a href="/search/cs?searchtype=author&query=Pergola%2C+G">Gabriele Pergola</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yulan He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACL2021 Main Conference, Oral paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.10433" title="Abstract">arXiv:2106.10433</a> (replaced) [<a href="/pdf/2106.10433" title="Download PDF">pdf</a>, <a href="/format/2106.10433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sharp-interface limits of the diffuse interface model for two-phase  inductionless magnetohydrodynamic fluids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+X">Xiaodi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.05997" title="Abstract">arXiv:2112.05997</a> (replaced) [<a href="/e-print/2112.05997" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two Sequential Squaring Verifiable Delay Function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sur%2C+S">Souvik Sur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The proofs are insufficient
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.10985" title="Abstract">arXiv:2112.10985</a> (replaced) [<a href="/pdf/2112.10985" title="Download PDF">pdf</a>, <a href="/format/2112.10985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learned ISTA with Error-based Thresholding for Adaptive Sparse Coding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kailun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yiwen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Changshui Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.11607" title="Abstract">arXiv:2112.11607</a> (replaced) [<a href="/pdf/2112.11607" title="Download PDF">pdf</a>, <a href="/format/2112.11607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Complexity of Iterated Reversible Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eppstein%2C+D">David Eppstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 8 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> TheoretiCS, Volume 2 (2023), Article 10, 1-41
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Cellular Automata and Lattice Gases (nlin.CG)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.00611" title="Abstract">arXiv:2201.00611</a> (replaced) [<a href="/pdf/2201.00611" title="Download PDF">pdf</a>, <a href="/ps/2201.00611" title="Download PostScript">ps</a>, <a href="/format/2201.00611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust parameter estimation using the ensemble Kalman filter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Reich%2C+S">Sebastian Reich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.00906" title="Abstract">arXiv:2201.00906</a> (replaced) [<a href="/pdf/2201.00906" title="Download PDF">pdf</a>, <a href="/ps/2201.00906" title="Download PostScript">ps</a>, <a href="/format/2201.00906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the concentration of the chromatic number of random graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Surya%2C+E">Erlang Surya</a>, 
<a href="/search/math?searchtype=author&query=Warnke%2C+L">Lutz Warnke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 1 figure. Minor edits, to appear in The Electronic Journal of Combinatorics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.02327" title="Abstract">arXiv:2201.02327</a> (replaced) [<a href="/pdf/2201.02327" title="Download PDF">pdf</a>, <a href="/format/2201.02327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Effectiveness of Sampled Softmax Loss for Item Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiancan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xingyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiawei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Hongcheng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+T">Tianyu Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TOIS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.06104" title="Abstract">arXiv:2201.06104</a> (replaced) [<a href="/pdf/2201.06104" title="Download PDF">pdf</a>, <a href="/format/2201.06104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A phase-space discontinuous Galerkin approximation for the radiative  transfer equation in slab geometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bardin%2C+R">Riccardo Bardin</a>, 
<a href="/search/math?searchtype=author&query=Bertrand%2C+F">Fleurianne Bertrand</a>, 
<a href="/search/math?searchtype=author&query=Palii%2C+O">Olena Palii</a>, 
<a href="/search/math?searchtype=author&query=Schlottbom%2C+M">Matthias Schlottbom</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.03005" title="Abstract">arXiv:2203.03005</a> (replaced) [<a href="/pdf/2203.03005" title="Download PDF">pdf</a>, <a href="/format/2203.03005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Face Image Restoration with a One-Shot Reference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yanhui Guo</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+F">Fangzhou Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shaoyuan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.16284" title="Abstract">arXiv:2203.16284</a> (replaced) [<a href="/pdf/2203.16284" title="Download PDF">pdf</a>, <a href="/format/2203.16284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FIRe: Fast Inverse Rendering using Directional and Signed Distance  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yenamandra%2C+T">Tarun Yenamandra</a>, 
<a href="/search/cs?searchtype=author&query=Tewari%2C+A">Ayush Tewari</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+N">Nan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Bernard%2C+F">Florian Bernard</a>, 
<a href="/search/cs?searchtype=author&query=Theobalt%2C+C">Christian Theobalt</a>, 
<a href="/search/cs?searchtype=author&query=Cremers%2C+D">Daniel Cremers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> News: Accepted to WACV'24. Project page: <a href="https://vision.in.tum.de/research/geometry/fire">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.16557" title="Abstract">arXiv:2203.16557</a> (replaced) [<a href="/pdf/2203.16557" title="Download PDF">pdf</a>, <a href="/format/2203.16557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COSMOS: Cross-Modality Unsupervised Domain Adaptation for 3D Medical  Image Segmentation based on Target-aware Domain Translation and Iterative  Self-Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shin%2C+H">Hyungseob Shin</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+H">Hyeongyu Kim</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+S">Sewon Kim</a>, 
<a href="/search/eess?searchtype=author&query=Jun%2C+Y">Yohan Jun</a>, 
<a href="/search/eess?searchtype=author&query=Eo%2C+T">Taejoon Eo</a>, 
<a href="/search/eess?searchtype=author&query=Hwang%2C+D">Dosik Hwang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures, MICCAI 2021 Cross-Modality Domain Adaptation (crossMoDA) Challenge
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.02031" title="Abstract">arXiv:2204.02031</a> (replaced) [<a href="/pdf/2204.02031" title="Download PDF">pdf</a>, <a href="/format/2204.02031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Nonparametric Estimation of Distribution Divergence in  Non-Euclidean Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C+X">Chong Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tay%2C+W+P">Wee Peng Tay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.08359" title="Abstract">arXiv:2204.08359</a> (replaced) [<a href="/pdf/2204.08359" title="Download PDF">pdf</a>, <a href="/format/2204.08359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed MIS in $O(\log\log{n} )$ Awake Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dufoulon%2C+F">Fabien Dufoulon</a>, 
<a href="/search/cs?searchtype=author&query=Moses%2C+W+K">William K. Moses Jr.</a>, 
<a href="/search/cs?searchtype=author&query=Pandurangan%2C+G">Gopal Pandurangan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Abstract shortened to fit arXiv constraints
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.08385" title="Abstract">arXiv:2204.08385</a> (replaced) [<a href="/pdf/2204.08385" title="Download PDF">pdf</a>, <a href="/format/2204.08385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Awake Complexity of Distributed Minimum Spanning Tree
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Augustine%2C+J">John Augustine</a>, 
<a href="/search/cs?searchtype=author&query=Moses%2C+W+K">William K. Moses Jr.</a>, 
<a href="/search/cs?searchtype=author&query=Pandurangan%2C+G">Gopal Pandurangan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 1 table, 5 figures, abstract modified to fit arXiv constraints
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Data Structures and Algorithms (cs.DS); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.03553" title="Abstract">arXiv:2205.03553</a> (replaced) [<a href="/pdf/2205.03553" title="Download PDF">pdf</a>, <a href="/format/2205.03553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From heavy rain removal to detail restoration: A faster and better  network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yuanbo Wen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+T">Tao Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Ting Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Pattern Recognition
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.09431" title="Abstract">arXiv:2205.09431</a> (replaced) [<a href="/pdf/2205.09431" title="Download PDF">pdf</a>, <a href="/ps/2205.09431" title="Download PostScript">ps</a>, <a href="/format/2205.09431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pitch-axis supermanoeuvrability in a biomimetic morphing-wing UAV
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Pons%2C+A">Arion Pons</a>, 
<a href="/search/physics?searchtype=author&query=Cirak%2C+F">Fehmi Cirak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biological Physics (physics.bio-ph)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.15677" title="Abstract">arXiv:2205.15677</a> (replaced) [<a href="/pdf/2205.15677" title="Download PDF">pdf</a>, <a href="/format/2205.15677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmentation-Aware Self-Supervision for Data-Efficient GAN Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Liang Hou</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Q">Qi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yige Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Songtao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chongyang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Siyuan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+P">Pengfei Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Huawei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.06009" title="Abstract">arXiv:2206.06009</a> (replaced) [<a href="/pdf/2206.06009" title="Download PDF">pdf</a>, <a href="/format/2206.06009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relative Policy-Transition Optimization for Fast Policy Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiawei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Cheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yizheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Baoxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Lei Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.13429" title="Abstract">arXiv:2206.13429</a> (replaced) [<a href="/pdf/2206.13429" title="Download PDF">pdf</a>, <a href="/format/2206.13429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incivility Detection in Open Source Code Review and Issue Discussions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferreira%2C+I">Isabella Ferreira</a>, 
<a href="/search/cs?searchtype=author&query=Rafiq%2C+A">Ahlaam Rafiq</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jinghui Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.08012" title="Abstract">arXiv:2207.08012</a> (replaced) [<a href="/pdf/2207.08012" title="Download PDF">pdf</a>, <a href="/format/2207.08012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-Referential Games to Learn Compositional Learning Behaviours
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Denamgana%C3%AF%2C+K">Kevin Denamgana&#xef;</a>, 
<a href="/search/cs?searchtype=author&query=Missaoui%2C+S">Sondess Missaoui</a>, 
<a href="/search/cs?searchtype=author&query=Walker%2C+J+A">James Alfred Walker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.14513" title="Abstract">arXiv:2207.14513</a> (replaced) [<a href="/pdf/2207.14513" title="Download PDF">pdf</a>, <a href="/format/2207.14513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-Driven Action Quality Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Caixia Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yaping Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+H">Haibin Ling</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.11790" title="Abstract">arXiv:2208.11790</a> (replaced) [<a href="/pdf/2208.11790" title="Download PDF">pdf</a>, <a href="/format/2208.11790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Addressing Token Uniformity in Transformers via Singular Value  Transformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hanqi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+L">Lin Gui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenjie Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yulan He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> UAI2022 Main Conference, Spotlight, combined with supplementary files
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.06327" title="Abstract">arXiv:2209.06327</a> (replaced) [<a href="/pdf/2209.06327" title="Download PDF">pdf</a>, <a href="/format/2209.06327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reproducibility-Oriented and Privacy-Preserving Genomic Dataset Sharing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuzhou Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+T">Tianxi Ji</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pan Li</a>, 
<a href="/search/cs?searchtype=author&query=Ayday%2C+E">Erman Ayday</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.08563" title="Abstract">arXiv:2209.08563</a> (replaced) [<a href="/pdf/2209.08563" title="Download PDF">pdf</a>, <a href="/format/2209.08563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Submodularity, pairwise independence and correlation gap
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ramachandra%2C+A">Arjun Ramachandra</a>, 
<a href="/search/math?searchtype=author&query=Natarajan%2C+K">Karthik Natarajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 5 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.12756" title="Abstract">arXiv:2209.12756</a> (replaced) [<a href="/pdf/2209.12756" title="Download PDF">pdf</a>, <a href="/format/2209.12756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FAL-CUR: Fair Active Learning using Uncertainty and Representativeness  on Fair Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fajri%2C+R">Ricky Fajri</a>, 
<a href="/search/cs?searchtype=author&query=Saxena%2C+A">Akrati Saxena</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+Y">Yulong Pei</a>, 
<a href="/search/cs?searchtype=author&query=Pechenizkiy%2C+M">Mykola Pechenizkiy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.01905" title="Abstract">arXiv:2210.01905</a> (replaced) [<a href="/pdf/2210.01905" title="Download PDF">pdf</a>, <a href="/format/2210.01905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polar Encoding: A Simple Baseline Approach for Classification with  Missing Values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lenz%2C+O+U">Oliver Urs Lenz</a>, 
<a href="/search/cs?searchtype=author&query=Peralta%2C+D">Daniel Peralta</a>, 
<a href="/search/cs?searchtype=author&query=Cornelis%2C+C">Chris Cornelis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.07780" title="Abstract">arXiv:2210.07780</a> (replaced) [<a href="/pdf/2210.07780" title="Download PDF">pdf</a>, <a href="/format/2210.07780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Best Arm Identification with Heterogeneous Clients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhirui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Karthik%2C+P+N">P. N. Karthik</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+V+Y+F">Vincent Y. F. Tan</a>, 
<a href="/search/cs?searchtype=author&query=Chee%2C+Y+M">Yeow Meng Chee</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Information Theory, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.11584" title="Abstract">arXiv:2210.11584</a> (replaced) [<a href="/pdf/2210.11584" title="Download PDF">pdf</a>, <a href="/format/2210.11584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Human-centered Explainable AI: A Survey of User Studies for  Model Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rong%2C+Y">Yao Rong</a>, 
<a href="/search/cs?searchtype=author&query=Leemann%2C+T">Tobias Leemann</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thai-trang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Fiedler%2C+L">Lisa Fiedler</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+P">Peizhu Qian</a>, 
<a href="/search/cs?searchtype=author&query=Unhelkar%2C+V">Vaibhav Unhelkar</a>, 
<a href="/search/cs?searchtype=author&query=Seidel%2C+T">Tina Seidel</a>, 
<a href="/search/cs?searchtype=author&query=Kasneci%2C+G">Gjergji Kasneci</a>, 
<a href="/search/cs?searchtype=author&query=Kasneci%2C+E">Enkelejda Kasneci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.15657" title="Abstract">arXiv:2210.15657</a> (replaced) [<a href="/e-print/2210.15657" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting fake accounts through Generative Adversarial Network in online  social media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bordbar%2C+J">Jinus Bordbar</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadrezaie%2C+M">Mohammadreza Mohammadrezaie</a>, 
<a href="/search/cs?searchtype=author&query=Ardalan%2C+S">Saman Ardalan</a>, 
<a href="/search/cs?searchtype=author&query=Shiri%2C+M+E">Mohammad Ebrahim Shiri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> need more investigation on the paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.16058" title="Abstract">arXiv:2210.16058</a> (replaced) [<a href="/pdf/2210.16058" title="Download PDF">pdf</a>, <a href="/format/2210.16058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Goal Exploration Augmentation via Pre-trained Skills for Sparse-Reward  Long-Horizon Goal-Conditioned Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lisheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Ke Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Machine Learning (Springer): 35 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.16222" title="Abstract">arXiv:2210.16222</a> (replaced) [<a href="/pdf/2210.16222" title="Download PDF">pdf</a>, <a href="/format/2210.16222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Lipschitz-Constrained Neural Networks by Learning Activation  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ducotterd%2C+S">Stanislas Ducotterd</a>, 
<a href="/search/cs?searchtype=author&query=Goujon%2C+A">Alexis Goujon</a>, 
<a href="/search/cs?searchtype=author&query=Bohra%2C+P">Pakshal Bohra</a>, 
<a href="/search/cs?searchtype=author&query=Perdios%2C+D">Dimitris Perdios</a>, 
<a href="/search/cs?searchtype=author&query=Neumayer%2C+S">Sebastian Neumayer</a>, 
<a href="/search/cs?searchtype=author&query=Unser%2C+M">Michael Unser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.16660" title="Abstract">arXiv:2210.16660</a> (replaced) [<a href="/pdf/2210.16660" title="Download PDF">pdf</a>, <a href="/format/2210.16660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alya towards Exascale: Algorithmic Scalability using PSCToolkit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Owen%2C+H">Herbert Owen</a>, 
<a href="/search/math?searchtype=author&query=Lehmkuhl%2C+O">Oriol Lehmkuhl</a>, 
<a href="/search/math?searchtype=author&query=D%27Ambra%2C+P">Pasqua D&#x27;Ambra</a>, 
<a href="/search/math?searchtype=author&query=Durastante%2C+F">Fabio Durastante</a>, 
<a href="/search/math?searchtype=author&query=Filippone%2C+S">Salvatore Filippone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.07945" title="Abstract">arXiv:2211.07945</a> (replaced) [<a href="/pdf/2211.07945" title="Download PDF">pdf</a>, <a href="/ps/2211.07945" title="Download PostScript">ps</a>, <a href="/format/2211.07945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometric Impedance Control on SE(3) for Robotic Manipulators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seo%2C+J">Joohwan Seo</a>, 
<a href="/search/cs?searchtype=author&query=Prakash%2C+N+P+S">Nikhil Potu Surya Prakash</a>, 
<a href="/search/cs?searchtype=author&query=Rose%2C+A">Alexander Rose</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jongeun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Horowitz%2C+R">Roberto Horowitz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at IFAC World Congress 2023, Yokohama, Japan
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08494" title="Abstract">arXiv:2211.08494</a> (replaced) [<a href="/pdf/2211.08494" title="Download PDF">pdf</a>, <a href="/format/2211.08494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Who Reviews The Reviewers? A Multi-Level Jury Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abramowitz%2C+B">Ben Abramowitz</a>, 
<a href="/search/cs?searchtype=author&query=Lev%2C+O">Omer Lev</a>, 
<a href="/search/cs?searchtype=author&query=Mattei%2C+N">Nicholas Mattei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Social and Information Networks (cs.SI); Theoretical Economics (econ.TH)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08511" title="Abstract">arXiv:2211.08511</a> (replaced) [<a href="/pdf/2211.08511" title="Download PDF">pdf</a>, <a href="/ps/2211.08511" title="Download PostScript">ps</a>, <a href="/format/2211.08511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Heuristic Subexponential Algorithm to Find Paths in Markoff Graphs  Over Finite Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Silverman%2C+J+H">Joseph H. Silverman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Number Theory (math.NT)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.09273" title="Abstract">arXiv:2211.09273</a> (replaced) [<a href="/pdf/2211.09273" title="Download PDF">pdf</a>, <a href="/format/2211.09273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy against Real-Time Speech Emotion Detection via Acoustic  Adversarial Evasion of Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Testa%2C+B">Brian Testa</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yi Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+H">Harshit Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Gump%2C+A">Avery Gump</a>, 
<a href="/search/cs?searchtype=author&query=Salekin%2C+A">Asif Salekin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.09340" title="Abstract">arXiv:2211.09340</a> (replaced) [<a href="/pdf/2211.09340" title="Download PDF">pdf</a>, <a href="/format/2211.09340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive user interfaces in systems targeting chronic disease: a  systematic literature review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Khalajzadeh%2C+H">Hourieh Khalajzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Madugalla%2C+A">Anuradha Madugalla</a>, 
<a href="/search/cs?searchtype=author&query=Mcintosh%2C+J">Jennifer Mcintosh</a>, 
<a href="/search/cs?searchtype=author&query=Obie%2C+H">Humphrey Obie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 62 pages, 10 figures, 8 tables, Accepted in User Modeling and User-Adapted Interaction
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.12393" title="Abstract">arXiv:2211.12393</a> (replaced) [<a href="/pdf/2211.12393" title="Download PDF">pdf</a>, <a href="/format/2211.12393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Weak PINNs for Hyperbolic Conservation Laws: Dual Norm  Computation, Boundary Conditions and Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chaumet%2C+A">Aidan Chaumet</a>, 
<a href="/search/math?searchtype=author&query=Giesselmann%2C+J">Jan Giesselmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> New version now contains extensions of weak PINNs to weak boundary conditions and applications for systems as well. The title was changed to better reflect the new content
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01071" title="Abstract">arXiv:2212.01071</a> (replaced) [<a href="/e-print/2212.01071" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fake detection in imbalance dataset by Semi-supervised learning with GAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bordbar%2C+J">Jinus Bordbar</a>, 
<a href="/search/cs?searchtype=author&query=Ardalan%2C+S">Saman Ardalan</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadrezaie%2C+M">Mohammadreza Mohammadrezaie</a>, 
<a href="/search/cs?searchtype=author&query=Ghasemi%2C+Z">Zahra Ghasemi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> need more investigation on results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07761" title="Abstract">arXiv:2212.07761</a> (replaced) [<a href="/pdf/2212.07761" title="Download PDF">pdf</a>, <a href="/format/2212.07761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Successive Interference Cancellation for Bandlimited Channels with  Direct Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prinz%2C+T">Tobias Prinz</a>, 
<a href="/search/cs?searchtype=author&query=Plabst%2C+D">Daniel Plabst</a>, 
<a href="/search/cs?searchtype=author&query=Wiegart%2C+T">Thomas Wiegart</a>, 
<a href="/search/cs?searchtype=author&query=Calabr%C3%B2%2C+S">Stefano Calabr&#xf2;</a>, 
<a href="/search/cs?searchtype=author&query=Hanik%2C+N">Norbert Hanik</a>, 
<a href="/search/cs?searchtype=author&query=Kramer%2C+G">Gerhard Kramer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Journal of Lightwave Technology on December 15, 2022; Resubmitted to IEEE Transactions on Communications on September 9, 2023; accepted November 17, 2023;
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.08645" title="Abstract">arXiv:2212.08645</a> (replaced) [<a href="/pdf/2212.08645" title="Download PDF">pdf</a>, <a href="/format/2212.08645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Conditionally Invariant Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pogodin%2C+R">Roman Pogodin</a>, 
<a href="/search/cs?searchtype=author&query=Deka%2C+N">Namrata Deka</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yazhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Sutherland%2C+D+J">Danica J. Sutherland</a>, 
<a href="/search/cs?searchtype=author&query=Veitch%2C+V">Victor Veitch</a>, 
<a href="/search/cs?searchtype=author&query=Gretton%2C+A">Arthur Gretton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The Eleventh International Conference on Learning Representations,
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09010" title="Abstract">arXiv:2212.09010</a> (replaced) [<a href="/pdf/2212.09010" title="Download PDF">pdf</a>, <a href="/format/2212.09010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Risk-Sensitive Reinforcement Learning with Exponential Criteria
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Noorani%2C+E">Erfaun Noorani</a>, 
<a href="/search/eess?searchtype=author&query=Mavridis%2C+C">Christos Mavridis</a>, 
<a href="/search/eess?searchtype=author&query=Baras%2C+J">John Baras</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09897" title="Abstract">arXiv:2212.09897</a> (replaced) [<a href="/pdf/2212.09897" title="Download PDF">pdf</a>, <a href="/format/2212.09897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inducing Character-level Structure in Subword-based Language Models with  Type-level Interchange Intervention Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhengxuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Mahowald%2C+K">Kyle Mahowald</a>, 
<a href="/search/cs?searchtype=author&query=Potts%2C+C">Christopher Potts</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of the Association for Computational Linguistics: ACL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.12538" title="Abstract">arXiv:2212.12538</a> (replaced) [<a href="/pdf/2212.12538" title="Download PDF">pdf</a>, <a href="/format/2212.12538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mathematical Foundations for a Compositional Account of the Bayesian  Brain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Smithe%2C+T+S+C">Toby St Clere Smithe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> DPhil thesis, as accepted by the University of Oxford. Comments most welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI); Category Theory (math.CT); Dynamical Systems (math.DS); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.14197" title="Abstract">arXiv:2212.14197</a> (replaced) [<a href="/pdf/2212.14197" title="Download PDF">pdf</a>, <a href="/format/2212.14197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PointVST: Self-Supervised Pre-training for 3D Point Clouds via  View-Specific Point-to-Image Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qijian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Junhui Hou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IEEE TVCG
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.04312" title="Abstract">arXiv:2301.04312</a> (replaced) [<a href="/pdf/2301.04312" title="Download PDF">pdf</a>, <a href="/format/2301.04312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Word-Graph2vec: An efficient word embedding approach on word  co-occurrence graph using random walk sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenting Li</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+J">Jiahong Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huacan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zeyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yuanzhe Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.08336" title="Abstract">arXiv:2301.08336</a> (replaced) [<a href="/pdf/2301.08336" title="Download PDF">pdf</a>, <a href="/format/2301.08336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PyOED: An Extensible Suite for Data Assimilation and Model-Constrained  Optimal Design of Experiments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chowdhary%2C+A">Abhijit Chowdhary</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S+E">Shady E. Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Attia%2C+A">Ahmed Attia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Software (cs.MS)</span>

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.08830" title="Abstract">arXiv:2301.08830</a> (replaced) [<a href="/pdf/2301.08830" title="Download PDF">pdf</a>, <a href="/ps/2301.08830" title="Download PostScript">ps</a>, <a href="/format/2301.08830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Nash equilibria by minimizing approximate exploitability with  learned best responses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martin%2C+C">Carlos Martin</a>, 
<a href="/search/cs?searchtype=author&query=Sandholm%2C+T">Tuomas Sandholm</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/1611.01673">arXiv:1611.01673</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11145" title="Abstract">arXiv:2301.11145</a> (replaced) [<a href="/pdf/2301.11145" title="Download PDF">pdf</a>, <a href="/format/2301.11145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning from Mistakes: Self-Regularizing Hierarchical Representations  in Point Cloud Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Camuffo%2C+E">Elena Camuffo</a>, 
<a href="/search/cs?searchtype=author&query=Michieli%2C+U">Umberto Michieli</a>, 
<a href="/search/cs?searchtype=author&query=Milani%2C+S">Simone Milani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13770" title="Abstract">arXiv:2301.13770</a> (replaced) [<a href="/pdf/2301.13770" title="Download PDF">pdf</a>, <a href="/format/2301.13770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-Conserving Neural Network for Turbulence Closure Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=van+Gastelen%2C+T">Toby van Gastelen</a>, 
<a href="/search/math?searchtype=author&query=Edeling%2C+W">Wouter Edeling</a>, 
<a href="/search/math?searchtype=author&query=Sanderse%2C+B">Benjamin Sanderse</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 15 figures, source code can be found at <a href="https://github.com/tobyvg/ECNCM_1D">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01190" title="Abstract">arXiv:2302.01190</a> (replaced) [<a href="/pdf/2302.01190" title="Download PDF">pdf</a>, <a href="/format/2302.01190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Efficacy of Differentially Private Few-shot Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Tobaben%2C+M">Marlon Tobaben</a>, 
<a href="/search/stat?searchtype=author&query=Shysheya%2C+A">Aliaksandra Shysheya</a>, 
<a href="/search/stat?searchtype=author&query=Bronskill%2C+J">John Bronskill</a>, 
<a href="/search/stat?searchtype=author&query=Paverd%2C+A">Andrew Paverd</a>, 
<a href="/search/stat?searchtype=author&query=Tople%2C+S">Shruti Tople</a>, 
<a href="/search/stat?searchtype=author&query=Zanella-Beguelin%2C+S">Santiago Zanella-Beguelin</a>, 
<a href="/search/stat?searchtype=author&query=Turner%2C+R+E">Richard E Turner</a>, 
<a href="/search/stat?searchtype=author&query=Honkela%2C+A">Antti Honkela</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 49 pages, 24 figures; published in TMLR 12/2023 <a href="https://openreview.net/forum?id=hFsr59Imzm">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transactions on Machine Learning Research, ISSN 2835-8856, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01242" title="Abstract">arXiv:2302.01242</a> (replaced) [<a href="/pdf/2302.01242" title="Download PDF">pdf</a>, <a href="/format/2302.01242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuro-Symbolic Continual Learning: Knowledge, Reasoning Shortcuts and  Concept Rehearsal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marconato%2C+E">Emanuele Marconato</a>, 
<a href="/search/cs?searchtype=author&query=Bontempo%2C+G">Gianpaolo Bontempo</a>, 
<a href="/search/cs?searchtype=author&query=Ficarra%2C+E">Elisa Ficarra</a>, 
<a href="/search/cs?searchtype=author&query=Calderara%2C+S">Simone Calderara</a>, 
<a href="/search/cs?searchtype=author&query=Passerini%2C+A">Andrea Passerini</a>, 
<a href="/search/cs?searchtype=author&query=Teso%2C+S">Stefano Teso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40th International Conference on Machine Learning (ICML 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02870" title="Abstract">arXiv:2302.02870</a> (replaced) [<a href="/pdf/2302.02870" title="Download PDF">pdf</a>, <a href="/ps/2302.02870" title="Download PostScript">ps</a>, <a href="/format/2302.02870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noisy decoding by shallow circuits with parities: classical and quantum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bri%C3%ABt%2C+J">Jop Bri&#xeb;t</a>, 
<a href="/search/cs?searchtype=author&query=Buhrman%2C+H">Harry Buhrman</a>, 
<a href="/search/cs?searchtype=author&query=Castro-Silva%2C+D">Davi Castro-Silva</a>, 
<a href="/search/cs?searchtype=author&query=Neumann%2C+N+M+P">Niels M. P. Neumann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages; This is the full version of an extended abstract that will appear in the proceedings of ITCS'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Combinatorics (math.CO); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04977" title="Abstract">arXiv:2302.04977</a> (replaced) [<a href="/pdf/2302.04977" title="Download PDF">pdf</a>, <a href="/format/2302.04977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mithridates: Auditing and Boosting Backdoor Resistance of Machine  Learning Pipelines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bagdasaryan%2C+E">Eugene Bagdasaryan</a>, 
<a href="/search/cs?searchtype=author&query=Shmatikov%2C+V">Vitaly Shmatikov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05428" title="Abstract">arXiv:2302.05428</a> (replaced) [<a href="/pdf/2302.05428" title="Download PDF">pdf</a>, <a href="/format/2302.05428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STERLING: Synergistic Representation Learning on Bipartite Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jing%2C+B">Baoyu Jing</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yuchen Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+K">Kaize Ding</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+C">Chanyoung Park</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yada Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+H">Hanghang Tong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI'2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09532" title="Abstract">arXiv:2302.09532</a> (replaced) [<a href="/pdf/2302.09532" title="Download PDF">pdf</a>, <a href="/format/2302.09532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pseudo Contrastive Learning for Graph-based Semi-supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Weigang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Z">Ziyu Guan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yaming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Y">Yuanhai Lv</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+L">Lining Xing</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Baosheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12633" title="Abstract">arXiv:2302.12633</a> (replaced) [<a href="/pdf/2302.12633" title="Download PDF">pdf</a>, <a href="/ps/2302.12633" title="Download PostScript">ps</a>, <a href="/format/2302.12633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neighborhood complexity of planar graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Joret%2C+G">Gwena&#xeb;l Joret</a>, 
<a href="/search/math?searchtype=author&query=Rambaud%2C+C">Cl&#xe9;ment Rambaud</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v2: simpler proof for K_t-minor-free graphs; paper revised following the referees' comments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14696" title="Abstract">arXiv:2302.14696</a> (replaced) [<a href="/pdf/2302.14696" title="Download PDF">pdf</a>, <a href="/format/2302.14696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dissolving Is Amplifying: Towards Fine-Grained Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pengyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ni Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ghazzai%2C+H">Hakim Ghazzai</a>, 
<a href="/search/cs?searchtype=author&query=Wonka%2C+P">Peter Wonka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03906" title="Abstract">arXiv:2303.03906</a> (replaced) [<a href="/pdf/2303.03906" title="Download PDF">pdf</a>, <a href="/format/2303.03906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Confluence Criteria
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shintani%2C+K">Kiraku Shintani</a>, 
<a href="/search/cs?searchtype=author&query=Hirokawa%2C+N">Nao Hirokawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 3 figures, 1 table, submitted to LMCS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06999" title="Abstract">arXiv:2303.06999</a> (replaced) [<a href="/pdf/2303.06999" title="Download PDF">pdf</a>, <a href="/format/2303.06999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying Label Errors in Object Detection Datasets by Loss Inspection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schubert%2C+M">Marius Schubert</a>, 
<a href="/search/cs?searchtype=author&query=Riedlinger%2C+T">Tobias Riedlinger</a>, 
<a href="/search/cs?searchtype=author&query=Kahl%2C+K">Karsten Kahl</a>, 
<a href="/search/cs?searchtype=author&query=Kr%C3%B6ll%2C+D">Daniel Kr&#xf6;ll</a>, 
<a href="/search/cs?searchtype=author&query=Schoenen%2C+S">Sebastian Schoenen</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0egvi%C4%87%2C+S">Sini&#x161;a &#x160;egvi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Rottmann%2C+M">Matthias Rottmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08774" title="Abstract">arXiv:2303.08774</a> (replaced) [<a href="/pdf/2303.08774" title="Download PDF">pdf</a>, <a href="/format/2303.08774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT-4 Technical Report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=OpenAI">OpenAI</a>: 
<a href="/search/cs?searchtype=author&query=Achiam%2C+J">Josh Achiam</a>, 
<a href="/search/cs?searchtype=author&query=Adler%2C+S">Steven Adler</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+S">Sandhini Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+L">Lama Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Akkaya%2C+I">Ilge Akkaya</a>, 
<a href="/search/cs?searchtype=author&query=Aleman%2C+F+L">Florencia Leoni Aleman</a>, 
<a href="/search/cs?searchtype=author&query=Almeida%2C+D">Diogo Almeida</a>, 
<a href="/search/cs?searchtype=author&query=Altenschmidt%2C+J">Janko Altenschmidt</a>, 
<a href="/search/cs?searchtype=author&query=Altman%2C+S">Sam Altman</a>, 
<a href="/search/cs?searchtype=author&query=Anadkat%2C+S">Shyamal Anadkat</a>, 
<a href="/search/cs?searchtype=author&query=Avila%2C+R">Red Avila</a>, 
<a href="/search/cs?searchtype=author&query=Babuschkin%2C+I">Igor Babuschkin</a>, 
<a href="/search/cs?searchtype=author&query=Balaji%2C+S">Suchir Balaji</a>, 
<a href="/search/cs?searchtype=author&query=Balcom%2C+V">Valerie Balcom</a>, 
<a href="/search/cs?searchtype=author&query=Baltescu%2C+P">Paul Baltescu</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+H">Haiming Bao</a>, 
<a href="/search/cs?searchtype=author&query=Bavarian%2C+M">Mo Bavarian</a>, 
<a href="/search/cs?searchtype=author&query=Belgum%2C+J">Jeff Belgum</a>, 
<a href="/search/cs?searchtype=author&query=Bello%2C+I">Irwan Bello</a>, 
<a href="/search/cs?searchtype=author&query=Berdine%2C+J">Jake Berdine</a>, 
<a href="/search/cs?searchtype=author&query=Bernadett-Shapiro%2C+G">Gabriel Bernadett-Shapiro</a>, 
<a href="/search/cs?searchtype=author&query=Berner%2C+C">Christopher Berner</a>, 
<a href="/search/cs?searchtype=author&query=Bogdonoff%2C+L">Lenny Bogdonoff</a>, 
<a href="/search/cs?searchtype=author&query=Boiko%2C+O">Oleg Boiko</a>, 
<a href="/search/cs?searchtype=author&query=Boyd%2C+M">Madelaine Boyd</a>, 
<a href="/search/cs?searchtype=author&query=Brakman%2C+A">Anna-Luisa Brakman</a>, 
<a href="/search/cs?searchtype=author&query=Brockman%2C+G">Greg Brockman</a>, 
<a href="/search/cs?searchtype=author&query=Brooks%2C+T">Tim Brooks</a>, 
<a href="/search/cs?searchtype=author&query=Brundage%2C+M">Miles Brundage</a>, 
<a href="/search/cs?searchtype=author&query=Button%2C+K">Kevin Button</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+T">Trevor Cai</a>, 
<a href="/search/cs?searchtype=author&query=Campbell%2C+R">Rosie Campbell</a>, 
<a href="/search/cs?searchtype=author&query=Cann%2C+A">Andrew Cann</a>, 
<a href="/search/cs?searchtype=author&query=Carey%2C+B">Brittany Carey</a>, 
<a href="/search/cs?searchtype=author&query=Carlson%2C+C">Chelsea Carlson</a>, 
<a href="/search/cs?searchtype=author&query=Carmichael%2C+R">Rory Carmichael</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+B">Brooke Chan</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Che Chang</a>, 
<a href="/search/cs?searchtype=author&query=Chantzis%2C+F">Fotis Chantzis</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Derek Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sully Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruby Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jason Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mark Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chess%2C+B">Ben Chess</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+C">Chester Cho</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+C">Casey Chu</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+H+W">Hyung Won Chung</a>, 
<a href="/search/cs?searchtype=author&query=Cummings%2C+D">Dave Cummings</a>, 
<a href="/search/cs?searchtype=author&query=Currier%2C+J">Jeremiah Currier</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yunxing Dai</a>, 
<a href="/search/cs?searchtype=author&query=Decareaux%2C+C">Cory Decareaux</a>, 
<a href="/search/cs?searchtype=author&query=Degry%2C+T">Thomas Degry</a>, 
<a href="/search/cs?searchtype=author&query=Deutsch%2C+N">Noah Deutsch</a>,  et al. (226 additional authors not shown)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 100 pages; updated authors list
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08906" title="Abstract">arXiv:2303.08906</a> (replaced) [<a href="/pdf/2303.08906" title="Download PDF">pdf</a>, <a href="/format/2303.08906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VVS: Video-to-Video Retrieval with Irrelevant Frame Suppression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jo%2C+W">Won Jo</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+G">Geuntaek Lim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+G">Gwangjin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyunwoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+B">Byungsoo Ko</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yukyung Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09734" title="Abstract">arXiv:2303.09734</a> (replaced) [<a href="/pdf/2303.09734" title="Download PDF">pdf</a>, <a href="/format/2303.09734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Moderating Effect of Instant Runoff Voting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tomlinson%2C+K">Kiran Tomlinson</a>, 
<a href="/search/cs?searchtype=author&query=Ugander%2C+J">Johan Ugander</a>, 
<a href="/search/cs?searchtype=author&query=Kleinberg%2C+J">Jon Kleinberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages; extended version of AAAI '24 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Computer Science and Game Theory (cs.GT); Theoretical Economics (econ.TH)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10343" title="Abstract">arXiv:2303.10343</a> (replaced) [<a href="/pdf/2303.10343" title="Download PDF">pdf</a>, <a href="/format/2303.10343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supervision Interpolation via LossMix: Generalizing Mixup for Object  Detection and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vu%2C+T">Thanh Vu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Baochen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+B">Bodi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ngai%2C+A">Alex Ngai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yueqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Frahm%2C+J">Jan-Michael Frahm</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI-24 Camera Ready Version, with supplementary material, 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11681" title="Abstract">arXiv:2303.11681</a> (replaced) [<a href="/pdf/2303.11681" title="Download PDF">pdf</a>, <a href="/format/2303.11681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffuMask: Synthesizing Images with Pixel-level Annotations for Semantic  Segmentation Using Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Weijia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuzhong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chunhua Shen</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.14027" title="Abstract">arXiv:2303.14027</a> (replaced) [<a href="/pdf/2303.14027" title="Download PDF">pdf</a>, <a href="/format/2303.14027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Poincar&#xe9; ResNet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Spengler%2C+M">Max van Spengler</a>, 
<a href="/search/cs?searchtype=author&query=Berkhout%2C+E">Erwin Berkhout</a>, 
<a href="/search/cs?searchtype=author&query=Mettes%2C+P">Pascal Mettes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Computer Vision 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.14628" title="Abstract">arXiv:2303.14628</a> (replaced) [<a href="/pdf/2303.14628" title="Download PDF">pdf</a>, <a href="/format/2303.14628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Frame Self-Supervised Depth Estimation with Multi-Scale Feature  Fusion in Dynamic Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+J">Jiquan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaolin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiao Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures, ACM MM'23 accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16454" title="Abstract">arXiv:2303.16454</a> (replaced) [<a href="/pdf/2303.16454" title="Download PDF">pdf</a>, <a href="/format/2303.16454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conductivity Imaging from Internal Measurements with Mixed Least-Squares  Deep Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jin%2C+B">Bangti Jin</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+X">Xiyao Li</a>, 
<a href="/search/math?searchtype=author&query=Quan%2C+Q">Qimeng Quan</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+Z">Zhi Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> corrected a few typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16532" title="Abstract">arXiv:2303.16532</a> (replaced) [<a href="/pdf/2303.16532" title="Download PDF">pdf</a>, <a href="/format/2303.16532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Futures Quantitative Investment with Heterogeneous Continual Graph  Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+M">Min Hu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhizhong Tan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+G">Guosheng Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistical Finance (q-fin.ST); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16737" title="Abstract">arXiv:2303.16737</a> (replaced) [<a href="/pdf/2303.16737" title="Download PDF">pdf</a>, <a href="/format/2303.16737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Reinforcement Learning with Action Masking for UAV-enabled  Mobile Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rizvi%2C+D">Danish Rizvi</a>, 
<a href="/search/cs?searchtype=author&query=Boyle%2C+D">David Boyle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17338" title="Abstract">arXiv:2303.17338</a> (replaced) [<a href="/pdf/2303.17338" title="Download PDF">pdf</a>, <a href="/format/2303.17338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local region-learning modules for point cloud classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Turgut%2C+K">Kaya Turgut</a>, 
<a href="/search/cs?searchtype=author&query=Dutagaci%2C+H">Helin Dutagaci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00355" title="Abstract">arXiv:2304.00355</a> (replaced) [<a href="/pdf/2304.00355" title="Download PDF">pdf</a>, <a href="/format/2304.00355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-Centric Resource Allocation in the Metaverse over Wireless  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+L">Liangxin Qian</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenhan Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in IEEE Journal on Selected Areas in Communications (JSAC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00644" title="Abstract">arXiv:2304.00644</a> (replaced) [<a href="/pdf/2304.00644" title="Download PDF">pdf</a>, <a href="/format/2304.00644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributionally Robust Optimal and Safe Control of Stochastic Systems  via Kernel Conditional Mean Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Romao%2C+L">Licio Romao</a>, 
<a href="/search/eess?searchtype=author&query=Hota%2C+A+R">Ashish R. Hota</a>, 
<a href="/search/eess?searchtype=author&query=Abate%2C+A">Alessandro Abate</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05805" title="Abstract">arXiv:2304.05805</a> (replaced) [<a href="/pdf/2304.05805" title="Download PDF">pdf</a>, <a href="/format/2304.05805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GDP nowcasting with artificial neural networks: How much does long-term  memory matter?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=N%C3%A9meth%2C+K">Krist&#xf3;f N&#xe9;meth</a>, 
<a href="/search/econ?searchtype=author&query=Hadh%C3%A1zi%2C+D">D&#xe1;niel Hadh&#xe1;zi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2106.08901">arXiv:2106.08901</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics (econ.EM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14082" title="Abstract">arXiv:2304.14082</a> (replaced) [<a href="/pdf/2304.14082" title="Download PDF">pdf</a>, <a href="/format/2304.14082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JaxPruner: A concise library for sparsity research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+H">Joo Hyung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+W">Wonpyo Park</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+N">Nicole Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Pilault%2C+J">Jonathan Pilault</a>, 
<a href="/search/cs?searchtype=author&query=Obando-Ceron%2C+J">Johan Obando-Ceron</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Han-Byul Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+N">Namhoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Frantar%2C+E">Elias Frantar</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+Y">Yun Long</a>, 
<a href="/search/cs?searchtype=author&query=Yazdanbakhsh%2C+A">Amir Yazdanbakhsh</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+S">Shivani Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Subramanian%2C+S">Suvinay Subramanian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kao%2C+S">Sheng-Chun Kao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gale%2C+T">Trevor Gale</a>, 
<a href="/search/cs?searchtype=author&query=Bik%2C+A">Aart Bik</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+W">Woohyun Han</a>, 
<a href="/search/cs?searchtype=author&query=Ferev%2C+M">Milen Ferev</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhonglin Han</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hong-Seok Kim</a>, 
<a href="/search/cs?searchtype=author&query=Dauphin%2C+Y">Yann Dauphin</a>, 
<a href="/search/cs?searchtype=author&query=Dziugaite%2C+G+K">Gintare Karolina Dziugaite</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+P+S">Pablo Samuel Castro</a>, 
<a href="/search/cs?searchtype=author&query=Evci%2C+U">Utku Evci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Jaxpruner is hosted at <a href="http://github.com/google-research/jaxpruner">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02240" title="Abstract">arXiv:2305.02240</a> (replaced) [<a href="/pdf/2305.02240" title="Download PDF">pdf</a>, <a href="/format/2305.02240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A $4/3$ Approximation for $2$-Vertex-Connectivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bosch-Calvo%2C+M">Miguel Bosch-Calvo</a>, 
<a href="/search/cs?searchtype=author&query=Grandoni%2C+F">Fabrizio Grandoni</a>, 
<a href="/search/cs?searchtype=author&query=Ameli%2C+A+J">Afrouz Jabal Ameli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 20 figures, ICALP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04550" title="Abstract">arXiv:2305.04550</a> (replaced) [<a href="/pdf/2305.04550" title="Download PDF">pdf</a>, <a href="/ps/2305.04550" title="Download PostScript">ps</a>, <a href="/format/2305.04550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing Reconfiguration Time in Hybrid Optical-Electrical Datacenter  Networks (Extended Abstract)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+S">Shu Shan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shizhen Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06252" title="Abstract">arXiv:2305.06252</a> (replaced) [<a href="/pdf/2305.06252" title="Download PDF">pdf</a>, <a href="/format/2305.06252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embedded Feature Similarity Optimization with Specific Parameter  Initialization for 2D/3D Medical Image Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Minheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhirun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+S">Shuheng Gu</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Y">Youyong Kong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures, accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07490" title="Abstract">arXiv:2305.07490</a> (replaced) [<a href="/pdf/2305.07490" title="Download PDF">pdf</a>, <a href="/format/2305.07490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ArtGPT-4: Towards Artistic-understanding Large Vision-Language Models  with Enhanced Adapter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhengqing Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yanfang Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09820" title="Abstract">arXiv:2305.09820</a> (replaced) [<a href="/pdf/2305.09820" title="Download PDF">pdf</a>, <a href="/format/2305.09820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine-Made Media: Monitoring the Mobilization of Machine-Generated  Articles on Misinformation and Mainstream News Websites
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hanley%2C+H+W+A">Hans W. A. Hanley</a>, 
<a href="/search/cs?searchtype=author&query=Durumeric%2C+Z">Zakir Durumeric</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICWSM 2024. Updated threshold; additional month of data
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10701" title="Abstract">arXiv:2305.10701</a> (replaced) [<a href="/pdf/2305.10701" title="Download PDF">pdf</a>, <a href="/format/2305.10701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalization as a Shortcut for Few-Shot Backdoor Attack against  Text-to-Image Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yihao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Juefei-Xu%2C+F">Felix Juefei-Xu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yutong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+M">Ming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianlin Li</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+G">Geguang Pu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11014" title="Abstract">arXiv:2305.11014</a> (replaced) [<a href="/pdf/2305.11014" title="Download PDF">pdf</a>, <a href="/format/2305.11014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Planning in PDDL Domains with Pretrained Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Silver%2C+T">Tom Silver</a>, 
<a href="/search/cs?searchtype=author&query=Dan%2C+S">Soham Dan</a>, 
<a href="/search/cs?searchtype=author&query=Srinivas%2C+K">Kavitha Srinivas</a>, 
<a href="/search/cs?searchtype=author&query=Tenenbaum%2C+J+B">Joshua B. Tenenbaum</a>, 
<a href="/search/cs?searchtype=author&query=Kaelbling%2C+L+P">Leslie Pack Kaelbling</a>, 
<a href="/search/cs?searchtype=author&query=Katz%2C+M">Michael Katz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12015" title="Abstract">arXiv:2305.12015</a> (replaced) [<a href="/pdf/2305.12015" title="Download PDF">pdf</a>, <a href="/format/2305.12015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inventing art styles with no artistic training data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abrahamsen%2C+N">Nilin Abrahamsen</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiahao Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> updated title
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12097" title="Abstract">arXiv:2305.12097</a> (replaced) [<a href="/pdf/2305.12097" title="Download PDF">pdf</a>, <a href="/ps/2305.12097" title="Download PostScript">ps</a>, <a href="/format/2305.12097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Testing and Learning Quantum Junta Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Bao%2C+Z">Zongbo Bao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yao%2C+P">Penghui Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13030" title="Abstract">arXiv:2305.13030</a> (replaced) [<a href="/pdf/2305.13030" title="Download PDF">pdf</a>, <a href="/format/2305.13030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive action supervision in reinforcement learning from real-world  multi-agent demonstrations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fujii%2C+K">Keisuke Fujii</a>, 
<a href="/search/cs?searchtype=author&query=Tsutsui%2C+K">Kazushi Tsutsui</a>, 
<a href="/search/cs?searchtype=author&query=Scott%2C+A">Atom Scott</a>, 
<a href="/search/cs?searchtype=author&query=Nakahara%2C+H">Hiroshi Nakahara</a>, 
<a href="/search/cs?searchtype=author&query=Takeishi%2C+N">Naoya Takeishi</a>, 
<a href="/search/cs?searchtype=author&query=Kawahara%2C+Y">Yoshinobu Kawahara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures, accepted in ICAART 2024 Oral
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13619" title="Abstract">arXiv:2305.13619</a> (replaced) [<a href="/pdf/2305.13619" title="Download PDF">pdf</a>, <a href="/ps/2305.13619" title="Download PostScript">ps</a>, <a href="/format/2305.13619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory Asymmetry Creates Heteroclinic Orbits to Nash Equilibrium in  Learning in Zero-Sum Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fujimoto%2C+Y">Yuma Fujimoto</a>, 
<a href="/search/cs?searchtype=author&query=Ariu%2C+K">Kaito Ariu</a>, 
<a href="/search/cs?searchtype=author&query=Abe%2C+K">Kenshi Abe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages &amp; 5 figures (main), 5 pages &amp; 2 figures (appendix)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA); Optimization and Control (math.OC); Chaotic Dynamics (nlin.CD)

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14160" title="Abstract">arXiv:2305.14160</a> (replaced) [<a href="/pdf/2305.14160" title="Download PDF">pdf</a>, <a href="/format/2305.14160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Label Words are Anchors: An Information Flow Perspective for  Understanding In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lean Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+D">Damai Dai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Deli Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fandong Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xu Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14901" title="Abstract">arXiv:2305.14901</a> (replaced) [<a href="/pdf/2305.14901" title="Download PDF">pdf</a>, <a href="/format/2305.14901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chain-of-Questions Training with Latent Answers for Robust Multistep  Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Thomason%2C+J">Jesse Thomason</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+R">Robin Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14978" title="Abstract">arXiv:2305.14978</a> (replaced) [<a href="/pdf/2305.14978" title="Download PDF">pdf</a>, <a href="/format/2305.14978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Exponential Integrators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bosch%2C+N">Nathanael Bosch</a>, 
<a href="/search/math?searchtype=author&query=Hennig%2C+P">Philipp Hennig</a>, 
<a href="/search/math?searchtype=author&query=Tronarp%2C+F">Filip Tronarp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16901" title="Abstract">arXiv:2305.16901</a> (replaced) [<a href="/pdf/2305.16901" title="Download PDF">pdf</a>, <a href="/format/2305.16901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizing Adam to Manifolds for Efficiently Training Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brantner%2C+B">Benedikt Brantner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 4 figures, was presented at Enumath2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Differential Geometry (math.DG)

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17205" title="Abstract">arXiv:2305.17205</a> (replaced) [<a href="/pdf/2305.17205" title="Download PDF">pdf</a>, <a href="/format/2305.17205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ghost Noise for Regularizing Deep Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kosson%2C+A">Atli Kosson</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+D">Dongyang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Jaggi%2C+M">Martin Jaggi</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18072" title="Abstract">arXiv:2305.18072</a> (replaced) [<a href="/pdf/2305.18072" title="Download PDF">pdf</a>, <a href="/format/2305.18072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Captioning with Multi-Context Synthetic Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+F">Feipeng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yizhou Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+F">Fengyun Rao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yueyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaoyan Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01843" title="Abstract">arXiv:2306.01843</a> (replaced) [<a href="/pdf/2306.01843" title="Download PDF">pdf</a>, <a href="/format/2306.01843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lifting Architectural Constraints of Injective Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sorrenson%2C+P">Peter Sorrenson</a>, 
<a href="/search/cs?searchtype=author&query=Draxler%2C+F">Felix Draxler</a>, 
<a href="/search/cs?searchtype=author&query=Rousselot%2C+A">Armand Rousselot</a>, 
<a href="/search/cs?searchtype=author&query=Hummerich%2C+S">Sander Hummerich</a>, 
<a href="/search/cs?searchtype=author&query=Zimmermann%2C+L">Lea Zimmermann</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6the%2C+U">Ullrich K&#xf6;the</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Resubmission of previous work: title and abstract have been changed and new content has been added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04744" title="Abstract">arXiv:2306.04744</a> (replaced) [<a href="/pdf/2306.04744" title="Download PDF">pdf</a>, <a href="/format/2306.04744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WOUAF: Weight Modulation for User Attribution and Fingerprinting in  Text-to-Image Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Changhoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+K">Kyle Min</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+M">Maitreya Patel</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Sheng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yezhou Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06154" title="Abstract">arXiv:2306.06154</a> (replaced) [<a href="/pdf/2306.06154" title="Download PDF">pdf</a>, <a href="/format/2306.06154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HypLL: The Hyperbolic Learning Library
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Spengler%2C+M">Max van Spengler</a>, 
<a href="/search/cs?searchtype=author&query=Wirth%2C+P">Philipp Wirth</a>, 
<a href="/search/cs?searchtype=author&query=Mettes%2C+P">Pascal Mettes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM Multimedia Open-Source Software Competition 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07008" title="Abstract">arXiv:2306.07008</a> (replaced) [<a href="/pdf/2306.07008" title="Download PDF">pdf</a>, <a href="/format/2306.07008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Phase Estimation by Compressed Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Yi%2C+C">Changhao Yi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhou%2C+C">Cunlu Zhou</a>, 
<a href="/search/quant-ph?searchtype=author&query=Takahashi%2C+J">Jun Takahashi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07915" title="Abstract">arXiv:2306.07915</a> (replaced) [<a href="/pdf/2306.07915" title="Download PDF">pdf</a>, <a href="/format/2306.07915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Captioners Are Scalable Vision Learners Too
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tschannen%2C+M">Michael Tschannen</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+M">Manoj Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Steiner%2C+A">Andreas Steiner</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaohua Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Houlsby%2C+N">Neil Houlsby</a>, 
<a href="/search/cs?searchtype=author&query=Beyer%2C+L">Lucas Beyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023. v2 adds SugarCrepe results and more ablations, v3 has minor fixes. v4 adds a code link ( <a href="https://github.com/google-research/big_vision">this https URL</a> )
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08456" title="Abstract">arXiv:2306.08456</a> (replaced) [<a href="/pdf/2306.08456" title="Download PDF">pdf</a>, <a href="/format/2306.08456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PoetryDiffusion: Towards Joint Semantic and Metrical Manipulation in  Poetry Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhiyuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chumin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yue Feng</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+A+T">Anh Tuan Luu</a>, 
<a href="/search/cs?searchtype=author&query=Hooi%2C+B">Bryan Hooi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12681" title="Abstract">arXiv:2306.12681</a> (replaced) [<a href="/pdf/2306.12681" title="Download PDF">pdf</a>, <a href="/format/2306.12681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One at a Time: Progressive Multi-step Volumetric Probability Learning  for Reliable 3D Scene Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bohan Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yasheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jingxin Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Wenjun Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14048" title="Abstract">arXiv:2306.14048</a> (replaced) [<a href="/pdf/2306.14048" title="Download PDF">pdf</a>, <a href="/format/2306.14048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> H$_2$O: Heavy-Hitter Oracle for Efficient Generative Inference of Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+Y">Ying Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianlong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Lianmin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+R">Ruisi Cai</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhao Song</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuandong Tian</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%A9%2C+C">Christopher R&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Barrett%2C+C">Clark Barrett</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Beidi Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17808" title="Abstract">arXiv:2306.17808</a> (replaced) [<a href="/pdf/2306.17808" title="Download PDF">pdf</a>, <a href="/format/2306.17808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Circular Systems Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=David%2C+I">Istvan David</a>, 
<a href="/search/cs?searchtype=author&query=Bork%2C+D">Dominik Bork</a>, 
<a href="/search/cs?searchtype=author&query=Kappel%2C+G">Gerti Kappel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Software Engineering (cs.SE); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03452" title="Abstract">arXiv:2307.03452</a> (replaced) [<a href="/pdf/2307.03452" title="Download PDF">pdf</a>, <a href="/ps/2307.03452" title="Download PostScript">ps</a>, <a href="/format/2307.03452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-performance evaluation of high angular momentum 4-center Gaussian  integrals on modern accelerated processors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Asadchev%2C+A">Andrey Asadchev</a>, 
<a href="/search/physics?searchtype=author&query=Valeev%2C+E+F">Edward F. Valeev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Computational Engineering, Finance, and Science (cs.CE); Chemical Physics (physics.chem-ph)

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05152" title="Abstract">arXiv:2307.05152</a> (replaced) [<a href="/pdf/2307.05152" title="Download PDF">pdf</a>, <a href="/format/2307.05152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Neural Network Inference on FPGAs for Triggering on Long-Lived  Particles at Colliders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ex?searchtype=author&query=Coccaro%2C+A">Andrea Coccaro</a>, 
<a href="/search/hep-ex?searchtype=author&query=Di+Bello%2C+F+A">Francesco Armando Di Bello</a>, 
<a href="/search/hep-ex?searchtype=author&query=Giagu%2C+S">Stefano Giagu</a>, 
<a href="/search/hep-ex?searchtype=author&query=Rambelli%2C+L">Lucrezia Rambelli</a>, 
<a href="/search/hep-ex?searchtype=author&query=Stocchetti%2C+N">Nicola Stocchetti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures, 2 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Mach.Learn.Sci.Tech. 4 (2023) 4, 045040
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Experiment (hep-ex)</span>; Machine Learning (cs.LG); Instrumentation and Detectors (physics.ins-det)

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05608" title="Abstract">arXiv:2307.05608</a> (replaced) [<a href="/pdf/2307.05608" title="Download PDF">pdf</a>, <a href="/format/2307.05608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DP-Auditorium: a Large Scale Library for Auditing Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+W">William Kong</a>, 
<a href="/search/cs?searchtype=author&query=Medina%2C+A+M">Andr&#xe9;s Mu&#xf1;oz Medina</a>, 
<a href="/search/cs?searchtype=author&query=Ribero%2C+M">M&#xf3;nica Ribero</a>, 
<a href="/search/cs?searchtype=author&query=Syed%2C+U">Umar Syed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06399" title="Abstract">arXiv:2307.06399</a> (replaced) [<a href="/pdf/2307.06399" title="Download PDF">pdf</a>, <a href="/format/2307.06399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing Behavior Trees from Goal-Oriented LTLf Formulas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neupane%2C+A">Aadesh Neupane</a>, 
<a href="/search/cs?searchtype=author&query=Mercer%2C+E+G">Eric G Mercer</a>, 
<a href="/search/cs?searchtype=author&query=Goodrich%2C+M+A">Michael A. Goodrich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as "Most Visionary Paper" in Autonomous Robots and Multirobot Systems (ARMS) 2023 workshop affiliated with the 22nd International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07924" title="Abstract">arXiv:2307.07924</a> (replaced) [<a href="/pdf/2307.07924" title="Download PDF">pdf</a>, <a href="/format/2307.07924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communicative Agents for Software Development
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chen Qian</a>, 
<a href="/search/cs?searchtype=author&query=Cong%2C+X">Xin Cong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weize Chen</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yusheng Su</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+Y">Yufan Dang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiahao Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Juyuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dahai Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Maosong Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://github.com/OpenBMB/ChatDev">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10069" title="Abstract">arXiv:2307.10069</a> (replaced) [<a href="/pdf/2307.10069" title="Download PDF">pdf</a>, <a href="/format/2307.10069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust constrained nonlinear Model Predictive Control with Gated  Recurrent Unit model -- Extended version
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Schimperna%2C+I">Irene Schimperna</a>, 
<a href="/search/eess?searchtype=author&query=Magni%2C+L">Lalo Magni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the extended version of <a href="https://doi.org/10.1016/j.automatica.2023.111472">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Automatica, Volume 161, 2024, 111472
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10156" title="Abstract">arXiv:2307.10156</a> (replaced) [<a href="/pdf/2307.10156" title="Download PDF">pdf</a>, <a href="/format/2307.10156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Transformer Extrapolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhen Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yiran Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+H">Hui Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI Camera Ready. Zhen Qin and Yiran Zhong contribute equally to this paper; Yiran Zhong is the corresponding author. The code is available at <a href="https://github.com/OpenNLPLab/Rpe">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16159" title="Abstract">arXiv:2307.16159</a> (replaced) [<a href="/pdf/2307.16159" title="Download PDF">pdf</a>, <a href="/format/2307.16159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polytopes with Bounded Integral Slack Matrices Have Sub-Exponential  Extension Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+S">Sally Dong</a>, 
<a href="/search/cs?searchtype=author&query=Rothvoss%2C+T">Thomas Rothvoss</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16676" title="Abstract">arXiv:2307.16676</a> (replaced) [<a href="/pdf/2307.16676" title="Download PDF">pdf</a>, <a href="/format/2307.16676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-End Reinforcement Learning for Torque Based Variable Height  Hopping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soni%2C+R">Raghav Soni</a>, 
<a href="/search/cs?searchtype=author&query=Harnack%2C+D">Daniel Harnack</a>, 
<a href="/search/cs?searchtype=author&query=Isermann%2C+H">Hauke Isermann</a>, 
<a href="/search/cs?searchtype=author&query=Fushimi%2C+S">Sotaro Fushimi</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Shivesh Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Kirchner%2C+F">Frank Kirchner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Update publication info. Cite as: R. Soni, D. Harnack, H. Isermann, S. Fushimi, S. Kumar and F. Kirchner, "End-to-End Reinforcement Learning for Torque Based Variable Height Hopping," 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, MI, USA, 2023, pp. 7531-7538, doi: 10.1109/IROS55552.2023.10342187
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> End-to-End Reinforcement Learning for Torque Based Variable Height
  Hopping, 2023 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS), Detroit, MI, USA, 2023, pp. 7531-7538
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01037" title="Abstract">arXiv:2308.01037</a> (replaced) [<a href="/pdf/2308.01037" title="Download PDF">pdf</a>, <a href="/format/2308.01037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Fast Monte Carlo algorithm for evaluating matrix functions with  application in complex networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guidotti%2C+N+L">Nicolas L. Guidotti</a>, 
<a href="/search/cs?searchtype=author&query=Acebr%C3%B3n%2C+J+A">Juan A. Acebr&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Monteiro%2C+J">Jos&#xe9; Monteiro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the Journal of Scientific Computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02068" title="Abstract">arXiv:2308.02068</a> (replaced) [<a href="/pdf/2308.02068" title="Download PDF">pdf</a>, <a href="/format/2308.02068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Specious Sites: Tracking the Spread and Sway of Spurious News Stories at  Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hanley%2C+H+W+A">Hans W. A. Hanley</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+D">Deepak Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Durumeric%2C+Z">Zakir Durumeric</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE S&amp;P 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03358" title="Abstract">arXiv:2308.03358</a> (replaced) [<a href="/pdf/2308.03358" title="Download PDF">pdf</a>, <a href="/format/2308.03358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RGMComm: Return Gap Minimization via Discrete Communications in  Multi-Agent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingdi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+T">Tian Lan</a>, 
<a href="/search/cs?searchtype=author&query=Joe-Wong%2C+C">Carlee Joe-Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04355" title="Abstract">arXiv:2308.04355</a> (replaced) [<a href="/pdf/2308.04355" title="Download PDF">pdf</a>, <a href="/format/2308.04355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vascular Ageing and Smoking Habit Prediction via a Low-Cost Single-Lead  ECG Module
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ali%2C+S+A">S. Anas Ali</a>, 
<a href="/search/eess?searchtype=author&query=Niaz%2C+M+S">M. Saqib Niaz</a>, 
<a href="/search/eess?searchtype=author&query=Rehman%2C+M">Mubashir Rehman</a>, 
<a href="/search/eess?searchtype=author&query=Mehmood%2C+A">Ahsan Mehmood</a>, 
<a href="/search/eess?searchtype=author&query=Rahman%2C+M+M+U">M. Mahboob Ur Rahman</a>, 
<a href="/search/eess?searchtype=author&query=Riaz%2C+K">Kashif Riaz</a>, 
<a href="/search/eess?searchtype=author&query=Abbasi%2C+Q+H">Qammer H. Abbasi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures, 5 tables, submitted to a journal for review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04455" title="Abstract">arXiv:2308.04455</a> (replaced) [<a href="/pdf/2308.04455" title="Download PDF">pdf</a>, <a href="/format/2308.04455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anonymizing Speech: Evaluating and Designing Speaker Anonymization  Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Champion%2C+P">Pierre Champion</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD Thesis Pierre Champion | Universit\'e de Lorraine - INRIA Nancy | for associated source code, see <a href="https://github.com/deep-privacy/SA-toolkit">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04690" title="Abstract">arXiv:2308.04690</a> (replaced) [<a href="/pdf/2308.04690" title="Download PDF">pdf</a>, <a href="/format/2308.04690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite Element Operator Network for Solving Parametric PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lee%2C+J+Y">Jae Yong Lee</a>, 
<a href="/search/math?searchtype=author&query=Ko%2C+S">Seungchan Ko</a>, 
<a href="/search/math?searchtype=author&query=Hong%2C+Y">Youngjoon Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06962" title="Abstract">arXiv:2308.06962</a> (replaced) [<a href="/pdf/2308.06962" title="Download PDF">pdf</a>, <a href="/format/2308.06962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Color-NeuS: Reconstructing Neural Implicit Surfaces with Color
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+L">Licheng Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lixin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kailin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhen%2C+H">Haoyu Zhen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+M">Mei Han</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08288" title="Abstract">arXiv:2308.08288</a> (replaced) [<a href="/pdf/2308.08288" title="Download PDF">pdf</a>, <a href="/format/2308.08288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Audio-Visual Segmentation with Bidirectional Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+D">Dawei Hao</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yuxin Mao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bowen He</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaodong Han</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yuchao Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yiran Zhong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI Camera Ready. Dawei Hao and Yuxin Mao contribute equality to this paper. Yiran Zhong is the corresponding author. The code will be released at <a href="https://github.com/OpenNLPLab/AVS-bidirectional">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09997" title="Abstract">arXiv:2308.09997</a> (replaced) [<a href="/pdf/2308.09997" title="Download PDF">pdf</a>, <a href="/format/2308.09997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Additive Schwarz methods for semilinear elliptic problems with convex  energy functionals: Convergence rate independent of nonlinearity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Park%2C+J">Jongho Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12681" title="Abstract">arXiv:2308.12681</a> (replaced) [<a href="/pdf/2308.12681" title="Download PDF">pdf</a>, <a href="/format/2308.12681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LR-XFL: Logical Reasoning-based Explainable Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanci Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Han Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13304" title="Abstract">arXiv:2308.13304</a> (replaced) [<a href="/pdf/2308.13304" title="Download PDF">pdf</a>, <a href="/format/2308.13304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rapid Artefact Removal and H&amp;E-Stained Tissue Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Schreiber%2C+B+A">B. A. Schreiber</a>, 
<a href="/search/eess?searchtype=author&query=Denholm%2C+J">J. Denholm</a>, 
<a href="/search/eess?searchtype=author&query=Jaeckle%2C+F">F. Jaeckle</a>, 
<a href="/search/eess?searchtype=author&query=Arends%2C+M+J">M. J. Arends</a>, 
<a href="/search/eess?searchtype=author&query=Branson%2C+K+M">K. M. Branson</a>, 
<a href="/search/eess?searchtype=author&query=Sch%C3%B6nlieb%2C+C+-">C.-B. Sch&#xf6;nlieb</a>, 
<a href="/search/eess?searchtype=author&query=Soilleux%2C+E+J">E. J. Soilleux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13890" title="Abstract">arXiv:2308.13890</a> (replaced) [<a href="/pdf/2308.13890" title="Download PDF">pdf</a>, <a href="/ps/2308.13890" title="Download PostScript">ps</a>, <a href="/format/2308.13890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spanning Adjacency Oracles in Sublinear Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bodwin%2C+G">Greg Bodwin</a>, 
<a href="/search/cs?searchtype=author&query=Fleischmann%2C+H">Henry Fleischmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 1 figure. Accepted to ITCS '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13976" title="Abstract">arXiv:2308.13976</a> (replaced) [<a href="/pdf/2308.13976" title="Download PDF">pdf</a>, <a href="/format/2308.13976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Label Denoising through Cross-Model Agreement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+X">Xin Xin</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Z">Zaiqiao Meng</a>, 
<a href="/search/cs?searchtype=author&query=Jose%2C+J">Joemon Jose</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fuli Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2105.09605">arXiv:2105.09605</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14984" title="Abstract">arXiv:2308.14984</a> (replaced) [<a href="/pdf/2308.14984" title="Download PDF">pdf</a>, <a href="/format/2308.14984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contact-rich SE(3)-Equivariant Robot Manipulation Task Learning via  Geometric Impedance Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seo%2C+J">Joohwan Seo</a>, 
<a href="/search/cs?searchtype=author&query=Prakash%2C+N+P+S">Nikhil Potu Surya Prakash</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Changhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jongeun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Tomizuka%2C+M">Masayoshi Tomizuka</a>, 
<a href="/search/cs?searchtype=author&query=Horowitz%2C+R">Roberto Horowitz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01759" title="Abstract">arXiv:2309.01759</a> (replaced) [<a href="/pdf/2309.01759" title="Download PDF">pdf</a>, <a href="/ps/2309.01759" title="Download PostScript">ps</a>, <a href="/format/2309.01759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extremal Growth of Multiple Toeplitz Operators and Applications to  Numerical Stability of Approximation Schemes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Rastogi%2C+Y">Yash Rastogi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Functional Analysis (math.FA)

</div>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02318" title="Abstract">arXiv:2309.02318</a> (replaced) [<a href="/pdf/2309.02318" title="Download PDF">pdf</a>, <a href="/format/2309.02318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TiAVox: Time-aware Attenuation Voxels for Sparse-view 4D DSA  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhenghong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Huangxuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Jiemin Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+D">Dongqiao Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lingxia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Feihong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chuansheng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinggang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03647" title="Abstract">arXiv:2309.03647</a> (replaced) [<a href="/pdf/2309.03647" title="Download PDF">pdf</a>, <a href="/format/2309.03647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProvG-Searcher: A Graph Representation Learning Approach for Efficient  Provenance Graph Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Altinisik%2C+E">Enes Altinisik</a>, 
<a href="/search/cs?searchtype=author&query=Deniz%2C+F">Fatih Deniz</a>, 
<a href="/search/cs?searchtype=author&query=Sencar%2C+H+T">Husrev Taha Sencar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03848" title="Abstract">arXiv:2309.03848</a> (replaced) [<a href="/pdf/2309.03848" title="Download PDF">pdf</a>, <a href="/format/2309.03848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bipartite Friends and Strangers Walking on Bipartite Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jeong%2C+R">Ryan Jeong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 8 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04766" title="Abstract">arXiv:2309.04766</a> (replaced) [<a href="/pdf/2309.04766" title="Download PDF">pdf</a>, <a href="/format/2309.04766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment  to Cultural Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+F">Fangkai Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Aw%2C+A+T">Ai Ti Aw</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N+F">Nancy F. Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages. More datasets (2 on Cross-Lingual Consistency and 4 on Cultural Understanding) and more supported languages. Code: <a href="https://github.com/SeaEval/SeaEval">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05138" title="Abstract">arXiv:2309.05138</a> (replaced) [<a href="/pdf/2309.05138" title="Download PDF">pdf</a>, <a href="/format/2309.05138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GenAIPABench: A Benchmark for Generative AI-based Privacy Assistants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamid%2C+A">Aamir Hamid</a>, 
<a href="/search/cs?searchtype=author&query=Samidi%2C+H+R">Hemanth Reddy Samidi</a>, 
<a href="/search/cs?searchtype=author&query=Finin%2C+T">Tim Finin</a>, 
<a href="/search/cs?searchtype=author&query=Pappachan%2C+P">Primal Pappachan</a>, 
<a href="/search/cs?searchtype=author&query=Yus%2C+R">Roberto Yus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06453" title="Abstract">arXiv:2309.06453</a> (replaced) [<a href="/pdf/2309.06453" title="Download PDF">pdf</a>, <a href="/format/2309.06453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Narrowing the Gap between Supervised and Unsupervised Sentence  Representation Learning with Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Richong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Z">Zhijie Nie</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yongyi Mao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08320" title="Abstract">arXiv:2309.08320</a> (replaced) [<a href="/pdf/2309.08320" title="Download PDF">pdf</a>, <a href="/format/2309.08320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diff-SV: A Unified Hierarchical Framework for Noise-Robust Speaker  Verification Using Score-Based Diffusion Probabilistic Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kim%2C+J">Ju-ho Kim</a>, 
<a href="/search/eess?searchtype=author&query=Heo%2C+J">Jungwoo Heo</a>, 
<a href="/search/eess?searchtype=author&query=Shin%2C+H">Hyun-seo Shin</a>, 
<a href="/search/eess?searchtype=author&query=Lim%2C+C">Chan-yeong Lim</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+H">Ha-Jin Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, accepted for ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08765" title="Abstract">arXiv:2309.08765</a> (replaced) [<a href="/pdf/2309.08765" title="Download PDF">pdf</a>, <a href="/format/2309.08765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mining Patents with Large Language Models Elucidates the Chemical  Function Landscape
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Kosonocky%2C+C+W">Clayton W. Kosonocky</a>, 
<a href="/search/q-bio?searchtype=author&query=Wilke%2C+C+O">Claus O. Wilke</a>, 
<a href="/search/q-bio?searchtype=author&query=Marcotte%2C+E+M">Edward M. Marcotte</a>, 
<a href="/search/q-bio?searchtype=author&query=Ellington%2C+A+D">Andrew D. Ellington</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10092" title="Abstract">arXiv:2309.10092</a> (replaced) [<a href="/pdf/2309.10092" title="Download PDF">pdf</a>, <a href="/format/2309.10092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conformal Temporal Logic Planning using Large Language Models: Knowing  When to Do What and When to Ask for Help
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+J">Jiaming Tong</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+K">Kaiyuan Tan</a>, 
<a href="/search/cs?searchtype=author&query=Vorobeychik%2C+Y">Yevgeniy Vorobeychik</a>, 
<a href="/search/cs?searchtype=author&query=Kantaros%2C+Y">Yiannis Kantaros</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10625" title="Abstract">arXiv:2309.10625</a> (replaced) [<a href="/pdf/2309.10625" title="Download PDF">pdf</a>, <a href="/format/2309.10625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NoisyNN: Exploring the Influence of Information Entropy Change in  Learning Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiaowei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Y">Yao Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Li Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Dajiang Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Information Entropy, NoisyNN, ViT, CNN
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11518" title="Abstract">arXiv:2309.11518</a> (replaced) [<a href="/pdf/2309.11518" title="Download PDF">pdf</a>, <a href="/format/2309.11518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ad-load Balancing via Off-policy Learning in a Content Marketplace
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sagtani%2C+H">Hitesh Sagtani</a>, 
<a href="/search/cs?searchtype=author&query=Jhawar%2C+M">Madan Jhawar</a>, 
<a href="/search/cs?searchtype=author&query=Mehrotra%2C+R">Rishabh Mehrotra</a>, 
<a href="/search/cs?searchtype=author&query=Jeunen%2C+O">Olivier Jeunen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Early version presented at the CONSEQUENCES '23 workshop at RecSys '23, final version appearing at WSDM '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11651" title="Abstract">arXiv:2309.11651</a> (replaced) [<a href="/pdf/2309.11651" title="Download PDF">pdf</a>, <a href="/format/2309.11651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Drift Control of High-Dimensional RBM: A Computational Method Based on  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ata%2C+B">Baris Ata</a>, 
<a href="/search/eess?searchtype=author&query=Harrison%2C+J+M">J. Michael Harrison</a>, 
<a href="/search/eess?searchtype=author&query=Si%2C+N">Nian Si</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Analysis of PDEs (math.AP); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12211" title="Abstract">arXiv:2309.12211</a> (replaced) [<a href="/pdf/2309.12211" title="Download PDF">pdf</a>, <a href="/format/2309.12211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-informed State-space Neural Networks for Transport Phenomena
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dave%2C+A+J">Akshay J. Dave</a>, 
<a href="/search/cs?searchtype=author&query=Vilim%2C+R+B">Richard B. Vilim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Computational Physics (physics.comp-ph); Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12276" title="Abstract">arXiv:2309.12276</a> (replaced) [<a href="/pdf/2309.12276" title="Download PDF">pdf</a>, <a href="/format/2309.12276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMR: Real-time Prompting of Interactive Worlds using Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+La+Torre%2C+F">Fernanda De La Torre</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C+M">Cathy Mengying Fang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Han Huang</a>, 
<a href="/search/cs?searchtype=author&query=Banburski-Fahey%2C+A">Andrzej Banburski-Fahey</a>, 
<a href="/search/cs?searchtype=author&query=Fernandez%2C+J+A">Judith Amores Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=Lanier%2C+J">Jaron Lanier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 60 pages, 18 figures; Expanded discussion of experiments and the influence of various modules
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15016" title="Abstract">arXiv:2309.15016</a> (replaced) [<a href="/pdf/2309.15016" title="Download PDF">pdf</a>, <a href="/ps/2309.15016" title="Download PostScript">ps</a>, <a href="/format/2309.15016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Question-Answering Approach to Evaluating Legal Summaries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huihui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ashley%2C+K">Kevin Ashley</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Legal Knowledge and Information Systems 379(2023) 293-298
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15188" title="Abstract">arXiv:2309.15188</a> (replaced) [<a href="/pdf/2309.15188" title="Download PDF">pdf</a>, <a href="/format/2309.15188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ICML 2023 Topological Deep Learning Challenge : Design and Results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papillon%2C+M">Mathilde Papillon</a>, 
<a href="/search/cs?searchtype=author&query=Hajij%2C+M">Mustafa Hajij</a>, 
<a href="/search/cs?searchtype=author&query=Jenne%2C+H">Helen Jenne</a>, 
<a href="/search/cs?searchtype=author&query=Mathe%2C+J">Johan Mathe</a>, 
<a href="/search/cs?searchtype=author&query=Myers%2C+A">Audun Myers</a>, 
<a href="/search/cs?searchtype=author&query=Papamarkou%2C+T">Theodore Papamarkou</a>, 
<a href="/search/cs?searchtype=author&query=Zamzmi%2C+G">Ghada Zamzmi</a>, 
<a href="/search/cs?searchtype=author&query=Birdal%2C+T">Tolga Birdal</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+T">Tamal Dey</a>, 
<a href="/search/cs?searchtype=author&query=Doster%2C+T">Tim Doster</a>, 
<a href="/search/cs?searchtype=author&query=Emerson%2C+T">Tegan Emerson</a>, 
<a href="/search/cs?searchtype=author&query=Gopalakrishnan%2C+G">Gurusankar Gopalakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Govil%2C+D">Devendra Govil</a>, 
<a href="/search/cs?searchtype=author&query=Guzm%C3%A1n-S%C3%A1enz%2C+A">Aldo Guzm&#xe1;n-S&#xe1;enz</a>, 
<a href="/search/cs?searchtype=author&query=Kvinge%2C+H">Henry Kvinge</a>, 
<a href="/search/cs?searchtype=author&query=Livesay%2C+N">Neal Livesay</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+S">Soham Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Samaga%2C+S+N">Shreyas N. Samaga</a>, 
<a href="/search/cs?searchtype=author&query=Ramamurthy%2C+K+N">Karthikeyan Natesan Ramamurthy</a>, 
<a href="/search/cs?searchtype=author&query=Karri%2C+M+R">Maneel Reddy Karri</a>, 
<a href="/search/cs?searchtype=author&query=Rosen%2C+P">Paul Rosen</a>, 
<a href="/search/cs?searchtype=author&query=Sanborn%2C+S">Sophia Sanborn</a>, 
<a href="/search/cs?searchtype=author&query=Walters%2C+R">Robin Walters</a>, 
<a href="/search/cs?searchtype=author&query=Agerberg%2C+J">Jens Agerberg</a>, 
<a href="/search/cs?searchtype=author&query=Barikbin%2C+S">Sadrodin Barikbin</a>, 
<a href="/search/cs?searchtype=author&query=Battiloro%2C+C">Claudio Battiloro</a>, 
<a href="/search/cs?searchtype=author&query=Bazhenov%2C+G">Gleb Bazhenov</a>, 
<a href="/search/cs?searchtype=author&query=Bernardez%2C+G">Guillermo Bernardez</a>, 
<a href="/search/cs?searchtype=author&query=Brent%2C+A">Aiden Brent</a>, 
<a href="/search/cs?searchtype=author&query=Escalera%2C+S">Sergio Escalera</a>, 
<a href="/search/cs?searchtype=author&query=Fiorellino%2C+S">Simone Fiorellino</a>, 
<a href="/search/cs?searchtype=author&query=Gavrilev%2C+D">Dmitrii Gavrilev</a>, 
<a href="/search/cs?searchtype=author&query=Hassanin%2C+M">Mohammed Hassanin</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%A4usner%2C+P">Paul H&#xe4;usner</a>, 
<a href="/search/cs?searchtype=author&query=Gardaa%2C+O+H">Odin Hoff Gardaa</a>, 
<a href="/search/cs?searchtype=author&query=Khamis%2C+A">Abdelwahed Khamis</a>, 
<a href="/search/cs?searchtype=author&query=Lecha%2C+M">Manuel Lecha</a>, 
<a href="/search/cs?searchtype=author&query=Magai%2C+G">German Magai</a>, 
<a href="/search/cs?searchtype=author&query=Malygina%2C+T">Tatiana Malygina</a>, 
<a href="/search/cs?searchtype=author&query=Ballester%2C+R">Rub&#xe9;n Ballester</a>, 
<a href="/search/cs?searchtype=author&query=Nadimpalli%2C+K">Kalyan Nadimpalli</a>, 
<a href="/search/cs?searchtype=author&query=Nikitin%2C+A">Alexander Nikitin</a>, 
<a href="/search/cs?searchtype=author&query=Rabinowitz%2C+A">Abraham Rabinowitz</a>, 
<a href="/search/cs?searchtype=author&query=Salatiello%2C+A">Alessandro Salatiello</a>, 
<a href="/search/cs?searchtype=author&query=Scardapane%2C+S">Simone Scardapane</a>, 
<a href="/search/cs?searchtype=author&query=Scofano%2C+L">Luca Scofano</a>,  et al. (11 additional authors not shown)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15289" title="Abstract">arXiv:2309.15289</a> (replaced) [<a href="/pdf/2309.15289" title="Download PDF">pdf</a>, <a href="/format/2309.15289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEPT: Towards Efficient Scene Representation Learning for Motion  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lan%2C+Z">Zhiqian Lan</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuxuan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+Y">Yao Mu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S+E">Shengbo Eben Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16583" title="Abstract">arXiv:2309.16583</a> (replaced) [<a href="/pdf/2309.16583" title="Download PDF">pdf</a>, <a href="/format/2309.16583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT-Fathom: Benchmarking Large Language Models to Decipher the  Evolutionary Path towards GPT-4 and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yijie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+C">Chenguang Xi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Pengyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K+C">Kevin Chen-Chuan Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16737" title="Abstract">arXiv:2309.16737</a> (replaced) [<a href="/pdf/2309.16737" title="Download PDF">pdf</a>, <a href="/ps/2309.16737" title="Download PostScript">ps</a>, <a href="/format/2309.16737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Small Teams Propel Fresh Ideas in Science and Technology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yiling Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lingfei Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00149" title="Abstract">arXiv:2310.00149</a> (replaced) [<a href="/pdf/2310.00149" title="Download PDF">pdf</a>, <a href="/format/2310.00149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One for All: Towards Training One Graph Model for All Classification  Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiarui Feng</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lecheng Kong</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+N">Ningyue Liang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yixin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Muhan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00625" title="Abstract">arXiv:2310.00625</a> (replaced) [<a href="/pdf/2310.00625" title="Download PDF">pdf</a>, <a href="/format/2310.00625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reduced basis stabilization and post-processing for the virtual element  method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Credali%2C+F">Fabio Credali</a>, 
<a href="/search/math?searchtype=author&query=Bertoluzza%2C+S">Silvia Bertoluzza</a>, 
<a href="/search/math?searchtype=author&query=Prada%2C+D">Daniele Prada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 4 algorithms, 16 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00757" title="Abstract">arXiv:2310.00757</a> (replaced) [<a href="/pdf/2310.00757" title="Download PDF">pdf</a>, <a href="/ps/2310.00757" title="Download PostScript">ps</a>, <a href="/format/2310.00757" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mind the Gap: Federated Learning Broadens Domain Generalization in  Diagnostic AI Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arasteh%2C+S+T">Soroosh Tayebi Arasteh</a>, 
<a href="/search/cs?searchtype=author&query=Kuhl%2C+C">Christiane Kuhl</a>, 
<a href="/search/cs?searchtype=author&query=Saehn%2C+M">Marwin-Jonathan Saehn</a>, 
<a href="/search/cs?searchtype=author&query=Isfort%2C+P">Peter Isfort</a>, 
<a href="/search/cs?searchtype=author&query=Truhn%2C+D">Daniel Truhn</a>, 
<a href="/search/cs?searchtype=author&query=Nebelung%2C+S">Sven Nebelung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Nature Scientific Reports
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sci Rep 13, 22576 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02651" title="Abstract">arXiv:2310.02651</a> (replaced) [<a href="/pdf/2310.02651" title="Download PDF">pdf</a>, <a href="/format/2310.02651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hire When You Need to: Gradual Participant Recruitment for Auction-based  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xavier Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Han Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 Pages, 3 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03780" title="Abstract">arXiv:2310.03780</a> (replaced) [<a href="/pdf/2310.03780" title="Download PDF">pdf</a>, <a href="/format/2310.03780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automating Human Tutor-Style Programming Feedback: Leveraging GPT-4  Tutor Model for Hint Generation and GPT-3.5 Student Model for Hint Validation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phung%2C+T">Tung Phung</a>, 
<a href="/search/cs?searchtype=author&query=P%C4%83durean%2C+V">Victor-Alexandru P&#x103;durean</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Anjali Singh</a>, 
<a href="/search/cs?searchtype=author&query=Brooks%2C+C">Christopher Brooks</a>, 
<a href="/search/cs?searchtype=author&query=Cambronero%2C+J">Jos&#xe9; Cambronero</a>, 
<a href="/search/cs?searchtype=author&query=Gulwani%2C+S">Sumit Gulwani</a>, 
<a href="/search/cs?searchtype=author&query=Singla%2C+A">Adish Singla</a>, 
<a href="/search/cs?searchtype=author&query=Soares%2C+G">Gustavo Soares</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Learning Analytics and Knowledge Conference (LAK) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04780" title="Abstract">arXiv:2310.04780</a> (replaced) [<a href="/pdf/2310.04780" title="Download PDF">pdf</a>, <a href="/format/2310.04780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IPMix: Label-Preserving Data Augmentation Method for Training Robust  Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhenglin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+X">Xianan Bao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Na Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+X">Xiaomei Tu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Biao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05161" title="Abstract">arXiv:2310.05161</a> (replaced) [<a href="/pdf/2310.05161" title="Download PDF">pdf</a>, <a href="/format/2310.05161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recurrent Neural Language Models as Probabilistic Finite-state Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Svete%2C+A">Anej Svete</a>, 
<a href="/search/cs?searchtype=author&query=Cotterell%2C+R">Ryan Cotterell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computational Complexity (cs.CC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06009" title="Abstract">arXiv:2310.06009</a> (replaced) [<a href="/pdf/2310.06009" title="Download PDF">pdf</a>, <a href="/format/2310.06009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Divide-and-Conquer Dynamics in AI-Driven Disempowerment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+P+S">Peter S. Park</a>, 
<a href="/search/cs?searchtype=author&query=Tegmark%2C+M">Max Tegmark</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, nine visualizations (seven figures and two tables)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07971" title="Abstract">arXiv:2310.07971</a> (replaced) [<a href="/pdf/2310.07971" title="Download PDF">pdf</a>, <a href="/format/2310.07971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interval Decomposition for Persistence Modules Freely Generated over  PIDs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Luo%2C+J">Jiajie Luo</a>, 
<a href="/search/math?searchtype=author&query=Henselman-Petrusek%2C+G">Gregory Henselman-Petrusek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Topology (math.AT)</span>; Computational Geometry (cs.CG); Category Theory (math.CT)

</div>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08206" title="Abstract">arXiv:2310.08206</a> (replaced) [<a href="/pdf/2310.08206" title="Download PDF">pdf</a>, <a href="/format/2310.08206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long-Tailed Classification Based on Coarse-Grained Leading Forest and  Multi-Center Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jinye Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Ji Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Di Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jianhang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shaobo Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoyin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is another research work to apply leading tree structure along with deep learning architecture, aiming to deal with attribute-wise long-tail distribution within class
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09767" title="Abstract">arXiv:2310.09767</a> (replaced) [<a href="/pdf/2310.09767" title="Download PDF">pdf</a>, <a href="/format/2310.09767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VLIS: Unimodal Language Models Guide Multimodal Language Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chung%2C+J">Jiwan Chung</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Youngjae Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as main paper in EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10198" title="Abstract">arXiv:2310.10198</a> (replaced) [<a href="/pdf/2310.10198" title="Download PDF">pdf</a>, <a href="/format/2310.10198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MoConVQ: Unified Physics-Based Motion Control via Scalable Discrete  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Heyuan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhenhua Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ao%2C+T">Tenglong Ao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Baoquan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Libin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: MoConVQ.github.io
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13023" title="Abstract">arXiv:2310.13023</a> (replaced) [<a href="/pdf/2310.13023" title="Download PDF">pdf</a>, <a href="/format/2310.13023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphGPT: Graph Instruction Tuning for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiabin Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuhao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Lei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+L">Lixin Su</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Suqi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Dawei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15190" title="Abstract">arXiv:2310.15190</a> (replaced) [<a href="/pdf/2310.15190" title="Download PDF">pdf</a>, <a href="/format/2310.15190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Path Planning for Autonomous Vehicle Parking with Safety-Guarantee  using Hamilton-Jacobi Reachability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chi%2C+X">Xuemin Chi</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+J">Jun Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jihao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhitao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hongye Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Resubmit
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15516" title="Abstract">arXiv:2310.15516</a> (replaced) [<a href="/pdf/2310.15516" title="Download PDF">pdf</a>, <a href="/format/2310.15516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Attention-based Deep Reinforcement Learning for solving the  Chinese Postman Problem with Load-dependent costs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+C+D">Cong Dao Tran</a>, 
<a href="/search/cs?searchtype=author&query=Hy%2C+T+S">Truong Son Hy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15646" title="Abstract">arXiv:2310.15646</a> (replaced) [<a href="/pdf/2310.15646" title="Download PDF">pdf</a>, <a href="/format/2310.15646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mean Teacher DETR with Masked Feature Alignment: A Robust Domain  Adaptive Detection Transformer Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weng%2C+W">Weixi Weng</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chun Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17658" title="Abstract">arXiv:2310.17658</a> (replaced) [<a href="/pdf/2310.17658" title="Download PDF">pdf</a>, <a href="/format/2310.17658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is Channel Independent strategy optimal for Time Series Forecasting?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peiwen%2C+Y">Yuan Peiwen</a>, 
<a href="/search/cs?searchtype=author&query=Changsheng%2C+Z">Zhu Changsheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18021" title="Abstract">arXiv:2310.18021</a> (replaced) [<a href="/pdf/2310.18021" title="Download PDF">pdf</a>, <a href="/format/2310.18021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FormalGeo: The First Step Toward Human-like IMO-level Geometric  Automated Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaokai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+N">Na Zhu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yiming He</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">Jia Zou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qike Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xiaoxiao Jin</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yanjun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+C">Chenyang Mao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhe Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+D">Dengfeng Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Fangzhen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yiwen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Runan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+C">Cheng Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhenbing Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shaorong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiangfeng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Leng%2C+T">Tuo Leng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18313" title="Abstract">arXiv:2310.18313</a> (replaced) [<a href="/pdf/2310.18313" title="Download PDF">pdf</a>, <a href="/format/2310.18313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FP8-LM: Training FP8 Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Houwen Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yixuan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+G">Guoshuai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuxiang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ze Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yifan Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ziyue Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+B">Bolin Ni</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jingcheng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruihang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Miaosen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+J">Jia Ning</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruizhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuguang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chau%2C+J">Joe Chau</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Han Hu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Peng Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02507" title="Abstract">arXiv:2311.02507</a> (replaced) [<a href="/pdf/2311.02507" title="Download PDF">pdf</a>, <a href="/format/2311.02507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear stability of discrete shock profiles for systems of conservation  laws
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Coeuret%2C+L">Lucas Coeuret</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 86 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02775" title="Abstract">arXiv:2311.02775</a> (replaced) [<a href="/pdf/2311.02775" title="Download PDF">pdf</a>, <a href="/format/2311.02775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-TA: Towards an Intelligent Question-Answer Teaching Assistant using  Open-Source LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hicke%2C+Y">Yann Hicke</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+A">Anmol Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Q">Qianou Ma</a>, 
<a href="/search/cs?searchtype=author&query=Denny%2C+P">Paul Denny</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updates for camera-ready submission
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS Workshop on Generative AI for Education (GAIED), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03498" title="Abstract">arXiv:2311.03498</a> (replaced) [<a href="/pdf/2311.03498" title="Download PDF">pdf</a>, <a href="/format/2311.03498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Context Exemplars as Clues to Retrieving from Large Associative  Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiachen Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at Neural Conversational AI @ ICML 2023 and Associative Memory &amp; Hopfield Networks @ NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03821" title="Abstract">arXiv:2311.03821</a> (replaced) [<a href="/pdf/2311.03821" title="Download PDF">pdf</a>, <a href="/format/2311.03821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Positive Competitive Networks for Sparse Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Centorrino%2C+V">Veronica Centorrino</a>, 
<a href="/search/q-bio?searchtype=author&query=Gokhale%2C+A">Anand Gokhale</a>, 
<a href="/search/q-bio?searchtype=author&query=Davydov%2C+A">Alexander Davydov</a>, 
<a href="/search/q-bio?searchtype=author&query=Russo%2C+G">Giovanni Russo</a>, 
<a href="/search/q-bio?searchtype=author&query=Bullo%2C+F">Francesco Bullo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 9 Figure, 1 Table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05144" title="Abstract">arXiv:2311.05144</a> (replaced) [<a href="/pdf/2311.05144" title="Download PDF">pdf</a>, <a href="/format/2311.05144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counter-Empirical Attacking based on Adversarial Reinforcement Learning  for Time-Relevant Scoring System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiangguo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hong Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+B">Bo Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+S">Si Qin</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qingwei Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TKDE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05587" title="Abstract">arXiv:2311.05587</a> (replaced) [<a href="/pdf/2311.05587" title="Download PDF">pdf</a>, <a href="/ps/2311.05587" title="Download PostScript">ps</a>, <a href="/format/2311.05587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Methods for Media Mix Modelling with shape and funnel effects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marin%2C+J">Javier Marin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Rev. 4, December 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06281" title="Abstract">arXiv:2311.06281</a> (replaced) [<a href="/pdf/2311.06281" title="Download PDF">pdf</a>, <a href="/format/2311.06281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Parallelization of a Ubiquitous Sequential Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heinsen%2C+F+A">Franz A. Heinsen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Source code for replicating our results is available online at <a href="https://github.com/glassroom/heinsen_sequence">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07594" title="Abstract">arXiv:2311.07594</a> (replaced) [<a href="/pdf/2311.07594" title="Download PDF">pdf</a>, <a href="/format/2311.07594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Bridge the Gap between Modalities: A Comprehensive Survey on  Multimodal Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shezheng Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaopeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shasha Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jie Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+X">Xiaoguang Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weimin Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09506" title="Abstract">arXiv:2311.09506</a> (replaced) [<a href="/pdf/2311.09506" title="Download PDF">pdf</a>, <a href="/format/2311.09506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating the Impact of Weight Sharing Decisions on Knowledge  Transfer in Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Andle%2C+J">Josh Andle</a>, 
<a href="/search/cs?searchtype=author&query=Payani%2C+A">Ali Payani</a>, 
<a href="/search/cs?searchtype=author&query=Yasaei-Sekeh%2C+S">Salimeh Yasaei-Sekeh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 Figures, 4 Tables, 2 Algorithms
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10090" title="Abstract">arXiv:2311.10090</a> (replaced) [<a href="/pdf/2311.10090" title="Download PDF">pdf</a>, <a href="/format/2311.10090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JaxMARL: Multi-Agent RL Environments in JAX
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rutherford%2C+A">Alexander Rutherford</a>, 
<a href="/search/cs?searchtype=author&query=Ellis%2C+B">Benjamin Ellis</a>, 
<a href="/search/cs?searchtype=author&query=Gallici%2C+M">Matteo Gallici</a>, 
<a href="/search/cs?searchtype=author&query=Cook%2C+J">Jonathan Cook</a>, 
<a href="/search/cs?searchtype=author&query=Lupu%2C+A">Andrei Lupu</a>, 
<a href="/search/cs?searchtype=author&query=Ingvarsson%2C+G">Gardar Ingvarsson</a>, 
<a href="/search/cs?searchtype=author&query=Willi%2C+T">Timon Willi</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Akbir Khan</a>, 
<a href="/search/cs?searchtype=author&query=de+Witt%2C+C+S">Christian Schroeder de Witt</a>, 
<a href="/search/cs?searchtype=author&query=Souly%2C+A">Alexandra Souly</a>, 
<a href="/search/cs?searchtype=author&query=Bandyopadhyay%2C+S">Saptarashmi Bandyopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Samvelyan%2C+M">Mikayel Samvelyan</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Minqi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lange%2C+R+T">Robert Tjarko Lange</a>, 
<a href="/search/cs?searchtype=author&query=Whiteson%2C+S">Shimon Whiteson</a>, 
<a href="/search/cs?searchtype=author&query=Lacerda%2C+B">Bruno Lacerda</a>, 
<a href="/search/cs?searchtype=author&query=Hawes%2C+N">Nick Hawes</a>, 
<a href="/search/cs?searchtype=author&query=Rocktaschel%2C+T">Tim Rocktaschel</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chris Lu</a>, 
<a href="/search/cs?searchtype=author&query=Foerster%2C+J+N">Jakob Nicolaus Foerster</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11608" title="Abstract">arXiv:2311.11608</a> (replaced) [<a href="/pdf/2311.11608" title="Download PDF">pdf</a>, <a href="/ps/2311.11608" title="Download PostScript">ps</a>, <a href="/format/2311.11608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taiyi: A Bilingual Fine-Tuned Large Language Model for Diverse  Biomedical Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Ling Luo</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+J">Jinzhong Ning</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yingwen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhijun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zeyuan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+W">Weiru Fu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Q">Qinyu Han</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guangtao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yunzhi Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+D">Dinghao Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiru Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+W">Wenduo Feng</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+S">Senbo Tu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhihao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuanyuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hongfei Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14743" title="Abstract">arXiv:2311.14743</a> (replaced) [<a href="/pdf/2311.14743" title="Download PDF">pdf</a>, <a href="/format/2311.14743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Baseline Analysis of Reward Models&#x27; Ability To Accurately Analyze  Foundation Models Under Distribution Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=LeVine%2C+W">Will LeVine</a>, 
<a href="/search/cs?searchtype=author&query=Pikus%2C+B">Ben Pikus</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tony Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hendryx%2C+S">Sean Hendryx</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15570" title="Abstract">arXiv:2311.15570</a> (replaced) [<a href="/pdf/2311.15570" title="Download PDF">pdf</a>, <a href="/format/2311.15570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UFDA: Universal Federated Domain Adaptation with Practical Assumptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinhui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenghao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Luping Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+W">Wei Xi</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+G">Gairui Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yihan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jizhong Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15646" title="Abstract">arXiv:2311.15646</a> (replaced) [<a href="/pdf/2311.15646" title="Download PDF">pdf</a>, <a href="/ps/2311.15646" title="Download PostScript">ps</a>, <a href="/format/2311.15646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> k-dimensional transversals for balls
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jung%2C+A">Attila Jung</a>, 
<a href="/search/math?searchtype=author&query=P%C3%A1lv%C3%B6lgyi%2C+D">D&#xf6;m&#xf6;t&#xf6;r P&#xe1;lv&#xf6;lgyi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We corrected the statements of Corollaries 19, 20 and 22, and added an example after Corollary 19. The proofs needed no modification
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Geometry (cs.CG)

</div>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16502" title="Abstract">arXiv:2311.16502</a> (replaced) [<a href="/pdf/2311.16502" title="Download PDF">pdf</a>, <a href="/format/2311.16502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning  Benchmark for Expert AGI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+X">Xiang Yue</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+Y">Yuansheng Ni</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tianyu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruoqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Ge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Stevens%2C+S">Samuel Stevens</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Dongfu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+W">Weiming Ren</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuxuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+C">Cong Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Botao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+R">Ruibin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+R">Renliang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+M">Ming Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Boyuan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhenzhu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yibo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenhao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Huan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yu Su</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenhu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 117 pages, 99 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16751" title="Abstract">arXiv:2311.16751</a> (replaced) [<a href="/pdf/2311.16751" title="Download PDF">pdf</a>, <a href="/format/2311.16751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultiCBR: Multi-view Contrastive Learning for Bundle Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yunshan Ma</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yingzhi He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yinwei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xiaoyu Du</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yuyangzi Fu</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> fix a typo in Table 2, i.e., the R@20 and N@20 of LightGCL are updated
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16895" title="Abstract">arXiv:2311.16895</a> (replaced) [<a href="/pdf/2311.16895" title="Download PDF">pdf</a>, <a href="/format/2311.16895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimization Theory Based Deep Reinforcement Learning for Resource  Allocation in Ultra-Reliable Wireless Networked Control Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ali%2C+H+Q">Hamida Qumber Ali</a>, 
<a href="/search/eess?searchtype=author&query=Darabi%2C+A+B">Amirhassan Babazadeh Darabi</a>, 
<a href="/search/eess?searchtype=author&query=Coleri%2C+S">Sinem Coleri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17280" title="Abstract">arXiv:2311.17280</a> (replaced) [<a href="/pdf/2311.17280" title="Download PDF">pdf</a>, <a href="/format/2311.17280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does VLN Pretraining Work with Nonsensical or Irrelevant Instructions?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+I">Ishika Singh</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+R">Robin Jia</a>, 
<a href="/search/cs?searchtype=author&query=Thomason%2C+J">Jesse Thomason</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by O-DRUM @ CVPR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18826" title="Abstract">arXiv:2311.18826</a> (replaced) [<a href="/pdf/2311.18826" title="Download PDF">pdf</a>, <a href="/format/2311.18826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometry-Aware Normalizing Wasserstein Flows for Optimal Causal  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+K">Kaiwen Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00038" title="Abstract">arXiv:2312.00038</a> (replaced) [<a href="/pdf/2312.00038" title="Download PDF">pdf</a>, <a href="/format/2312.00038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Posteriori Evaluation of a Physics-Constrained Neural Ordinary  Differential Equations Approach Coupled with CFD Solver for Modeling Stiff  Chemical Kinetics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kumar%2C+T">Tadbhagya Kumar</a>, 
<a href="/search/physics?searchtype=author&query=Kumar%2C+A">Anuj Kumar</a>, 
<a href="/search/physics?searchtype=author&query=Pal%2C+P">Pinaki Pal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Machine Learning (cs.LG); Chemical Physics (physics.chem-ph); Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00634" title="Abstract">arXiv:2312.00634</a> (replaced) [<a href="/pdf/2312.00634" title="Download PDF">pdf</a>, <a href="/ps/2312.00634" title="Download PostScript">ps</a>, <a href="/format/2312.00634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Recent Survey of Vision Transformers for Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Khan%2C+A">Asifullah Khan</a>, 
<a href="/search/eess?searchtype=author&query=Rauf%2C+Z">Zunaira Rauf</a>, 
<a href="/search/eess?searchtype=author&query=Khan%2C+A+R">Abdul Rehman Khan</a>, 
<a href="/search/eess?searchtype=author&query=Rathore%2C+S">Saima Rathore</a>, 
<a href="/search/eess?searchtype=author&query=Khan%2C+S+H">Saddam Hussain Khan</a>, 
<a href="/search/eess?searchtype=author&query=Shah%2C+N+S">Najmus Saher Shah</a>, 
<a href="/search/eess?searchtype=author&query=Farooq%2C+U">Umair Farooq</a>, 
<a href="/search/eess?searchtype=author&query=Asif%2C+H">Hifsa Asif</a>, 
<a href="/search/eess?searchtype=author&query=Asif%2C+A">Aqsa Asif</a>, 
<a href="/search/eess?searchtype=author&query=Zahoora%2C+U">Umme Zahoora</a>, 
<a href="/search/eess?searchtype=author&query=Khalil%2C+R+U">Rafi Ullah Khalil</a>, 
<a href="/search/eess?searchtype=author&query=Qamar%2C+S">Suleman Qamar</a>, 
<a href="/search/eess?searchtype=author&query=Asif%2C+U+H">Umme Hani Asif</a>, 
<a href="/search/eess?searchtype=author&query=Khan%2C+F+B">Faiza Babar Khan</a>, 
<a href="/search/eess?searchtype=author&query=Majid%2C+A">Abdul Majid</a>, 
<a href="/search/eess?searchtype=author&query=Gwak%2C+J">Jeonghwan Gwak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00812" title="Abstract">arXiv:2312.00812</a> (replaced) [<a href="/pdf/2312.00812" title="Download PDF">pdf</a>, <a href="/format/2312.00812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empowering Autonomous Driving with Large Language Models: A Safety  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yixuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+R">Ruochen Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Lang%2C+C">Chengtian Lang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+S+S">Sinong Simon Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaoran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhuoran Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qi Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures, baseline added in the experiment
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04326" title="Abstract">arXiv:2312.04326</a> (replaced) [<a href="/pdf/2312.04326" title="Download PDF">pdf</a>, <a href="/format/2312.04326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> iDesigner: A High-Resolution and Complex-Prompt Following Text-to-Image  Diffusion Model for Interior Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gan%2C+R">Ruyi Gan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaojun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Junyu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuanhe Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dixiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Ziwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+R">Renliang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaxing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pingjian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yan Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04877" title="Abstract">arXiv:2312.04877</a> (replaced) [<a href="/pdf/2312.04877" title="Download PDF">pdf</a>, <a href="/format/2312.04877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Explanations to Understand and Repair Embedding-based Entity  Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+X">Xiaobin Tian</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zequn Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wei Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the 40th IEEE International Conference on Data Engineering (ICDE 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05281" title="Abstract">arXiv:2312.05281</a> (replaced) [<a href="/pdf/2312.05281" title="Download PDF">pdf</a>, <a href="/format/2312.05281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> X2-Softmax: Margin Adaptive Loss Function for Face Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiamu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoxiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+Y">Yain-Whar Si</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaofan Li</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zheng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Ke Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+X">Xueyuan Gong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05571" title="Abstract">arXiv:2312.05571</a> (replaced) [<a href="/pdf/2312.05571" title="Download PDF">pdf</a>, <a href="/format/2312.05571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frugal LMs Trained to Invoke Symbolic Solvers Achieve  Parameter-Efficient Arithmetic Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dutta%2C+S">Subhabrata Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+J">Joykirat Singh</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+I">Ishan Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Manchanda%2C+S">Sunny Manchanda</a>, 
<a href="/search/cs?searchtype=author&query=Chakrabarti%2C+S">Soumen Chakrabarti</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+T">Tanmoy Chakraborty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06171" title="Abstract">arXiv:2312.06171</a> (replaced) [<a href="/pdf/2312.06171" title="Download PDF">pdf</a>, <a href="/format/2312.06171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jointly Explicit and Implicit Cross-Modal Interaction Network for  Anterior Chamber Inflammation Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+Q">Qian Shao</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Ye Dai</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+H">Haochao Ying</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+W">Wei Chi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07021" title="Abstract">arXiv:2312.07021</a> (replaced) [<a href="/pdf/2312.07021" title="Download PDF">pdf</a>, <a href="/format/2312.07021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transferring Modality-Aware Pedestrian Attentive Learning for  Visible-Infrared Person Re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuwei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+L">Licheng Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07266" title="Abstract">arXiv:2312.07266</a> (replaced) [<a href="/pdf/2312.07266" title="Download PDF">pdf</a>, <a href="/format/2312.07266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProxyDet: Synthesizing Proxy Novel Classes via Classwise Mixup for  Open-Vocabulary Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeong%2C+J">Joonhyun Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+G">Geondo Park</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+J">Jayeon Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+H">Hyungsik Jung</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Heesu Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07374" title="Abstract">arXiv:2312.07374</a> (replaced) [<a href="/pdf/2312.07374" title="Download PDF">pdf</a>, <a href="/format/2312.07374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relax Image-Specific Prompt Requirement in SAM: A Single Generic Prompt  for Segmenting Camouflaged Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jian Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiayi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Weitong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+S">Shaogang Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07937" title="Abstract">arXiv:2312.07937</a> (replaced) [<a href="/pdf/2312.07937" title="Download PDF">pdf</a>, <a href="/format/2312.07937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BOTH2Hands: Inferring 3D Hands from Both Text Prompts and Body Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenqian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Molin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuxuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Juze Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jingyi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingya Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08528" title="Abstract">arXiv:2312.08528</a> (replaced) [<a href="/pdf/2312.08528" title="Download PDF">pdf</a>, <a href="/format/2312.08528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> auto-sktime: Automated Time Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Z%C3%B6ller%2C+M">Marc-Andr&#xe9; Z&#xf6;ller</a>, 
<a href="/search/cs?searchtype=author&query=Lindauer%2C+M">Marius Lindauer</a>, 
<a href="/search/cs?searchtype=author&query=Huber%2C+M+F">Marco F. Huber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08670" title="Abstract">arXiv:2312.08670</a> (replaced) [<a href="/pdf/2312.08670" title="Download PDF">pdf</a>, <a href="/format/2312.08670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal-Spatial Entropy Balancing for Causal Continuous  Treatment-Effect Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hu%2C+T">Tao Hu</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+H">Honglong Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Zeng%2C+F">Fan Zeng</a>, 
<a href="/search/stat?searchtype=author&query=Du%2C+M">Min Du</a>, 
<a href="/search/stat?searchtype=author&query=Du%2C+X">XiangKun Du</a>, 
<a href="/search/stat?searchtype=author&query=Zheng%2C+Y">Yue Zheng</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+Q">Quanqi Li</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+M">Mengran Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Yang%2C+D">Dan Yang</a>, 
<a href="/search/stat?searchtype=author&query=Wu%2C+J">Jihao Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages;
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08957" title="Abstract">arXiv:2312.08957</a> (replaced) [<a href="/pdf/2312.08957" title="Download PDF">pdf</a>, <a href="/format/2312.08957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Acceptance and Trust: Drivers&#x27; First Contact with Released Automated  Vehicles in Naturalistic Traffic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schwindt-Drews%2C+S">Sarah Schwindt-Drews</a>, 
<a href="/search/cs?searchtype=author&query=Storms%2C+K">Kai Storms</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+S">Steven Peters</a>, 
<a href="/search/cs?searchtype=author&query=Abendroth%2C+B">Bettina Abendroth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09058" title="Abstract">arXiv:2312.09058</a> (replaced) [<a href="/pdf/2312.09058" title="Download PDF">pdf</a>, <a href="/format/2312.09058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Coalition Structures with Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y+E">Yixuan Even Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+C+K">Chun Kai Ling</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+F">Fei Fang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures, 3 tables, aaai 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09131" title="Abstract">arXiv:2312.09131</a> (replaced) [<a href="/pdf/2312.09131" title="Download PDF">pdf</a>, <a href="/format/2312.09131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Informed Neural Network Lyapunov Functions: PDE  Characterization, Learning, and Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+J">Jun Liu</a>, 
<a href="/search/math?searchtype=author&query=Meng%2C+Y">Yiming Meng</a>, 
<a href="/search/math?searchtype=author&query=Fitzsimmons%2C+M">Maxwell Fitzsimmons</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+R">Ruikun Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The current version has been submitted for publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09147" title="Abstract">arXiv:2312.09147</a> (replaced) [<a href="/pdf/2312.09147" title="Download PDF">pdf</a>, <a href="/format/2312.09147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Triplane Meets Gaussian Splatting: Fast and Generalizable Single-View 3D  Reconstruction with Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+Z">Zi-Xin Zou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhipeng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuan-Chen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yangguang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+D">Ding Liang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yan-Pei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Song-Hai Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://zouzx.github.io/TriplaneGaussian/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09259" title="Abstract">arXiv:2312.09259</a> (replaced) [<a href="/pdf/2312.09259" title="Download PDF">pdf</a>, <a href="/ps/2312.09259" title="Download PostScript">ps</a>, <a href="/format/2312.09259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Livestock feeding behavior: A tutorial review on automated techniques  for ruminant monitoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chelotti%2C+J">Jos&#xe9; Chelotti</a>, 
<a href="/search/eess?searchtype=author&query=Martinez-Rau%2C+L">Luciano Martinez-Rau</a>, 
<a href="/search/eess?searchtype=author&query=Ferrero%2C+M">Mariano Ferrero</a>, 
<a href="/search/eess?searchtype=author&query=Vignolo%2C+L">Leandro Vignolo</a>, 
<a href="/search/eess?searchtype=author&query=Galli%2C+J">Julio Galli</a>, 
<a href="/search/eess?searchtype=author&query=Planisich%2C+A">Alejandra Planisich</a>, 
<a href="/search/eess?searchtype=author&query=Rufiner%2C+H+L">H. Leonardo Rufiner</a>, 
<a href="/search/eess?searchtype=author&query=Giovanini%2C+L">Leonardo Giovanini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint submitted to biosystems engineering journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item671">[671]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09313" title="Abstract">arXiv:2312.09313</a> (replaced) [<a href="/pdf/2312.09313" title="Download PDF">pdf</a>, <a href="/format/2312.09313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LatentEditor: Text Driven Local Editing of 3D Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khalid%2C+U">Umar Khalid</a>, 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+H">Hasan Iqbal</a>, 
<a href="/search/cs?searchtype=author&query=Karim%2C+N">Nazmul Karim</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+J">Jing Hua</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://latenteditor.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item672">[672]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09323" title="Abstract">arXiv:2312.09323</a> (replaced) [<a href="/pdf/2312.09323" title="Download PDF">pdf</a>, <a href="/format/2312.09323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perspectives on the State and Future of Deep Learning -- 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goldblum%2C+M">Micah Goldblum</a>, 
<a href="/search/cs?searchtype=author&query=Anandkumar%2C+A">Anima Anandkumar</a>, 
<a href="/search/cs?searchtype=author&query=Baraniuk%2C+R">Richard Baraniuk</a>, 
<a href="/search/cs?searchtype=author&query=Goldstein%2C+T">Tom Goldstein</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+K">Kyunghyun Cho</a>, 
<a href="/search/cs?searchtype=author&query=Lipton%2C+Z+C">Zachary C Lipton</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+M">Melanie Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Nakkiran%2C+P">Preetum Nakkiran</a>, 
<a href="/search/cs?searchtype=author&query=Welling%2C+M">Max Welling</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+A+G">Andrew Gordon Wilson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item673">[673]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09754" title="Abstract">arXiv:2312.09754</a> (replaced) [<a href="/pdf/2312.09754" title="Download PDF">pdf</a>, <a href="/format/2312.09754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PPFM: Image denoising in photon-counting CT using single-step posterior  sampling Poisson flow generative models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hein%2C+D">Dennis Hein</a>, 
<a href="/search/eess?searchtype=author&query=Holmin%2C+S">Staffan Holmin</a>, 
<a href="/search/eess?searchtype=author&query=Szczykutowicz%2C+T">Timothy Szczykutowicz</a>, 
<a href="/search/eess?searchtype=author&query=Maltz%2C+J+S">Jonathan S Maltz</a>, 
<a href="/search/eess?searchtype=author&query=Danielsson%2C+M">Mats Danielsson</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+G">Ge Wang</a>, 
<a href="/search/eess?searchtype=author&query=Persson%2C+M">Mats Persson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)

</div>
</div>
</dd>
<dt><a name="item674">[674]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09775" title="Abstract">arXiv:2312.09775</a> (replaced) [<a href="/pdf/2312.09775" title="Download PDF">pdf</a>, <a href="/ps/2312.09775" title="Download PostScript">ps</a>, <a href="/format/2312.09775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative Evaluation of Additive Separability Tests for  Physics-Informed Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khoo%2C+Z">Zi-Yu Khoo</a>, 
<a href="/search/cs?searchtype=author&query=Low%2C+J+S+C">Jonathan Sze Choong Low</a>, 
<a href="/search/cs?searchtype=author&query=Bressan%2C+S">St&#xe9;phane Bressan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item675">[675]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09783" title="Abstract">arXiv:2312.09783</a> (replaced) [<a href="/pdf/2312.09783" title="Download PDF">pdf</a>, <a href="/format/2312.09783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Keep the Faith: Faithful Explanations in Convolutional Neural Networks  for Case-Based Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wolf%2C+T+N">Tom Nuno Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Bongratz%2C+F">Fabian Bongratz</a>, 
<a href="/search/cs?searchtype=author&query=Rickmann%2C+A">Anne-Marie Rickmann</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%B6lsterl%2C+S">Sebastian P&#xf6;lsterl</a>, 
<a href="/search/cs?searchtype=author&query=Wachinger%2C+C">Christian Wachinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in proceedings of AAAI Conference on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item676">[676]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09844" title="Abstract">arXiv:2312.09844</a> (replaced) [<a href="/pdf/2312.09844" title="Download PDF">pdf</a>, <a href="/format/2312.09844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Small Dataset, Big Gains: Enhancing Reinforcement Learning by Offline  Pre-Training with Model Based Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Macaluso%2C+G">Girolamo Macaluso</a>, 
<a href="/search/cs?searchtype=author&query=Sestini%2C+A">Alessandro Sestini</a>, 
<a href="/search/cs?searchtype=author&query=Bagdanov%2C+A+D">Andrew D. Bagdanov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item677">[677]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10087" title="Abstract">arXiv:2312.10087</a> (replaced) [<a href="/pdf/2312.10087" title="Download PDF">pdf</a>, <a href="/ps/2312.10087" title="Download PostScript">ps</a>, <a href="/format/2312.10087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting the Entropy Semiring for Neural Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chang%2C+O">Oscar Chang</a>, 
<a href="/search/eess?searchtype=author&query=Hwang%2C+D">Dongseong Hwang</a>, 
<a href="/search/eess?searchtype=author&query=Siohan%2C+O">Olivier Siohan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item678">[678]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10088" title="Abstract">arXiv:2312.10088</a> (replaced) [<a href="/pdf/2312.10088" title="Download PDF">pdf</a>, <a href="/ps/2312.10088" title="Download PostScript">ps</a>, <a href="/format/2312.10088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Robustness to Missing Video for Audiovisual Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chang%2C+O">Oscar Chang</a>, 
<a href="/search/eess?searchtype=author&query=Braga%2C+O">Otavio Braga</a>, 
<a href="/search/eess?searchtype=author&query=Liao%2C+H">Hank Liao</a>, 
<a href="/search/eess?searchtype=author&query=Serdyuk%2C+D">Dmitriy Serdyuk</a>, 
<a href="/search/eess?searchtype=author&query=Siohan%2C+O">Olivier Siohan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item679">[679]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10130" title="Abstract">arXiv:2312.10130</a> (replaced) [<a href="/pdf/2312.10130" title="Download PDF">pdf</a>, <a href="/format/2312.10130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving new physics searches with diffusion models for event  observables and jet constituents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Sengupta%2C+D">Debajyoti Sengupta</a>, 
<a href="/search/physics?searchtype=author&query=Leigh%2C+M">Matthew Leigh</a>, 
<a href="/search/physics?searchtype=author&query=Raine%2C+J+A">John Andrew Raine</a>, 
<a href="/search/physics?searchtype=author&query=Klein%2C+S">Samuel Klein</a>, 
<a href="/search/physics?searchtype=author&query=Golling%2C+T">Tobias Golling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Analysis, Statistics and Probability (physics.data-an)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex); High Energy Physics - Phenomenology (hep-ph)

</div>
</div>
</dd>
<dt><a name="item680">[680]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10194" title="Abstract">arXiv:2312.10194</a> (replaced) [<a href="/pdf/2312.10194" title="Download PDF">pdf</a>, <a href="/format/2312.10194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pareto Envelope Augmented with Reinforcement Learning: Multi-objective  reinforcement learning-based approach for Large-Scale Constrained Pressurized  Water Reactor optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seurin%2C+P">Paul Seurin</a>, 
<a href="/search/cs?searchtype=author&query=Shirvan%2C+K">Koroush Shirvan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item681">[681]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10237" title="Abstract">arXiv:2312.10237</a> (replaced) [<a href="/pdf/2312.10237" title="Download PDF">pdf</a>, <a href="/format/2312.10237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vertical Federated Alzheimer&#x27;s Detection on Multimodal Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mandal%2C+P+K">Paul K. Mandal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item682">[682]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10276" title="Abstract">arXiv:2312.10276</a> (replaced) [<a href="/pdf/2312.10276" title="Download PDF">pdf</a>, <a href="/format/2312.10276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymmetric Norms to Approximate the Minimum Action Distance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Steccanella%2C+L">Lorenzo Steccanella</a>, 
<a href="/search/cs?searchtype=author&query=Jonsson%2C+A">Anders Jonsson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item683">[683]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10300" title="Abstract">arXiv:2312.10300</a> (replaced) [<a href="/pdf/2312.10300" title="Download PDF">pdf</a>, <a href="/format/2312.10300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shot2Story20K: A New Benchmark for Comprehensive Understanding of  Multi-shot Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+M">Mingfei Han</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Linjie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiaojun Chang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Heng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> See <a href="https://mingfei.info/shot2story">this https URL</a> for updates and more information
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item684">[684]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10302" title="Abstract">arXiv:2312.10302</a> (replaced) [<a href="/pdf/2312.10302" title="Download PDF">pdf</a>, <a href="/format/2312.10302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One Shot Learning as Instruction Data Prospector for Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunshui Li</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+B">Binyuan Hui</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xiaobo Xia</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiaxi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Min Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+S">Shuzheng Si</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junhao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tongliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongbin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item685">[685]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10381" title="Abstract">arXiv:2312.10381</a> (replaced) [<a href="/pdf/2312.10381" title="Download PDF">pdf</a>, <a href="/format/2312.10381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SECap: Speech Emotion Captioning with Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yaoxun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hangting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jianwei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qiaochu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiyong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shixiong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guangzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yi Luo</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+R">Rongzhi Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item686">[686]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10418" title="Abstract">arXiv:2312.10418</a> (replaced) [<a href="/pdf/2312.10418" title="Download PDF">pdf</a>, <a href="/format/2312.10418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fractional Deep Reinforcement Learning for Age-Minimal Mobile Edge  Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Lyudong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+M">Ming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Meng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item687">[687]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10422" title="Abstract">arXiv:2312.10422</a> (replaced) [<a href="/pdf/2312.10422" title="Download PDF">pdf</a>, <a href="/format/2312.10422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Dense Correspondence for NeRF-Based Face Reenactment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Songlin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yushi Lan</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiangyu Fan</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Bo Peng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jing Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Proceedings of the AAAI Conference on Artificial Intelligence, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item688">[688]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10439" title="Abstract">arXiv:2312.10439</a> (replaced) [<a href="/pdf/2312.10439" title="Download PDF">pdf</a>, <a href="/format/2312.10439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simple Image-level Classification Improves Open-vocabulary Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+R">Ruohuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+G">Guansong Pang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiao Bai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item689">[689]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10447" title="Abstract">arXiv:2312.10447</a> (replaced) [<a href="/pdf/2312.10447" title="Download PDF">pdf</a>, <a href="/ps/2312.10447" title="Download PostScript">ps</a>, <a href="/format/2312.10447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finger Biometric Recognition With Feature Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bera%2C+A">Asish Bera</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharjee%2C+D">Debotosh Bhattacharjee</a>, 
<a href="/search/cs?searchtype=author&query=Nasipuri%2C+M">Mita Nasipuri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages. The Biometric Computing: Recognition and Registration, 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item690">[690]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10493" title="Abstract">arXiv:2312.10493</a> (replaced) [<a href="/pdf/2312.10493" title="Download PDF">pdf</a>, <a href="/format/2312.10493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Debiasing Multimodal Sarcasm Detection with Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+M">Mengzhao Jia</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Can Xie</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+L">Liqiang Jing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item691">[691]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10572" title="Abstract">arXiv:2312.10572</a> (replaced) [<a href="/pdf/2312.10572" title="Download PDF">pdf</a>, <a href="/format/2312.10572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Anonymous Multi-Agent Path Finding Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali%2C+Z+A">Zain Alabedeen Ali</a>, 
<a href="/search/cs?searchtype=author&query=Yakovlev%2C+K">Konstantin Yakovlev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item692">[692]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10656" title="Abstract">arXiv:2312.10656</a> (replaced) [<a href="/pdf/2312.10656" title="Download PDF">pdf</a>, <a href="/format/2312.10656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VidToMe: Video Token Merging for Zero-Shot Video Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xirui Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaokang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://vidtome-diffusion.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item693">[693]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10676" title="Abstract">arXiv:2312.10676</a> (replaced) [<a href="/pdf/2312.10676" title="Download PDF">pdf</a>, <a href="/format/2312.10676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fuzz Driver Synthesis for Rust Generic APIs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yehong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hui Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item694">[694]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10686" title="Abstract">arXiv:2312.10686</a> (replaced) [<a href="/pdf/2312.10686" title="Download PDF">pdf</a>, <a href="/format/2312.10686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Out-of-Distribution Detection in Long-Tailed Recognition with Calibrated  Outlier Class Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miao%2C+W">Wenjun Miao</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+G">Guansong Pang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiao Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jin Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024, with supplementary material
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item695">[695]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10687" title="Abstract">arXiv:2312.10687</a> (replaced) [<a href="/pdf/2312.10687" title="Download PDF">pdf</a>, <a href="/format/2312.10687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MM-TTS: Multi-modal Prompt based Style Transfer for Expressive  Text-to-Speech Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Guan%2C+W">Wenhao Guan</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yishuang Li</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+T">Tao Li</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+H">Hukai Huang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+F">Feng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+J">Jiayan Lin</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+L">Lingyan Huang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+L">Lin Li</a>, 
<a href="/search/eess?searchtype=author&query=Hong%2C+Q">Qingyang Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item696">[696]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10695" title="Abstract">arXiv:2312.10695</a> (replaced) [<a href="/pdf/2312.10695" title="Download PDF">pdf</a>, <a href="/ps/2312.10695" title="Download PostScript">ps</a>, <a href="/format/2312.10695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonparametric Strategy Test
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ganzfried%2C+S">Sam Ganzfried</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA); Theoretical Economics (econ.TH)

</div>
</div>
</dd>
<dt><a name="item697">[697]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10716" title="Abstract">arXiv:2312.10716</a> (replaced) [<a href="/pdf/2312.10716" title="Download PDF">pdf</a>, <a href="/format/2312.10716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Computationally Efficient Neural Video Compression Accelerator Based  on a Sparse CNN-Transformer Hybrid Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+S">Siyu Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Mao%2C+W">Wendong Mao</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+H">Huihong Shi</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zhongfeng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by DATE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item698">[698]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10737" title="Abstract">arXiv:2312.10737</a> (replaced) [<a href="/pdf/2312.10737" title="Download PDF">pdf</a>, <a href="/format/2312.10737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Traffic Incident Database with Multiple Labels Including Various  Perspective Environmental Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nishiyama%2C+S">Shota Nishiyama</a>, 
<a href="/search/cs?searchtype=author&query=Saito%2C+T">Takuma Saito</a>, 
<a href="/search/cs?searchtype=author&query=Nakamura%2C+R">Ryo Nakamura</a>, 
<a href="/search/cs?searchtype=author&query=Ohtani%2C+G">Go Ohtani</a>, 
<a href="/search/cs?searchtype=author&query=Kataoka%2C+H">Hirokatsu Kataoka</a>, 
<a href="/search/cs?searchtype=author&query=Hara%2C+K">Kensho Hara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference paper accepted to IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2023 Reason for revision: Corrected due to a missing space between sentences in the preview's abstract, which led to an unintended URL interpretation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item699">[699]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10793" title="Abstract">arXiv:2312.10793</a> (replaced) [<a href="/pdf/2312.10793" title="Download PDF">pdf</a>, <a href="/format/2312.10793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Instruction Mixture for Large Language Model  Fine-tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Renxi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Minghao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xudong Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chiyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haonan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Instruction Tuning, Large Language Model, Alignment
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item700">[700]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10798" title="Abstract">arXiv:2312.10798</a> (replaced) [<a href="/pdf/2312.10798" title="Download PDF">pdf</a>, <a href="/ps/2312.10798" title="Download PostScript">ps</a>, <a href="/format/2312.10798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Land use/land cover classification of fused Sentinel-1 and Sentinel-2  imageries using ensembles of Random Forests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pande%2C+S">Shivam Pande</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Thesis for Master of Technology. Created: July 2018. Total pages 124
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item701">[701]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10915" title="Abstract">arXiv:2312.10915</a> (replaced) [<a href="/pdf/2312.10915" title="Download PDF">pdf</a>, <a href="/format/2312.10915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relaxation schemes for entropy dissipative system of viscous  conservation laws
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+T">Tuowei Chen</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+J">Jiequan Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item702">[702]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11026" title="Abstract">arXiv:2312.11026</a> (replaced) [<a href="/pdf/2312.11026" title="Download PDF">pdf</a>, <a href="/format/2312.11026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MISA: Unveiling the Vulnerabilities in Split Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+W">Wei Wan</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+Y">Yuxuan Ning</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shengshan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+L">Lulu Xue</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Minghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L+Y">Leo Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hai Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item703">[703]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11075" title="Abstract">arXiv:2312.11075</a> (replaced) [<a href="/pdf/2312.11075" title="Download PDF">pdf</a>, <a href="/format/2312.11075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Split and Rephrase with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ponce%2C+D">David Ponce</a>, 
<a href="/search/cs?searchtype=author&query=Etchegoyhen%2C+T">Thierry Etchegoyhen</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+J+C">Jes&#xfa;s Calleja P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Gete%2C+H">Harritxu Gete</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item704">[704]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11111" title="Abstract">arXiv:2312.11111</a> (replaced) [<a href="/pdf/2312.11111" title="Download PDF">pdf</a>, <a href="/format/2312.11111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Good, The Bad, and Why: Unveiling Emotions in Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Cheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jindong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yixuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Kaijie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+W">Wenxin Hou</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+J">Jianxun Lian</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+F">Fang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qiang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report; an extension to EmotionPrompt (<a href="/abs/2307.11760">arXiv:2307.11760</a>); 34 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item705">[705]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11116" title="Abstract">arXiv:2312.11116</a> (replaced) [<a href="/pdf/2312.11116" title="Download PDF">pdf</a>, <a href="/format/2312.11116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implementation of the IIIF Presentation API 3.0 based on Software  Support: Use Case of an Incremental IIIF Deployment within a Citizen Science  Project
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raemy%2C+J+A">Julien Antoine Raemy</a>, 
<a href="/search/cs?searchtype=author&query=Demleitner%2C+A">Adrian Demleitner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Corrected typos. 12 pages, 5 figures. This is the preprint version of a conference paper that was accepted at EuroMed2022, the International Conference on Digital Heritage, that took place in Limassol, Cyprus between the 7th November and the 11th November 2022. The conference proceedings are due to be published by Springer Nature Publisher in the Lecture Notes in Computer Science (LNCS) series
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
</div>
</dd>
<dt><a name="item706">[706]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11193" title="Abstract">arXiv:2312.11193</a> (replaced) [<a href="/pdf/2312.11193" title="Download PDF">pdf</a>, <a href="/ps/2312.11193" title="Download PostScript">ps</a>, <a href="/format/2312.11193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Paraphrasing The Original Text&quot; Makes High Accuracy Long-Context QA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yijiong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Chinese version of this paper can be downloaded from (<a href="https://cloud.tsinghua.edu.cn/d/5894ec4442e54a6aac96/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item707">[707]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11229" title="Abstract">arXiv:2312.11229</a> (replaced) [<a href="/pdf/2312.11229" title="Download PDF">pdf</a>, <a href="/format/2312.11229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CaseGNN: Graph Neural Networks for Legal Case Retrieval with  Text-Attributed Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yanran Tang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+R">Ruihong Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yilun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xue Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zi Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item708">[708]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11274" title="Abstract">arXiv:2312.11274</a> (replaced) [<a href="/pdf/2312.11274" title="Download PDF">pdf</a>, <a href="/ps/2312.11274" title="Download PostScript">ps</a>, <a href="/format/2312.11274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Student Learning with Hybrid Human-AI Tutoring: A Three-Study  Quasi-Experimental Investigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thomas%2C+D+R">Danielle R. Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jionghao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Gatz%2C+E">Erin Gatz</a>, 
<a href="/search/cs?searchtype=author&query=Gurung%2C+A">Ashish Gurung</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Shivang Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Norberg%2C+K">Kole Norberg</a>, 
<a href="/search/cs?searchtype=author&query=Fancsali%2C+S+E">Stephen E. Fancsali</a>, 
<a href="/search/cs?searchtype=author&query=Aleven%2C+V">Vincent Aleven</a>, 
<a href="/search/cs?searchtype=author&query=Branstetter%2C+L">Lee Branstetter</a>, 
<a href="/search/cs?searchtype=author&query=Brunskill%2C+E">Emma Brunskill</a>, 
<a href="/search/cs?searchtype=author&query=Koedinger%2C+K+R">Kenneth R. Koedinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item709">[709]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11276" title="Abstract">arXiv:2312.11276</a> (replaced) [<a href="/pdf/2312.11276" title="Download PDF">pdf</a>, <a href="/format/2312.11276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Generalization for Multi-label Text Classification: A  Data-Augmentation Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chai%2C+Y">Yuyang Chai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiahui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fei Li</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+D">Donghong Ji</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+C">Chong Teng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item710">[710]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11297" title="Abstract">arXiv:2312.11297</a> (replaced) [<a href="/pdf/2312.11297" title="Download PDF">pdf</a>, <a href="/format/2312.11297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimised Storage for Datalog Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+P">Pan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Nenov%2C+Y">Yavor Nenov</a>, 
<a href="/search/cs?searchtype=author&query=Horrocks%2C+I">Ian Horrocks</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item711">[711]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11315" title="Abstract">arXiv:2312.11315</a> (replaced) [<a href="/pdf/2312.11315" title="Download PDF">pdf</a>, <a href="/format/2312.11315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CaRe-CNN: Cascading Refinement CNN for Myocardial Infarct Segmentation  with Microvascular Obstructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thaler%2C+F">Franz Thaler</a>, 
<a href="/search/cs?searchtype=author&query=Gsell%2C+M+A+F">Matthias A.F. Gsell</a>, 
<a href="/search/cs?searchtype=author&query=Plank%2C+G">Gernot Plank</a>, 
<a href="/search/cs?searchtype=author&query=Urschler%2C+M">Martin Urschler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at VISIGRAPP 2024, 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item712">[712]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11352" title="Abstract">arXiv:2312.11352</a> (replaced) [<a href="/pdf/2312.11352" title="Download PDF">pdf</a>, <a href="/format/2312.11352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safety verification of Neural-Network-based controllers: a set  invariance approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jouret%2C+L">Louis Jouret</a>, 
<a href="/search/eess?searchtype=author&query=Saoud%2C+A">Adnane Saoud</a>, 
<a href="/search/eess?searchtype=author&query=Olaru%2C+S">Sorin Olaru</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in: IEEE Control Systems Letters ( Early Access ) Electronic ISSN: 2475-1456
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item713">[713]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11359" title="Abstract">arXiv:2312.11359</a> (replaced) [<a href="/pdf/2312.11359" title="Download PDF">pdf</a>, <a href="/format/2312.11359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combining Game Design and Data Visualization to Inform Plastics Policy:  Fostering Collaboration between Science, Decision-Makers, and Artificial  Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pottinger%2C+A+S">A Samuel Pottinger</a>, 
<a href="/search/cs?searchtype=author&query=Biyani%2C+N">Nivedita Biyani</a>, 
<a href="/search/cs?searchtype=author&query=Geyer%2C+R">Roland Geyer</a>, 
<a href="/search/cs?searchtype=author&query=McCauley%2C+D+J">Douglas J McCauley</a>, 
<a href="/search/cs?searchtype=author&query=de+Bruyn%2C+M">Magali de Bruyn</a>, 
<a href="/search/cs?searchtype=author&query=Morse%2C+M+R">Molly R Morse</a>, 
<a href="/search/cs?searchtype=author&query=Nathan%2C+N">Neil Nathan</a>, 
<a href="/search/cs?searchtype=author&query=Koy%2C+K">Kevin Koy</a>, 
<a href="/search/cs?searchtype=author&query=Martinez%2C+C">Ciera Martinez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages of which 8 are citations, 4 figures, latex generated from markdown via Pandoc (<a href="https://pandoc.org/">this https URL</a>) for Arxiv
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item714">[714]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11376" title="Abstract">arXiv:2312.11376</a> (replaced) [<a href="/pdf/2312.11376" title="Download PDF">pdf</a>, <a href="/format/2312.11376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIM: Contrastive Language-Image Mosaic for Region Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Size Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lumin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Sheng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wentao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Loy%2C+C+C">Chen Change Loy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item715">[715]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11408" title="Abstract">arXiv:2312.11408</a> (replaced) [<a href="/pdf/2312.11408" title="Download PDF">pdf</a>, <a href="/format/2312.11408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approval-Based Committee Voting in Practice: A Case Study of  (Over-)Representation in the Polkadot Blockchain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boehmer%2C+N">Niclas Boehmer</a>, 
<a href="/search/cs?searchtype=author&query=Brill%2C+M">Markus Brill</a>, 
<a href="/search/cs?searchtype=author&query=Cevallos%2C+A">Alfonso Cevallos</a>, 
<a href="/search/cs?searchtype=author&query=Gehrlein%2C+J">Jonas Gehrlein</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez-Fern%C3%A1ndez%2C+L">Luis S&#xe1;nchez-Fern&#xe1;ndez</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt-Kraepelin%2C+U">Ulrike Schmidt-Kraepelin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item416">Cross-lists</a></li>
<li><a href="#item461">Replacements</a></li>
</ul>
<small>[ total of 715 entries:  <b>1-715</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2312">2312</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
