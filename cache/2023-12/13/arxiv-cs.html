<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Mon 11 Dec 23  to  Tue 12 Dec 23, announced Wed, 13 Dec 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item385">Cross-lists</a></li>
<li><a href="#item416">Replacements</a></li>
</ul>
<small>[ total of 644 entries:  <b>1-644</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Wed, 13 Dec 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06667" title="Abstract">arXiv:2312.06667</a> [<a href="/pdf/2312.06667" title="Download PDF">pdf</a>, <a href="/ps/2312.06667" title="Download PostScript">ps</a>, <a href="/format/2312.06667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Fault-Tolerant Quality-Guaranteed Sensor Deployments for UAV  Localization in Critical Areas via Computational Geometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esposito%2C+M">Marco Esposito</a>, 
<a href="/search/cs?searchtype=author&query=Mancini%2C+T">Toni Mancini</a>, 
<a href="/search/cs?searchtype=author&query=Tronci%2C+E">Enrico Tronci</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Systems, Man, and Cybernetics: Systems, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computational Geometry (cs.CG)

</div>
<p class="mathjax">The increasing spreading of small commercial Unmanned Aerial Vehicles (UAVs,
aka drones) presents serious threats for critical areas such as airports, power
plants, governmental and military facilities. In fact, such UAVs can easily
disturb or jam radio communications, collide with other flying objects, perform
espionage activity, and carry offensive payloads, e.g., weapons or explosives.
A central problem when designing surveillance solutions for the localization of
unauthorized UAVs in critical areas is to decide how many triangulating sensors
to use, and where to deploy them to optimise both coverage and cost
effectiveness.
<br />In this article, we compute deployments of triangulating sensors for UAV
localization, optimizing a given blend of metrics, namely: coverage under
multiple sensing quality levels, cost-effectiveness, fault-tolerance. We focus
on large, complex 3D regions, which exhibit obstacles (e.g., buildings),
varying terrain elevation, different coverage priorities, constraints on
possible sensors placement. Our novel approach relies on computational geometry
and statistical model checking, and enables the effective use of off-the-shelf
AI-based black-box optimizers. Moreover, our method allows us to compute a
closed-form, analytical representation of the region uncovered by a sensor
deployment, which provides the means for rigorous, formal certification of the
quality of the latter.
<br />We show the practical feasibility of our approach by computing optimal sensor
deployments for UAV localization in two large, complex 3D critical regions, the
Rome Leonardo Da Vinci International Airport (FCO) and the Vienna International
Center (VIC), using NOMAD as our state-of-the-art underlying optimization
engine. Results show that we can compute optimal sensor deployments within a
few hours on a standard workstation and within minutes on a small parallel
infrastructure.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06668" title="Abstract">arXiv:2312.06668</a> [<a href="/pdf/2312.06668" title="Download PDF">pdf</a>, <a href="/ps/2312.06668" title="Download PostScript">ps</a>, <a href="/format/2312.06668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Self-supervised Speech Models on a Taiwanese Hokkien Corpus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chou%2C+Y">Yi-Hui Chou</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kalvin Chang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Meng-Ju Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ou%2C+W">Winston Ou</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+A+W">Alice Wen-Hsin Bi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Carol Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B+Y">Bryan Y. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pai%2C+R">Rong-Wei Pai</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+P">Po-Yen Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Chiang%2C+J">Jo-Peng Chiang</a>, 
<a href="/search/cs?searchtype=author&query=Phoann%2C+I">Iu-Tshian Phoann</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+W">Winnie Chang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+C">Chenxuan Cui</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Noel Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jiatong Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ASRU 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Taiwanese Hokkien is declining in use and status due to a language shift
towards Mandarin in Taiwan. This is partly why it is a low resource language in
NLP and speech research today. To ensure that the state of the art in speech
processing does not leave Taiwanese Hokkien behind, we contribute a 1.5-hour
dataset of Taiwanese Hokkien to ML-SUPERB's hidden set. Evaluating ML-SUPERB's
suite of self-supervised learning (SSL) speech representations on our dataset,
we find that model size does not consistently determine performance. In fact,
certain smaller models outperform larger ones. Furthermore, linguistic
alignment between pretraining data and the target language plays a crucial
role.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06670" title="Abstract">arXiv:2312.06670</a> [<a href="/pdf/2312.06670" title="Download PDF">pdf</a>, <a href="/format/2312.06670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combating the effects of speed and delays in end-to-end self-driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tampuu%2C+A">Ardi Tampuu</a>, 
<a href="/search/cs?searchtype=author&query=Uduste%2C+I">Ilmar Uduste</a>, 
<a href="/search/cs?searchtype=author&query=Roosild%2C+K">Kristjan Roosild</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In the behavioral cloning approach to end-to-end driving, a dataset of expert
driving is collected and the model learns to guess what the expert would do in
different situations. Situations are summarized in observations and the outputs
are low or mid-level commands (e.g. brake, throttle, and steering; or
trajectories). The models learn to match observations at time T to actions
recorded at T or as simultaneously as possible. However, when deploying the
models to the real world (or to an asynchronous simulation), the action
predicted based on observations at time T gets applied at T + $\Delta$ T. In a
variety of cases, $\Delta$ T can be considerable and significantly influence
performance.
<br />We first demonstrate that driving at two different speeds is effectively two
different tasks. Delays partially cause this difference and linearly amplify
it. Even without computational delays, actuator delays and slipping due to
inertia result in the need to perform actions preemptively when driving fast.
The function mapping observations to commands becomes different compared to
slow driving. We experimentally show that models trained to drive fast cannot
perform the seemingly easier task of driving slow and vice-versa. Good driving
models may be judged to be poor due to testing them at "a safe low speed", a
task they cannot perform.
<br />Secondly, we show how to counteract the effect of delays in end-to-end
networks by changing the target labels. This is in contrast to the approaches
attempting to minimize the delays, i.e. the cause, not the effect. To exemplify
the problems and solutions in the real world, we use 1:10 scale minicars with
limited computing power, using behavioral cloning for end-to-end driving. Some
of the ideas discussed here may be transferable to the wider context of
self-driving, to vehicles with more compute power and end-to-mid or modular
approaches.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06674" title="Abstract">arXiv:2312.06674</a> [<a href="/pdf/2312.06674" title="Download PDF">pdf</a>, <a href="/format/2312.06674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Inan%2C+H">Hakan Inan</a>, 
<a href="/search/cs?searchtype=author&query=Upasani%2C+K">Kartikeya Upasani</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+J">Jianfeng Chi</a>, 
<a href="/search/cs?searchtype=author&query=Rungta%2C+R">Rashi Rungta</a>, 
<a href="/search/cs?searchtype=author&query=Iyer%2C+K">Krithika Iyer</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yuning Mao</a>, 
<a href="/search/cs?searchtype=author&query=Tontchev%2C+M">Michael Tontchev</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Fuller%2C+B">Brian Fuller</a>, 
<a href="/search/cs?searchtype=author&query=Testuggine%2C+D">Davide Testuggine</a>, 
<a href="/search/cs?searchtype=author&query=Khabsa%2C+M">Madian Khabsa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We introduce Llama Guard, an LLM-based input-output safeguard model geared
towards Human-AI conversation use cases. Our model incorporates a safety risk
taxonomy, a valuable tool for categorizing a specific set of safety risks found
in LLM prompts (i.e., prompt classification). This taxonomy is also
instrumental in classifying the responses generated by LLMs to these prompts, a
process we refer to as response classification. For the purpose of both prompt
and response classification, we have meticulously gathered a dataset of high
quality. Llama Guard, a Llama2-7b model that is instruction-tuned on our
collected dataset, albeit low in volume, demonstrates strong performance on
existing benchmarks such as the OpenAI Moderation Evaluation dataset and
ToxicChat, where its performance matches or exceeds that of currently available
content moderation tools. Llama Guard functions as a language model, carrying
out multi-class classification and generating binary decision scores.
Furthermore, the instruction fine-tuning of Llama Guard allows for the
customization of tasks and the adaptation of output formats. This feature
enhances the model's capabilities, such as enabling the adjustment of taxonomy
categories to align with specific use cases, and facilitating zero-shot or
few-shot prompting with diverse taxonomies at the input. We are making Llama
Guard model weights available and we encourage researchers to further develop
and adapt them to meet the evolving needs of the community for AI safety.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06677" title="Abstract">arXiv:2312.06677</a> [<a href="/pdf/2312.06677" title="Download PDF">pdf</a>, <a href="/format/2312.06677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligent Virtual Assistants with LLM-based Process Automation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+Y">Yanchu Guan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+Z">Zhixuan Chu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+F">Feiyue Ni</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+R">Ruihua Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Longfei Li</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinjie Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+C">Chenyi Zhuang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">While intelligent virtual assistants like Siri, Alexa, and Google Assistant
have become ubiquitous in modern life, they still face limitations in their
ability to follow multi-step instructions and accomplish complex goals
articulated in natural language. However, recent breakthroughs in large
language models (LLMs) show promise for overcoming existing barriers by
enhancing natural language processing and reasoning capabilities. Though
promising, applying LLMs to create more advanced virtual assistants still faces
challenges like ensuring robust performance and handling variability in
real-world user commands. This paper proposes a novel LLM-based virtual
assistant that can automatically perform multi-step operations within mobile
apps based on high-level user requests. The system represents an advance in
assistants by providing an end-to-end solution for parsing instructions,
reasoning about goals, and executing actions. LLM-based Process Automation
(LLMPA) has modules for decomposing instructions, generating descriptions,
detecting interface elements, predicting next actions, and error checking.
Experiments demonstrate the system completing complex mobile operation tasks in
Alipay based on natural language instructions. This showcases how large
language models can enable automated assistants to accomplish real-world tasks.
The main contributions are the novel LLMPA architecture optimized for app
process automation, the methodology for applying LLMs to mobile apps, and
demonstrations of multi-step task completion in a real-world environment.
Notably, this work represents the first real-world deployment and extensive
evaluation of a large language model-based virtual assistant in a widely used
mobile application with an enormous user base numbering in the hundreds of
millions.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06680" title="Abstract">arXiv:2312.06680</a> [<a href="/pdf/2312.06680" title="Download PDF">pdf</a>, <a href="/format/2312.06680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perceptual Similarity guidance and text guidance optimization for  Editing Real Images using Guided Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruichen Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">When using a diffusion model for image editing, there are times when the
modified image can differ greatly from the source. To address this, we apply a
dual-guidance approach to maintain high fidelity to the original in areas that
are not altered. First, we employ text-guided optimization, using text
embeddings to direct latent space and classifier-free guidance. Second, we use
perceptual similarity guidance, optimizing latent vectors with posterior
sampling via Tweedie formula during the reverse process. This method ensures
the realistic rendering of both the edited elements and the preservation of the
unedited parts of the original image.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06681" title="Abstract">arXiv:2312.06681</a> [<a href="/pdf/2312.06681" title="Download PDF">pdf</a>, <a href="/format/2312.06681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Steering Llama 2 via Contrastive Activation Addition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rimsky%2C+N">Nina Rimsky</a>, 
<a href="/search/cs?searchtype=author&query=Gabrieli%2C+N">Nick Gabrieli</a>, 
<a href="/search/cs?searchtype=author&query=Schulz%2C+J">Julian Schulz</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+M">Meg Tong</a>, 
<a href="/search/cs?searchtype=author&query=Hubinger%2C+E">Evan Hubinger</a>, 
<a href="/search/cs?searchtype=author&query=Turner%2C+A+M">Alexander Matt Turner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce Contrastive Activation Addition (CAA), an innovative method for
steering language models by modifying activations during their forward passes.
CAA computes ``steering vectors'' by averaging the difference in residual
stream activations between pairs of positive and negative examples of a
particular behavior such as factual versus hallucinatory responses. During
inference, these steering vectors are added at all token positions after the
user's prompt with either a positive or negative coefficient, allowing precise
control over the degree of the targeted behavior. We evaluate CAA's
effectiveness on Llama 2 Chat using both multiple-choice behavioral question
datasets and open-ended generation tasks. We demonstrate that CAA significantly
alters model behavior, outperforms traditional methods like finetuning and
few-shot prompting, and minimally reduces capabilities. Moreover, by employing
various activation space interpretation methods, we gain deeper insights into
CAA's mechanisms. CAA both accurately steers model outputs and also sheds light
on how high-level concepts are represented in Large Language Models (LLMs).
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06682" title="Abstract">arXiv:2312.06682</a> [<a href="/pdf/2312.06682" title="Download PDF">pdf</a>, <a href="/format/2312.06682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Denoise Unreliable Interactions for Link Prediction on  Biomedical Knowledge Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Tengfei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yujie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+W">Wen Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">Dashun Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xuan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+P+C">Patrick Cheong-lao Pang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yijun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+B">Bosheng Song</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xiangxiang Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Link prediction in biomedical knowledge graphs (KGs) aims at predicting
unknown interactions between entities, including drug-target interaction (DTI)
and drug-drug interaction (DDI), which is critical for drug discovery and
therapeutics. Previous methods prefer to utilize the rich semantic relations
and topological structure of the KG to predict missing links, yielding
promising outcomes. However, all these works only focus on improving the
predictive performance without considering the inevitable noise and unreliable
interactions existing in the KGs, which limits the development of KG-based
computational methods. To address these limitations, we propose a Denoised Link
Prediction framework, called DenoisedLP. DenoisedLP obtains reliable
interactions based on the local subgraph by denoising noisy links in a
learnable way, providing a universal module for mining underlying task-relevant
relations. To collaborate with the smoothed semantic information, DenoisedLP
introduces the semantic subgraph by blurring conflict relations around the
predicted link. By maximizing the mutual information between the reliable
structure and smoothed semantic relations, DenoisedLP emphasizes the
informative interactions for predicting relation-specific links. Experimental
results on real-world datasets demonstrate that DenoisedLP outperforms
state-of-the-art methods on DTI and DDI prediction tasks, and verify the
effectiveness and robustness of denoising unreliable interactions on the
contaminated KGs.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06683" title="Abstract">arXiv:2312.06683</a> [<a href="/pdf/2312.06683" title="Download PDF">pdf</a>, <a href="/format/2312.06683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AT4CTR: Auxiliary Match Tasks for Enhancing Click-Through Rate  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+X">Xuyang Hou</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+D">Defu Lian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Haoran Jin</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jia Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+J">Jun Lei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Click-through rate (CTR) prediction is a vital task in industry advertising
systems. Most existing methods focus on the structure design of neural network
for better accuracy and suffer from the data sparsity problem. Especially in
industry advertising systems, the widely applied negative sample downsampling
technique due to resource limitation worsens the problem, resulting in a
decline in performance. In this paper, we propose \textbf{A}uxiliary Match
\textbf{T}asks for enhancing \textbf{C}lick-\textbf{T}hrough \textbf{R}ate
performance (AT4CTR) to alleviate the data sparsity problem. Specifically, we
design two match tasks inspired by collaborative filtering to enhance the
relevance between user and item. As the "click" action is a strong signal which
indicates user's preference towards item directly, we make the first match task
aim at pulling closer the representation between user and item regarding the
positive samples. Since the user's past click behaviors can also be treated as
the user him/herself, we apply the next item prediction as the second match
task. For both the match tasks, we choose the InfoNCE in contrastive learning
as their loss function. The two match tasks can provide meaningful training
signals to speed up the model's convergence and alleviate the data sparsity. We
conduct extensive experiments on a public dataset and a large-scale industry
advertising dataset. The results demonstrate the effectiveness of the proposed
auxiliary match tasks. AT4CTR has been deployed in the real industry
advertising system and gains remarkable revenue.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06684" title="Abstract">arXiv:2312.06684</a> [<a href="/pdf/2312.06684" title="Download PDF">pdf</a>, <a href="/format/2312.06684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced E-Commerce Attribute Extraction: Innovating with Decorative  Relation Correction and LLAMA 2.0-Based Annotation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jianghong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Weizhi Du</a>, 
<a href="/search/cs?searchtype=author&query=Rokon%2C+M+O+F">Md Omar Faruk Rokon</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaodong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiaxuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+I">Isha Shah</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kuang-chih Lee</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+M">Musen Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 images
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The rapid proliferation of e-commerce platforms accentuates the need for
advanced search and retrieval systems to foster a superior user experience.
Central to this endeavor is the precise extraction of product attributes from
customer queries, enabling refined search, comparison, and other crucial
e-commerce functionalities. Unlike traditional Named Entity Recognition (NER)
tasks, e-commerce queries present a unique challenge owing to the intrinsic
decorative relationship between product types and attributes. In this study, we
propose a pioneering framework that integrates BERT for classification, a
Conditional Random Fields (CRFs) layer for attribute value extraction, and
Large Language Models (LLMs) for data annotation, significantly advancing
attribute recognition from customer inquiries. Our approach capitalizes on the
robust representation learning of BERT, synergized with the sequence decoding
prowess of CRFs, to adeptly identify and extract attribute values. We introduce
a novel decorative relation correction mechanism to further refine the
extraction process based on the nuanced relationships between product types and
attributes inherent in e-commerce data. Employing LLMs, we annotate additional
data to expand the model's grasp and coverage of diverse attributes. Our
methodology is rigorously validated on various datasets, including Walmart,
BestBuy's e-commerce NER dataset, and the CoNLL dataset, demonstrating
substantial improvements in attribute recognition performance. Particularly,
the model showcased promising results during a two-month deployment in
Walmart's Sponsor Product Search, underscoring its practical utility and
effectiveness.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06685" title="Abstract">arXiv:2312.06685</a> [<a href="/pdf/2312.06685" title="Download PDF">pdf</a>, <a href="/format/2312.06685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal-CoG: A Causal-Effect Look at Context Generation for Boosting  Multi-modal Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shitian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuowan Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yadong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Yuille%2C+A">Alan Yuille</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">While Multi-modal Language Models (MLMs) demonstrate impressive multimodal
ability, they still struggle on providing factual and precise responses for
tasks like visual question answering (VQA). In this paper, we address this
challenge from the perspective of contextual information. We propose Causal
Context Generation, Causal-CoG, which is a prompting strategy that engages
contextual information to enhance precise VQA during inference. Specifically,
we prompt MLMs to generate contexts, i.e, text description of an image, and
engage the generated contexts for question answering. Moreover, we investigate
the advantage of contexts on VQA from a causality perspective, introducing
causality filtering to select samples for which contextual information is
helpful. To show the effectiveness of Causal-CoG, we run extensive experiments
on 10 multimodal benchmarks and show consistent improvements, e.g., +6.30% on
POPE, +13.69% on Vizwiz and +6.43% on VQAv2 compared to direct decoding,
surpassing existing methods. We hope Casual-CoG inspires explorations of
context knowledge in multimodal models, and serves as a plug-and-play strategy
for MLM decoding.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06686" title="Abstract">arXiv:2312.06686</a> [<a href="/pdf/2312.06686" title="Download PDF">pdf</a>, <a href="/format/2312.06686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robo360: A 3D Omnispective Multi-Material Robotic Manipulation Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+L">Litian Liang</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+L">Liuyu Bian</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Caiwei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jialin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Linghao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+I">Isabella Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+F">Fanbo Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhiao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hao Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Building robots that can automate labor-intensive tasks has long been the
core motivation behind the advancements in computer vision and the robotics
community. Recent interest in leveraging 3D algorithms, particularly neural
fields, has led to advancements in robot perception and physical understanding
in manipulation scenarios. However, the real world's complexity poses
significant challenges. To tackle these challenges, we present Robo360, a
dataset that features robotic manipulation with a dense view coverage, which
enables high-quality 3D neural representation learning, and a diverse set of
objects with various physical and optical properties and facilitates research
in various object manipulation and physical world modeling tasks. We confirm
the effectiveness of our dataset using existing dynamic NeRF and evaluate its
potential in learning multi-view policies. We hope that Robo360 can open new
research directions yet to be explored at the intersection of understanding the
physical world in 3D and robot control.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06689" title="Abstract">arXiv:2312.06689</a> [<a href="/pdf/2312.06689" title="Download PDF">pdf</a>, <a href="/format/2312.06689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Introduction to IoT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ananna%2C+T+N">Tajkia Nuri Ananna</a>, 
<a href="/search/cs?searchtype=author&query=Saifuzzaman%2C+M">Munshi Saifuzzaman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 63 pages, 6 figures, 7 tables, chapter 1 revised version of "IoT and ML for Information Management: A Smart Healthcare Perspective" under the Springer Studies in Computational Intelligence series
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The Internet of Things (IoT) has rapidly transformed the 21st century,
enhancing decision-making processes and introducing innovative consumer
services such as pay-as-you-use models. This integration of smart devices and
automation technologies has revolutionized our lives. However, it is essential
to recognize the significant concerns surrounding security, privacy,
intellectual property rights, safety, and trust in this technological
landscape, which require further exploration. This chapter serves as a
comprehensive guide to newcomers interested in the IoT domain, providing a
foundation for making future contributions. It begins by explaining the core
concept of IoT, its historical evolution, network components, and key
characteristics. The advantages of IoT deployment across various domains are
discussed, along with an introduction to the foundational layered architectures
supporting IoT. The chapter also delves into the taxonomy of IoT technologies,
encompassing hardware, software, wireless communication technologies, hardware
platforms, and cloud solutions. Existing applications in major domains like
smart cities, healthcare, and agriculture are explored, offering a broad
perspective on the IoT's application potential. In addressing prevalent issues
and challenges in designing and deploying IoT applications, the chapter
examines security threats across architectural layers, ethical considerations,
user privacy concerns, and trust-related issues. This discussion equips
researchers with a solid understanding of diverse IoT aspects, providing a
strong foundation for both practical IoT projects and the development of novel
theoretical approaches within the IoT field.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06695" title="Abstract">arXiv:2312.06695</a> [<a href="/pdf/2312.06695" title="Download PDF">pdf</a>, <a href="/format/2312.06695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolving Reservoirs for Meta Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%A9ger%2C+C">Corentin L&#xe9;ger</a>, 
<a href="/search/cs?searchtype=author&query=Hamon%2C+G">Gautier Hamon</a>, 
<a href="/search/cs?searchtype=author&query=Nisioti%2C+E">Eleni Nisioti</a>, 
<a href="/search/cs?searchtype=author&query=Hinaut%2C+X">Xavier Hinaut</a>, 
<a href="/search/cs?searchtype=author&query=Moulin-Frier%2C+C">Cl&#xe9;ment Moulin-Frier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Animals often demonstrate a remarkable ability to adapt to their environments
during their lifetime. They do so partly due to the evolution of morphological
and neural structures. These structures capture features of environments shared
between generations to bias and speed up lifetime learning. In this work, we
propose a computational model for studying a mechanism that can enable such a
process. We adopt a computational framework based on meta reinforcement
learning as a model of the interplay between evolution and development. At the
evolutionary scale, we evolve reservoirs, a family of recurrent neural networks
that differ from conventional networks in that one optimizes not the weight
values but hyperparameters of the architecture: the later control macro-level
properties, such as memory and dynamics. At the developmental scale, we employ
these evolved reservoirs to facilitate the learning of a behavioral policy
through Reinforcement Learning (RL). Within an RL agent, a reservoir encodes
the environment state before providing it to an action policy. We evaluate our
approach on several 2D and 3D simulated environments. Our results show that the
evolution of reservoirs can improve the learning of diverse challenging tasks.
We study in particular three hypotheses: the use of an architecture combining
reservoirs and reinforcement learning could enable (1) solving tasks with
partial observability, (2) generating oscillatory dynamics that facilitate the
learning of locomotion tasks, and (3) facilitating the generalization of
learned behaviors to new tasks unknown during the evolution phase.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06697" title="Abstract">arXiv:2312.06697</a> [<a href="/pdf/2312.06697" title="Download PDF">pdf</a>, <a href="/ps/2312.06697" title="Download PostScript">ps</a>, <a href="/format/2312.06697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance of externally validated machine learning models based on  histopathology images for the diagnosis, classification, prognosis, or  treatment outcome prediction in female breast cancer: A systematic review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+R">Ricardo Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Nejat%2C+P">Peyman Nejat</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+A">Ashirbani Saha</a>, 
<a href="/search/cs?searchtype=author&query=Campbell%2C+C+J+V">Clinton J.V. Campbell</a>, 
<a href="/search/cs?searchtype=author&query=Norgan%2C+A+P">Andrew P. Norgan</a>, 
<a href="/search/cs?searchtype=author&query=Lokker%2C+C">Cynthia Lokker</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Pathology Informatics. 2023;15:100348
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Numerous machine learning (ML) models have been developed for breast cancer
using various types of data. Successful external validation (EV) of ML models
is important evidence of their generalizability. The aim of this systematic
review was to assess the performance of externally validated ML models based on
histopathology images for diagnosis, classification, prognosis, or treatment
outcome prediction in female breast cancer. A systematic search of MEDLINE,
EMBASE, CINAHL, IEEE, MICCAI, and SPIE conferences was performed for studies
published between January 2010 and February 2022. The Prediction Model Risk of
Bias Assessment Tool (PROBAST) was employed, and the results were narratively
described. Of the 2011 non-duplicated citations, 8 journal articles and 2
conference proceedings met inclusion criteria. Three studies externally
validated ML models for diagnosis, 4 for classification, 2 for prognosis, and 1
for both classification and prognosis. Most studies used Convolutional Neural
Networks and one used logistic regression algorithms. For
diagnostic/classification models, the most common performance metrics reported
in the EV were accuracy and area under the curve, which were greater than 87%
and 90%, respectively, using pathologists' annotations as ground truth. The
hazard ratios in the EV of prognostic ML models were between 1.7 (95% CI,
1.2-2.6) and 1.8 (95% CI, 1.3-2.7) to predict distant disease-free survival;
1.91 (95% CI, 1.11-3.29) for recurrence, and between 0.09 (95% CI, 0.01-0.70)
and 0.65 (95% CI, 0.43-0.98) for overall survival, using clinical data as
ground truth. Despite EV being an important step before the clinical
application of a ML model, it hasn't been performed routinely. The large
variability in the training/validation datasets, methods, performance metrics,
and reported information limited the comparison of the models and the analysis
of their results (...)
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06699" title="Abstract">arXiv:2312.06699</a> [<a href="/pdf/2312.06699" title="Download PDF">pdf</a>, <a href="/format/2312.06699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Generative Language Models for Weakly Supervised Sentence  Component Analysis in Video-Language Joint Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hakim%2C+Z+I+A">Zaber Ibn Abdul Hakim</a>, 
<a href="/search/cs?searchtype=author&query=Sarker%2C+N+H">Najibul Haque Sarker</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+R+P">Rahul Pratap Singh</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+B">Bishmoy Paul</a>, 
<a href="/search/cs?searchtype=author&query=Dabouei%2C+A">Ali Dabouei</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Min Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">A thorough comprehension of textual data is a fundamental element in
multi-modal video analysis tasks. However, recent works have shown that the
current models do not achieve a comprehensive understanding of the textual data
during the training for the target downstream tasks. Orthogonal to the previous
approaches to this limitation, we postulate that understanding the significance
of the sentence components according to the target task can potentially enhance
the performance of the models. Hence, we utilize the knowledge of a pre-trained
large language model (LLM) to generate text samples from the original ones,
targeting specific sentence components. We propose a weakly supervised
importance estimation module to compute the relative importance of the
components and utilize them to improve different video-language tasks. Through
rigorous quantitative analysis, our proposed method exhibits significant
improvement across several video-language tasks. In particular, our approach
notably enhances video-text retrieval by a relative improvement of 8.3\% in
video-to-text and 1.4\% in text-to-video retrieval over the baselines, in terms
of R@1. Additionally, in video moment retrieval, average mAP shows a relative
improvement ranging from 2.0\% to 13.7 \% across different baselines.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06700" title="Abstract">arXiv:2312.06700</a> [<a href="/pdf/2312.06700" title="Download PDF">pdf</a>, <a href="/ps/2312.06700" title="Download PostScript">ps</a>, <a href="/format/2312.06700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and Architecture for a Centralized, Extensible, and Configurable  Scoring Application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanwal%2C+S">Sumit Sanwal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">In modern-day organizations, many software applications require critical
input to decide the next steps in the application workflow and approval. One of
the most important inputs to decide the subsequent course of action is the key
performance indicator-based scoring for the entities used in the application.
Computing the right score for the entities in the application is a critical
step that will drive the subsequent processing and help to decide the next
course of action for the entity accurately. Computing the right score is a
critical parameter for application processing; deriving the precise and correct
score is crucial and pivotal for the application's intended objective; this
mandates a very efficient and optimized scoring application in place and is of
paramount importance for the success of such applications. We will discuss in
this article how to envision and design a generic, extensible scoring engine
and a few use cases for scoring with the associated intricacies and
complexities to implement the scoring framework.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06701" title="Abstract">arXiv:2312.06701</a> [<a href="/pdf/2312.06701" title="Download PDF">pdf</a>, <a href="/format/2312.06701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Adversarial Attacks on Autonomous Driving Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chahe%2C+A">Amirhosein Chahe</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jeyapratap%2C+A">Abhishek Jeyapratap</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kaidi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Lifeng Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper introduces an attacking mechanism to challenge the resilience of
autonomous driving systems. Specifically, we manipulate the decision-making
processes of an autonomous vehicle by dynamically displaying adversarial
patches on a screen mounted on another moving vehicle. These patches are
optimized to deceive the object detection models into misclassifying targeted
objects, e.g., traffic signs. Such manipulation has significant implications
for critical multi-vehicle interactions such as intersection crossing and lane
changing, which are vital for safe and efficient autonomous driving systems.
Particularly, we make four major contributions. First, we introduce a novel
adversarial attack approach where the patch is not co-located with its target,
enabling more versatile and stealthy attacks. Moreover, our method utilizes
dynamic patches displayed on a screen, allowing for adaptive changes and
movement, enhancing the flexibility and performance of the attack. To do so, we
design a Screen Image Transformation Network (SIT-Net), which simulates
environmental effects on the displayed images, narrowing the gap between
simulated and real-world scenarios. Further, we integrate a positional loss
term into the adversarial training process to increase the success rate of the
dynamic attack. Finally, we shift the focus from merely attacking perceptual
systems to influencing the decision-making algorithms of self-driving systems.
Our experiments demonstrate the first successful implementation of such dynamic
adversarial attacks in real-world autonomous driving scenarios, paving the way
for advancements in the field of robust and secure autonomous driving.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06703" title="Abstract">arXiv:2312.06703</a> [<a href="/pdf/2312.06703" title="Download PDF">pdf</a>, <a href="/format/2312.06703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenSD: Unified Open-Vocabulary Segmentation and Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuai Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Minghan Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengfei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, a few open-vocabulary methods have been proposed by employing a
unified architecture to tackle generic segmentation and detection tasks.
However, their performance still lags behind the task-specific models due to
the conflict between different tasks, and their open-vocabulary capability is
limited due to the inadequate use of CLIP. To address these challenges, we
present a universal transformer-based framework, abbreviated as OpenSD, which
utilizes the same architecture and network parameters to handle open-vocabulary
segmentation and detection tasks. First, we introduce a decoder decoupled
learning strategy to alleviate the semantic conflict between thing and staff
categories so that each individual task can be learned more effectively under
the same framework. Second, to better leverage CLIP for end-to-end segmentation
and detection, we propose dual classifiers to handle the in-vocabulary domain
and out-of-vocabulary domain, respectively. The text encoder is further trained
to be region-aware for both thing and stuff categories through decoupled prompt
learning, enabling them to filter out duplicated and low-quality predictions,
which is important to end-to-end segmentation and detection. Extensive
experiments are conducted on multiple datasets under various circumstances. The
results demonstrate that OpenSD outperforms state-of-the-art open-vocabulary
segmentation and detection methods in both closed- and open-vocabulary
settings. Code is available at https://github.com/strongwolf/OpenSD
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06704" title="Abstract">arXiv:2312.06704</a> [<a href="/pdf/2312.06704" title="Download PDF">pdf</a>, <a href="/format/2312.06704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SIFU: Side-view Conditioned Implicit Function for Real-world Usable  Clothed Human Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zechuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zongxin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page <a href="https://river-zhang.github.io/SIFU-projectpage/">this https URL</a> ;
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Creating high-quality 3D models of clothed humans from single images for
real-world applications is crucial. Despite recent advancements, accurately
reconstructing humans in complex poses or with loose clothing from in-the-wild
images, along with predicting textures for unseen areas, remains a significant
challenge. A key limitation of previous methods is their insufficient prior
guidance in transitioning from 2D to 3D and in texture prediction. In response,
we introduce SIFU (Side-view Conditioned Implicit Function for Real-world
Usable Clothed Human Reconstruction), a novel approach combining a Side-view
Decoupling Transformer with a 3D Consistent Texture Refinement pipeline.SIFU
employs a cross-attention mechanism within the transformer, using SMPL-X
normals as queries to effectively decouple side-view features in the process of
mapping 2D features to 3D. This method not only improves the precision of the
3D models but also their robustness, especially when SMPL-X estimates are not
perfect. Our texture refinement process leverages text-to-image diffusion-based
prior to generate realistic and consistent textures for invisible views.
Through extensive experiments, SIFU surpasses SOTA methods in both geometry and
texture reconstruction, showcasing enhanced robustness in complex scenarios and
achieving an unprecedented Chamfer and P2S measurement. Our approach extends to
practical applications such as 3D printing and scene building, demonstrating
its broad utility in real-world scenarios. Project page
https://river-zhang.github.io/SIFU-projectpage/ .
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06705" title="Abstract">arXiv:2312.06705</a> [<a href="/pdf/2312.06705" title="Download PDF">pdf</a>, <a href="/format/2312.06705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perceiving University Student&#x27;s Opinions from Google App Reviews
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ranjan%2C+S">Sakshi Ranjan</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Subhankar Mishra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Concurrency and Computation Practice and Experience
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Concurrency and Computation: Practice and Experience, 34(10),
  p.e6800 (2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Google app market captures the school of thought of users from every corner
of the globe via ratings and text reviews, in a multilinguistic arena. The
potential information from the reviews cannot be extracted manually, due to its
exponential growth. So, Sentiment analysis, by machine learning and deep
learning algorithms employing NLP, explicitly uncovers and interprets the
emotions. This study performs the sentiment classification of the app reviews
and identifies the university student's behavior towards the app market via
exploratory analysis. We applied machine learning algorithms using the TP, TF,
and TF IDF text representation scheme and evaluated its performance on Bagging,
an ensemble learning method. We used word embedding, Glove, on the deep
learning paradigms. Our model was trained on Google app reviews and tested on
Student's App Reviews(SAR). The various combinations of these algorithms were
compared amongst each other using F score and accuracy and inferences were
highlighted graphically. SVM, amongst other classifiers, gave fruitful
accuracy(93.41%), F score(89%) on bigram and TF IDF scheme. Bagging enhanced
the performance of LR and NB with accuracy of 87.88% and 86.69% and F score of
86% and 78% respectively. Overall, LSTM on Glove embedding recorded the highest
accuracy(95.2%) and F score(88%).
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06706" title="Abstract">arXiv:2312.06706</a> [<a href="/pdf/2312.06706" title="Download PDF">pdf</a>, <a href="/format/2312.06706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UNeR3D: Versatile and Scalable 3D RGB Point Cloud Generation from 2D  Images in Unsupervised Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hongbin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Juangui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qingfeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhengyu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Handing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yunzhi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yongjun Hu</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Z">Zhenguo Nie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the realm of 3D reconstruction from 2D images, a persisting challenge is
to achieve high-precision reconstructions devoid of 3D Ground Truth data
reliance. We present UNeR3D, a pioneering unsupervised methodology that sets a
new standard for generating detailed 3D reconstructions solely from 2D views.
Our model significantly cuts down the training costs tied to supervised
approaches and introduces RGB coloration to 3D point clouds, enriching the
visual experience. Employing an inverse distance weighting technique for color
rendering, UNeR3D ensures seamless color transitions, enhancing visual
fidelity. Our model's flexible architecture supports training with any number
of views, and uniquely, it is not constrained by the number of views used
during training when performing reconstructions. It can infer with an arbitrary
count of views during inference, offering unparalleled versatility.
Additionally, the model's continuous spatial input domain allows the generation
of point clouds at any desired resolution, empowering the creation of
high-resolution 3D RGB point clouds. We solidify the reconstruction process
with a novel multi-view geometric loss and color loss, demonstrating that our
model excels with single-view inputs and beyond, thus reshaping the paradigm of
unsupervised learning in 3D vision. Our contributions signal a substantial leap
forward in 3D vision, offering new horizons for content creation across diverse
applications. Code is available at https://github.com/HongbinLin3589/UNeR3D.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06707" title="Abstract">arXiv:2312.06707</a> [<a href="/pdf/2312.06707" title="Download PDF">pdf</a>, <a href="/format/2312.06707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Public&#x27;s Perception of Safety and Video Surveillance  Technology: A Survey Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ardabili%2C+B+R">Babak Rahimi Ardabili</a>, 
<a href="/search/cs?searchtype=author&query=Pazho%2C+A+D">Armin Danesh Pazho</a>, 
<a href="/search/cs?searchtype=author&query=Noghre%2C+G+A">Ghazal Alinezhad Noghre</a>, 
<a href="/search/cs?searchtype=author&query=Katariya%2C+V">Vinit Katariya</a>, 
<a href="/search/cs?searchtype=author&query=Hull%2C+G">Gordon Hull</a>, 
<a href="/search/cs?searchtype=author&query=Reid%2C+S">Shannon Reid</a>, 
<a href="/search/cs?searchtype=author&query=Tabkhi%2C+H">Hamed Tabkhi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Addressing public safety effectively requires incorporating diverse
stakeholder perspectives, particularly those of the community, which are often
underrepresented compared to other stakeholders. This study presents a
comprehensive analysis of the community's general public safety concerns, their
view of existing surveillance technologies, and their perception of AI-driven
solutions for enhancing safety in urban environments, focusing on Charlotte,
NC. Through a survey approach, including in-person surveys conducted in August
and September 2023 with 410 participants, this research investigates
demographic factors such as age, gender, ethnicity, and educational level to
gain insights into public perception and concerns toward public safety and
possible solutions. Based on the type of dependent variables, we utilized
different statistical and significance analyses, such as logit regression and
ordinal logistic regression, to explore the effects of demographic factors on
the various dependent variables. Our results reveal demographic differences in
public safety concerns. Younger females tend to feel less secure yet trust
existing video surveillance systems, whereas older, educated individuals are
more concerned about violent crimes in malls. Additionally, attitudes towards
AI-driven surveillance differ: older Black individuals demonstrate support for
it despite having concerns about data privacy, while educated females show a
tendency towards skepticism.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06708" title="Abstract">arXiv:2312.06708</a> [<a href="/pdf/2312.06708" title="Download PDF">pdf</a>, <a href="/format/2312.06708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neutral Editing Framework for Diffusion-based Video Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S">Sunjae Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Koo%2C+G">Gwanhyeong Koo</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+J+W">Ji Woo Hong</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+C+D">Chang D. Yoo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-conditioned image editing has succeeded in various types of editing
based on a diffusion framework. Unfortunately, this success did not carry over
to a video, which continues to be challenging. Existing video editing systems
are still limited to rigid-type editing such as style transfer and object
overlay. To this end, this paper proposes Neutral Editing (NeuEdit) framework
to enable complex non-rigid editing by changing the motion of a person/object
in a video, which has never been attempted before. NeuEdit introduces a concept
of `neutralization' that enhances a tuning-editing process of diffusion-based
editing systems in a model-agnostic manner by leveraging input video and text
without any other auxiliary aids (e.g., visual masks, video captions).
Extensive experiments on numerous videos demonstrate adaptability and
effectiveness of the NeuEdit framework. The website of our work is available
here: https://neuedit.github.io
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06709" title="Abstract">arXiv:2312.06709</a> [<a href="/pdf/2312.06709" title="Download PDF">pdf</a>, <a href="/format/2312.06709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AM-RADIO: Agglomerative Model -- Reduce All Domains Into One
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ranzinger%2C+M">Mike Ranzinger</a>, 
<a href="/search/cs?searchtype=author&query=Heinrich%2C+G">Greg Heinrich</a>, 
<a href="/search/cs?searchtype=author&query=Kautz%2C+J">Jan Kautz</a>, 
<a href="/search/cs?searchtype=author&query=Molchanov%2C+P">Pavlo Molchanov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">A handful of visual foundation models (VFMs) have recently emerged as the
backbones for numerous downstream tasks. VFMs like CLIP, DINOv2, SAM are
trained with distinct objectives, exhibiting unique characteristics for various
downstream tasks. We find that despite their conceptual differences, these
models can be effectively merged into a unified model through multi-teacher
distillation. We name this approach AM-RADIO (Agglomerative Model -- Reduce All
Domains Into One). This integrative approach not only surpasses the performance
of individual teacher models but also amalgamates their distinctive features,
such as zero-shot vision-language comprehension, detailed pixel-level
understanding, and open vocabulary segmentation capabilities. In pursuit of the
most hardware-efficient backbone, we evaluated numerous architectures in our
multi-teacher distillation pipeline using the same training recipe. This led to
the development of a novel architecture (E-RADIO) that exceeds the performance
of its predecessors and is at least 7x faster than the teacher models. Our
comprehensive benchmarking process covers downstream tasks including ImageNet
classification, ADE20k semantic segmentation, COCO object detection and
LLaVa-1.5 framework.
<br />Code: https://github.com/NVlabs/RADIO
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06710" title="Abstract">arXiv:2312.06710</a> [<a href="/pdf/2312.06710" title="Download PDF">pdf</a>, <a href="/format/2312.06710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Class-Prototype Conditional Diffusion Model for Continual Learning with  Generative Replay
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doan%2C+K">Khanh Doan</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+Q">Quyen Tran</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Tuan Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Phung%2C+D">Dinh Phung</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Trung Le</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Mitigating catastrophic forgetting is a key hurdle in continual learning.
Deep Generative Replay (GR) provides techniques focused on generating samples
from prior tasks to enhance the model's memory capabilities. With the
progression in generative AI, generative models have advanced from Generative
Adversarial Networks (GANs) to the more recent Diffusion Models (DMs). A major
issue is the deterioration in the quality of generated data compared to the
original, as the generator continuously self-learns from its outputs. This
degradation can lead to the potential risk of catastrophic forgetting occurring
in the classifier. To address this, we propose the Class-Prototype Conditional
Diffusion Model (CPDM), a GR-based approach for continual learning that
enhances image quality in generators and thus reduces catastrophic forgetting
in classifiers. The cornerstone of CPDM is a learnable class-prototype that
captures the core characteristics of images in a given class. This prototype,
integrated into the diffusion model's denoising process, ensures the generation
of high-quality images. It maintains its effectiveness for old tasks even when
new tasks are introduced, preserving image generation quality and reducing the
risk of catastrophic forgetting in classifiers. Our empirical studies on
diverse datasets demonstrate that our proposed method significantly outperforms
existing state-of-the-art models, highlighting its exceptional ability to
preserve image quality and enhance the model's memory retention.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06712" title="Abstract">arXiv:2312.06712</a> [<a href="/pdf/2312.06712" title="Download PDF">pdf</a>, <a href="/format/2312.06712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Separate-and-Enhance: Compositional Finetuning for Text2Image Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+Z">Zhipeng Bao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yijun Li</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+K+K">Krishna Kumar Singh</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Xiong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hebert%2C+M">Martial Hebert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The project webpage is available at <a href="https://zpbao.github.io/projects/SepEn/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite recent significant strides achieved by diffusion-based Text-to-Image
(T2I) models, current systems are still less capable of ensuring decent
compositional generation aligned with text prompts, particularly for the
multi-object generation. This work illuminates the fundamental reasons for such
misalignment, pinpointing issues related to low attention activation scores and
mask overlaps. While previous research efforts have individually tackled these
issues, we assert that a holistic approach is paramount. Thus, we propose two
novel objectives, the Separate loss and the Enhance loss, that reduce object
mask overlaps and maximize attention scores, respectively. Our method diverges
from conventional test-time-adaptation techniques, focusing on finetuning
critical parameters, which enhances scalability and generalizability.
Comprehensive evaluations demonstrate the superior performance of our model in
terms of image realism, text-image alignment, and adaptability, notably
outperforming prominent baselines. Ultimately, this research paves the way for
T2I diffusion models with enhanced compositional capacities and broader
applicability. The project webpage is available at
https://zpbao.github.io/projects/SepEn/.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06713" title="Abstract">arXiv:2312.06713</a> [<a href="/pdf/2312.06713" title="Download PDF">pdf</a>, <a href="/format/2312.06713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TeTriRF: Temporal Tri-Plane Radiance Fields for Efficient Free-Viewpoint  Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Minye Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zehao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kouros%2C+G">Georgios Kouros</a>, 
<a href="/search/cs?searchtype=author&query=Tuytelaars%2C+T">Tinne Tuytelaars</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural Radiance Fields (NeRF) revolutionize the realm of visual media by
providing photorealistic Free-Viewpoint Video (FVV) experiences, offering
viewers unparalleled immersion and interactivity. However, the technology's
significant storage requirements and the computational complexity involved in
generation and rendering currently limit its broader application. To close this
gap, this paper presents Temporal Tri-Plane Radiance Fields (TeTriRF), a novel
technology that significantly reduces the storage size for Free-Viewpoint Video
(FVV) while maintaining low-cost generation and rendering. TeTriRF introduces a
hybrid representation with tri-planes and voxel grids to support scaling up to
long-duration sequences and scenes with complex motions or rapid changes. We
propose a group training scheme tailored to achieving high training efficiency
and yielding temporally consistent, low-entropy scene representations.
Leveraging these properties of the representations, we introduce a compression
pipeline with off-the-shelf video codecs, achieving an order of magnitude less
storage size compared to the state-of-the-art. Our experiments demonstrate that
TeTriRF can achieve competitive quality with a higher compression rate.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06716" title="Abstract">arXiv:2312.06716</a> [<a href="/pdf/2312.06716" title="Download PDF">pdf</a>, <a href="/format/2312.06716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deciphering &#x27;What&#x27; and &#x27;Where&#x27; Visual Pathways from Spectral Clustering  of Layer-Distributed Neural Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yunis%2C+D">David Yunis</a>, 
<a href="/search/cs?searchtype=author&query=Maire%2C+M">Michael Maire</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present an approach for analyzing grouping information contained within a
neural network's activations, permitting extraction of spatial layout and
semantic segmentation from the behavior of large pre-trained vision models.
Unlike prior work, our method conducts a wholistic analysis of a network's
activation state, leveraging features from all layers and obviating the need to
guess which part of the model contains relevant information. Motivated by
classic spectral clustering, we formulate this analysis in terms of an
optimization objective involving a set of affinity matrices, each formed by
comparing features within a different layer. Solving this optimization problem
using gradient descent allows our technique to scale from single images to
dataset-level analysis, including, in the latter, both intra- and inter-image
relationships. Analyzing a pre-trained generative transformer provides insight
into the computational strategy learned by such models. Equating affinity with
key-query similarity across attention layers yields eigenvectors encoding scene
spatial layout, whereas defining affinity by value vector similarity yields
eigenvectors encoding object identity. This result suggests that key and query
vectors coordinate attentional information flow according to spatial proximity
(a `where' pathway), while value vectors refine a semantic category
representation (a `what' pathway).
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06717" title="Abstract">arXiv:2312.06717</a> [<a href="/pdf/2312.06717" title="Download PDF">pdf</a>, <a href="/format/2312.06717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy Issues in Large Language Models: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neel%2C+S">Seth Neel</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+P">Peter Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This is the first survey of the active area of AI research that focuses on
privacy issues in Large Language Models (LLMs). Specifically, we focus on work
that red-teams models to highlight privacy risks, attempts to build privacy
into the training or inference process, enables efficient data deletion from
trained models to comply with existing privacy regulations, and tries to
mitigate copyright issues. Our focus is on summarizing technical research that
develops algorithms, proves theorems, and runs empirical evaluations. While
there is an extensive body of legal and policy work addressing these challenges
from a different angle, that is not the focus of our survey. Nevertheless,
these works, along with recent legal developments do inform how these technical
problems are formalized, and so we discuss them briefly in Section 1. While we
have made our best effort to include all the relevant work, due to the fast
moving nature of this research we may have missed some recent work. If we have
missed some of your work please contact us, as we will attempt to keep this
survey relatively up to date. We are maintaining a repository with the list of
papers covered in this survey and any relevant code that was publicly available
at https://github.com/safr-ml-lab/survey-llm.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06718" title="Abstract">arXiv:2312.06718</a> [<a href="/pdf/2312.06718" title="Download PDF">pdf</a>, <a href="/format/2312.06718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Scale Foundation Models for Intelligent Manufacturing  Applications: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haotian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dereck%2C+S+S">Semujju Stuart Dereck</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhicheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+X">Xianwei Lv</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Liang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Ye Jia</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+Z">Zhuo Long</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+W">Wensheng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X+G">X.G. Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+R">Ruiyan Zhuang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Although the applications of artificial intelligence especially deep learning
had greatly improved various aspects of intelligent manufacturing, they still
face challenges for wide employment due to the poor generalization ability,
difficulties to establish high-quality training datasets, and unsatisfactory
performance of deep learning methods. The emergence of large scale foundational
models(LSFMs) had triggered a wave in the field of artificial intelligence,
shifting deep learning models from single-task, single-modal, limited data
patterns to a paradigm encompassing diverse tasks, multimodal, and pre-training
on massive datasets. Although LSFMs had demonstrated powerful generalization
capabilities, automatic high-quality training dataset generation and superior
performance across various domains, applications of LSFMs on intelligent
manufacturing were still in their nascent stage. A systematic overview of this
topic was lacking, especially regarding which challenges of deep learning can
be addressed by LSFMs and how these challenges can be systematically tackled.
To fill this gap, this paper systematically expounded current statue of LSFMs
and their advantages in the context of intelligent manufacturing. and compared
comprehensively with the challenges faced by current deep learning models in
various intelligent manufacturing applications. We also outlined the roadmaps
for utilizing LSFMs to address these challenges. Finally, case studies of
applications of LSFMs in real-world intelligent manufacturing scenarios were
presented to illustrate how LSFMs could help industries, improve their
efficiency.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06719" title="Abstract">arXiv:2312.06719</a> [<a href="/pdf/2312.06719" title="Download PDF">pdf</a>, <a href="/format/2312.06719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SkyScenes: A Synthetic Dataset for Aerial Scene Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khose%2C+S">Sahil Khose</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+A">Anisha Pal</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+A">Aayushi Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Deepanshi">Deepanshi</a>, 
<a href="/search/cs?searchtype=author&query=Hoffman%2C+J">Judy Hoffman</a>, 
<a href="/search/cs?searchtype=author&query=Chattopadhyay%2C+P">Prithvijit Chattopadhyay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Real-world aerial scene understanding is limited by a lack of datasets that
contain densely annotated images curated under a diverse set of conditions. Due
to inherent challenges in obtaining such images in controlled real-world
settings, we present SkyScenes, a synthetic dataset of densely annotated aerial
images captured from Unmanned Aerial Vehicle (UAV) perspectives. We carefully
curate SkyScenes images from CARLA to comprehensively capture diversity across
layout (urban and rural maps), weather conditions, times of day, pitch angles
and altitudes with corresponding semantic, instance and depth annotations.
Through our experiments using SkyScenes, we show that (1) Models trained on
SkyScenes generalize well to different real-world scenarios, (2) augmenting
training on real images with SkyScenes data can improve real-world performance,
(3) controlled variations in SkyScenes can offer insights into how models
respond to changes in viewpoint conditions, and (4) incorporating additional
sensor modalities (depth) can improve aerial scene understanding.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06720" title="Abstract">arXiv:2312.06720</a> [<a href="/pdf/2312.06720" title="Download PDF">pdf</a>, <a href="/format/2312.06720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audio-Visual LLM for Video Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shu%2C+F">Fangxun Shu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Cihang Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents Audio-Visual LLM, a Multimodal Large Language Model that
takes both visual and auditory inputs for holistic video understanding. A key
design is the modality-augmented training, which involves the integration of
modality-specific tokens engineered to activate the appropriate visual and/or
auditory encoder selectively. This mechanism is pivotal in enabling end-to-end
joint training with video data at different modalities, including visual-only,
audio-only, and audio-visual formats. Moreover, we introduce a high-quality
video instruction dataset, derived from GPT-4. This dataset allows Audio-Visual
LLM to adeptly process a variety of task-oriented video instructions, ranging
from multi-turn conversations and audio-visual narratives to complex reasoning
tasks. Extensive experiments demonstrate that Audio-Visual LLM impressively
achieves strong zero-shot results across a range of video understanding tasks.
For example, Audio-Visual LLM achieves an accuracy of 53.7% on MSRVTT-QA,
outperforming non-LLM-based InterVideo by 6.6% and LLM-based Valley by 4.4%,
respectively. Additionally, our Audio-Visual LLM also achieves competitive
performance on audio tasks (e.g., AudioCaps).
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06721" title="Abstract">arXiv:2312.06721</a> [<a href="/pdf/2312.06721" title="Download PDF">pdf</a>, <a href="/format/2312.06721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counterfactual World Modeling for Physical Dynamics Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Venkatesh%2C+R">Rahul Venkatesh</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Honglin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Feigelis%2C+K">Kevin Feigelis</a>, 
<a href="/search/cs?searchtype=author&query=Jedoui%2C+K">Khaled Jedoui</a>, 
<a href="/search/cs?searchtype=author&query=Kotar%2C+K">Klemen Kotar</a>, 
<a href="/search/cs?searchtype=author&query=Binder%2C+F">Felix Binder</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+W">Wanhee Lee</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sherry Liu</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+K+A">Kevin A. Smith</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J+E">Judith E. Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yamins%2C+D+L+K">Daniel L. K. Yamins</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The ability to understand physical dynamics is essential to learning agents
acting in the world. This paper presents Counterfactual World Modeling (CWM), a
candidate pure vision foundational model for physical dynamics understanding.
CWM consists of three basic concepts. First, we propose a simple and powerful
temporally-factored masking policy for masked prediction of video data, which
encourages the model to learn disentangled representations of scene appearance
and dynamics. Second, as a result of the factoring, CWM is capable of
generating counterfactual next-frame predictions by manipulating a few patch
embeddings to exert meaningful control over scene dynamics. Third, the
counterfactual modeling capability enables the design of counterfactual queries
to extract vision structures similar to keypoints, optical flows, and
segmentations, which are useful for dynamics understanding. We show that
zero-shot readouts of these structures extracted by the counterfactual queries
attain competitive performance to prior methods on real-world datasets.
Finally, we demonstrate that CWM achieves state-of-the-art performance on the
challenging Physion benchmark for evaluating physical dynamics understanding.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06722" title="Abstract">arXiv:2312.06722</a> [<a href="/pdf/2312.06722" title="Download PDF">pdf</a>, <a href="/format/2312.06722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EgoPlan-Bench: Benchmarking Egocentric Embodied Planning with Multimodal  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yuying Ge</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yixiao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Mingyu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bohao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ruifeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xihui Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project released at: <a href="https://github.com/ChenYi99/EgoPlan">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Robotics (cs.RO)

</div>
<p class="mathjax">Multimodal Large Language Models (MLLMs), building upon the powerful Large
Language Models (LLMs) with exceptional reasoning and generalization
capability, have opened up new avenues for embodied task planning. MLLMs excel
in their ability to integrate diverse environmental inputs, such as real-time
task progress, visual observations, and open-form language instructions, which
are crucial for executable task planning. In this work, we introduce a
benchmark with human annotations, EgoPlan-Bench, to quantitatively investigate
the potential of MLLMs as embodied task planners in real-world scenarios. Our
benchmark is distinguished by realistic tasks derived from real-world videos, a
diverse set of actions involving interactions with hundreds of different
objects, and complex visual observations from varied environments. We evaluate
various open-source MLLMs, revealing that these models have not yet evolved
into embodied planning generalists (even GPT-4V). We further construct an
instruction-tuning dataset EgoPlan-IT from videos of human-object interactions,
to facilitate the learning of high-level task planning in intricate real-world
situations. The experiment results demonstrate that the model tuned on
EgoPlan-IT not only significantly improves performance on our benchmark, but
also effectively acts as embodied planner in simulations.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06723" title="Abstract">arXiv:2312.06723</a> [<a href="/pdf/2312.06723" title="Download PDF">pdf</a>, <a href="/format/2312.06723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to See Low-Light Images via Feature Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qirui Yang</a>, 
<a href="/search/cs?searchtype=author&query=qihua%2C+c">cheng qihua</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+H">Huanjing Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Le Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yihao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jingyu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Raw low light image enhancement (LLIE) has achieved much better performance
than the sRGB domain enhancement methods due to the merits of raw data.
However, the ambiguity between noisy to clean and raw to sRGB mappings may
mislead the single-stage enhancement networks. The two-stage networks avoid
ambiguity by decoupling the two mappings but usually have large computing
complexity. To solve this problem, we propose a single-stage network empowered
by Feature Domain Adaptation (FDA) to decouple the denoising and color mapping
tasks in raw LLIE. The denoising encoder is supervised by the clean raw image,
and then the denoised features are adapted for the color mapping task by an FDA
module. We propose a Lineformer to serve as the FDA, which can well explore the
global and local correlations with fewer line buffers (friendly to the
line-based imaging process). During inference, the raw supervision branch is
removed. In this way, our network combines the advantage of a two-stage
enhancement process with the efficiency of single-stage inference. Experiments
on four benchmark datasets demonstrate that our method achieves
state-of-the-art performance with fewer computing costs (60\% FLOPs of the
two-stage method DNF). \textit{Our codes will be released after the acceptance
of this work.}
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06724" title="Abstract">arXiv:2312.06724</a> [<a href="/pdf/2312.06724" title="Download PDF">pdf</a>, <a href="/format/2312.06724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient and Effective Similarity Search over Bipartite Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Renchi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Best Paper Award Nominee in WWW 2022. Fixing the incorrect figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Similarity search over a bipartite graph aims to retrieve from the graph the
nodes that are similar to each other, which finds applications in various
fields such as online advertising, recommender systems etc. Existing similarity
measures either (i) overlook the unique properties of bipartite graphs, or (ii)
fail to capture high-order information between nodes accurately, leading to
suboptimal result quality. Recently, Hidden Personalized PageRank (HPP) is
applied to this problem and found to be more effective compared with prior
similarity measures. However, existing solutions for HPP computation incur
significant computational costs, rendering it inefficient especially on large
graphs.
<br />In this paper, we first identify an inherent drawback of HPP and overcome it
by proposing bidirectional HPP (BHPP). Then, we formulate similarity search
over bipartite graphs as the problem of approximate BHPP computation, and
present an efficient solution Approx-BHPP. Specifically, Approx-BHPP offers
rigorous theoretical accuracy guarantees with optimal computational complexity
by combining deterministic graph traversal with matrix operations in an
optimized and non-trivial way. Moreover, our solution achieves significant gain
in practical efficiency due to several carefully-designed optimizations.
Extensive experiments, comparing BHPP against 8 existing similarity measures
over 7 real bipartite graphs, demonstrate the effectiveness of BHPP on query
rewriting and item recommendation. Moreover, Approx-BHPP outperforms baseline
solutions often by up to orders of magnitude in terms of computational time on
both small and large datasets.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06725" title="Abstract">arXiv:2312.06725</a> [<a href="/pdf/2312.06725" title="Download PDF">pdf</a>, <a href="/format/2312.06725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EpiDiff: Enhancing Multi-View Synthesis via Localized  Epipolar-Constrained Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zehuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Hao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Junting Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaohui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yangguang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yan-Pei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+D">Ding Liang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bo Dai</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+L">Lu Sheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://huanngzh.github.io/EpiDiff/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generating multiview images from a single view facilitates the rapid
generation of a 3D mesh conditioned on a single image. Recent methods that
introduce 3D global representation into diffusion models have shown the
potential to generate consistent multiviews, but they have reduced generation
speed and face challenges in maintaining generalizability and quality. To
address this issue, we propose EpiDiff, a localized interactive multiview
diffusion model. At the core of the proposed approach is to insert a
lightweight epipolar attention block into the frozen diffusion model,
leveraging epipolar constraints to enable cross-view interaction among feature
maps of neighboring views. The newly initialized 3D modeling module preserves
the original feature distribution of the diffusion model, exhibiting
compatibility with a variety of base diffusion models. Experiments show that
EpiDiff generates 16 multiview images in just 12 seconds, and it surpasses
previous methods in quality evaluation metrics, including PSNR, SSIM and LPIPS.
Additionally, EpiDiff can generate a more diverse distribution of views,
improving the reconstruction quality from generated multiviews. Please see our
project page at https://huanngzh.github.io/EpiDiff/.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06726" title="Abstract">arXiv:2312.06726</a> [<a href="/pdf/2312.06726" title="Download PDF">pdf</a>, <a href="/format/2312.06726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compress &amp; Align: Curating Image-Text Data with Human Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+F">Fangxun Shu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Sucheng Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bingchen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Cihang Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The massive growth of image-text data through web crawling inherently
presents the challenge of variability in data quality. This paper introduces a
novel algorithm, rooted in human knowledge, to compress this vast corpus of
web-crawled image-text datasets to a compact and high-quality form. Our method
unfolds in three major steps. First, we collect an image-text dataset, wherein
each image is associated with multiple captions sourced from diverse origins.
Then, to systemically capture human preferences regarding the best caption
paired with each image, we establish a comprehensive set of both subjective and
objective criteria for critically guiding the alignment assessment from
labelers. Lastly, we train a reward model on the annotated dataset to
internalize the nuanced human understanding of image-text alignment. The
resulting reward model thus can act as a human-like referee to filter
misaligned/low-quality image-text pairs. Extensive experiments demonstrate that
we are able to secure (or even improve) model performance by compressing the
image-text datasets up to ~90%. An impressive example is that, by aggressively
reducing the total training sample from 130M to 15.5M (e.g., ~9x smaller), our
BLIP-B/16 models still consistently show superior performance compared with the
full-size-dataset counterpart on image-text retrieval (Flickr30K, COCO) by
~2.5% in Recall@1, and on image-captioning (Nocaps, COCO) by ~10.0% in CIDEr
and ~2.7% in SPICE.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06727" title="Abstract">arXiv:2312.06727</a> [<a href="/pdf/2312.06727" title="Download PDF">pdf</a>, <a href="/ps/2312.06727" title="Download PostScript">ps</a>, <a href="/format/2312.06727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A method for recovery of multidimensional time series based on the  detection of behavioral patterns and the use of autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yurtin%2C+A">Alexey Yurtin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, in Russian language, 2 figure, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This article presents a method for recovering missing values in
multidimensional time series. The method combines neural network technologies
and an algorithm for searching snippets (behavioral patterns of a time series).
It includes the stages of data preprocessing, recognition and reconstruction,
using convolutional and recurrent neural networks. Experiments have shown high
accuracy of recovery and the advantage of the method over SOTA methods.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06728" title="Abstract">arXiv:2312.06728</a> [<a href="/pdf/2312.06728" title="Download PDF">pdf</a>, <a href="/format/2312.06728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multimodal Dataset and Benchmark for Radio Galaxy and Infrared Host  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+N">Nikhel Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Hayder%2C+Z">Zeeshan Hayder</a>, 
<a href="/search/cs?searchtype=author&query=Norris%2C+R+P">Ray P. Norris</a>, 
<a href="/search/cs?searchtype=author&query=Hyunh%2C+M">Minh Hyunh</a>, 
<a href="/search/cs?searchtype=author&query=Petersson%2C+L">Lars Petersson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in NeurIPS 2023 conference ML4PS workshop (<a href="https://nips.cc/">this https URL</a>). The full version accepted in PASA, is available at <a href="https://doi.org/10.1017/pasa.2023.64">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cosmology and Nongalactic Astrophysics (astro-ph.CO); Astrophysics of Galaxies (astro-ph.GA); Instrumentation and Methods for Astrophysics (astro-ph.IM)

</div>
<p class="mathjax">We present a novel multimodal dataset developed by expert astronomers to
automate the detection and localisation of multi-component extended radio
galaxies and their corresponding infrared hosts. The dataset comprises 4,155
instances of galaxies in 2,800 images with both radio and infrared modalities.
Each instance contains information on the extended radio galaxy class, its
corresponding bounding box that encompasses all of its components, pixel-level
segmentation mask, and the position of its corresponding infrared host galaxy.
Our dataset is the first publicly accessible dataset that includes images from
a highly sensitive radio telescope, infrared satellite, and instance-level
annotations for their identification. We benchmark several object detection
algorithms on the dataset and propose a novel multimodal approach to identify
radio galaxies and the positions of infrared hosts simultaneously.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06729" title="Abstract">arXiv:2312.06729</a> [<a href="/pdf/2312.06729" title="Download PDF">pdf</a>, <a href="/format/2312.06729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RGNet: A Unified Retrieval and Grounding Network for Long Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hannan%2C+T">Tanveer Hannan</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+M">Md Mohaiminul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Seidl%2C+T">Thomas Seidl</a>, 
<a href="/search/cs?searchtype=author&query=Bertasius%2C+G">Gedas Bertasius</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The code is released at <a href="https://github.com/Tanveer81/RGNet">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a novel end-to-end method for long-form video temporal grounding
to locate specific moments described by natural language queries. Prior
long-video methods for this task typically contain two stages: proposal
selection and grounding regression. However, the proposal selection of these
methods is disjoint from the grounding network and is not trained end-to-end,
which limits the effectiveness of these methods. Moreover, these methods
operate uniformly over the entire temporal window, which is suboptimal given
redundant and irrelevant features in long videos. In contrast to these prior
approaches, we introduce RGNet, a unified network designed for jointly
selecting proposals from hour-long videos and locating moments specified by
natural language queries within them. To achieve this, we redefine proposal
selection as a video-text retrieval task, i.e., retrieving the correct
candidate videos given a text query. The core component of RGNet is a unified
cross-modal RG-Encoder that bridges the two stages with shared features and
mutual optimization. The encoder strategically focuses on relevant time frames
using a sparse sampling technique. RGNet outperforms previous methods,
demonstrating state-of-the-art performance on long video temporal grounding
datasets MAD and Ego4D. The code is released at
https://github.com/Tanveer81/RGNet
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06731" title="Abstract">arXiv:2312.06731</a> [<a href="/pdf/2312.06731" title="Download PDF">pdf</a>, <a href="/format/2312.06731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Genixer: Empowering Multimodal Large Language Models as a Powerful Data  Generator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H+H">Henry Hengyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) excel in understanding human instructions,
driving the development of Multimodal LLMs (MLLMs) with instruction tuning.
However, acquiring high-quality multimodal instruction tuning data poses a
significant challenge. Previous approaches relying on GPT-4 for data generation
proved expensive and exhibited unsatisfactory performance for certain tasks. To
solve this, we present Genixer, an innovative data generation pipeline
producing high-quality multimodal instruction tuning data for various tasks.
Genixer collects datasets for ten prevalent multimodal tasks and designs
instruction templates to transform these datasets into instruction-tuning data.
It then trains pretrained MLLMs to generate task-specific instruction data and
proposes an effective data filtering strategy to ensure high quality. To
evaluate Genixer, a base MLLM model, Kakapo, is built and achieves SoTA
performance in image captioning and visual question answering (VQA) tasks
across multiple datasets. Experimental results show that filtered data from
Genixer continually improves Kakapo for image captioning and VQA tasks. For the
SoTA Shikra MLLM model on the image-region-related tasks, e.g., region caption
and detection, Genixer also successfully generates corresponding data and
improves its performance. Genixer opens avenues for generating high-quality
multimodal instruction data for diverse tasks, enabling innovative applications
across domains. The code and models will be released soon.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06733" title="Abstract">arXiv:2312.06733</a> [<a href="/pdf/2312.06733" title="Download PDF">pdf</a>, <a href="/format/2312.06733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TULIP: Transformer for Upsampling of LiDAR Point Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Pfreundschuh%2C+P">Patrick Pfreundschuh</a>, 
<a href="/search/cs?searchtype=author&query=Siegwart%2C+R">Roland Siegwart</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+M">Marco Hutter</a>, 
<a href="/search/cs?searchtype=author&query=Moghadam%2C+P">Peyman Moghadam</a>, 
<a href="/search/cs?searchtype=author&query=Patil%2C+V">Vaishakh Patil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">LiDAR Upsampling is a challenging task for the perception systems of robots
and autonomous vehicles, due to the sparse and irregular structure of
large-scale scene contexts. Recent works propose to solve this problem by
converting LiDAR data from 3D Euclidean space into an image super-resolution
problem in 2D image space. Although their methods can generate high-resolution
range images with fine-grained details, the resulting 3D point clouds often
blur out details and predict invalid points. In this paper, we propose TULIP, a
new method to reconstruct high-resolution LiDAR point clouds from
low-resolution LiDAR input. We also follow a range image-based approach but
specifically modify the patch and window geometries of a Swin-Transformer-based
network to better fit the characteristics of range images. We conducted several
experiments on three different public real-world and simulated datasets. TULIP
outperforms state-of-the-art methods in all relevant metrics and generates
robust and more realistic point clouds than prior works.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06734" title="Abstract">arXiv:2312.06734</a> [<a href="/pdf/2312.06734" title="Download PDF">pdf</a>, <a href="/format/2312.06734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffCast: A Unified Framework via Residual Diffusion for Precipitation  Nowcasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Demin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xutao Li</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yunming Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Baoquan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Chuyao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+K">Kuai Dai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xunlai Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Precipitation nowcasting is an important spatio-temporal prediction task to
predict the radar echoes sequences based on current observations, which can
serve both meteorological science and smart city applications. Due to the
chaotic evolution nature of the precipitation systems, it is a very challenging
problem. Previous studies address the problem either from the perspectives of
deterministic modeling or probabilistic modeling. However, their predictions
suffer from the blurry, high-value echoes fading away and position inaccurate
issues. The root reason of these issues is that the chaotic evolutionary
precipitation systems are not appropriately modeled. Inspired by the nature of
the systems, we propose to decompose and model them from the perspective of
global deterministic motion and local stochastic variations with residual
mechanism. A unified and flexible framework that can equip any type of
spatio-temporal models is proposed based on residual diffusion, which
effectively tackles the shortcomings of previous methods. Extensive
experimental results on four publicly available radar datasets demonstrate the
effectiveness and superiority of the proposed framework, compared to
state-of-the-art techniques. Our code will be made publicly available soon.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06736" title="Abstract">arXiv:2312.06736</a> [<a href="/pdf/2312.06736" title="Download PDF">pdf</a>, <a href="/format/2312.06736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SqueezeSAM: User friendly mobile interactive segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Varadarajan%2C+B">Balakrishnan Varadarajan</a>, 
<a href="/search/cs?searchtype=author&query=Soran%2C+B">Bilge Soran</a>, 
<a href="/search/cs?searchtype=author&query=Iandola%2C+F">Forrest Iandola</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+X">Xiaoyu Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yunyang Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chenchen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamoorthi%2C+R">Raghuraman Krishnamoorthi</a>, 
<a href="/search/cs?searchtype=author&query=Chandra%2C+V">Vikas Chandra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Segment Anything Model (SAM) is a foundation model for interactive
segmentation, and it has catalyzed major advances in generative AI,
computational photography, and medical imaging. This model takes in an
arbitrary user input and provides segmentation masks of the corresponding
objects. It is our goal to develop a version of SAM that is appropriate for use
in a photography app. The original SAM model has a few challenges in this
setting. First, original SAM a 600 million parameter based on ViT-H, and its
high computational cost and large model size that are not suitable for todays
mobile hardware. We address this by proposing the SqueezeSAM model
architecture, which is 50x faster and 100x smaller than SAM. Next, when a user
takes a photo on their phone, it might not occur to them to click on the image
and get a mask. Our solution is to use salient object detection to generate the
first few clicks. This produces an initial segmentation mask that the user can
interactively edit. Finally, when a user clicks on an object, they typically
expect all related pieces of the object to be segmented. For instance, if a
user clicks on a person t-shirt in a photo, they expect the whole person to be
segmented, but SAM typically segments just the t-shirt. We address this with a
new data augmentation scheme, and the end result is that if the user clicks on
a person holding a basketball, the person and the basketball are all segmented
together.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06738" title="Abstract">arXiv:2312.06738</a> [<a href="/pdf/2312.06738" title="Download PDF">pdf</a>, <a href="/format/2312.06738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InstructAny2Pix: Flexible Visual Editing via Multimodal Instruction  Following
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shufan Li</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+H">Harkanwar Singh</a>, 
<a href="/search/cs?searchtype=author&query=Grover%2C+A">Aditya Grover</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The ability to provide fine-grained control for generating and editing visual
imagery has profound implications for computer vision and its applications.
Previous works have explored extending controllability in two directions:
instruction tuning with text-based prompts and multi-modal conditioning.
However, these works make one or more unnatural assumptions on the number
and/or type of modality inputs used to express controllability. We propose
InstructAny2Pix, a flexible multi-modal instruction-following system that
enables users to edit an input image using instructions involving audio,
images, and text. InstructAny2Pix consists of three building blocks that
facilitate this capability: a multi-modal encoder that encodes different
modalities such as images and audio into a unified latent space, a diffusion
model that learns to decode representations in this latent space into images,
and a multi-modal LLM that can understand instructions involving multiple
images and audio pieces and generate a conditional embedding of the desired
output, which can be used by the diffusion decoder. Additionally, to facilitate
training efficiency and improve generation quality, we include an additional
refinement prior module that enhances the visual quality of LLM outputs. These
designs are critical to the performance of our system. We demonstrate that our
system can perform a series of novel instruction-guided editing tasks. The code
is available at https://github.com/jacklishufan/InstructAny2Pix.git
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06739" title="Abstract">arXiv:2312.06739</a> [<a href="/pdf/2312.06739" title="Download PDF">pdf</a>, <a href="/format/2312.06739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SmartEdit: Exploring Complex Instruction-based Image Editing with  Multimodal Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuzhou Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Liangbin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xintao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Ziyang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Cun%2C+X">Xiaodong Cun</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yixiao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiantao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+C">Chao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Rui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruimao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://yuzhou914.github.io/SmartEdit/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Current instruction-based editing methods, such as InstructPix2Pix, often
fail to produce satisfactory results in complex scenarios due to their
dependence on the simple CLIP text encoder in diffusion models. To rectify
this, this paper introduces SmartEdit, a novel approach to instruction-based
image editing that leverages Multimodal Large Language Models (MLLMs) to
enhance their understanding and reasoning capabilities. However, direct
integration of these elements still faces challenges in situations requiring
complex reasoning. To mitigate this, we propose a Bidirectional Interaction
Module that enables comprehensive bidirectional information interactions
between the input image and the MLLM output. During training, we initially
incorporate perception data to boost the perception and understanding
capabilities of diffusion models. Subsequently, we demonstrate that a small
amount of complex instruction editing data can effectively stimulate
SmartEdit's editing capabilities for more complex instructions. We further
construct a new evaluation dataset, Reason-Edit, specifically tailored for
complex instruction-based image editing. Both quantitative and qualitative
results on this evaluation dataset indicate that our SmartEdit surpasses
previous methods, paving the way for the practical application of complex
instruction-based image editing.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06740" title="Abstract">arXiv:2312.06740</a> [<a href="/pdf/2312.06740" title="Download PDF">pdf</a>, <a href="/format/2312.06740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MonoNPHM: Dynamic Head Reconstruction from Monocular Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Giebenhain%2C+S">Simon Giebenhain</a>, 
<a href="/search/cs?searchtype=author&query=Kirschstein%2C+T">Tobias Kirschstein</a>, 
<a href="/search/cs?searchtype=author&query=Georgopoulos%2C+M">Markos Georgopoulos</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%BCnz%2C+M">Martin R&#xfc;nz</a>, 
<a href="/search/cs?searchtype=author&query=Agapito%2C+L">Lourdes Agapito</a>, 
<a href="/search/cs?searchtype=author&query=Nie%C3%9Fner%2C+M">Matthias Nie&#xdf;ner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: see <a href="https://simongiebenhain.github.io/MonoNPHM/">this https URL</a> ; Video: see <a href="https://youtu.be/n-wjaC3UIeE">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present Monocular Neural Parametric Head Models (MonoNPHM) for dynamic 3D
head reconstructions from monocular RGB videos. To this end, we propose a
latent appearance space that parameterizes a texture field on top of a neural
parametric model. We constrain predicted color values to be correlated with the
underlying geometry such that gradients from RGB effectively influence latent
geometry codes during inverse rendering. To increase the representational
capacity of our expression space, we augment our backward deformation field
with hyper-dimensions, thus improving color and geometry representation in
topologically challenging expressions. Using MonoNPHM as a learned prior, we
approach the task of 3D head reconstruction using signed distance field based
volumetric rendering. By numerically inverting our backward deformation field,
we incorporated a landmark loss using facial anchor points that are closely
tied to our canonical geometry representation. To evaluate the task of dynamic
face reconstruction from monocular RGB videos we record 20 challenging Kinect
sequences under casual conditions. MonoNPHM outperforms all baselines with a
significant margin, and makes an important step towards easily accessible
neural parametric face models through RGB tracking.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06741" title="Abstract">arXiv:2312.06741</a> [<a href="/pdf/2312.06741" title="Download PDF">pdf</a>, <a href="/format/2312.06741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Splatting SLAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Matsuki%2C+H">Hidenobu Matsuki</a>, 
<a href="/search/cs?searchtype=author&query=Murai%2C+R">Riku Murai</a>, 
<a href="/search/cs?searchtype=author&query=Kelly%2C+P+H+J">Paul H.J. Kelly</a>, 
<a href="/search/cs?searchtype=author&query=Davison%2C+A+J">Andrew J. Davison</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First two authors contributed equally to this work. Project Page: <a href="https://rmurai.co.uk/projects/GaussianSplattingSLAM/">this https URL</a> Video: <a href="https://www.youtube.com/watch?v=x604ghp9R_Q">this https URL</a>&amp;ab_channel=DysonRoboticsLaboratoryatImperialCollege
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">We present the first application of 3D Gaussian Splatting to incremental 3D
reconstruction using a single moving monocular or RGB-D camera. Our
Simultaneous Localisation and Mapping (SLAM) method, which runs live at 3fps,
utilises Gaussians as the only 3D representation, unifying the required
representation for accurate, efficient tracking, mapping, and high-quality
rendering. Several innovations are required to continuously reconstruct 3D
scenes with high fidelity from a live camera. First, to move beyond the
original 3DGS algorithm, which requires accurate poses from an offline
Structure from Motion (SfM) system, we formulate camera tracking for 3DGS using
direct optimisation against the 3D Gaussians, and show that this enables fast
and robust tracking with a wide basin of convergence. Second, by utilising the
explicit nature of the Gaussians, we introduce geometric verification and
regularisation to handle the ambiguities occurring in incremental 3D dense
reconstruction. Finally, we introduce a full SLAM system which not only
achieves state-of-the-art results in novel view synthesis and trajectory
estimation, but also reconstruction of tiny and even transparent objects.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06742" title="Abstract">arXiv:2312.06742</a> [<a href="/pdf/2312.06742" title="Download PDF">pdf</a>, <a href="/format/2312.06742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Honeybee: Locality-enhanced Projector for Multimodal LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cha%2C+J">Junbum Cha</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+W">Wooyoung Kang</a>, 
<a href="/search/cs?searchtype=author&query=Mun%2C+J">Jonghwan Mun</a>, 
<a href="/search/cs?searchtype=author&query=Roh%2C+B">Byungseok Roh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">In Multimodal Large Language Models (MLLMs), a visual projector plays a
crucial role in bridging pre-trained vision encoders with LLMs, enabling
profound visual understanding while harnessing the LLMs' robust capabilities.
Despite the importance of the visual projector, it has been relatively less
explored. In this study, we first identify two essential projector properties:
(i) flexibility in managing the number of visual tokens, crucial for MLLMs'
overall efficiency, and (ii) preservation of local context from visual
features, vital for spatial understanding. Based on these findings, we propose
a novel projector design that is both flexible and locality-enhanced,
effectively satisfying the two desirable properties. Additionally, we present
comprehensive strategies to effectively utilize multiple and multifaceted
instruction datasets. Through extensive experiments, we examine the impact of
individual design choices. Finally, our proposed MLLM, Honeybee, remarkably
outperforms previous state-of-the-art methods across various benchmarks,
including MME, MMBench, SEED-Bench, and LLaVA-Bench, achieving significantly
higher efficiency. Code and models are available at
https://github.com/kakaobrain/honeybee.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06786" title="Abstract">arXiv:2312.06786</a> [<a href="/pdf/2312.06786" title="Download PDF">pdf</a>, <a href="/format/2312.06786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixture-of-Linear-Experts for Long-term Time Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+R">Ronghao Ni</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zinan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuaiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fanti%2C+G">Giulia Fanti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Long-term time series forecasting (LTSF) aims to predict future values of a
time series given the past values. The current state-of-the-art (SOTA) on this
problem is attained in some cases by linear-centric models, which primarily
feature a linear mapping layer. However, due to their inherent simplicity, they
are not able to adapt their prediction rules to periodic changes in time series
patterns. To address this challenge, we propose a Mixture-of-Experts-style
augmentation for linear-centric models and propose Mixture-of-Linear-Experts
(MoLE). Instead of training a single model, MoLE trains multiple linear-centric
models (i.e., experts) and a router model that weighs and mixes their outputs.
While the entire framework is trained end-to-end, each expert learns to
specialize in a specific temporal pattern, and the router model learns to
compose the experts adaptively. Experiments show that MoLE reduces forecasting
error of linear-centric models, including DLinear, RLinear, and RMLP, in over
78% of the datasets and settings we evaluated. By using MoLE existing
linear-centric models can achieve SOTA LTSF results in 68% of the experiments
that PatchTST reports and we compare to, whereas existing single-head
linear-centric models achieve SOTA results in only 25% of cases. Additionally,
MoLE models achieve SOTA in all settings for the newly released Weather2K
datasets.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06789" title="Abstract">arXiv:2312.06789</a> [<a href="/pdf/2312.06789" title="Download PDF">pdf</a>, <a href="/format/2312.06789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Critique of Human-Autonomous Team Dynamics: Contrasting Qualitative  and Quantitative Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Hanjing Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The critique paper provides an in-depth analysis of two influential studies
in the field of Human-Autonomous Teams (HATs). Musick et al. explored
qualitative dimensions of HAT dynamics, examining the influence of team
composition on emotions, cognitive processes, and the development of team
cognition. Their research revealed that teams with a majority of human members,
known as Multi-Human HATs, generally surpass Multi-Agent HATs in performance,
highlighting the critical influence of human perception on team dynamics.
Employing qualitative interview analysis anchored in theoretical frameworks,
Musick et al. captured the detailed subtleties of participants' experiences. In
contrast, Schelble et al. utilized a quantitative methodology to provide
data-driven insights into how the perception of AI teammates affects team
performance. Despite the rich insights from Musick et al.'s qualitative
research, their findings face limitations in terms of broader applicability.
Both Musick et al. and Schelble et al. agree in their conclusions that
Multi-Human HATs typically outperform their Multi-Agent counterparts, again
emphasizing the crucial role of human perception in team dynamics. The critique
paper suggests that future research should focus on understanding perceptions
of teams heavily reliant on AI. Such investigations could illuminate how trust
and skepticism are shaped in teams where AI plays a dominant role.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06790" title="Abstract">arXiv:2312.06790</a> [<a href="/pdf/2312.06790" title="Download PDF">pdf</a>, <a href="/format/2312.06790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Uncanny Valley Effect in Dark Colored Skin Virtual Humans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Araujo%2C+V">Victor Araujo</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+A+B">Angelo Brandelli Costa</a>, 
<a href="/search/cs?searchtype=author&query=Musse%2C+S+R">Soraia Raupp Musse</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures, published at SIBIGRAPI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">With the rapid advancement of technology, the design of virtual humans has
led to a very realistic user experience, such as in movies, video games, and
simulations. As a result, virtual humans are becoming increasingly similar to
real humans. However, following the Uncanny Valley (UV) theory, users tend to
feel discomfort when watching entities with anthropomorphic traits that differ
from real humans. This phenomenon is related to social identity theory, where
the observer looks for something familiar. In Computer Graphics (CG),
techniques used to create virtual humans with dark skin tones often rely on
approaches initially developed for rendering characters with white skin tones.
Furthermore, most CG characters portrayed in various media, including movies
and games, predominantly exhibit white skin tones. Consequently, it is
pertinent to explore people's perceptions regarding different groups of virtual
humans. Thus, this paper aims to examine and evaluate the human perception of
CG characters from different media, comparing two types of skin colors. The
findings indicate that individuals felt more comfortable and perceived less
realism when watching characters with dark colored skin than those with white
colored skin. Our central hypothesis is that dark colored characters, rendered
with classical developed algorithms, are considered more cartoon than realistic
and placed on the left of the Valley in the UV chart.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06795" title="Abstract">arXiv:2312.06795</a> [<a href="/pdf/2312.06795" title="Download PDF">pdf</a>, <a href="/format/2312.06795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Breadcrumbs: Scaling Multi-Task Model Merging with Sparse Masks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Davari%2C+M">MohammadReza Davari</a>, 
<a href="/search/cs?searchtype=author&query=Belilovsky%2C+E">Eugene Belilovsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The rapid development of AI systems has been greatly influenced by the
emergence of foundation models. A common approach for targeted problems
involves fine-tuning these pre-trained foundation models for specific target
tasks, resulting in a rapid spread of models fine-tuned across a diverse array
of tasks. This work focuses on the problem of merging multiple fine-tunings of
the same foundation model derived from a spectrum of auxiliary tasks. We
introduce a new simple method, Model Breadcrumbs, which consists of a sparsely
defined set of weights that carve out a trajectory within the weight space of a
pre-trained model, enhancing task performance when traversed. These breadcrumbs
are constructed by subtracting the weights from a pre-trained model before and
after fine-tuning, followed by a sparsification process that eliminates weight
outliers and negligible perturbations. Our experiments demonstrate the
effectiveness of Model Breadcrumbs to simultaneously improve performance across
multiple tasks. This contribution aligns with the evolving paradigm of
updatable machine learning, reminiscent of the collaborative principles
underlying open-source software development, fostering a community-driven
effort to reliably update machine learning models. Our method is shown to be
more efficient and unlike previous proposals does not require hyperparameter
tuning for each new task added. Through extensive experimentation involving
various models, tasks, and modalities we establish that integrating Model
Breadcrumbs offers a simple, efficient, and highly effective approach for
constructing multi-task models and facilitating updates to foundation models.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06797" title="Abstract">arXiv:2312.06797</a> [<a href="/pdf/2312.06797" title="Download PDF">pdf</a>, <a href="/format/2312.06797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the Robustness of 3D Human Pose Estimation: A Benchmark and  Learning from Noisy Input
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoang%2C+T">Trung-Hieu Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Zehni%2C+M">Mona Zehni</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+H">Huy Phan</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+M+N">Minh N. Do</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite the promising performance of current 3D human pose estimation
techniques, understanding and enhancing their generalization on challenging
in-the-wild videos remain an open problem. In this work, we focus on the
robustness of 2D-to-3D pose lifters. To this end, we develop two benchmark
datasets, namely Human3.6M-C and HumanEva-I-C, to examine the robustness of
video-based 3D pose lifters to a wide range of common video corruptions
including temporary occlusion, motion blur, and pixel-level noise. We observe
the poor generalization of state-of-the-art 3D pose lifters in the presence of
corruption and establish two techniques to tackle this issue. First, we
introduce Temporal Additive Gaussian Noise (TAGN) as a simple yet effective 2D
input pose data augmentation. Additionally, to incorporate the confidence
scores output by the 2D pose detectors, we design a confidence-aware
convolution (CA-Conv) block. Extensively tested on corrupted videos, the
proposed strategies consistently boost the robustness of 3D pose lifters and
serve as new baselines for future research.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06798" title="Abstract">arXiv:2312.06798</a> [<a href="/pdf/2312.06798" title="Download PDF">pdf</a>, <a href="/format/2312.06798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building Trustworthy NeuroSymbolic AI Systems: Consistency, Reliability,  Explainability, and Safety
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gaur%2C+M">Manas Gaur</a>, 
<a href="/search/cs?searchtype=author&query=Sheth%2C+A">Amit Sheth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To Appear in AAAI AI Magazine. 15 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Explainability and Safety engender Trust. These require a model to exhibit
consistency and reliability. To achieve these, it is necessary to use and
analyze data and knowledge with statistical and symbolic AI methods relevant to
the AI application - neither alone will do. Consequently, we argue and seek to
demonstrate that the NeuroSymbolic AI approach is better suited for making AI a
trusted AI system. We present the CREST framework that shows how Consistency,
Reliability, user-level Explainability, and Safety are built on NeuroSymbolic
methods that use data and knowledge to support requirements for critical
applications such as health and well-being. This article focuses on Large
Language Models (LLMs) as the chosen AI system within the CREST framework. LLMs
have garnered substantial attention from researchers due to their versatility
in handling a broad array of natural language processing (NLP) scenarios. For
example, ChatGPT and Google's MedPaLM have emerged as highly promising
platforms for providing information in general and health-related queries,
respectively. Nevertheless, these models remain black boxes despite
incorporating human feedback and instruction-guided tuning. For instance,
ChatGPT can generate unsafe responses despite instituting safety guardrails.
CREST presents a plausible approach harnessing procedural and graph-based
knowledge within a NeuroSymbolic framework to shed light on the challenges
associated with LLMs.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06799" title="Abstract">arXiv:2312.06799</a> [<a href="/pdf/2312.06799" title="Download PDF">pdf</a>, <a href="/format/2312.06799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Densify Your Labels: Unsupervised Clustering with Bipartite Matching for  Weakly Supervised Point Cloud Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shaobo Xia</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+J">Jun Yue</a>, 
<a href="/search/cs?searchtype=author&query=Kania%2C+K">Kacper Kania</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+L">Leyuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Tagliasacchi%2C+A">Andrea Tagliasacchi</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+K+M">Kwang Moo Yi</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weiwei Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors contributed equally; Project website: <a href="https://densify-your-labels.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose a weakly supervised semantic segmentation method for point clouds
that predicts "per-point" labels from just "whole-scene" annotations while
achieving the performance of recent fully supervised approaches. Our core idea
is to propagate the scene-level labels to each point in the point cloud by
creating pseudo labels in a conservative way. Specifically, we over-segment
point cloud features via unsupervised clustering and associate scene-level
labels with clusters through bipartite matching, thus propagating scene labels
only to the most relevant clusters, leaving the rest to be guided solely via
unsupervised clustering. We empirically demonstrate that over-segmentation and
bipartite assignment plays a crucial role. We evaluate our method on ScanNet
and S3DIS datasets, outperforming state of the art, and demonstrate that we can
achieve results comparable to fully supervised methods.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06800" title="Abstract">arXiv:2312.06800</a> [<a href="/pdf/2312.06800" title="Download PDF">pdf</a>, <a href="/format/2312.06800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topiary: Fast, Scalable Publish/Subscribe for Peer-to-Peer (D)Apps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yifan Mao</a>, 
<a href="/search/cs?searchtype=author&query=Venkatakrishnan%2C+S+B">Shaileshh Bojja Venkatakrishnan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The emergence of blockchain technology has fostered the development of
numerous decentralized applications (dapps) in recent years Pub/sub
(publish/subscribe) systems play a crucial role by associating messages with
specific topics and propagating them from publishers to subscribers across the
network. Decentralized pub/sub aims to provide this functionality without
relying on centralized control or global network state information, enabling
message propagation among nodes in a coordinated manner. Efficiency in pub/sub
services entails ensuring that subscribers receive published messages promptly.
We introduce Topiary, a rapid and scalable protocol designed for decentralized
applications' pub/sub systems. Topiary autonomously learns an efficient
peer-to-peer (p2p) topology tailored to the publish/subscribe network. It does
so by analyzing peers' interactions with their neighbors. Inspired by concepts
from the multi-armed bandit problem, Topiary strikes an optimal balance between
maintaining connections with well-connected neighbors and exploring new
connections within the network, based on their topical needs. Through
experimental evaluations, Topiary has shown a 50% reduction in broadcast
latency while achieving an interested topic coverage of over 98%, marking it as
a promising solution for efficient decentralized pub/sub networks.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06801" title="Abstract">arXiv:2312.06801</a> [<a href="/pdf/2312.06801" title="Download PDF">pdf</a>, <a href="/format/2312.06801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ADOD: Adaptive Domain-Aware Object Detection with Residual Attention for  Underwater Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saoud%2C+L+S">Lyes Saad Saoud</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Z">Zhenwei Niu</a>, 
<a href="/search/cs?searchtype=author&query=Sultan%2C+A">Atif Sultan</a>, 
<a href="/search/cs?searchtype=author&query=Seneviratne%2C+L">Lakmal Seneviratne</a>, 
<a href="/search/cs?searchtype=author&query=Hussain%2C+I">Irfan Hussain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This research presents ADOD, a novel approach to address domain
generalization in underwater object detection. Our method enhances the model's
ability to generalize across diverse and unseen domains, ensuring robustness in
various underwater environments. The first key contribution is Residual
Attention YOLOv3, a novel variant of the YOLOv3 framework empowered by residual
attention modules. These modules enable the model to focus on informative
features while suppressing background noise, leading to improved detection
accuracy and adaptability to different domains. The second contribution is the
attention-based domain classification module, vital during training. This
module helps the model identify domain-specific information, facilitating the
learning of domain-invariant features. Consequently, ADOD can generalize
effectively to underwater environments with distinct visual characteristics.
Extensive experiments on diverse underwater datasets demonstrate ADOD's
superior performance compared to state-of-the-art domain generalization
methods, particularly in challenging scenarios. The proposed model achieves
exceptional detection performance in both seen and unseen domains, showcasing
its effectiveness in handling domain shifts in underwater object detection
tasks. ADOD represents a significant advancement in adaptive object detection,
providing a promising solution for real-world applications in underwater
environments. With the prevalence of domain shifts in such settings, the
model's strong generalization ability becomes a valuable asset for practical
underwater surveillance and marine research endeavors.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06802" title="Abstract">arXiv:2312.06802</a> [<a href="/pdf/2312.06802" title="Download PDF">pdf</a>, <a href="/format/2312.06802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Feasibility of Fingerprinting Collaborative Robot Traffic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Cheng Tang</a>, 
<a href="/search/cs?searchtype=author&query=Barradas%2C+D">Diogo Barradas</a>, 
<a href="/search/cs?searchtype=author&query=Hengartner%2C+U">Urs Hengartner</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yue Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This study examines privacy risks in collaborative robotics, focusing on the
potential for traffic analysis in encrypted robot communications. While
previous research has explored low-level command recovery, our work
investigates high-level motion recovery from command message sequences. We
evaluate the efficacy of traditional website fingerprinting techniques (k-FP,
KNN, and CUMUL) and their limitations in accurately identifying robotic actions
due to their inability to capture detailed temporal relationships. To address
this, we introduce a traffic classification approach using signal processing
techniques, demonstrating high accuracy in action identification and
highlighting the vulnerability of encrypted communications to privacy breaches.
Additionally, we explore defenses such as packet padding and timing
manipulation, revealing the challenges in balancing traffic analysis resistance
with network efficiency. Our findings emphasize the need for continued
development of practical defenses in robotic privacy and security.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06808" title="Abstract">arXiv:2312.06808</a> [<a href="/pdf/2312.06808" title="Download PDF">pdf</a>, <a href="/format/2312.06808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BPF-oF: Storage Function Pushdown Over the Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zarkadas%2C+I">Ioannis Zarkadas</a>, 
<a href="/search/cs?searchtype=author&query=Zussman%2C+T">Tal Zussman</a>, 
<a href="/search/cs?searchtype=author&query=Carin%2C+J">Jeremy Carin</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Sheng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yuhong Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Pfefferle%2C+J">Jonas Pfefferle</a>, 
<a href="/search/cs?searchtype=author&query=Franke%2C+H">Hubertus Franke</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Junfeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kaffes%2C+K">Kostis Kaffes</a>, 
<a href="/search/cs?searchtype=author&query=Stutsman%2C+R">Ryan Stutsman</a>, 
<a href="/search/cs?searchtype=author&query=Cidon%2C+A">Asaf Cidon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Operating Systems (cs.OS)</span>

</div>
<p class="mathjax">Storage disaggregation, wherein storage is accessed over the network, is
popular because it allows applications to independently scale storage capacity
and bandwidth based on dynamic application demand. However, the added network
processing introduced by disaggregation can consume significant CPU resources.
In many storage systems, logical storage operations (e.g., lookups,
aggregations) involve a series of simple but dependent I/O access patterns.
Therefore, one way to reduce the network processing overhead is to execute
dependent series of I/O accesses at the remote storage server, reducing the
back-and-forth communication between the storage layer and the application. We
refer to this approach as \emph{remote-storage pushdown}. We present BPF-oF, a
new remote-storage pushdown protocol built on top of NVMe-oF, which enables
applications to safely push custom eBPF storage functions to a remote storage
server.
<br />The main challenge in integrating BPF-oF with storage systems is preserving
the benefits of their client-based in-memory caches. We address this challenge
by designing novel caching techniques for storage pushdown, including splitting
queries into separate in-memory and remote-storage phases and periodically
refreshing the client cache with sampled accesses from the remote storage
device. We demonstrate the utility of BPF-oF by integrating it with three
storage systems, including RocksDB, a popular persistent key-value store that
has no existing storage pushdown capability. We show BPF-oF provides
significant speedups in all three systems when accessed over the network, for
example improving RocksDB's throughput by up to 2.8$\times$ and tail latency by
up to 2.6$\times$.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06810" title="Abstract">arXiv:2312.06810</a> [<a href="/pdf/2312.06810" title="Download PDF">pdf</a>, <a href="/format/2312.06810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> System-level Safety Guard: Safe Tracking Control through Uncertain  Neural Network Dynamics Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yutong Li</a>, 
<a href="/search/cs?searchtype=author&query=Girard%2C+A">Anouck Girard</a>, 
<a href="/search/cs?searchtype=author&query=Kolmanovsky%2C+I">Ilya Kolmanovsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">The Neural Network (NN), as a black-box function approximator, has been
considered in many control and robotics applications. However, difficulties in
verifying the overall system safety in the presence of uncertainties hinder the
modular deployment of NN in safety-critical systems. In this paper, we leverage
the NNs as predictive models for trajectory tracking of unknown dynamical
systems. We consider controller design in the presence of both intrinsic
uncertainty and uncertainties from other system modules. In this setting, we
formulate the constrained trajectory tracking problem and show that it can be
solved using Mixed-integer Linear Programming (MILP). The proposed MILP-based
solution enjoys a provable safety guarantee for the overall system, and the
approach is empirically demonstrated in robot navigation and obstacle avoidance
through simulations. The demonstration videos are available at
https://xiaolisean.github.io/publication/2023-11-01-L4DC2024.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06812" title="Abstract">arXiv:2312.06812</a> [<a href="/pdf/2312.06812" title="Download PDF">pdf</a>, <a href="/format/2312.06812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On quadrature for singular integral operators with complex symmetric  quadratic forms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hoskins%2C+J">Jeremy Hoskins</a>, 
<a href="/search/math?searchtype=author&query=Rachh%2C+M">Manas Rachh</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+B">Bowei Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper describes a trapezoidal quadrature method for the discretization
of weakly singular, singular and hypersingular boundary integral operators with
complex symmetric quadratic forms. Such integral operators naturally arise when
complex coordinate methods or complexified contour methods are used for the
solution of time-harmonic acoustic and electromagnetic interface problems in
three dimensions. The quadrature is an extension of a locally corrected
punctured trapezoidal rule in parameter space wherein the correction weights
are determined by fitting moments of error in the punctured trapezoidal rule,
which is known analytically in terms of the Epstein zeta function. In this
work, we analyze the analytic continuation of the Epstein zeta function and the
generalized Wigner limits to complex quadratic forms; this analysis is
essential to apply the fitting procedure for computing the correction weights.
We illustrate the high-order convergence of this approach through several
numerical examples.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06820" title="Abstract">arXiv:2312.06820</a> [<a href="/pdf/2312.06820" title="Download PDF">pdf</a>, <a href="/format/2312.06820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extracting Self-Consistent Causal Insights from Users Feedback with LLMs  and In-context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdali%2C+S">Sara Abdali</a>, 
<a href="/search/cs?searchtype=author&query=Parikh%2C+A">Anjali Parikh</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Steve Lim</a>, 
<a href="/search/cs?searchtype=author&query=Kiciman%2C+E">Emre Kiciman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Microsoft Windows Feedback Hub is designed to receive customer feedback on a
wide variety of subjects including critical topics such as power and battery.
Feedback is one of the most effective ways to have a grasp of users' experience
with Windows and its ecosystem. However, the sheer volume of feedback received
by Feedback Hub makes it immensely challenging to diagnose the actual cause of
reported issues. To better understand and triage issues, we leverage Double
Machine Learning (DML) to associate users' feedback with telemetry signals. One
of the main challenges we face in the DML pipeline is the necessity of domain
knowledge for model design (e.g., causal graph), which sometimes is either not
available or hard to obtain. In this work, we take advantage of reasoning
capabilities in Large Language Models (LLMs) to generate a prior model that
which to some extent compensates for the lack of domain knowledge and could be
used as a heuristic for measuring feedback informativeness. Our LLM-based
approach is able to extract previously known issues, uncover new bugs, and
identify sequences of events that lead to a bug, while minimizing out-of-domain
outputs.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06825" title="Abstract">arXiv:2312.06825</a> [<a href="/pdf/2312.06825" title="Download PDF">pdf</a>, <a href="/ps/2312.06825" title="Download PostScript">ps</a>, <a href="/format/2312.06825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utilization of Non-verbal Behaviour and Social Gaze in Classroom  Human-Robot Interaction Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaghaghi%2C+S">Sahand Shaghaghi</a>, 
<a href="/search/cs?searchtype=author&query=Aliasghari%2C+P">Pourya Aliasghari</a>, 
<a href="/search/cs?searchtype=author&query=Tripp%2C+B">Bryan Tripp</a>, 
<a href="/search/cs?searchtype=author&query=Dautenhahn%2C+K">Kerstin Dautenhahn</a>, 
<a href="/search/cs?searchtype=author&query=Nehaniv%2C+C">Chrystopher Nehaniv</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> CUI2023, ACM Conversational User Interfaces
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">This abstract explores classroom Human-Robot Interaction (HRI) scenarios with
an emphasis on the adaptation of human-inspired social gaze models in robot
cognitive architecture to facilitate a more seamless social interaction. First,
we detail the HRI scenarios explored by us in our studies followed by a
description of the social gaze model utilized for our research. We highlight
the advantages of utilizing such an attentional model in classroom HRI
scenarios. We also detail the intended goals of our upcoming study involving
this social gaze model.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06826" title="Abstract">arXiv:2312.06826</a> [<a href="/pdf/2312.06826" title="Download PDF">pdf</a>, <a href="/format/2312.06826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User Friendly and Adaptable Discriminative AI: Using the Lessons from  the Success of LLMs and Image Generation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+S+T">Son The Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Tulabandhula%2C+T">Theja Tulabandhula</a>, 
<a href="/search/cs?searchtype=author&query=Watson-Manheim%2C+M+B">Mary Beth Watson-Manheim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">While there is significant interest in using generative AI tools as
general-purpose models for specific ML applications, discriminative models are
much more widely deployed currently. One of the key shortcomings of these
discriminative AI tools that have been already deployed is that they are not
adaptable and user-friendly compared to generative AI tools (e.g., GPT4, Stable
Diffusion, Bard, etc.), where a non-expert user can iteratively refine model
inputs and give real-time feedback that can be accounted for immediately,
allowing users to build trust from the start. Inspired by this emerging
collaborative workflow, we develop a new system architecture that enables users
to work with discriminative models (such as for object detection, sentiment
classification, etc.) in a fashion similar to generative AI tools, where they
can easily provide immediate feedback as well as adapt the deployed models as
desired. Our approach has implications on improving trust, user-friendliness,
and adaptability of these versatile but traditional prediction models.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06827" title="Abstract">arXiv:2312.06827</a> [<a href="/pdf/2312.06827" title="Download PDF">pdf</a>, <a href="/ps/2312.06827" title="Download PostScript">ps</a>, <a href="/format/2312.06827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid-Rendering Techniques in GPU
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Granja%2C+P">Pedro Granja</a>, 
<a href="/search/cs?searchtype=author&query=Pereira%2C+J">Jo&#xe3;o Pereira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">Ray tracing has long been the holy grail of real time rendering. This
technique, commonly used for photo realism, simulates the physical behavior of
light, at the cost of being computationally heavy. With the introduction of
Nvidia RTX graphic card family, which provides hardware support for ray
tracing, this technique started to look like a reality for real time. However,
the same problems that afflicted the usage of this technique remain, and even
with specialized hardware it is still extremely expensive. To account for these
drawbacks, researchers and developers pair this technique with rasterization
and denoising. This results in a hybrid system that tries to join the best of
both worlds, having both photo realistic quality and real time performance. In
this work we intend on further exploring hybrid render systems, offering a
review of the state of the art with a special focus on real time ray tracing
and our own hybrid implementation with photo realistic quality and real time
performance (&gt;30 fps), implemented using the Vulkan API. In this project, we
highlight the detailed analysis of the impacts of History Rectification
(Variance Color Clamping) on the temporal filter component of the denoising
system and how to overcome the introduced artifacts. Additionally, we also
highlight the analysis of the introduction of a separable blur on the spatial
filter and the introduction of Reinhard Tone Mapping prior to denoising,
consequently improving this procedure.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06829" title="Abstract">arXiv:2312.06829</a> [<a href="/pdf/2312.06829" title="Download PDF">pdf</a>, <a href="/format/2312.06829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Encoding Surgical Videos as Latent Spatiotemporal Graphs for Object and  Anatomy-Driven Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Murali%2C+A">Aditya Murali</a>, 
<a href="/search/cs?searchtype=author&query=Alapatt%2C+D">Deepak Alapatt</a>, 
<a href="/search/cs?searchtype=author&query=Mascagni%2C+P">Pietro Mascagni</a>, 
<a href="/search/cs?searchtype=author&query=Vardazaryan%2C+A">Armine Vardazaryan</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+A">Alain Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Okamoto%2C+N">Nariaki Okamoto</a>, 
<a href="/search/cs?searchtype=author&query=Mutter%2C+D">Didier Mutter</a>, 
<a href="/search/cs?searchtype=author&query=Padoy%2C+N">Nicolas Padoy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 2 figures, MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, spatiotemporal graphs have emerged as a concise and elegant manner
of representing video clips in an object-centric fashion, and have shown to be
useful for downstream tasks such as action recognition. In this work, we
investigate the use of latent spatiotemporal graphs to represent a surgical
video in terms of the constituent anatomical structures and tools and their
evolving properties over time. To build the graphs, we first predict frame-wise
graphs using a pre-trained model, then add temporal edges between nodes based
on spatial coherence and visual and semantic similarity. Unlike previous
approaches, we incorporate long-term temporal edges in our graphs to better
model the evolution of the surgical scene and increase robustness to temporary
occlusions. We also introduce a novel graph-editing module that incorporates
prior knowledge and temporal coherence to correct errors in the graph, enabling
improved downstream task performance. Using our graph representations, we
evaluate two downstream tasks, critical view of safety prediction and surgical
phase recognition, obtaining strong results that demonstrate the quality and
flexibility of the learned representations. Code is available at
github.com/CAMMA-public/SurgLatentGraph.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06832" title="Abstract">arXiv:2312.06832</a> [<a href="/pdf/2312.06832" title="Download PDF">pdf</a>, <a href="/ps/2312.06832" title="Download PostScript">ps</a>, <a href="/format/2312.06832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symptom-based Machine Learning Models for the Early Detection of  COVID-19: A Narrative Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akinloye%2C+M">Moyosolu Akinloye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite the widespread testing protocols for COVID-19, there are still
significant challenges in early detection of the disease, which is crucial for
preventing its spread and optimizing patient outcomes. Owing to the limited
testing capacity in resource-strapped settings and the limitations of the
available traditional methods of testing, it has been established that a fast
and efficient strategy is important to fully stop the virus. Machine learning
models can analyze large datasets, incorporating patient-reported symptoms,
clinical data, and medical imaging. Symptom-based detection methods have been
developed to predict COVID-19, and they have shown promising results. In this
paper, we provide an overview of the landscape of symptoms-only machine
learning models for predicting COVID-19, including their performance and
limitations. The review will also examine the performance of symptom-based
models when compared to image-based models. Because different studies used
varying datasets, methodologies, and performance metrics. Selecting the model
that performs best relies on the context and objectives of the research.
However, based on the results, we observed that ensemble classifier performed
exceptionally well in predicting the occurrence of COVID-19 based on patient
symptoms with the highest overall accuracy of 97.88%. Gradient Boosting
Algorithm achieved an AUC (Area Under the Curve) of 0.90 and identified key
features contributing to the decision-making process. Image-based models, as
observed in the analyzed studies, have consistently demonstrated higher
accuracy than symptom-based models, often reaching impressive levels ranging
from 96.09% to as high as 99%.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06833" title="Abstract">arXiv:2312.06833</a> [<a href="/pdf/2312.06833" title="Download PDF">pdf</a>, <a href="/ps/2312.06833" title="Download PostScript">ps</a>, <a href="/format/2312.06833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The unreasonable effectiveness of AI CADe polyp detectors to generalize  to new countries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shor%2C+J">Joel Shor</a>, 
<a href="/search/cs?searchtype=author&query=Yamano%2C+H">Hiro-o Yamano</a>, 
<a href="/search/cs?searchtype=author&query=Tsurumaru%2C+D">Daisuke Tsurumaru</a>, 
<a href="/search/cs?searchtype=author&query=Intrator%2C+Y">Yotami Intrator</a>, 
<a href="/search/cs?searchtype=author&query=Kayama%2C+H">Hiroki Kayama</a>, 
<a href="/search/cs?searchtype=author&query=Ledsam%2C+J">Joe Ledsam</a>, 
<a href="/search/cs?searchtype=author&query=Hamabe%2C+A">Atsushi Hamabe</a>, 
<a href="/search/cs?searchtype=author&query=Ando%2C+K">Koji Ando</a>, 
<a href="/search/cs?searchtype=author&query=Ota%2C+M">Mitsuhiko Ota</a>, 
<a href="/search/cs?searchtype=author&query=Ogino%2C+H">Haruei Ogino</a>, 
<a href="/search/cs?searchtype=author&query=Nakase%2C+H">Hiroshi Nakase</a>, 
<a href="/search/cs?searchtype=author&query=Kobayashi%2C+K">Kaho Kobayashi</a>, 
<a href="/search/cs?searchtype=author&query=Oki%2C+E">Eiji Oki</a>, 
<a href="/search/cs?searchtype=author&query=Goldenberg%2C+R">Roman Goldenberg</a>, 
<a href="/search/cs?searchtype=author&query=Rivlin%2C+E">Ehud Rivlin</a>, 
<a href="/search/cs?searchtype=author&query=Takemasa%2C+I">Ichiro Takemasa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY)

</div>
<p class="mathjax">$\textbf{Background and aims}$: Artificial Intelligence (AI) Computer-Aided
Detection (CADe) is commonly used for polyp detection, but data seen in
clinical settings can differ from model training. Few studies evaluate how well
CADe detectors perform on colonoscopies from countries not seen during
training, and none are able to evaluate performance without collecting
expensive and time-intensive labels.
<br />$\textbf{Methods}$: We trained a CADe polyp detector on Israeli colonoscopy
videos (5004 videos, 1106 hours) and evaluated on Japanese videos (354 videos,
128 hours) by measuring the True Positive Rate (TPR) versus false alarms per
minute (FAPM). We introduce a colonoscopy dissimilarity measure called "MAsked
mediCal Embedding Distance" (MACE) to quantify differences between
colonoscopies, without labels. We evaluated CADe on all Japan videos and on
those with the highest MACE.
<br />$\textbf{Results}$: MACE correctly quantifies that narrow-band imaging (NBI)
and chromoendoscopy (CE) frames are less similar to Israel data than Japan
whitelight (bootstrapped z-test, |z| &gt; 690, p &lt; $10^{-8}$ for both). Despite
differences in the data, CADe performance on Japan colonoscopies was
non-inferior to Israel ones without additional training (TPR at 0.5 FAPM: 0.957
and 0.972 for Israel and Japan; TPR at 1.0 FAPM: 0.972 and 0.989 for Israel and
Japan; superiority test t &gt; 45.2, p &lt; $10^{-8}$). Despite not being trained on
NBI or CE, TPR on those subsets were non-inferior to Japan overall
(non-inferiority test t &gt; 47.3, p &lt; $10^{-8}$, $\delta$ = 1.5% for both).
<br />$\textbf{Conclusion}$: Differences that prevent CADe detectors from
performing well in non-medical settings do not degrade the performance of our
AI CADe polyp detector when applied to data from a new country. MACE can help
medical AI models internationalize by identifying the most "dissimilar" data on
which to evaluate models.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06837" title="Abstract">arXiv:2312.06837</a> [<a href="/pdf/2312.06837" title="Download PDF">pdf</a>, <a href="/format/2312.06837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral State Space Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+N">Naman Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Suo%2C+D">Daniel Suo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hazan%2C+E">Elad Hazan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper studies sequence modeling for prediction tasks with long range
dependencies. We propose a new formulation for state space models based on
learning linear dynamical systems with the spectral filtering algorithm
[HSZ17]. This gives rise to a novel sequence prediction architecture we call
spectral state space models. The resulting models are evaluated on synthetic
dynamical systems. These evaluations support the theoretical benefits of
spectral filtering for tasks requiring very long range memory.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06841" title="Abstract">arXiv:2312.06841</a> [<a href="/pdf/2312.06841" title="Download PDF">pdf</a>, <a href="/format/2312.06841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> memorAIs: an Optical Character Recognition and Rule-Based Medication  Intake Reminder-Generating Solution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaveet%2C+E">Eden Shaveet</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+U">Utkarsh Singh</a>, 
<a href="/search/cs?searchtype=author&query=Assaderaghi%2C+N">Nicholas Assaderaghi</a>, 
<a href="/search/cs?searchtype=author&query=Librandi%2C+M">Maximo Librandi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Memory-based medication non-adherence is an unsolved problem that is
responsible for considerable disease burden in the United States. Digital
medication intake reminder solutions with minimal onboarding requirements that
are usable at the point of medication acquisition may help to alleviate this
problem by offering a low barrier way to help people remember to take their
medications. In this paper, we propose memorAIs, a digital medication intake
reminder solution that mitigates onboarding friction by leveraging optical
character recognition strategies for text extraction from medication bottles
and rule based expressions for text processing to create configured medication
reminders as local device calendar invitations. We describe our ideation and
development process, as well as limitations of the current implementation.
memorAIs was the winner of the Patient Safety award at the 2023 Columbia
University DivHacks Hackathon, presented by the Patient Safety Technology
Challenge, sponsored by the Pittsburgh Regional Health Initiative.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06848" title="Abstract">arXiv:2312.06848</a> [<a href="/pdf/2312.06848" title="Download PDF">pdf</a>, <a href="/format/2312.06848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Modeling and Verification of Perception-Based Autonomous  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Waite%2C+T">Thomas Waite</a>, 
<a href="/search/eess?searchtype=author&query=Robey%2C+A">Alexander Robey</a>, 
<a href="/search/eess?searchtype=author&query=Hamed%2C+H">Hassani Hamed</a>, 
<a href="/search/eess?searchtype=author&query=Pappas%2C+G+J">George J. Pappas</a>, 
<a href="/search/eess?searchtype=author&query=Ivanov%2C+R">Radoslav Ivanov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 12 figures, and 3 tables. Submitted to: 6th Annual Learning for Dynamics &amp; Control Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This paper addresses the problem of data-driven modeling and verification of
perception-based autonomous systems. We assume the perception model can be
decomposed into a canonical model (obtained from first principles or a
simulator) and a noise model that contains the measurement noise introduced by
the real environment. We focus on two types of noise, benign and adversarial
noise, and develop a data-driven model for each type using generative models
and classifiers, respectively. We show that the trained models perform well
according to a variety of evaluation metrics based on downstream tasks such as
state estimation and control. Finally, we verify the safety of two systems with
high-dimensional data-driven models, namely an image-based version of mountain
car (a reinforcement learning benchmark) as well as the F1/10 car, which uses
LiDAR measurements to navigate a racing track.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06849" title="Abstract">arXiv:2312.06849</a> [<a href="/pdf/2312.06849" title="Download PDF">pdf</a>, <a href="/ps/2312.06849" title="Download PostScript">ps</a>, <a href="/format/2312.06849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning based Modeling of Wireless Communication Channel with  Fading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Youngmin%2C+L">Lee Youngmin</a>, 
<a href="/search/cs?searchtype=author&query=Xiaomin%2C+M">Ma Xiaomin</a>, 
<a href="/search/cs?searchtype=author&query=Andrew%2C+L+S+I+D">Lang S.I.D. Andrew</a>, 
<a href="/search/cs?searchtype=author&query=Enrique%2C+V+F">Valderrama-Araya F. Enrique</a>, 
<a href="/search/cs?searchtype=author&query=Andrew%2C+C+L">Chapuis L. Andrew</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In the realm of wireless communication, stochastic modeling of channels is
instrumental for the assessment and design of operational systems. Deep
learning neural networks (DLNN), including generative adversarial networks
(GANs), are being used to approximate wireless Orthogonal frequency-division
multiplexing (OFDM) channels with fading and noise, using real measurement
data. These models primarily focus on channel output (y) distribution given
input x: p(y|x), limiting their application scope. DLNN channel models have
been tested predominantly on simple simulated channels. In this paper, we build
both GANs and feedforward neural networks (FNN) to approximate a more general
channel model, which is represented by a conditional probability density
function (PDF) of receiving signal or power of node receiving power Prx:
f_p_rx|d(()), where is communication distance. The stochastic models are
trained and tested for the impact of fading channels on transmissions of OFDM
QAM modulated signal and transmissions of general signal regardless of
modulations. New metrics are proposed for evaluation of modeling accuracy and
comparisons of the GAN-based model with the FNN-based model. Extensive
experiments on Nakagami fading channel show accuracy and the effectiveness of
the approaches.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06850" title="Abstract">arXiv:2312.06850</a> [<a href="/pdf/2312.06850" title="Download PDF">pdf</a>, <a href="/format/2312.06850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NDELS: A Novel Approach for Nighttime Dehazing, Low-Light Enhancement,  and Light Suppression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bernabel%2C+S+A">Silvano A. Bernabel</a>, 
<a href="/search/cs?searchtype=author&query=Agaian%2C+S+S">Sos S. Agaian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper tackles the intricate challenge of improving the quality of
nighttime images under hazy and low-light conditions. Overcoming issues
including nonuniform illumination glows, texture blurring, glow effects, color
distortion, noise disturbance, and overall, low light have proven daunting.
Despite the inherent difficulties, this paper introduces a pioneering solution
named Nighttime Dehazing, Low-Light Enhancement, and Light Suppression (NDELS).
NDELS utilizes a unique network that combines three essential processes to
enhance visibility, brighten low-light regions, and effectively suppress glare
from bright light sources. In contrast to limited progress in nighttime
dehazing, unlike its daytime counterpart, NDELS presents a comprehensive and
innovative approach. The efficacy of NDELS is rigorously validated through
extensive comparisons with eight state-of-the-art algorithms across four
diverse datasets. Experimental results showcase the superior performance of our
method, demonstrating its outperformance in terms of overall image quality,
including color and edge enhancement. Quantitative (PSNR, SSIM) and qualitative
metrics (CLIPIQA, MANIQA, TRES), measure these results.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06853" title="Abstract">arXiv:2312.06853</a> [<a href="/pdf/2312.06853" title="Download PDF">pdf</a>, <a href="/format/2312.06853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLF-Bench: Benchmark for Interactive Learning from Language Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+C">Ching-An Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Kolobov%2C+A">Andrey Kolobov</a>, 
<a href="/search/cs?searchtype=author&query=Misra%2C+D">Dipendra Misra</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+A">Allen Nie</a>, 
<a href="/search/cs?searchtype=author&query=Swaminathan%2C+A">Adith Swaminathan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">We introduce a new benchmark, LLF-Bench (Learning from Language Feedback
Benchmark; pronounced as "elf-bench"), to evaluate the ability of AI agents to
interactively learn from natural language feedback and instructions. Learning
from language feedback (LLF) is essential for people, largely because the rich
information this feedback provides can help a learner avoid much of trial and
error and thereby speed up the learning process. Large Language Models (LLMs)
have recently enabled AI agents to comprehend natural language -- and hence AI
agents can potentially benefit from language feedback during learning like
humans do. But existing interactive benchmarks do not assess this crucial
capability: they either use numeric reward feedback or require no learning at
all (only planning or information retrieval). LLF-Bench is designed to fill
this omission. LLF-Bench is a diverse collection of sequential decision-making
tasks that includes user recommendation, poem writing, navigation, and robot
control. The objective of an agent is to interactively solve these tasks based
on their natural-language instructions and the feedback received after taking
actions. Crucially, to ensure that the agent actually "learns" from the
feedback, LLF-Bench implements several randomization techniques (such as
paraphrasing and environment randomization) to ensure that the task isn't
familiar to the agent and that the agent is robust to various verbalizations.
In addition, LLF-Bench provides a unified OpenAI Gym interface for all its
tasks and allows the users to easily configure the information the feedback
conveys (among suggestion, explanation, and instantaneous performance) to study
how agents respond to different types of feedback. Together, these features
make LLF-Bench a unique research platform for developing and testing LLF
agents.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06855" title="Abstract">arXiv:2312.06855</a> [<a href="/pdf/2312.06855" title="Download PDF">pdf</a>, <a href="/format/2312.06855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Pretraining of Medical Time Series and Notes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=King%2C+R">Ryan King</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tianbao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Mortazavi%2C+B">Bobak Mortazavi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Within the intensive care unit (ICU), a wealth of patient data, including
clinical measurements and clinical notes, is readily available. This data is a
valuable resource for comprehending patient health and informing medical
decisions, but it also contains many challenges in analysis. Deep learning
models show promise in extracting meaningful patterns, but they require
extensive labeled data, a challenge in critical care. To address this, we
propose a novel approach employing self-supervised pretraining, focusing on the
alignment of clinical measurements and notes. Our approach combines contrastive
and masked token prediction tasks during pretraining. Semi-supervised
experiments on the MIMIC-III dataset demonstrate the effectiveness of our
self-supervised pretraining. In downstream tasks, including in-hospital
mortality prediction and phenotyping, our pretrained model outperforms
baselines in settings where only a fraction of the data is labeled, emphasizing
its ability to enhance ICU data analysis. Notably, our method excels in
situations where very few labels are available, as evidenced by an increase in
the AUC-ROC for in-hospital mortality by 0.17 and in AUC-PR for phenotyping by
0.1 when only 1% of labels are accessible. This work advances self-supervised
learning in the healthcare domain, optimizing clinical insights from abundant
yet challenging ICU data.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06857" title="Abstract">arXiv:2312.06857</a> [<a href="/pdf/2312.06857" title="Download PDF">pdf</a>, <a href="/format/2312.06857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge-Informed Neuro-Integrators for Aggregation Kinetics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lukashevich%2C+D">Dmitrii Lukashevich</a>, 
<a href="/search/math?searchtype=author&query=Tyukin%2C+I">Ivan Tyukin</a>, 
<a href="/search/math?searchtype=author&query=Brilliantov%2C+N">Nikolay Brilliantov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We report a novel approach for the efficient computation of solutions of a
broad class of large-scale systems of non-linear ordinary differential
equations, describing aggregation kinetics. The method is based on a new take
on the dimensionality reduction for this class of equations which can be
naturally implemented by a cascade of small feed-forward artificial neural
networks. We show that this cascade, of otherwise static models, is capable of
predicting solutions of the original large-scale system over large intervals of
time, using the information about the solution computed over much smaller
intervals. The computational cost of the method depends very mildly on the
temporal horizon, which is a major improvement over the current
state-of-the-art methods, whose complexity increases super-linearly with the
system's size and proportionally to the simulation time. In cases when prior
information about the values of solutions over a relatively small interval of
time is already available, the method's computational complexity does not
depend explicitly on the system's size. The successful application of the new
method is illustrated for spatially-homogeneous systems, with a source of
monomers, for a number of the most representative reaction rates kernels.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06858" title="Abstract">arXiv:2312.06858</a> [<a href="/pdf/2312.06858" title="Download PDF">pdf</a>, <a href="/format/2312.06858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Decentralized Cooperative Platoon using Multi-Agent Deep  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdelrahman%2C+A">Ahmed Abdelrahman</a>, 
<a href="/search/cs?searchtype=author&query=Shehata%2C+O+M">Omar M. Shehata</a>, 
<a href="/search/cs?searchtype=author&query=Basyoni%2C+Y">Yarah Basyoni</a>, 
<a href="/search/cs?searchtype=author&query=Morgan%2C+E+I">Elsayed I. Morgan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Systems and Control (eess.SY)

</div>
<p class="mathjax">Cooperative autonomous driving plays a pivotal role in improving road
capacity and safety within intelligent transportation systems, particularly
through the deployment of autonomous vehicles on urban streets. By enabling
vehicle-to-vehicle communication, these systems expand the vehicles
environmental awareness, allowing them to detect hidden obstacles and thereby
enhancing safety and reducing crash rates compared to human drivers who rely
solely on visual perception. A key application of this technology is vehicle
platooning, where connected vehicles drive in a coordinated formation. This
paper introduces a vehicle platooning approach designed to enhance traffic flow
and safety. Developed using deep reinforcement learning in the Unity 3D game
engine, known for its advanced physics, this approach aims for a high-fidelity
physical simulation that closely mirrors real-world conditions. The proposed
platooning model focuses on scalability, decentralization, and fostering
positive cooperation through the introduced predecessor-follower "sharing and
caring" communication framework. The study demonstrates how these elements
collectively enhance autonomous driving performance and robustness, both for
individual vehicles and for the platoon as a whole, in an urban setting. This
results in improved road safety and reduced traffic congestion.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06861" title="Abstract">arXiv:2312.06861</a> [<a href="/pdf/2312.06861" title="Download PDF">pdf</a>, <a href="/format/2312.06861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangling Perceptions of Offensiveness: Cultural and Moral  Correlates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Davani%2C+A">Aida Davani</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz%2C+M">Mark D&#xed;az</a>, 
<a href="/search/cs?searchtype=author&query=Baker%2C+D">Dylan Baker</a>, 
<a href="/search/cs?searchtype=author&query=Prabhakaran%2C+V">Vinodkumar Prabhakaran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Perception of offensiveness is inherently subjective, shaped by the lived
experiences and socio-cultural values of the perceivers. Recent years have seen
substantial efforts to build AI-based tools that can detect offensive language
at scale, as a means to moderate social media platforms, and to ensure safety
of conversational AI technologies such as ChatGPT and Bard. However, existing
approaches treat this task as a technical endeavor, built on top of data
annotated for offensiveness by a global crowd workforce without any attention
to the crowd workers' provenance or the values their perceptions reflect. We
argue that cultural and psychological factors play a vital role in the
cognitive processing of offensiveness, which is critical to consider in this
context. We re-frame the task of determining offensiveness as essentially a
matter of moral judgment -- deciding the boundaries of ethically wrong vs.
right language within an implied set of socio-cultural norms. Through a
large-scale cross-cultural study based on 4309 participants from 21 countries
across 8 cultural regions, we demonstrate substantial cross-cultural
differences in perceptions of offensiveness. More importantly, we find that
individual moral values play a crucial role in shaping these variations: moral
concerns about Care and Purity are significant mediating factors driving
cross-cultural differences. These insights are of crucial importance as we
build AI models for the pluralistic world, where the values they espouse should
aim to respect and account for moral values in diverse geo-cultural contexts.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06865" title="Abstract">arXiv:2312.06865</a> [<a href="/pdf/2312.06865" title="Download PDF">pdf</a>, <a href="/format/2312.06865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Keypoint-based Stereophotoclinometry for Characterizing and Navigating  Small Bodies: A Factor Graph Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Driver%2C+T">Travis Driver</a>, 
<a href="/search/cs?searchtype=author&query=Vaughan%2C+A">Andrew Vaughan</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yang Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Ansar%2C+A">Adnan Ansar</a>, 
<a href="/search/cs?searchtype=author&query=Christian%2C+J">John Christian</a>, 
<a href="/search/cs?searchtype=author&query=Tsiotras%2C+P">Panagiotis Tsiotras</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper proposes the incorporation of techniques from
stereophotoclinometry (SPC) into a keypoint-based structure-from-motion (SfM)
system to estimate the surface normal and albedo at detected landmarks to
improve autonomous surface and shape characterization of small celestial bodies
from in-situ imagery. In contrast to the current state-of-the-practice method
for small body shape reconstruction, i.e., SPC, which relies on
human-in-the-loop verification and high-fidelity a priori information to
achieve accurate results, we forego the expensive maplet estimation step and
instead leverage dense keypoint measurements and correspondences from an
autonomous keypoint detection and matching method based on deep learning to
provide the necessary photogrammetric constraints. Moreover, we develop a
factor graph-based approach allowing for simultaneous optimization of the
spacecraft's pose, landmark positions, Sun-relative direction, and surface
normals and albedos via fusion of Sun sensor measurements and image keypoint
measurements. The proposed framework is validated on real imagery of the
Cornelia crater on Asteroid 4 Vesta, along with pose estimation and mapping
comparison against an SPC reconstruction, where we demonstrate precise
alignment to the SPC solution without relying on any a priori camera pose and
topography information or humans-in-the-loop
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06867" title="Abstract">arXiv:2312.06867</a> [<a href="/pdf/2312.06867" title="Download PDF">pdf</a>, <a href="/format/2312.06867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Get an A in Math: Progressive Rectification Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhenyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Meng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chao Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 - Camera Ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Chain-of-Thought (CoT) prompting methods have enabled large language models
(LLMs) to generate reasoning paths and solve math word problems (MWPs).
However, they are sensitive to mistakes in the paths, as any mistake can result
in an incorrect answer. We propose a novel method named Progressive
Rectification Prompting (PRP) to improve average accuracy on eight MWP datasets
from 77.3 to 90.5. Given an initial answer from CoT, PRP iterates a
verify-then-rectify process to progressively identify incorrect answers and
rectify the reasoning paths. With the most likely correct answer, the LLM
predicts a masked numerical value in the question; if the prediction does not
match the masked value, the answer is likely incorrect. Then the LLM is
prompted to re-generate the reasoning path hinted with a set of incorrect
answers to prevent itself from repeating previous mistakes. PRP achieves the
best performance compared against the CoT methods. Our implementation is made
publicly available at https://wzy6642.github.io/prp.github.io/.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06868" title="Abstract">arXiv:2312.06868</a> [<a href="/pdf/2312.06868" title="Download PDF">pdf</a>, <a href="/format/2312.06868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RAFIC: Retrieval-Augmented Few-shot Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hangfei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+L">Li Miao</a>, 
<a href="/search/cs?searchtype=author&query=Ziai%2C+A">Amir Ziai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Few-shot image classification is the task of classifying unseen images to one
of N mutually exclusive classes, using only a small number of training examples
for each class. The limited availability of these examples (denoted as K)
presents a significant challenge to classification accuracy in some cases. To
address this, we have developed a method for augmenting the set of K with an
addition set of A retrieved images. We call this system Retrieval-Augmented
Few-shot Image Classification (RAFIC). Through a series of experiments, we
demonstrate that RAFIC markedly improves performance of few-shot image
classification across two challenging datasets. RAFIC consists of two main
components: (a) a retrieval component which uses CLIP, LAION-5B, and faiss, in
order to efficiently retrieve images similar to the supplied images, and (b)
retrieval meta-learning, which learns to judiciously utilize the retrieved
images. Code and data is available at github.com/amirziai/rafic.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06869" title="Abstract">arXiv:2312.06869</a> [<a href="/pdf/2312.06869" title="Download PDF">pdf</a>, <a href="/format/2312.06869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Estimation of Topological Dimension with Harmonic Score Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeats%2C+E">Eric Yeats</a>, 
<a href="/search/cs?searchtype=author&query=Darwin%2C+C">Cameron Darwin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Frank Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hai Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the NeurIPS'23 Workshop on Diffusion Models
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Quantification of the number of variables needed to locally explain complex
data is often the first step to better understanding it. Existing techniques
from intrinsic dimension estimation leverage statistical models to glean this
information from samples within a neighborhood. However, existing methods often
rely on well-picked hyperparameters and ample data as manifold dimension and
curvature increases. Leveraging insight into the fixed point of the score
matching objective as the score map is regularized by its Dirichlet energy, we
show that it is possible to retrieve the topological dimension of the manifold
learned by the score map. We then introduce a novel method to measure the
learned manifold's topological dimension (i.e., local intrinsic dimension)
using adversarial attacks, thereby generating useful interpretations of the
learned manifold.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06871" title="Abstract">arXiv:2312.06871</a> [<a href="/pdf/2312.06871" title="Download PDF">pdf</a>, <a href="/format/2312.06871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Analytics on Student Created Data to Content Validate Pedagogical  Tools
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kos%2C+J">John Kos</a>, 
<a href="/search/cs?searchtype=author&query=Eaton%2C+K">Kenneth Eaton</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sareen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dass%2C+R">Rahul Dass</a>, 
<a href="/search/cs?searchtype=author&query=Buckley%2C+S">Stephen Buckley</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+S">Sungeun An</a>, 
<a href="/search/cs?searchtype=author&query=Goel%2C+A">Ashok Goel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Conceptual and simulation models can function as useful pedagogical tools,
however it is important to categorize different outcomes when evaluating them
in order to more meaningfully interpret results. VERA is a ecology-based
conceptual modeling software that enables users to simulate interactions
between biotics and abiotics in an ecosystem, allowing users to form and then
verify hypothesis through observing a time series of the species populations.
In this paper, we classify this time series into common patterns found in the
domain of ecological modeling through two methods, hierarchical clustering and
curve fitting, illustrating a general methodology for showing content validity
when combining different pedagogical tools. When applied to a diverse sample of
263 models containing 971 time series collected from three different VERA user
categories: a Georgia Tech (GATECH), North Georgia Technical College (NGTC),
and ``Self Directed Learners'', results showed agreement between both
classification methods on 89.38\% of the sample curves in the test set. This
serves as a good indication that our methodology for determining content
validity was successful.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06872" title="Abstract">arXiv:2312.06872</a> [<a href="/pdf/2312.06872" title="Download PDF">pdf</a>, <a href="/format/2312.06872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ELSA: Partial Weight Freezing for Overhead-Free Sparse Network  Deployment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Halvachi%2C+P">Paniz Halvachi</a>, 
<a href="/search/cs?searchtype=author&query=Peste%2C+A">Alexandra Peste</a>, 
<a href="/search/cs?searchtype=author&query=Alistarh%2C+D">Dan Alistarh</a>, 
<a href="/search/cs?searchtype=author&query=Lampert%2C+C+H">Christoph H. Lampert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We present ELSA, a practical solution for creating deep networks that can
easily be deployed at different levels of sparsity. The core idea is to embed
one or more sparse networks within a single dense network as a proper subset of
the weights. At prediction time, any sparse model can be extracted effortlessly
simply be zeroing out weights according to a predefined mask. ELSA is simple,
powerful and highly flexible. It can use essentially any existing technique for
network sparsification and network training. In particular, it does not
restrict the loss function, architecture or the optimization technique. Our
experiments show that ELSA's advantages of flexible deployment comes with no or
just a negligible reduction in prediction quality compared to the standard way
of using multiple sparse networks that are trained and stored independently.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06874" title="Abstract">arXiv:2312.06874</a> [<a href="/pdf/2312.06874" title="Download PDF">pdf</a>, <a href="/format/2312.06874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dozerformer: Sequence Adaptive Sparse Transformer for Multivariate Time  Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Rui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Dascalu%2C+S+M">Sergiu M. Dascalu</a>, 
<a href="/search/cs?searchtype=author&query=Harris%2C+F+C">Frederick C. Harris Jr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Transformers have achieved remarkable performance in multivariate time
series(MTS) forecasting due to their capability to capture long-term
dependencies. However, the canonical attention mechanism has two key
limitations: (1) its quadratic time complexity limits the sequence length, and
(2) it generates future values from the entire historical sequence. To address
this, we propose a Dozer Attention mechanism consisting of three sparse
components: (1) Local, each query exclusively attends to keys within a
localized window of neighboring time steps. (2) Stride, enables each query to
attend to keys at predefined intervals. (3) Vary, allows queries to selectively
attend to keys from a subset of the historical sequence. Notably, the size of
this subset dynamically expands as forecasting horizons extend. Those three
components are designed to capture essential attributes of MTS data, including
locality, seasonality, and global temporal dependencies. Additionally, we
present the Dozerformer Framework, incorporating the Dozer Attention mechanism
for the MTS forecasting task. We evaluated the proposed Dozerformer framework
with recent state-of-the-art methods on nine benchmark datasets and confirmed
its superior performance. The code will be released after the manuscript is
accepted.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06875" title="Abstract">arXiv:2312.06875</a> [<a href="/pdf/2312.06875" title="Download PDF">pdf</a>, <a href="/format/2312.06875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Oracle-based Protocol Testing with Eywa
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kakarla%2C+S+K+R">Siva Kesava Reddy Kakarla</a>, 
<a href="/search/cs?searchtype=author&query=Beckett%2C+R">Ryan Beckett</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">We present oracle-based testing a new technique for automatic black-box
testing of network protocol implementations. Oracle-based testing leverages
recent advances in LLMs to build rich models of intended protocol behavior from
knowledge embedded in RFCs, blogs, forums, and other natural language sources.
From these models it systematically derives exhaustive test cases using
symbolic program execution. We realize oracle-based testing through Eywa, a
novel protocol testing framework implemented in Python. To demonstrate Eywa's
effectiveness, we show its use through an extensive case study of the DNS
protocol. Despite requiring minimal effort, applying Eywa to the DNS resulting
in the discovery of 26 unique bugs across ten widely used DNS implementations,
including 11 new bugs that were previously undiscovered despite elaborate prior
testing with manually crafted models.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06876" title="Abstract">arXiv:2312.06876</a> [<a href="/pdf/2312.06876" title="Download PDF">pdf</a>, <a href="/format/2312.06876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Planning Using Large Language Models for Partially  Observable Robotics Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lingfeng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+D+K">Devesh K. Jha</a>, 
<a href="/search/cs?searchtype=author&query=Hori%2C+C">Chiori Hori</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Siddarth Jain</a>, 
<a href="/search/cs?searchtype=author&query=Corcodel%2C+R">Radu Corcodel</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xinghao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Tomizuka%2C+M">Masayoshi Tomizuka</a>, 
<a href="/search/cs?searchtype=author&query=Romeres%2C+D">Diego Romeres</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Designing robotic agents to perform open vocabulary tasks has been the
long-standing goal in robotics and AI. Recently, Large Language Models (LLMs)
have achieved impressive results in creating robotic agents for performing open
vocabulary tasks. However, planning for these tasks in the presence of
uncertainties is challenging as it requires \enquote{chain-of-thought}
reasoning, aggregating information from the environment, updating state
estimates, and generating actions based on the updated state estimates. In this
paper, we present an interactive planning technique for partially observable
tasks using LLMs. In the proposed method, an LLM is used to collect missing
information from the environment using a robot and infer the state of the
underlying problem from collected observations while guiding the robot to
perform the required actions. We also use a fine-tuned Llama 2 model via
self-instruct and compare its performance against a pre-trained LLM like GPT-4.
Results are demonstrated on several tasks in simulation as well as real-world
environments. A video describing our work along with some results could be
found here.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06877" title="Abstract">arXiv:2312.06877</a> [<a href="/pdf/2312.06877" title="Download PDF">pdf</a>, <a href="/ps/2312.06877" title="Download PostScript">ps</a>, <a href="/format/2312.06877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Differentiable Loss Function for Unsupervised Graph Neural  Networks in Graph Partitioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaudhary%2C+V">Vivek Chaudhary</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 Tables, 2 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper, we explore the graph partitioning problem, a pivotal
combina-torial optimization challenge with extensive applications in various
fields such as science, technology, and business. Recognized as an NP-hard
prob-lem, graph partitioning lacks polynomial-time algorithms for its
resolution. Recently, there has been a burgeoning interest in leveraging
machine learn-ing, particularly approaches like supervised, unsupervised, and
reinforce-ment learning, to tackle such NP-hard problems. However, these
methods face significant hurdles: supervised learning is constrained by the
necessity of labeled solution instances, which are often computationally
impractical to obtain; reinforcement learning grapples with instability in the
learning pro-cess; and unsupervised learning contends with the absence of a
differentia-ble loss function, a consequence of the discrete nature of most
combinatorial optimization problems. Addressing these challenges, our research
introduces a novel pipeline employing an unsupervised graph neural network to
solve the graph partitioning problem. The core innovation of this study is the
for-mulation of a differentiable loss function tailored for this purpose. We
rigor-ously evaluate our methodology against contemporary state-of-the-art
tech-niques, focusing on metrics: cuts and balance, and our findings reveal
that our is competitive with these leading methods.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06881" title="Abstract">arXiv:2312.06881</a> [<a href="/pdf/2312.06881" title="Download PDF">pdf</a>, <a href="/format/2312.06881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DYAD: A Descriptive Yet Abjuring Density efficient approximation to  linear neural network layers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chandy%2C+S">Sarin Chandy</a>, 
<a href="/search/cs?searchtype=author&query=Gangal%2C+V">Varun Gangal</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Maggiotti%2C+G">Gabriel Maggiotti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WANT workshop at NeurIPS 2023; code at <a href="https://github.com/asappresearch/dyad">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">We devise, implement and performance-asses DYAD, a layer which can serve as a
faster and more memory-efficient approximate replacement for linear layers,
(nn.Linear() in Pytorch). These layers appear in common subcomponents, such as
in the ff module of Transformers. DYAD is based on a bespoke near-sparse matrix
structure which approximates the dense "weight" matrix W that matrix-multiplies
the input in the typical realization of such a layer, a.k.a DENSE. Our
alternative near-sparse matrix structure is decomposable to a sum of 2 matrices
permutable to a block-sparse counterpart. These can be represented as 3D
tensors, which in unison allow a faster execution of matrix multiplication with
the mini-batched input matrix X compared to DENSE (O(rows(W ) x cols(W )) --&gt;
O( rows(W ) x cols(W ) # of blocks )). As the crux of our experiments, we
pretrain both DYAD and DENSE variants of 2 sizes of the OPT arch and 1 size of
the Pythia arch, including at different token scales of the babyLM benchmark.
We find DYAD to be competitive (&gt;= 90%) of DENSE performance on zero-shot (e.g.
BLIMP), few-shot (OPENLM) and finetuning (GLUE) benchmarks, while being &gt;=7-15%
faster to train on-GPU even at 125m scale, besides surfacing larger speedups at
increasing scale and model width.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06885" title="Abstract">arXiv:2312.06885</a> [<a href="/pdf/2312.06885" title="Download PDF">pdf</a>, <a href="/format/2312.06885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral Koopman Method for Identifying Stability Boundary
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Umathe%2C+B">Bhagyashree Umathe</a>, 
<a href="/search/eess?searchtype=author&query=Vaidya%2C+U">Umesh Vaidya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The paper is about characterizing the stability boundary of an autonomous
dynamical system using the Koopman spectrum. For a dynamical system with an
asymptotically stable equilibrium point, the domain of attraction constitutes a
region consisting of all initial conditions attracted to the equilibrium point.
The stability boundary is a separatrix region that separates the domain of
attraction from the rest of the state space. For a large class of dynamical
systems, this stability boundary consists of the union of stable manifolds of
all the unstable equilibrium points on the stability boundary. We characterize
the stable manifold in terms of the zero-level curve of the Koopman
eigenfunction. A path-integral formula is proposed to compute the Koopman
eigenfunction for a saddle-type equilibrium point on the stability boundary.
The algorithm for identifying stability boundary based on the Koopman
eigenfunction is attractive as it does not involve explicit knowledge of system
dynamics. We present simulation results to verify the main results of the
paper.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06886" title="Abstract">arXiv:2312.06886</a> [<a href="/pdf/2312.06886" title="Download PDF">pdf</a>, <a href="/format/2312.06886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relightful Harmonization: Lighting-aware Portrait Background Replacement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+M">Mengwei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+W">Wei Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+J+S">Jae Shin Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+Z">Zhixin Shu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+H">HyunJoon Jung</a>, 
<a href="/search/cs?searchtype=author&query=Gerig%2C+G">Guido Gerig</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">He Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Portrait harmonization aims to composite a subject into a new background,
adjusting its lighting and color to ensure harmony with the background scene.
Existing harmonization techniques often only focus on adjusting the global
color and brightness of the foreground and ignore crucial illumination cues
from the background such as apparent lighting direction, leading to unrealistic
compositions. We introduce Relightful Harmonization, a lighting-aware diffusion
model designed to seamlessly harmonize sophisticated lighting effect for the
foreground portrait using any background image. Our approach unfolds in three
stages. First, we introduce a lighting representation module that allows our
diffusion model to encode lighting information from target image background.
Second, we introduce an alignment network that aligns lighting features learned
from image background with lighting features learned from panorama environment
maps, which is a complete representation for scene illumination. Last, to
further boost the photorealism of the proposed method, we introduce a novel
data simulation pipeline that generates synthetic training pairs from a diverse
range of natural images, which are used to refine the model. Our method
outperforms existing benchmarks in visual fidelity and lighting coherence,
showing superior generalization in real-world testing scenarios, highlighting
its versatility and practicality.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06887" title="Abstract">arXiv:2312.06887</a> [<a href="/pdf/2312.06887" title="Download PDF">pdf</a>, <a href="/format/2312.06887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding and Leveraging the Learning Phases of Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schneider%2C+J">Johannes Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Prabhushanka%2C+M">Mohit Prabhushanka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted paper at AAAI 2024. This is the extended version with all proofs and additional datasets
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The learning dynamics of deep neural networks are not well understood. The
information bottleneck (IB) theory proclaimed separate fitting and compression
phases. But they have since been heavily debated. We comprehensively analyze
the learning dynamics by investigating a layer's reconstruction ability of the
input and prediction performance based on the evolution of parameters during
training. We empirically show the existence of three phases using common
datasets and architectures such as ResNet and VGG: (i) near constant
reconstruction loss, (ii) decrease, and (iii) increase. We also derive an
empirically grounded data model and prove the existence of phases for
single-layer networks. Technically, our approach leverages classical complexity
analysis. It differs from IB by relying on measuring reconstruction loss rather
than information theoretic measures to relate information of intermediate
layers and inputs. Our work implies a new best practice for transfer learning:
We show empirically that the pre-training of a classifier should stop well
before its performance is optimal.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06892" title="Abstract">arXiv:2312.06892</a> [<a href="/pdf/2312.06892" title="Download PDF">pdf</a>, <a href="/ps/2312.06892" title="Download PostScript">ps</a>, <a href="/format/2312.06892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VitalLens: Take A Vital Selfie
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rouast%2C+P+V">Philipp V. Rouast</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">This report introduces VitalLens, an app that estimates vital signs such as
heart rate and respiration rate from selfie video in real time. VitalLens uses
a computer vision model trained on a diverse dataset of video and physiological
sensor data. We benchmark performance on several diverse datasets, including
VV-Medium, which consists of 289 unique participants. VitalLens outperforms
several existing methods including POS and MTTS-CAN on all datasets while
maintaining a fast inference speed. On VV-Medium, VitalLens achieves absolute
errors of 0.71 bpm for heart rate estimation, and 0.76 rpm for respiratory rate
estimation.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06893" title="Abstract">arXiv:2312.06893</a> [<a href="/pdf/2312.06893" title="Download PDF">pdf</a>, <a href="/format/2312.06893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Styx: Deterministic Transactional Serverless Functions on Streaming  Dataflows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Psarakis%2C+K">Kyriakos Psarakis</a>, 
<a href="/search/cs?searchtype=author&query=Siachamis%2C+G">George Siachamis</a>, 
<a href="/search/cs?searchtype=author&query=Christodoulou%2C+G">George Christodoulou</a>, 
<a href="/search/cs?searchtype=author&query=Fragkoulis%2C+M">Marios Fragkoulis</a>, 
<a href="/search/cs?searchtype=author&query=Katsifodimos%2C+A">Asterios Katsifodimos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Databases (cs.DB)

</div>
<p class="mathjax">Is it possible to execute stateful serverless functions with transactional
guarantees at high performance through a high-level programming model? In this
work, we present Styx, the first stateful serverless runtime to guarantee
serializable transactions through a high-level programming model that
eliminates transaction and failure management code from cloud applications. To
avoid expensive locking mechanisms and enable high concurrency, Styx extends
the concept of deterministic databases to execute transactional stateful
serverless functions and contributes a novel distributed streaming dataflow
engine that guarantees exactly-once processing semantics over arbitrary
function-to-function calls. As a result, Styx outperforms state-of-the-art
approaches by achieving at least one order of magnitude lower median latency
and two orders of magnitude lower 99th percentile latency in a fully
transactional workload while achieving 2-4x gains in throughput in microservice
workflows.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06899" title="Abstract">arXiv:2312.06899</a> [<a href="/pdf/2312.06899" title="Download PDF">pdf</a>, <a href="/format/2312.06899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LoRA-Enhanced Distillation on Guided Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Golnari%2C+P+A">Pareesa Ameneh Golnari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion models, such as Stable Diffusion (SD), offer the ability to
generate high-resolution images with diverse features, but they come at a
significant computational and memory cost. In classifier-free guided diffusion
models, prolonged inference times are attributed to the necessity of computing
two separate diffusion models at each denoising step. Recent work has shown
promise in improving inference time through distillation techniques, teaching
the model to perform similar denoising steps with reduced computations.
However, the application of distillation introduces additional memory overhead
to these already resource-intensive diffusion models, making it less practical.
<br />To address these challenges, our research explores a novel approach that
combines Low-Rank Adaptation (LoRA) with model distillation to efficiently
compress diffusion models. This approach not only reduces inference time but
also mitigates memory overhead, and notably decreases memory consumption even
before applying distillation. The results are remarkable, featuring a
significant reduction in inference time due to the distillation process and a
substantial 50% reduction in memory consumption. Our examination of the
generated images underscores that the incorporation of LoRA-enhanced
distillation maintains image quality and alignment with the provided prompts.
In summary, while conventional distillation tends to increase memory
consumption, LoRA-enhanced distillation offers optimization without any
trade-offs or compromises in quality.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06900" title="Abstract">arXiv:2312.06900</a> [<a href="/pdf/2312.06900" title="Download PDF">pdf</a>, <a href="/format/2312.06900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Bio-Inspired Computing meets Deep Learning: Low-Latency, Accurate,  &amp; Energy-Efficient Spiking Neural Networks from Artificial Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Datta%2C+G">Gourav Datta</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zeyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Diffenderfer%2C+J">James Diffenderfer</a>, 
<a href="/search/cs?searchtype=author&query=Kailkhura%2C+B">Bhavya Kailkhura</a>, 
<a href="/search/cs?searchtype=author&query=Beerel%2C+P+A">Peter A. Beerel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Bio-inspired Spiking Neural Networks (SNN) are now demonstrating comparable
accuracy to intricate convolutional neural networks (CNN), all while delivering
remarkable energy and latency efficiency when deployed on neuromorphic
hardware. In particular, ANN-to-SNN conversion has recently gained significant
traction in developing deep SNNs with close to state-of-the-art (SOTA) test
accuracy on complex image recognition tasks. However, advanced ANN-to-SNN
conversion approaches demonstrate that for lossless conversion, the number of
SNN time steps must equal the number of quantization steps in the ANN
activation function. Reducing the number of time steps significantly increases
the conversion error. Moreover, the spiking activity of the SNN, which
dominates the compute energy in neuromorphic chips, does not reduce
proportionally with the number of time steps. To mitigate the accuracy concern,
we propose a novel ANN-to-SNN conversion framework, that incurs an
exponentially lower number of time steps compared to that required in the SOTA
conversion approaches. Our framework modifies the SNN integrate-and-fire (IF)
neuron model with identical complexity and shifts the bias term of each batch
normalization (BN) layer in the trained ANN. To mitigate the spiking activity
concern, we propose training the source ANN with a fine-grained L1 regularizer
with surrogate gradients that encourages high spike sparsity in the converted
SNN. Our proposed framework thus yields lossless SNNs with ultra-low latency,
ultra-low compute energy, thanks to the ultra-low timesteps and high spike
sparsity, and ultra-high test accuracy, for example, 73.30% with only 4 time
steps on the ImageNet dataset.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06901" title="Abstract">arXiv:2312.06901</a> [<a href="/pdf/2312.06901" title="Download PDF">pdf</a>, <a href="/format/2312.06901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Extractive Summarization with Learnable Length Control  Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jie%2C+R">Renlong Jie</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+X">Xiaojun Meng</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qun Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Unsupervised extractive summarization is an important technique in
information extraction and retrieval. Compared with supervised method, it does
not require high-quality human-labelled summaries for training and thus can be
easily applied for documents with different types, domains or languages. Most
of existing unsupervised methods including TextRank and PACSUM rely on
graph-based ranking on sentence centrality. However, this scorer can not be
directly applied in end-to-end training, and the positional-related prior
assumption is often needed for achieving good summaries. In addition, less
attention is paid to length-controllable extractor, where users can decide to
summarize texts under particular length constraint. This paper introduces an
unsupervised extractive summarization model based on a siamese network, for
which we develop a trainable bidirectional prediction objective between the
selected summary and the original document. Different from the centrality-based
ranking methods, our extractive scorer can be trained in an end-to-end manner,
with no other requirement of positional assumption. In addition, we introduce a
differentiable length control module by approximating 0-1 knapsack solver for
end-to-end length-controllable extracting. Experiments show that our
unsupervised method largely outperforms the centrality-based baseline using a
same sentence encoder. In terms of length control ability, via our trainable
knapsack module, the performance consistently outperforms the strong baseline
without utilizing end-to-end training. Human evaluation further evidences that
our method performs the best among baselines in terms of relevance and
consistency.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06902" title="Abstract">arXiv:2312.06902</a> [<a href="/pdf/2312.06902" title="Download PDF">pdf</a>, <a href="/format/2312.06902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perseus: Removing Energy Bloat from Large Model Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chung%2C+J">Jae-Won Chung</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yile Gu</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+I">Insu Jang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+L">Luoxi Meng</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+N">Nikhil Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+M">Mosharaf Chowdhury</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Open-source at <a href="https://ml.energy/zeus/perseus/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Training large AI models on numerous GPUs consumes a massive amount of
energy. We observe that not all energy consumed during training directly
contributes to end-to-end training throughput, and a significant portion can be
removed without slowing down training, which we call energy bloat.
<br />In this work, we identify two independent sources of energy bloat in large
model training, intrinsic and extrinsic, and propose Perseus, a unified
optimization framework that mitigates both. Perseus obtains the "iteration
time-energy" Pareto frontier of any large model training job using an efficient
iterative graph cut-based algorithm and schedules energy consumption of its
forward and backward computations across time to remove intrinsic and extrinsic
energy bloat. Evaluation on large models like GPT-3 and Bloom shows that
Perseus reduces energy consumption of large model training by up to 30%,
enabling savings otherwise unobtainable before.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06904" title="Abstract">arXiv:2312.06904</a> [<a href="/pdf/2312.06904" title="Download PDF">pdf</a>, <a href="/format/2312.06904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced Q-Learning Approach to Finite-Time Reachability with Maximum  Probability for Probabilistic Boolean Control Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fan%2C+H">Hongyue Fan</a>, 
<a href="/search/eess?searchtype=author&query=Ni%2C+J">Jingjie Ni</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+F">Fangfei Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, we investigate the problem of controlling probabilistic
Boolean control networks (PBCNs) to achieve reachability with maximum
probability in the finite time horizon. We address three questions: 1) finding
control policies that achieve reachability with maximum probability under
fixed, and particularly, varied finite time horizon, 2) leveraging prior
knowledge to solve question 1) with faster convergence speed in scenarios where
time is a variable framework, and 3) proposing an enhanced Q-learning (QL)
method to efficiently address the aforementioned questions for large-scale
PBCNs. For question 1), we demonstrate the applicability of QL method on the
finite-time reachability problem. For question 2), considering the possibility
of varied time frames, we incorporate transfer learning (TL) technique to
leverage prior knowledge and enhance convergence speed. For question 3), an
enhanced model-free QL approach that improves upon the traditional QL algorithm
by introducing memory-efficient modifications to address these issues in
large-scale PBCNs effectively. Finally, we apply the proposed method to two
examples: a small-scale PBCN and a large-scale PBCN, demonstrating the
effectiveness of our approach.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06908" title="Abstract">arXiv:2312.06908</a> [<a href="/pdf/2312.06908" title="Download PDF">pdf</a>, <a href="/format/2312.06908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;I Want It That Way&quot;: Enabling Interactive Decision Support Using Large  Language Models and Constraint Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lawless%2C+C">Connor Lawless</a>, 
<a href="/search/cs?searchtype=author&query=Schoeffer%2C+J">Jakob Schoeffer</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+L">Lindy Le</a>, 
<a href="/search/cs?searchtype=author&query=Rowan%2C+K">Kael Rowan</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+S">Shilad Sen</a>, 
<a href="/search/cs?searchtype=author&query=Hill%2C+C+S">Cristina St. Hill</a>, 
<a href="/search/cs?searchtype=author&query=Suh%2C+J">Jina Suh</a>, 
<a href="/search/cs?searchtype=author&query=Sarrafzadeh%2C+B">Bahar Sarrafzadeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">A critical factor in the success of decision support systems is the accurate
modeling of user preferences. Psychology research has demonstrated that users
often develop their preferences during the elicitation process, highlighting
the pivotal role of system-user interaction in developing personalized systems.
This paper introduces a novel approach, combining Large Language Models (LLMs)
with Constraint Programming to facilitate interactive decision support. We
study this hybrid framework through the lens of meeting scheduling, a
time-consuming daily activity faced by a multitude of information workers. We
conduct three studies to evaluate the novel framework, including a diary study
(n=64) to characterize contextual scheduling preferences, a quantitative
evaluation of the system's performance, and a user study (n=10) with a
prototype system. Our work highlights the potential for a hybrid LLM and
optimization approach for iterative preference elicitation and design
considerations for building systems that support human-system collaborative
decision-making processes.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06910" title="Abstract">arXiv:2312.06910</a> [<a href="/pdf/2312.06910" title="Download PDF">pdf</a>, <a href="/format/2312.06910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strong convergence of a class of adaptive numerical methods for SDEs  with jumps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kelly%2C+C">C&#xf3;nall Kelly</a>, 
<a href="/search/math?searchtype=author&query=Lord%2C+G">Gabriel Lord</a>, 
<a href="/search/math?searchtype=author&query=Sun%2C+F">Fandi Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
<p class="mathjax">We develop adaptive time-stepping strategies for It\^o-type stochastic
differential equations (SDEs) with jump perturbations. Our approach builds on
adaptive strategies for SDEs. Adaptive methods can ensure strong convergence of
nonlinear SDEs with drift and diffusion coefficients that violate global
Lipschitz bounds by adjusting the stepsize dynamically on each trajectory to
prevent spurious growth that can lead to loss of convergence if it occurs with
sufficiently high probability. In this article we demonstrate the use of a
jump-adapted mesh that incorporates jump times into the adaptive time-stepping
strategy. We prove that any adaptive scheme satisfying a particular mean-square
consistency bound for a nonlinear SDE in the non-jump case may be extended to a
strongly convergent scheme in the Poisson jump case where jump and diffusion
perturbations are mutually independent and the jump coefficient satisfies a
global Lipschitz condition.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06914" title="Abstract">arXiv:2312.06914</a> [<a href="/pdf/2312.06914" title="Download PDF">pdf</a>, <a href="/format/2312.06914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Novel Object Recognition and Spontaneous Location Recognition  Machine Learning Analysis Techniques in Alzheimer&#x27;s Mice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bafana%2C+S">Soham Bafana</a>, 
<a href="/search/cs?searchtype=author&query=Raghuraman%2C+R">Radha Raghuraman</a>, 
<a href="/search/cs?searchtype=author&query=Hussaini%2C+S+A">S. Abid Hussaini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 Pages. All code used in this research can be found at <a href="https://github.com/bafanaS/DLC-Object-Recognition-Analysis.git">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Understanding object recognition patterns in mice is crucial for advancing
behavioral neuroscience and has significant implications for human health,
particularly in the realm of Alzheimer's research. This study is centered on
the development, application, and evaluation of a state-of-the-art
computational pipeline designed to analyze such behaviors, specifically
focusing on Novel Object Recognition (NOR) and Spontaneous Location Recognition
(SLR) tasks. The pipeline integrates three advanced computational models:
Any-Maze for initial data collection, DeepLabCut for detailed pose estimation,
and Convolutional Neural Networks (CNNs) for nuanced behavioral classification.
Employed across four distinct mouse groups, this pipeline demonstrated high
levels of accuracy and robustness. Despite certain challenges like video
quality limitations and the need for manual calculations, the results affirm
the pipeline's efficacy and potential for scalability. The study serves as a
proof of concept for a multidimensional computational approach to behavioral
neuroscience, emphasizing the pipeline's versatility and readiness for future,
more complex analyses.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06919" title="Abstract">arXiv:2312.06919</a> [<a href="/pdf/2312.06919" title="Download PDF">pdf</a>, <a href="/format/2312.06919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolving Neural Network (ENN) Method for One-Dimensional Scalar  Hyperbolic Conservation Laws: I Linear and Quadratic Fluxes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cai%2C+Z">Zhiqiang Cai</a>, 
<a href="/search/math?searchtype=author&query=Hejnal%2C+B">Brooke Hejnal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose and study the evolving neural network (ENN) method for solving
one-dimensional scalar hyperbolic conservation laws with linear and quadratic
spatial fluxes. The ENN method first represents the initial data and the inflow
boundary data by neural networks. Then, it evolves the neural network
representation of the initial data along the temporal direction. The evolution
is computed using a combination of characteristic and finite volume methods.
For the linear spatial flux, the method is not subject to any time step size,
and it is shown theoretically that the error at any time step is bounded by the
representation errors of the initial and boundary condition. For the quadratic
flux, an error estimate is studied in a companion paper. Finally, numerical
results for the linear advection equation and the inviscid Burgers equation are
presented to show that the ENN method is more accurate and cost efficient than
traditional mesh-based methods.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06920" title="Abstract">arXiv:2312.06920</a> [<a href="/pdf/2312.06920" title="Download PDF">pdf</a>, <a href="/format/2312.06920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pain Analysis using Adaptive Hierarchical Spatiotemporal Dynamic Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Serraoui%2C+I">Issam Serraoui</a>, 
<a href="/search/cs?searchtype=author&query=Granger%2C+E">Eric Granger</a>, 
<a href="/search/cs?searchtype=author&query=Hadid%2C+A">Abdenour Hadid</a>, 
<a href="/search/cs?searchtype=author&query=Taleb-Ahmed%2C+A">Abdelmalik Taleb-Ahmed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Automatic pain intensity estimation plays a pivotal role in healthcare and
medical fields. While many methods have been developed to gauge human pain
using behavioral or physiological indicators, facial expressions have emerged
as a prominent tool for this purpose. Nevertheless, the dependence on labeled
data for these techniques often renders them expensive and time-consuming. To
tackle this, we introduce the Adaptive Hierarchical Spatio-temporal Dynamic
Image (AHDI) technique. AHDI encodes spatiotemporal changes in facial videos
into a singular RGB image, permitting the application of simpler 2D deep models
for video representation. Within this framework, we employ a residual network
to derive generalized facial representations. These representations are
optimized for two tasks: estimating pain intensity and differentiating between
genuine and simulated pain expressions. For the former, a regression model is
trained using the extracted representations, while for the latter, a binary
classifier identifies genuine versus feigned pain displays. Testing our method
on two widely-used pain datasets, we observed encouraging results for both
tasks. On the UNBC database, we achieved an MSE of 0.27 outperforming the SOTA
which had an MSE of 0.40. On the BioVid dataset, our model achieved an accuracy
of 89.76%, which is an improvement of 5.37% over the SOTA accuracy. Most
notably, for distinguishing genuine from simulated pain, our accuracy stands at
94.03%, marking a substantial improvement of 8.98%. Our methodology not only
minimizes the need for extensive labeled data but also augments the precision
of pain evaluations, facilitating superior pain management.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06923" title="Abstract">arXiv:2312.06923</a> [<a href="/pdf/2312.06923" title="Download PDF">pdf</a>, <a href="/format/2312.06923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear Expectation Inference for Direct Uncertainty Quantification of  Nonlinear Inverse Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+Z">Zhao Zhang</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+X">Xinpeng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
<p class="mathjax">Most existing inference methods for the uncertainty quantification of
nonlinear inverse problems need repetitive runs of the forward model which is
computationally expensive for high-dimensional problems, where the forward
model is expensive and the inference need more iterations. These methods are
generally based on the Bayes' rule and implicitly assume that the probability
distribution is unique, which is not the case for scenarios with Knightian
uncertainty. In the current study, we assume that the probability distribution
is uncertain, and establish a new inference method based on the nonlinear
expectation theory for 'direct' uncertainty quantification of nonlinear inverse
problems. The uncertainty of random parameters is quantified using the
sublinear expectation defined as the limits of an ensemble of linear
expectations estimated on samples. Given noisy observed data, the posterior
sublinear expectation is computed using posterior linear expectations with
highest likelihoods. In contrary to iterative inference methods, the new
nonlinear expectation inference method only needs forward model runs on the
prior samples, while subsequent evaluations of linear and sublinear
expectations requires no forward model runs, thus quantifying uncertainty
directly which is more efficient than iterative inference methods. The new
method is analysed and validated using 2D and 3D test cases of transient Darcy
flows.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06924" title="Abstract">arXiv:2312.06924</a> [<a href="/pdf/2312.06924" title="Download PDF">pdf</a>, <a href="/format/2312.06924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safety Alignment in NLP Tasks: Weakly Aligned Summarization as an  In-Context Attack
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yufei Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+W">Wen Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yue Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages,10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent developments in balancing the usefulness and safety of Large Language
Models (LLMs) have raised a critical question: Are mainstream NLP tasks
adequately aligned with safety consideration? Our study, focusing on
safety-sensitive documents obtained through adversarial attacks, reveals
significant disparities in the safety alignment of various NLP tasks. For
instance, LLMs can effectively summarize malicious long documents but often
refuse to translate them. This discrepancy highlights a previously unidentified
vulnerability: attacks exploiting tasks with weaker safety alignment, like
summarization, can potentially compromise the integraty of tasks traditionally
deemed more robust, such as translation and question-answering (QA). Moreover,
the concurrent use of multiple NLP tasks with lesser safety alignment increases
the risk of LLMs inadvertently processing harmful content. We demonstrate these
vulnerabilities in various safety-aligned LLMs, particularly Llama2 models and
GPT-4, indicating an urgent need for strengthening safety alignments across a
broad spectrum of NLP tasks.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06925" title="Abstract">arXiv:2312.06925</a> [<a href="/pdf/2312.06925" title="Download PDF">pdf</a>, <a href="/format/2312.06925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Facial Emotion Recognition in VR Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dehghani%2C+F">Fatemeh Dehghani</a>, 
<a href="/search/cs?searchtype=author&query=Zaman%2C+L">Loutfouz Zaman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Conference on Games 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Emotion detection is a crucial component of Games User Research (GUR), as it
allows game developers to gain insights into players' emotional experiences and
tailor their games accordingly. However, detecting emotions in Virtual Reality
(VR) games is challenging due to the Head-Mounted Display (HMD) that covers the
top part of the player's face, namely, their eyes and eyebrows, which provide
crucial information for recognizing the impression. To tackle this we used a
Convolutional Neural Network (CNN) to train a model to predict emotions in
full-face images where the eyes and eyebrows are covered. We used the FER2013
dataset, which we modified to cover eyes and eyebrows in images. The model in
these images can accurately recognize seven different emotions which are anger,
happiness, disgust, fear, impartiality, sadness and surprise.
<br />We assessed the model's performance by testing it on two VR games and using
it to detect players' emotions. We collected self-reported emotion data from
the players after the gameplay sessions. We analyzed the data collected from
our experiment to understand which emotions players experience during the
gameplay. We found that our approach has the potential to enhance gameplay
analysis by enabling the detection of players' emotions in VR games, which can
help game developers create more engaging and immersive game experiences.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06926" title="Abstract">arXiv:2312.06926</a> [<a href="/pdf/2312.06926" title="Download PDF">pdf</a>, <a href="/format/2312.06926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Content-Localization based Neural Machine Translation for Informal  Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alzamzami%2C+F">Fatimah Alzamzami</a>, 
<a href="/search/cs?searchtype=author&query=Saddik%2C+A+E">Abdulmotaleb El Saddik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2312.03727">arXiv:2312.03727</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Resources in high-resource languages have not been efficiently exploited in
low-resource languages to solve language-dependent research problems. Spanish
and French are considered high resource languages in which an adequate level of
data resources for informal online social behavior modeling, is observed.
However, a machine translation system to access those data resources and
transfer their context and tone to a low-resource language like dialectal
Arabic, does not exist. In response, we propose a framework that localizes
contents of high-resource languages to a low-resource language/dialects by
utilizing AI power. To the best of our knowledge, we are the first work to
provide a parallel translation dataset from/to informal Spanish and French
to/from informal Arabic dialects. Using this, we aim to enrich the
under-resource-status dialectal Arabic and fast-track the research of diverse
online social behaviors within and across smart cities in different
geo-regions. The experimental results have illustrated the capability of our
proposed solution in exploiting the resources between high and low resource
languages and dialects. Not only this, but it has also been proven that
ignoring dialects within the same language could lead to misleading analysis of
online social behavior.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06928" title="Abstract">arXiv:2312.06928</a> [<a href="/pdf/2312.06928" title="Download PDF">pdf</a>, <a href="/format/2312.06928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blockchain-Based Security Architecture for Unmanned Aerial Vehicles in  B5G/6G Services and Beyond: A Comprehensive Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jagatheesaperumal%2C+S+K">Senthil Kumar Jagatheesaperumal</a>, 
<a href="/search/cs?searchtype=author&query=Rahouti%2C+M">Mohamed Rahouti</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+K">Kaiqi Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Chehri%2C+A">Abdellah Chehri</a>, 
<a href="/search/cs?searchtype=author&query=Ghani%2C+N">Nasir Ghani</a>, 
<a href="/search/cs?searchtype=author&query=Bieniek%2C+J">Jan Bieniek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 6 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Unmanned Aerial Vehicles (UAVs), previously favored by enthusiasts, have
evolved into indispensable tools for effectively managing disasters and
responding to emergencies. For example, one of their most critical applications
is to provide seamless wireless communication services in remote rural areas.
Thus, it is substantial to identify and consider the different security
challenges in the research and development associated with advanced UAV-based
B5G/6G architectures. Following this requirement, the present study thoroughly
examines the security considerations about UAVs in relation to the
architectural framework of the 5G/6G system, the technologies that facilitate
its operation, and the concerns surrounding privacy. It exhibits security
integration at all the protocol stack layers and analyzes the existing
mechanisms to secure UAV-based B5G/6G communications and its energy and power
optimization factors. Last, this article also summarizes modern technological
trends for establishing security and protecting UAV-based systems, along with
the open challenges and strategies for future research work.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06932" title="Abstract">arXiv:2312.06932</a> [<a href="/pdf/2312.06932" title="Download PDF">pdf</a>, <a href="/format/2312.06932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predictive variational autoencoder for learning robust representations  of time-series data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J+H">Julia Huiming Wang</a> (1), 
<a href="/search/cs?searchtype=author&query=Tsin%2C+D">Dexter Tsin</a> (2), 
<a href="/search/cs?searchtype=author&query=Engel%2C+T">Tatiana Engel</a> (2) ((1) Cold Spring Harbor School of Biological Sciences, (2) Princeton Neuroscience Institute)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 4 main figures, 4 supplemental figures, accepted for publication at Unireps Workshop in 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Variational autoencoders (VAEs) have been used extensively to discover
low-dimensional latent factors governing neural activity and animal behavior.
However, without careful model selection, the uncovered latent factors may
reflect noise in the data rather than true underlying features, rendering such
representations unsuitable for scientific interpretation. Existing solutions to
this problem involve introducing additional measured variables or data
augmentations specific to a particular data type. We propose a VAE architecture
that predicts the next point in time and show that it mitigates the learning of
spurious features. In addition, we introduce a model selection metric based on
smoothness over time in the latent space. We show that together these two
constraints on VAEs to be smooth over time produce robust latent
representations and faithfully recover latent factors on synthetic datasets.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06934" title="Abstract">arXiv:2312.06934</a> [<a href="/pdf/2312.06934" title="Download PDF">pdf</a>, <a href="/format/2312.06934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Real Text Manipulation Detection: New Dataset and New Solution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+D">Dongliang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Rui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianjin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+J">Jishen Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiang Bai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the surge in realistic text tampering, detecting fraudulent text in
images has gained prominence for maintaining information security. However, the
high costs associated with professional text manipulation and annotation limit
the availability of real-world datasets, with most relying on synthetic
tampering, which inadequately replicates real-world tampering attributes. To
address this issue, we present the Real Text Manipulation (RTM) dataset,
encompassing 14,250 text images, which include 5,986 manually and 5,258
automatically tampered images, created using a variety of techniques, alongside
3,006 unaltered text images for evaluating solution stability. Our evaluations
indicate that existing methods falter in text forgery detection on the RTM
dataset. We propose a robust baseline solution featuring a Consistency-aware
Aggregation Hub and a Gated Cross Neighborhood-attention Fusion module for
efficient multi-modal information fusion, supplemented by a Tampered-Authentic
Contrastive Learning module during training, enriching feature representation
distinction. This framework, extendable to other dual-stream architectures,
demonstrated notable localization performance improvements of 7.33% and 6.38%
on manual and overall manipulations, respectively. Our contributions aim to
propel advancements in real-world text tampering detection. Code and dataset
will be made available at https://github.com/DrLuo/RTM
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06936" title="Abstract">arXiv:2312.06936</a> [<a href="/pdf/2312.06936" title="Download PDF">pdf</a>, <a href="/format/2312.06936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparison of Interfaces for Learning How to Play a Mixed Reality  Handpan
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gosling%2C+G">Gavin Gosling</a>, 
<a href="/search/cs?searchtype=author&query=Catovic%2C+I">Ivan-teofil Catovic</a>, 
<a href="/search/cs?searchtype=author&query=Bangash%2C+G">Ghazal Bangash</a>, 
<a href="/search/cs?searchtype=author&query=MacCormick%2C+D">Daniel MacCormick</a>, 
<a href="/search/cs?searchtype=author&query=Zaman%2C+L">Loutfouz Zaman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE GEM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In the realm of music therapy, Virtual Reality (VR) has a long-standing
history of enriching human experiences through immersive applications, spanning
entertainment games, serious games, and professional training in various
fields. However, the untapped potential lies in using VR games to support
mindfulness through music. We present a new approach utilizing a virtual
environment to facilitate learning how to play the handpan -- an instrument in
the shape of a spherical dish with harmonically tuned notes used commonly in
the sound healing practice of mindfulness. In a preliminary study, we compared
six interfaces, where the highlighted path interface performed best. However,
participants expressed preference for the standard interface inspired by rhythm
games like Guitar Hero.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06937" title="Abstract">arXiv:2312.06937</a> [<a href="/pdf/2312.06937" title="Download PDF">pdf</a>, <a href="/ps/2312.06937" title="Download PostScript">ps</a>, <a href="/format/2312.06937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can a Transformer Represent a Kalman Filter?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goel%2C+G">Gautam Goel</a>, 
<a href="/search/cs?searchtype=author&query=Bartlett%2C+P">Peter Bartlett</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Transformers are a class of autoregressive deep learning architectures which
have recently achieved state-of-the-art performance in various vision,
language, and robotics tasks. We revisit the problem of Kalman Filtering in
linear dynamical systems and show that Transformers can approximate the Kalman
Filter in a strong sense. Specifically, for any observable LTI system we
construct an explicit causally-masked Transformer which implements the Kalman
Filter, up to a small additive error which is bounded uniformly in time; we
call our construction the Transformer Filter. Our construction is based on a
two-step reduction. We first show that a softmax self-attention block can
exactly represent a certain Gaussian kernel smoothing estimator. We then show
that this estimator closely approximates the Kalman Filter. We also investigate
how the Transformer Filter can be used for measurement-feedback control and
prove that the resulting nonlinear controllers closely approximate the
performance of standard optimal control policies such as the LQG controller.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06940" title="Abstract">arXiv:2312.06940</a> [<a href="/pdf/2312.06940" title="Download PDF">pdf</a>, <a href="/format/2312.06940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Deep Learning Classifiers for SAR Automatic Target  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fein-Ashley%2C+J">Jacob Fein-Ashley</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+T">Tian Ye</a>, 
<a href="/search/cs?searchtype=author&query=Kannan%2C+R">Rajgopal Kannan</a>, 
<a href="/search/cs?searchtype=author&query=Prasanna%2C+V">Viktor Prasanna</a>, 
<a href="/search/cs?searchtype=author&query=Busart%2C+C">Carl Busart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Synthetic Aperture Radar SAR Automatic Target Recognition ATR is a key
technique of remote-sensing image recognition which can be supported by deep
neural networks The existing works of SAR ATR mostly focus on improving the
accuracy of the target recognition while ignoring the systems performance in
terms of speed and storage which is critical to real-world applications of SAR
ATR For decision-makers aiming to identify a proper deep learning model to
deploy in a SAR ATR system it is important to understand the performance of
different candidate deep learning models and determine the best model
accordingly This paper comprehensively benchmarks several advanced deep
learning models for SAR ATR with multiple distinct SAR imagery datasets
Specifically we train and test five SAR image classifiers based on Residual
Neural Networks ResNet18 ResNet34 ResNet50 Graph Neural Network GNN and Vision
Transformer for Small-Sized Datasets (SS-ViT) We select three datasets MSTAR
GBSAR and SynthWakeSAR that offer heterogeneity We evaluate and compare the
five classifiers concerning their classification accuracy runtime performance
in terms of inference throughput and analytical performance in terms of number
of parameters number of layers model size and number of operations Experimental
results show that the GNN classifier outperforms with respect to throughput and
latency However it is also shown that no clear model winner emerges from all of
our chosen metrics and a one model rules all case is doubtful in the domain of
SAR ATR
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06941" title="Abstract">arXiv:2312.06941</a> [<a href="/pdf/2312.06941" title="Download PDF">pdf</a>, <a href="/ps/2312.06941" title="Download PostScript">ps</a>, <a href="/format/2312.06941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Humans vs Large Language Models: Judgmental Forecasting in an Era of  Advanced AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abolghasemi%2C+M">MAhdi Abolghasemi</a>, 
<a href="/search/cs?searchtype=author&query=Ganbold%2C+O">Odkhishig Ganbold</a>, 
<a href="/search/cs?searchtype=author&query=Rotaru%2C+K">Kristian Rotaru</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">This study investigates the forecasting accuracy of human experts versus
Large Language Models (LLMs) in the retail sector, particularly during standard
and promotional sales periods. Utilizing a controlled experimental setup with
123 human forecasters and five LLMs, including ChatGPT4, ChatGPT3.5, Bard,
Bing, and Llama2, we evaluated forecasting precision through Mean Absolute
Percentage Error. Our analysis centered on the effect of the following factors
on forecasters performance: the supporting statistical model (baseline and
advanced), whether the product was on promotion, and the nature of external
impact. The findings indicate that LLMs do not consistently outperform humans
in forecasting accuracy and that advanced statistical forecasting models do not
uniformly enhance the performance of either human forecasters or LLMs. Both
human and LLM forecasters exhibited increased forecasting errors, particularly
during promotional periods and under the influence of positive external
impacts. Our findings call for careful consideration when integrating LLMs into
practical forecasting processes.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06942" title="Abstract">arXiv:2312.06942</a> [<a href="/pdf/2312.06942" title="Download PDF">pdf</a>, <a href="/format/2312.06942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Control: Improving Safety Despite Intentional Subversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Greenblatt%2C+R">Ryan Greenblatt</a>, 
<a href="/search/cs?searchtype=author&query=Shlegeris%2C+B">Buck Shlegeris</a>, 
<a href="/search/cs?searchtype=author&query=Sachan%2C+K">Kshitij Sachan</a>, 
<a href="/search/cs?searchtype=author&query=Roger%2C+F">Fabien Roger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">As large language models (LLMs) become more powerful and are deployed more
autonomously, it will be increasingly important to prevent them from causing
harmful outcomes. Researchers have investigated a variety of safety techniques
for this purpose, e.g. using models to review the outputs of other models, or
red-teaming techniques to surface subtle failure modes. However, researchers
have not evaluated whether such techniques still ensure safety if the model is
itself intentionally trying to subvert them. In this paper, we develop and
evaluate pipelines of safety techniques ("protocols") that are robust to
intentional subversion.
<br />We investigate a scenario in which we want to solve a sequence of programming
problems, using access to a powerful but untrusted model (in our case, GPT-4),
access to a less powerful trusted model (in our case, GPT-3.5), and limited
access to human contractors who provide high-quality trusted labor. We
investigate protocols that aim to never submit solutions containing backdoors,
which we operationalize here as logical errors that are not caught by test
cases.
<br />We investigate a range of protocols and test each against strategies that the
untrusted model could use to subvert them. One protocol is what we call trusted
editing. This protocol first asks GPT-4 to write code, and then asks GPT-3.5 to
rate the suspiciousness of that code. If the code is below some suspiciousness
threshold, it is submitted. Otherwise, GPT-3.5 edits the solution to remove
parts that seem suspicious and then submits the edited code. Another protocol
is untrusted monitoring. This protocol asks GPT-4 to write code, and then asks
another instance of GPT-4 whether the code is backdoored, using various
techniques to prevent the GPT-4 instances from colluding. These protocols
improve substantially on simple baselines.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06946" title="Abstract">arXiv:2312.06946</a> [<a href="/pdf/2312.06946" title="Download PDF">pdf</a>, <a href="/format/2312.06946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WaterHE-NeRF: Water-ray Tracing Neural Radiance Fields for Underwater  Scene Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingchun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+T">Tianyu Liang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zongxin He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dehuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weishi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xianping Fu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chongyi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural Radiance Field (NeRF) technology demonstrates immense potential in
novel viewpoint synthesis tasks, due to its physics-based volumetric rendering
process, which is particularly promising in underwater scenes. Addressing the
limitations of existing underwater NeRF methods in handling light attenuation
caused by the water medium and the lack of real Ground Truth (GT) supervision,
this study proposes WaterHE-NeRF. We develop a new water-ray tracing field by
Retinex theory that precisely encodes color, density, and illuminance
attenuation in three-dimensional space. WaterHE-NeRF, through its illuminance
attenuation mechanism, generates both degraded and clear multi-view images and
optimizes image restoration by combining reconstruction loss with Wasserstein
distance. Additionally, the use of histogram equalization (HE) as pseudo-GT
enhances the network's accuracy in preserving original details and color
distribution. Extensive experiments on real underwater datasets and synthetic
datasets validate the effectiveness of WaterHE-NeRF. Our code will be made
publicly available.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06947" title="Abstract">arXiv:2312.06947</a> [<a href="/pdf/2312.06947" title="Download PDF">pdf</a>, <a href="/format/2312.06947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MaTe3D: Mask-guided Text-based 3D-aware Portrait Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kangneng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+D">Daiheng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xusen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Longhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shiqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bo%2C+L">Liefeng Bo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaxing Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, 3D-aware face editing has witnessed remarkable progress. Although
current approaches successfully perform mask-guided or text-based editing,
these properties have not been combined into a single method. To address this
limitation, we propose \textbf{MaTe3D}: mask-guided text-based 3D-aware
portrait editing. First, we propose a new SDF-based 3D generator. To better
perform masked-based editing (mainly happening in local areas), we propose SDF
and density consistency losses, aiming to effectively model both the global and
local representations jointly. Second, we introduce an inference-optimized
method. We introduce two techniques based on the SDS (Score Distillation
Sampling), including a blending SDS and a conditional SDS. The former aims to
overcome the mismatch problem between geometry and appearance, ultimately
harming fidelity. The conditional SDS contributes to further producing
satisfactory and stable results. Additionally, we create CatMask-HQ dataset, a
large-scale high-resolution cat face annotations. We perform experiments on
both the FFHQ and CatMask-HQ datasets to demonstrate the effectiveness of the
proposed method. Our method generates faithfully a edited 3D-aware face image
given a modified mask and a text prompt. Our code and models will be publicly
released.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06950" title="Abstract">arXiv:2312.06950</a> [<a href="/pdf/2312.06950" title="Download PDF">pdf</a>, <a href="/format/2312.06950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> READ-PVLA: Recurrent Adapter with Partial Video-Language Alignment for  Parameter-Efficient Transfer Learning in Low-Resource Video-Language Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thong Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaobao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xinshuai Dong</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+K">Khoi Le</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhiyuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+C">Cong-Duy Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+S">See-Kiong Ng</a>, 
<a href="/search/cs?searchtype=author&query=Tuan%2C+L+A">Luu Anh Tuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Fully fine-tuning pretrained large-scale transformer models has become a
popular paradigm for video-language modeling tasks, such as temporal language
grounding and video-language summarization. With a growing number of tasks and
limited training data, such full fine-tuning approach leads to costly model
storage and unstable training. To overcome these shortcomings, we introduce
lightweight adapters to the pre-trained model and only update them at
fine-tuning time. However, existing adapters fail to capture intrinsic temporal
relations among video frames or textual words. Moreover, they neglect the
preservation of critical task-related information that flows from the raw
video-language input into the adapter's low-dimensional space. To address these
issues, we first propose a novel REcurrent ADapter (READ) that employs
recurrent computation to enable temporal modeling capability. Second, we
propose Partial Video-Language Alignment (PVLA) objective via the use of
partial optimal transport to maintain task-related information flowing into our
READ modules. We validate our READ-PVLA framework through extensive experiments
where READ-PVLA significantly outperforms all existing fine-tuning strategies
on multiple low-resource temporal language grounding and video-language
summarization benchmarks.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06951" title="Abstract">arXiv:2312.06951</a> [<a href="/pdf/2312.06951" title="Download PDF">pdf</a>, <a href="/format/2312.06951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Norm Regularized Federated Learning: Transforming Skewed  Distributions into Global Insights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+K">Ke Hu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+W">WeiDong Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+P">Peng Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In the field of federated learning, addressing non-independent and
identically distributed (non-i.i.d.) data remains a quintessential challenge
for improving global model performance. This work introduces the Feature Norm
Regularized Federated Learning (FNR-FL) algorithm, which uniquely incorporates
class average feature norms to enhance model accuracy and convergence in
non-i.i.d. scenarios. Our comprehensive analysis reveals that FNR-FL not only
accelerates convergence but also significantly surpasses other contemporary
federated learning algorithms in test accuracy, particularly under feature
distribution skew scenarios. The novel modular design of FNR-FL facilitates
seamless integration with existing federated learning frameworks, reinforcing
its adaptability and potential for widespread application. We substantiate our
claims through rigorous empirical evaluations, demonstrating FNR-FL's
exceptional performance across various skewed data distributions. Relative to
FedAvg, FNR-FL exhibits a substantial 66.24\% improvement in accuracy and a
significant 11.40\% reduction in training time, underscoring its enhanced
effectiveness and efficiency.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06955" title="Abstract">arXiv:2312.06955</a> [<a href="/pdf/2312.06955" title="Download PDF">pdf</a>, <a href="/format/2312.06955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IA2U: A Transfer Plugin with Multi-Prior for In-Air Model to Underwater
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingchun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gai%2C+Q">Qilin Gai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weishi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+K">Kin-man Lam</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xianping Fu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Ting Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chongyi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In underwater environments, variations in suspended particle concentration
and turbidity cause severe image degradation, posing significant challenges to
image enhancement (IE) and object detection (OD) tasks. Currently, in-air image
enhancement and detection methods have made notable progress, but their
application in underwater conditions is limited due to the complexity and
variability of these environments. Fine-tuning in-air models saves high
overhead and has more optional reference work than building an underwater model
from scratch. To address these issues, we design a transfer plugin with
multiple priors for converting in-air models to underwater applications, named
IA2U. IA2U enables efficient application in underwater scenarios, thereby
improving performance in Underwater IE and OD. IA2U integrates three types of
underwater priors: the water type prior that characterizes the degree of image
degradation, such as color and visibility; the degradation prior, focusing on
differences in details and textures; and the sample prior, considering the
environmental conditions at the time of capture and the characteristics of the
photographed object. Utilizing a Transformer-like structure, IA2U employs these
priors as query conditions and a joint task loss function to achieve
hierarchical enhancement of task-level underwater image features, therefore
considering the requirements of two different tasks, IE and OD. Experimental
results show that IA2U combined with an in-air model can achieve superior
performance in underwater image enhancement and object detection tasks. The
code will be made publicly available.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06956" title="Abstract">arXiv:2312.06956</a> [<a href="/pdf/2312.06956" title="Download PDF">pdf</a>, <a href="/ps/2312.06956" title="Download PostScript">ps</a>, <a href="/format/2312.06956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robotics Applications in Neurology: A Review of Recent Advancements and  Future Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Retnaningsih%2C+R">Retnaningsih Retnaningsih</a>, 
<a href="/search/cs?searchtype=author&query=Budiyono%2C+A">Agus Budiyono</a>, 
<a href="/search/cs?searchtype=author&query=Ismail%2C+R">Rifky Ismail</a>, 
<a href="/search/cs?searchtype=author&query=Tugasworo%2C+D">Dodik Tugasworo</a>, 
<a href="/search/cs?searchtype=author&query=Danuaji%2C+R">Rivan Danuaji</a>, 
<a href="/search/cs?searchtype=author&query=Syahrul%2C+S">Syahrul Syahrul</a>, 
<a href="/search/cs?searchtype=author&query=Gunawan%2C+H">Hendry Gunawan</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal Of Instrumentation, Automation And Systems, 10(1) (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robotic technology has the potential to revolutionize the field of neurology
by providing new methods for diagnosis, treatment, and rehabilitation of
neurological disorders. In recent years, there has been an increasing interest
in the development of robotics applications for neurology, driven by advances
in sensing, actuation, and control systems. This review paper provides a
comprehensive overview of the recent advancements in robotics technology for
neurology, with a focus on three main areas: diagnosis, treatment, and
rehabilitation. In the area of diagnosis, robotics has been used for developing
new imaging techniques and tools for more accurate and non-invasive mapping of
brain structures and functions. For treatment, robotics has been used for
developing minimally invasive surgical procedures, including stereotactic and
endoscopic approaches, as well as for the delivery of therapeutic agents to
specific targets in the brain. In rehabilitation, robotics has been used for
developing assistive devices and platforms for motor and cognitive training of
patients with neurological disorders. The paper also discusses the challenges
and limitations of current robotics technology for neurology, including the
need for more reliable and precise sensing and actuation systems, the
development of better control algorithms, and the ethical implications of
robotic interventions in the human brain. Finally, the paper outlines future
directions and opportunities for robotics applications in neurology, including
the integration of robotics with other emerging technologies, such as
neuroprosthetics, artificial intelligence, and virtual reality. Overall, this
review highlights the potential of robotics technology to transform the field
of neurology and improve the lives of patients with neurological disorders.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06957" title="Abstract">arXiv:2312.06957</a> [<a href="/pdf/2312.06957" title="Download PDF">pdf</a>, <a href="/format/2312.06957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Saddle Point Problem and Online Convex-Concave Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+Q">Qing-xin Meng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jian-wei Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Centered around solving the Online Saddle Point problem, this paper
introduces the Online Convex-Concave Optimization (OCCO) framework, which
involves a sequence of two-player time-varying convex-concave games. We propose
the generalized duality gap (Dual-Gap) as the performance metric and establish
the parallel relationship between OCCO with Dual-Gap and Online Convex
Optimization (OCO) with regret. To demonstrate the natural extension of OCCO
from OCO, we develop two algorithms, the implicit online mirror descent-ascent
and its optimistic variant. Analysis reveals that their duality gaps share
similar expression forms with the corresponding dynamic regrets arising from
implicit updates in OCO. Empirical results further substantiate the
effectiveness of our algorithms. Simultaneously, we unveil that the dynamic
Nash equilibrium regret, which was initially introduced in a recent paper, has
inherent defects.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06958" title="Abstract">arXiv:2312.06958</a> [<a href="/pdf/2312.06958" title="Download PDF">pdf</a>, <a href="/format/2312.06958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PatchMorph: A Stochastic Deep Learning Approach for Unsupervised 3D  Brain Image Registration with Small Patches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Skibbe%2C+H">Henrik Skibbe</a>, 
<a href="/search/cs?searchtype=author&query=Byra%2C+M">Michal Byra</a>, 
<a href="/search/cs?searchtype=author&query=Watakabe%2C+A">Akiya Watakabe</a>, 
<a href="/search/cs?searchtype=author&query=Yamamori%2C+T">Tetsuo Yamamori</a>, 
<a href="/search/cs?searchtype=author&query=Reisert%2C+M">Marco Reisert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce "PatchMorph," an new stochastic deep learning algorithm tailored
for unsupervised 3D brain image registration. Unlike other methods, our method
uses compact patches of a constant small size to derive solutions that can
combine global transformations with local deformations. This approach minimizes
the memory footprint of the GPU during training, but also enables us to operate
on numerous amounts of randomly overlapping small patches during inference to
mitigate image and patch boundary problems. PatchMorph adeptly handles world
coordinate transformations between two input images, accommodating variances in
attributes such as spacing, array sizes, and orientations. The spatial
resolution of patches transitions from coarse to fine, addressing both global
and local attributes essential for aligning the images. Each patch offers a
unique perspective, together converging towards a comprehensive solution.
Experiments on human T1 MRI brain images and marmoset brain images from serial
2-photon tomography affirm PatchMorph's superior performance.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06960" title="Abstract">arXiv:2312.06960</a> [<a href="/pdf/2312.06960" title="Download PDF">pdf</a>, <a href="/format/2312.06960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Remote Sensing Vision-Language Foundation Models without Annotations via  Ground Remote Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mall%2C+U">Utkarsh Mall</a>, 
<a href="/search/cs?searchtype=author&query=Phoo%2C+C+P">Cheng Perng Phoo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M+K">Meilin Kelsey Liu</a>, 
<a href="/search/cs?searchtype=author&query=Vondrick%2C+C">Carl Vondrick</a>, 
<a href="/search/cs?searchtype=author&query=Hariharan%2C+B">Bharath Hariharan</a>, 
<a href="/search/cs?searchtype=author&query=Bala%2C+K">Kavita Bala</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce a method to train vision-language models for remote-sensing
images without using any textual annotations. Our key insight is to use
co-located internet imagery taken on the ground as an intermediary for
connecting remote-sensing images and language. Specifically, we train an image
encoder for remote sensing images to align with the image encoder of CLIP using
a large amount of paired internet and satellite images. Our unsupervised
approach enables the training of a first-of-its-kind large-scale vision
language model (VLM) for remote sensing images at two different resolutions. We
show that these VLMs enable zero-shot, open-vocabulary image classification,
retrieval, segmentation and visual question answering for satellite images. On
each of these tasks, our VLM trained without textual annotations outperforms
existing VLMs trained with supervision, with gains of up to 20% for
classification and 80% for segmentation.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06962" title="Abstract">arXiv:2312.06962</a> [<a href="/pdf/2312.06962" title="Download PDF">pdf</a>, <a href="/ps/2312.06962" title="Download PostScript">ps</a>, <a href="/format/2312.06962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strictly Monotone Brouwer Trees for Well-founded Recursion Over Multiple  Arguments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eremondi%2C+J">Joseph Eremondi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at CPP 2024. Accompanying code on Zenodo: <a href="https://zenodo.org/doi/10.5281/zenodo.10204397">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Logic (math.LO)

</div>
<p class="mathjax">Ordinals can help prove termination for dependently typed programs. Brouwer
trees are a particular ordinal notation that make it very easy to assign sizes
to higher order data structures. They extend natural numbers with a limit
constructor, so a function's size can be the supremum of the sizes of values
from its image. These can then be used to define well-founded recursion: any
recursive calls are allowed so long as they are on values whose sizes are
strictly smaller than the current size. Unfortunately, Brouwer trees are not
algebraically well-behaved. They can be characterized equationally as a
join-semilattice, where the join takes the maximum of two trees. However, it
does not interact well with the successor constructor, so it does not interact
properly with the strict ordering used in well-founded recursion. We present
Strictly Monotone Brouwer trees (SMB-trees), a refinement of Brouwer trees that
are algebraically well-behaved. SMB-trees are built using functions with the
same signatures as Brouwer tree constructors, and they satisfy all Brouwer tree
inequalities. However, their join operator distributes over the successor,
making them suited for well-founded recursion or equational reasoning. We show
how, using dependent pairs and careful definitions, an ill-behaved definition
can be turned into a well-behaved one, with light axiomatic requirements. We
implement a recursively-defined maximum operator for Brouwer trees that matches
on successors and handles them specifically. Then, we define SMB-trees as the
subset of Brouwer trees for which the recursive maximum computes a least upper
bound. Finally, we show that every Brouwer tree can be transformed into a
corresponding SMB-tree by joining it with itself an infinite number of times.
All definitions and theorems are implemented in Agda.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06965" title="Abstract">arXiv:2312.06965</a> [<a href="/pdf/2312.06965" title="Download PDF">pdf</a>, <a href="/format/2312.06965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Enhanced Human Activity Recognition through Natural Language  Generation and Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kashyap%2C+N">Nikhil Kashyap</a>, 
<a href="/search/cs?searchtype=author&query=Bedmutha%2C+M+S">Manas Satish Bedmutha</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhary%2C+P">Prerit Chaudhary</a>, 
<a href="/search/cs?searchtype=author&query=Wood%2C+B">Brian Wood</a>, 
<a href="/search/cs?searchtype=author&query=Pratt%2C+W">Wanda Pratt</a>, 
<a href="/search/cs?searchtype=author&query=Sabin%2C+J">Janice Sabin</a>, 
<a href="/search/cs?searchtype=author&query=Hartzler%2C+A">Andrea Hartzler</a>, 
<a href="/search/cs?searchtype=author&query=Weibel%2C+N">Nadir Weibel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the Symposium on Generative AI for Pervasive Computing (GenAI4PC) held at UbiComp/ISWC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Vision-based human activity recognition (HAR) has made substantial progress
in recognizing predefined gestures but lacks adaptability for emerging
activities. This paper introduces a paradigm shift by harnessing generative
modeling and large language models (LLMs) to enhance vision-based HAR. We
propose utilizing LLMs to generate descriptive textual representations of
activities using pose keypoints as an intermediate representation.
Incorporating pose keypoints adds contextual depth to the recognition process,
allowing for sequences of vectors resembling text chunks, compatible with LLMs.
This innovative fusion of computer vision and natural language processing holds
significant potential for revolutionizing activity recognition. A proof of
concept study on a Kinetics700 dataset subset validates the approach's
efficacy, highlighting improved accuracy and interpretability. Future
implications encompass enhanced accuracy, novel research avenues, model
generalization, and ethical considerations for transparency. This framework has
real-world applications, including personalized gym workout feedback and
nuanced sports training insights. By connecting visual cues to interpretable
textual descriptions, the proposed framework advances HAR accuracy and
applicability, shaping the landscape of pervasive computing and activity
recognition research. As this approach evolves, it promises a more insightful
understanding of human activities across diverse contexts, marking a
significant step towards a better world.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06966" title="Abstract">arXiv:2312.06966</a> [<a href="/pdf/2312.06966" title="Download PDF">pdf</a>, <a href="/format/2312.06966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Much Data is Needed for Channel Knowledge Map Construction?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaoli Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yong Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Channel knowledge map (CKM) has been recently proposed to enable
environment-aware communications by utilizing historical or simulation
generated wireless channel data. This paper studies the construction of one
particular type of CKM, namely channel gain map (CGM), by using a finite number
of measurements or simulation-generated data, with model-based spatial channel
prediction. We try to answer the following question: How much data is
sufficient for CKM construction? To this end, we first derive the average mean
square error (AMSE) of the channel gain prediction as a function of the sample
density of data collection for offline CGM construction, as well as the number
of data points used for online spatial channel gain prediction. To model the
spatial variation of the wireless environment even within each cell, we divide
the CGM into subregions and estimate the channel parameters from the local data
within each subregion. The parameter estimation error and the channel
prediction error based on estimated channel parameters are derived as functions
of the number of data points within the subregion. The analytical results
provide useful guide for CGM construction and utilization by determining the
required spatial sample density for offline data collection and number of data
points to be used for online channel prediction, so that the desired level of
channel prediction accuracy is guaranteed.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06968" title="Abstract">arXiv:2312.06968</a> [<a href="/pdf/2312.06968" title="Download PDF">pdf</a>, <a href="/format/2312.06968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hallucination Augmented Contrastive Learning for Multimodal Large  Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chaoya Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haiyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+M">Mengfan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaxing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+W">Wei Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+M">Ming Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qinghao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Ji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shikun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-modal large language models (MLLMs) have been shown to efficiently
integrate natural language with visual information to handle multi-modal tasks.
However, MLLMs still face a fundamental limitation of hallucinations, where
they tend to generate erroneous or fabricated information. In this paper, we
address hallucinations in MLLMs from a novel perspective of representation
learning. We first analyzed the representation distribution of textual and
visual tokens in MLLM, revealing two important findings: 1) there is a
significant gap between textual and visual representations, indicating
unsatisfactory cross-modal representation alignment; 2) representations of
texts that contain and do not contain hallucinations are entangled, making it
challenging to distinguish them. These two observations inspire us with a
simple yet effective method to mitigate hallucinations. Specifically, we
introduce contrastive learning into MLLMs and use text with hallucination as
hard negative examples, naturally bringing representations of non-hallucinative
text and visual samples closer while pushing way representations of
non-hallucinating and hallucinative text. We evaluate our method quantitatively
and qualitatively, showing its effectiveness in reducing hallucination
occurrences and improving performance across multiple benchmarks. On the
MMhal-Bench benchmark, our method obtains a 34.66% /29.5% improvement over the
baseline MiniGPT-4/LLaVA.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06969" title="Abstract">arXiv:2312.06969</a> [<a href="/pdf/2312.06969" title="Download PDF">pdf</a>, <a href="/ps/2312.06969" title="Download PostScript">ps</a>, <a href="/format/2312.06969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Channel Estimation for Movable Antenna Communication Systems: A  Framework Based on Compressed Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zhenyu Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Songqi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lipeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yanming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xiang-Gen Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Movable antenna (MA) is a new technology with great potential to improve
communication performance by enabling local movement of antennas for pursuing
better channel conditions. In particular, the acquisition of complete channel
state information (CSI) between the transmitter (Tx) and receiver (Rx) regions
is an essential problem for MA systems to reap performance gains. In this
paper, we propose a general channel estimation framework for MA systems by
exploiting the multi-path field response channel structure. Specifically, the
angles of departure (AoDs), angles of arrival (AoAs), and complex coefficients
of the multi-path components (MPCs) are jointly estimated by employing the
compressed sensing method, based on multiple channel measurements at designated
positions of the Tx-MA and Rx-MA. Under this framework, the Tx-MA and Rx-MA
measurement positions fundamentally determine the measurement matrix for
compressed sensing, of which the mutual coherence is analyzed from the
perspective of Fourier transform. Moreover, two criteria for MA measurement
positions are provided to guarantee the successful recovery of MPCs. Then, we
propose several MA measurement position setups and compare their performance.
Finally, comprehensive simulation results show that the proposed framework is
able to estimate the complete CSI between the Tx and Rx regions with a high
accuracy.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06971" title="Abstract">arXiv:2312.06971</a> [<a href="/pdf/2312.06971" title="Download PDF">pdf</a>, <a href="/format/2312.06971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CCM: Adding Conditional Controls to Text-to-Image Consistency Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jie Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Kai Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Han Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yujun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xueyang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+Z">Zheng-Jun Zha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://swiftforce.github.io/CCM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Consistency Models (CMs) have showed a promise in creating visual content
efficiently and with high quality. However, the way to add new conditional
controls to the pretrained CMs has not been explored. In this technical report,
we consider alternative strategies for adding ControlNet-like conditional
control to CMs and present three significant findings. 1) ControlNet trained
for diffusion models (DMs) can be directly applied to CMs for high-level
semantic controls but struggles with low-level detail and realism control. 2)
CMs serve as an independent class of generative models, based on which
ControlNet can be trained from scratch using Consistency Training proposed by
Song et al. 3) A lightweight adapter can be jointly optimized under multiple
conditions through Consistency Training, allowing for the swift transfer of
DMs-based ControlNet to CMs. We study these three solutions across various
conditional controls, including edge, depth, human pose, low-resolution image
and masked image with text-to-image latent consistency models.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06973" title="Abstract">arXiv:2312.06973</a> [<a href="/pdf/2312.06973" title="Download PDF">pdf</a>, <a href="/format/2312.06973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anytime Approximate Formal Feature Attribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jinqiang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Farr%2C+G">Graham Farr</a>, 
<a href="/search/cs?searchtype=author&query=Ignatiev%2C+A">Alexey Ignatiev</a>, 
<a href="/search/cs?searchtype=author&query=Stuckey%2C+P+J">Peter J. Stuckey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Widespread use of artificial intelligence (AI) algorithms and machine
learning (ML) models on the one hand and a number of crucial issues pertaining
to them warrant the need for explainable artificial intelligence (XAI). A key
explainability question is: given this decision was made, what are the input
features which contributed to the decision? Although a range of XAI approaches
exist to tackle this problem, most of them have significant limitations.
Heuristic XAI approaches suffer from the lack of quality guarantees, and often
try to approximate Shapley values, which is not the same as explaining which
features contribute to a decision. A recent alternative is so-called formal
feature attribution (FFA), which defines feature importance as the fraction of
formal abductive explanations (AXp's) containing the given feature. This
measures feature importance from the view of formally reasoning about the
model's behavior. It is challenging to compute FFA using its definition because
that involves counting AXp's, although one can approximate it. Based on these
results, this paper makes several contributions. First, it gives compelling
evidence that computing FFA is intractable, even if the set of contrastive
formal explanations (CXp's) is provided, by proving that the problem is
#P-hard. Second, by using the duality between AXp's and CXp's, it proposes an
efficient heuristic to switch from CXp enumeration to AXp enumeration
on-the-fly resulting in an adaptive explanation enumeration algorithm
effectively approximating FFA in an anytime fashion. Finally, experimental
results obtained on a range of widely used datasets demonstrate the
effectiveness of the proposed FFA approximation approach in terms of the error
of FFA approximation as well as the number of explanations computed and their
diversity given a fixed time limit.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06974" title="Abstract">arXiv:2312.06974</a> [<a href="/pdf/2312.06974" title="Download PDF">pdf</a>, <a href="/ps/2312.06974" title="Download PostScript">ps</a>, <a href="/format/2312.06974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SM70: A Large Language Model for Medical Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhatti%2C+A">Anubhav Bhatti</a>, 
<a href="/search/cs?searchtype=author&query=Parmar%2C+S">Surajsinh Parmar</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">San Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 Pages, Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We are introducing SM70, a 70 billion-parameter Large Language Model that is
specifically designed for SpassMed's medical devices under the brand name
'JEE1' (pronounced as G1 and means 'Life'). This large language model provides
more accurate and safe responses to medical-domain questions. To fine-tune
SM70, we used around 800K data entries from the publicly available dataset
MedAlpaca. The Llama2 70B open-sourced model served as the foundation for SM70,
and we employed the QLoRA technique for fine-tuning. The evaluation is
conducted across three benchmark datasets - MEDQA - USMLE, PUBMEDQA, and USMLE
- each representing a unique aspect of medical knowledge and reasoning. The
performance of SM70 is contrasted with other notable LLMs, including Llama2
70B, Clinical Camel 70 (CC70), GPT 3.5, GPT 4, and Med-Palm, to provide a
comparative understanding of its capabilities within the medical domain. Our
results indicate that SM70 outperforms several established models in these
datasets, showcasing its proficiency in handling a range of medical queries,
from fact-based questions derived from PubMed abstracts to complex clinical
decision-making scenarios. The robust performance of SM70, particularly in the
USMLE and PUBMEDQA datasets, suggests its potential as an effective tool in
clinical decision support and medical information retrieval. Despite its
promising results, the paper also acknowledges the areas where SM70 lags behind
the most advanced model, GPT 4, thereby highlighting the need for further
development, especially in tasks demanding extensive medical knowledge and
intricate reasoning.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06978" title="Abstract">arXiv:2312.06978</a> [<a href="/pdf/2312.06978" title="Download PDF">pdf</a>, <a href="/format/2312.06978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLASSMix: Adaptive stain separation-based contrastive learning with  pseudo labeling for histopathological image classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bodong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Manoochehri%2C+H">Hamid Manoochehri</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+M+M">Man Minh Ho</a>, 
<a href="/search/cs?searchtype=author&query=Fooladgar%2C+F">Fahimeh Fooladgar</a>, 
<a href="/search/cs?searchtype=author&query=Chong%2C+Y">Yosep Chong</a>, 
<a href="/search/cs?searchtype=author&query=Knudsen%2C+B+S">Beatrice S. Knudsen</a>, 
<a href="/search/cs?searchtype=author&query=Sirohi%2C+D">Deepika Sirohi</a>, 
<a href="/search/cs?searchtype=author&query=Tasdizen%2C+T">Tolga Tasdizen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Histopathological image classification is one of the critical aspects in
medical image analysis. Due to the high expense associated with the labeled
data in model training, semi-supervised learning methods have been proposed to
alleviate the need of extensively labeled datasets. In this work, we propose a
model for semi-supervised classification tasks on digital histopathological
Hematoxylin and Eosin (H&amp;E) images. We call the new model Contrastive Learning
with Adaptive Stain Separation and MixUp (CLASSMix). Our model is formed by two
main parts: contrastive learning between adaptively stain separated Hematoxylin
images and Eosin images, and pseudo labeling using MixUp. We compare our model
with other state-of-the-art models on clear cell renal cell carcinoma (ccRCC)
datasets from our institution and The Cancer Genome Atlas Program (TCGA). We
demonstrate that our CLASSMix model has the best performance on both datasets.
The contributions of different parts in our model are also analyzed.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06980" title="Abstract">arXiv:2312.06980</a> [<a href="/pdf/2312.06980" title="Download PDF">pdf</a>, <a href="/format/2312.06980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPFNO: Spectral operator learning for PDEs with Dirichlet and Neumann  boundary conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+Z">Ziyuan Liu</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+Y">Yuhang Wu</a>, 
<a href="/search/math?searchtype=author&query=Huang%2C+D+Z">Daniel Zhengyu Huang</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+H">Hong Zhang</a>, 
<a href="/search/math?searchtype=author&query=Qian%2C+X">Xu Qian</a>, 
<a href="/search/math?searchtype=author&query=Song%2C+S">Songhe Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Neural operators have been validated as promising deep surrogate models for
solving partial differential equations (PDEs). Despite the critical role of
boundary conditions in PDEs, however, only a limited number of neural operators
robustly enforce these conditions. In this paper we introduce semi-periodic
Fourier neural operator (SPFNO), a novel spectral operator learning method, to
learn the target operators of PDEs with non-periodic BCs. This method extends
our previous work (<a href="/abs/2206.12698">arXiv:2206.12698</a>), which showed significant improvements by
employing enhanced neural operators that precisely satisfy the boundary
conditions. However, the previous work is associated with Gaussian grids,
restricting comprehensive comparisons across most public datasets.
Additionally, we present numerical results for various PDEs such as the viscous
Burgers' equation, Darcy flow, incompressible pipe flow, and coupled
reactiondiffusion equations. These results demonstrate the computational
efficiency, resolution invariant property, and BC-satisfaction behavior of
proposed model. An accuracy improvement of approximately 1.7X-4.7X over the
non-BC-satisfying baselines is also achieved. Furthermore, our studies on SOL
underscore the significance of satisfying BCs as a criterion for deep surrogate
models of PDEs.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06986" title="Abstract">arXiv:2312.06986</a> [<a href="/pdf/2312.06986" title="Download PDF">pdf</a>, <a href="/format/2312.06986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic extraction of cause-effect-relations from requirements  artifacts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frattini%2C+J">Julian Frattini</a>, 
<a href="/search/cs?searchtype=author&query=Junker%2C+M">Maximilian Junker</a>, 
<a href="/search/cs?searchtype=author&query=Unterkalmsteiner%2C+M">Michael Unterkalmsteiner</a>, 
<a href="/search/cs?searchtype=author&query=Mendez%2C+D">Daniel Mendez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ASE '20: Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Background: The detection and extraction of causality from natural language
sentences have shown great potential in various fields of application. The
field of requirements engineering is eligible for multiple reasons: (1)
requirements artifacts are primarily written in natural language, (2) causal
sentences convey essential context about the subject of requirements, and (3)
extracted and formalized causality relations are usable for a (semi-)automatic
translation into further artifacts, such as test cases. Objective: We aim at
understanding the value of interactive causality extraction based on syntactic
criteria for the context of requirements engineering. Method: We developed a
prototype of a system for automatic causality extraction and evaluate it by
applying it to a set of publicly available requirements artifacts, determining
whether the automatic extraction reduces the manual effort of requirements
formalization. Result: During the evaluation we analyzed 4457 natural language
sentences from 18 requirements documents, 558 of which were causal (12.52%).
The best evaluation of a requirements document provided an automatic extraction
of 48.57% cause-effect graphs on average, which demonstrates the feasibility of
the approach. Limitation: The feasibility of the approach has been proven in
theory but lacks exploration of being scaled up for practical use. Evaluating
the applicability of the automatic causality extraction for a requirements
engineer is left for future research. Conclusion: A syntactic approach for
causality extraction is viable for the context of requirements engineering and
can aid a pipeline towards an automatic generation of further artifacts from
requirements artifacts.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06987" title="Abstract">arXiv:2312.06987</a> [<a href="/pdf/2312.06987" title="Download PDF">pdf</a>, <a href="/format/2312.06987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new lightweight additive homomorphic encryption algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+W">Wuqiong Pan</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hongliang Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Chinese language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">This article describes a lightweight additive homomorphic algorithm with the
same encryption and decryption keys. Compared to standard additive homomorphic
algorithms like Paillier, this algorithm reduces the computational cost of
encryption and decryption from modular exponentiation to modular
multiplication, and reduces the computational cost of ciphertext addition from
modular multiplication to modular addition. This algorithm is based on a new
mathematical problem: in two division operations, whether it is possible to
infer the remainder or divisor based on the dividend when two remainders are
related. Currently, it is not obvious how to break this problem, but further
exploration is needed to determine if it is sufficiently difficult. In addition
to this mathematical problem, we have also designed two interesting
mathematical structures for decryption, which are used in the two algorithms
mentioned in the main text. It is possible that the decryption structure of
Algorithm 2 introduces new security vulnerabilities, but we have not
investigated this issue thoroughly.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06988" title="Abstract">arXiv:2312.06988</a> [<a href="/pdf/2312.06988" title="Download PDF">pdf</a>, <a href="/format/2312.06988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MWSIS: Multimodal Weakly Supervised Instance Segmentation with 2D Box  Annotations for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+G">Guangfeng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuzhi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+W">Wenlong Liao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tao He</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+P">Pai Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Instance segmentation is a fundamental research in computer vision,
especially in autonomous driving. However, manual mask annotation for instance
segmentation is quite time-consuming and costly. To address this problem, some
prior works attempt to apply weakly supervised manner by exploring 2D or 3D
boxes. However, no one has ever successfully segmented 2D and 3D instances
simultaneously by only using 2D box annotations, which could further reduce the
annotation cost by an order of magnitude. Thus, we propose a novel framework
called Multimodal Weakly Supervised Instance Segmentation (MWSIS), which
incorporates various fine-grained label generation and correction modules for
both 2D and 3D modalities to improve the quality of pseudo labels, along with a
new multimodal cross-supervision approach, named Consistency Sparse Cross-modal
Supervision (CSCS), to reduce the inconsistency of multimodal predictions by
response distillation. Particularly, transferring the 3D backbone to downstream
tasks not only improves the performance of the 3D detectors, but also
outperforms fully supervised instance segmentation with only 5% fully
supervised annotations. On the Waymo dataset, the proposed framework
demonstrates significant improvements over the baseline, especially achieving
2.59% mAP and 12.75% mAP increases for 2D and 3D instance segmentation tasks,
respectively. The code is available at
https://github.com/jiangxb98/mwsis-plugin.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06989" title="Abstract">arXiv:2312.06989</a> [<a href="/pdf/2312.06989" title="Download PDF">pdf</a>, <a href="/format/2312.06989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task-Agnostic Privacy-Preserving Representation Learning for Federated  Learning Against Attribute Inference Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arevalo%2C+C+A">Caridad Arroyo Arevalo</a>, 
<a href="/search/cs?searchtype=author&query=Noorbakhsh%2C+S+L">Sayedeh Leila Noorbakhsh</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yun Dong</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yuan Hong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Binghui Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024; Full version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Federated learning (FL) has been widely studied recently due to its property
to collaboratively train data from different devices without sharing the raw
data. Nevertheless, recent studies show that an adversary can still be possible
to infer private information about devices' data, e.g., sensitive attributes
such as income, race, and sexual orientation. To mitigate the attribute
inference attacks, various existing privacy-preserving FL methods can be
adopted/adapted. However, all these existing methods have key limitations: they
need to know the FL task in advance, or have intolerable computational
overheads or utility losses, or do not have provable privacy guarantees.
<br />We address these issues and design a task-agnostic privacy-preserving
presentation learning method for FL ({\bf TAPPFL}) against attribute inference
attacks. TAPPFL is formulated via information theory. Specifically, TAPPFL has
two mutual information goals, where one goal learns task-agnostic data
representations that contain the least information about the private attribute
in each device's data, and the other goal ensures the learnt data
representations include as much information as possible about the device data
to maintain FL utility. We also derive privacy guarantees of TAPPFL against
worst-case attribute inference attacks, as well as the inherent tradeoff
between utility preservation and privacy protection. Extensive results on
multiple datasets and applications validate the effectiveness of TAPPFL to
protect data privacy, maintain the FL utility, and be efficient as well.
Experimental results also show that TAPPFL outperforms the existing
defenses\footnote{Source code and full version:
\url{https://github.com/TAPPFL}}.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06990" title="Abstract">arXiv:2312.06990</a> [<a href="/pdf/2312.06990" title="Download PDF">pdf</a>, <a href="/format/2312.06990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-based Wildfire Prevention, Detection and Suppression System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shroff%2C+P">Prisha Shroff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Wildfires pose a serious threat to the environment of the world. The global
wildfire season length has increased by 19% and severe wildfires have besieged
nations around the world. Every year, forests are burned by wildfires, causing
vast amounts of carbon dioxide to be released into the atmosphere, contributing
to climate change. There is a need for a system which prevents, detects, and
suppresses wildfires. The AI based Wildfire Prevention, Detection and
Suppression System (WPDSS) is a novel, fully automated, end to end, AI based
solution to effectively predict hotspots and detect wildfires, deploy drones to
spray fire retardant, preventing and suppressing wildfires. WPDSS consists of
four steps. 1. Preprocessing: WPDSS loads real time satellite data from NASA
and meteorological data from NOAA of vegetation, temperature, precipitation,
wind, soil moisture, and land cover for prevention. For detection, it loads the
real time data of Land Cover, Humidity, Temperature, Vegetation, Burned Area
Index, Ozone, and CO2. It uses the process of masking to eliminate not hotspots
and not wildfires such as water bodies, and rainfall. 2. Learning: The AI model
consists of a random forest classifier, which is trained using a labeled
dataset of hotspots and wildfires and not hotspots and not wildfires. 3.
Identification of hotspots and wildfires: WPDSS runs the real time data through
the model to automatically identify hotspots and wildfires. 4. Drone
deployment: The drone flies to the identified hotspot or wildfire location.
WPDSS attained a 98.6% accuracy in identifying hotspots and a 98.7% accuracy in
detecting wildfires. WPDSS will reduce the impacts of climate change, protect
ecosystems and biodiversity, avert huge economic losses, and save human lives.
The power of WPDSS developed can be applied to any location globally to prevent
and suppress wildfires, reducing climate change.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06991" title="Abstract">arXiv:2312.06991</a> [<a href="/pdf/2312.06991" title="Download PDF">pdf</a>, <a href="/format/2312.06991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attacking the Loop: Adversarial Attacks on Graph-based Loop Closure  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J+J+Y">Jonathan J.Y. Kim</a>, 
<a href="/search/cs?searchtype=author&query=Urschler%2C+M">Martin Urschler</a>, 
<a href="/search/cs?searchtype=author&query=Riddle%2C+P+J">Patricia J. Riddle</a>, 
<a href="/search/cs?searchtype=author&query=Wicker%2C+J+S">Jorg S. Wicker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at VISIGRAPP 2024, 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">With the advancement in robotics, it is becoming increasingly common for
large factories and warehouses to incorporate visual SLAM (vSLAM) enabled
automated robots that operate closely next to humans. This makes any
adversarial attacks on vSLAM components potentially detrimental to humans
working alongside them. Loop Closure Detection (LCD) is a crucial component in
vSLAM that minimizes the accumulation of drift in mapping, since even a small
drift can accumulate into a significant drift over time. A prior work by Kim et
al., SymbioLCD2, unified visual features and semantic objects into a single
graph structure for finding loop closure candidates. While this provided a
performance improvement over visual feature-based LCD, it also created a single
point of vulnerability for potential graph-based adversarial attacks. Unlike
previously reported visual-patch based attacks, small graph perturbations are
far more challenging to detect, making them a more significant threat. In this
paper, we present Adversarial-LCD, a novel black-box evasion attack framework
that employs an eigencentrality-based perturbation method and an SVM-RBF
surrogate model with a Weisfeiler-Lehman feature extractor for attacking
graph-based LCD. Our evaluation shows that the attack performance of
Adversarial-LCD with the SVM-RBF surrogate model was superior to that of other
machine learning surrogate algorithms, including SVM-linear, SVM-polynomial,
and Bayesian classifier, demonstrating the effectiveness of our attack
framework. Furthermore, we show that our eigencentrality-based perturbation
method outperforms other algorithms, such as Random-walk and Shortest-path,
highlighting the efficiency of Adversarial-LCD's perturbation selection method.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06993" title="Abstract">arXiv:2312.06993</a> [<a href="/pdf/2312.06993" title="Download PDF">pdf</a>, <a href="/ps/2312.06993" title="Download PostScript">ps</a>, <a href="/format/2312.06993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamically configured physics-informed neural network in topology  optimization applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jichao Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Z">Ziming Wen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhanga%2C+Y">Yaya Zhanga</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 22 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Integration of machine learning (ML) into the topology optimization (TO)
framework is attracting increasing attention, but data acquisition in
data-driven models is prohibitive. Compared with popular ML methods, the
physics-informed neural network (PINN) can avoid generating enormous amounts of
data when solving forward problems and additionally provide better inference.
To this end, a dynamically configured PINN-based topology optimization
(DCPINN-TO) method is proposed. The DCPINN is composed of two subnetworks,
namely the backbone neural network (NN) and the coefficient NN, where the
coefficient NN has fewer trainable parameters. The designed architecture aims
to dynamically configure trainable parameters; that is, an inexpensive NN is
used to replace an expensive one at certain optimization cycles. Furthermore,
an active sampling strategy is proposed to selectively sample collocations
depending on the pseudo-densities at each optimization cycle. In this manner,
the number of collocations will decrease with the optimization process but will
hardly affect it. The Gaussian integral is used to calculate the strain energy
of elements, which yields a byproduct of decoupling the mapping of the material
at the collocations. Several examples with different resolutions validate the
feasibility of the DCPINN-TO method, and multiload and multiconstraint problems
are employed to illustrate its generalization. In addition, compared to finite
element analysis-based TO (FEA-TO), the accuracy of the displacement prediction
and optimization results indicate that the DCPINN-TO method is effective and
efficient.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06995" title="Abstract">arXiv:2312.06995</a> [<a href="/pdf/2312.06995" title="Download PDF">pdf</a>, <a href="/format/2312.06995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer-based No-Reference Image Quality Assessment via Supervised  Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jinsong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Pan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jie Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Image Quality Assessment (IQA) has long been a research hotspot in the field
of image processing, especially No-Reference Image Quality Assessment (NR-IQA).
Due to the powerful feature extraction ability, existing Convolution Neural
Network (CNN) and Transformers based NR-IQA methods have achieved considerable
progress. However, they still exhibit limited capability when facing unknown
authentic distortion datasets. To further improve NR-IQA performance, in this
paper, a novel supervised contrastive learning (SCL) and Transformer-based
NR-IQA model SaTQA is proposed. We first train a model on a large-scale
synthetic dataset by SCL (no image subjective score is required) to extract
degradation features of images with various distortion types and levels. To
further extract distortion information from images, we propose a backbone
network incorporating the Multi-Stream Block (MSB) by combining the CNN
inductive bias and Transformer long-term dependence modeling capability.
Finally, we propose the Patch Attention Block (PAB) to obtain the final
distorted image quality score by fusing the degradation features learned from
contrastive learning with the perceptual distortion information extracted by
the backbone network. Experimental results on seven standard IQA datasets show
that SaTQA outperforms the state-of-the-art methods for both synthetic and
authentic datasets. Code is available at
https://github.com/I2-Multimedia-Lab/SaTQA
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06999" title="Abstract">arXiv:2312.06999</a> [<a href="/pdf/2312.06999" title="Download PDF">pdf</a>, <a href="/format/2312.06999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DGNet: Dynamic Gradient-guided Network with Noise Suppression for  Underwater Image Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingchun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zongxin He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dehuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+K">Kin-man Lam</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weishi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xianping Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chongyi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Underwater image enhancement (UIE) is a challenging task due to the complex
degradation caused by underwater environments. To solve this issue, previous
methods often idealize the degradation process, and neglect the impact of
medium noise and object motion on the distribution of image features, limiting
the generalization and adaptability of the model. Previous methods use the
reference gradient that is constructed from original images and synthetic
ground-truth images. This may cause the network performance to be influenced by
some low-quality training data. Our approach utilizes predicted images to
dynamically update pseudo-labels, adding a dynamic gradient to optimize the
network's gradient space. This process improves image quality and avoids local
optima. Moreover, we propose a Feature Restoration and Reconstruction module
(FRR) based on a Channel Combination Inference (CCI) strategy and a Frequency
Domain Smoothing module (FRS). These modules decouple other degradation
features while reducing the impact of various types of noise on network
performance. Experiments on multiple public datasets demonstrate the
superiority of our method over existing state-of-the-art approaches, especially
in achieving performance milestones: PSNR of 25.6dB and SSIM of 0.93 on the
UIEB dataset. Its efficiency in terms of parameter size and inference time
further attests to its broad practicality. The code will be made publicly
available.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07000" title="Abstract">arXiv:2312.07000</a> [<a href="/pdf/2312.07000" title="Download PDF">pdf</a>, <a href="/format/2312.07000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alignment for Honesty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuqing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chern%2C+E">Ethan Chern</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Neubig%2C+G">Graham Neubig</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Pengfei Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent research has made significant strides in applying alignment techniques
to enhance the helpfulness and harmlessness of large language models (LLMs) in
accordance with human intentions. In this paper, we argue for the importance of
alignment for honesty, ensuring that LLMs proactively refuse to answer
questions when they lack knowledge, while still not being overly conservative.
However, a pivotal aspect of alignment for honesty involves discerning the
limits of an LLM's knowledge, which is far from straightforward. This challenge
demands comprehensive solutions in terms of metric development, benchmark
creation, and training methodologies. In this paper, we address these
challenges by first establishing a precise problem definition and defining
``honesty'' inspired by the Analects of Confucius. This serves as a cornerstone
for developing metrics that effectively measure an LLM's honesty by quantifying
its progress post-alignment. Furthermore, we introduce a flexible training
framework which is further instantiated by several efficient fine-tuning
techniques that emphasize honesty without sacrificing performance on other
tasks. Our extensive experiments reveal that these aligned models show a marked
increase in honesty, as indicated by our proposed metrics. We open-source a
wealth of resources to facilitate future research at
https://github.com/GAIR-NLP/alignment-for-honesty, including honesty-aligned
models, training and evaluation datasets for honesty alignment, concept
glossary, as well as all relevant source code.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07001" title="Abstract">arXiv:2312.07001</a> [<a href="/pdf/2312.07001" title="Download PDF">pdf</a>, <a href="/format/2312.07001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stein Coverage: a Variational Inference Approach to  Distribution-matching Multisensor Deployment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghimire%2C+D">Donipolo Ghimire</a>, 
<a href="/search/cs?searchtype=author&query=Kia%2C+S+S">Solmaz S. Kia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">This paper examines the spatial coverage optimization problem for multiple
sensors in a known convex environment, where the coverage service of each
sensor is heterogeneous and anisotropic. We introduce the Stein Coverage
algorithm, a distribution-matching coverage approach that aims to place sensors
at positions and orientations such that their collective coverage distribution
is as close as possible to the event distribution. To select the most important
representative points from the coverage event distribution, Stein Coverage
utilizes the Stein Variational Gradient Descent (SVGD), a deterministic
sampling method from the variational inference literature. An innovation in our
work is the introduction of a repulsive force between the samples in the SVGD
algorithm to spread the samples and avoid footprint overlap for the deployed
sensors. After pinpointing the points of interest for deployment, Stein
Coverage solves the multisensor assignment problem using a bipartite optimal
matching process. Simulations demonstrate the advantages of the Stein Coverage
method compared to conventional Voronoi partitioning multisensor deployment
methods.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07003" title="Abstract">arXiv:2312.07003</a> [<a href="/pdf/2312.07003" title="Download PDF">pdf</a>, <a href="/format/2312.07003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RACER: Rational Artificial Intelligence Car-following-model Enhanced by  Reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Halatsis%2C+A">Alexander Halatsis</a>, 
<a href="/search/cs?searchtype=author&query=Stern%2C+R">Raphael Stern</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">This paper introduces RACER, the Rational Artificial Intelligence
Car-following model Enhanced by Reality, a cutting-edge deep learning
car-following model, that satisfies partial derivative constraints, designed to
predict Adaptive Cruise Control (ACC) driving behavior while staying
theoretically feasible. Unlike conventional models, RACER effectively
integrates Rational Driving Constraints (RDCs), crucial tenets of actual
driving, resulting in strikingly accurate and realistic predictions. Against
established models like the Optimal Velocity Relative Velocity (OVRV), a
car-following Neural Network (NN), and a car-following Physics-Informed Neural
Network (PINN), RACER excels across key metrics, such as acceleration,
velocity, and spacing. Notably, it displays a perfect adherence to the RDCs,
registering zero violations, in stark contrast to other models. This study
highlights the immense value of incorporating physical constraints within AI
models, especially for augmenting safety measures in transportation. It also
paves the way for future research to test these models against human driving
data, with the potential to guide safer and more rational driving behavior. The
versatility of the proposed model, including its potential to incorporate
additional derivative constraints and broader architectural applications,
enhances its appeal and broadens its impact within the scientific community.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07006" title="Abstract">arXiv:2312.07006</a> [<a href="/pdf/2312.07006" title="Download PDF">pdf</a>, <a href="/format/2312.07006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed Pseudo Labels for Semi-Supervised Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zeming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinjiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While the pseudo-label method has demonstrated considerable success in
semi-supervised object detection tasks, this paper uncovers notable limitations
within this approach. Specifically, the pseudo-label method tends to amplify
the inherent strengths of the detector while accentuating its weaknesses, which
is manifested in the missed detection of pseudo-labels, particularly for small
and tail category objects. To overcome these challenges, this paper proposes
Mixed Pseudo Labels (MixPL), consisting of Mixup and Mosaic for pseudo-labeled
data, to mitigate the negative impact of missed detections and balance the
model's learning across different object scales. Additionally, the model's
detection performance on tail categories is improved by resampling labeled data
with relevant instances. Notably, MixPL consistently improves the performance
of various detectors and obtains new state-of-the-art results with Faster
R-CNN, FCOS, and DINO on COCO-Standard and COCO-Full benchmarks. Furthermore,
MixPL also exhibits good scalability on large models, improving DINO Swin-L by
2.5% mAP and achieving nontrivial new records (60.2% mAP) on the COCO val2017
benchmark without extra annotations.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07009" title="Abstract">arXiv:2312.07009</a> [<a href="/pdf/2312.07009" title="Download PDF">pdf</a>, <a href="/format/2312.07009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision-language Assisted Attribute Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+K">Kongming Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+D">Donghui Gao</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Ling Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weidong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiatian Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhanyu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jun Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE IC-NIDC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Attribute labeling at large scale is typically incomplete and partial, posing
significant challenges to model optimization. Existing attribute learning
methods often treat the missing labels as negative or simply ignore them all
during training, either of which could hamper the model performance to a great
extent. To overcome these limitations, in this paper we leverage the available
vision-language knowledge to explicitly disclose the missing labels for
enhancing model learning. Given an image, we predict the likelihood of each
missing attribute label assisted by an off-the-shelf vision-language model, and
randomly select to ignore those with high scores in training. Our strategy
strikes a good balance between fully ignoring and negatifying the missing
labels, as these high scores are found to be informative on revealing label
ambiguity. Extensive experiments show that our proposed vision-language
assisted loss can achieve state-of-the-art performance on the newly cleaned VAW
dataset. Qualitative evaluation demonstrates the ability of the proposed method
in predicting more complete attributes.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07010" title="Abstract">arXiv:2312.07010</a> [<a href="/pdf/2312.07010" title="Download PDF">pdf</a>, <a href="/ps/2312.07010" title="Download PostScript">ps</a>, <a href="/format/2312.07010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximum principle and energy stability preserving finite-difference  scheme based on the regularized lattice Boltzmann method for the Allen-Cahn  equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+Y">Ying Chen</a>, 
<a href="/search/math?searchtype=author&query=Chai%2C+Z">Zhenhua Chai</a>, 
<a href="/search/math?searchtype=author&query=Shi%2C+B">Baochang Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The Allen-Cahn equation (ACE) inherently possesses two crucial properties:
the maximum principle and the energy dissipation law. Preserving these two
properties at the discrete level is necessary in numerically solving the ACE.
In this paper, unlike the traditional top-down macroscopic numerical schemes
which discretize the ACE directly, we first propose a novel macroscopic
numerical scheme derived from the bottom-up mesoscopic regularized lattice
Boltzmann (RLB) method for the d(=1,2,3)-dimensional ACE, where the DdQ(2d+1)
(2d+1 discrete velocities in d-dimensional space) lattice structure is adopted.
In particular, the proposed macroscopic numerical scheme has a second-order
accuracy in space and can also be viewd as an implicit-explicit
finite-difference scheme for the ACE, in which the nonlinear part of the ACE is
discretized semi-implicitly, and the temporal derivative and dissipation term
of the ACE are discretized using the explicit Euler method and second-order
spatial difference method, respectively. Then we also demonstrate that the
proposed scheme preserves the maximum bound principle and the original energy
dissipation law at the discrete level by choosing appropriate parameters.
Finally, some numerical experiments are conducted to validate our theoretical
analysis.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07011" title="Abstract">arXiv:2312.07011</a> [<a href="/pdf/2312.07011" title="Download PDF">pdf</a>, <a href="/ps/2312.07011" title="Download PostScript">ps</a>, <a href="/format/2312.07011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Securing MIMO Wiretap Channel with Learning-Based Friendly Jamming under  Imperfect CSI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tuan%2C+B+M">Bui Minh Tuan</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+N">Diep N. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Trung%2C+N+L">Nguyen Linh Trung</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V">Van-Dinh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Van+Huynh%2C+N">Nguyen Van Huynh</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+D+T">Dinh Thai Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Krunz%2C+M">Marwan Krunz</a>, 
<a href="/search/cs?searchtype=author&query=Dutkiewicz%2C+E">Eryk Dutkiewicz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Wireless communications are particularly vulnerable to eavesdropping attacks
due to their broadcast nature. To effectively deal with eavesdroppers, existing
security techniques usually require accurate channel state information (CSI),
e.g., for friendly jamming (FJ), and/or additional computing resources at
transceivers, e.g., cryptography-based solutions, which unfortunately may not
be feasible in practice. This challenge is even more acute in low-end IoT
devices. We thus introduce a novel deep learning-based FJ framework that can
effectively defeat eavesdropping attacks with imperfect CSI and even without
CSI of legitimate channels. In particular, we first develop an
autoencoder-based communication architecture with FJ, namely AEFJ, to jointly
maximize the secrecy rate and minimize the block error rate at the receiver
without requiring perfect CSI of the legitimate channels. In addition, to deal
with the case without CSI, we leverage the mutual information neural estimation
(MINE) concept and design a MINE-based FJ scheme that can achieve comparable
security performance to the conventional FJ methods that require perfect CSI.
Extensive simulations in a multiple-input multiple-output (MIMO) system
demonstrate that our proposed solution can effectively deal with eavesdropping
attacks in various settings. Moreover, the proposed framework can seamlessly
integrate MIMO security and detection tasks into a unified end-to-end learning
process. This integrated approach can significantly maximize the throughput and
minimize the block error rate, offering a good solution for enhancing
communication security in wireless communication systems.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07019" title="Abstract">arXiv:2312.07019</a> [<a href="/pdf/2312.07019" title="Download PDF">pdf</a>, <a href="/format/2312.07019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond 1D and oversimplified kinematics: A generic analytical framework  for surrogate safety measures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Sixu Li</a>, 
<a href="/search/eess?searchtype=author&query=Anis%2C+M">Mohammad Anis</a>, 
<a href="/search/eess?searchtype=author&query=Lord%2C+D">Dominique Lord</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Yang Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Ye%2C+X">Xinyue Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents a generic analytical framework tailored for surrogate
safety measures (SSMs) that is versatile across various highway geometries,
capable of encompassing vehicle dynamics of differing dimensionality and
fidelity, and suitable for dynamic, real-world environments. The framework
incorporates a generic vehicle movement model, accommodating a spectrum of
scenarios with varying degrees of complexity and dimensionality, facilitating
the prediction of future vehicle trajectories. It establishes a generic
mathematical criterion to denote potential collisions, characterized by the
spatial overlap between a vehicle and any other entity. A collision risk is
present if the collision criterion is met at any non-negative time point, with
the minimum threshold representing the remaining time to collision. The
framework's proficiency spans from conventional one-dimensional (1D) SSMs to
extended multi-dimensional, high-fidelity SSMs. Its validity is corroborated
through simulation experiments that assess the precision of the framework when
linearization is performed on the vehicle movement model. The outcomes showcase
remarkable accuracy in predicting vehicle trajectories and the time remaining
before potential collisions occur. The necessity of higher-dimensional and
higher-fidelity SSMs is highlighted through a comparison of conventional 1D
SSMs and extended three-dimensional (3D) SSMs. Furthermore, the framework's
practical application is demonstrated through a case study that actively
evaluates all potential conflicts, underscoring its effectiveness in dynamic,
real-world traffic situations.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07021" title="Abstract">arXiv:2312.07021</a> [<a href="/pdf/2312.07021" title="Download PDF">pdf</a>, <a href="/format/2312.07021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transferring Modality-Aware Pedestrian Attentive Learning  Visible-Infrared Person Re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuwei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+L">Licheng Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Visible-infrared person re-identification (VI-ReID) aims to search the same
pedestrian of interest across visible and infrared modalities. Existing models
mainly focus on compensating for modality-specific information to reduce
modality variation. However, these methods often lead to a higher computational
overhead and may introduce interfering information when generating the
corresponding images or features. To address this issue, it is critical to
leverage pedestrian-attentive features and learn modality-complete and
-consistent representation. In this paper, a novel Transferring Modality-Aware
Pedestrian Attentive Learning (TMPA) model is proposed, focusing on the
pedestrian regions to efficiently compensate for missing modality-specific
features. Specifically, we propose a region-based data augmentation module
PedMix to enhance pedestrian region coherence by mixing the corresponding
regions from different modalities. A lightweight hybrid compensation module,
i.e., the Modality Feature Transfer (MFT), is devised to integrate cross
attention and convolution networks to fully explore the discriminative
modality-complete features with minimal computational overhead. Extensive
experiments conducted on the benchmark SYSU-MM01 and RegDB datasets
demonstrated the effectiveness of our proposed TMPA model.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07022" title="Abstract">arXiv:2312.07022</a> [<a href="/pdf/2312.07022" title="Download PDF">pdf</a>, <a href="/format/2312.07022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EdgePruner: Poisoned Edge Pruning in Graph Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kato%2C+H">Hiroya Kato</a>, 
<a href="/search/cs?searchtype=author&query=Hasegawa%2C+K">Kento Hasegawa</a>, 
<a href="/search/cs?searchtype=author&query=Hidano%2C+S">Seira Hidano</a>, 
<a href="/search/cs?searchtype=author&query=Fukushima%2C+K">Kazuhide Fukushima</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Graph Contrastive Learning (GCL) is unsupervised graph representation
learning that can obtain useful representation of unknown nodes. The node
representation can be utilized as features of downstream tasks. However, GCL is
vulnerable to poisoning attacks as with existing learning models. A
state-of-the-art defense cannot sufficiently negate adverse effects by poisoned
graphs although such a defense introduces adversarial training in the GCL. To
achieve further improvement, pruning adversarial edges is important. To the
best of our knowledge, the feasibility remains unexplored in the GCL domain. In
this paper, we propose a simple defense for GCL, EdgePruner. We focus on the
fact that the state-of-the-art poisoning attack on GCL tends to mainly add
adversarial edges to create poisoned graphs, which means that pruning edges is
important to sanitize the graphs. Thus, EdgePruner prunes edges that contribute
to minimizing the contrastive loss based on the node representation obtained
after training on poisoned graphs by GCL. Furthermore, we focus on the fact
that nodes with distinct features are connected by adversarial edges in
poisoned graphs. Thus, we introduce feature similarity between neighboring
nodes to help more appropriately determine adversarial edges. This similarity
is helpful in further eliminating adverse effects from poisoned graphs on
various datasets. Finally, EdgePruner outputs a graph that yields the minimum
contrastive loss as the sanitized graph. Our results demonstrate that pruning
adversarial edges is feasible on six datasets. EdgePruner can improve the
accuracy of node classification under the attack by up to 5.55% compared with
that of the state-of-the-art defense. Moreover, we show that EdgePruner is
immune to an adaptive attack.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07025" title="Abstract">arXiv:2312.07025</a> [<a href="/pdf/2312.07025" title="Download PDF">pdf</a>, <a href="/format/2312.07025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noise Distribution Decomposition based Multi-Agent Distributional  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geng%2C+W">Wei Geng</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+B">Baidi Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rongpeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+N">Ning Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhifeng Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Generally, Reinforcement Learning (RL) agent updates its policy by
repetitively interacting with the environment, contingent on the received
rewards to observed states and undertaken actions. However, the environmental
disturbance, commonly leading to noisy observations (e.g., rewards and states),
could significantly shape the performance of agent. Furthermore, the learning
performance of Multi-Agent Reinforcement Learning (MARL) is more susceptible to
noise due to the interference among intelligent agents. Therefore, it becomes
imperative to revolutionize the design of MARL, so as to capably ameliorate the
annoying impact of noisy rewards. In this paper, we propose a novel
decomposition-based multi-agent distributional RL method by approximating the
globally shared noisy reward by a Gaussian mixture model (GMM) and decomposing
it into the combination of individual distributional local rewards, with which
each agent can be updated locally through distributional RL. Moreover, a
diffusion model (DM) is leveraged for reward generation in order to mitigate
the issue of costly interaction expenditure for learning distributions.
Furthermore, the optimality of the distribution decomposition is theoretically
validated, while the design of loss function is carefully calibrated to avoid
the decomposition ambiguity. We also verify the effectiveness of the proposed
method through extensive simulation experiments with noisy rewards. Besides,
different risk-sensitive policies are evaluated in order to demonstrate the
superiority of distributional RL in different MARL tasks.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07028" title="Abstract">arXiv:2312.07028</a> [<a href="/pdf/2312.07028" title="Download PDF">pdf</a>, <a href="/format/2312.07028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Corrective Self-Distillation for Better Fine-Tuning of  Pretrained Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amara%2C+I">Ibtihel Amara</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+V">Vinija Jain</a>, 
<a href="/search/cs?searchtype=author&query=Chadha%2C+A">Aman Chadha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We tackle the challenging issue of aggressive fine-tuning encountered during
the process of transfer learning of pre-trained language models (PLMs) with
limited labeled downstream data. This problem primarily results in a decline in
performance on the subsequent task. Inspired by the adaptive boosting method in
traditional machine learning, we present an effective dynamic corrective
self-distillation (DCS) approach to improve the fine-tuning of the PLMs. Our
technique involves performing a self-distillation mechanism where, at each
iteration, the student model actively adapts and corrects itself by dynamically
adjusting the weights assigned to individual data points. This iterative
self-correcting process significantly enhances the overall fine-tuning
capability of PLMs, leading to improved performance and robustness. We
conducted comprehensive evaluations using the GLUE benchmark demonstrating the
efficacy of our method in enhancing the fine-tuning process for various PLMs
across diverse downstream tasks.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07032" title="Abstract">arXiv:2312.07032</a> [<a href="/pdf/2312.07032" title="Download PDF">pdf</a>, <a href="/ps/2312.07032" title="Download PostScript">ps</a>, <a href="/format/2312.07032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ahpatron: A New Budgeted Online Kernel Learning Machine with Tighter  Mistake Bound
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yun Liao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junfan Li</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+S">Shizhong Liao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qinghua Hu</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+J">Jianwu Dang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">In this paper, we study the mistake bound of online kernel learning on a
budget. We propose a new budgeted online kernel learning model, called
Ahpatron, which significantly improves the mistake bound of previous work and
resolves the open problem posed by Dekel, Shalev-Shwartz, and Singer (2005). We
first present an aggressive variant of Perceptron, named AVP, a model without
budget, which uses an active updating rule. Then we design a new budget
maintenance mechanism, which removes a half of examples,and projects the
removed examples onto a hypothesis space spanned by the remaining examples.
Ahpatron adopts the above mechanism to approximate AVP. Theoretical analyses
prove that Ahpatron has tighter mistake bounds, and experimental results show
that Ahpatron outperforms the state-of-the-art algorithms on the same or a
smaller budget.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07035" title="Abstract">arXiv:2312.07035</a> [<a href="/pdf/2312.07035" title="Download PDF">pdf</a>, <a href="/format/2312.07035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperRouter: Towards Efficient Training and Inference of Sparse Mixture  of Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Do%2C+G">Giang Do</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+K">Khiem Le</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+Q">Quang Pham</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">TrungTin Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Doan%2C+T">Thanh-Nam Doan</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+B+T">Bint T. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chenghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ramasamy%2C+S">Savitha Ramasamy</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoli Li</a>, 
<a href="/search/cs?searchtype=author&query=Hoi%2C+S">Steven Hoi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">By routing input tokens to only a few split experts, Sparse
Mixture-of-Experts has enabled efficient training of large language models.
Recent findings suggest that fixing the routers can achieve competitive
performance by alleviating the collapsing problem, where all experts eventually
learn similar representations. However, this strategy has two key limitations:
(i) the policy derived from random routers might be sub-optimal, and (ii) it
requires extensive resources during training and evaluation, leading to limited
efficiency gains. This work introduces \HyperRout, which dynamically generates
the router's parameters through a fixed hypernetwork and trainable embeddings
to achieve a balance between training the routers and freezing them to learn an
improved routing policy. Extensive experiments across a wide range of tasks
demonstrate the superior performance and efficiency gains of \HyperRouter
compared to existing routing methods. Our implementation is publicly available
at {\url{{https://github.com/giangdip2410/HyperRouter}}}.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07036" title="Abstract">arXiv:2312.07036</a> [<a href="/pdf/2312.07036" title="Download PDF">pdf</a>, <a href="/format/2312.07036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Debiasing Sequential Recommenders through Distributionally Robust  Optimization over System Exposure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yue Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yidan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+P">Pengjie Ren</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhumin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+F">Fei Cai</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhaochun Ren</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+X">Xin Xin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accept by WSDM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Sequential recommendation (SR) models are typically trained on user-item
interactions which are affected by the system exposure bias, leading to the
user preference learned from the biased SR model not being fully consistent
with the true user preference. Exposure bias refers to the fact that user
interactions are dependent upon the partial items exposed to the user. Existing
debiasing methods do not make full use of the system exposure data and suffer
from sub-optimal recommendation performance and high variance. In this paper,
we propose to debias sequential recommenders through Distributionally Robust
Optimization (DRO) over system exposure data. The key idea is to utilize DRO to
optimize the worst-case error over an uncertainty set to safeguard the model
against distributional discrepancy caused by the exposure bias. The main
challenge to apply DRO for exposure debiasing in SR lies in how to construct
the uncertainty set and avoid the overestimation of user preference on biased
samples. Moreover, how to evaluate the debiasing effect on biased test set is
also an open question. To this end, we first introduce an exposure simulator
trained upon the system exposure data to calculate the exposure distribution,
which is then regarded as the nominal distribution to construct the uncertainty
set of DRO. Then, we introduce a penalty to items with high exposure
probability to avoid the overestimation of user preference for biased samples.
Finally, we design a debiased self-normalized inverse propensity score (SNIPS)
evaluator for evaluating the debiasing effect on the biased offline test set.
We conduct extensive experiments on two real-world datasets to verify the
effectiveness of the proposed methods. Experimental results demonstrate the
superior exposure debiasing performance of proposed methods. Codes and data are
available at \url{https://github.com/nancheng58/DebiasedSR_DRO}.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07039" title="Abstract">arXiv:2312.07039</a> [<a href="/pdf/2312.07039" title="Download PDF">pdf</a>, <a href="/format/2312.07039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diff-OP3D: Bridging 2D Diffusion for Open Pose 3D Zero-Shot  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Weiguang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guanyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chaolong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chenru Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yuyao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaizhu Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the explosive 3D data growth, the urgency of utilizing zero-shot
learning to facilitate data labeling becomes evident. Recently, the methods via
transferring Contrastive Language-Image Pre-training (CLIP) to 3D vision have
made great progress in the 3D zero-shot classification task. However, these
methods primarily focus on aligned pose 3D objects (ap-3os), overlooking the
recognition of 3D objects with open poses (op-3os) typically encountered in
real-world scenarios, such as an overturned chair or a lying teddy bear. To
this end, we propose a more challenging benchmark for 3D open-pose zero-shot
classification. Echoing our benchmark, we design a concise angle-refinement
mechanism that automatically optimizes one ideal pose as well as classifies
these op-3os. Furthermore, we make a first attempt to bridge 2D pre-trained
diffusion model as a classifer to 3D zero-shot classification without any
additional training. Such 2D diffusion to 3D objects proves vital in improving
zero-shot classification for both ap-3os and op-3os. Our model notably improves
by 3.5% and 15.8% on ModelNet10$^{\ddag}$ and McGill$^{\ddag}$ open pose
benchmarks, respectively, and surpasses the current state-of-the-art by 6.8% on
the aligned pose ModelNet10, affirming diffusion's efficacy in 3D zero-shot
tasks.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07040" title="Abstract">arXiv:2312.07040</a> [<a href="/pdf/2312.07040" title="Download PDF">pdf</a>, <a href="/ps/2312.07040" title="Download PostScript">ps</a>, <a href="/format/2312.07040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Patch-MI: Enhancing Model Inversion Attacks via Patch-Based  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jang%2C+J">Jonggyu Jang</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+H">Hyeonsu Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H+J">Hyun Jong Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Model inversion (MI) attacks aim to reveal sensitive information in training
datasets by solely accessing model weights. Generative MI attacks, a prominent
strand in this field, utilize auxiliary datasets to recreate target data
attributes, restricting the images to remain photo-realistic, but their success
often depends on the similarity between auxiliary and target datasets. If the
distributions are dissimilar, existing MI attack attempts frequently fail,
yielding unrealistic or target-unrelated results. In response to these
challenges, we introduce a groundbreaking approach named Patch-MI, inspired by
jigsaw puzzle assembly. To this end, we build upon a new probabilistic
interpretation of MI attacks, employing a generative adversarial network
(GAN)-like framework with a patch-based discriminator. This approach allows the
synthesis of images that are similar to the target dataset distribution, even
in cases of dissimilar auxiliary dataset distribution. Moreover, we artfully
employ a random transformation block, a sophisticated maneuver that crafts
generalized images, thus enhancing the efficacy of the target classifier. Our
numerical and graphical findings demonstrate that Patch-MI surpasses existing
generative MI methods in terms of accuracy, marking significant advancements
while preserving comparable statistical dataset quality. For reproducibility of
our results, we make our source code publicly available in
https://github.com/jonggyujang0123/Patch-Attack.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07042" title="Abstract">arXiv:2312.07042</a> [<a href="/pdf/2312.07042" title="Download PDF">pdf</a>, <a href="/ps/2312.07042" title="Download PostScript">ps</a>, <a href="/format/2312.07042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rectified deep neural networks overcome the curse of dimensionality when  approximating solutions of McKean--Vlasov stochastic differential equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Neufeld%2C+A">Ariel Neufeld</a>, 
<a href="/search/math?searchtype=author&query=Nguyen%2C+T+A">Tuan Anh Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
<p class="mathjax">In this paper we prove that rectified deep neural networks do not suffer from
the curse of dimensionality when approximating McKean--Vlasov SDEs in the sense
that the number of parameters in the deep neural networks only grows
polynomially in the space dimension $d$ of the SDE and the reciprocal of the
accuracy $\epsilon$.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07043" title="Abstract">arXiv:2312.07043</a> [<a href="/pdf/2312.07043" title="Download PDF">pdf</a>, <a href="/format/2312.07043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Complexity of Envy-Free Graph Cutting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deligkas%2C+A">Argyrios Deligkas</a>, 
<a href="/search/cs?searchtype=author&query=Eiben%2C+E">Eduard Eiben</a>, 
<a href="/search/cs?searchtype=author&query=Ganian%2C+R">Robert Ganian</a>, 
<a href="/search/cs?searchtype=author&query=Hamm%2C+T">Thekla Hamm</a>, 
<a href="/search/cs?searchtype=author&query=Ordyniak%2C+S">Sebastian Ordyniak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Short version appeared at IJCAI 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI); Computational Complexity (cs.CC)

</div>
<p class="mathjax">We consider the problem of fairly dividing a set of heterogeneous divisible
resources among agents with different preferences. We focus on the setting
where the resources correspond to the edges of a connected graph, every agent
must be assigned a connected piece of this graph, and the fairness notion
considered is the classical envy freeness. The problem is NP-complete, and we
analyze its complexity with respect to two natural complexity measures: the
number of agents and the number of edges in the graph. While the problem
remains NP-hard even for instances with 2 agents, we provide a dichotomy
characterizing the complexity of the problem when the number of agents is
constant based on structural properties of the graph. For the latter case, we
design a polynomial-time algorithm when the graph has a constant number of
edges.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07044" title="Abstract">arXiv:2312.07044</a> [<a href="/pdf/2312.07044" title="Download PDF">pdf</a>, <a href="/format/2312.07044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Foundation Models for Power Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Huang%2C+C">Chenghao Huang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Siyang Li</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+R">Ruohong Liu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yize Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code available at <a href="https://github.com/chennnnnyize/LLM_PowerSystems">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Foundation models, such as Large Language Models (LLMs), can respond to a
wide range of format-free queries without any task-specific data collection or
model training, creating various research and application opportunities for the
modeling and operation of large-scale power systems. In this paper, we outline
how such large foundation model such as GPT-4 are developed, and discuss how
they can be leveraged in challenging power and energy system tasks. We first
investigate the potential of existing foundation models by validating their
performance on four representative tasks across power system domains, including
the optimal power flow (OPF), electric vehicle (EV) scheduling, knowledge
retrieval for power engineering technical reports, and situation awareness. Our
results indicate strong capabilities of such foundation models on boosting the
efficiency and reliability of power system operational pipelines. We also
provide suggestions and projections on future deployment of foundation models
in power system applications.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07046" title="Abstract">arXiv:2312.07046</a> [<a href="/pdf/2312.07046" title="Download PDF">pdf</a>, <a href="/ps/2312.07046" title="Download PostScript">ps</a>, <a href="/format/2312.07046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Compression: Reduced Order Modelling of Latent Features in  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chavan%2C+A">Arnav Chavan</a>, 
<a href="/search/cs?searchtype=author&query=Lele%2C+N">Nahush Lele</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+D">Deepak Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Brief technical report; Code will be made available at <a href="https://github.com/transmuteAI/trailmet/tree/main/trailmet/algorithms/llm-rom">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Due to the substantial scale of Large Language Models (LLMs), the direct
application of conventional compression methodologies proves impractical. The
computational demands associated with even minimal gradient updates present
challenges, particularly on consumer-grade hardware. This paper introduces an
innovative approach for the parametric and practical compression of LLMs based
on reduced order modelling, which entails low-rank decomposition within the
feature space and re-parameterization in the weight space. Notably, this
compression technique operates in a layer-wise manner, obviating the need for a
GPU device and enabling the compression of billion-scale models within
stringent constraints of both memory and time. Our method represents a
significant advancement in model compression by leveraging matrix
decomposition, demonstrating superior efficacy compared to the prevailing
state-of-the-art structured pruning method.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07048" title="Abstract">arXiv:2312.07048</a> [<a href="/pdf/2312.07048" title="Download PDF">pdf</a>, <a href="/format/2312.07048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge Wasserstein Distance Loss for Oriented Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuke Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+Y">Yumeng Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zihua Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Sheng Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Regression loss design is an essential topic for oriented object detection.
Due to the periodicity of the angle and the ambiguity of width and height
definition, traditional L1-distance loss and its variants have been suffered
from the metric discontinuity and the square-like problem. As a solution, the
distribution based methods show significant advantages by representing oriented
boxes as distributions. Differing from exploited the Gaussian distribution to
get analytical form of distance measure, we propose a novel oriented regression
loss, Wasserstein Distance(EWD) loss, to alleviate the square-like problem.
Specifically, for the oriented box(OBox) representation, we choose a
specially-designed distribution whose probability density function is only
nonzero over the edges. On this basis, we develop Wasserstein distance as the
measure. Besides, based on the edge representation of OBox, the EWD loss can be
generalized to quadrilateral and polynomial regression scenarios. Experiments
on multiple popular datasets and different detectors show the effectiveness of
the proposed method.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07049" title="Abstract">arXiv:2312.07049</a> [<a href="/pdf/2312.07049" title="Download PDF">pdf</a>, <a href="/format/2312.07049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Factual Error Correction by Learning to Inject Factual Errors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xingwei He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qianru Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+A">A-Long Jin</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yiu%2C+S+M">Siu Ming Yiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Factual error correction (FEC) aims to revise factual errors in false claims
with minimal editing, making them faithful to the provided evidence. This task
is crucial for alleviating the hallucination problem encountered by large
language models. Given the lack of paired data (i.e., false claims and their
corresponding correct claims), existing methods typically adopt the
mask-then-correct paradigm. This paradigm relies solely on unpaired false
claims and correct claims, thus being referred to as distantly supervised
methods. These methods require a masker to explicitly identify factual errors
within false claims before revising with a corrector. However, the absence of
paired data to train the masker makes accurately pinpointing factual errors
within claims challenging. To mitigate this, we propose to improve FEC by
Learning to Inject Factual Errors (LIFE), a three-step distantly supervised
method: mask-corrupt-correct. Specifically, we first train a corruptor using
the mask-then-corrupt procedure, allowing it to deliberately introduce factual
errors into correct text. The corruptor is then applied to correct claims,
generating a substantial amount of paired data. After that, we filter out
low-quality data, and use the remaining data to train a corrector. Notably, our
corrector does not require a masker, thus circumventing the bottleneck
associated with explicit factual error identification. Our experiments on a
public dataset verify the effectiveness of LIFE in two key aspects: Firstly, it
outperforms the previous best-performing distantly supervised method by a
notable margin of 10.59 points in SARI Final (19.3% improvement). Secondly,
even compared to ChatGPT prompted with in-context examples, LIFE achieves a
superiority of 7.16 points in SARI Final.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07051" title="Abstract">arXiv:2312.07051</a> [<a href="/pdf/2312.07051" title="Download PDF">pdf</a>, <a href="/format/2312.07051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mask as Supervision: Leveraging Unified Mask Information for  Unsupervised 3D Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuchen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiao Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Automatic estimation of 3D human pose from monocular RGB images is a
challenging and unsolved problem in computer vision. In a supervised manner,
approaches heavily rely on laborious annotations and present hampered
generalization ability due to the limited diversity of 3D pose datasets. To
address these challenges, we propose a unified framework that leverages mask as
supervision for unsupervised 3D pose estimation. With general unsupervised
segmentation algorithms, the proposed model employs skeleton and physique
representations that exploit accurate pose information from coarse to fine.
Compared with previous unsupervised approaches, we organize the human skeleton
in a fully unsupervised way which enables the processing of annotation-free
data and provides ready-to-use estimation results. Comprehensive experiments
demonstrate our state-of-the-art pose estimation performance on Human3.6M and
MPI-INF-3DHP datasets. Further experiments on in-the-wild datasets also
illustrate the capability to access more data to boost our model. Code will be
available at https://github.com/Charrrrrlie/Mask-as-Supervision.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07052" title="Abstract">arXiv:2312.07052</a> [<a href="/pdf/2312.07052" title="Download PDF">pdf</a>, <a href="/format/2312.07052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adjustable Robust Transformer for High Myopia Screening in Optical  Coherence Tomography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zetian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Z">Zexuan Ji</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+N">Na Su</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+S">Songtao Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qiang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures, MICCAI 2023 - Accepted Papers; International Conference on Medical Image Computing and Computer-Assisted Intervention, 2023: 504-514
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Myopia is a manifestation of visual impairment caused by an excessively
elongated eyeball. Image data is critical material for studying high myopia and
pathological myopia. Measurements of spherical equivalent and axial length are
the gold standards for identifying high myopia, but the available image data
for matching them is scarce. In addition, the criteria for defining high myopia
vary from study to study, and therefore the inclusion of samples in automated
screening efforts requires an appropriate assessment of interpretability. In
this work, we propose a model called adjustable robust transformer (ARTran) for
high myopia screening of optical coherence tomography (OCT) data. Based on
vision transformer, we propose anisotropic patch embedding (APE) to capture
more discriminative features of high myopia. To make the model effective under
variable screening conditions, we propose an adjustable class embedding (ACE)
to replace the fixed class token, which changes the output to adapt to
different conditions. Considering the confusion of the data at high myopia and
low myopia threshold, we introduce the label noise learning strategy and
propose a shifted subspace transition matrix (SST) to enhance the robustness of
the model. Besides, combining the two structures proposed above, the model can
provide evidence for uncertainty evaluation. The experimental results
demonstrate the effectiveness and reliability of the proposed method. Code is
available at: https://github.com/maxiao0234/ARTran.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07055" title="Abstract">arXiv:2312.07055</a> [<a href="/pdf/2312.07055" title="Download PDF">pdf</a>, <a href="/format/2312.07055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication Cost Reduction for Subgraph Counting under Local  Differential Privacy via Hash Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hillebrand%2C+Q">Quentin Hillebrand</a>, 
<a href="/search/cs?searchtype=author&query=Suppakitpaisarn%2C+V">Vorapong Suppakitpaisarn</a>, 
<a href="/search/cs?searchtype=author&query=Shibuya%2C+T">Tetsuo Shibuya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We suggest the use of hash functions to cut down the communication costs when
counting subgraphs under edge local differential privacy. While various
algorithms exist for computing graph statistics, including the count of
subgraphs, under the edge local differential privacy, many suffer with high
communication costs, making them less efficient for large graphs. Though data
compression is a typical approach in differential privacy, its application in
local differential privacy requires a form of compression that every node can
reproduce. In our study, we introduce linear congruence hashing. With a
sampling rate of $s$, our method can cut communication costs by a factor of
$s^2$, albeit at the cost of increasing variance in the published graph
statistic by a factor of $s$. The experimental results indicate that, when
matched for communication costs, our method achieves a reduction in the
$\ell_2$-error for triangle counts by up to 1000 times compared to the
performance of leading algorithms.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07059" title="Abstract">arXiv:2312.07059</a> [<a href="/pdf/2312.07059" title="Download PDF">pdf</a>, <a href="/format/2312.07059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LSTM-CNN Network for Audio Signature Analysis in Noisy Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Damacharla%2C+P">Praveen Damacharla</a>, 
<a href="/search/cs?searchtype=author&query=Rajabalipanah%2C+H">Hamid Rajabalipanah</a>, 
<a href="/search/cs?searchtype=author&query=Fakheri%2C+M+H">Mohammad Hosein Fakheri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10th Annual Conf. on Computational Science &amp; Computational Intelligence (CSCI'23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">There are multiple applications to automatically count people and specify
their gender at work, exhibitions, malls, sales, and industrial usage. Although
current speech detection methods are supposed to operate well, in most
situations, in addition to genders, the number of current speakers is unknown
and the classification methods are not suitable due to many possible classes.
In this study, we focus on a long-short-term memory convolutional neural
network (LSTM-CNN) to extract time and / or frequency-dependent features of the
sound data to estimate the number / gender of simultaneous active speakers at
each frame in noisy environments. Considering the maximum number of speakers as
10, we have utilized 19000 audio samples with diverse combinations of males,
females, and background noise in public cities, industrial situations, malls,
exhibitions, workplaces, and nature for learning purposes. This proof of
concept shows promising performance with training/validation MSE values of
about 0.019/0.017 in detecting count and gender.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07060" title="Abstract">arXiv:2312.07060</a> [<a href="/pdf/2312.07060" title="Download PDF">pdf</a>, <a href="/format/2312.07060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Layered Randomized Quantization for Communication-Efficient and  Privacy-Preserving Distributed Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+G">Guangfeng Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tan Li</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+T">Tian Lan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Linqi Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Next-generation wireless networks, such as edge intelligence and wireless
distributed learning, face two critical challenges: communication efficiency
and privacy protection. In this work, our focus is on addressing these issues
in a distributed learning framework. We consider a new approach that
simultaneously achieves communication efficiency and privacy protection by
exploiting the privacy advantage offered by quantization. Specifically, we use
a quantization scheme called \textbf{Gau}ssian \textbf{L}ayered
\textbf{R}andomized \textbf{Q}uantization (Gau-LRQ) that compresses the raw
model gradients using a layer multishift coupler. By adjusting the parameters
of Gau-LRQ, we shape the quantization error to follow the expected Gaussian
distribution, thus ensuring client-level differential privacy (CLDP). We
demonstrate the effectiveness of our proposed Gau-LRQ in the distributed
stochastic gradient descent (SGD) framework and theoretically quantify the
trade-offs between communication, privacy, and convergence performance. We
further improve the convergence performance by enabling dynamic private budget
and quantization bit allocation. We achieve this by using an optimization
formula that minimizes convergence error subject to the privacy budget
constraint. We evaluate our approach on multiple datasets, including MNIST,
CIFAR-10, and CIFAR-100, and show that our proposed method outperforms the
baselines in terms of learning performance under various privacy constraints.
Moreover, we observe that dynamic privacy allocation yields additional accuracy
improvements for the models compared to the fixed scheme.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07061" title="Abstract">arXiv:2312.07061</a> [<a href="/pdf/2312.07061" title="Download PDF">pdf</a>, <a href="/format/2312.07061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MaxQ: Multi-Axis Query for N:M Sparsity Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiang%2C+J">Jingyang Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Siqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuangzhi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tianxin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+L">Linpeng Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">N:M sparsity has received increasing attention due to its remarkable
performance and latency trade-off compared with structured and unstructured
sparsity. However, existing N:M sparsity methods do not differentiate the
relative importance of weights among blocks and leave important weights
underappreciated. Besides, they directly apply N:M sparsity to the whole
network, which will cause severe information loss. Thus, they are still
sub-optimal. In this paper, we propose an efficient and effective Multi-Axis
Query methodology, dubbed as MaxQ, to rectify these problems. During the
training, MaxQ employs a dynamic approach to generate soft N:M masks,
considering the weight importance across multiple axes. This method enhances
the weights with more importance and ensures more effective updates. Meanwhile,
a sparsity strategy that gradually increases the percentage of N:M weight
blocks is applied, which allows the network to heal from the pruning-induced
damage progressively. During the runtime, the N:M soft masks can be precomputed
as constants and folded into weights without causing any distortion to the
sparse pattern and incurring additional computational overhead. Comprehensive
experiments demonstrate that MaxQ achieves consistent improvements across
diverse CNN architectures in various computer vision tasks, including image
classification, object detection and instance segmentation. For ResNet50 with
1:16 sparse pattern, MaxQ can achieve 74.6\% top-1 accuracy on ImageNet and
improve by over 2.8\% over the state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07062" title="Abstract">arXiv:2312.07062</a> [<a href="/pdf/2312.07062" title="Download PDF">pdf</a>, <a href="/format/2312.07062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ThinkBot: Embodied Instruction Following with Thought Chain Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+G">Guanxing Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Changliu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiwen Lu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yansong Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Embodied Instruction Following (EIF) requires agents to complete human
instruction by interacting objects in complicated surrounding environments.
Conventional methods directly consider the sparse human instruction to generate
action plans for agents, which usually fail to achieve human goals because of
the instruction incoherence in action descriptions. On the contrary, we propose
ThinkBot that reasons the thought chain in human instruction to recover the
missing action descriptions, so that the agent can successfully complete human
goals by following the coherent instruction. Specifically, we first design an
instruction completer based on large language models to recover the missing
actions with interacted objects between consecutive human instruction, where
the perceived surrounding environments and the completed sub-goals are
considered for instruction completion. Based on the partially observed scene
semantic maps, we present an object localizer to infer the position of
interacted objects for agents to achieve complex human goals. Extensive
experiments in the simulated environment show that our ThinkBot outperforms the
state-of-the-art EIF methods by a sizable margin in both success rate and
execution efficiency.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07063" title="Abstract">arXiv:2312.07063</a> [<a href="/pdf/2312.07063" title="Download PDF">pdf</a>, <a href="/format/2312.07063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Template Free Reconstruction of Human-object Interaction with Procedural  Interaction Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xianghui Xie</a>, 
<a href="/search/cs?searchtype=author&query=Bhatnagar%2C+B+L">Bharat Lal Bhatnagar</a>, 
<a href="/search/cs?searchtype=author&query=Lenssen%2C+J+E">Jan Eric Lenssen</a>, 
<a href="/search/cs?searchtype=author&query=Pons-Moll%2C+G">Gerard Pons-Moll</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 18 figures. Project page: <a href="https://virtualhumans.mpi-inf.mpg.de/procigen-hdm">this https URL</a> (will be available soon)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Reconstructing human-object interaction in 3D from a single RGB image is a
challenging task and existing data driven methods do not generalize beyond the
objects present in the carefully curated 3D interaction datasets. Capturing
large-scale real data to learn strong interaction and 3D shape priors is very
expensive due to the combinatorial nature of human-object interactions. In this
paper, we propose ProciGen (Procedural interaction Generation), a method to
procedurally generate datasets with both, plausible interaction and diverse
object variation. We generate 1M+ human-object interaction pairs in 3D and
leverage this large-scale data to train our HDM (Hierarchical Diffusion Model),
a novel method to reconstruct interacting human and unseen objects, without any
templates. Our HDM is an image-conditioned diffusion model that learns both
realistic interaction and highly accurate human and object shapes. Experiments
show that our HDM trained with ProciGen significantly outperforms prior methods
that requires template meshes and that our dataset allows training methods with
strong generalization ability to unseen object instances. Our code and data
will be publicly released at:
https://virtualhumans.mpi-inf.mpg.de/procigen-hdm.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07064" title="Abstract">arXiv:2312.07064</a> [<a href="/pdf/2312.07064" title="Download PDF">pdf</a>, <a href="/format/2312.07064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Cross-Domain Federated Learning by MixStyle Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=R%C3%B6der%2C+M">Manuel R&#xf6;der</a>, 
<a href="/search/cs?searchtype=author&query=Heller%2C+L">Leon Heller</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCnch%2C+M">Maximilian M&#xfc;nch</a>, 
<a href="/search/cs?searchtype=author&query=Schleif%2C+F">Frank-Michael Schleif</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the Adapting to Change: Reliable Multimodal Learning Across Domains Workshop @ ECML PKKD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">With the advent of interconnected and sensor-equipped edge devices, Federated
Learning (FL) has gained significant attention, enabling decentralized learning
while maintaining data privacy. However, FL faces two challenges in real-world
tasks: expensive data labeling and domain shift between source and target
samples. In this paper, we introduce a privacy-preserving, resource-efficient
FL concept for client adaptation in hardware-constrained environments. Our
approach includes server model pre-training on source data and subsequent
fine-tuning on target data via low-end clients. The local client adaptation
process is streamlined by probabilistic mixing of instance-level feature
statistics approximated from source and target domain data. The adapted
parameters are transferred back to the central server and globally aggregated.
Preliminary results indicate that our method reduces computational and
transmission costs while maintaining competitive performance on downstream
tasks.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07066" title="Abstract">arXiv:2312.07066</a> [<a href="/pdf/2312.07066" title="Download PDF">pdf</a>, <a href="/format/2312.07066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffuVST: Narrating Fictional Scenes with Global-History-Guided  Denoising Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shengguang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+M">Mei Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Q">Qi Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recent advances in image and video creation, especially AI-based image
synthesis, have led to the production of numerous visual scenes that exhibit a
high level of abstractness and diversity. Consequently, Visual Storytelling
(VST), a task that involves generating meaningful and coherent narratives from
a collection of images, has become even more challenging and is increasingly
desired beyond real-world imagery. While existing VST techniques, which
typically use autoregressive decoders, have made significant progress, they
suffer from low inference speed and are not well-suited for synthetic scenes.
To this end, we propose a novel diffusion-based system DiffuVST, which models
the generation of a series of visual descriptions as a single conditional
denoising process. The stochastic and non-autoregressive nature of DiffuVST at
inference time allows it to generate highly diverse narratives more
efficiently. In addition, DiffuVST features a unique design with bi-directional
text history guidance and multimodal adapter modules, which effectively improve
inter-sentence coherence and image-to-text fidelity. Extensive experiments on
the story generation task covering four fictional visual-story datasets
demonstrate the superiority of DiffuVST over traditional autoregressive models
in terms of both text quality and inference speed.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07067" title="Abstract">arXiv:2312.07067</a> [<a href="/pdf/2312.07067" title="Download PDF">pdf</a>, <a href="/format/2312.07067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Focus on Hiders: Exploring Hidden Threats for Enhancing Adversarial  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qian Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yuxiao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yinpeng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongxiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuntian Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV); Applications (stat.AP)

</div>
<p class="mathjax">Adversarial training is often formulated as a min-max problem, however,
concentrating only on the worst adversarial examples causes alternating
repetitive confusion of the model, i.e., previously defended or correctly
classified samples are not defensible or accurately classifiable in subsequent
adversarial training. We characterize such non-ignorable samples as "hiders",
which reveal the hidden high-risk regions within the secure area obtained
through adversarial training and prevent the model from finding the real worst
cases. We demand the model to prevent hiders when defending against adversarial
examples for improving accuracy and robustness simultaneously. By rethinking
and redefining the min-max optimization problem for adversarial training, we
propose a generalized adversarial training algorithm called Hider-Focused
Adversarial Training (HFAT). HFAT introduces the iterative evolution
optimization strategy to simplify the optimization problem and employs an
auxiliary model to reveal hiders, effectively combining the optimization
directions of standard adversarial training and prevention hiders. Furthermore,
we introduce an adaptive weighting mechanism that facilitates the model in
adaptively adjusting its focus between adversarial examples and hiders during
different training periods. We demonstrate the effectiveness of our method
based on extensive experiments, and ensure that HFAT can provide higher
robustness and accuracy.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07069" title="Abstract">arXiv:2312.07069</a> [<a href="/pdf/2312.07069" title="Download PDF">pdf</a>, <a href="/format/2312.07069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context Matter: Data-Efficient Augmentation of Large Language Models for  Scientific Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Haoran Tang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Maravi%2C+A">Anurag Maravi</a>, 
<a href="/search/cs?searchtype=author&query=Abram%2C+M">Marcin Abram</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures, 4 tables, 3 pages of supplementary material
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we explore the challenges inherent to Large Language Models
(LLMs) like GPT-4, particularly their propensity for hallucinations, logic
mistakes, and incorrect conclusions when tasked with answering complex
questions. The capacity of LLMs to present erroneous answers in a coherent and
semantically rigorous manner further complicates the detection of factual
inaccuracies. This issue is especially pronounced in fields that require
specialized expertise. Our work delves into these challenges, aiming to enhance
the understanding and mitigation of such errors, thereby contributing to the
improvement of LLM accuracy and reliability in scientific and other specialized
domains. Our findings reveal a non-linear relationship between the context's
relevancy and the answers' measured quality. In addition, we demonstrate that
with the correct calibration, it is possible to automate the grading procedure
-- a finding suggesting that, at least to some degree, the LLMs can be used to
self-examine the quality of their own performance. Finally, we describe an
experimental platform that can be seen as a proof-of-concept of the techniques
described in this work.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07071" title="Abstract">arXiv:2312.07071</a> [<a href="/pdf/2312.07071" title="Download PDF">pdf</a>, <a href="/ps/2312.07071" title="Download PostScript">ps</a>, <a href="/format/2312.07071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Large-Scale Electricity Market Pricing Problems in Polynomial  Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahunbay%2C+M+%C5%9E">Mete &#x15e;eref Ahunbay</a>, 
<a href="/search/cs?searchtype=author&query=Bichler%2C+M">Martin Bichler</a>, 
<a href="/search/cs?searchtype=author&query=Dobos%2C+T">Teodora Dobos</a>, 
<a href="/search/cs?searchtype=author&query=Kn%C3%B6rr%2C+J">Johannes Kn&#xf6;rr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Electricity market operators worldwide use mixed-integer linear programming
to solve the allocation problem in wholesale electricity markets. Prices are
typically determined based on the duals of relaxed versions of this
optimization problem. The resulting outcomes are efficient, but market
operators must pay out-of-market uplifts to some market participants and incur
a considerable budget deficit that was criticized by regulators. As the share
of renewables increases, the number of market participants will grow, leading
to larger optimization problems and runtime issues. At the same time,
non-convexities will continue to matter e.g., due to ramping constraints of the
generators required to address the variability of renewables or non-convex
curtailment costs. We draw on recent theoretical advances in the approximation
of competitive equilibrium to compute allocations and prices in electricity
markets using convex optimization. The proposed mechanism promises approximate
efficiency, no budget deficit, and computational tractability. We present
experimental results for this new mechanism in the context of electricity
markets, and compare the runtimes, the average efficiency loss of the method,
and the uplifts paid with standard pricing rules. We find that the computations
with the new algorithm are considerably fast for relevant problem sizes. In
general, the computational advantages come at the cost of efficiency losses and
a price markup for the demand side. Interestingly, both are small with
realistic problem instances. Importantly, the market operator does not incur a
budget deficit and the uplifts paid to market participants are significantly
lower compared to standard pricing rules.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07075" title="Abstract">arXiv:2312.07075</a> [<a href="/pdf/2312.07075" title="Download PDF">pdf</a>, <a href="/format/2312.07075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion Planning and Control of A Morphing Quadrotor in Restricted  Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+G">Guiyang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+R">Ruihao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yang Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Morphing quadrotors with four external actuators can adapt to different
restricted scenarios by changing their geometric structure. However, previous
works mainly focus on the improvements in structures and controllers, and
existing planning algorithms don't consider the morphological modifications,
which leads to safety and dynamic feasibility issues. In this paper, we propose
a unified planning and control framework for morphing quadrotors to deform
autonomously and efficiently. The framework consists of a milliseconds-level
spatial-temporal trajectory optimizer that takes into account the morphological
modifications of quadrotors. The optimizer can generate full-body safety
trajectories including position and attitude. Additionally, it incorporates a
nonlinear attitude controller that accounts for aerodynamic drag and
dynamically adjusts dynamic parameters such as the inertia tensor and Center of
Gravity. The controller can also online compute the thrust coefficient during
morphing. Benchmark experiments compared with existing methods validate the
robustness of the proposed controller. Extensive simulations and real-world
experiments are performed to demonstrate the effectiveness of the proposed
framework.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07077" title="Abstract">arXiv:2312.07077</a> [<a href="/pdf/2312.07077" title="Download PDF">pdf</a>, <a href="/format/2312.07077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Potential of an Independent Avatar to Augment Metaverse User  Socialization Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raptis%2C+T+P">Theofanis P. Raptis</a>, 
<a href="/search/cs?searchtype=author&query=Boldrini%2C+C">Chiara Boldrini</a>, 
<a href="/search/cs?searchtype=author&query=Conti%2C+M">Marco Conti</a>, 
<a href="/search/cs?searchtype=author&query=Passarella%2C+A">Andrea Passarella</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Supported by the projects: Piano Nazionale di Ripresa e Resilienza IR0000013 - "SoBigData.it", Partenariato Esteso PE00000013 - "FAIR", Centro Nazionale CN00000013 - "ICSC"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">We present a computational modelling approach which targets at capturing the
specifics on how to virtually augment a Metaverse user's available social time
capacity via using an independent and autonomous version of her digital
representation in the Metaverse. We envision a Metaverse-focused extension of
the traditional avatar concept: An avatar can be as well programmed to operate
independently when its user is not controlling it directly, thus turning it
into an agent-based digital human representation. This way, the user can
virtually delegate on the avatar socializing time required for maintaining the
existing contacts, so as to eventually maintain spare non-avatar-mediated
socializing time which can be potentially invested in additional socialization
activities. We model the setting and identify the characteristic variables via
using selected concepts from social sciences: ego networks, social presence,
and social cues. Then, we formulate the problem of maximizing the user's
non-avatar-mediated spare time as a linear optimization. Finally, we analyze
the feasible region of the problem and we present some initial insights on the
spare time that can be achieved for different parameter values of the
avatar-mediated interactions.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07079" title="Abstract">arXiv:2312.07079</a> [<a href="/pdf/2312.07079" title="Download PDF">pdf</a>, <a href="/format/2312.07079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial-Contextual Discrepancy Information Compensation for GAN  Inversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziqiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+J">Jing-Hao Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanzi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Most existing GAN inversion methods either achieve accurate reconstruction
but lack editability or offer strong editability at the cost of fidelity.
Hence, how to balance the distortioneditability trade-off is a significant
challenge for GAN inversion. To address this challenge, we introduce a novel
spatial-contextual discrepancy information compensationbased GAN-inversion
method (SDIC), which consists of a discrepancy information prediction network
(DIPN) and a discrepancy information compensation network (DICN). SDIC follows
a "compensate-and-edit" paradigm and successfully bridges the gap in image
details between the original image and the reconstructed/edited image. On the
one hand, DIPN encodes the multi-level spatial-contextual information of the
original and initial reconstructed images and then predicts a
spatial-contextual guided discrepancy map with two hourglass modules. In this
way, a reliable discrepancy map that models the contextual relationship and
captures finegrained image details is learned. On the other hand, DICN
incorporates the predicted discrepancy information into both the latent code
and the GAN generator with different transformations, generating high-quality
reconstructed/edited images. This effectively compensates for the loss of image
details during GAN inversion. Both quantitative and qualitative experiments
demonstrate that our proposed method achieves the excellent
distortion-editability trade-off at a fast inference speed for both image
inversion and editing tasks.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07080" title="Abstract">arXiv:2312.07080</a> [<a href="/pdf/2312.07080" title="Download PDF">pdf</a>, <a href="/format/2312.07080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proving the stability estimates of variational least-squares  Kernel-Based methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+M">Meng Chen</a>, 
<a href="/search/math?searchtype=author&query=Ling%2C+L">Leevan Ling</a>, 
<a href="/search/math?searchtype=author&query=Yun%2C+D">Dongfang Yun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Motivated by the need for the rigorous analysis of the numerical stability of
variational least-squares kernel-based methods for solving second-order
elliptic partial differential equations, we provide previously lacking
stability inequalities. This fills a significant theoretical gap in the
previous work [Comput. Math. Appl. 103 (2021) 1-11], which provided error
estimates based on a conjecture on the stability. With the stability estimate
now rigorously proven, we complete the theoretical foundations and compare the
convergence behavior to the proven rates. Furthermore, we establish another
stability inequality involving weighted-discrete norms, and provide a
theoretical proof demonstrating that the exact quadrature weights are not
necessary for the weighted least-squares kernel-based collocation method to
converge. Our novel theoretical insights are validated by numerical examples,
which showcase the relative efficiency and accuracy of these methods on data
sets with large mesh ratios. The results confirm our theoretical predictions
regarding the performance of variational least-squares kernel-based method,
least-squares kernel-based collocation method, and our new weighted
least-squares kernel-based collocation method. Most importantly, our results
demonstrate that all methods converge at the same rate, validating the
convergence theory of weighted least-squares in our proven theories.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07082" title="Abstract">arXiv:2312.07082</a> [<a href="/pdf/2312.07082" title="Download PDF">pdf</a>, <a href="/format/2312.07082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Learning through Networks Splitting and Merging with  Dreaming-Meta-Weighted Model Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jian Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+G">Guanglei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yifei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Q">Qiang Fang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">It's challenging to balance the networks stability and plasticity in
continual learning scenarios, considering stability suffers from the update of
model and plasticity benefits from it. Existing works usually focus more on the
stability and restrict the learning plasticity of later tasks to avoid
catastrophic forgetting of learned knowledge. Differently, we propose a
continual learning method named Split2MetaFusion which can achieve better
trade-off by employing a two-stage strategy: splitting and meta-weighted
fusion. In this strategy, a slow model with better stability, and a fast model
with better plasticity are learned sequentially at the splitting stage. Then
stability and plasticity are both kept by fusing the two models in an adaptive
manner. Towards this end, we design an optimizer named Task-Preferred Null
Space Projector(TPNSP) to the slow learning process for narrowing the fusion
gap. To achieve better model fusion, we further design a Dreaming-Meta-Weighted
fusion policy for better maintaining the old and new knowledge simultaneously,
which doesn't require to use the previous datasets. Experimental results and
analysis reported in this work demonstrate the superiority of the proposed
method for maintaining networks stability and keeping its plasticity. Our code
will be released.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07083" title="Abstract">arXiv:2312.07083</a> [<a href="/pdf/2312.07083" title="Download PDF">pdf</a>, <a href="/format/2312.07083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GNBG: A Generalized and Configurable Benchmark Generator for Continuous  Numerical Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yazdani%2C+D">Danial Yazdani</a> (1), 
<a href="/search/cs?searchtype=author&query=Omidvar%2C+M+N">Mohammad Nabi Omidvar</a> (2), 
<a href="/search/cs?searchtype=author&query=Yazdani%2C+D">Delaram Yazdani</a> (3), 
<a href="/search/cs?searchtype=author&query=Deb%2C+K">Kalyanmoy Deb</a> (4), 
<a href="/search/cs?searchtype=author&query=Gandomi%2C+A+H">Amir H. Gandomi</a> (1,5) ((1) Faculty of Engineering &amp; Information Technology, University of Technology Sydney, (2) School of Computing, University of Leeds, and Leeds University Business School, (3) Liverpool Logistics, Offshore and Marine (LOOM) Research Institute, Faculty of Engineering and Technology, School of Engineering, Liverpool John Moores University, (4) BEACON Center, Michigan State University, (5) University Research and Innovation Center (EKIK), Obuda University)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">As optimization challenges continue to evolve, so too must our tools and
understanding. To effectively assess, validate, and compare optimization
algorithms, it is crucial to use a benchmark test suite that encompasses a
diverse range of problem instances with various characteristics. Traditional
benchmark suites often consist of numerous fixed test functions, making it
challenging to align these with specific research objectives, such as the
systematic evaluation of algorithms under controllable conditions. This paper
introduces the Generalized Numerical Benchmark Generator (GNBG) for
single-objective, box-constrained, continuous numerical optimization. Unlike
existing approaches that rely on multiple baseline functions and
transformations, GNBG utilizes a single, parametric, and configurable baseline
function. This design allows for control over various problem characteristics.
Researchers using GNBG can generate instances that cover a broad array of
morphological features, from unimodal to highly multimodal functions, various
local optima patterns, and symmetric to highly asymmetric structures. The
generated problems can also vary in separability, variable interaction
structures, dimensionality, conditioning, and basin shapes. These customizable
features enable the systematic evaluation and comparison of optimization
algorithms, allowing researchers to probe their strengths and weaknesses under
diverse and controllable conditions.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07086" title="Abstract">arXiv:2312.07086</a> [<a href="/pdf/2312.07086" title="Download PDF">pdf</a>, <a href="/ps/2312.07086" title="Download PostScript">ps</a>, <a href="/format/2312.07086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating the generative AI era: Introducing the AI assessment scale  for ethical GenAI assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perkins%2C+M">Mike Perkins</a> (1), 
<a href="/search/cs?searchtype=author&query=Furze%2C+L">Leon Furze</a> (2), 
<a href="/search/cs?searchtype=author&query=Roe%2C+J">Jasper Roe</a> (3), 
<a href="/search/cs?searchtype=author&query=MacVaugh%2C+J">Jason MacVaugh</a> (1) ((1) British University Vietnam, (2) Deakin University, (3) James Cook University Singapore)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Recent developments in Generative Artificial Intelligence (GenAI) have
created a paradigm shift in multiple areas of society, and the use of these
technologies is likely to become a defining feature of education in coming
decades. GenAI offers transformative pedagogical opportunities, while
simultaneously posing ethical and academic challenges. Against this backdrop,
we outline a practical, simple, and sufficiently comprehensive tool to allow
for the integration of GenAI tools into educational assessment: the AI
Assessment Scale (AIAS). The AIAS empowers educators to select the appropriate
level of GenAI usage in assessments based on the learning outcomes they seek to
address. The AIAS offers greater clarity and transparency for students and
educators, provides a fair and equitable policy tool for institutions to work
with, and offers a nuanced approach which embraces the opportunities of GenAI
while recognising that there are instances where such tools may not be
pedagogically appropriate or necessary. By adopting a practical, flexible
approach that can be implemented quickly, the AIAS can form a much-needed
starting point to address the current uncertainty and anxiety regarding GenAI
in education. As a secondary objective, we engage with the current literature
and advocate for a refocused discourse on GenAI tools in education, one which
foregrounds how technologies can help support and enhance teaching and
learning, which contrasts with the current focus on GenAI as a facilitator of
academic misconduct.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07087" title="Abstract">arXiv:2312.07087</a> [<a href="/pdf/2312.07087" title="Download PDF">pdf</a>, <a href="/format/2312.07087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Robustness in Multi-label Classification: A Data Augmentation  Strategy against Imbalance and Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hwanjun Song</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minseok Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jae-Gil Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was accepted at AAAI 2024. We upload the full version of our paper on arXiv due to the page limit of AAAI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multi-label classification poses challenges due to imbalanced and noisy
labels in training data. We propose a unified data augmentation method, named
BalanceMix, to address these challenges. Our approach includes two samplers for
imbalanced labels, generating minority-augmented instances with high diversity.
It also refines multi-labels at the label-wise granularity, categorizing noisy
labels as clean, re-labeled, or ambiguous for robust optimization. Extensive
experiments on three benchmark datasets demonstrate that BalanceMix outperforms
existing state-of-the-art methods. We release the code at
https://github.com/DISL-Lab/BalanceMix.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07088" title="Abstract">arXiv:2312.07088</a> [<a href="/pdf/2312.07088" title="Download PDF">pdf</a>, <a href="/format/2312.07088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BED: Bi-Encoder-Decoder Model for Canonical Relation Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+N">Nantao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+S">Siyu Long</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xinyu Dai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Canonical relation extraction aims to extract relational triples from
sentences, where the triple elements (entity pairs and their relationship) are
mapped to the knowledge base. Recently, methods based on the encoder-decoder
architecture are proposed and achieve promising results. However, these methods
cannot well utilize the entity information, which is merely used as augmented
training data. Moreover, they are incapable of representing novel entities,
since no embeddings have been learned for them. In this paper, we propose a
novel framework, Bi-Encoder-Decoder (BED), to solve the above issues.
Specifically, to fully utilize entity information, we employ an encoder to
encode semantics of this information, leading to high-quality entity
representations. For novel entities, given a trained entity encoder, their
representations can be easily generated. Experimental results on two datasets
show that, our method achieves a significant performance improvement over the
previous state-of-the-art and handle novel entities well without retraining.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07090" title="Abstract">arXiv:2312.07090</a> [<a href="/pdf/2312.07090" title="Download PDF">pdf</a>, <a href="/format/2312.07090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling a Variant Calling Genomics Pipeline with FaaS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arjona%2C+A">Aitor Arjona</a>, 
<a href="/search/cs?searchtype=author&query=Gabriel-Atienza%2C+A">Arnau Gabriel-Atienza</a>, 
<a href="/search/cs?searchtype=author&query=Lanuza-Orna%2C+S">Sara Lanuza-Orna</a>, 
<a href="/search/cs?searchtype=author&query=Roca-Canals%2C+X">Xavier Roca-Canals</a>, 
<a href="/search/cs?searchtype=author&query=Bourramouss%2C+A">Ayman Bourramouss</a>, 
<a href="/search/cs?searchtype=author&query=Chafin%2C+T+K">Tyler K. Chafin</a>, 
<a href="/search/cs?searchtype=author&query=Marcello%2C+L">Lucio Marcello</a>, 
<a href="/search/cs?searchtype=author&query=Ribeca%2C+P">Paolo Ribeca</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa-L%C3%B3pez%2C+P">Pedro Garc&#xed;a-L&#xf3;pez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, published at 9th International Workshop on Serverless Computing (WoSC '23), December 11-15, 2023, Bologna, Italy
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> WoSC 23 Proceedings of the 9th International Workshop on
  Serverless Computing, December 2023, Pages 59 64
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">With the escalating complexity and volume of genomic data, the capacity of
biology institutions' HPC faces limitations. While the Cloud presents a viable
solution for short-term elasticity, its intricacies pose challenges for
bioinformatics users. Alternatively, serverless computing allows for workload
scalability with minimal developer burden. However, porting a scientific
application to serverless is not a straightforward process. In this article, we
present a Variant Calling genomics pipeline migrated from single-node HPC to a
serverless architecture. We describe the inherent challenges of this approach
and the engineering efforts required to achieve scalability. We contribute by
open-sourcing the pipeline for future systems research and as a scalable
user-friendly tool for the bioinformatics community.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07093" title="Abstract">arXiv:2312.07093</a> [<a href="/pdf/2312.07093" title="Download PDF">pdf</a>, <a href="/format/2312.07093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TT-RecS: The Taxonomic Trace Recommender System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Unterkalmsteiner%2C+M">Michael Unterkalmsteiner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Seventh International Workshop on Artificial Intelligence for Requirements Engineering (AIRE 2020)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Traditional trace links are established directly between source and target
artefacts. This requires that the target artefact exists when the trace is
established. We introduce the concept of indirect trace links between a source
artefact and a knowledge organization structure, e.g. a taxonomy. This allows
the creation of links (we call them taxonomic traces) before target artefacts
are created. To gauge the viability of this concept and approach, we developed
a prototype, TT-RecS, that allows to create such trace links either manually or
with the help of a recommender system.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07100" title="Abstract">arXiv:2312.07100</a> [<a href="/pdf/2312.07100" title="Download PDF">pdf</a>, <a href="/format/2312.07100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightweight high-resolution Subject Matting in the Real World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Peng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fanyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Jingwen Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+G">Guojun Qi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing saliency object detection (SOD) methods struggle to satisfy fast
inference and accurate results simultaneously in high resolution scenes. They
are limited by the quality of public datasets and efficient network modules for
high-resolution images. To alleviate these issues, we propose to construct a
saliency object matting dataset HRSOM and a lightweight network PSUNet.
Considering efficient inference of mobile depolyment framework, we design a
symmetric pixel shuffle module and a lightweight module TRSU. Compared to 13
SOD methods, the proposed PSUNet has the best objective performance on the
high-resolution benchmark dataset. Evaluation results of objective assessment
are superior compared to U$^2$Net that has 10 times of parameter amount of our
network. On Snapdragon 8 Gen 2 Mobile Platform, inference a single
640$\times$640 image only takes 113ms. And on the subjective assessment,
evaluation results are better than the industry benchmark IOS16 (Lift subject
from background).
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07101" title="Abstract">arXiv:2312.07101</a> [<a href="/pdf/2312.07101" title="Download PDF">pdf</a>, <a href="/format/2312.07101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-survey on outlier and anomaly detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Olteanu%2C+M">Madalina Olteanu</a> (CEREMADE), 
<a href="/search/cs?searchtype=author&query=Rossi%2C+F">Fabrice Rossi</a> (CEREMADE), 
<a href="/search/cs?searchtype=author&query=Yger%2C+F">Florian Yger</a> (MILES, LAMSADE)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neurocomputing, 2023, 555, pp.126634
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Statistics Theory (math.ST)

</div>
<p class="mathjax">The impact of outliers and anomalies on model estimation and data processing
is of paramount importance, as evidenced by the extensive body of research
spanning various fields over several decades: thousands of research papers have
been published on the subject. As a consequence, numerous reviews, surveys, and
textbooks have sought to summarize the existing literature, encompassing a wide
range of methods from both the statistical and data mining communities. While
these endeavors to organize and summarize the research are invaluable, they
face inherent challenges due to the pervasive nature of outliers and anomalies
in all data-intensive applications, irrespective of the specific application
field or scientific discipline. As a result, the resulting collection of papers
remains voluminous and somewhat heterogeneous. To address the need for
knowledge organization in this domain, this paper implements the first
systematic meta-survey of general surveys and reviews on outlier and anomaly
detection. Employing a classical systematic survey approach, the study collects
nearly 500 papers using two specialized scientific search engines. From this
comprehensive collection, a subset of 56 papers that claim to be general
surveys on outlier detection is selected using a snowball search technique to
enhance field coverage. A meticulous quality assessment phase further refines
the selection to a subset of 25 high-quality general surveys. Using this
curated collection, the paper investigates the evolution of the outlier
detection field over a 20-year period, revealing emerging themes and methods.
Furthermore, an analysis of the surveys sheds light on the survey writing
practices adopted by scholars from different communities who have contributed
to this field. Finally, the paper delves into several topics where consensus
has emerged from the literature. These include taxonomies of outlier types,
challenges posed by high-dimensional data, the importance of anomaly scores,
the impact of learning conditions, difficulties in benchmarking, and the
significance of neural networks. Non-consensual aspects are also discussed,
particularly the distinction between local and global outliers and the
challenges in organizing detection methods into meaningful taxonomies.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07103" title="Abstract">arXiv:2312.07103</a> [<a href="/pdf/2312.07103" title="Download PDF">pdf</a>, <a href="/ps/2312.07103" title="Download PostScript">ps</a>, <a href="/format/2312.07103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Computational Complexity of Concise Hypersphere Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eiben%2C+E">Eduard Eiben</a>, 
<a href="/search/cs?searchtype=author&query=Ganian%2C+R">Robert Ganian</a>, 
<a href="/search/cs?searchtype=author&query=Kanj%2C+I">Iyad Kanj</a>, 
<a href="/search/cs?searchtype=author&query=Ordyniak%2C+S">Sebastian Ordyniak</a>, 
<a href="/search/cs?searchtype=author&query=Szeider%2C+S">Stefan Szeider</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Short version appeared at ICML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Hypersphere classification is a classical and foundational method that can
provide easy-to-process explanations for the classification of real-valued and
binary data. However, obtaining an (ideally concise) explanation via
hypersphere classification is much more difficult when dealing with binary data
than real-valued data. In this paper, we perform the first complexity-theoretic
study of the hypersphere classification problem for binary data. We use the
fine-grained parameterized complexity paradigm to analyze the impact of
structural properties that may be present in the input data as well as
potential conciseness constraints. Our results include stronger lower bounds
and new fixed-parameter algorithms for hypersphere classification of binary
data, which can find an exact and concise explanation when one exists.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07104" title="Abstract">arXiv:2312.07104</a> [<a href="/pdf/2312.07104" title="Download PDF">pdf</a>, <a href="/format/2312.07104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficiently Programming Large Language Models using SGLang
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Lianmin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+L">Liangsheng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhiqiang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jeff Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chuyue Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C+H">Cody Hao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Shiyi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Kozyrakis%2C+C">Christos Kozyrakis</a>, 
<a href="/search/cs?searchtype=author&query=Stoica%2C+I">Ion Stoica</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+J+E">Joseph E. Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Barrett%2C+C">Clark Barrett</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+Y">Ying Sheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Large language models (LLMs) are increasingly used for complex tasks
requiring multiple chained generation calls, advanced prompting techniques,
control flow, and interaction with external environments. However, efficient
systems for programming and executing these applications are lacking. To bridge
this gap, we introduce SGLang, a Structured Generation Language for LLMs.
SGLang is designed for the efficient programming of LLMs and incorporates
primitives for common LLM programming patterns. We have implemented SGLang as a
domain-specific language embedded in Python, and we developed an interpreter, a
compiler, and a high-performance runtime for SGLang. These components work
together to enable optimizations such as parallelism, batching, caching,
sharing, and other compilation techniques. Additionally, we propose
RadixAttention, a novel technique that maintains a Least Recently Used (LRU)
cache of the Key-Value (KV) cache for all requests in a radix tree, enabling
automatic KV cache reuse across multiple generation calls at runtime. SGLang
simplifies the writing of LLM programs and boosts execution efficiency. Our
experiments demonstrate that SGLang can speed up common LLM tasks by up to 5x,
while reducing code complexity and enhancing control.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07106" title="Abstract">arXiv:2312.07106</a> [<a href="/pdf/2312.07106" title="Download PDF">pdf</a>, <a href="/format/2312.07106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Progression Model of Software Engineering Goals, Challenges, and  Practices in Start-Ups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klotins%2C+E">Eriks Klotins</a>, 
<a href="/search/cs?searchtype=author&query=Unterkalmsteiner%2C+M">Michael Unterkalmsteiner</a>, 
<a href="/search/cs?searchtype=author&query=Chatzipetrou%2C+P">Panagiota Chatzipetrou</a>, 
<a href="/search/cs?searchtype=author&query=Gorschek%2C+T">Tony Gorschek</a>, 
<a href="/search/cs?searchtype=author&query=Prikladnicki%2C+R">Rafael Prikladnicki</a>, 
<a href="/search/cs?searchtype=author&query=Tripathi%2C+N">Nirnaya Tripathi</a>, 
<a href="/search/cs?searchtype=author&query=Pompermaier%2C+L+B">Leandro Bento Pompermaier</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Trans. Software Eng. 47(3): 498-521 (2021)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Context: Software start-ups are emerging as suppliers of innovation and
software-intensive products. However, traditional software engineering
practices are not evaluated in the context, nor adopted to goals and challenges
of start-ups. As a result, there is insufficient support for software
engineering in the start-up context. Objective: We aim to collect data related
to engineering goals, challenges, and practices in start-up companies to
ascertain trends and patterns characterizing engineering work in start-ups.
Such data allows researchers to understand better how goals and challenges are
related to practices. This understanding can then inform future studies aimed
at designing solutions addressing those goals and challenges. Besides, these
trends and patterns can be useful for practitioners to make more informed
decisions in their engineering practice. Method: We use a case survey method to
gather first-hand, in-depth experiences from a large sample of software
start-ups. We use open coding and cross-case analysis to describe and identify
patterns, and corroborate the findings with statistical analysis. Results: We
analyze 84 start-up cases and identify 16 goals, 9 challenges, and 16
engineering practices that are common among start-ups. We have mapped these
goals, challenges, and practices to start-up life-cycle stages (inception,
stabilization, growth, and maturity). Thus, creating the progression model
guiding software engineering efforts in start-ups. Conclusions: We conclude
that start-ups to a large extent face the same challenges and use the same
practices as established companies. However, the primary software engineering
challenge in start-ups is to evolve multiple process areas at once, with a
little margin for serious errors.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07107" title="Abstract">arXiv:2312.07107</a> [<a href="/pdf/2312.07107" title="Download PDF">pdf</a>, <a href="/format/2312.07107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Logic of Doxastic Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Junli Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Naumov%2C+P">Pavel Naumov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 38th Annual AAAI Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">In many real-world situations, there is often not enough information to know
that a certain strategy will succeed in achieving the goal, but there is a good
reason to believe that it will. The paper introduces the term ``doxastic'' for
such strategies.
<br />The main technical contribution is a sound and complete logical system that
describes the interplay between doxastic strategy and belief modalities.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07110" title="Abstract">arXiv:2312.07110</a> [<a href="/pdf/2312.07110" title="Download PDF">pdf</a>, <a href="/format/2312.07110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMs Perform Poorly at Concept Extraction in Cyber-security Research  Literature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=W%C3%BCrsch%2C+M">Maxime W&#xfc;rsch</a>, 
<a href="/search/cs?searchtype=author&query=Kucharavy%2C+A">Andrei Kucharavy</a>, 
<a href="/search/cs?searchtype=author&query=David%2C+D+P">Dimitri Percia David</a>, 
<a href="/search/cs?searchtype=author&query=Mermoud%2C+A">Alain Mermoud</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">The cybersecurity landscape evolves rapidly and poses threats to
organizations. To enhance resilience, one needs to track the latest
developments and trends in the domain. It has been demonstrated that standard
bibliometrics approaches show their limits in such a fast-evolving domain. For
this purpose, we use large language models (LLMs) to extract relevant knowledge
entities from cybersecurity-related texts. We use a subset of arXiv preprints
on cybersecurity as our data and compare different LLMs in terms of entity
recognition (ER) and relevance. The results suggest that LLMs do not produce
good knowledge entities that reflect the cybersecurity context, but our results
show some potential for noun extractors. For this reason, we developed a noun
extractor boosted with some statistical analysis to extract specific and
relevant compound nouns from the domain. Later, we tested our model to identify
trends in the LLM domain. We observe some limitations, but it offers promising
results to monitor the evolution of emergent trends.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07112" title="Abstract">arXiv:2312.07112</a> [<a href="/pdf/2312.07112" title="Download PDF">pdf</a>, <a href="/format/2312.07112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating High-Resolution Regional Precipitation Using Conditional  Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shidqi%2C+N">Naufal Shidqi</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+C">Chaeyoon Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sungwon Park</a>, 
<a href="/search/cs?searchtype=author&query=Zeller%2C+E">Elke Zeller</a>, 
<a href="/search/cs?searchtype=author&query=Nellikkattil%2C+A+B">Arjun Babu Nellikkattil</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+K">Karandeep Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, the 9th Joint Conference of Korean Artificial Intelligence Association, KAIA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">Climate downscaling is a crucial technique within climate research, serving
to project low-resolution (LR) climate data to higher resolutions (HR).
Previous research has demonstrated the effectiveness of deep learning for
downscaling tasks. However, most deep learning models for climate downscaling
may not perform optimally for high scaling factors (i.e., 4x, 8x) due to their
limited ability to capture the intricate details required for generating HR
climate data. Furthermore, climate data behaves differently from image data,
necessitating a nuanced approach when employing deep generative models. In
response to these challenges, this paper presents a deep generative model for
downscaling climate data, specifically precipitation on a regional scale. We
employ a denoising diffusion probabilistic model (DDPM) conditioned on multiple
LR climate variables. The proposed model is evaluated using precipitation data
from the Community Earth System Model (CESM) v1.2.2 simulation. Our results
demonstrate significant improvements over existing baselines, underscoring the
effectiveness of the conditional diffusion model in downscaling climate data.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07117" title="Abstract">arXiv:2312.07117</a> [<a href="/pdf/2312.07117" title="Download PDF">pdf</a>, <a href="/format/2312.07117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On inefficiently connecting temporal networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Christiann%2C+E">Esteban Christiann</a>, 
<a href="/search/cs?searchtype=author&query=Sanlaville%2C+E">Eric Sanlaville</a>, 
<a href="/search/cs?searchtype=author&query=Schoeters%2C+J">Jason Schoeters</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">A temporal graph can be represented by a graph with an edge labelling, such
that an edge is present in the network if and only if the edge is assigned the
corresponding time label. A journey is a labelled path in a temporal graph such
that labels on successive edges of the path are increasing, and if all vertices
admit journeys to all other vertices, the temporal graph is temporally
connected. A temporal spanner is a sublabelling of the temporal graph such that
temporal connectivity is maintained. The study of temporal spanners has raised
interest since the early 2000's. Essentially two types of studies have been
conducted: the positive side where families of temporal graphs are shown to
(deterministically or stochastically) admit sparse temporal spanners, and the
negative side where constructions of temporal graphs with no sparse spanners
are of importance. Often such studies considered temporal graphs with happy or
simple labellings, which associate exactly one label per edge. In this paper,
we focus on the negative side and consider proper labellings, where multiple
labels per edge are allowed. More precisely, we aim to construct dense
temporally connected graphs such that all labels are necessary for temporal
connectivity. Our contributions are multiple: we present the first labellings
maximizing a local density measure; exact or asymptotically tight results for
basic graph families, which are then extended to larger graph families; an
extension of an efficient temporal graph labelling generator; and overall
denser labellings than previous work even when restricted to happy labellings.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07122" title="Abstract">arXiv:2312.07122</a> [<a href="/pdf/2312.07122" title="Download PDF">pdf</a>, <a href="/format/2312.07122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Reasoning About Agents&#x27; Goals, Preferences, and Actions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bortoletto%2C+M">Matteo Bortoletto</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Lei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Bulling%2C+A">Andreas Bulling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 38th Annual AAAI Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">We propose the Intuitive Reasoning Network (IRENE) - a novel neural model for
intuitive psychological reasoning about agents' goals, preferences, and actions
that can generalise previous experiences to new situations. IRENE combines a
graph neural network for learning agent and world state representations with a
transformer to encode the task context. When evaluated on the challenging Baby
Intuitions Benchmark, IRENE achieves new state-of-the-art performance on three
out of its five tasks - with up to 48.9% improvement. In contrast to existing
methods, IRENE is able to bind preferences to specific agents, to better
distinguish between rational and irrational agents, and to better understand
the role of blocking obstacles. We also investigate, for the first time, the
influence of the training tasks on test performance. Our analyses demonstrate
the effectiveness of IRENE in combining prior knowledge gained during training
for unseen evaluation tasks.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07124" title="Abstract">arXiv:2312.07124</a> [<a href="/pdf/2312.07124" title="Download PDF">pdf</a>, <a href="/format/2312.07124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A robust finite strain isogeometric solid-beam element
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shafqat%2C+A">Abdullah Shafqat</a>, 
<a href="/search/math?searchtype=author&query=Weeger%2C+O">Oliver Weeger</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+B">Bai-Xiang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph)

</div>
<p class="mathjax">In this work, an efficient and robust isogeometric three-dimensional
solid-beam finite element is developed for large deformations and finite
rotations with merely displacements as degrees of freedom. The finite strain
theory and hyperelastic constitutive models are considered and B-Spline and
NURBS are employed for the finite element discretization. Similar to finite
elements based on Lagrange polynomials, also NURBS-based formulations are
affected by the non-physical phenomena of locking, which constrains the field
variables and negatively impacts the solution accuracy and deteriorates
convergence behavior. To avoid this problem within the context of a Solid-Beam
formulation, the Assumed Natural Strain (ANS) method is applied to alleviate
membrane and transversal shear locking and the Enhanced Assumed Strain (EAS)
method against Poisson thickness locking. Furthermore, the Mixed Integration
Point (MIP) method is employed to make the formulation more efficient and
robust. The proposed novel isogeometric solid-beam element is tested on several
single-patch and multi-patch benchmark problems, and it is validated against
classical solid finite elements and isoparametric solid-beam elements. The
results show that the proposed formulation can alleviate the locking effects
and significantly improve the performance of the isogeometric solid-beam
element. With the developed element, efficient and accurate predictions of
mechanical properties of lattice-based structured materials can be achieved.
The proposed solid-beam element inherits both the merits of solid elements e.g.
flexible boundary conditions and of the beam elements i.e. higher computational
efficiency.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07125" title="Abstract">arXiv:2312.07125</a> [<a href="/pdf/2312.07125" title="Download PDF">pdf</a>, <a href="/format/2312.07125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Few-Shot Clinical Task Adaptation with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+K">Kaipeng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Weiran Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Few-shot learning has been studied to adapt models to tasks with very few
samples. It holds profound significance, particularly in clinical tasks, due to
the high annotation cost of medical images. Several works have explored
few-shot learning on medical images, yet they still require a large number of
medical images for pre-training models to gain domain-specific priors. Vision
foundation models recently have achieved remarkable success in natural images.
Hence, adapting rapidly advancing vision foundation models from natural images
to few-shot clinical tasks holds great promise. MedFMC has recently organized a
challenge to shed more light on this topic at NeurIPS 2023. In this work, we
present our challenge solution. We observe that a simple variant of fine-tuning
with partial freezing shows remarkable performance. Empirical evidence
demonstrates that this approach could outperform various common fine-tuning
methods under limited sample sizes. Additionally, we explore enhanced
utilization of semantic supervision to boost performance. We propose a novel
approach that contextualizes labels via large language models (LLMs). Our
findings reveal that the context generated by LLMs significantly enhances the
discrimination of semantic embeddings for similar categories, resulting in a
notable performance improvement of 3%-5% in 1-shot settings compared to
commonly employed one-hot labels and other semantic supervision methods. Our
solution secures the 1st place in the MedFMC challenge.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07130" title="Abstract">arXiv:2312.07130</a> [<a href="/pdf/2312.07130" title="Download PDF">pdf</a>, <a href="/format/2312.07130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Divide-and-Conquer Attack: Harnessing the Power of LLM to Bypass the  Censorship of Text-to-Image Generation Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yimo Deng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huangxun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages,6 figures, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Text-to-image generative models offer many innovative services but also raise
ethical concerns due to their potential to generate unethical images. Most
publicly available text-to-image models employ safety filters to prevent
unintended generation intents. In this work, we introduce the
Divide-and-Conquer Attack to circumvent the safety filters of state-of-the-art
text-to-image models. Our attack leverages LLMs as agents for text
transformation, creating adversarial prompts from sensitive ones. We have
developed effective helper prompts that enable LLMs to break down sensitive
drawing prompts into multiple harmless descriptions, allowing them to bypass
safety filters while still generating sensitive images. This means that the
latent harmful meaning only becomes apparent when all individual elements are
drawn together. Our evaluation demonstrates that our attack successfully
circumvents the closed-box safety filter of SOTA DALLE-3 integrated natively
into ChatGPT to generate unethical images. This approach, which essentially
uses LLM-generated adversarial prompts against GPT-4-assisted DALLE-3, is akin
to using one's own spear to breach their shield. It could have more severe
security implications than previous manual crafting or iterative model querying
methods, and we hope it stimulates more attention towards similar efforts. Our
code and data are available at:
https://github.com/researchcode001/Divide-and-Conquer-Attack
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07132" title="Abstract">arXiv:2312.07132</a> [<a href="/pdf/2312.07132" title="Download PDF">pdf</a>, <a href="/format/2312.07132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Content Generation with Causal Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaochuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+B">Baoyu Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Runze Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Liang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhenhua Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yaqian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rengang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 38th Annual AAAI Conference on Artificial Intelligence (AAAI 2024) in December 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">The emergence of ChatGPT has once again sparked research in generative
artificial intelligence (GAI). While people have been amazed by the generated
results, they have also noticed the reasoning potential reflected in the
generated textual content. However, this current ability for causal reasoning
is primarily limited to the domain of language generation, such as in models
like GPT-3. In visual modality, there is currently no equivalent research.
Considering causal reasoning in visual content generation is significant. This
is because visual information contains infinite granularity. Particularly,
images can provide more intuitive and specific demonstrations for certain
reasoning tasks, especially when compared to coarse-grained text. Hence, we
propose a new image generation task called visual question answering with image
(VQAI) and establish a dataset of the same name based on the classic
\textit{Tom and Jerry} animated series. Additionally, we develop a new paradigm
for image generation to tackle the challenges of this task. Finally, we perform
extensive experiments and analyses, including visualizations of the generated
content and discussions on the potentials and limitations. The code and data
are publicly available under the license of CC BY-NC-SA 4.0 for academic and
non-commercial usage. The code and dataset are publicly available at:
https://github.com/IEIT-AGI/MIX-Shannon/blob/main/projects/VQAI/lgd_vqai.md.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07133" title="Abstract">arXiv:2312.07133</a> [<a href="/pdf/2312.07133" title="Download PDF">pdf</a>, <a href="/format/2312.07133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text2AC-Zero: Consistent Synthesis of Animated Characters using 2D  Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eldesokey%2C+A">Abdelrahman Eldesokey</a>, 
<a href="/search/cs?searchtype=author&query=Wonka%2C+P">Peter Wonka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://abdo-eldesokey.github.io/text2ac-zero/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose a zero-shot approach for consistent Text-to-Animated-Characters
synthesis based on pre-trained Text-to-Image (T2I) diffusion models. Existing
Text-to-Video (T2V) methods are expensive to train and require large-scale
video datasets to produce diverse characters and motions. At the same time,
their zero-shot alternatives fail to produce temporally consistent videos. We
strive to bridge this gap, and we introduce a zero-shot approach that produces
temporally consistent videos of animated characters and requires no training or
fine-tuning. We leverage existing text-based motion diffusion models to
generate diverse motions that we utilize to guide a T2I model. To achieve
temporal consistency, we introduce the Spatial Latent Alignment module that
exploits cross-frame dense correspondences that we compute to align the latents
of the video frames. Furthermore, we propose Pixel-Wise Guidance to steer the
diffusion process in a direction that minimizes visual discrepancies. Our
proposed approach generates temporally consistent videos with diverse motions
and styles, outperforming existing zero-shot T2V approaches in terms of
pixel-wise consistency and user preference.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07136" title="Abstract">arXiv:2312.07136</a> [<a href="/pdf/2312.07136" title="Download PDF">pdf</a>, <a href="/format/2312.07136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust End-to-End Diarization with Domain Adaptive Training and  Multi-Task Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fung%2C+I">Ivan Fung</a>, 
<a href="/search/cs?searchtype=author&query=Samarakoon%2C+L">Lahiru Samarakoon</a>, 
<a href="/search/cs?searchtype=author&query=Broughton%2C+S+J">Samuel J. Broughton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures, ASRU 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Due to the scarcity of publicly available diarization data, the model
performance can be improved by training a single model with data from different
domains. In this work, we propose to incorporate domain information to train a
single end-to-end diarization model for multiple domains. First, we employ
domain adaptive training with parameter-efficient adapters for on-the-fly model
reconfiguration. Second, we introduce an auxiliary domain classification task
to make the diarization model more domain-aware. For seen domains, the
combination of our proposed methods reduces the absolute DER from 17.66% to
16.59% when compared with the baseline. During inference, adapters from
ground-truth domains are not available for unseen domains. We demonstrate our
model exhibits a stronger generalizability to unseen domains when adapters are
removed. For two unseen domains, this improves the DER performance from 39.91%
to 23.09% and 25.32% to 18.76% over the baseline, respectively.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07139" title="Abstract">arXiv:2312.07139</a> [<a href="/pdf/2312.07139" title="Download PDF">pdf</a>, <a href="/format/2312.07139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Practical considerations on using private sampling for synthetic data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pierquin%2C+C">Cl&#xe9;ment Pierquin</a>, 
<a href="/search/cs?searchtype=author&query=Zimmermann%2C+B">Bastien Zimmermann</a>, 
<a href="/search/cs?searchtype=author&query=Boussard%2C+M">Matthieu Boussard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Artificial intelligence and data access are already mainstream. One of the
main challenges when designing an artificial intelligence or disclosing content
from a database is preserving the privacy of individuals who participate in the
process. Differential privacy for synthetic data generation has received much
attention due to the ability of preserving privacy while freely using the
synthetic data. Private sampling is the first noise-free method to construct
differentially private synthetic data with rigorous bounds for privacy and
accuracy. However, this synthetic data generation method comes with constraints
which seem unrealistic and not applicable for real-world datasets. In this
paper, we provide an implementation of the private sampling algorithm and
discuss the realism of its constraints in practical cases.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07140" title="Abstract">arXiv:2312.07140</a> [<a href="/pdf/2312.07140" title="Download PDF">pdf</a>, <a href="/format/2312.07140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Automorphisms of Temporal Graphs for Fast Exploration and  Rendezvous
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dogeas%2C+K">Konstantinos Dogeas</a>, 
<a href="/search/cs?searchtype=author&query=Erlebach%2C+T">Thomas Erlebach</a>, 
<a href="/search/cs?searchtype=author&query=Kammer%2C+F">Frank Kammer</a>, 
<a href="/search/cs?searchtype=author&query=Meintrup%2C+J">Johannes Meintrup</a>, 
<a href="/search/cs?searchtype=author&query=Moses%2C+W+K">William K. Moses Jr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Temporal graphs are dynamic graphs where the edge set can change in each time
step, while the vertex set stays the same. Exploration of temporal graphs whose
snapshot in each time step is a connected graph, called connected temporal
graphs, has been widely studied. In this paper, we extend the concept of graph
automorphisms from static graphs to temporal graphs for the first time and show
that symmetries enable faster exploration: We prove that a connected temporal
graph with $n$ vertices and orbit number $r$ (i.e., $r$~is the number of
automorphism orbits) can be explored in $O(r n^{1+\epsilon})$ time steps, for
any fixed $\epsilon&gt;0$. For $r=O(n^c)$ for constant $c&lt;1$, this is a
significant improvement over the known tight worst-case bound of $\Theta(n^2)$
time steps for arbitrary connected temporal graphs. We also give two lower
bounds for temporal exploration, showing that $\Omega(n \log n)$ time steps are
required for some inputs with $r=O(1)$ and that $\Omega(rn)$ time steps are
required for some inputs for any $r$ with $1\le r\le n$.
<br />Moreover, we show that the techniques we develop for fast exploration can be
used to derive the following result for rendezvous: Two agents with different
programs and without communication ability are placed by an adversary at
arbitrary vertices and given full information about the connected temporal
graph, except that they do not have consistent vertex labels. Then the two
agents can meet at a common vertex after $O(n^{1+\epsilon})$ time steps, for
any constant $\epsilon&gt;0$. For some connected temporal graphs with the orbit
number being a constant, we also present a complementary lower bound of
$\Omega(n\log n)$ time steps.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07141" title="Abstract">arXiv:2312.07141</a> [<a href="/pdf/2312.07141" title="Download PDF">pdf</a>, <a href="/format/2312.07141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilingual large language models leak human stereotypes across  language boundaries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y+T">Yang Trista Cao</a>, 
<a href="/search/cs?searchtype=author&query=Sotnikova%2C+A">Anna Sotnikova</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jieyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+L+X">Linda X. Zou</a>, 
<a href="/search/cs?searchtype=author&query=Rudinger%2C+R">Rachel Rudinger</a>, 
<a href="/search/cs?searchtype=author&query=Daume%2C+H">Hal Daume III</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Multilingual large language models have been increasingly popular for their
proficiency in comprehending and generating text across various languages.
Previous research has shown that the presence of stereotypes and biases in
monolingual large language models can be attributed to the nature of their
training data, which is collected from humans and reflects societal biases.
Multilingual language models undergo the same training procedure as monolingual
ones, albeit with training data sourced from various languages. This raises the
question: do stereotypes present in one social context leak across languages
within the model? In our work, we first define the term ``stereotype leakage''
and propose a framework for its measurement. With this framework, we
investigate how stereotypical associations leak across four languages: English,
Russian, Chinese, and Hindi. To quantify the stereotype leakage, we employ an
approach from social psychology, measuring stereotypes via group-trait
associations. We evaluate human stereotypes and stereotypical associations
manifested in multilingual large language models such as mBERT, mT5, and
ChatGPT. Our findings show a noticeable leakage of positive, negative, and
non-polar associations across all languages. Notably, Hindi within multilingual
models appears to be the most susceptible to influence from other languages,
while Chinese is the least. Additionally, ChatGPT exhibits a better alignment
with human scores than other models.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07142" title="Abstract">arXiv:2312.07142</a> [<a href="/pdf/2312.07142" title="Download PDF">pdf</a>, <a href="/format/2312.07142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> General Tail Bounds for Non-Smooth Stochastic Mirror Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eldowa%2C+K">Khaled Eldowa</a>, 
<a href="/search/cs?searchtype=author&query=Paudice%2C+A">Andrea Paudice</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">In this paper, we provide novel tail bounds on the optimization error of
Stochastic Mirror Descent for convex and Lipschitz objectives. Our analysis
extends the existing tail bounds from the classical light-tailed Sub-Gaussian
noise case to heavier-tailed noise regimes. We study the optimization error of
the last iterate as well as the average of the iterates. We instantiate our
results in two important cases: a class of noise with exponential tails and one
with polynomial tails. A remarkable feature of our results is that they do not
require an upper bound on the diameter of the domain. Finally, we support our
theory with illustrative experiments that compare the behavior of the average
of the iterates with that of the last iterate in heavy-tailed noise regimes.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07144" title="Abstract">arXiv:2312.07144</a> [<a href="/pdf/2312.07144" title="Download PDF">pdf</a>, <a href="/format/2312.07144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Parameterized Complexity of Coordinated Motion Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eiben%2C+E">Eduard Eiben</a>, 
<a href="/search/cs?searchtype=author&query=Ganian%2C+R">Robert Ganian</a>, 
<a href="/search/cs?searchtype=author&query=Kanj%2C+I">Iyad Kanj</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Short version appeared in SoCG 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI); Computational Geometry (cs.CG)

</div>
<p class="mathjax">In Coordinated Motion Planning (CMP), we are given a rectangular-grid on
which $k$ robots occupy $k$ distinct starting gridpoints and need to reach $k$
distinct destination gridpoints. In each time step, any robot may move to a
neighboring gridpoint or stay in its current gridpoint, provided that it does
not collide with other robots. The goal is to compute a schedule for moving the
$k$ robots to their destinations which minimizes a certain objective target -
prominently the number of time steps in the schedule, i.e., the makespan, or
the total length traveled by the robots. We refer to the problem arising from
minimizing the former objective target as CMP-M and the latter as CMP-L. Both
CMP-M and CMP-L are fundamental problems that were posed as the computational
geometry challenge of SoCG 2021, and CMP also embodies the famous
$(n^2-1)$-puzzle as a special case.
<br />In this paper, we settle the parameterized complexity of CMP-M and CMP-L with
respect to their two most fundamental parameters: the number of robots, and the
objective target. We develop a new approach to establish the fixed-parameter
tractability of both problems under the former parameterization that relies on
novel structural insights into optimal solutions to the problem. When
parameterized by the objective target, we show that CMP-L remains
fixed-parameter tractable while CMP-M becomes para-NP-hard. The latter result
is noteworthy, not only because it improves the previously-known boundaries of
intractability for the problem, but also because the underlying reduction
allows us to establish - as a simpler case - the NP-hardness of the classical
Vertex Disjoint and Edge Disjoint Paths problems with constant path-lengths on
grids.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07145" title="Abstract">arXiv:2312.07145</a> [<a href="/pdf/2312.07145" title="Download PDF">pdf</a>, <a href="/format/2312.07145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextual Bandits with Online Neural Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deb%2C+R">Rohan Deb</a>, 
<a href="/search/cs?searchtype=author&query=Ban%2C+Y">Yikun Ban</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+S">Shiliang Zuo</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jingrui He</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+A">Arindam Banerjee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Recent works have shown a reduction from contextual bandits to online
regression under a realizability assumption [Foster and Rakhlin, 2020, Foster
and Krishnamurthy, 2021]. In this work, we investigate the use of neural
networks for such online regression and associated Neural Contextual Bandits
(NeuCBs). Using existing results for wide networks, one can readily show a
${\mathcal{O}}(\sqrt{T})$ regret for online regression with square loss, which
via the reduction implies a ${\mathcal{O}}(\sqrt{K} T^{3/4})$ regret for
NeuCBs. Departing from this standard approach, we first show a
$\mathcal{O}(\log T)$ regret for online regression with almost convex losses
that satisfy QG (Quadratic Growth) condition, a generalization of the PL
(Polyak-\L ojasiewicz) condition, and that have a unique minima. Although not
directly applicable to wide networks since they do not have unique minima, we
show that adding a suitable small random perturbation to the network
predictions surprisingly makes the loss satisfy QG with unique minima. Based on
such a perturbed prediction, we show a ${\mathcal{O}}(\log T)$ regret for
online regression with both squared loss and KL loss, and subsequently convert
these respectively to $\tilde{\mathcal{O}}(\sqrt{KT})$ and
$\tilde{\mathcal{O}}(\sqrt{KL^*} + K)$ regret for NeuCB, where $L^*$ is the
loss of the best policy. Separately, we also show that existing regret bounds
for NeuCBs are $\Omega(T)$ or assume i.i.d. contexts, unlike this work.
Finally, our experimental results on various datasets demonstrate that our
algorithms, especially the one based on KL loss, persistently outperform
existing algorithms.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07146" title="Abstract">arXiv:2312.07146</a> [<a href="/pdf/2312.07146" title="Download PDF">pdf</a>, <a href="/format/2312.07146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CompdVision: Combining Near-Field 3D Visual and Tactile Sensing Using a  Compact Compound-Eye Imaging System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Lifan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Boyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zhijie Peng</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+Y+K">Yik Kin Cheung</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guanlan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhigang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M+Y">Michael Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hongyu Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">As automation technologies advance, the need for compact and multi-modal
sensors in robotic applications is growing. To address this demand, we
introduce CompdVision, a novel sensor that combines near-field 3D visual and
tactile sensing. This sensor, with dimensions of 22$\times$14$\times$14 mm,
leverages the compound eye imaging system to achieve a compact form factor
without compromising its dual modalities. CompdVision utilizes two types of
vision units to meet diverse sensing requirements. Stereo units with far-focus
lenses can see through the transparent elastomer, facilitating depth estimation
beyond the contact surface, while tactile units with near-focus lenses track
the movement of markers embedded in the elastomer to obtain contact
deformation. Experimental results validate the sensor's superior performance in
3D visual and tactile sensing. The sensor demonstrates effective depth
estimation within a 70mm range from its surface. Additionally, it registers
high accuracy in tangential and normal force measurements. The dual modalities
and compact design make the sensor a versatile tool for complex robotic tasks.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07152" title="Abstract">arXiv:2312.07152</a> [<a href="/pdf/2312.07152" title="Download PDF">pdf</a>, <a href="/format/2312.07152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightweight Implementation of Per-packet Service Protection in eBPF/XDP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fejes%2C+F">Ferenc Fejes</a>, 
<a href="/search/cs?searchtype=author&query=Orosi%2C+F">Ferenc Orosi</a>, 
<a href="/search/cs?searchtype=author&query=Varga%2C+B">Bal&#xe1;zs Varga</a>, 
<a href="/search/cs?searchtype=author&query=Farkas%2C+J">J&#xe1;nos Farkas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper submission for the talk with same title on netdev 0x17 conference: <a href="https://netdevconf.info/0x17/sessions/talk/lightweight-implementation-of-per-packet-service-protection-in-ebpfxdp.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Deterministic communication means reliable packet forwarding with close to
zero packet loss and bounded latency. Packet loss or delay above a threshold
caused by, e.g., equipment failure or malfunction could be catastrophic for
applications that require deterministic communication. To meet loss related
targets, per-packet service protection has been introduced by deterministic
communications standards; it is provided by Frame Replication and Elimination
for Reliability (FRER) for Layer 2 Ethernet networks and by Packet Replication,
Elimination, and Ordering Functions (PREOF) for Layer 3 IP/MPLS networks.
<br />We have implemented FRER with two conceptually different methods: (1) in
eBPF/XDP as a lightweight software implementation; and (2) in userspace. We
evaluate our XDP FRER via an experimental analysis and compare the two FRER
implementations.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07157" title="Abstract">arXiv:2312.07157</a> [<a href="/pdf/2312.07157" title="Download PDF">pdf</a>, <a href="/ps/2312.07157" title="Download PostScript">ps</a>, <a href="/format/2312.07157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stop Following Me! Evaluating the Effectiveness of Anti-Stalking  Features of Personal Item Tracking Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Turk%2C+K+I">Kieron Ivy Turk</a>, 
<a href="/search/cs?searchtype=author&query=Hutchings%2C+A">Alice Hutchings</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Personal item tracking devices are popular for locating lost items such as
keys, wallets, and suitcases. Originally created to help users find personal
items quickly, these devices are now being abused by stalkers and domestic
abusers to track their victims' location over time. Some device manufacturers
created `anti-stalking features' in response, and later improved on them after
criticism that they were insufficient. We analyse the effectiveness of the
anti-stalking features with five brands of tracking devices through a gamified
naturalistic quasi-experiment in collaboration with the Assassins' Guild
student society. Despite participants knowing they might be tracked, and being
incentivised to detect and remove the tracker, the anti-stalking features were
not useful and were rarely used. We also identify additional issues with
feature availability, usability, and effectiveness. These failures combined
imply a need to greatly improve the presence of anti-stalking features to
prevent trackers being abused.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07158" title="Abstract">arXiv:2312.07158</a> [<a href="/pdf/2312.07158" title="Download PDF">pdf</a>, <a href="/format/2312.07158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cost Aware Untargeted Poisoning Attack against Graph Neural Networks,
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yuwei Han</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">Yuni Lai</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yulin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kai Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Graph Neural Networks (GNNs) have become widely used in the field of graph
mining. However, these networks are vulnerable to structural perturbations.
While many research efforts have focused on analyzing vulnerability through
poisoning attacks, we have identified an inefficiency in current attack losses.
These losses steer the attack strategy towards modifying edges targeting
misclassified nodes or resilient nodes, resulting in a waste of structural
adversarial perturbation. To address this issue, we propose a novel attack loss
framework called the Cost Aware Poisoning Attack (CA-attack) to improve the
allocation of the attack budget by dynamically considering the classification
margins of nodes. Specifically, it prioritizes nodes with smaller positive
margins while postponing nodes with negative margins. Our experiments
demonstrate that the proposed CA-attack significantly enhances existing attack
strategies
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07159" title="Abstract">arXiv:2312.07159</a> [<a href="/pdf/2312.07159" title="Download PDF">pdf</a>, <a href="/ps/2312.07159" title="Download PostScript">ps</a>, <a href="/format/2312.07159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rate-Splitting Multiple Access for Semantic-Aware Networks: an Age of  Incorrect Information Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dizdar%2C+O">Onur Dizdar</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Stephen Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this letter, we design a downlink multi-user communication framework based
on Rate-Splitting Multiple Access (RSMA) for semantic-aware networks. First, we
formulate an optimization problem to obtain the optimal user scheduling,
precoding, and power allocation schemes jointly. We consider the metric Age of
Incorrect Information (AoII) in the objective function of the formulated
problem to maximize the freshness of the overall information to be transmitted.
Using big-M and Successive Convex Approximation (SCA) methods, we convert the
resulting non-convex problem with conditional objective and constraints into a
convex one and propose an iterative algorithm to solve it. By numerical
results, we show that RSMA achieves a lower AoII than SDMA owing to its
superior performance under multi-user interference.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07160" title="Abstract">arXiv:2312.07160</a> [<a href="/pdf/2312.07160" title="Download PDF">pdf</a>, <a href="/format/2312.07160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audience Prospecting for Dynamic-Product-Ads in Native Advertising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abutbul%2C+E">Eliran Abutbul</a>, 
<a href="/search/cs?searchtype=author&query=Kaplan%2C+Y">Yohay Kaplan</a>, 
<a href="/search/cs?searchtype=author&query=Krasne%2C+N">Naama Krasne</a>, 
<a href="/search/cs?searchtype=author&query=David%2C+O+S+O">Oren Somekh Or David</a>, 
<a href="/search/cs?searchtype=author&query=Duvdevany%2C+O">Omer Duvdevany</a>, 
<a href="/search/cs?searchtype=author&query=Segal%2C+E">Evgeny Segal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proc. IeeeBigData'2023 (Industry and Government Program)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">With yearly revenue exceeding one billion USD, Yahoo Gemini native
advertising marketplace serves more than two billion impressions daily to
hundreds of millions of unique users. One of the fastest growing segments of
Gemini native is dynamic-product-ads (DPA), where major advertisers, such as
Amazon and Walmart, provide catalogs with millions of products for the system
to choose from and present to users. The subject of this work is finding and
expanding the right audience for each DPA ad, which is one of the many
challenges DPA presents. Approaches such as targeting various user groups,
e.g., users who already visited the advertisers' websites (Retargeting), users
that searched for certain products (Search-Prospecting), or users that reside
in preferred locations (Location-Prospecting), have limited audience expansion
capabilities. In this work we present two new approaches for audience expansion
that also maintain predefined performance goals. The Conversion-Prospecting
approach predicts DPA conversion rates based on Gemini native logged data, and
calculates the expected cost-per-action (CPA) for determining users'
eligibility to products and optimizing DPA bids in Gemini native auctions. To
support new advertisers and products, the Trending-Prospecting approach matches
trending products to users by learning their tendency towards products from
advertisers' sites logged events. The tendency scores indicate the popularity
of the product and the similarity of the user to those who have previously
engaged with this product. The two new prospecting approaches were tested
online, serving real Gemini native traffic, demonstrating impressive DPA
delivery and DPA revenue lifts while maintaining most traffic within the
acceptable CPA range (i.e., performance goal). After a successful testing
phase, the proposed approaches are currently in production and serve all Gemini
native traffic.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07165" title="Abstract">arXiv:2312.07165</a> [<a href="/pdf/2312.07165" title="Download PDF">pdf</a>, <a href="/format/2312.07165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language-Guided Transformer for Federated Multi-Label Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+I">I-Jieh Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Ci-Siang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fu-En Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y+F">Yu-Chiang Frank Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated Learning (FL) is an emerging paradigm that enables multiple users
to collaboratively train a robust model in a privacy-preserving manner without
sharing their private data. Most existing approaches of FL only consider
traditional single-label image classification, ignoring the impact when
transferring the task to multi-label image classification. Nevertheless, it is
still challenging for FL to deal with user heterogeneity in their local data
distribution in the real-world FL scenario, and this issue becomes even more
severe in multi-label image classification. Inspired by the recent success of
Transformers in centralized settings, we propose a novel FL framework for
multi-label classification. Since partial label correlation may be observed by
local clients during training, direct aggregation of locally updated models
would not produce satisfactory performances. Thus, we propose a novel FL
framework of Language-Guided Transformer (FedLGT) to tackle this challenging
task, which aims to exploit and transfer knowledge across different clients for
learning a robust global model. Through extensive experiments on various
multi-label datasets (e.g., FLAIR, MS-COCO, etc.), we show that our FedLGT is
able to achieve satisfactory performance and outperforms standard FL techniques
under multi-label FL scenarios. Code is available at
https://github.com/Jack24658735/FedLGT.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07168" title="Abstract">arXiv:2312.07168</a> [<a href="/pdf/2312.07168" title="Download PDF">pdf</a>, <a href="/format/2312.07168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equivariant Flow Matching with Hybrid Probability Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yuxuan Song</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+J">Jingjing Gong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Minkai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Ziyao Cao</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yanyan Lan</a>, 
<a href="/search/cs?searchtype=author&query=Ermon%2C+S">Stefano Ermon</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wei-Ying Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The generation of 3D molecules requires simultaneously deciding the
categorical features~(atom types) and continuous features~(atom coordinates).
Deep generative models, especially Diffusion Models (DMs), have demonstrated
effectiveness in generating feature-rich geometries. However, existing DMs
typically suffer from unstable probability dynamics with inefficient sampling
speed. In this paper, we introduce geometric flow matching, which enjoys the
advantages of both equivariant modeling and stabilized probability dynamics.
More specifically, we propose a hybrid probability path where the coordinates
probability path is regularized by an equivariant optimal transport, and the
information between different modalities is aligned. Experimentally, the
proposed method could consistently achieve better performance on multiple
molecule generation benchmarks with 4.75$\times$ speed up of sampling on
average.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07169" title="Abstract">arXiv:2312.07169</a> [<a href="/pdf/2312.07169" title="Download PDF">pdf</a>, <a href="/format/2312.07169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-supervised Active Learning for Video Action Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Aayush Singh</a>, 
<a href="/search/cs?searchtype=author&query=Rana%2C+A+J">Aayush J Rana</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Akash Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Vyas%2C+S">Shruti Vyas</a>, 
<a href="/search/cs?searchtype=author&query=Rawat%2C+Y+S">Yogesh Singh Rawat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI'24 Main Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this work, we focus on label efficient learning for video action
detection. We develop a novel semi-supervised active learning approach which
utilizes both labeled as well as unlabeled data along with informative sample
selection for action detection. Video action detection requires spatio-temporal
localization along with classification, which poses several challenges for both
active learning informative sample selection as well as semi-supervised
learning pseudo label generation. First, we propose NoiseAug, a simple
augmentation strategy which effectively selects informative samples for video
action detection. Next, we propose fft-attention, a novel technique based on
high-pass filtering which enables effective utilization of pseudo label for SSL
in video action detection by emphasizing on relevant activity region within a
video. We evaluate the proposed approach on three different benchmark datasets,
UCF-101-24, JHMDB-21, and Youtube-VOS. First, we demonstrate its effectiveness
on video action detection where the proposed approach outperforms prior works
in semi-supervised and weakly-supervised learning along with several baseline
approaches in both UCF101-24 and JHMDB-21. Next, we also show its effectiveness
on Youtube-VOS for video object segmentation demonstrating its generalization
capability for other dense prediction tasks in videos.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07170" title="Abstract">arXiv:2312.07170</a> [<a href="/pdf/2312.07170" title="Download PDF">pdf</a>, <a href="/format/2312.07170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Very high order treatment of embedded curved boundaries in compressible  flows: ADER discontinuous Galerkin with a space-time Reconstruction for  Off-site data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ciallella%2C+M">Mirco Ciallella</a>, 
<a href="/search/math?searchtype=author&query=Clain%2C+S">Stephane Clain</a>, 
<a href="/search/math?searchtype=author&query=Gaburro%2C+E">Elena Gaburro</a>, 
<a href="/search/math?searchtype=author&query=Ricchiuto%2C+M">Mario Ricchiuto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper we present a novel approach for the design of high order
general boundary conditions when approximating solutions of the Euler equations
on domains with curved boundaries, using meshes which may not be boundary
conformal. When dealing with curved boundaries and/or unfitted discretizations,
the consistency of boundary conditions is a well-known challenge, especially in
the context of high order schemes. In order to tackle such consistency
problems, the so-called Reconstruction for Off-site Data (ROD) method has been
recently introduced in the finite volume framework: it is based on performing a
boundary polynomial reconstruction that embeds the considered boundary
treatment thanks to the implementation of a constrained minimization problem.
This work is devoted to the development of the ROD approach in the context of
discontinuous finite elements. We use the genuine space-time nature of the
local ADER predictors to reformulate the ROD as a single space-time
reconstruction procedure. This allows us to avoid a new reconstruction (linear
system inversion) at each sub-time node and retrieve a single space-time
polynomial that embeds the considered boundary conditions for the entire
space-time element. Several numerical experiments are presented proving the
consistency of the new approach for all kinds of boundary conditions.
Computations involving the interaction of shocks with embedded curved
boundaries are made possible through an a posteriori limiting technique.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07174" title="Abstract">arXiv:2312.07174</a> [<a href="/pdf/2312.07174" title="Download PDF">pdf</a>, <a href="/format/2312.07174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigation into the Training Dynamics of Learned Optimizers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sobotka%2C+J">Jan Sobotka</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0im%C3%A1nek%2C+P">Petr &#x160;im&#xe1;nek</a>, 
<a href="/search/cs?searchtype=author&query=Va%C5%A1ata%2C+D">Daniel Va&#x161;ata</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Optimization is an integral part of modern deep learning. Recently, the
concept of learned optimizers has emerged as a way to accelerate this
optimization process by replacing traditional, hand-crafted algorithms with
meta-learned functions. Despite the initial promising results of these methods,
issues with stability and generalization still remain, limiting their practical
use. Moreover, their inner workings and behavior under different conditions are
not yet fully understood, making it difficult to come up with improvements. For
this reason, our work examines their optimization trajectories from the
perspective of network architecture symmetries and parameter update
distributions. Furthermore, by contrasting the learned optimizers with their
manually designed counterparts, we identify several key insights that
demonstrate how each approach can benefit from the strengths of the other.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07175" title="Abstract">arXiv:2312.07175</a> [<a href="/pdf/2312.07175" title="Download PDF">pdf</a>, <a href="/format/2312.07175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instrumental Variable Estimation for Causal Inference in Longitudinal  Data with Time-Dependent Latent Confounders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+D">Debo Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Ziqi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiuyong Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jixue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Wentao Gao</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T+D">Thuc Duy Le</a> (UniSA STEM, University of South Australia, Adelaide, SA, Australia)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures and 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
<p class="mathjax">Causal inference from longitudinal observational data is a challenging
problem due to the difficulty in correctly identifying the time-dependent
confounders, especially in the presence of latent time-dependent confounders.
Instrumental variable (IV) is a powerful tool for addressing the latent
confounders issue, but the traditional IV technique cannot deal with latent
time-dependent confounders in longitudinal studies. In this work, we propose a
novel Time-dependent Instrumental Factor Model (TIFM) for time-varying causal
effect estimation from data with latent time-dependent confounders. At each
time-step, the proposed TIFM method employs the Recurrent Neural Network (RNN)
architecture to infer latent IV, and then uses the inferred latent IV factor
for addressing the confounding bias caused by the latent time-dependent
confounders. We provide a theoretical analysis for the proposed TIFM method
regarding causal effect estimation in longitudinal data. Extensive evaluation
with synthetic datasets demonstrates the effectiveness of TIFM in addressing
causal effect estimation over time. We further apply TIFM to a climate dataset
to showcase the potential of the proposed method in tackling real-world
problems.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07178" title="Abstract">arXiv:2312.07178</a> [<a href="/pdf/2312.07178" title="Download PDF">pdf</a>, <a href="/format/2312.07178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Expected Return: Accounting for Policy Reproducibility when  Evaluating Reinforcement Learning Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Flageat%2C+M">Manon Flageat</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+B">Bryan Lim</a>, 
<a href="/search/cs?searchtype=author&query=Cully%2C+A">Antoine Cully</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Many applications in Reinforcement Learning (RL) usually have noise or
stochasticity present in the environment. Beyond their impact on learning,
these uncertainties lead the exact same policy to perform differently, i.e.
yield different return, from one roll-out to another. Common evaluation
procedures in RL summarise the consequent return distributions using solely the
expected return, which does not account for the spread of the distribution. Our
work defines this spread as the policy reproducibility: the ability of a policy
to obtain similar performance when rolled out many times, a crucial property in
some real-world applications. We highlight that existing procedures that only
use the expected return are limited on two fronts: first an infinite number of
return distributions with a wide range of performance-reproducibility
trade-offs can have the same expected return, limiting its effectiveness when
used for comparing policies; second, the expected return metric does not leave
any room for practitioners to choose the best trade-off value for considered
applications. In this work, we address these limitations by recommending the
use of Lower Confidence Bound, a metric taken from Bayesian optimisation that
provides the user with a preference parameter to choose a desired
performance-reproducibility trade-off. We also formalise and quantify policy
reproducibility, and demonstrate the benefit of our metrics using extensive
experiments of popular RL algorithms on common uncertain RL tasks.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07180" title="Abstract">arXiv:2312.07180</a> [<a href="/pdf/2312.07180" title="Download PDF">pdf</a>, <a href="/format/2312.07180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-Aware Iteration Policy Network for Efficient Optical Flow  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+R">Ri Cheng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ruian He</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xuhao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shili Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+W">Weimin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Bo Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2024, Association for the Advancement of Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing recurrent optical flow estimation networks are computationally
expensive since they use a fixed large number of iterations to update the flow
field for each sample. An efficient network should skip iterations when the
flow improvement is limited. In this paper, we develop a Context-Aware
Iteration Policy Network for efficient optical flow estimation, which
determines the optimal number of iterations per sample. The policy network
achieves this by learning contextual information to realize whether flow
improvement is bottlenecked or minimal. On the one hand, we use iteration
embedding and historical hidden cell, which include previous iterations
information, to convey how flow has changed from previous iterations. On the
other hand, we use the incremental loss to make the policy network implicitly
perceive the magnitude of optical flow improvement in the subsequent iteration.
Furthermore, the computational complexity in our dynamic network is
controllable, allowing us to satisfy various resource preferences with a single
trained model. Our policy network can be easily integrated into
state-of-the-art optical flow networks. Extensive experiments show that our
method maintains performance while reducing FLOPs by about 40%/20% for the
Sintel/KITTI datasets.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07182" title="Abstract">arXiv:2312.07182</a> [<a href="/pdf/2312.07182" title="Download PDF">pdf</a>, <a href="/format/2312.07182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classifying complex documents: comparing bespoke solutions to large  language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hopkins%2C+G">Glen Hopkins</a>, 
<a href="/search/cs?searchtype=author&query=Kalm%2C+K">Kristjan Kalm</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Here we search for the best automated classification approach for a set of
complex legal documents. Our classification task is not trivial: our aim is to
classify ca 30,000 public courthouse records from 12 states and 267 counties at
two different levels using nine sub-categories. Specifically, we investigated
whether a fine-tuned large language model (LLM) can achieve the accuracy of a
bespoke custom-trained model, and what is the amount of fine-tuning necessary.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07183" title="Abstract">arXiv:2312.07183</a> [<a href="/pdf/2312.07183" title="Download PDF">pdf</a>, <a href="/ps/2312.07183" title="Download PostScript">ps</a>, <a href="/format/2312.07183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear complementary pairs of skew constacyclic codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lobillo%2C+F+J">F. J. Lobillo</a>, 
<a href="/search/cs?searchtype=author&query=Mu%C3%B1oz%2C+J+M">Jos&#xe9; Manuel Mu&#xf1;oz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 0 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Rings and Algebras (math.RA)

</div>
<p class="mathjax">Linear complementary pairs (LCPs) of codes have been studied since they were
introduced in the context of discussing mitigation measures against possible
hardware attacks to integrated circuits. Since the security parameters for LCPs
of codes are defined from the (Hamming) distance and the dual distance of the
codes in the pair, and the additional algebraic structure of skew constacyclic
codes provides tools for studying the the dual and the distance of a code, we
study the properties of LCPs of skew constacyclic codes. As a result, we give a
characterization for those pairs, as well as multiple results that lead to
constructing pairs with designed security parameters. We extend skew BCH codes
to a constacyclic context and show that an LCP of codes can be immediately
constructed from a skew BCH constacyclic code. Additionally, we describe a
Hamming weight-preserving automorphism group in the set of skew constacyclic
codes, which can be used for constructing LCPs of codes.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07190" title="Abstract">arXiv:2312.07190</a> [<a href="/pdf/2312.07190" title="Download PDF">pdf</a>, <a href="/format/2312.07190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noised Autoencoders for Point Annotation Restoration in Object Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+Y">Yuda Zou</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xin Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Peilin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+B">Bo Du</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yongchao Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Object counting is a field of growing importance in domains such as security
surveillance, urban planning, and biology. The annotation is usually provided
in terms of 2D points. However, the complexity of object shapes and subjective
of annotators may lead to annotation inconsistency, potentially confusing the
model during training. To alleviate this issue, we introduce the Noised
Autoencoders (NAE) methodology, which extracts general positional knowledge
from all annotations. The method involves adding random offsets to initial
point annotations, followed by a UNet to restore them to their original
positions. Similar to MAE, NAE faces challenges in restoring non-generic
points, necessitating reliance on the most common positions inferred from
general knowledge. This reliance forms the cornerstone of our method's
effectiveness. Different from existing noise-resistance methods, our approach
focus on directly improving initial point annotations. Extensive experiments
show that NAE yields more consistent annotations compared to the original ones,
steadily enhancing the performance of advanced models trained with these
revised annotations. \textbf{Remarkably, the proposed approach helps to set new
records in nine datasets}. We will make the NAE codes and refined point
annotations available.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07192" title="Abstract">arXiv:2312.07192</a> [<a href="/pdf/2312.07192" title="Download PDF">pdf</a>, <a href="/format/2312.07192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> waveSLAM: Empowering Accurate Indoor Mapping Using Off-the-Shelf  Millimeter-wave Self-sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Picazo%2C+P">Pablo Picazo</a>, 
<a href="/search/cs?searchtype=author&query=Groshev%2C+M">Milan Groshev</a>, 
<a href="/search/cs?searchtype=author&query=Blanco%2C+A">Alejandro Blanco</a>, 
<a href="/search/cs?searchtype=author&query=Fiandrino%2C+C">Claudio Fiandrino</a>, 
<a href="/search/cs?searchtype=author&query=de+la+Oliva%2C+A">Antonio de la Oliva</a>, 
<a href="/search/cs?searchtype=author&query=Widmer%2C+J">Joerg Widmer</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> VTC FALL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This paper presents the design, implementation and evaluation of waveSLAM, a
low-cost mobile robot system that uses the millimetre wave (mmWave)
communication devices to enhance the indoor mapping process targeting
environments with reduced visibility or glass/mirror walls. A unique feature of
waveSLAM is that it only leverages existing Commercial-Off-The-Shelf (COTS)
hardware (Lidar and mmWave radios) that are mounted on mobile robots to improve
the accurate indoor mapping achieved with optical sensors. The key intuition
behind the waveSLAM design is that while the mobile robots moves freely, the
mmWave radios can periodically exchange angle and distance estimates between
themselves (self-sensing) by bouncing the signal from the environment, thus
enabling accurate estimates of the target object/material surface. Our
experiments verify that waveSLAM can archive cm-level accuracy with errors
below 22 cm and 20deg in angle orientation which is compatible with Lidar when
building indoor maps.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07193" title="Abstract">arXiv:2312.07193</a> [<a href="/pdf/2312.07193" title="Download PDF">pdf</a>, <a href="/ps/2312.07193" title="Download PostScript">ps</a>, <a href="/format/2312.07193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $(&#x3c3;,&#x3b4;)$-polycyclic codes in Ore extensions over rings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bajalan%2C+M">Maryam Bajalan</a>, 
<a href="/search/cs?searchtype=author&query=Landjev%2C+I">Ivan Landjev</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez-Moro%2C+E">Edgar Mart&#xed;nez-Moro</a>, 
<a href="/search/cs?searchtype=author&query=Szabo%2C+S">Steve Szabo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, no figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we study the algebraic structure of
$(\sigma,\delta)$-polycyclic codes as submodules in the quotient module $S/Sf$,
where $S=R[x,\sigma,\delta]$ is the Ore extension, $f\in S$, and $R$ is a
finite but not necessarily commutative ring. We establish that the Euclidean
duals of $(\sigma,\delta)$-polycyclic codes are $(\sigma,\delta)$-sequential
codes. By using $(\sigma,\delta)$-Pseudo Linear Transformation (PLT), we define
the annihilator dual of $(\sigma,\delta)$-polycyclic codes. Then, we
demonstrate that the annihilator duals of $(\sigma,\delta)$-polycyclic codes
maintain their $(\sigma,\delta)$-polycyclic nature. Furthermore, we classify
when two $(\sigma,\delta)$-polycyclic codes are Hamming isometrical equivalent.
By employing Wedderburn polynomials, we introduce simple-root
$(\sigma,\delta)$-polycyclic codes. Subsequently, we define the $(\sigma,
\delta)$-Mattson-Solomon transform for this class of codes and we address the
problem of decomposing these codes by using the properties of Wedderburn
polynomials.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07194" title="Abstract">arXiv:2312.07194</a> [<a href="/pdf/2312.07194" title="Download PDF">pdf</a>, <a href="/ps/2312.07194" title="Download PostScript">ps</a>, <a href="/format/2312.07194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verbreitungsmechanismen sch&#xe4;digender Sprache im Netz: Anatomie zweier  Shitstorms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scheffler%2C+T">Tatjana Scheffler</a>, 
<a href="/search/cs?searchtype=author&query=Solopova%2C+V">Veronika Solopova</a>, 
<a href="/search/cs?searchtype=author&query=Popa-Wyatt%2C+M">Mihaela Popa-Wyatt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in German language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this working paper, we turn our attention to two exemplary, cross-media
shitstorms directed against well-known individuals from the business world.
Both have in common, first, the trigger, a controversial statement by the
person who thereby becomes the target of the shitstorm, and second, the
identity of this target as relatively privileged: cis-male, white, successful.
We examine the spread of the outrage wave across two media at a time and test
the applicability of computational linguistic methods for analyzing its time
course. Assuming that harmful language spreads like a virus in digital space,
we are primarily interested in the events and constellations that lead to the
use of harmful language, and whether and how a linguistic formation of "tribes"
occurs. Our research therefore focuses, first, on the distribution of
linguistic features within the overall shitstorm: are individual words or
phrases increasingly used after their introduction, and through which pathways
they spread. Second, we ask whether "tribes," for example, one group of
supporters and one of opponents of the target, have a distinguished linguistic
form. Our hypothesis is that supporters remain equally active over time, while
the dynamic "ripple" effect of the shitstorm is based on the varying
participation of opponents.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07195" title="Abstract">arXiv:2312.07195</a> [<a href="/pdf/2312.07195" title="Download PDF">pdf</a>, <a href="/ps/2312.07195" title="Download PostScript">ps</a>, <a href="/format/2312.07195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nearly Equitable Allocations Beyond Additivity and Monotonicity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barman%2C+S">Siddharth Barman</a>, 
<a href="/search/cs?searchtype=author&query=Bhaskar%2C+U">Umang Bhaskar</a>, 
<a href="/search/cs?searchtype=author&query=Pandit%2C+Y">Yeshwant Pandit</a>, 
<a href="/search/cs?searchtype=author&query=Pyne%2C+S">Soumyajit Pyne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Equitability (EQ) in fair division requires that items be allocated such that
all agents value the bundle they receive equally. With indivisible items, an
equitable allocation may not exist, and hence we instead consider a meaningful
analog, EQx, that requires equitability up to any item. EQx allocations exist
for monotone, additive valuations. However, if (1) the agents' valuations are
not additive or (2) the set of indivisible items includes both goods and chores
(positively and negatively valued items), then prior to the current work it was
not known whether EQx allocations exist or not.
<br />We study both the existence and efficient computation of EQx allocations. (1)
For monotone valuations (not necessarily additive), we show that EQx
allocations always exist. Also, for the large class of weakly well-layered
valuations, EQx allocations can be found in polynomial time. Further, we prove
that approximately EQx allocations can be computed efficiently under general
monotone valuations. (2) For non-monotone valuations, we show that an EQx
allocation may not exist, even for two agents with additive valuations. Under
some special cases, however, we establish existence and efficient computability
of EQx allocations. This includes the case of two agents with additive
valuations where each item is either a good or a chore, and there are no mixed
items. In addition, we show that, under nonmonotone valuations, determining the
existence of EQx allocations is weakly NP-hard for two agents and strongly
NP-hard for more agents.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07199" title="Abstract">arXiv:2312.07199</a> [<a href="/pdf/2312.07199" title="Download PDF">pdf</a>, <a href="/format/2312.07199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeasFire as a Multivariate Earth System Datacube for Wildfire Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karasante%2C+I">Ilektra Karasante</a>, 
<a href="/search/cs?searchtype=author&query=Alonso%2C+L">Lazaro Alonso</a>, 
<a href="/search/cs?searchtype=author&query=Prapas%2C+I">Ioannis Prapas</a>, 
<a href="/search/cs?searchtype=author&query=Ahuja%2C+A">Akanksha Ahuja</a>, 
<a href="/search/cs?searchtype=author&query=Carvalhais%2C+N">Nuno Carvalhais</a>, 
<a href="/search/cs?searchtype=author&query=Papoutsis%2C+I">Ioannis Papoutsis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 9 figures, and 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The global occurrence, scale, and frequency of wildfires pose significant
threats to ecosystem services and human livelihoods. To effectively quantify
and attribute the antecedent conditions for wildfires, a thorough understanding
of Earth system dynamics is imperative. In response, we introduce the SeasFire
datacube, a meticulously curated spatiotemporal dataset tailored for global
sub-seasonal to seasonal wildfire modeling via Earth observation. The SeasFire
datacube comprises of 59 variables encompassing climate, vegetation, oceanic
indices, and human factors, has an 8-day temporal resolution and a spatial
resolution of 0.25 degrees, and spans from 2001 to 2021. We showcase the
versatility of SeasFire for exploring the variability and seasonality of
wildfire drivers, modeling causal links between ocean-climate teleconnections
and wildfires, and predicting sub-seasonal wildfire patterns across multiple
timescales with a Deep Learning model. We publicly release the SeasFire
datacube and appeal to Earth system scientists and Machine Learning
practitioners to use it for an improved understanding and anticipation of
wildfires.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07200" title="Abstract">arXiv:2312.07200</a> [<a href="/pdf/2312.07200" title="Download PDF">pdf</a>, <a href="/format/2312.07200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Code Membership Inference for Detecting Unauthorized Data Use in Code  Pre-trained Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hui Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Code pre-trained language models (CPLMs) have received great attention since
they can benefit various tasks that facilitate software development and
maintenance. However, CPLMs are trained on massive open-source code, raising
concerns about potential data infringement. This paper launches the first study
of detecting unauthorized code use in CPLMs, i.e., Code Membership Inference
(CMI) task. We design a framework Buzzer for different settings of CMI. Buzzer
deploys several inference techniques, including distilling the target CPLM,
ensemble inference, and unimodal and bimodal calibration. Extensive experiments
show that CMI can be achieved with high accuracy using Buzzer. Hence, Buzzer
can serve as a CMI tool and help protect intellectual property rights.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07205" title="Abstract">arXiv:2312.07205</a> [<a href="/pdf/2312.07205" title="Download PDF">pdf</a>, <a href="/format/2312.07205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Construction and application of an algebraic dual basis and the  Fine-Scale Greens&#x27; Function for computing projections and reconstructing  unresolved scales
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shrestha%2C+S">Suyash Shrestha</a>, 
<a href="/search/math?searchtype=author&query=Dekker%2C+J">Joey Dekker</a>, 
<a href="/search/math?searchtype=author&query=Gerritsma%2C+M">Marc Gerritsma</a>, 
<a href="/search/math?searchtype=author&query=Hulshoff%2C+S">Steven Hulshoff</a>, 
<a href="/search/math?searchtype=author&query=Akkerman%2C+I">Ido Akkerman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph)

</div>
<p class="mathjax">In this paper, we build on the work of [T. Hughes, G. Sangalli, VARIATIONAL
MULTISCALE ANALYSIS: THE FINE-SCALE GREENS' FUNCTION, PROJECTION, OPTIMIZATION,
LOCALIZATION, AND STABILIZED METHODS, SIAM Journal of Numerical Analysis,
45(2), 2007] dealing with the explicit computation of the Fine-Scale Green's
function. The original approach chooses a set of functionals associated with a
projector to compute the Fine-Scale Green's function. The construction of these
functionals, however, does not generalise to arbitrary projections, higher
dimensions, or Spectral Element methods.
<br />We propose to generalise the construction of the required functionals by
using dual functions. These dual functions can be directly derived from the
chosen projector and are explicitly computable. We show how to find the dual
functions for both the $L^2$ and the $H^1_0$ projections. We then go on to
demonstrate that the Fine-Scale Green's functions constructed with the dual
basis functions consistently reproduce the unresolved scales removed by the
projector.
<br />The methodology is tested using one-dimensional Poisson and
advection-diffusion problems, as well as a two-dimensional Poisson problem. We
present the computed components of the Fine-Scale Green's function, and the
Fine-Scale Green's function itself. These results show that the method works
for arbitrary projections, in arbitrary dimensions. Moreover, the methodology
can be applied to any Finite/Spectral Element or Isogeometric framework.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07206" title="Abstract">arXiv:2312.07206</a> [<a href="/pdf/2312.07206" title="Download PDF">pdf</a>, <a href="/format/2312.07206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A churn prediction dataset from the telecom sector: a new benchmark for  uplift modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verhelst%2C+T">Th&#xe9;o Verhelst</a>, 
<a href="/search/cs?searchtype=author&query=Mercier%2C+D">Denis Mercier</a>, 
<a href="/search/cs?searchtype=author&query=Shrestha%2C+J">Jeevan Shrestha</a>, 
<a href="/search/cs?searchtype=author&query=Bontempi%2C+G">Gianluca Bontempi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures, 5 tables, post-proceedings of the ECML PKDD 2023 Workshop on Uplift Modeling and Causal Machine Learning for Operational Decision Making
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Uplift modeling, also known as individual treatment effect (ITE) estimation,
is an important approach for data-driven decision making that aims to identify
the causal impact of an intervention on individuals. This paper introduces a
new benchmark dataset for uplift modeling focused on churn prediction, coming
from a telecom company in Belgium, Orange Belgium. Churn, in this context,
refers to customers terminating their subscription to the telecom service. This
is the first publicly available dataset offering the possibility to evaluate
the efficiency of uplift modeling on the churn prediction problem. Moreover,
its unique characteristics make it more challenging than the few other public
uplift datasets.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07207" title="Abstract">arXiv:2312.07207</a> [<a href="/pdf/2312.07207" title="Download PDF">pdf</a>, <a href="/ps/2312.07207" title="Download PostScript">ps</a>, <a href="/format/2312.07207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MCFNet: Multi-scale Covariance Feature Fusion Network for Real-time  Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+X">Xiaojie Fang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xingguo Song</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+X">Xiangyin Meng</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+X">Xu Fang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Sheng Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">The low-level spatial detail information and high-level semantic abstract
information are both essential to the semantic segmentation task. The features
extracted by the deep network can obtain rich semantic information, while a lot
of spatial information is lost. However, how to recover spatial detail
information effectively and fuse it with high-level semantics has not been well
addressed so far. In this paper, we propose a new architecture based on
Bilateral Segmentation Network (BiseNet) called Multi-scale Covariance Feature
Fusion Network (MCFNet). Specifically, this network introduces a new feature
refinement module and a new feature fusion module. Furthermore, a gating unit
named L-Gate is proposed to filter out invalid information and fuse multi-scale
features. We evaluate our proposed model on Cityscapes, CamVid datasets and
compare it with the state-of-the-art methods. Extensive experiments show that
our method achieves competitive success. On Cityscapes, we achieve 75.5% mIOU
with a speed of 151.3 FPS.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07208" title="Abstract">arXiv:2312.07208</a> [<a href="/pdf/2312.07208" title="Download PDF">pdf</a>, <a href="/format/2312.07208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimental Investigation of Machine Learning based Soft-Failure  Management using the Optical Spectrum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kruse%2C+L+E">Lars E. Kruse</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BChl%2C+S">Sebastian K&#xfc;hl</a>, 
<a href="/search/cs?searchtype=author&query=Dochhan%2C+A">Annika Dochhan</a>, 
<a href="/search/cs?searchtype=author&query=Pachnicke%2C+S">Stephan Pachnicke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The demand for high-speed data is exponentially growing. To conquer this,
optical networks underwent significant changes getting more complex and
versatile. The increasing complexity necessitates the fault management to be
more adaptive to enhance network assurance. In this paper, we experimentally
compare the performance of soft-failure management of different machine
learning algorithms. We further introduce a machine-learning based soft-failure
management framework. It utilizes a variational autoencoder based generative
adversarial network (VAE-GAN) running on optical spectral data obtained by
optical spectrum analyzers. The framework is able to reliably run on a fraction
of available training data as well as identifying unknown failure types. The
investigations show, that the VAE-GAN outperforms the other machine learning
algorithms when up to 10\% of the total training data is available in
identification tasks. Furthermore, the advanced training mechanism for the GAN
shows a high F1-score for unknown spectrum identification. The failure
localization comparison shows the advantage of a low complexity neural network
in combination with a VAE over established machine learning algorithms.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07212" title="Abstract">arXiv:2312.07212</a> [<a href="/pdf/2312.07212" title="Download PDF">pdf</a>, <a href="/format/2312.07212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> More than Vanilla Fusion: a Simple, Decoupling-free, Attention Module  for Multimodal Fusion Based on Signal Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+P">Peiwen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zishan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Donghao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Honggang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The vanilla fusion methods still dominate a large percentage of mainstream
audio-visual tasks. However, the effectiveness of vanilla fusion from a
theoretical perspective is still worth discussing. Thus, this paper reconsiders
the signal fused in the multimodal case from a bionics perspective and proposes
a simple, plug-and-play, attention module for vanilla fusion based on
fundamental signal theory and uncertainty theory. In addition, previous work on
multimodal dynamic gradient modulation still relies on decoupling the
modalities. So, a decoupling-free gradient modulation scheme has been designed
in conjunction with the aforementioned attention module, which has various
advantages over the decoupled one. Experiment results show that just a few
lines of code can achieve up to 2.0% performance improvements to several
multimodal classification methods. Finally, quantitative evaluation of other
fusion tasks reveals the potential for additional application scenarios.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07213" title="Abstract">arXiv:2312.07213</a> [<a href="/pdf/2312.07213" title="Download PDF">pdf</a>, <a href="/format/2312.07213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brain-inspired Computing Based on Machine Learning And Deep Learning:A  Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bihui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sibo Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21pages,7 figures and 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The continuous development of artificial intelligence has a profound impact
on biomedical research and other fields.Brain-inspired computing is an
important intersection of multimodal technology and biomedical field. This
paper provides a comprehensive review of machine learning (ML) and deep
learning (DL) models in brain-inspired computing, tracking their evolution,
application value, challenges, and potential research trajectories. First, the
basic concepts and development history are reviewed, and their evolution is
divided into two stages: recent machine learning and current deep learning,
emphasizing the importance of each stage in the research state of
brain-inspired computing. In addition, the latest progress and key techniques
of deep learning in different tasks of brain-inspired computing are introduced
from six perspectives. Despite significant progress, challenges remain in
making full use of its capabilities. This paper aims to provide a comprehensive
review of brain-inspired computing models based on machine learning and deep
learning, highlighting their potential in various applications and providing a
valuable reference for future academic research. It can be accessed through the
following url: https://github.com/ultracoolHub/brain-inspired-computing
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07214" title="Abstract">arXiv:2312.07214</a> [<a href="/pdf/2312.07214" title="Download PDF">pdf</a>, <a href="/format/2312.07214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Large Language Models to Facilitate Variable Autonomy for  Human-Robot Teaming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lakhnati%2C+Y">Younes Lakhnati</a>, 
<a href="/search/cs?searchtype=author&query=Pascher%2C+M">Max Pascher</a>, 
<a href="/search/cs?searchtype=author&query=Gerken%2C+J">Jens Gerken</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to: Frontiers in Robotics and AI, Variable Autonomy for Human-Robot Teaming
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">In a rapidly evolving digital landscape autonomous tools and robots are
becoming commonplace. Recognizing the significance of this development, this
paper explores the integration of Large Language Models (LLMs) like Generative
pre-trained transformer (GPT) into human-robot teaming environments to
facilitate variable autonomy through the means of verbal human-robot
communication. In this paper, we introduce a novel framework for such a
GPT-powered multi-robot testbed environment, based on a Unity Virtual Reality
(VR) setting. This system allows users to interact with robot agents through
natural language, each powered by individual GPT cores. By means of OpenAI's
function calling, we bridge the gap between unstructured natural language input
and structure robot actions. A user study with 12 participants explores the
effectiveness of GPT-4 and, more importantly, user strategies when being given
the opportunity to converse in natural language within a multi-robot
environment. Our findings suggest that users may have preconceived expectations
on how to converse with robots and seldom try to explore the actual language
and cognitive capabilities of their robot collaborators. Still, those users who
did explore where able to benefit from a much more natural flow of
communication and human-like back-and-forth. We provide a set of lessons
learned for future research and technical implementations of similar systems.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07216" title="Abstract">arXiv:2312.07216</a> [<a href="/pdf/2312.07216" title="Download PDF">pdf</a>, <a href="/format/2312.07216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning from Interaction: User Interface Adaptation using Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gaspar-Figueiredo%2C+D">Daniel Gaspar-Figueiredo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The continuous adaptation of software systems to meet the evolving needs of
users is very important for enhancing user experience (UX). User interface (UI)
adaptation, which involves adjusting the layout, navigation, and content
presentation based on user preferences and contextual conditions, plays an
important role in achieving this goal. However, suggesting the right adaptation
at the right time and in the right place remains a challenge in order to make
it valuable for the end-user. To tackle this challenge, machine learning
approaches could be used. In particular, we are using Reinforcement Learning
(RL) due to its ability to learn from interaction with the users. In this
approach, the feedback is very important and the use of physiological data
could be benefitial to obtain objective insights into how users are reacting to
the different adaptations. Thus, in this PhD thesis, we propose an RL-based UI
adaptation framework that uses physiological data. The framework aims to learn
from user interactions and make informed adaptations to improve UX. To this
end, our research aims to answer the following questions: Does the use of an
RL-based approach improve UX? How effective is RL in guiding UI adaptation? and
Can physiological data support UI adaptation for enhancing UX? The evaluation
plan involves conducting user studies to evaluate answer these questions. The
empirical evaluation will provide a strong empirical foundation for building,
evaluating, and improving the proposed adaptation framework. The expected
contributions of this research include the development of a novel framework for
intelligent Adaptive UIs, insights into the effectiveness of RL algorithms in
guiding UI adaptation, the integration of physiological data as objective
measures of UX, and empirical validation of the proposed framework's impact on
UX.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07218" title="Abstract">arXiv:2312.07218</a> [<a href="/pdf/2312.07218" title="Download PDF">pdf</a>, <a href="/format/2312.07218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Quantification for the Homogeneous Landau-Fokker-Planck  Equation via Deterministic Particle Galerkin methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bailo%2C+R">Rafael Bailo</a>, 
<a href="/search/math?searchtype=author&query=Carrillo%2C+J+A">Jos&#xe9; Antonio Carrillo</a>, 
<a href="/search/math?searchtype=author&query=Medaglia%2C+A">Andrea Medaglia</a>, 
<a href="/search/math?searchtype=author&query=Zanella%2C+M">Mattia Zanella</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP); Computational Physics (physics.comp-ph); Plasma Physics (physics.plasm-ph)

</div>
<p class="mathjax">We design a deterministic particle method for the solution of the spatially
homogeneous Landau equation with uncertainty. The deterministic particle
approximation is based on the reformulation of the Landau equation as a formal
gradient flow on the set of probability measures, whereas the propagation of
uncertain quantities is computed by means of a sg representation of each
particle. This approach guarantees spectral accuracy in uncertainty space while
preserving the fundamental structural properties of the model: the positivity
of the solution, the conservation of invariant quantities, and the entropy
production. We provide a regularity results for the particle method in the
random space. We perform the numerical validation of the particle method in a
wealth of test cases.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07220" title="Abstract">arXiv:2312.07220</a> [<a href="/pdf/2312.07220" title="Download PDF">pdf</a>, <a href="/format/2312.07220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance Characterization of Containerized DNN Training and Inference  on Edge Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=K.%2C+P+S">Prashanthi S.K.</a>, 
<a href="/search/cs?searchtype=author&query=Hegde%2C+V">Vinayaka Hegde</a>, 
<a href="/search/cs?searchtype=author&query=Patchava%2C+K">Keerthana Patchava</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Ankita Das</a>, 
<a href="/search/cs?searchtype=author&query=Simmhan%2C+Y">Yogesh Simmhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in HiPC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Edge devices have typically been used for DNN inferencing. The increase in
the compute power of accelerated edges is leading to their use in DNN training
also. As privacy becomes a concern on multi-tenant edge devices, Docker
containers provide a lightweight virtualization mechanism to sandbox models.
But their overheads for edge devices are not yet explored. In this work, we
study the impact of containerized DNN inference and training workloads on an
NVIDIA AGX Orin edge device and contrast it against bare metal execution on
running time, CPU, GPU and memory utilization, and energy consumption. Our
analysis provides several interesting insights on these overheads.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07221" title="Abstract">arXiv:2312.07221</a> [<a href="/pdf/2312.07221" title="Download PDF">pdf</a>, <a href="/format/2312.07221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transferring CLIP&#x27;s Knowledge into Zero-Shot Point Cloud Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuanbin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shaofei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yulu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+K">Kehua Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Si Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Traditional 3D segmentation methods can only recognize a fixed range of
classes that appear in the training set, which limits their application in
real-world scenarios due to the lack of generalization ability. Large-scale
visual-language pre-trained models, such as CLIP, have shown their
generalization ability in the zero-shot 2D vision tasks, but are still unable
to be applied to 3D semantic segmentation directly. In this work, we focus on
zero-shot point cloud semantic segmentation and propose a simple yet effective
baseline to transfer the visual-linguistic knowledge implied in CLIP to point
cloud encoder at both feature and output levels. Both feature-level and
output-level alignments are conducted between 2D and 3D encoders for effective
knowledge transfer. Concretely, a Multi-granularity Cross-modal Feature
Alignment (MCFA) module is proposed to align 2D and 3D features from global
semantic and local position perspectives for feature-level alignment. For the
output level, per-pixel pseudo labels of unseen classes are extracted using the
pre-trained CLIP model as supervision for the 3D segmentation model to mimic
the behavior of the CLIP image encoder. Extensive experiments are conducted on
two popular benchmarks of point cloud segmentation. Our method outperforms
significantly previous state-of-the-art methods under zero-shot setting (+29.2%
mIoU on SemanticKITTI and 31.8% mIoU on nuScenes), and further achieves
promising results in the annotation-free point cloud semantic segmentation
setting, showing its great potential for label-efficient learning.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07223" title="Abstract">arXiv:2312.07223</a> [<a href="/pdf/2312.07223" title="Download PDF">pdf</a>, <a href="/ps/2312.07223" title="Download PostScript">ps</a>, <a href="/format/2312.07223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the logic of interventionist counterfactuals under indeterministic  causal laws
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barbero%2C+F">Fausto Barbero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Logic (math.LO); Statistics Theory (math.ST)

</div>
<p class="mathjax">We investigate the generalization of causal models to the case of
indeterministic causal laws that was suggested in Halpern (2000). We give an
overview of what differences in modeling are enforced by this more general
perspective, and propose an implementation of generalized models in the style
of the causal team semantics of Barbero &amp; Sandu (2020). In these models, the
laws are not represented by functions (as in the deterministic case), but more
generally by relations.
<br />We analyze significant differences in the axiomatization of interventionist
counterfactuals in the indeterministic vs. the deterministic case, and provide
strongly complete axiomatizations over the full class of indeterministic models
and over its recursive subclass.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07227" title="Abstract">arXiv:2312.07227</a> [<a href="/pdf/2312.07227" title="Download PDF">pdf</a>, <a href="/format/2312.07227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalarizing Multi-Objective Robot Planning Problems using Weighted  Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wilde%2C+N">Nils Wilde</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+S+L">Stephen L. Smith</a>, 
<a href="/search/cs?searchtype=author&query=Alonso-Mora%2C+J">Javier Alonso-Mora</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">When designing a motion planner for autonomous robots there are usually
multiple objectives to be considered. However, a cost function that yields the
desired trade-off between objectives is not easily obtainable. A common
technique across many applications is to use a weighted sum of relevant
objective functions and then carefully adapt the weights. However, this
approach may not find all relevant trade-offs even in simple planning problems.
Thus, we study an alternative method based on a weighted maximum of objectives.
Such a cost function is more expressive than the weighted sum, and we show how
it can be deployed in both continuous- and discrete-space motion planning
problems. We propose a novel path planning algorithm for the proposed cost
function and establish its correctness, and present heuristic adaptations that
yield a practical runtime. In extensive simulation experiments, we demonstrate
that the proposed cost function and algorithm are able to find a wider range of
trade-offs between objectives (i.e., Pareto-optimal solutions) for various
planning problems, showcasing its advantages in practice.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07228" title="Abstract">arXiv:2312.07228</a> [<a href="/pdf/2312.07228" title="Download PDF">pdf</a>, <a href="/ps/2312.07228" title="Download PostScript">ps</a>, <a href="/format/2312.07228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toxic language detection: a systematic survey of Arabic datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bensalem%2C+I">Imene Bensalem</a>, 
<a href="/search/cs?searchtype=author&query=Rosso%2C+P">Paolo Rosso</a>, 
<a href="/search/cs?searchtype=author&query=Zitouni%2C+H">Hanane Zitouni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper offers a comprehensive survey of Arabic datasets focused on online
toxic language. We systematically gathered a total of 49 available datasets and
their corresponding papers and conducted a thorough analysis, considering 16
criteria across three primary dimensions: content, annotation process, and
reusability. This analysis enabled us to identify existing gaps and make
recommendations for future research works.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07231" title="Abstract">arXiv:2312.07231</a> [<a href="/pdf/2312.07231" title="Download PDF">pdf</a>, <a href="/format/2312.07231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Training of Diffusion Transformer with Extreme Masking for 3D Point  Clouds Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mo%2C+S">Shentong Mo</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+E">Enze Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junsong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Nie%C3%9Fner%2C+M">Matthias Nie&#xdf;ner</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://dit-3d.github.io/FastDiT-3D/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion Transformers have recently shown remarkable effectiveness in
generating high-quality 3D point clouds. However, training voxel-based
diffusion models for high-resolution 3D voxels remains prohibitively expensive
due to the cubic complexity of attention operators, which arises from the
additional dimension of voxels. Motivated by the inherent redundancy of 3D
compared to 2D, we propose FastDiT-3D, a novel masked diffusion transformer
tailored for efficient 3D point cloud generation, which greatly reduces
training costs. Specifically, we draw inspiration from masked autoencoders to
dynamically operate the denoising process on masked voxelized point clouds. We
also propose a novel voxel-aware masking strategy to adaptively aggregate
background/foreground information from voxelized point clouds. Our method
achieves state-of-the-art performance with an extreme masking ratio of nearly
99%. Moreover, to improve multi-category 3D generation, we introduce
Mixture-of-Expert (MoE) in 3D diffusion model. Each category can learn a
distinct diffusion path with different experts, relieving gradient conflict.
Experimental results on the ShapeNet dataset demonstrate that our method
achieves state-of-the-art high-fidelity and diverse 3D point cloud generation
performance. Our FastDiT-3D improves 1-Nearest Neighbor Accuracy and Coverage
metrics when generating 128-resolution voxel point clouds, using only 6.5% of
the original training cost.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07234" title="Abstract">arXiv:2312.07234</a> [<a href="/pdf/2312.07234" title="Download PDF">pdf</a>, <a href="/format/2312.07234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing Heterogeneous Robot Fleets for Task Allocation and Sequencing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wilde%2C+N">Nils Wilde</a>, 
<a href="/search/cs?searchtype=author&query=Alonso-Mora%2C+J">Javier Alonso-Mora</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We study the problem of selecting a fleet of robots to service spatially
distributed tasks with diverse requirements within time-windows. The problem of
allocating tasks to a fleet of potentially heterogeneous robots and finding an
optimal sequence for each robot is known as multi-robot task assignment (MRTA).
Most state-of-the-art methods focus on the problem when the fleet of robots is
fixed. In contrast, we consider that we are given a set of available robot
types and requested tasks, and need to assemble a fleet that optimally services
the tasks while the cost of the fleet remains under a budget limit. We
characterize the complexity of the problem and provide a Mixed-Integer Linear
Program (MILP) formulation. Due to poor scalability of the MILP, we propose a
heuristic solution based on a Large Neighbourhood Search (LNS). In simulations,
we demonstrate that the proposed method requires substantially lower budgets
than a greedy algorithm to service all tasks.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07241" title="Abstract">arXiv:2312.07241</a> [<a href="/pdf/2312.07241" title="Download PDF">pdf</a>, <a href="/ps/2312.07241" title="Download PostScript">ps</a>, <a href="/format/2312.07241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reachability of Fair Allocations via Sequential Exchanges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Igarashi%2C+A">Ayumi Igarashi</a>, 
<a href="/search/cs?searchtype=author&query=Kamiyama%2C+N">Naoyuki Kamiyama</a>, 
<a href="/search/cs?searchtype=author&query=Suksompong%2C+W">Warut Suksompong</a>, 
<a href="/search/cs?searchtype=author&query=Yuen%2C+S+M">Sheung Man Yuen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the 38th AAAI Conference on Artificial Intelligence (AAAI), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">In the allocation of indivisible goods, a prominent fairness notion is
envy-freeness up to one good (EF1). We initiate the study of reachability
problems in fair division by investigating the problem of whether one EF1
allocation can be reached from another EF1 allocation via a sequence of
exchanges such that every intermediate allocation is also EF1. We show that two
EF1 allocations may not be reachable from each other even in the case of two
agents, and deciding their reachability is PSPACE-complete in general. On the
other hand, we prove that reachability is guaranteed for two agents with
identical or binary utilities as well as for any number of agents with
identical binary utilities. We also examine the complexity of deciding whether
there is an EF1 exchange sequence that is optimal in the number of exchanges
required.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07243" title="Abstract">arXiv:2312.07243</a> [<a href="/pdf/2312.07243" title="Download PDF">pdf</a>, <a href="/format/2312.07243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Sampling Framework for Solver Searching of Diffusion  Probabilistic Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+E">Enshu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+X">Xuefei Ning</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Huazhong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Recent years have witnessed the rapid progress and broad application of
diffusion probabilistic models (DPMs). Sampling from DPMs can be viewed as
solving an ordinary differential equation (ODE). Despite the promising
performance, the generation of DPMs usually consumes much time due to the large
number of function evaluations (NFE). Though recent works have accelerated the
sampling to around 20 steps with high-order solvers, the sample quality with
less than 10 NFE can still be improved. In this paper, we propose a unified
sampling framework (USF) to study the optional strategies for solver. Under
this framework, we further reveal that taking different solving strategies at
different timesteps may help further decrease the truncation error, and a
carefully designed \emph{solver schedule} has the potential to improve the
sample quality by a large margin. Therefore, we propose a new sampling
framework based on the exponential integral formulation that allows free
choices of solver strategy at each step and design specific decisions for the
framework. Moreover, we propose $S^3$, a predictor-based search method that
automatically optimizes the solver schedule to get a better time-quality
trade-off of sampling. We demonstrate that $S^3$ can find outstanding solver
schedules which outperform the state-of-the-art sampling methods on CIFAR-10,
CelebA, ImageNet, and LSUN-Bedroom datasets. Specifically, we achieve 2.69 FID
with 10 NFE and 6.86 FID with 5 NFE on CIFAR-10 dataset, outperforming the SOTA
method significantly. We further apply $S^3$ to Stable-Diffusion model and get
an acceleration ratio of 2$\times$, showing the feasibility of sampling in very
few steps without retraining the neural network.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07245" title="Abstract">arXiv:2312.07245</a> [<a href="/pdf/2312.07245" title="Download PDF">pdf</a>, <a href="/format/2312.07245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DTA: Distribution Transform-based Attack for Query-Limited Scenario
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Renyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Song Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuanyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruxin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In generating adversarial examples, the conventional black-box attack methods
rely on sufficient feedback from the to-be-attacked models by repeatedly
querying until the attack is successful, which usually results in thousands of
trials during an attack. This may be unacceptable in real applications since
Machine Learning as a Service Platform (MLaaS) usually only returns the final
result (i.e., hard-label) to the client and a system equipped with certain
defense mechanisms could easily detect malicious queries. By contrast, a
feasible way is a hard-label attack that simulates an attacked action being
permitted to conduct a limited number of queries. To implement this idea, in
this paper, we bypass the dependency on the to-be-attacked model and benefit
from the characteristics of the distributions of adversarial examples to
reformulate the attack problem in a distribution transform manner and propose a
distribution transform-based attack (DTA). DTA builds a statistical mapping
from the benign example to its adversarial counterparts by tackling the
conditional likelihood under the hard-label black-box settings. In this way, it
is no longer necessary to query the target model frequently. A well-trained DTA
model can directly and efficiently generate a batch of adversarial examples for
a certain input, which can be used to attack un-seen models based on the
assumed transferability. Furthermore, we surprisingly find that the
well-trained DTA model is not sensitive to the semantic spaces of the training
dataset, meaning that the model yields acceptable attack performance on other
datasets. Extensive experiments validate the effectiveness of the proposed idea
and the superiority of DTA over the state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07246" title="Abstract">arXiv:2312.07246</a> [<a href="/pdf/2312.07246" title="Download PDF">pdf</a>, <a href="/format/2312.07246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unifying Correspondence, Pose and NeRF for Pose-Free Novel View  Synthesis from Stereo Pairs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Sunghwan Hong</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+J">Jaewoo Jung</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+H">Heeseong Shin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiaolong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungryong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Chong Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://ku-cvlab.github.io/CoPoNeRF/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This work delves into the task of pose-free novel view synthesis from stereo
pairs, a challenging and pioneering task in 3D vision. Our innovative
framework, unlike any before, seamlessly integrates 2D correspondence matching,
camera pose estimation, and NeRF rendering, fostering a synergistic enhancement
of these tasks. We achieve this through designing an architecture that utilizes
a shared representation, which serves as a foundation for enhanced 3D geometry
understanding. Capitalizing on the inherent interplay between the tasks, our
unified framework is trained end-to-end with the proposed training strategy to
improve overall model accuracy. Through extensive evaluations across diverse
indoor and outdoor scenes from two real-world datasets, we demonstrate that our
approach achieves substantial improvement over previous methodologies,
especially in scenarios characterized by extreme viewpoint changes and the
absence of accurate camera poses.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07248" title="Abstract">arXiv:2312.07248</a> [<a href="/pdf/2312.07248" title="Download PDF">pdf</a>, <a href="/ps/2312.07248" title="Download PostScript">ps</a>, <a href="/format/2312.07248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Granularity Framework for Unsupervised Representation Learning of  Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+C">Chengyang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Q">Qiang Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Representation learning plays a critical role in the analysis of time series
data and has high practical value across a wide range of applications.
including trend analysis, time series data retrieval and forecasting. In
practice, data confusion is a significant issue as it can considerably impact
the effectiveness and accuracy of data analysis, machine learning models and
decision-making processes. In general, previous studies did not consider the
variability at various levels of granularity, thus resulting in inadequate
information utilization, which further exacerbated the issue of data confusion.
This paper proposes an unsupervised framework to realize multi-granularity
representation learning for time series. Specifically, we employed a
cross-granularity transformer to develop an association between fine- and
coarse-grained representations. In addition, we introduced a retrieval task as
an unsupervised training task to learn the multi-granularity representation of
time series. Moreover, a novel loss function was designed to obtain the
comprehensive multi-granularity representation of the time series via
unsupervised learning. The experimental results revealed that the proposed
framework demonstrates significant advantages over alternative representation
learning models.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07250" title="Abstract">arXiv:2312.07250</a> [<a href="/pdf/2312.07250" title="Download PDF">pdf</a>, <a href="/format/2312.07250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Machine Translation of Clinical Text: An Empirical Investigation  into Multilingual Pre-Trained Language Models and Transfer-Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Lifeng Han</a>, 
<a href="/search/cs?searchtype=author&query=Gladkoff%2C+S">Serge Gladkoff</a>, 
<a href="/search/cs?searchtype=author&query=Erofeev%2C+G">Gleb Erofeev</a>, 
<a href="/search/cs?searchtype=author&query=Sorokina%2C+I">Irina Sorokina</a>, 
<a href="/search/cs?searchtype=author&query=Galiano%2C+B">Betty Galiano</a>, 
<a href="/search/cs?searchtype=author&query=Nenadic%2C+G">Goran Nenadic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Frontiers in Digital Health - Health Informatics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We conduct investigations on clinical text machine translation by examining
multilingual neural network models using deep learning such as Transformer
based structures. Furthermore, to address the language resource imbalance
issue, we also carry out experiments using a transfer learning methodology
based on massive multilingual pre-trained language models (MMPLMs). The
experimental results on three subtasks including 1) clinical case (CC), 2)
clinical terminology (CT), and 3) ontological concept (OC) show that our models
achieved top-level performances in the ClinSpEn-2022 shared task on
English-Spanish clinical domain data. Furthermore, our expert-based human
evaluations demonstrate that the small-sized pre-trained language model (PLM)
won over the other two extra-large language models by a large margin, in the
clinical domain fine-tuning, which finding was never reported in the field.
Finally, the transfer learning method works well in our experimental setting
using the WMT21fb model to accommodate a new language space Spanish that was
not seen at the pre-training stage within WMT21fb itself, which deserves more
exploitation for clinical knowledge transformation, e.g. to investigate into
more languages. These research findings can shed some light on domain-specific
machine translation development, especially in clinical and healthcare fields.
Further research projects can be carried out based on our work to improve
healthcare text analytics and knowledge transformation.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07252" title="Abstract">arXiv:2312.07252</a> [<a href="/pdf/2312.07252" title="Download PDF">pdf</a>, <a href="/format/2312.07252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying Drivers of Predictive Uncertainty using Variance Feature  Attribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Iversen%2C+P">Pascal Iversen</a>, 
<a href="/search/cs?searchtype=author&query=Witzke%2C+S">Simon Witzke</a>, 
<a href="/search/cs?searchtype=author&query=Baum%2C+K">Katharina Baum</a>, 
<a href="/search/cs?searchtype=author&query=Renard%2C+B+Y">Bernhard Y. Renard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Simon Witzke and Pascal Iversen contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Explainability and uncertainty quantification are two pillars of trustable
artificial intelligence. However, the reasoning behind uncertainty estimates is
generally left unexplained. Identifying the drivers of uncertainty complements
explanations of point predictions in recognizing potential model limitations.
It facilitates the detection of oversimplification in the uncertainty
estimation process. Explanations of uncertainty enhance communication and trust
in decisions. They allow for verifying whether the main drivers of model
uncertainty are relevant and may impact model usage. So far, the subject of
explaining uncertainties has been rarely studied. The few exceptions in
existing literature are tailored to Bayesian neural networks or rely heavily on
technically intricate approaches, hindering their broad adoption. We propose
variance feature attribution, a simple and scalable solution to explain
predictive aleatoric uncertainties. First, we estimate uncertainty as
predictive variance by equipping a neural network with a Gaussian output
distribution by adding a variance output neuron. Thereby, we can rely on
pre-trained point prediction models and fine-tune them for meaningful variance
estimation. Second, we apply out-of-the-box explainers on the variance output
of these models to explain the uncertainty estimation. We evaluate our approach
in a synthetic setting where the data-generating process is known. We show that
our method can explain uncertainty influences more reliably and faster than the
established baseline CLUE. We fine-tune a state-of-the-art age regression model
to estimate uncertainty and obtain attributions. Our explanations highlight
potential sources of uncertainty, such as laugh lines. Variance feature
attribution provides accurate explanations for uncertainty estimates with
little modifications to the model architecture and low computational overhead.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07254" title="Abstract">arXiv:2312.07254</a> [<a href="/pdf/2312.07254" title="Download PDF">pdf</a>, <a href="/format/2312.07254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The GUA-Speech System Description for CNVSRC Challenge 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shengqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+C">Chao Lei</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+B">Baozhong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Binbin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+F">Fuping Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CNVSRC 2023 Challenge
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This study describes our system for Task 1 Single-speaker Visual Speech
Recognition (VSR) fixed track in the Chinese Continuous Visual Speech
Recognition Challenge (CNVSRC) 2023. Specifically, we use intermediate
connectionist temporal classification (Inter CTC) residual modules to relax the
conditional independence assumption of CTC in our model. Then we use a
bi-transformer decoder to enable the model to capture both past and future
contextual information. In addition, we use Chinese characters as the modeling
units to improve the recognition accuracy of our model. Finally, we use a
recurrent neural network language model (RNNLM) for shallow fusion in the
inference stage. Experiments show that our system achieves a character error
rate (CER) of 38.09% on the Eval set which reaches a relative CER reduction of
21.63% over the official baseline, and obtains a second place in the challenge.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07255" title="Abstract">arXiv:2312.07255</a> [<a href="/pdf/2312.07255" title="Download PDF">pdf</a>, <a href="/format/2312.07255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GIST: Improving Parameter Efficient Fine Tuning via Knowledge  Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruan%2C+J">Jiacheng Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jingsheng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+M">Mingye Xie</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+S">Suncheng Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zefang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yuzhuo Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17pages, 8 figures, 22 tables, Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The Parameter-Efficient Fine-Tuning (PEFT) method, which adjusts or
introduces fewer trainable parameters to calibrate pre-trained models on
downstream tasks, has become a recent research interest. However, existing PEFT
methods within the traditional fine-tiuning framework have two main
shortcomings: 1) They overlook the explicit association between trainable
parameters and downstream task knowledge. 2) They neglect the interaction
between the intrinsic task-agnostic knowledge of pre-trained models and the
task-specific knowledge in downstream tasks. To address this gap, we propose a
novel fine-tuning framework, named GIST, in a plug-and-play manner.
Specifically, our framework first introduces a trainable token, called the Gist
token, when applying PEFT methods on downstream tasks. This token serves as an
aggregator of the task-specific knowledge learned by the PEFT methods and forms
an explicit association with downstream knowledge. Furthermore, to facilitate
explicit interaction between task-agnostic and task-specific knowledge, we
introduce the concept of Knowledge Interaction via a Bidirectional
Kullback-Leibler Divergence objective. As a result, PEFT methods within our
framework can make the pre-trained model understand downstream tasks more
comprehensively by leveraging the knowledge interaction. Extensive experiments
demonstrate the universality and scalability of our framework. Notably, on the
VTAB-1K benchmark, we employ the Adapter (a prevalent PEFT method) within our
GIST framework and achieve a performance boost of 2.25%, with an increase of
only 0.8K parameters. The Code will be released.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07258" title="Abstract">arXiv:2312.07258</a> [<a href="/pdf/2312.07258" title="Download PDF">pdf</a>, <a href="/format/2312.07258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SSTA: Salient Spatially Transformed Attack
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Renyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Sixin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+K">Kwok-Yan Lam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Extensive studies have demonstrated that deep neural networks (DNNs) are
vulnerable to adversarial attacks, which brings a huge security risk to the
further application of DNNs, especially for the AI models developed in the real
world. Despite the significant progress that has been made recently, existing
attack methods still suffer from the unsatisfactory performance of escaping
from being detected by naked human eyes due to the formulation of adversarial
example (AE) heavily relying on a noise-adding manner. Such mentioned
challenges will significantly increase the risk of exposure and result in an
attack to be failed. Therefore, in this paper, we propose the Salient Spatially
Transformed Attack (SSTA), a novel framework to craft imperceptible AEs, which
enhance the stealthiness of AEs by estimating a smooth spatial transform metric
on a most critical area to generate AEs instead of adding external noise to the
whole image. Compared to state-of-the-art baselines, extensive experiments
indicated that SSTA could effectively improve the imperceptibility of the AEs
while maintaining a 100\% attack success rate.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07261" title="Abstract">arXiv:2312.07261</a> [<a href="/pdf/2312.07261" title="Download PDF">pdf</a>, <a href="/format/2312.07261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relocating thermal stimuli to the proximal phalanx may not affect  vibrotactile sensitivity on the fingertip
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Riessen%2C+H+A+J">Huibert A. J. van Riessen</a>, 
<a href="/search/cs?searchtype=author&query=Vardar%2C+Y">Yasemin Vardar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Wearable devices that relocate tactile feedback from fingertips can enable
users to interact with their physical world augmented by virtual effects. While
studies have shown that relocating same-modality tactile stimuli can influence
the one perceived at the fingertip, the interaction of cross-modal tactile
stimuli remains unclear. Here, we investigate how thermal cues applied on the
index finger's proximal phalanx affect vibrotactile sensitivity at the
fingertip of the same finger when employed at varying contact pressures. We
designed a novel wearable device that can deliver thermal stimuli at adjustable
contact pressures on the proximal phalanx. Utilizing this device, we measured
the detection thresholds of fifteen participants for 250 Hz sinusoidal
vibration applied on the fingertip while concurrently applying constant cold
and warm stimuli at high and low contact pressures to the proximal phalanx. Our
results revealed no significant differences in detection thresholds across
conditions. These preliminary findings suggest that applying constant thermal
stimuli to other skin locations does not affect fingertip vibrotactile
sensitivity, possibly due to perceptual adaptation. However, the influence of
dynamic multisensory tactile stimuli remains an open question for future
research.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07263" title="Abstract">arXiv:2312.07263</a> [<a href="/pdf/2312.07263" title="Download PDF">pdf</a>, <a href="/ps/2312.07263" title="Download PostScript">ps</a>, <a href="/format/2312.07263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Saturation-Based Unification Algorithm for Higher-Order Rational  Patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhibo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pfenning%2C+F">Frank Pfenning</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Higher-order unification has been shown to be undecidable. Miller discovered
the pattern fragment and subsequently showed that higher-order pattern
unification is decidable and has most general unifiers. We extend the algorithm
to higher-order rational terms (a.k.a. regular B\"{o}hm trees, a form of cyclic
$\lambda$-terms) and show that pattern unification on higher-order rational
terms is decidable and has most general unifiers. We prove the soundness and
completeness of the algorithm.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07264" title="Abstract">arXiv:2312.07264</a> [<a href="/pdf/2312.07264" title="Download PDF">pdf</a>, <a href="/format/2312.07264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual Structure-Preserving Image Filterings for Semi-supervised Medical  Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuliang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xin Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Y">Yuda Zou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zelong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yongchao Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semi-supervised image segmentation has attracted great attention recently.
The key is how to leverage unlabeled images in the training process. Most
methods maintain consistent predictions of the unlabeled images under
variations (e.g., adding noise/perturbations, or creating alternative versions)
in the image and/or model level. In most image-level variation, medical images
often have prior structure information, which has not been well explored. In
this paper, we propose novel dual structure-preserving image filterings (DSPIF)
as the image-level variations for semi-supervised medical image segmentation.
Motivated by connected filtering that simplifies image via filtering in
structure-aware tree-based image representation, we resort to the dual contrast
invariant Max-tree and Min-tree representation. Specifically, we propose a
novel connected filtering that removes topologically equivalent nodes (i.e.
connected components) having no siblings in the Max/Min-tree. This results in
two filtered images preserving topologically critical structure. Applying such
dual structure-preserving image filterings in mutual supervision is beneficial
for semi-supervised medical image segmentation. Extensive experimental results
on three benchmark datasets demonstrate that the proposed method
significantly/consistently outperforms some state-of-the-art methods. The
source codes will be publicly available.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07266" title="Abstract">arXiv:2312.07266</a> [<a href="/pdf/2312.07266" title="Download PDF">pdf</a>, <a href="/format/2312.07266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProxyDet: Synthesizing Proxy Novel Classes via Classwise Mixup for Open  Vocabulary Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeong%2C+J">Joonhyun Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+G">Geondo Park</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+J">Jayeon Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+H">Hyungsik Jung</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Heesu Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in AAAI24. Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Open-vocabulary object detection (OVOD) aims to recognize novel objects whose
categories are not included in training set. In order to classify these unseen
classes during training, many OVOD frameworks leverage the zero-shot capability
of largely pretrained vision and language models, such as CLIP. To further
improve generalization on the unseen novel classes, several approaches proposed
to additionally train with pseudo region labeling on the external data sources
that contain a substantial number of novel category labels beyond the existing
training data. Albeit its simplicity, these pseudo-labeling methods still
exhibit limited improvement with regard to the genuine novel classes that were
not pseudo-labeled. In this paper, we present a novel, yet simple technique
that helps generalization on the overall distribution of novel classes.
Inspired by our observation that numerous novel classes reside within the
convex hull constructed by the base (seen) classes in the CLIP embedding space,
we propose to synthesize proxy-novel classes approximating novel classes via
linear mixup between a pair of base classes. By training our detector with
these synthetic proxy-novel classes, we effectively explore the embedding space
of novel classes. The experimental results on various OVOD benchmarks such as
LVIS and COCO demonstrate superior performance on novel classes compared to the
other state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07268" title="Abstract">arXiv:2312.07268</a> [<a href="/pdf/2312.07268" title="Download PDF">pdf</a>, <a href="/format/2312.07268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A space-time continuous and coercive formulation for the wave equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bignardi%2C+P">Paolo Bignardi</a>, 
<a href="/search/math?searchtype=author&query=Moiola%2C+A">Andrea Moiola</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose a new space-time variational formulation for wave equation
initial-boundary value problems. The key property is that the formulation is
coercive (sign-definite) and continuous in a norm stronger than $H^1(Q)$, $Q$
being the space-time cylinder. Coercivity holds for constant-coefficient
impedance cavity problems posed in star-shaped domains, and for a class of
impedance-Dirichlet problems. The formulation is defined using simple Morawetz
multipliers and its coercivity is proved with elementary analytical tools,
following earlier work on the Helmholtz equation. The formulation can be stably
discretised with any $H^2(Q)$-conforming discrete space, leading to
quasi-optimal space-time Galerkin schemes. Several numerical experiments show
the excellent properties of the method.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07269" title="Abstract">arXiv:2312.07269</a> [<a href="/pdf/2312.07269" title="Download PDF">pdf</a>, <a href="/format/2312.07269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calibrating &quot;Cheap Signals&quot; in Peer Review without a Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yuxuan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Y">Yuqing Kong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Peer review lies at the core of the academic process, but even
well-intentioned reviewers can still provide noisy ratings. While ranking
papers by average ratings may reduce noise, varying noise levels and systematic
biases stemming from ``cheap'' signals (e.g. author identity, proof length) can
lead to unfairness. Detecting and correcting bias is challenging, as ratings
are subjective and unverifiable. Unlike previous works relying on prior
knowledge or historical data, we propose a one-shot noise calibration process
without any prior information. We ask reviewers to predict others' scores and
use these predictions for calibration. Assuming reviewers adjust their
predictions according to the noise, we demonstrate that the calibrated score
results in a more robust ranking compared to average ratings, even with varying
noise levels and biases. In detail, we show that the error probability of the
calibrated score approaches zero as the number of reviewers increases and is
significantly lower compared to average ratings when the number of reviewers is
small.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07271" title="Abstract">arXiv:2312.07271</a> [<a href="/pdf/2312.07271" title="Download PDF">pdf</a>, <a href="/ps/2312.07271" title="Download PostScript">ps</a>, <a href="/format/2312.07271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyze the Robustness of Classifiers under Label Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+C">Cheng Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yixuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jiaqi Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">This study explores the robustness of label noise classifiers, aiming to
enhance model resilience against noisy data in complex real-world scenarios.
Label noise in supervised learning, characterized by erroneous or imprecise
labels, significantly impairs model performance. This research focuses on the
increasingly pertinent issue of label noise's impact on practical applications.
Addressing the prevalent challenge of inaccurate training data labels, we
integrate adversarial machine learning (AML) and importance reweighting
techniques. Our approach involves employing convolutional neural networks (CNN)
as the foundational model, with an emphasis on parameter adjustment for
individual training samples. This strategy is designed to heighten the model's
focus on samples critically influencing performance.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07273" title="Abstract">arXiv:2312.07273</a> [<a href="/pdf/2312.07273" title="Download PDF">pdf</a>, <a href="/format/2312.07273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Pretrained Vision Embeddings for Near- and Duplicate  Detection in Medical Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Truong%2C+T">Tuan Truong</a>, 
<a href="/search/cs?searchtype=author&query=Jush%2C+F+K">Farnaz Khun Jush</a>, 
<a href="/search/cs?searchtype=author&query=Lenga%2C+M">Matthias Lenga</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Near- and duplicate image detection is a critical concern in the field of
medical imaging. Medical datasets often contain similar or duplicate images
from various sources, which can lead to significant performance issues and
evaluation biases, especially in machine learning tasks due to data leakage
between training and testing subsets. In this paper, we present an approach for
identifying near- and duplicate 3D medical images leveraging publicly available
2D computer vision embeddings. We assessed our approach by comparing embeddings
extracted from two state-of-the-art self-supervised pretrained models and two
different vector index structures for similarity retrieval. We generate an
experimental benchmark based on the publicly available Medical Segmentation
Decathlon dataset. The proposed method yields promising results for near- and
duplicate image detection achieving a mean sensitivity and specificity of
0.9645 and 0.8559, respectively.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07280" title="Abstract">arXiv:2312.07280</a> [<a href="/pdf/2312.07280" title="Download PDF">pdf</a>, <a href="/format/2312.07280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Equipping Transformer with the Ability of Systematic  Compositionality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+P">Peixin Qin</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+W">Wenqiang Lei</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+J">Jiancheng Lv</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024. Paper with appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">One of the key factors in language productivity and human cognition is the
ability of systematic compositionality, which refers to understanding composed
unseen examples of seen primitives. However, recent evidence reveals that the
Transformers have difficulty generalizing the composed context based on the
seen primitives. To this end, we take the first step to propose a
compositionality-aware Transformer called CAT and two novel pre-training tasks
to facilitate systematic compositionality. We tentatively provide a successful
implementation of a multi-layer CAT on the basis of the especially popular
BERT. The experimental results demonstrate that CAT outperforms baselines on
compositionality-aware tasks with minimal impact on the effectiveness on
standardized language understanding tasks.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07281" title="Abstract">arXiv:2312.07281</a> [<a href="/pdf/2312.07281" title="Download PDF">pdf</a>, <a href="/format/2312.07281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Multi-Task Bayesian Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%BCbsen%2C+J+O">Jannis O. L&#xfc;bsen</a>, 
<a href="/search/cs?searchtype=author&query=Hespe%2C+C">Christian Hespe</a>, 
<a href="/search/cs?searchtype=author&query=Eichler%2C+A">Annika Eichler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to L4DC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Machine Learning (stat.ML)

</div>
<p class="mathjax">Bayesian optimization has become a powerful tool for safe online optimization
of systems, due to its high sample efficiency and noise robustness. For further
speed-up reduced physical models of the system can be incorporated into the
optimization to accelerate the process, since the models are able to offer an
approximation of the actual system, and sampling from them is significantly
cheaper. The similarity between model and reality is represented by additional
hyperparameters and learned within the optimization process. Safety is an
important criteria for online optimization methods like Bayesian optimization,
which has been addressed by recent literature, which provide safety guarantees
under the assumption of known hyperparameters. However, in practice this is not
applicable. Therefore, we extend the robust Gaussian process uniform error
bounds to meet the multi-task setting, which involves the calculation of a
confidence region from the hyperparameter posterior distribution utilizing
Markov chain Monte Carlo methods. Then, using the robust safety bounds,
Bayesian optimization is applied to safely optimize the system while
incorporating measurements of the models. Simulations show that the
optimization can be significantly accelerated compared to other
state-of-the-art safe Bayesian optimization methods depending on the fidelity
of the models.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07284" title="Abstract">arXiv:2312.07284</a> [<a href="/pdf/2312.07284" title="Download PDF">pdf</a>, <a href="/format/2312.07284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Your Vulnerability Disclosure Is Important To Us: An Analysis of  Coordinated Vulnerability Disclosure Responses Using a Real Security Issue
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Hove%2C+K">Koen van Hove</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Ham-de+Vos%2C+J">Jeroen van der Ham-de Vos</a>, 
<a href="/search/cs?searchtype=author&query=van+Rijswijk-Deij%2C+R">Roland van Rijswijk-Deij</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">It is a public secret that doing email securely is fraught with challenges.
We found a vulnerability present at many email providers, allowing us to spoof
email on behalf of many organisations. As email vulnerabilities are ten a
penny, instead of focusing on yet another email vulnerability we ask a
different question: how do organisations react to the disclosure of such a
security issue in the wild? We specifically focus on organisations from the
public and critical infrastructure sector who are required to respond to such
notifications by law. We find that many organisations are difficult to reach
when it concerns security issues, even if they have a security contact point.
Additionally, our findings show that having policy in place improves the
response and resolution rate, but that even with a policy in place, half of our
reports remain unanswered and unsolved after 90~days. Based on these findings
we provide recommendations to organisations and bodies such as ENISA to improve
future coordinated vulnerability disclosure processes.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07285" title="Abstract">arXiv:2312.07285</a> [<a href="/pdf/2312.07285" title="Download PDF">pdf</a>, <a href="/format/2312.07285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forced Exploration in Bandit Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+H">Han Qi</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+F">Fei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Li Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">The multi-armed bandit(MAB) is a classical sequential decision problem. Most
work requires assumptions about the reward distribution (e.g., bounded), while
practitioners may have difficulty obtaining information about these
distributions to design models for their problems, especially in non-stationary
MAB problems. This paper aims to design a multi-armed bandit algorithm that can
be implemented without using information about the reward distribution while
still achieving substantial regret upper bounds. To this end, we propose a
novel algorithm alternating between greedy rule and forced exploration. Our
method can be applied to Gaussian, Bernoulli and other subgaussian
distributions, and its implementation does not require additional information.
We employ a unified analysis method for different forced exploration strategies
and provide problem-dependent regret upper bounds for stationary and
piecewise-stationary settings. Furthermore, we compare our algorithm with
popular bandit algorithms on different reward distributions.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07290" title="Abstract">arXiv:2312.07290</a> [<a href="/pdf/2312.07290" title="Download PDF">pdf</a>, <a href="/format/2312.07290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Underwater motions analysis and control of a coupling-tiltable unmanned  aerial-aquatic quadrotor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Dongyue Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenggang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+M">Minghao Dou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuchen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zixuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Biao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B+M">Ben M. Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Unmanned Aerial-Aquatic Vehicle
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper proposes a method for analyzing a series of potential motions in a
coupling-tiltable aerial-aquatic quadrotor based on its nonlinear dynamics.
Some characteristics and constraints derived by this method are specified as
Singular Thrust Tilt Angles (STTAs), utilizing to generate motions including
planar motions. A switch-based control scheme addresses issues of control
direction uncertainty inherent to the mechanical structure by incorporating a
saturated Nussbaum function. A high-fidelity simulation environment
incorporating a comprehensive hydrodynamic model is built based on a
Hardware-In-The-Loop (HITL) setup with Gazebo and a flight control board. The
experiments validate the effectiveness of the absolute and quasi planar
motions, which cannot be achieved by conventional quadrotors, and demonstrate
stable performance when the pitch or roll angle is activated in the auxiliary
control channel.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07291" title="Abstract">arXiv:2312.07291</a> [<a href="/pdf/2312.07291" title="Download PDF">pdf</a>, <a href="/format/2312.07291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An approximation of matrix exponential by a truncated Laguerre series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Khoroshikh%2C+E+D">E.D. Khoroshikh</a>, 
<a href="/search/math?searchtype=author&query=Kurbatov%2C+V+G">V.G. Kurbatov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Dynamical Systems (math.DS); Functional Analysis (math.FA); Spectral Theory (math.SP)

</div>
<p class="mathjax">The Laguerre functions $l_{n,\tau}^\alpha$, $n=0,1,\dots$, are constructed
from generalized Laguerre polynomials. The functions $l_{n,\tau}^\alpha$ depend
on two parameters: scale $\tau&gt;0$ and order of generalization $\alpha&gt;-1$, and
form an orthogonal basis in $L_2[0,\infty)$. Let the spectrum of a square
matrix $A$ lie in the open left half-plane. Then the matrix exponential
$H_A(t)=e^{At}$, $t&gt;0$, belongs to $L_2[0,\infty)$. Hence the matrix
exponential $H_A$ can be expanded in a series $H_A=\sum_{n=0}^\infty
S_{n,\tau,\alpha,A}\,l_{n,\tau}^\alpha$. An estimate of the norm $\Bigl\lVert
H_A-\sum_{n=0}^N
S_{n,\tau,\alpha,A}\,l_{n,\tau}^\alpha\Bigr\rVert_{L_2[0,\infty)}$ is proposed.
Finding the minimum of this estimate over $\tau$ and $\alpha$ is discussed.
Numerical examples show that the optimal $\alpha$ is often almost 0, which
essentially simplifies the problem.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07292" title="Abstract">arXiv:2312.07292</a> [<a href="/pdf/2312.07292" title="Download PDF">pdf</a>, <a href="/format/2312.07292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistically Distinct Plans for Multi-Objective Task Assignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wilde%2C+N">Nils Wilde</a>, 
<a href="/search/cs?searchtype=author&query=Alonso-Mora%2C+J">Javier Alonso-Mora</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We study the problem of finding statistically distinct plans for stochastic
planning and task assignment problems such as online multi-robot pickup and
delivery (MRPD) when facing multiple competing objectives. In many real-world
settings robot fleets do not only need to fulfil delivery requests, but also
have to consider auxiliary objectives such as energy efficiency or avoiding
human-centered work spaces. We pose MRPD as a multi-objective optimization
problem where the goal is to find MRPD policies that yield different trade-offs
between given objectives. There are two main challenges: 1) MRPD is
computationally hard, which limits the number of trade-offs that can reasonably
be computed, and 2) due to the random task arrivals, one needs to consider
statistical variance of the objective values in addition to the average. We
present an adaptive sampling algorithm that finds a set of policies which i)
are approximately optimal, ii) approximate the set of all optimal solutions,
and iii) are statistically distinguishable. We prove completeness and adapt a
state-of-the-art MRPD solver to the multi-objective setting for three example
objectives. In a series of simulation experiments we demonstrate the advantages
of the proposed method compared to baseline approaches and show its robustness
in a sensitivity analysis. The approach is general and could be adapted to
other multi-objective task assignment and planning problems under uncertainty.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07294" title="Abstract">arXiv:2312.07294</a> [<a href="/pdf/2312.07294" title="Download PDF">pdf</a>, <a href="/format/2312.07294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probing Commonsense Reasoning Capability of Text-to-Image Generative  Models via Non-visual Description
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+M">Mianzhi Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianfei Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+M">Mingyue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zheng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+K">Kanzhi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianbing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiajun Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">Commonsense reasoning, the ability to make logical assumptions about daily
scenes, is one core intelligence of human beings. In this work, we present a
novel task and dataset for evaluating the ability of text-to-image generative
models to conduct commonsense reasoning, which we call PAINTaboo. Given a
description with few visual clues of one object, the goal is to generate images
illustrating the object correctly. The dataset was carefully hand-curated and
covered diverse object categories to analyze model performance comprehensively.
Our investigation of several prevalent text-to-image generative models reveals
that these models are not proficient in commonsense reasoning, as anticipated.
We trust that PAINTaboo can improve our understanding of the reasoning
abilities of text-to-image generative models.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07296" title="Abstract">arXiv:2312.07296</a> [<a href="/pdf/2312.07296" title="Download PDF">pdf</a>, <a href="/format/2312.07296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complex Recurrent Spectral Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chicchi%2C+L">Lorenzo Chicchi</a>, 
<a href="/search/cs?searchtype=author&query=Giambagli%2C+L">Lorenzo Giambagli</a>, 
<a href="/search/cs?searchtype=author&query=Buffoni%2C+L">Lorenzo Buffoni</a>, 
<a href="/search/cs?searchtype=author&query=Marino%2C+R">Raffaele Marino</a>, 
<a href="/search/cs?searchtype=author&query=Fanelli%2C+D">Duccio Fanelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">This paper presents a novel approach to advancing artificial intelligence
(AI) through the development of the Complex Recurrent Spectral Network
($\mathbb{C}$-RSN), an innovative variant of the Recurrent Spectral Network
(RSN) model. The $\mathbb{C}$-RSN is designed to address a critical limitation
in existing neural network models: their inability to emulate the complex
processes of biological neural networks dynamically and accurately. By
integrating key concepts from dynamical systems theory and leveraging
principles from statistical mechanics, the $\mathbb{C}$-RSN model introduces
localized non-linearity, complex fixed eigenvalues, and a distinct separation
of memory and input processing functionalities. These features collectively
enable the $\mathbb{C}$-RSN evolving towards a dynamic, oscillating final state
that more closely mirrors biological cognition. Central to this work is the
exploration of how the $\mathbb{C}$-RSN manages to capture the rhythmic,
oscillatory dynamics intrinsic to biological systems, thanks to its complex
eigenvalue structure and the innovative segregation of its linear and
non-linear components. The model's ability to classify data through a
time-dependent function, and the localization of information processing, is
demonstrated with an empirical evaluation using the MNIST dataset. Remarkably,
distinct items supplied as a sequential input yield patterns in time which bear
the indirect imprint of the insertion order (and of the time of separation
between contiguous insertions).
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07298" title="Abstract">arXiv:2312.07298</a> [<a href="/pdf/2312.07298" title="Download PDF">pdf</a>, <a href="/ps/2312.07298" title="Download PostScript">ps</a>, <a href="/format/2312.07298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combined Invariant Subspace \&amp; Frequency-Domain Subspace Method for  Identification of Discrete-Time MIMO Linear Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=You%2C+J">Jingze You</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+C">Chao Huang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> algorithm implemented via MATLAB: <a href="https://github.com/wyqy/dcissim">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Systems &amp; Control Letters, vol. 181, p. 105641, Nov. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Recently, a novel system identification method based on invariant subspace
theory is introduced, aiming to address the identification problem of
continuous-time (CT) linear time-invariant (LTI) systems by combining
time-domain and frequency-domain methods. Subsequently, the combined
Invariant-Subspace and Subspace Identification Method (cISSIM) is introduced,
enabling direct estimation of CT LTI systems in state-space forms. It produces
consistent estimation that is robust in an error-in-variable and slow-sampling
conditions, while no pre-filtering operation of the input-output signals is
needed. This paper presents the discrete-cISSIM, which extends cISSIM to
discrete-time (DT) systems and offers the following improvements: 1) the
capability to utilize arbitrary discrete periodic excitations while cISSIM uses
multi-sine signals; 2) a faster estimation with reduced computational
complexity is proposed; 3) the covariance estimation problem can be addressed
concurrently with the system parameter estimation. An implementation of
discrete-cISSIM by MATLAB has also been provided.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07302" title="Abstract">arXiv:2312.07302</a> [<a href="/pdf/2312.07302" title="Download PDF">pdf</a>, <a href="/format/2312.07302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Knowledge Representation to Knowledge Organization and Back
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Giunchiglia%2C+F">Fausto Giunchiglia</a>, 
<a href="/search/cs?searchtype=author&query=Bagchi%2C+M">Mayukh Bagchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Information (iConference) 2024 - Wisdom, Well-being, Win-win - Springer LNCS, Springer Cham Switzerland
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Digital Libraries (cs.DL)

</div>
<p class="mathjax">Knowledge Representation (KR) and facet-analytical Knowledge Organization
(KO) have been the two most prominent methodologies of data and knowledge
modelling in the Artificial Intelligence community and the Information Science
community, respectively. KR boasts of a robust and scalable ecosystem of
technologies to support knowledge modelling while, often, underemphasizing the
quality of its models (and model-based data). KO, on the other hand, is less
technology-driven but has developed a robust framework of guiding principles
(canons) for ensuring modelling (and model-based data) quality. This paper
elucidates both the KR and facet-analytical KO methodologies in detail and
provides a functional mapping between them. Out of the mapping, the paper
proposes an integrated KO-enriched KR methodology with all the standard
components of a KR methodology plus the guiding canons of modelling quality
provided by KO. The practical benefits of the methodological integration has
been exemplified through a prominent case study of KR-based image annotation
exercise.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07305" title="Abstract">arXiv:2312.07305</a> [<a href="/pdf/2312.07305" title="Download PDF">pdf</a>, <a href="/format/2312.07305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCCA: Shifted Cross Chunk Attention for long contextual semantic  expansion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuxiang Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Sparse attention as a efficient method can significantly decrease the
computation cost, but current sparse attention tend to rely on window self
attention which block the global information flow. For this problem, we present
Shifted Cross Chunk Attention (SCCA), using different KV shifting strategy to
extend respective field in each attention layer. Except, we combine Dilated
Attention(DA) and Dilated Neighborhood Attention(DNA) to present Shifted
Dilated Attention(SDA). Both SCCA and SDA can accumulate attention results in
multi head attention to obtain approximate respective field in full attention.
In this paper, we conduct language modeling experiments using different pattern
of SCCA and combination of SCCA and SDA. The proposed shifted cross chunk
attention (SCCA) can effectively extend large language models (LLMs) to longer
context combined with Positional interpolation(PI) and LoRA than current sparse
attention. Notably, SCCA adopts LLaMA2 7B from 4k context to 8k in single V100.
This attention pattern can provide a Plug-and-play fine-tuning method to extend
model context while retaining their original architectures, and is compatible
with most existing techniques.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07311" title="Abstract">arXiv:2312.07311</a> [<a href="/pdf/2312.07311" title="Download PDF">pdf</a>, <a href="/format/2312.07311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Motion Style Transfer with Constrained Diffusion Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+W">Wenjie Yin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hang Yin</a>, 
<a href="/search/cs?searchtype=author&query=Kragic%2C+D">Danica Kragic</a>, 
<a href="/search/cs?searchtype=author&query=Bj%C3%B6rkman%2C+M">M&#xe5;rten Bj&#xf6;rkman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Current training of motion style transfer systems relies on consistency
losses across style domains to preserve contents, hindering its scalable
application to a large number of domains and private data. Recent image
transfer works show the potential of independent training on each domain by
leveraging implicit bridging between diffusion models, with the content
preservation, however, limited to simple data patterns. We address this by
imposing biased sampling in backward diffusion while maintaining the domain
independence in the training stage. We construct the bias from the source
domain keyframes and apply them as the gradient of content constraints,
yielding a framework with keyframe manifold constraint gradients (KMCGs). Our
validation demonstrates the success of training separate models to transfer
between as many as ten dance motion styles. Comprehensive experiments find a
significant improvement in preserving motion contents in comparison to baseline
and ablative diffusion-based style transfer models. In addition, we perform a
human study for a subjective assessment of the quality of generated dance
motions. The results validate the competitiveness of KMCGs.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07315" title="Abstract">arXiv:2312.07315</a> [<a href="/pdf/2312.07315" title="Download PDF">pdf</a>, <a href="/format/2312.07315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NVS-Adapter: Plug-and-Play Novel View Synthesis from a Single Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeong%2C+Y">Yoonwoo Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jinwoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Chiheon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+M">Minsu Cho</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Doyup Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://postech-cvlab.github.io/nvsadapter/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Transfer learning of large-scale Text-to-Image (T2I) models has recently
shown impressive potential for Novel View Synthesis (NVS) of diverse objects
from a single image. While previous methods typically train large models on
multi-view datasets for NVS, fine-tuning the whole parameters of T2I models not
only demands a high cost but also reduces the generalization capacity of T2I
models in generating diverse images in a new domain. In this study, we propose
an effective method, dubbed NVS-Adapter, which is a plug-and-play module for a
T2I model, to synthesize novel multi-views of visual objects while fully
exploiting the generalization capacity of T2I models. NVS-Adapter consists of
two main components; view-consistency cross-attention learns the visual
correspondences to align the local details of view features, and global
semantic conditioning aligns the semantic structure of generated views with the
reference view. Experimental results demonstrate that the NVS-Adapter can
effectively synthesize geometrically consistent multi-views and also achieve
high performance on benchmarks without full fine-tuning of T2I models. The code
and data are publicly available in
~\href{https://postech-cvlab.github.io/nvsadapter/}{https://postech-cvlab.github.io/nvsadapter/}.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07316" title="Abstract">arXiv:2312.07316</a> [<a href="/pdf/2312.07316" title="Download PDF">pdf</a>, <a href="/format/2312.07316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GateNet: A novel Neural Network Architecture for Automated Flow  Cytometry Gating
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fisch%2C+L">Lukas Fisch</a>, 
<a href="/search/cs?searchtype=author&query=Heming%2C+M+O">Michael O. Heming</a>, 
<a href="/search/cs?searchtype=author&query=Schulte-Mecklenbeck%2C+A">Andreas Schulte-Mecklenbeck</a>, 
<a href="/search/cs?searchtype=author&query=Gross%2C+C+C">Catharina C. Gross</a>, 
<a href="/search/cs?searchtype=author&query=Zumdick%2C+S">Stefan Zumdick</a>, 
<a href="/search/cs?searchtype=author&query=Barkhau%2C+C">Carlotta Barkhau</a>, 
<a href="/search/cs?searchtype=author&query=Emden%2C+D">Daniel Emden</a>, 
<a href="/search/cs?searchtype=author&query=Ernsting%2C+J">Jan Ernsting</a>, 
<a href="/search/cs?searchtype=author&query=Leenings%2C+R">Ramona Leenings</a>, 
<a href="/search/cs?searchtype=author&query=Sarink%2C+K">Kelvin Sarink</a>, 
<a href="/search/cs?searchtype=author&query=Winter%2C+N+R">Nils R. Winter</a>, 
<a href="/search/cs?searchtype=author&query=Dannlowski%2C+U">Udo Dannlowski</a>, 
<a href="/search/cs?searchtype=author&query=Wiendl%2C+H">Heinz Wiendl</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B6rste%2C+G+M+z">Gerd Meyer zu H&#xf6;rste</a>, 
<a href="/search/cs?searchtype=author&query=Hahn%2C+T">Tim Hahn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Flow cytometry is widely used to identify cell populations in patient-derived
fluids such as peripheral blood (PB) or cerebrospinal fluid (CSF). While
ubiquitous in research and clinical practice, flow cytometry requires gating,
i.e. cell type identification which requires labor-intensive and error-prone
manual adjustments. To facilitate this process, we designed GateNet, the first
neural network architecture enabling full end-to-end automated gating without
the need to correct for batch effects. We train GateNet with over 8,000,000
events based on N=127 PB and CSF samples which were manually labeled
independently by four experts. We show that for novel, unseen samples, GateNet
achieves human-level performance (F1 score ranging from 0.910 to 0.997). In
addition we apply GateNet to a publicly available dataset confirming
generalization with an F1 score of 0.936. As our implementation utilizes
graphics processing units (GPU), gating only needs 15 microseconds per event.
Importantly, we also show that GateNet only requires ~10 samples to reach
human-level performance, rendering it widely applicable in all domains of flow
cytometry.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07319" title="Abstract">arXiv:2312.07319</a> [<a href="/pdf/2312.07319" title="Download PDF">pdf</a>, <a href="/format/2312.07319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Top-Down Drawings of Compound Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kasperowski%2C+M">Maximilian Kasperowski</a>, 
<a href="/search/cs?searchtype=author&query=von+Hanxleden%2C+R">Reinhard von Hanxleden</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Bottom-up layout algorithms for compound graphs are suitable for presenting
the microscale view of models and are often used in model-driven engineering.
However, they have difficulties at the macroscale where maintaining the
overview of large models becomes challenging. We propose top-down layout, which
utilizes scale to hide low-level details at high zoom levels. The entire
high-level view can fit into the viewport and remain readable, while the
ability to zoom in to see the details is still maintained. Top-down layout is
an abstract high-level layout process that can be used in conjunction with
classic layout algorithms to produce visually compelling and readable diagrams
of large compound graphs.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07322" title="Abstract">arXiv:2312.07322</a> [<a href="/pdf/2312.07322" title="Download PDF">pdf</a>, <a href="/format/2312.07322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GenHowTo: Learning to Generate Actions and State Transformations from  Instructional Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sou%C4%8Dek%2C+T">Tom&#xe1;&#x161; Sou&#x10d;ek</a>, 
<a href="/search/cs?searchtype=author&query=Damen%2C+D">Dima Damen</a>, 
<a href="/search/cs?searchtype=author&query=Wray%2C+M">Michael Wray</a>, 
<a href="/search/cs?searchtype=author&query=Laptev%2C+I">Ivan Laptev</a>, 
<a href="/search/cs?searchtype=author&query=Sivic%2C+J">Josef Sivic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We address the task of generating temporally consistent and physically
plausible images of actions and object state transformations. Given an input
image and a text prompt describing the targeted transformation, our generated
images preserve the environment and transform objects in the initial image. Our
contributions are threefold. First, we leverage a large body of instructional
videos and automatically mine a dataset of triplets of consecutive frames
corresponding to initial object states, actions, and resulting object
transformations. Second, equipped with this data, we develop and train a
conditioned diffusion model dubbed GenHowTo. Third, we evaluate GenHowTo on a
variety of objects and actions and show superior performance compared to
existing methods. In particular, we introduce a quantitative evaluation where
GenHowTo achieves 88% and 74% on seen and unseen interaction categories,
respectively, outperforming prior work by a large margin.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07327" title="Abstract">arXiv:2312.07327</a> [<a href="/pdf/2312.07327" title="Download PDF">pdf</a>, <a href="/format/2312.07327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Confidence Multi-View Hashing for Multimedia Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jian Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yu Cui</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhangmin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+L">Lingfang Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+L">Li-Rong Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by International Conference on Acoustics, Speech and Signal Processing 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The multi-view hash method converts heterogeneous data from multiple views
into binary hash codes, which is one of the critical technologies in multimedia
retrieval. However, the current methods mainly explore the complementarity
among multiple views while lacking confidence learning and fusion. Moreover, in
practical application scenarios, the single-view data contain redundant noise.
To conduct the confidence learning and eliminate unnecessary noise, we propose
a novel Adaptive Confidence Multi-View Hashing (ACMVH) method. First, a
confidence network is developed to extract useful information from various
single-view features and remove noise information. Furthermore, an adaptive
confidence multi-view network is employed to measure the confidence of each
view and then fuse multi-view features through a weighted summation. Lastly, a
dilation network is designed to further enhance the feature representation of
the fused features. To the best of our knowledge, we pioneer the application of
confidence learning into the field of multimedia retrieval. Extensive
experiments on two public datasets show that the proposed ACMVH performs better
than state-of-the-art methods (maximum increase of 3.24%). The source code is
available at https://github.com/HackerHyper/ACMVH.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07330" title="Abstract">arXiv:2312.07330</a> [<a href="/pdf/2312.07330" title="Download PDF">pdf</a>, <a href="/format/2312.07330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learned representation-guided diffusion models for large-image  generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Graikos%2C+A">Alexandros Graikos</a>, 
<a href="/search/cs?searchtype=author&query=Yellapragada%2C+S">Srikar Yellapragada</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+M">Minh-Quan Le</a>, 
<a href="/search/cs?searchtype=author&query=Kapse%2C+S">Saarthak Kapse</a>, 
<a href="/search/cs?searchtype=author&query=Prasanna%2C+P">Prateek Prasanna</a>, 
<a href="/search/cs?searchtype=author&query=Saltz%2C+J">Joel Saltz</a>, 
<a href="/search/cs?searchtype=author&query=Samaras%2C+D">Dimitris Samaras</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">To synthesize high-fidelity samples, diffusion models typically require
auxiliary data to guide the generation process. However, it is impractical to
procure the painstaking patch-level annotation effort required in specialized
domains like histopathology and satellite imagery; it is often performed by
domain experts and involves hundreds of millions of patches. Modern-day
self-supervised learning (SSL) representations encode rich semantic and visual
information. In this paper, we posit that such representations are expressive
enough to act as proxies to fine-grained human labels. We introduce a novel
approach that trains diffusion models conditioned on embeddings from SSL. Our
diffusion models successfully project these features back to high-quality
histopathology and remote sensing images. In addition, we construct larger
images by assembling spatially consistent patches inferred from SSL embeddings,
preserving long-range dependencies. Augmenting real data by generating
variations of real images improves downstream classifier accuracy for
patch-level and larger, image-scale classification tasks. Our models are
effective even on datasets not encountered during training, demonstrating their
robustness and generalizability. Generating images from learned embeddings is
agnostic to the source of the embeddings. The SSL embeddings used to generate a
large image can either be extracted from a reference image, or sampled from an
auxiliary model conditioned on any related modality (e.g. class labels, text,
genomic data). As proof of concept, we introduce the text-to-large image
synthesis paradigm where we successfully synthesize large pathology and
satellite images out of text descriptions.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07331" title="Abstract">arXiv:2312.07331</a> [<a href="/pdf/2312.07331" title="Download PDF">pdf</a>, <a href="/format/2312.07331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coupled Confusion Correction: Learning from Crowds with Sparse  Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hansong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shikun Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+D">Dan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+C">Chenggang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+S">Shiming Ge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">As the size of the datasets getting larger, accurately annotating such
datasets is becoming more impractical due to the expensiveness on both time and
economy. Therefore, crowd-sourcing has been widely adopted to alleviate the
cost of collecting labels, which also inevitably introduces label noise and
eventually degrades the performance of the model. To learn from crowd-sourcing
annotations, modeling the expertise of each annotator is a common but
challenging paradigm, because the annotations collected by crowd-sourcing are
usually highly-sparse. To alleviate this problem, we propose Coupled Confusion
Correction (CCC), where two models are simultaneously trained to correct the
confusion matrices learned by each other. Via bi-level optimization, the
confusion matrices learned by one model can be corrected by the distilled data
from the other. Moreover, we cluster the ``annotator groups'' who share similar
expertise so that their confusion matrices could be corrected together. In this
way, the expertise of the annotators, especially of those who provide seldom
labels, could be better captured. Remarkably, we point out that the annotation
sparsity not only means the average number of labels is low, but also there are
always some annotators who provide very few labels, which is neglected by
previous works when constructing synthetic crowd-sourcing annotations. Based on
that, we propose to use Beta distribution to control the generation of the
crowd-sourcing labels so that the synthetic annotations could be more
consistent with the real-world ones. Extensive experiments are conducted on two
types of synthetic datasets and three real-world datasets, the results of which
demonstrate that CCC significantly outperforms state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07335" title="Abstract">arXiv:2312.07335</a> [<a href="/pdf/2312.07335" title="Download PDF">pdf</a>, <a href="/format/2312.07335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Momentum Particle Maximum Likelihood
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lim%2C+J+N">Jen Ning Lim</a>, 
<a href="/search/cs?searchtype=author&query=Kuntz%2C+J">Juan Kuntz</a>, 
<a href="/search/cs?searchtype=author&query=Power%2C+S">Samuel Power</a>, 
<a href="/search/cs?searchtype=author&query=Johansen%2C+A+M">Adam M. Johansen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Maximum likelihood estimation (MLE) of latent variable models is often recast
as an optimization problem over the extended space of parameters and
probability distributions. For example, the Expectation Maximization (EM)
algorithm can be interpreted as coordinate descent applied to a suitable free
energy functional over this space. Recently, this perspective has been combined
with insights from optimal transport and Wasserstein gradient flows to develop
particle-based algorithms applicable to wider classes of models than standard
EM.
<br />Drawing inspiration from prior works which interpret `momentum-enriched'
optimisation algorithms as discretizations of ordinary differential equations,
we propose an analogous dynamical systems-inspired approach to minimizing the
free energy functional over the extended space of parameters and probability
distributions. The result is a dynamic system that blends elements of
Nesterov's Accelerated Gradient method, the underdamped Langevin diffusion, and
particle methods.
<br />Under suitable assumptions, we establish quantitative convergence of the
proposed system to the unique minimiser of the functional in continuous time.
We then propose a numerical discretization of this system which enables its
application to parameter estimation in latent variable models. Through
numerical experiments, we demonstrate that the resulting algorithm converges
faster than existing methods and compares favourably with other (approximate)
MLE algorithms.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07337" title="Abstract">arXiv:2312.07337</a> [<a href="/pdf/2312.07337" title="Download PDF">pdf</a>, <a href="/format/2312.07337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RMS: Redundancy-Minimizing Point Cloud Sampling for Real-Time Pose  Estimation in Degenerated Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Petracek%2C+P">Pavel Petracek</a>, 
<a href="/search/cs?searchtype=author&query=Alexis%2C+K">Kostas Alexis</a>, 
<a href="/search/cs?searchtype=author&query=Saska%2C+M">Martin Saska</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE RA-L on December 1, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The typical point cloud sampling methods used in state estimation for mobile
robots preserve a high level of point redundancy. The point redundancy slows
down the estimation pipeline and can make real-time estimation drift in
geometrically symmetrical and structureless environments. We propose a novel
point cloud sampling method that is capable of lowering the effects of
geometrical degeneracies by minimizing redundancy within the cloud. The
proposed method is an alternative to the commonly used sparsification methods
that normalize the density of points to comply with the constraints on the
real-time capabilities of a robot. In contrast to density normalization, our
method builds on the fact that linear and planar surfaces contain a high level
of redundancy propagated into iterative estimation pipelines. We define the
concept of gradient flow quantifying the surface underlying a point. We also
show that maximizing the entropy of the gradient flow minimizes point
redundancy for robot ego-motion estimation. We integrate the proposed method
into the point-based KISS-ICP and feature-based LOAM odometry pipelines and
evaluate it experimentally on KITTI, Hilti-Oxford, and custom datasets from
multirotor UAVs. The experiments show that the proposed sampling technique
outperforms state-of-the-art methods in well-conditioned as well as in
geometrically-degenerated settings, in both accuracy and speed.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07338" title="Abstract">arXiv:2312.07338</a> [<a href="/pdf/2312.07338" title="Download PDF">pdf</a>, <a href="/format/2312.07338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Adaptive Pre-training of Multilingual Speech Models for  Language and Dialect Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaik%2C+M+M">Mohammed Maqsood Shaik</a>, 
<a href="/search/cs?searchtype=author&query=Klakow%2C+D">Dietrich Klakow</a>, 
<a href="/search/cs?searchtype=author&query=Abdullah%2C+B+M">Badr M. Abdullah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Pre-trained Transformer-based speech models have shown striking performance
when fine-tuned on various downstream tasks such as automatic speech
recognition and spoken language identification (SLID). However, the problem of
domain mismatch remains a challenge in this area, where the domain of the
pre-training data might differ from that of the downstream labeled data used
for fine-tuning. In multilingual tasks such as SLID, the pre-trained speech
model may not support all the languages in the downstream task. To address this
challenge, we propose self-supervised adaptive pre-training (SAPT) to adapt the
pre-trained model to the target domain and languages of the downstream task. We
apply SAPT to the XLSR-128 model and investigate the effectiveness of this
approach for the SLID task. First, we demonstrate that SAPT improves XLSR
performance on the FLEURS benchmark with substantial gains up to 40.1% for
under-represented languages. Second, we apply SAPT on four different datasets
in a few-shot learning setting, showing that our approach improves the sample
efficiency of XLSR during fine-tuning. Our experiments provide strong empirical
evidence that continual adaptation via self-supervision improves downstream
performance for multilingual speech models.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07340" title="Abstract">arXiv:2312.07340</a> [<a href="/pdf/2312.07340" title="Download PDF">pdf</a>, <a href="/format/2312.07340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MuscleVAE: Model-Based Controllers of Muscle-Actuated Characters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yusen Feng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiyan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Libin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">In this paper, we present a simulation and control framework for generating
biomechanically plausible motion for muscle-actuated characters. We incorporate
a fatigue dynamics model, the 3CC-r model, into the widely-adopted Hill-type
muscle model to simulate the development and recovery of fatigue in muscles,
which creates a natural evolution of motion style caused by the accumulation of
fatigue from prolonged activities. To address the challenging problem of
controlling a musculoskeletal system with high degrees of freedom, we propose a
novel muscle-space control strategy based on PD control. Our simulation and
control framework facilitates the training of a generative model for
muscle-based motion control, which we refer to as MuscleVAE. By leveraging the
variational autoencoders (VAEs), MuscleVAE is capable of learning a rich and
flexible latent representation of skills from a large unstructured motion
dataset, encoding not only motion features but also muscle control and fatigue
properties. We demonstrate that the MuscleVAE model can be efficiently trained
using a model-based approach, resulting in the production of high-fidelity
motions and enabling a variety of downstream tasks.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07342" title="Abstract">arXiv:2312.07342</a> [<a href="/pdf/2312.07342" title="Download PDF">pdf</a>, <a href="/format/2312.07342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expand-and-Quantize: Unsupervised Semantic Segmentation Using  High-Dimensional Space and Product Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jiyoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Shim%2C+K">Kyuhong Shim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+I">Insu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Shim%2C+B">Byonghyo Shim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unsupervised semantic segmentation (USS) aims to discover and recognize
meaningful categories without any labels. For a successful USS, two key
abilities are required: 1) information compression and 2) clustering
capability. Previous methods have relied on feature dimension reduction for
information compression, however, this approach may hinder the process of
clustering. In this paper, we propose a novel USS framework called
Expand-and-Quantize Unsupervised Semantic Segmentation (EQUSS), which combines
the benefits of high-dimensional spaces for better clustering and product
quantization for effective information compression. Our extensive experiments
demonstrate that EQUSS achieves state-of-the-art results on three standard
benchmarks. In addition, we analyze the entropy of USS features, which is the
first step towards understanding USS from the perspective of information
theory.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07343" title="Abstract">arXiv:2312.07343</a> [<a href="/pdf/2312.07343" title="Download PDF">pdf</a>, <a href="/ps/2312.07343" title="Download PostScript">ps</a>, <a href="/format/2312.07343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can ChatGPT Play the Role of a Teaching Assistant in an Introductory  Programming Course?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anishka">Anishka</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+A">Atharva Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+N">Nipun Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+D">Dhruv Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Jalote%2C+P">Pankaj Jalote</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The emergence of Large language models (LLMs) is expected to have a major
impact on education. This paper explores the potential of using ChatGPT, an
LLM, as a virtual Teaching Assistant (TA) in an Introductory Programming
Course. We evaluate ChatGPT's capabilities by comparing its performance with
that of human TAs in some TA functions. The TA functions which we focus on
include (1) solving programming assignments, (2) grading student code
submissions, and (3) providing feedback to undergraduate students in an
introductory programming course. Firstly, we investigate how closely ChatGPT's
solutions align with those submitted by students. This analysis goes beyond
code correctness and also considers code quality. Secondly, we assess ChatGPT's
proficiency in grading student code submissions using a given grading rubric
and compare its performance with the grades assigned by human TAs. Thirdly, we
analyze the quality and relevance of the feedback provided by ChatGPT. This
evaluation considers how well ChatGPT addresses mistakes and offers suggestions
for improvement in student solutions from both code correctness and code
quality perspectives. We conclude with a discussion on the implications of
integrating ChatGPT into computing education for automated grading,
personalized learning experiences, and instructional support.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07345" title="Abstract">arXiv:2312.07345</a> [<a href="/pdf/2312.07345" title="Download PDF">pdf</a>, <a href="/format/2312.07345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Differentiable Integral Control Barrier Functions for Unknown  Nonlinear Systems with Input Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zinage%2C+V">Vrushabh Zinage</a>, 
<a href="/search/eess?searchtype=author&query=Chandra%2C+R">Rohan Chandra</a>, 
<a href="/search/eess?searchtype=author&query=Bakolas%2C+E">Efstathios Bakolas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, we propose a deep learning based control synthesis framework
for fast and online computation of controllers that guarantees the safety of
general nonlinear control systems with unknown dynamics in the presence of
input constraints. Towards this goal, we propose a framework for simultaneously
learning the unknown system dynamics, which can change with time due to
external disturbances, and an integral control law for trajectory tracking
based on imitation learning. Simultaneously, we learn corresponding safety
certificates, which we refer to as Neural Integral Control Barrier Functions
(Neural ICBF's), that automatically encode both the state and input constraints
into a single scalar-valued function and enable the design of controllers that
can guarantee that the state of the unknown system will never leave a safe
subset of the state space. Finally, we provide numerical simulations that
validate our proposed approach and compare it with classical as well as recent
learning based methods from the relevant literature.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07348" title="Abstract">arXiv:2312.07348</a> [<a href="/pdf/2312.07348" title="Download PDF">pdf</a>, <a href="/format/2312.07348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;It doesn&#x27;t tell me anything about how my data is used&#x27;&#x27;: User  Perceptions of Data Collection Purposes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kyi%2C+L">Lin Kyi</a>, 
<a href="/search/cs?searchtype=author&query=Mhaidli%2C+A">Abraham Mhaidli</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+C">Cristiana Santos</a>, 
<a href="/search/cs?searchtype=author&query=Roesner%2C+F">Franziska Roesner</a>, 
<a href="/search/cs?searchtype=author&query=Biega%2C+A">Asia Biega</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Data collection purposes and their descriptions are presented on almost all
privacy notices under the GDPR, yet there is a lack of research focusing on how
effective they are at informing users about data practices. We fill this gap by
investigating users' perceptions of data collection purposes and their
descriptions, a crucial aspect of informed consent. We conducted 23
semi-structured interviews with European users to investigate user perceptions
of six common purposes (Strictly Necessary, Statistics and Analytics,
Performance and Functionality, Marketing and Advertising, Personalized
Advertising, and Personalized Content) and identified elements of an effective
purpose name and description.
<br />We found that most purpose descriptions do not contain the information users
wish to know, and that participants preferred some purpose names over others
due to their perceived transparency or ease of understanding. Based on these
findings, we suggest how the framing of purposes can be improved toward
meaningful informed consent.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07349" title="Abstract">arXiv:2312.07349</a> [<a href="/pdf/2312.07349" title="Download PDF">pdf</a>, <a href="/format/2312.07349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A discontinuous Galerkin / cohesive zone model approach for the  computational modeling of fracture in geometrically exact slender beams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kota%2C+S+K">Sai Kubair Kota</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Siddhant Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Giovanardi%2C+B">Bianca Giovanardi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Mathematical Physics (math-ph)

</div>
<p class="mathjax">Slender beams are often employed as constituents in engineering materials and
structures. Prior experiments on lattices of slender beams have highlighted
their complex failure response, where the interplay between buckling and
fracture plays a critical role. In this paper, we introduce a novel
computational approach for modeling fracture in slender beams subjected to
large deformations. We adopt a state-of-the-art geometrically exact Kirchhoff
beam formulation to describe the finite deformations of beams in
three-dimensions. We develop a discontinuous Galerkin finite element
discretization of the beam governing equations, incorporating discontinuities
in the position and tangent degrees of freedom at the inter-element boundaries
of the finite elements. Before fracture initiation, we enforce compatibility of
nodal positions and tangents weakly, via the exchange of
variationally-consistent forces and moments at the interfaces between adjacent
elements. At the onset of fracture, these forces and moments transition to
cohesive laws modeling interface failure. We conduct a series of numerical
tests to verify our computational framework against a set of benchmarks and we
demonstrate its ability to capture the tensile and bending fracture modes in
beams exhibiting large deformations. Finally, we present the validation of our
framework against fracture experiments of dry spaghetti rods subjected to
sudden relaxation of curvature.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07352" title="Abstract">arXiv:2312.07352</a> [<a href="/pdf/2312.07352" title="Download PDF">pdf</a>, <a href="/format/2312.07352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CholecTrack20: A Dataset for Multi-Class Multiple Tool Tracking in  Laparoscopic Surgery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nwoye%2C+C+I">Chinedu Innocent Nwoye</a>, 
<a href="/search/cs?searchtype=author&query=Elgohary%2C+K">Kareem Elgohary</a>, 
<a href="/search/cs?searchtype=author&query=Srinivas%2C+A">Anvita Srinivas</a>, 
<a href="/search/cs?searchtype=author&query=Zaid%2C+F">Fauzan Zaid</a>, 
<a href="/search/cs?searchtype=author&query=Lavanchy%2C+J+L">Jo&#xeb;l L. Lavanchy</a>, 
<a href="/search/cs?searchtype=author&query=Padoy%2C+N">Nicolas Padoy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Surgical tool tracking dataset paper, 15 pages, 9 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Tool tracking in surgical videos is vital in computer-assisted intervention
for tasks like surgeon skill assessment, safety zone estimation, and
human-machine collaboration during minimally invasive procedures. The lack of
large-scale datasets hampers Artificial Intelligence implementation in this
domain. Current datasets exhibit overly generic tracking formalization, often
lacking surgical context: a deficiency that becomes evident when tools move out
of the camera's scope, resulting in rigid trajectories that hinder realistic
surgical representation. This paper addresses the need for a more precise and
adaptable tracking formalization tailored to the intricacies of endoscopic
procedures by introducing CholecTrack20, an extensive dataset meticulously
annotated for multi-class multi-tool tracking across three perspectives
representing the various ways of considering the temporal duration of a tool
trajectory: (1) intraoperative, (2) intracorporeal, and (3) visibility within
the camera's scope. The dataset comprises 20 laparoscopic videos with over
35,000 frames and 65,000 annotated tool instances with details on spatial
location, category, identity, operator, phase, and surgical visual conditions.
This detailed dataset caters to the evolving assistive requirements within a
procedure.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07353" title="Abstract">arXiv:2312.07353</a> [<a href="/pdf/2312.07353" title="Download PDF">pdf</a>, <a href="/format/2312.07353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIP in Medical Imaging: A Comprehensive Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zihao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuxiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Han Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yonghao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+L">Lin Teng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Disheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zhiming Cui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+D">Dinggang Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> * These authors contributed equally. Project page available at <a href="https://github.com/zhaozh10/Awesome-CLIP-in-Medical-Imaging">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Contrastive Language-Image Pre-training (CLIP), a straightforward yet
effective pre-training paradigm, successfully introduces semantic-rich text
supervision to vision models and has demonstrated promising results in various
tasks due to its generalizability and interpretability. It has recently gained
increasing interest in the medical imaging domain, either as a powerful
pre-training paradigm for medical vision language alignment or a pre-trained
key component for various clinical tasks. With the aim of facilitating a deeper
understanding of this promising direction, this survey offers an in-depth
exploration of the CLIP paradigm within the domain of medical imaging,
regarding both refined CLIP pre-training and CLIP-driven applications. Our
survey (1) starts with a brief introduction to the fundamentals of CLIP
methodology. (2) Then, we investigate the adaptation of CLIP pre-training in
the medical domain, focusing on how to optimize CLIP given characteristics of
medical images and reports. (3) Furthermore, we explore the practical
utilization of CLIP pre-trained models in various tasks, including
classification, dense prediction, and cross-modal tasks. (4) Finally, we
discuss existing limitations of CLIP in the context of medical imaging and
propose forward-looking directions to address the demands of medical imaging
domain. We expect that this comprehensive survey will provide researchers in
the field of medical image analysis with a holistic understanding of the CLIP
paradigm and its potential implications. The project page is available at
https://github.com/zhaozh10/Awesome-CLIP-in-Medical-Imaging, which will be
regularly updated.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07355" title="Abstract">arXiv:2312.07355</a> [<a href="/pdf/2312.07355" title="Download PDF">pdf</a>, <a href="/format/2312.07355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MRCN: Enhanced Coherence Mechanism for Near Memory Processing  Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kabat%2C+A+K">Amit Kumar Kabat</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+S">Shubhang Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Venkatesh%2C+T">TG Venkatesh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">In Near Memory Processing (NMP), processing elements(PEs) are placed near the
3D memory, reducing unnecessary data transfers between the CPU and the memory.
However, as the CPUs and the PEs of the NMP use a shared memory space,
maintaining coherency between them is a challenge. Most current literature
relies on maintaining coherence for fine-grained or coarse-grained instruction
granularities for the offloaded code blocks. We understand that for most
NMP-offloaded instructions, the coherence conflict is low, and waiting for the
coherence transaction hinders the performance. We construct an analytical model
for an existing coherence strategy called CONDA, which is within 4% accuracy.
This model indicates the key parameters responsible - the granularity of
offloaded code, probability of conflicts, transaction times, and commit time.
This paper identifies the prospective optimizations using the analytical model
for CONDA. It proposes a new coherence scheme called MRCN: Monitored Rollback
Coherence for NMP. MRCN addresses the coherence issue while eliminating
unnecessary re-executions with limited hardware overhead. The MRCN is evaluated
on synthetic as well as Rodinia benchmarks. The analytical results are within
4% accuracy of the simulation results. The MRCN shows improvement of upto 25%
over CONDA strategy for the same benchmark under different execution
conditions.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07357" title="Abstract">arXiv:2312.07357</a> [<a href="/pdf/2312.07357" title="Download PDF">pdf</a>, <a href="/format/2312.07357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic coral reef fish identification and 3D measurement in the wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barrelet%2C+C">Cyril Barrelet</a>, 
<a href="/search/cs?searchtype=author&query=Chaumont%2C+M">Marc Chaumont</a>, 
<a href="/search/cs?searchtype=author&query=Subsol%2C+G">G&#xe9;rard Subsol</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is in its draft version and should be improved in order to be published. This paper is issued from one Year of Engineering work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper we present a pipeline using stereo images in order to
automatically identify, track in 3D fish, and measure fish population.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07359" title="Abstract">arXiv:2312.07359</a> [<a href="/pdf/2312.07359" title="Download PDF">pdf</a>, <a href="/format/2312.07359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feedback-feedforward Signal Control with Exogenous Demand Estimation in  Congested Urban Road Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pedroso%2C+L">Leonardo Pedroso</a>, 
<a href="/search/eess?searchtype=author&query=Batista%2C+P">Pedro Batista</a>, 
<a href="/search/eess?searchtype=author&query=Papageorgiou%2C+M">Markos Papageorgiou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">To cope with varying and highly uncertain traffic patterns, a novel
network-wide traffic signal control strategy based on the store-and-forward
model of a traffic network is proposed. On one hand, making use of a single
loop detector in each road link, we develop an estimation solution for both the
link occupancy and the net exogenous demand in every road link of a network. On
the other hand, borrowing from optimal control theory, we design an optimal
linear quadratic control scheme, consisting of a linear feedback term, of the
occupancy of the road links, and a feedforward component, which accounts for
the varying exogenous vehicle load on the network. Thereby, the resulting
control scheme is a simple feedback-feedforward controller, which is fed with
occupancy and exogenous demand estimates, and is suitable for real-time
implementation. Numerical simulations of the urban traffic network of Chania,
Greece, show that, for realistic surges in the exogenous demand, the proposed
solution significantly outperforms tried-and-tested solutions that ignore the
exogenous demand.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07360" title="Abstract">arXiv:2312.07360</a> [<a href="/pdf/2312.07360" title="Download PDF">pdf</a>, <a href="/format/2312.07360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Latent Diffusion with Flow Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fischer%2C+J+S">Johannes S. Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+M">Ming Gui</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+P">Pingchuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Stracke%2C+N">Nick Stracke</a>, 
<a href="/search/cs?searchtype=author&query=Baumann%2C+S+A">Stefan A. Baumann</a>, 
<a href="/search/cs?searchtype=author&query=Ommer%2C+B">Bj&#xf6;rn Ommer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, there has been tremendous progress in visual synthesis and the
underlying generative models. Here, diffusion models (DMs) stand out
particularly, but lately, flow matching (FM) has also garnered considerable
interest. While DMs excel in providing diverse images, they suffer from long
training and slow generation. With latent diffusion, these issues are only
partially alleviated. Conversely, FM offers faster training and inference but
exhibits less diversity in synthesis. We demonstrate that introducing FM
between the Diffusion model and the convolutional decoder offers
high-resolution image synthesis with reduced computational cost and model size.
Diffusion can then efficiently provide the necessary generation diversity. FM
compensates for the lower resolution, mapping the small latent space to a
high-dimensional one. Subsequently, the convolutional decoder of the LDM maps
these latents to high-resolution images. By combining the diversity of DMs, the
efficiency of FMs, and the effectiveness of convolutional decoders, we achieve
state-of-the-art high-resolution image synthesis at $1024^2$ with minimal
computational cost. Importantly, our approach is orthogonal to recent
approximation and speed-up strategies for the underlying DMs, making it easily
integrable into various DM frameworks.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07362" title="Abstract">arXiv:2312.07362</a> [<a href="/pdf/2312.07362" title="Download PDF">pdf</a>, <a href="/format/2312.07362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligible Protocol Learning for Resource Allocation in 6G O-RAN  Slicing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rezazadeh%2C+F">Farhad Rezazadeh</a>, 
<a href="/search/cs?searchtype=author&query=Chergui%2C+H">Hatim Chergui</a>, 
<a href="/search/cs?searchtype=author&query=Siddiqui%2C+S">Shuaib Siddiqui</a>, 
<a href="/search/cs?searchtype=author&query=Mangues%2C+J">Josep Mangues</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Houbing Song</a>, 
<a href="/search/cs?searchtype=author&query=Saad%2C+W">Walid Saad</a>, 
<a href="/search/cs?searchtype=author&query=Bennis%2C+M">Mehdi Bennis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">An adaptive standardized protocol is essential for addressing inter-slice
resource contention and conflict in network slicing. Traditional protocol
standardization is a cumbersome task that yields hardcoded predefined
protocols, resulting in increased costs and delayed rollout. Going beyond these
limitations, this paper proposes a novel multi-agent deep reinforcement
learning (MADRL) communication framework called standalone explainable protocol
(STEP) for future sixth-generation (6G) open radio access network (O-RAN)
slicing. As new conditions arise and affect network operation, resource
orchestration agents adapt their communication messages to promote the
emergence of a protocol on-the-fly, which enables the mitigation of conflict
and resource contention between network slices. STEP weaves together the notion
of information bottleneck (IB) theory with deep Q-network (DQN) learning
concepts. By incorporating a stochastic bottleneck layer -- inspired by
variational autoencoders (VAEs) -- STEP imposes an information-theoretic
constraint for emergent inter-agent communication. This ensures that agents
exchange concise and meaningful information, preventing resource waste and
enhancing the overall system performance. The learned protocols enhance
interpretability, laying a robust foundation for standardizing next-generation
6G networks. By considering an O-RAN compliant network slicing resource
allocation problem, a conflict resolution protocol is developed. In particular,
the results demonstrate that, on average, STEP reduces inter-slice conflicts by
up to 6.06x compared to a predefined protocol method. Furthermore, in
comparison with an MADRL baseline, STEP achieves 1.4x and 3.5x lower resource
underutilization and latency, respectively.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07364" title="Abstract">arXiv:2312.07364</a> [<a href="/pdf/2312.07364" title="Download PDF">pdf</a>, <a href="/format/2312.07364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collapse-Oriented Adversarial Training with Triplet Decoupling for  Robust Image Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qiwei Tian</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chenhao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qian Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhengyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chao Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Adversarial training has achieved substantial performance in defending image
retrieval systems against adversarial examples. However, existing studies still
suffer from two major limitations: model collapse and weak adversary. This
paper addresses these two limitations by proposing collapse-oriented (COLO)
adversarial training with triplet decoupling (TRIDE). Specifically, COLO
prevents model collapse by temporally orienting the perturbation update
direction with a new collapse metric, while TRIDE yields a strong adversary by
spatially decoupling the update targets of perturbation into the anchor and the
two candidates of a triplet. Experimental results demonstrate that our
COLO-TRIDE outperforms the current state of the art by 7% on average over 10
robustness metrics and across 3 popular datasets. In addition, we identify the
fairness limitations of commonly used robustness metrics in image retrieval and
propose a new metric for more meaningful robustness evaluation. Codes will be
made publicly available on GitHub.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07368" title="Abstract">arXiv:2312.07368</a> [<a href="/pdf/2312.07368" title="Download PDF">pdf</a>, <a href="/ps/2312.07368" title="Download PostScript">ps</a>, <a href="/format/2312.07368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sequential Planning in Large Partially Observable Environments guided by  LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paul%2C+S+K">Swarna Kamal Paul</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Sequential planning in large state space and action space quickly becomes
intractable due to combinatorial explosion of the search space. Heuristic
methods, like monte-carlo tree search, though effective for large state space,
but struggle if action space is large. Pure reinforcement learning methods,
relying only on reward signals, needs prohibitively large interactions with the
environment to device a viable plan. If the state space, observations and
actions can be represented in natural language then Large Language models (LLM)
can be used to generate action plans. Recently several such goal-directed
agents like Reflexion, CLIN, SayCan were able to surpass the performance of
other state-of-the-art methods with minimum or no task specific training. But
they still struggle with exploration and get stuck in local optima. Their
planning capabilities are limited by the limited reasoning capability of the
foundational LLMs on text data. We propose a hybrid agent "neoplanner", that
synergizes both state space search with queries to foundational LLM to get the
best action plan. The reward signals are quantitatively used to drive the
search. A balance of exploration and exploitation is maintained by maximizing
upper confidence bounds of values of states. In places where random exploration
is needed, the LLM is queried to generate an action plan. Learnings from each
trial are stored as entity relationships in text format. Those are used in
future queries to the LLM for continual improvement. Experiments in the
Scienceworld environment reveals a 124% improvement from the current best
method in terms of average reward gained across multiple tasks.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07370" title="Abstract">arXiv:2312.07370</a> [<a href="/pdf/2312.07370" title="Download PDF">pdf</a>, <a href="/format/2312.07370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Semi-Supervised Domain Adaptation for Semantic Segmentation:  A New Role for Labeled Target Samples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kechaou%2C+M">Marwa Kechaou</a>, 
<a href="/search/cs?searchtype=author&query=Alaya%2C+M+Z">Mokhtar Z. Alaya</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%A9rault%2C+R">Romain H&#xe9;rault</a>, 
<a href="/search/cs?searchtype=author&query=Gasso%2C+G">Gilles Gasso</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Adversarial learning baselines for domain adaptation (DA) approaches in the
context of semantic segmentation are under explored in semi-supervised
framework. These baselines involve solely the available labeled target samples
in the supervision loss. In this work, we propose to enhance their usefulness
on both semantic segmentation and the single domain classifier neural networks.
We design new training objective losses for cases when labeled target data
behave as source samples or as real target samples. The underlying rationale is
that considering the set of labeled target samples as part of source domain
helps reducing the domain discrepancy and, hence, improves the contribution of
the adversarial loss. To support our approach, we consider a complementary
method that mixes source and labeled target data, then applies the same
adaptation process. We further propose an unsupervised selection procedure
using entropy to optimize the choice of labeled target samples for adaptation.
We illustrate our findings through extensive experiments on the benchmarks
GTA5, SYNTHIA, and Cityscapes. The empirical evaluation highlights competitive
performance of our proposed approach.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07371" title="Abstract">arXiv:2312.07371</a> [<a href="/pdf/2312.07371" title="Download PDF">pdf</a>, <a href="/format/2312.07371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Aware Energy Consumption Modeling of Connected Battery Electric  Vehicles using Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Sen Yan</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+H">Hongyuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Ji Li</a>, 
<a href="/search/cs?searchtype=author&query=Ward%2C+T">Tomas Ward</a>, 
<a href="/search/cs?searchtype=author&query=O%27Connor%2C+N">Noel O&#x27;Connor</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingming Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by IEEE Transactions on Transportation Electrification (TTE) on December 4, 2023. (13 pages, 6 figures, and 6 tables)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Battery Electric Vehicles (BEVs) are increasingly significant in modern
cities due to their potential to reduce air pollution. Precise and real-time
estimation of energy consumption for them is imperative for effective itinerary
planning and optimizing vehicle systems, which can reduce driving range anxiety
and decrease energy costs. As public awareness of data privacy increases,
adopting approaches that safeguard data privacy in the context of BEV energy
consumption modeling is crucial. Federated Learning (FL) is a promising
solution mitigating the risk of exposing sensitive information to third parties
by allowing local data to remain on devices and only sharing model updates with
a central server. Our work investigates the potential of using FL methods, such
as FedAvg, and FedPer, to improve BEV energy consumption prediction while
maintaining user privacy. We conducted experiments using data from 10 BEVs
under simulated real-world driving conditions. Our results demonstrate that the
FedAvg-LSTM model achieved a reduction of up to 67.84\% in the MAE value of the
prediction results. Furthermore, we explored various real-world scenarios and
discussed how FL methods can be employed in those cases. Our findings show that
FL methods can effectively improve the performance of BEV energy consumption
prediction while maintaining user privacy.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07374" title="Abstract">arXiv:2312.07374</a> [<a href="/pdf/2312.07374" title="Download PDF">pdf</a>, <a href="/format/2312.07374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relax Image-Specific Prompt Requirement in SAM: A Single Generic Prompt  for Segmenting Camouflaged Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jian Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiayi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Weitong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+S">Shaogang Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Camouflaged object detection (COD) approaches heavily rely on pixel-level
annotated datasets. Weakly-supervised COD (WSCOD) approaches use sparse
annotations like scribbles or points to reduce annotation effort, but this can
lead to decreased accuracy. The Segment Anything Model (SAM) shows remarkable
segmentation ability with sparse prompts like points. However, manual prompt is
not always feasible, as it may not be accessible in real-world application.
Additionally, it only provides localization information instead of semantic
one, which can intrinsically cause ambiguity in interpreting the targets. In
this work, we aim to eliminate the need for manual prompt. The key idea is to
employ Cross-modal Chains of Thought Prompting (CCTP) to reason visual prompts
using the semantic information given by a generic text prompt.To that end, we
introduce a test-time adaptation per-instance mechanism called Generalizable
SAM (GenSAM) to automatically enerate and optimize visual prompts the generic
task prompt for WSCOD. In particular, CCTP maps a single generic text prompt
onto image-specific consensus foreground and background heatmaps using
vision-language models, acquiring reliable visual prompts. Moreover, to
test-time adapt the visual prompts, we further propose Progressive Mask
Generation (PMG) to iteratively reweight the input image, guiding the model to
focus on the targets in a coarse-to-fine manner. Crucially, all network
parameters are fixed, avoiding the need for additional training. Experiments
demonstrate the superiority of GenSAM. Experiments on three benchmarks
demonstrate that GenSAM outperforms point supervision approaches and achieves
comparable results to scribble supervision ones, solely relying on general task
descriptions as prompts. our codes is in: https://lwpyh.github.io/GenSAM/.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07378" title="Abstract">arXiv:2312.07378</a> [<a href="/pdf/2312.07378" title="Download PDF">pdf</a>, <a href="/format/2312.07378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> X4D-SceneFormer: Enhanced Scene Understanding on 4D Point Cloud Videos  through Cross-modal Knowledge Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jing%2C+L">Linglin Jing</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Y">Ying Xue</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chaoda Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruimao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhigang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+H">Hui Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhen Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The field of 4D point cloud understanding is rapidly developing with the goal
of analyzing dynamic 3D point cloud sequences. However, it remains a
challenging task due to the sparsity and lack of texture in point clouds.
Moreover, the irregularity of point cloud poses a difficulty in aligning
temporal information within video sequences. To address these issues, we
propose a novel cross-modal knowledge transfer framework, called
X4D-SceneFormer. This framework enhances 4D-Scene understanding by transferring
texture priors from RGB sequences using a Transformer architecture with
temporal relationship mining. Specifically, the framework is designed with a
dual-branch architecture, consisting of an 4D point cloud transformer and a
Gradient-aware Image Transformer (GIT). During training, we employ multiple
knowledge transfer techniques, including temporal consistency losses and masked
self-attention, to strengthen the knowledge transfer between modalities. This
leads to enhanced performance during inference using single-modal 4D point
cloud inputs. Extensive experiments demonstrate the superior performance of our
framework on various 4D point cloud video understanding tasks, including action
recognition, action segmentation and semantic segmentation. The results achieve
1st places, i.e., 85.3% (+7.9%) accuracy and 47.3% (+5.0%) mIoU for 4D action
segmentation and semantic segmentation, on the HOI4D
challenge\footnote{\url{<a href="http://www.hoi4d.top/">this http URL</a>}.}, outperforming previous
state-of-the-art by a large margin. We release the code at
https://github.com/jinglinglingling/X4D
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07381" title="Abstract">arXiv:2312.07381</a> [<a href="/pdf/2312.07381" title="Download PDF">pdf</a>, <a href="/format/2312.07381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ScribblePrompt: Fast and Flexible Interactive Segmentation for Any  Medical Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wong%2C+H+E">Hallee E. Wong</a>, 
<a href="/search/cs?searchtype=author&query=Rakic%2C+M">Marianne Rakic</a>, 
<a href="/search/cs?searchtype=author&query=Guttag%2C+J">John Guttag</a>, 
<a href="/search/cs?searchtype=author&query=Dalca%2C+A+V">Adrian V. Dalca</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Website: <a href="https://scribbleprompt.csail.mit.edu">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Semantic medical image segmentation is a crucial part of both scientific
research and clinical care. With enough labelled data, deep learning models can
be trained to accurately automate specific medical image segmentation tasks.
However, manually segmenting images to create training data is highly labor
intensive. In this paper, we present ScribblePrompt, an interactive
segmentation framework for medical imaging that enables human annotators to
segment unseen structures using scribbles, clicks, and bounding boxes.
Scribbles are an intuitive and effective form of user interaction for complex
tasks, however most existing methods focus on click-based interactions. We
introduce algorithms for simulating realistic scribbles that enable training
models that are amenable to multiple types of interaction. To achieve
generalization to new tasks, we train on a diverse collection of 65 open-access
biomedical datasets -- using both real and synthetic labels. We test
ScribblePrompt on multiple network architectures and unseen datasets, and
demonstrate that it can be used in real-time on a single CPU. We evaluate
ScribblePrompt using manually-collected scribbles, simulated interactions, and
a user study. ScribblePrompt outperforms existing methods in all our
evaluations. In the user study, ScribblePrompt reduced annotation time by 28%
while improving Dice by 15% compared to existing methods. We showcase
ScribblePrompt in an online demo and provide code at
https://scribbleprompt.csail.mit.edu
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07382" title="Abstract">arXiv:2312.07382</a> [<a href="/pdf/2312.07382" title="Download PDF">pdf</a>, <a href="/format/2312.07382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous driving of trucks in off-road environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Caldas%2C+K+A+Q">Kenny A. Q. Caldas</a>, 
<a href="/search/eess?searchtype=author&query=Barbosa%2C+F+M">Filipe M. Barbosa</a>, 
<a href="/search/eess?searchtype=author&query=Silva%2C+J+A+R">Junior A. R. Silva</a>, 
<a href="/search/eess?searchtype=author&query=Santos%2C+T+C">Tiago C. Santos</a>, 
<a href="/search/eess?searchtype=author&query=Gomes%2C+I+P">Iago P. Gomes</a>, 
<a href="/search/eess?searchtype=author&query=Rosero%2C+L+A">Luis A. Rosero</a>, 
<a href="/search/eess?searchtype=author&query=Wolf%2C+D+F">Denis F. Wolf</a>, 
<a href="/search/eess?searchtype=author&query=Grassi%2C+V">Valdir Grassi Jr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted at Journal of Control, Automation and Electrical Systems
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Control, Automation and Electrical Systems, volume 34,
  pages 1179-1193 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Off-road driving operations can be a challenging environment for human
conductors as they are subject to accidents, repetitive and tedious tasks,
strong vibrations, which may affect their health in the long term. Therefore,
they can benefit from a successful implementation of autonomous vehicle
technology, improving safety, reducing labor costs and fuel consumption, and
increasing operational efficiency. The main contribution of this paper is the
experimental validation of a path tracking control strategy, composed of
longitudinal and lateral controllers, on an off-road scenario with a
fully-loaded heavy-duty truck. The longitudinal control strategy relies on a
Non-Linear Model Predictive Controller (NMPC), which considers the path
geometry and simplified vehicle dynamics to compute a smooth and comfortable
input velocity, without violating the imposed constraints. The lateral
controller is based on a Robust Linear Quadratic Regulator (RLQR), which
considers a vehicle model subject to parametric uncertainties to minimize its
lateral displacement and heading error, as well as ensure stability.
Experiments were carried out using a fully-loaded vehicle on unpaved roads in
an open-pit mine. The truck followed the reference path within the imposed
constraints, showing robustness and driving smoothness.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07383" title="Abstract">arXiv:2312.07383</a> [<a href="/pdf/2312.07383" title="Download PDF">pdf</a>, <a href="/ps/2312.07383" title="Download PostScript">ps</a>, <a href="/format/2312.07383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Delay analysis of the IEEE 802.11bd EDCA with repetitions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+A">Aditya Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Manjunath%2C+S">Sreelakshmi Manjunath</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">We analyse the performance of the IEEE 802.11bd MAC protocol, with Enhanced
Distributed Channel Access (EDCA) and repeated transmissions, in terms of the
MAC access delay of packets pertaining to safety-related events. We outline
Markov chain models for the contention mechanism of priority-based access
categories, and derive the associated steady-state probabilities. Using these
probabilities, we characterise the delay experienced by the packet in the MAC
layer. Further, we characterise the reliability of the protocol in terms of the
likelihood that a packet is delivered within a critical time interval.
Numerical computations are conducted to understand the impact of various system
parameters on the MAC access delay. The analysis indicates that the MAC access
delay depends on various system parameters, some of which are influenced by the
traffic scenario and nature of safety-critical events. Motivated by this, we
used our analysis to study the delay and reliability of the 802.11bd MAC
protocol specific to the context of platooning of connected vehicles subject to
interruptions by human-driven motorised two wheelers. We observe that while the
delay performance of the protocol is as per the QoS requirements of the
standard, the protocol may not be reliable for this specific application. Our
study suggests that it is desirable to co-design vehicular communication
protocols with prevalent safety-related traffic applications.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07384" title="Abstract">arXiv:2312.07384</a> [<a href="/pdf/2312.07384" title="Download PDF">pdf</a>, <a href="/format/2312.07384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Temporal Action Localization via Self-paced Incremental  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Haoyu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Han Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mingzhu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yupeng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jihua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+L">Liqiang Nie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, temporal action localization (TAL) has garnered significant
interest in information retrieval community. However, existing
supervised/weakly supervised methods are heavily dependent on extensive labeled
temporal boundaries and action categories, which is labor-intensive and
time-consuming. Although some unsupervised methods have utilized the
``iteratively clustering and localization'' paradigm for TAL, they still suffer
from two pivotal impediments: 1) unsatisfactory video clustering confidence,
and 2) unreliable video pseudolabels for model training. To address these
limitations, we present a novel self-paced incremental learning model to
enhance clustering and localization training simultaneously, thereby
facilitating more effective unsupervised TAL. Concretely, we improve the
clustering confidence through exploring the contextual feature-robust visual
information. Thereafter, we design two (constant- and variable- speed)
incremental instance learning strategies for easy-to-hard model training, thus
ensuring the reliability of these video pseudolabels and further improving
overall localization performance. Extensive experiments on two public datasets
have substantiated the superiority of our model over several state-of-the-art
competitors.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07385" title="Abstract">arXiv:2312.07385</a> [<a href="/pdf/2312.07385" title="Download PDF">pdf</a>, <a href="/format/2312.07385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GSmoothFace: Generalized Smooth Talking Face Generation via Fine Grained  3D Face Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhihao Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chaoda Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Baoyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Song Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shuguang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhen Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Although existing speech-driven talking face generation methods achieve
significant progress, they are far from real-world application due to the
avatar-specific training demand and unstable lip movements. To address the
above issues, we propose the GSmoothFace, a novel two-stage generalized talking
face generation model guided by a fine-grained 3d face model, which can
synthesize smooth lip dynamics while preserving the speaker's identity. Our
proposed GSmoothFace model mainly consists of the Audio to Expression
Prediction (A2EP) module and the Target Adaptive Face Translation (TAFT)
module. Specifically, we first develop the A2EP module to predict expression
parameters synchronized with the driven speech. It uses a transformer to
capture the long-term audio context and learns the parameters from the
fine-grained 3D facial vertices, resulting in accurate and smooth
lip-synchronization performance. Afterward, the well-designed TAFT module,
empowered by Morphology Augmented Face Blending (MAFB), takes the predicted
expression parameters and target video as inputs to modify the facial region of
the target video without distorting the background content. The TAFT
effectively exploits the identity appearance and background context in the
target video, which makes it possible to generalize to different speakers
without retraining. Both quantitative and qualitative experiments confirm the
superiority of our method in terms of realism, lip synchronization, and visual
quality. See the project page for code, data, and request pre-trained models:
https://zhanghm1995.github.io/GSmoothFace.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07388" title="Abstract">arXiv:2312.07388</a> [<a href="/pdf/2312.07388" title="Download PDF">pdf</a>, <a href="/format/2312.07388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformation rules for the decentralization of a blockchain-extended  global process model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=K%C3%B6pke%2C+J">Julius K&#xf6;pke</a>, 
<a href="/search/cs?searchtype=author&query=Trattnig%2C+S">Sebastian Trattnig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Blockchains and distributed ledger technology offer promising capabilities
for supporting collaborative business processes across organizations.
Typically, approaches in this field fall into two categories: either executing
the entire process model on the blockchain or using the blockchain primarily to
enforce or monitor the exchange of messages between participants. Our work
proposes a novel approach that sits between these two methods.
<br />We introduce a centralized process model extended with blockchain
annotations, detailing the tasks of each participating organization and the
extent to which blockchain technology is needed to secure task execution. This
model also includes all critical data objects and specifies how their handling
should be protected by the blockchain.
<br />This technical report outlines a systematic three-step method for
automatically decentralizing this comprehensive model into individual local
process models for each organization, coupled with a separate process model for
the blockchain. This decentralized structure effectively replicates the
original global process model.
<br />Our transformation approach is rule-based, focusing on creating a
platform-inde-pendent model first, then a platform-specific model.
Subsequently, we project the platform-specific model to obtain one model for
the blockchain and one model for each participating organization.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07389" title="Abstract">arXiv:2312.07389</a> [<a href="/pdf/2312.07389" title="Download PDF">pdf</a>, <a href="/ps/2312.07389" title="Download PostScript">ps</a>, <a href="/format/2312.07389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eroding Trust In Aerial Imagery: Comprehensive Analysis and Evaluation  Of Adversarial Attacks In Geospatial Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lanier%2C+M">Michael Lanier</a>, 
<a href="/search/cs?searchtype=author&query=Dhakal%2C+A">Aayush Dhakal</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zhexiao Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Arthur Li</a>, 
<a href="/search/cs?searchtype=author&query=Jacobs%2C+N">Nathan Jacobs</a>, 
<a href="/search/cs?searchtype=author&query=Vorobeychik%2C+Y">Yevgeniy Vorobeychik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE AIRP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In critical operations where aerial imagery plays an essential role, the
integrity and trustworthiness of data are paramount. The emergence of
adversarial attacks, particularly those that exploit control over labels or
employ physically feasible trojans, threatens to erode that trust, making the
analysis and mitigation of these attacks a matter of urgency. We demonstrate
how adversarial attacks can degrade confidence in geospatial systems,
specifically focusing on scenarios where the attacker's control over labels is
restricted and the use of realistic threat vectors. Proposing and evaluating
several innovative attack methodologies, including those tailored to overhead
images, we empirically show their threat to remote sensing systems using
high-quality SpaceNet datasets. Our experimentation reflects the unique
challenges posed by aerial imagery, and these preliminary results not only
reveal the potential risks but also highlight the non-trivial nature of the
problem compared to recent works.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07392" title="Abstract">arXiv:2312.07392</a> [<a href="/pdf/2312.07392" title="Download PDF">pdf</a>, <a href="/format/2312.07392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReRoGCRL: Representation-based Robustness in Goal-Conditioned  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xiangyu Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Sihao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaxu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+M">Meng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xingyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaowei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+W">Wenjie Ruan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted in AAAI24 (<a href="https://aaai.org/aaai-conference/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While Goal-Conditioned Reinforcement Learning (GCRL) has gained attention,
its algorithmic robustness, particularly against adversarial perturbations,
remains unexplored. Unfortunately, the attacks and robust representation
training methods specifically designed for traditional RL are not so effective
when applied to GCRL. To address this challenge, we propose the
\textit{Semi-Contrastive Representation} attack, a novel approach inspired by
the adversarial contrastive attack. Unlike existing attacks in RL, it only
necessitates information from the policy function and can be seamlessly
implemented during deployment. Furthermore, to mitigate the vulnerability of
existing GCRL algorithms, we introduce \textit{Adversarial Representation
Tactics}. This strategy combines \textit{Semi-Contrastive Adversarial
Augmentation} with \textit{Sensitivity-Aware Regularizer}. It improves the
adversarial robustness of the underlying agent against various types of
perturbations. Extensive experiments validate the superior performance of our
attack and defence mechanism across multiple state-of-the-art GCRL algorithms.
Our tool {\bf ReRoGCRL} is available at
\url{https://github.com/TrustAI/ReRoGCRL}.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07395" title="Abstract">arXiv:2312.07395</a> [<a href="/pdf/2312.07395" title="Download PDF">pdf</a>, <a href="/format/2312.07395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple Recipe for Contrastively Pre-training Video-First Encoders  Beyond 16 Frames
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papalampidi%2C+P">Pinelopi Papalampidi</a>, 
<a href="/search/cs?searchtype=author&query=Koppula%2C+S">Skanda Koppula</a>, 
<a href="/search/cs?searchtype=author&query=Pathak%2C+S">Shreya Pathak</a>, 
<a href="/search/cs?searchtype=author&query=Chiu%2C+J">Justin Chiu</a>, 
<a href="/search/cs?searchtype=author&query=Heyward%2C+J">Joe Heyward</a>, 
<a href="/search/cs?searchtype=author&query=Patraucean%2C+V">Viorica Patraucean</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jiajun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Miech%2C+A">Antoine Miech</a>, 
<a href="/search/cs?searchtype=author&query=Zisserman%2C+A">Andrew Zisserman</a>, 
<a href="/search/cs?searchtype=author&query=Nematzdeh%2C+A">Aida Nematzdeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Understanding long, real-world videos requires modeling of long-range visual
dependencies. To this end, we explore video-first architectures, building on
the common paradigm of transferring large-scale, image--text models to video
via shallow temporal fusion. However, we expose two limitations to the
approach: (1) decreased spatial capabilities, likely due to poor
video--language alignment in standard video datasets, and (2) higher memory
consumption, bottlenecking the number of frames that can be processed. To
mitigate the memory bottleneck, we systematically analyze the memory/accuracy
trade-off of various efficient methods: factorized attention,
parameter-efficient image-to-video adaptation, input masking, and
multi-resolution patchification. Surprisingly, simply masking large portions of
the video (up to 75%) during contrastive pre-training proves to be one of the
most robust ways to scale encoders to videos up to 4.3 minutes at 1 FPS. Our
simple approach for training long video-to-text models, which scales to 1B
parameters, does not add new architectural complexity and is able to outperform
the popular paradigm of using much larger LLMs as an information aggregator
over segment-based information on benchmarks with long-range temporal
dependencies (YouCook2, EgoSchema).
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07398" title="Abstract">arXiv:2312.07398</a> [<a href="/pdf/2312.07398" title="Download PDF">pdf</a>, <a href="/format/2312.07398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMEval: A Preliminary Study on How to Evaluate Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Ming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Haipeng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shichun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yongyao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+T">Tao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Recently, the evaluation of Large Language Models has emerged as a popular
area of research. The three crucial questions for LLM evaluation are ``what,
where, and how to evaluate''. However, the existing research mainly focuses on
the first two questions, which are basically what tasks to give the LLM during
testing and what kind of knowledge it should deal with. As for the third
question, which is about what standards to use, the types of evaluators, how to
score, and how to rank, there hasn't been much discussion. In this paper, we
analyze evaluation methods by comparing various criteria with both manual and
automatic evaluation, utilizing onsite, crowd-sourcing, public annotators and
GPT-4, with different scoring methods and ranking systems. We propose a new
dataset, LLMEval and conduct evaluations on 20 LLMs. A total of 2,186
individuals participated, leading to the generation of 243,337 manual
annotations and 57,511 automatic evaluation results. We perform comparisons and
analyses of different settings and conduct 10 conclusions that can provide some
insights for evaluating LLM in the future. The dataset and the results are
publicly available at https://github.com/llmeval .
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07399" title="Abstract">arXiv:2312.07399</a> [<a href="/pdf/2312.07399" title="Download PDF">pdf</a>, <a href="/format/2312.07399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models are Clinical Reasoners: Reasoning-Aware Diagnosis  Framework with Prompt-Generated Rationales
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwon%2C+T">Taeyoon Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Ong%2C+K+T">Kai Tzu-iunn Ong</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+D">Dongjin Kang</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+S">Seungjun Moon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+R">Jeong Ryong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+D">Dosik Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Sim%2C+Y">Yongsik Sim</a>, 
<a href="/search/cs?searchtype=author&query=Sohn%2C+B">Beomseok Sohn</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongha Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yeo%2C+J">Jinyoung Yeo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Machine reasoning has made great progress in recent years owing to large
language models (LLMs). In the clinical domain, however, most NLP-driven
projects mainly focus on clinical classification or reading comprehension, and
under-explore clinical reasoning for disease diagnosis due to the expensive
rationale annotation with clinicians. In this work, we present a
``reasoning-aware'' diagnosis framework that rationalizes the diagnostic
process via prompt-based learning in a time- and labor-efficient manner, and
learns to reason over the prompt-generated rationales. Specifically, we address
the clinical reasoning for disease diagnosis, where the LLM generates
diagnostic rationales providing its insight on presented patient data and the
reasoning path towards the diagnosis, namely Clinical Chain-of-Thought
(Clinical CoT). We empirically demonstrate LLMs/LMs' ability of clinical
reasoning via extensive experiments and analyses on both rationale generation
and disease diagnosis in various settings. We further propose a novel set of
criteria for evaluating machine-generated rationales' potential for real-world
clinical settings, facilitating and benefiting future research in this area.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07401" title="Abstract">arXiv:2312.07401</a> [<a href="/pdf/2312.07401" title="Download PDF">pdf</a>, <a href="/format/2312.07401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Diverse Preferences for Large Language Model Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+D">Dun Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yong Dai</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Pengyu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+T">Tianhao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wanshun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+N">Nan Du</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zenglin Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The alignment of large language models (LLMs) with human values is crucial
for the development of artificial general intelligence (AGI). One promising
approach to achieve this alignment is reinforcement learning from human
feedback, which employs a reward model (RM) learned from human preference
datasets to guide LLMs in generating text that aligns with human preferences.
Through intensive experiments and analysis of reward distribution, this paper
finds that preference datasets are diverse from each other, even though they
are all proposed to align human preference. Hence, mixing diverse human
preference datasets to increase data size for enhancing reward modeling could
fail. To address the issue and capture the shared human values from diverse
preferences, a new training policy called MORE is introduced, which minimizes
preference bias by adaptively adjusting the preference objective across diverse
preferences. Experiments with the Pythia-1.4B model and five mixed preference
datasets show that MORE achieves superior reward accuracy and lower calibration
error, highlighting its ability to leverage diverse human preference data.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07405" title="Abstract">arXiv:2312.07405</a> [<a href="/pdf/2312.07405" title="Download PDF">pdf</a>, <a href="/format/2312.07405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ICL Markup: Structuring In-Context Learning using Soft-Token Tags
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brunet%2C+M">Marc-Etienne Brunet</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+A">Ashton Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Zemel%2C+R">Richard Zemel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> R0-FoMo: Workshop on Robustness of Few-shot and Zero-shot Learning in Foundation Models at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large pretrained language models (LLMs) can be rapidly adapted to a wide
variety of tasks via a text-to-text approach, where the instruction and input
are fed to the model in natural language. Combined with in-context learning
(ICL), this paradigm is impressively flexible and powerful. However, it also
burdens users with an overwhelming number of choices, many of them arbitrary.
Inspired by markup languages like HTML, we contribute a method of using
soft-token tags to compose prompt templates. This approach reduces arbitrary
decisions and streamlines the application of ICL. Our method is a form of
meta-learning for ICL; it learns these tags in advance during a
parameter-efficient fine-tuning ``warm-up'' process. The tags can subsequently
be used in templates for ICL on new, unseen tasks without any additional
fine-tuning. Our experiments with this approach yield promising initial
results, improving LLM performance on important enterprise applications such as
few-shot and open-world intent detection, as well as text classification in
news and legal domains.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07408" title="Abstract">arXiv:2312.07408</a> [<a href="/pdf/2312.07408" title="Download PDF">pdf</a>, <a href="/format/2312.07408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Turbo: Informativity-Driven Acceleration Plug-In for Vision-Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ju%2C+C">Chen Ju</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haicheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zeqian Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+Z">Zhonghua Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Weilin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+S">Shuai Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision-Language Large Models (VLMs) have become primary backbone of AI, due
to the impressive performance. However, their expensive computation costs,
i.e., throughput and delay, impede potentials in real-world scenarios. To
achieve acceleration for VLMs, most existing methods focus on the model
perspective: pruning, distillation, quantification, but completely overlook the
data-perspective redundancy. To fill the overlook, this paper pioneers the
severity of data redundancy, and designs one plug-and-play Turbo module guided
by information degree to prune inefficient tokens from visual or textual data.
In pursuit of efficiency-performance trade-offs, information degree takes two
key factors into consideration: mutual redundancy and semantic value.
Concretely, the former evaluates the data duplication between sequential
tokens; while the latter evaluates each token by its contribution to the
overall semantics. As a result, tokens with high information degree carry less
redundancy and stronger semantics. For VLMs' calculation, Turbo works as a
user-friendly plug-in that sorts data referring to information degree,
utilizing only top-level ones to save costs. Its advantages are multifaceted,
e.g., being generally compatible to various VLMs across understanding and
generation, simple use without retraining and trivial engineering efforts. On
multiple public VLMs benchmarks, we conduct extensive experiments to reveal the
gratifying acceleration of Turbo, under negligible performance drop.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07409" title="Abstract">arXiv:2312.07409</a> [<a href="/pdf/2312.07409" title="Download PDF">pdf</a>, <a href="/format/2312.07409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffMorpher: Unleashing the Capability of Diffusion Models for Image  Morphing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaiwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yifan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xudong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xingang Pan</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bo Dai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion models have achieved remarkable image generation quality surpassing
previous generative models. However, a notable limitation of diffusion models,
in comparison to GANs, is their difficulty in smoothly interpolating between
two image samples, due to their highly unstructured latent space. Such a smooth
interpolation is intriguing as it naturally serves as a solution for the image
morphing task with many applications. In this work, we present DiffMorpher, the
first approach enabling smooth and natural image interpolation using diffusion
models. Our key idea is to capture the semantics of the two images by fitting
two LoRAs to them respectively, and interpolate between both the LoRA
parameters and the latent noises to ensure a smooth semantic transition, where
correspondence automatically emerges without the need for annotation. In
addition, we propose an attention interpolation and injection technique and a
new sampling schedule to further enhance the smoothness between consecutive
images. Extensive experiments demonstrate that DiffMorpher achieves starkly
better image morphing effects than previous methods across a variety of object
categories, bridging a critical functional gap that distinguished diffusion
models from GANs.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07413" title="Abstract">arXiv:2312.07413</a> [<a href="/pdf/2312.07413" title="Download PDF">pdf</a>, <a href="/format/2312.07413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI capabilities can be significantly improved without expensive  retraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Davidson%2C+T">Tom Davidson</a>, 
<a href="/search/cs?searchtype=author&query=Denain%2C+J">Jean-Stanislas Denain</a>, 
<a href="/search/cs?searchtype=author&query=Villalobos%2C+P">Pablo Villalobos</a>, 
<a href="/search/cs?searchtype=author&query=Bas%2C+G">Guillem Bas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 24 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">State-of-the-art AI systems can be significantly improved without expensive
retraining via "post-training enhancements"-techniques applied after initial
training like fine-tuning the system to use a web browser. We review recent
post-training enhancements, categorizing them into five types: tool-use,
prompting methods, scaffolding, solution selection, and data generation.
Different enhancements improve performance on different tasks, making it hard
to compare their significance. So we translate improvements from different
enhancements into a common currency, the compute-equivalent gain: how much
additional training compute would be needed to improve performance by the same
amount as the enhancement. Our non-experimental work shows that post-training
enhancements have significant benefits: most surveyed enhancements improve
benchmark performance by more than a 5x increase in training compute, some by
more than 20x. Post-training enhancements are relatively cheap to develop:
fine-tuning costs are typically &lt;1% of the original training cost. Governing
the development of capable post-training enhancements may be challenging
because frontier models could be enhanced by a wide range of actors.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07414" title="Abstract">arXiv:2312.07414</a> [<a href="/pdf/2312.07414" title="Download PDF">pdf</a>, <a href="/format/2312.07414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QSMVM: QoS-aware and social-aware multimetric routing protocol for  video-streaming services over MANETs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jara%2C+E+P">Efra&#xed;n Palacios Jara</a>, 
<a href="/search/cs?searchtype=author&query=Mezhe%2C+A+M">Ahmad Mohamad Mezhe</a>, 
<a href="/search/cs?searchtype=author&query=Igartua%2C+M+A">M&#xf3;nica Aguilar Igartua</a>, 
<a href="/search/cs?searchtype=author&query=Redondo%2C+R+P+D">Rebeca P. D&#xed;az Redondo</a>, 
<a href="/search/cs?searchtype=author&query=Vilas%2C+A+F">Ana Fern&#xe1;ndez Vilas</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sensors 2021, 21(3), 901
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">A mobile ad hoc network (MANET) is a set of autonomous mobile devices
connected by wireless links in a distributed manner and without a fixed
infrastructure. Real-time multimedia services, such as video-streaming over
MANETs, offers very promising applications, e.g. two members of a group of
tourists who want to share a video transmitted through the MANET they form; a
video-streaming service deployed over a MANET where users watch a film; among
other examples. On the other hand, social web technologies, where people
actively interact online with others through social networks, are leading to a
socialization of networks. Information of interaction among users is being used
to provide socially-enhanced software. To achieve this, we need to know the
strength of the relationship between a given user and each user they interact
with. This strength of the relationship can be measured through a concept
called tie strength (TS), first introduced by Mark Granovetter in 1973. In this
article, we modify our previous proposal named multipath multimedia dynamic
source routing (MMDSR) protocol to include a social metric TS in the decisions
taken by the forwarding algorithm. We find a trade-off between the quality of
service (QoS) and the trust level between users who form the forwarding path in
the MANET. Our goal is to increase the trust metric while the QoS is not
affected significantly.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07418" title="Abstract">arXiv:2312.07418</a> [<a href="/pdf/2312.07418" title="Download PDF">pdf</a>, <a href="/ps/2312.07418" title="Download PostScript">ps</a>, <a href="/format/2312.07418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention Based Encoder Decoder Model for Video Captioning in Nepali  (2023)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parajuli%2C+K">Kabita Parajuli</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+S+R">Shashidhar Ram Joshi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MSVD, Encoder, Decoder LSTM, GRU, Attention Mechanism
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video captioning in Nepali, a language written in the Devanagari script,
presents a unique challenge due to the lack of existing academic work in this
domain. This work develops a novel encoder-decoder paradigm for Nepali video
captioning to tackle this difficulty. LSTM and GRU sequence-to-sequence models
are used in the model to produce related textual descriptions based on features
retrieved from video frames using CNNs. Using Google Translate and manual
post-editing, a Nepali video captioning dataset is generated from the Microsoft
Research Video Description Corpus (MSVD) dataset created using Google
Translate, and manual post-editing work. The efficacy of the model for
Devanagari-scripted video captioning is demonstrated by BLEU, METOR, and ROUGE
measures, which are used to assess its performance.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07419" title="Abstract">arXiv:2312.07419</a> [<a href="/pdf/2312.07419" title="Download PDF">pdf</a>, <a href="/format/2312.07419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Faster k-Nearest-Neighbor Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xiangyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yunlong Liang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jinan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yufeng Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Recent works have proven the effectiveness of k-nearest-neighbor machine
translation(a.k.a kNN-MT) approaches to produce remarkable improvement in
cross-domain translations. However, these models suffer from heavy retrieve
overhead on the entire datastore when decoding each token. We observe that
during the decoding phase, about 67% to 84% of tokens are unvaried after
searching over the corpus datastore, which means most of the tokens cause
futile retrievals and introduce unnecessary computational costs by initiating
k-nearest-neighbor searches. We consider this phenomenon is explainable in
linguistics and propose a simple yet effective multi-layer perceptron (MLP)
network to predict whether a token should be translated jointly by the neural
machine translation model and probabilities produced by the kNN or just by the
neural model. The results show that our method succeeds in reducing redundant
retrieval operations and significantly reduces the overhead of kNN retrievals
by up to 53% at the expense of a slight decline in translation quality.
Moreover, our method could work together with all existing kNN-MT systems.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07420" title="Abstract">arXiv:2312.07420</a> [<a href="/pdf/2312.07420" title="Download PDF">pdf</a>, <a href="/format/2312.07420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FairSISA: Ensemble Post-Processing to Improve Fairness of Unlearning in  LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kadhe%2C+S+R">Swanand Ravindra Kadhe</a>, 
<a href="/search/cs?searchtype=author&query=Halimi%2C+A">Anisa Halimi</a>, 
<a href="/search/cs?searchtype=author&query=Rawat%2C+A">Ambrish Rawat</a>, 
<a href="/search/cs?searchtype=author&query=Baracaldo%2C+N">Nathalie Baracaldo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in NeurIPS 2023 Workshop on Socially Responsible Language Modelling Research (SoLaR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Training large language models (LLMs) is a costly endeavour in terms of time
and computational resources. The large amount of training data used during the
unsupervised pre-training phase makes it difficult to verify all data and,
unfortunately, undesirable data may be ingested during training. Re-training
from scratch is impractical and has led to the creation of the 'unlearning'
discipline where models are modified to "unlearn" undesirable information
without retraining. However, any modification can alter the behaviour of LLMs,
especially on key dimensions such as fairness. This is the first work that
examines this interplay between unlearning and fairness for LLMs. In
particular, we focus on a popular unlearning framework known as SISA [Bourtoule
et al., 2021], which creates an ensemble of models trained on disjoint shards.
We evaluate the performance-fairness trade-off for SISA, and empirically
demsontrate that SISA can indeed reduce fairness in LLMs. To remedy this, we
propose post-processing bias mitigation techniques for ensemble models produced
by SISA. We adapt the post-processing fairness improvement technique from
[Hardt et al., 2016] to design three methods that can handle model ensembles,
and prove that one of the methods is an optimal fair predictor for ensemble of
models. Through experimental results, we demonstrate the efficacy of our
post-processing framework called 'FairSISA'.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07421" title="Abstract">arXiv:2312.07421</a> [<a href="/pdf/2312.07421" title="Download PDF">pdf</a>, <a href="/ps/2312.07421" title="Download PostScript">ps</a>, <a href="/format/2312.07421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coarse-graining Complex Networks for Control Equivalence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Toller%2C+D">Daniele Toller</a>, 
<a href="/search/eess?searchtype=author&query=Tribastone%2C+M">Mirco Tribastone</a>, 
<a href="/search/eess?searchtype=author&query=Tschaikowski%2C+M">Max Tschaikowski</a>, 
<a href="/search/eess?searchtype=author&query=Vandin%2C+A">Andrea Vandin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The ability to control complex networks is of crucial importance across a
wide range of applications in natural and engineering sciences. However, issues
of both theoretical and numerical nature introduce fundamental limitations to
controlling large-scale networks. In this paper, we cope with this problem by
introducing a coarse-graining algorithm. It leads to an aggregated network
which satisfies control equivalence, i.e., such that the optimal control values
for the original network can be exactly recovered from those of the aggregated
one. The algorithm is based on a partition refinement method originally devised
for systems of ordinary differential equations, here extended and applied to
linear dynamics on complex networks. Using a number of benchmarks from the
literature we show considerable reductions across a variety of networks from
biology, ecology, engineering, and social sciences.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07423" title="Abstract">arXiv:2312.07423</a> [<a href="/pdf/2312.07423" title="Download PDF">pdf</a>, <a href="/format/2312.07423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Holoported Characters: Real-time Free-viewpoint Rendering of Humans from  Sparse RGB Cameras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shetty%2C+A">Ashwath Shetty</a>, 
<a href="/search/cs?searchtype=author&query=Habermann%2C+M">Marc Habermann</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Guoxing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Luvizon%2C+D">Diogo Luvizon</a>, 
<a href="/search/cs?searchtype=author&query=Golyanik%2C+V">Vladislav Golyanik</a>, 
<a href="/search/cs?searchtype=author&query=Theobalt%2C+C">Christian Theobalt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://vcai.mpi-inf.mpg.de/projects/holochar/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present the first approach to render highly realistic free-viewpoint
videos of a human actor in general apparel, from sparse multi-view recording to
display, in real-time at an unprecedented 4K resolution. At inference, our
method only requires four camera views of the moving actor and the respective
3D skeletal pose. It handles actors in wide clothing, and reproduces even
fine-scale dynamic detail, e.g. clothing wrinkles, face expressions, and hand
gestures. At training time, our learning-based approach expects dense
multi-view video and a rigged static surface scan of the actor. Our method
comprises three main stages. Stage 1 is a skeleton-driven neural approach for
high-quality capture of the detailed dynamic mesh geometry. Stage 2 is a novel
solution to create a view-dependent texture using four test-time camera views
as input. Finally, stage 3 comprises a new image-based refinement network
rendering the final 4K image given the output from the previous stages. Our
approach establishes a new benchmark for real-time rendering resolution and
quality using sparse input camera views, unlocking possibilities for immersive
telepresence.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07424" title="Abstract">arXiv:2312.07424</a> [<a href="/pdf/2312.07424" title="Download PDF">pdf</a>, <a href="/format/2312.07424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Well Does GPT-4V(ision) Adapt to Distribution Shifts? A Preliminary  Investigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhongyi Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Guanglin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Rundong He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jindong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tailin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yilong Yin</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Salman Khan</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+L">Lina Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tongliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 62 pages, 39 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In machine learning, generalization against distribution shifts -- where
deployment conditions diverge from the training scenarios -- is crucial,
particularly in fields like climate modeling, biomedicine, and autonomous
driving. The emergence of foundation models, distinguished by their extensive
pretraining and task versatility, has led to an increased interest in their
adaptability to distribution shifts. GPT-4V(ision) acts as the most advanced
publicly accessible multimodal foundation model, with extensive applications
across various domains, including anomaly detection, video understanding, image
generation, and medical diagnosis. However, its robustness against data
distributions remains largely underexplored. Addressing this gap, this study
rigorously evaluates GPT-4V's adaptability and generalization capabilities in
dynamic environments, benchmarking against prominent models like CLIP and
LLaVA. We delve into GPT-4V's zero-shot generalization across 13 diverse
datasets spanning natural, medical, and molecular domains. We further
investigate its adaptability to controlled data perturbations and examine the
efficacy of in-context learning as a tool to enhance its adaptation. Our
findings delineate GPT-4V's capability boundaries in distribution shifts,
shedding light on its strengths and limitations across various scenarios.
Importantly, this investigation contributes to our understanding of how AI
foundation models generalize to distribution shifts, offering pivotal insights
into their adaptability and robustness. Code is publicly available at
https://github.com/jameszhou-gl/gpt-4v-distribution-shift.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07425" title="Abstract">arXiv:2312.07425</a> [<a href="/pdf/2312.07425" title="Download PDF">pdf</a>, <a href="/format/2312.07425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Internal Learning: Deep Learning from a Single Input
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tirer%2C+T">Tom Tirer</a>, 
<a href="/search/cs?searchtype=author&query=Giryes%2C+R">Raja Giryes</a>, 
<a href="/search/cs?searchtype=author&query=Chun%2C+S+Y">Se Young Chun</a>, 
<a href="/search/cs?searchtype=author&query=Eldar%2C+Y+C">Yonina C. Eldar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV); Signal Processing (eess.SP)

</div>
<p class="mathjax">Deep learning in general focuses on training a neural network from large
labeled datasets. Yet, in many cases there is value in training a network just
from the input at hand. This may involve training a network from scratch using
a single input or adapting an already trained network to a provided input
example at inference time. This survey paper aims at covering deep
internal-learning techniques that have been proposed in the past few years for
these two important directions. While our main focus will be on image
processing problems, most of the approaches that we survey are derived for
general signals (vectors with recurring patterns that can be distinguished from
noise) and are therefore applicable to other modalities. We believe that the
topic of internal-learning is very important in many signal and image
processing problems where training data is scarce and diversity is large on the
one hand, and on the other, there is a lot of structure in the data that can be
exploited.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07428" title="Abstract">arXiv:2312.07428</a> [<a href="/pdf/2312.07428" title="Download PDF">pdf</a>, <a href="/format/2312.07428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensemble Federated Learning: an approach for collaborative pneumonia  diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mabrouk%2C+A">Alhassan Mabrouk</a>, 
<a href="/search/cs?searchtype=author&query=Redondo%2C+R+P+D">Rebeca P. D&#xed;az Redondo</a>, 
<a href="/search/cs?searchtype=author&query=Elaziz%2C+M+A">Mohamed Abd Elaziz</a>, 
<a href="/search/cs?searchtype=author&query=Kayed%2C+M">Mohammed Kayed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 9 figures, journal
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Applied Soft Computing, 2023, p. 110500
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Federated learning is a very convenient approach for scenarios where (i) the
exchange of data implies privacy concerns and/or (ii) a quick reaction is
needed. In smart healthcare systems, both aspects are usually required. In this
paper, we work on the first scenario, where preserving privacy is key and,
consequently, building a unique and massive medical image data set by fusing
different data sets from different medical institutions or research centers
(computation nodes) is not an option. We propose an ensemble federated learning
(EFL) approach that is based on the following characteristics: First, each
computation node works with a different data set (but of the same type). They
work locally and apply an ensemble approach combining eight well-known CNN
models (densenet169, mobilenetv2, xception, inceptionv3, vgg16, resnet50,
densenet121, and resnet152v2) on Chest X-ray images. Second, the best two local
models are used to create a local ensemble model that is shared with a central
node. Third, the ensemble models are aggregated to obtain a global model, which
is shared with the computation nodes to continue with a new iteration. This
procedure continues until there are no changes in the best local models. We
have performed different experiments to compare our approach with centralized
ones (with or without an ensemble approach)\color{black}. The results conclude
that our proposal outperforms these ones in Chest X-ray images (achieving an
accuracy of 96.63\%) and offers very competitive results compared to other
proposals in the literature.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07431" title="Abstract">arXiv:2312.07431</a> [<a href="/pdf/2312.07431" title="Download PDF">pdf</a>, <a href="/ps/2312.07431" title="Download PostScript">ps</a>, <a href="/format/2312.07431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithms and Complexity for Congested Assignments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiehua Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yinghui Wen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We study the congested assignment problem as introduced by Bogomolnaia and
Moulin (2023). We show that deciding whether a competitive assignment exists
can be done in polynomial time, while deciding whether an envy-free assignment
exists is NP-complete.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07434" title="Abstract">arXiv:2312.07434</a> [<a href="/pdf/2312.07434" title="Download PDF">pdf</a>, <a href="/format/2312.07434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Modal Conformal Prediction Regions by Optimizing Convex Shape  Templates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tumu%2C+R">Renukanandan Tumu</a>, 
<a href="/search/cs?searchtype=author&query=Cleaveland%2C+M">Matthew Cleaveland</a>, 
<a href="/search/cs?searchtype=author&query=Mangharam%2C+R">Rahul Mangharam</a>, 
<a href="/search/cs?searchtype=author&query=Pappas%2C+G+J">George J. Pappas</a>, 
<a href="/search/cs?searchtype=author&query=Lindemann%2C+L">Lars Lindemann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures. The source code and toolbox are available at <a href="https://github.com/nandantumu/conformal_region_designer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Conformal prediction is a statistical tool for producing prediction regions
for machine learning models that are valid with high probability. A key
component of conformal prediction algorithms is a non-conformity score function
that quantifies how different a model's prediction is from the unknown ground
truth value. Essentially, these functions determine the shape and the size of
the conformal prediction regions. However, little work has gone into finding
non-conformity score functions that produce prediction regions that are
multi-modal and practical, i.e., that can efficiently be used in engineering
applications. We propose a method that optimizes parameterized shape template
functions over calibration data, which results in non-conformity score
functions that produce prediction regions with minimum volume. Our approach
results in prediction regions that are multi-modal, so they can properly
capture residuals of distributions that have multiple modes, and practical, so
each region is convex and can be easily incorporated into downstream tasks,
such as a motion planner using conformal prediction regions. Our method applies
to general supervised learning tasks, while we illustrate its use in
time-series prediction. We provide a toolbox and present illustrative case
studies of F16 fighter jets and autonomous vehicles, showing an up to $68\%$
reduction in prediction region area.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07435" title="Abstract">arXiv:2312.07435</a> [<a href="/pdf/2312.07435" title="Download PDF">pdf</a>, <a href="/format/2312.07435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-modal Contrastive Learning with Asymmetric Co-attention Network  for Video Moment Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Panta%2C+L">Love Panta</a>, 
<a href="/search/cs?searchtype=author&query=Shrestha%2C+P">Prashant Shrestha</a>, 
<a href="/search/cs?searchtype=author&query=Sapkota%2C+B">Brabeem Sapkota</a>, 
<a href="/search/cs?searchtype=author&query=Bhattarai%2C+A">Amrita Bhattarai</a>, 
<a href="/search/cs?searchtype=author&query=Manandhar%2C+S">Suresh Manandhar</a>, 
<a href="/search/cs?searchtype=author&query=Sah%2C+A+K">Anand Kumar Sah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Video moment retrieval is a challenging task requiring fine-grained
interactions between video and text modalities. Recent work in image-text
pretraining has demonstrated that most existing pretrained models suffer from
information asymmetry due to the difference in length between visual and
textual sequences. We question whether the same problem also exists in the
video-text domain with an auxiliary need to preserve both spatial and temporal
information. Thus, we evaluate a recently proposed solution involving the
addition of an asymmetric co-attention network for video grounding tasks.
Additionally, we incorporate momentum contrastive loss for robust,
discriminative representation learning in both modalities. We note that the
integration of these supplementary modules yields better performance compared
to state-of-the-art models on the TACoS dataset and comparable results on
ActivityNet Captions, all while utilizing significantly fewer parameters with
respect to baseline.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07437" title="Abstract">arXiv:2312.07437</a> [<a href="/pdf/2312.07437" title="Download PDF">pdf</a>, <a href="/format/2312.07437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Medical Image Classification Using Transfer Learning and Chaos Game  Optimization on the Internet of Medical Things
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mabrouk%2C+A">Alhassan Mabrouk</a>, 
<a href="/search/cs?searchtype=author&query=Dahou%2C+A">Abdelghani Dahou</a>, 
<a href="/search/cs?searchtype=author&query=Elaziz%2C+M+A">Mohamed Abd Elaziz</a>, 
<a href="/search/cs?searchtype=author&query=Redondo%2C+R+P+D">Rebeca P. D&#xed;az Redondo</a>, 
<a href="/search/cs?searchtype=author&query=Kayed%2C+M">Mohammed Kayed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 12 figures, journal
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computational Intelligence and Neuroscience, 2022, vol. 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The Internet of Medical Things (IoMT) has dramatically benefited medical
professionals that patients and physicians can access from all regions.
Although the automatic detection and prediction of diseases such as melanoma
and leukemia is still being researched and studied in IoMT, existing approaches
are not able to achieve a high degree of efficiency. Thus, with a new approach
that provides better results, patients would access the adequate treatments
earlier and the death rate would be reduced. Therefore, this paper introduces
an IoMT proposal for medical images classification that may be used anywhere,
i.e. it is an ubiquitous approach. It was design in two stages: first, we
employ a Transfer Learning (TL)-based method for feature extraction, which is
carried out using MobileNetV3; second, we use the Chaos Game Optimization (CGO)
for feature selection, with the aim of excluding unnecessary features and
improving the performance, which is key in IoMT. Our methodology was evaluated
using ISIC-2016, PH2, and Blood-Cell datasets. The experimental results
indicated that the proposed approach obtained an accuracy of 88.39% on
ISIC-2016, 97.52% on PH2, and 88.79% on Blood-cell. Moreover, our approach had
successful performances for the metrics employed compared to other existing
methods.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07439" title="Abstract">arXiv:2312.07439</a> [<a href="/pdf/2312.07439" title="Download PDF">pdf</a>, <a href="/format/2312.07439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BIRB: A Generalization Benchmark for Information Retrieval in  Bioacoustics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamer%2C+J">Jenny Hamer</a>, 
<a href="/search/cs?searchtype=author&query=Triantafillou%2C+E">Eleni Triantafillou</a>, 
<a href="/search/cs?searchtype=author&query=van+Merrienboer%2C+B">Bart van Merrienboer</a>, 
<a href="/search/cs?searchtype=author&query=Kahl%2C+S">Stefan Kahl</a>, 
<a href="/search/cs?searchtype=author&query=Klinck%2C+H">Holger Klinck</a>, 
<a href="/search/cs?searchtype=author&query=Denton%2C+T">Tom Denton</a>, 
<a href="/search/cs?searchtype=author&query=Dumoulin%2C+V">Vincent Dumoulin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The ability for a machine learning model to cope with differences in training
and deployment conditions--e.g. in the presence of distribution shift or the
generalization to new classes altogether--is crucial for real-world use cases.
However, most empirical work in this area has focused on the image domain with
artificial benchmarks constructed to measure individual aspects of
generalization. We present BIRB, a complex benchmark centered on the retrieval
of bird vocalizations from passively-recorded datasets given focal recordings
from a large citizen science corpus available for training. We propose a
baseline system for this collection of tasks using representation learning and
a nearest-centroid search. Our thorough empirical evaluation and analysis
surfaces open research directions, suggesting that BIRB fills the need for a
more realistic and complex benchmark to drive progress on robustness to
distribution shifts and generalization of ML models.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07444" title="Abstract">arXiv:2312.07444</a> [<a href="/pdf/2312.07444" title="Download PDF">pdf</a>, <a href="/ps/2312.07444" title="Download PostScript">ps</a>, <a href="/format/2312.07444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rational Approximations for Oscillatory Two-Parameter Mittag-Leffler  Function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Honain%2C+A+H">Aljowhara H. Honain</a>, 
<a href="/search/math?searchtype=author&query=Furati%2C+K+M">Khaled M. Furati</a>, 
<a href="/search/math?searchtype=author&query=Sarumi%2C+I+O">Ibrahim O. Sarumi</a>, 
<a href="/search/math?searchtype=author&query=Khaliq%2C+A+Q+M">Abdul Q. M. Khaliq</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 14 figures and 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The two-parameter Mittag-Leffler function $E_{\alpha, \beta}$ is of
fundamental importance in fractional calculus. It appears frequently in the
solutions of fractional differential and integral equations. Nonetheless, this
vital function is often expensive to compute. Several attempts have been made
to construct cost-effective and accurate approximations. These attempts focus
mainly on the completely monotone Mittag-Leffler functions. However, when
$\alpha &gt; 1$ the monotonicity property is largely lost and as such roots and
oscillations are exhibited. Consequently, existing approximants constructed
mainly for $\alpha \in (0,1)$ often fail to capture this oscillatory behavior.
In this paper, we construct computationally efficient and accurate rational
approximants for $E_{\alpha, \beta}(-t)$, $t \ge 0$, with $\alpha \in (1,2)$.
This construction is fundamentally based on the decomposition of Mittag-Leffler
function with real roots into one without and a polynomial. Following which new
approximants are constructed by combining the global Pad\'e approximation with
a polynomial of appropriate degree. The rational approximants are extended to
approximation of matrix Mittag-Leffler and different approaches to achieve
efficient implementation for matrix arguments are discussed. Numerical
experiments are provided to illustrate the significant accuracy improvement
achieved by the proposed approximants.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07451" title="Abstract">arXiv:2312.07451</a> [<a href="/pdf/2312.07451" title="Download PDF">pdf</a>, <a href="/format/2312.07451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Daily Assistive View Control Learning of Low-Cost Low-Rigidity Robot via  Large-Scale Vision-Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kawaharazuka%2C+K">Kento Kawaharazuka</a>, 
<a href="/search/cs?searchtype=author&query=Kanazawa%2C+N">Naoaki Kanazawa</a>, 
<a href="/search/cs?searchtype=author&query=Obinata%2C+Y">Yoshiki Obinata</a>, 
<a href="/search/cs?searchtype=author&query=Okada%2C+K">Kei Okada</a>, 
<a href="/search/cs?searchtype=author&query=Inaba%2C+M">Masayuki Inaba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at Humanoids2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this study, we develop a simple daily assistive robot that controls its
own vision according to linguistic instructions. The robot performs several
daily tasks such as recording a user's face, hands, or screen, and remotely
capturing images of desired locations. To construct such a robot, we combine a
pre-trained large-scale vision-language model with a low-cost low-rigidity
robot arm. The correlation between the robot's physical and visual information
is learned probabilistically using a neural network, and changes in the
probability distribution based on changes in time and environment are
considered by parametric bias, which is a learnable network input variable. We
demonstrate the effectiveness of this learning method by open-vocabulary view
control experiments with an actual robot arm, MyCobot.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07454" title="Abstract">arXiv:2312.07454</a> [<a href="/pdf/2312.07454" title="Download PDF">pdf</a>, <a href="/format/2312.07454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;You Might Like It&quot;: How People Respond to Small Talk in Human-Robot  Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pineda%2C+K+T">Kaitlynn Taylor Pineda</a>, 
<a href="/search/cs?searchtype=author&query=Mahmood%2C+A">Amama Mahmood</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chien-Ming Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures, 3 tables,
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">In this work, we investigate people's engagement and attitudes towards a
non-anthropomorphic robot manipulator that initiates small talk with the user
during a collaborative assembly task, and explore how the presence of negative
team feedback may affect team dynamics and blame attribution. Through an
exploratory study with 20 participants, we found that 18 individuals interacted
socially with the robot, nine of which initiated questions back to the robot.
We report the frequency and length of users' responses in task-oriented and
non-task-oriented dialogue, and further elaborate on people's reactions to the
negative system feedback and robot-initiated small talk. We discuss the
potential for integrating small talk in non-social robots, and propose three
design guidelines to enhance human-robot small talk interactions.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07455" title="Abstract">arXiv:2312.07455</a> [<a href="/pdf/2312.07455" title="Download PDF">pdf</a>, <a href="/format/2312.07455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving high-dimensional Fokker-Planck equation with functional  hierarchical tensor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tang%2C+X">Xun Tang</a>, 
<a href="/search/math?searchtype=author&query=Ying%2C+L">Lexing Ying</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This work is concerned with solving high-dimensional Fokker-Planck equations
with the novel perspective that solving the PDE can be reduced to independent
instances of density estimation tasks based on the trajectories sampled from
its associated particle dynamics. With this approach, one sidesteps error
accumulation occurring from integrating the PDE dynamics on a parameterized
function class. This approach significantly simplifies deployment, as one is
free of the challenges of implementing loss terms based on the differential
equation. In particular, we introduce a novel class of high-dimensional
functions called the functional hierarchical tensor (FHT). The FHT ansatz
leverages a hierarchical low-rank structure, offering the advantage of linearly
scalable runtime and memory complexity relative to the dimension count. We
introduce a sketching-based technique that performs density estimation over
particles simulated from the particle dynamics associated with the equation,
thereby obtaining a representation of the Fokker-Planck solution in terms of
our ansatz. We apply the proposed approach successfully to three challenging
time-dependent Ginzburg-Landau models with hundreds of variables.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07457" title="Abstract">arXiv:2312.07457</a> [<a href="/pdf/2312.07457" title="Download PDF">pdf</a>, <a href="/format/2312.07457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamics Harmonic Analysis of Robotic Systems: Application in  Data-Driven Koopman Modelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ordo%C3%B1ez-Apraez%2C+D">Daniel Ordo&#xf1;ez-Apraez</a>, 
<a href="/search/cs?searchtype=author&query=Kostic%2C+V">Vladimir Kostic</a>, 
<a href="/search/cs?searchtype=author&query=Turrisi%2C+G">Giulio Turrisi</a>, 
<a href="/search/cs?searchtype=author&query=Novelli%2C+P">Pietro Novelli</a>, 
<a href="/search/cs?searchtype=author&query=Mastalli%2C+C">Carlos Mastalli</a>, 
<a href="/search/cs?searchtype=author&query=Semini%2C+C">Claudio Semini</a>, 
<a href="/search/cs?searchtype=author&query=Pontil%2C+M">Massimiliano Pontil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">We introduce the use of harmonic analysis to decompose the state space of
symmetric robotic systems into orthogonal isotypic subspaces. These are
lower-dimensional spaces that capture distinct, symmetric, and synergistic
motions. For linear dynamics, we characterize how this decomposition leads to a
subdivision of the dynamics into independent linear systems on each subspace, a
property we term dynamics harmonic analysis (DHA). To exploit this property, we
use Koopman operator theory to propose an equivariant deep-learning
architecture that leverages the properties of DHA to learn a global linear
model of system dynamics. Our architecture, validated on synthetic systems and
the dynamics of locomotion of a quadrupedal robot, demonstrates enhanced
generalization, sample efficiency, and interpretability, with less trainable
parameters and computational costs.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07459" title="Abstract">arXiv:2312.07459</a> [<a href="/pdf/2312.07459" title="Download PDF">pdf</a>, <a href="/format/2312.07459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Codesign of Humanoid Robots for Ergonomy Collaboration with Multiple  Humans via Genetic Algorithms and Nonlinear Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sartore%2C+C">Carlotta Sartore</a>, 
<a href="/search/cs?searchtype=author&query=Rapetti%2C+L">Lorenzo Rapetti</a>, 
<a href="/search/cs?searchtype=author&query=Bergonti%2C+F">Fabio Bergonti</a>, 
<a href="/search/cs?searchtype=author&query=Dafarra%2C+S">Stefano Dafarra</a>, 
<a href="/search/cs?searchtype=author&query=Traversaro%2C+S">Silvio Traversaro</a>, 
<a href="/search/cs?searchtype=author&query=Pucci%2C+D">Daniele Pucci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Ergonomics is a key factor to consider when designing control architectures
for effective physical collaborations between humans and humanoid robots. In
contrast, ergonomic indexes are often overlooked in the robot design phase,
which leads to suboptimal performance in physical human-robot interaction
tasks. This paper proposes a novel methodology for optimizing the design of
humanoid robots with respect to ergonomic indicators associated with the
interaction of multiple agents. Our approach leverages a dynamic and kinematic
parameterization of the robot link and motor specifications to seek for optimal
robot designs using a bilevel optimization approach. Specifically, a genetic
algorithm first generates robot designs by selecting the link and motor
characteristics. Then, we use nonlinear optimization to evaluate interaction
ergonomy indexes during collaborative payload lifting with different humans and
weights. To assess the effectiveness of our approach, we compare the optimal
design obtained using bilevel optimization against the design obtained using
nonlinear optimization. Our results show that the proposed approach
significantly improves ergonomics in terms of energy expenditure calculated in
two reference scenarios involving static and dynamic robot motions. We plan to
apply our methodology to drive the design of the ergoCub2 robot, a humanoid
intended for optimal physical collaboration with humans in diverse environments
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07466" title="Abstract">arXiv:2312.07466</a> [<a href="/pdf/2312.07466" title="Download PDF">pdf</a>, <a href="/format/2312.07466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Object Detection in Autonomous Driving using Spiking Neural  Networks: Performance, Energy Consumption Analysis, and Insights into  Open-set Object Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seras%2C+A+M">Aitor Martinez Seras</a>, 
<a href="/search/cs?searchtype=author&query=Del+Ser%2C+J">Javier Del Ser</a>, 
<a href="/search/cs?searchtype=author&query=Garcia-Bringas%2C+P">Pablo Garcia-Bringas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, presented at ITSC2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Besides performance, efficiency is a key design driver of technologies
supporting vehicular perception. Indeed, a well-balanced trade-off between
performance and energy consumption is crucial for the sustainability of
autonomous vehicles. In this context, the diversity of real-world contexts in
which autonomous vehicles can operate motivates the need for empowering
perception models with the capability to detect, characterize and identify
newly appearing objects by themselves. In this manuscript we elaborate on this
threefold conundrum (performance, efficiency and open-world learning) for
object detection modeling tasks over image data collected from vehicular
scenarios. Specifically, we show that well-performing and efficient models can
be realized by virtue of Spiking Neural Networks (SNNs), reaching competitive
levels of detection performance when compared to their non-spiking counterparts
at dramatic energy consumption savings (up to 85%) and a slightly improved
robustness against image noise. Our experiments herein offered also expose
qualitatively the complexity of detecting new objects based on the preliminary
results of a simple approach to discriminate potential object proposals in the
captured image.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07472" title="Abstract">arXiv:2312.07472</a> [<a href="/pdf/2312.07472" title="Download PDF">pdf</a>, <a href="/format/2312.07472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MP5: A Multi-modal Open-ended Embodied System in Minecraft via Active  Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yiran Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+E">Enshen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qichang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhenfei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+L">Lu Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruimao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jing Shao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">It is a long-lasting goal to design an embodied system that can solve
long-horizon open-world tasks in human-like ways. However, existing approaches
usually struggle with compound difficulties caused by the logic-aware
decomposition and context-aware execution of these tasks. To this end, we
introduce MP5, an open-ended multimodal embodied system built upon the
challenging Minecraft simulator, which can decompose feasible sub-objectives,
design sophisticated situation-aware plans, and perform embodied action
control, with frequent communication with a goal-conditioned active perception
scheme. Specifically, MP5 is developed on top of recent advances in Multimodal
Large Language Models (MLLMs), and the system is modulated into functional
modules that can be scheduled and collaborated to ultimately solve pre-defined
context- and process-dependent tasks. Extensive experiments prove that MP5 can
achieve a 22% success rate on difficult process-dependent tasks and a 91%
success rate on tasks that heavily depend on the context. Moreover, MP5
exhibits a remarkable ability to address many open-ended tasks that are
entirely novel.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07476" title="Abstract">arXiv:2312.07476</a> [<a href="/pdf/2312.07476" title="Download PDF">pdf</a>, <a href="/format/2312.07476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparable Demonstrations are Important in In-Context Learning: A Novel  Perspective on Demonstration Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Caoyun Fan</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jidong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yitian Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">Hao He</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yaohui Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In-Context Learning (ICL) is an important paradigm for adapting Large
Language Models (LLMs) to downstream tasks through a few demonstrations.
Despite the great success of ICL, the limitation of the demonstration number
may lead to demonstration bias, i.e. the input-label mapping induced by LLMs
misunderstands the task's essence. Inspired by human experience, we attempt to
mitigate such bias through the perspective of the inter-demonstration
relationship. Specifically, we construct Comparable Demonstrations (CDs) by
minimally editing the texts to flip the corresponding labels, in order to
highlight the task's essence and eliminate potential spurious correlations
through the inter-demonstration comparison. Through a series of experiments on
CDs, we find that (1) demonstration bias does exist in LLMs, and CDs can
significantly reduce such bias; (2) CDs exhibit good performance in ICL,
especially in out-of-distribution scenarios. In summary, this study explores
the ICL mechanisms from a novel perspective, providing a deeper insight into
the demonstration selection strategy for ICL.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07478" title="Abstract">arXiv:2312.07478</a> [<a href="/pdf/2312.07478" title="Download PDF">pdf</a>, <a href="/format/2312.07478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Double-Flow GAN model for the reconstruction of perceived faces from  brain activities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hui Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Face plays an important role in human's visual perception, and reconstructing
perceived faces from brain activities is challenging because of its difficulty
in extracting high-level features and maintaining consistency of multiple face
attributes, such as expression, identity, gender, etc. In this study, we
proposed a novel reconstruction framework, which we called Double-Flow GAN,
that can enhance the capability of discriminator and handle imbalances in
images from certain domains that are too easy for generators. We also designed
a pretraining process that uses features extracted from images as conditions
for making it possible to pretrain the conditional reconstruction model from
fMRI in a larger pure image dataset. Moreover, we developed a simple pretrained
model to perform fMRI alignment to alleviate the problem of cross-subject
reconstruction due to the variations of brain structure among different
subjects. We conducted experiments by using our proposed method and
state-of-the-art reconstruction models. Our results demonstrated that our
method showed significant reconstruction performance, outperformed the previous
reconstruction models, and exhibited a good generation ability.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07482" title="Abstract">arXiv:2312.07482</a> [<a href="/pdf/2312.07482" title="Download PDF">pdf</a>, <a href="/format/2312.07482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification of retail products: From probabilistic ranking to neural  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hafez%2C+M+M">Manar Mohamed Hafez</a>, 
<a href="/search/cs?searchtype=author&query=Redondo%2C+R+P+D">Rebeca P. D&#xed;az Redondo</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Vilas%2C+A">Ana Fern&#xe1;ndez-Vilas</a>, 
<a href="/search/cs?searchtype=author&query=Paz%C3%B3%2C+H+O">H&#xe9;ctor Olivera Paz&#xf3;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 8 figures, journal
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Applied Sciences, 2021, vol. 11, no 9, p. 4117
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Food retailing is now on an accelerated path to a success penetration into
the digital market by new ways of value creation at all stages of the consumer
decision process. One of the most important imperatives in this path is the
availability of quality data to feed all the process in digital transformation.
But the quality of data is not so obvious if we consider the variety of
products and suppliers in the grocery market. Within this context of digital
transformation of grocery industry, \textit{Midiadia} is Spanish data provider
company that works on converting data from the retailers' products into
knowledge with attributes and insights from the product labels, that is,
maintaining quality data in a dynamic market with a high dispersion of
products. Currently, they manually categorize products (groceries) according to
the information extracted directly (text processing) from the product labelling
and packaging. This paper introduces a solution to automatically categorize the
constantly changing product catalogue into a 3-level food taxonomy. Our
proposal studies three different approaches: a score-based ranking method,
traditional machine learning algorithms, and deep neural networks. Thus, we
provide four different classifiers that support a more efficient and less
error-prone maintenance of groceries catalogues, the main asset of the company.
Finally, we have compared the performance of these three alternatives,
concluding that traditional machine learning algorithms perform better, but
closely followed by the score-based approach.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07485" title="Abstract">arXiv:2312.07485</a> [<a href="/pdf/2312.07485" title="Download PDF">pdf</a>, <a href="/format/2312.07485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MinD-3D: Reconstruct High-quality 3D objects in Human Brain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianxiong Gao</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yuqian Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+X">Xuelin Qian</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jianfeng Feng</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yanwei Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we introduce Recon3DMind, a groundbreaking task focused on
reconstructing 3D visuals from Functional Magnetic Resonance Imaging (fMRI)
signals. This represents a major step forward in cognitive neuroscience and
computer vision. To support this task, we present the fMRI-Shape dataset,
utilizing 360-degree view videos of 3D objects for comprehensive fMRI signal
capture. Containing 55 categories of common objects from daily life, this
dataset will bolster future research endeavors. We also propose MinD-3D, a
novel and effective three-stage framework that decodes and reconstructs the
brain's 3D visual information from fMRI signals. This method starts by
extracting and aggregating features from fMRI frames using a neuro-fusion
encoder, then employs a feature bridge diffusion model to generate
corresponding visual features, and ultimately recovers the 3D object through a
generative transformer decoder. Our experiments demonstrate that this method
effectively extracts features that are valid and highly correlated with visual
regions of interest (ROIs) in fMRI signals. Notably, it not only reconstructs
3D objects with high semantic relevance and spatial similarity but also
significantly deepens our understanding of the human brain's 3D visual
processing capabilities. Project page at: https://jianxgao.github.io/MinD-3D.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07488" title="Abstract">arXiv:2312.07488</a> [<a href="/pdf/2312.07488" title="Download PDF">pdf</a>, <a href="/format/2312.07488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LMDrive: Closed-Loop End-to-End Driving with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+H">Hao Shao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yuxuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Letian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Waslander%2C+S+L">Steven L. Waslander</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongsheng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Despite significant recent progress in the field of autonomous driving,
modern methods still struggle and can incur serious accidents when encountering
long-tail unforeseen events and challenging urban scenarios. On the one hand,
large language models (LLM) have shown impressive reasoning capabilities that
approach "Artificial General Intelligence". On the other hand, previous
autonomous driving methods tend to rely on limited-format inputs (e.g. sensor
data and navigation waypoints), restricting the vehicle's ability to understand
language information and interact with humans. To this end, this paper
introduces LMDrive, a novel language-guided, end-to-end, closed-loop autonomous
driving framework. LMDrive uniquely processes and integrates multi-modal sensor
data with natural language instructions, enabling interaction with humans and
navigation software in realistic instructional settings. To facilitate further
research in language-based closed-loop autonomous driving, we also publicly
release the corresponding dataset which includes approximately 64K
instruction-following data clips, and the LangAuto benchmark that tests the
system's ability to handle complex instructions and challenging driving
scenarios. Extensive closed-loop experiments are conducted to demonstrate
LMDrive's effectiveness. To the best of our knowledge, we're the very first
work to leverage LLMs for closed-loop end-to-end autonomous driving. Codes can
be found at https://github.com/opendilab/LMDrive
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07489" title="Abstract">arXiv:2312.07489</a> [<a href="/pdf/2312.07489" title="Download PDF">pdf</a>, <a href="/format/2312.07489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NearbyPatchCL: Leveraging Nearby Patches for Self-Supervised Patch-Level  Multi-Class Classification in Whole-Slide Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+G">Gia-Bao Le</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V">Van-Tien Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Trung-Nghia Le</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+M">Minh-Triet Tran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MMM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Whole-slide image (WSI) analysis plays a crucial role in cancer diagnosis and
treatment. In addressing the demands of this critical task, self-supervised
learning (SSL) methods have emerged as a valuable resource, leveraging their
efficiency in circumventing the need for a large number of annotations, which
can be both costly and time-consuming to deploy supervised methods.
Nevertheless, patch-wise representation may exhibit instability in performance,
primarily due to class imbalances stemming from patch selection within WSIs. In
this paper, we introduce Nearby Patch Contrastive Learning (NearbyPatchCL), a
novel self-supervised learning method that leverages nearby patches as positive
samples and a decoupled contrastive loss for robust representation learning.
Our method demonstrates a tangible enhancement in performance for downstream
tasks involving patch-level multi-class classification. Additionally, we curate
a new dataset derived from WSIs sourced from the Canine Cutaneous Cancer
Histology, thus establishing a benchmark for the rigorous evaluation of
patch-level multi-class classification methodologies. Intensive experiments
show that our method significantly outperforms the supervised baseline and
state-of-the-art SSL methods with top-1 classification accuracy of 87.56%. Our
method also achieves comparable results while utilizing a mere 1% of labeled
data, a stark contrast to the 100% labeled data requirement of other
approaches. Source code: https://github.com/nvtien457/NearbyPatchCL
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07491" title="Abstract">arXiv:2312.07491</a> [<a href="/pdf/2312.07491" title="Download PDF">pdf</a>, <a href="/format/2312.07491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Robot Acceptance and Trust: A Review and Unanswered Questions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haring%2C+K+S">Kerstin S. Haring</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In SCRITA 2023 Workshop Proceedings (<a href="/abs/2311.05401">arXiv:2311.05401</a>) held in conjunction with 32nd IEEE International Conference on Robot &amp; Human Interactive Communication, 28/08 - 31/08 2023, Busan (Korea)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This position paper briefly considers the current benefits and shortcomings
surrounding robot trust and acceptance, focusing on robots with interactive
capabilities. The paper concludes with currently unanswered questions and may
serve as a jumping-off point for discussion.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07492" title="Abstract">arXiv:2312.07492</a> [<a href="/pdf/2312.07492" title="Download PDF">pdf</a>, <a href="/format/2312.07492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SocialStigmaQA: A Benchmark to Uncover Stigma Amplification in  Generative Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nagireddy%2C+M">Manish Nagireddy</a>, 
<a href="/search/cs?searchtype=author&query=Chiazor%2C+L">Lamogha Chiazor</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+M">Moninder Singh</a>, 
<a href="/search/cs?searchtype=author&query=Baldini%2C+I">Ioana Baldini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Current datasets for unwanted social bias auditing are limited to studying
protected demographic features such as race and gender. In this work, we
introduce a comprehensive benchmark that is meant to capture the amplification
of social bias, via stigmas, in generative language models. We start with a
comprehensive list of 93 stigmas documented in social science literature and
curate a question-answering (QA) dataset which involves simple social
situations. Our benchmark, SocialStigmaQA, contains roughly 10K prompts, with a
variety of prompt styles, carefully constructed to systematically test for both
social bias and model robustness. We present results for SocialStigmaQA with
two widely used open source generative language models and we demonstrate that
the output generated by these models considerably amplifies existing social
bias against stigmatized groups. Specifically, we find that the proportion of
socially biased output ranges from 45% to 59% across a variety of decoding
strategies and prompting styles. We discover that the deliberate design of the
templates in our benchmark (e.g., by adding biasing text to the prompt or
varying the answer that indicates bias) impact the model tendencies to generate
socially biased output. Additionally, we report on patterns in the generated
chain-of-thought output, finding a variety of problems from subtle bias to
evidence of a lack of reasoning.
<br />Warning: This paper contains examples of text which is toxic, biased, and
harmful.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07495" title="Abstract">arXiv:2312.07495</a> [<a href="/pdf/2312.07495" title="Download PDF">pdf</a>, <a href="/format/2312.07495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Plain ViT Reconstruction for Multi-class Unsupervised Anomaly  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiangning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuhai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yabiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangtai Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This work studies the recently proposed challenging and practical Multi-class
Unsupervised Anomaly Detection (MUAD) task, which only requires normal images
for training while simultaneously testing both normal/anomaly images for
multiple classes. Existing reconstruction-based methods typically adopt pyramid
networks as encoders/decoders to obtain multi-resolution features, accompanied
by elaborate sub-modules with heavier handcraft engineering designs for more
precise localization. In contrast, a plain Vision Transformer (ViT) with simple
architecture has been shown effective in multiple domains, which is simpler,
more effective, and elegant. Following this spirit, this paper explores plain
ViT architecture for MUAD. Specifically, we abstract a Meta-AD concept by
inducing current reconstruction-based methods. Then, we instantiate a novel and
elegant plain ViT-based symmetric ViTAD structure, effectively designed step by
step from three macro and four micro perspectives. In addition, this paper
reveals several interesting findings for further exploration. Finally, we
propose a comprehensive and fair evaluation benchmark on eight metrics for the
MUAD task. Based on a naive training recipe, ViTAD achieves state-of-the-art
(SoTA) results and efficiency on the MVTec AD and VisA datasets without bells
and whistles, obtaining 85.4 mAD that surpasses SoTA UniAD by +3.0, and only
requiring 1.1 hours and 2.3G GPU memory to complete model training by a single
V100 GPU. Source code, models, and more results are available at
https://zhangzjn.github.io/projects/ViTAD.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07500" title="Abstract">arXiv:2312.07500</a> [<a href="/pdf/2312.07500" title="Download PDF">pdf</a>, <a href="/format/2312.07500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Branch Network for Imagery Emotion Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ninh%2C+Q">Quoc-Bao Ninh</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Hai-Chan Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Huynh%2C+T">Triet Huynh</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Trung-Nghia Le</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SOICT 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">For a long time, images have proved perfect at both storing and conveying
rich semantics, especially human emotions. A lot of research has been conducted
to provide machines with the ability to recognize emotions in photos of people.
Previous methods mostly focus on facial expressions but fail to consider the
scene context, meanwhile scene context plays an important role in predicting
emotions, leading to more accurate results. In addition,
Valence-Arousal-Dominance (VAD) values offer a more precise quantitative
understanding of continuous emotions, yet there has been less emphasis on
predicting them compared to discrete emotional categories. In this paper, we
present a novel Multi-Branch Network (MBN), which utilizes various source
information, including faces, bodies, and scene contexts to predict both
discrete and continuous emotions in an image. Experimental results on EMOTIC
dataset, which contains large-scale images of people in unconstrained
situations labeled with 26 discrete categories of emotions and VAD values, show
that our proposed method significantly outperforms state-of-the-art methods
with 28.4% in mAP and 0.93 in MAE. The results highlight the importance of
utilizing multiple contextual information in emotion prediction and illustrate
the potential of our proposed method in a wide range of applications, such as
effective computing, human-computer interaction, and social robotics. Source
code:
https://github.com/BaoNinh2808/Multi-Branch-Network-for-Imagery-Emotion-Prediction
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07504" title="Abstract">arXiv:2312.07504</a> [<a href="/pdf/2312.07504" title="Download PDF">pdf</a>, <a href="/format/2312.07504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COLMAP-Free 3D Gaussian Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sifei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+A">Amey Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Kautz%2C+J">Jan Kautz</a>, 
<a href="/search/cs?searchtype=author&query=Efros%2C+A+A">Alexei A. Efros</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaolong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://oasisyang.github.io/colmap-free-3dgs">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While neural rendering has led to impressive advances in scene reconstruction
and novel view synthesis, it relies heavily on accurately pre-computed camera
poses. To relax this constraint, multiple efforts have been made to train
Neural Radiance Fields (NeRFs) without pre-processed camera poses. However, the
implicit representations of NeRFs provide extra challenges to optimize the 3D
structure and camera poses at the same time. On the other hand, the recently
proposed 3D Gaussian Splatting provides new opportunities given its explicit
point cloud representations. This paper leverages both the explicit geometric
representation and the continuity of the input video stream to perform novel
view synthesis without any SfM preprocessing. We process the input frames in a
sequential manner and progressively grow the 3D Gaussians set by taking one
input frame at a time, without the need to pre-compute the camera poses. Our
method significantly improves over previous approaches in view synthesis and
camera pose estimation under large motion changes. Our project page is
https://oasisyang.github.io/colmap-free-3dgs
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07507" title="Abstract">arXiv:2312.07507</a> [<a href="/pdf/2312.07507" title="Download PDF">pdf</a>, <a href="/format/2312.07507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NAC-TCN: Temporal Convolutional Networks with Causal Dilated  Neighborhood Attention for Emotion Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehta%2C+A">Alexander Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">William Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, presented at ICVIP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the task of emotion recognition from videos, a key improvement has been to
focus on emotions over time rather than a single frame. There are many
architectures to address this task such as GRUs, LSTMs, Self-Attention,
Transformers, and Temporal Convolutional Networks (TCNs). However, these
methods suffer from high memory usage, large amounts of operations, or poor
gradients. We propose a method known as Neighborhood Attention with
Convolutions TCN (NAC-TCN) which incorporates the benefits of attention and
Temporal Convolutional Networks while ensuring that causal relationships are
understood which results in a reduction in computation and memory cost. We
accomplish this by introducing a causal version of Dilated Neighborhood
Attention while incorporating it with convolutions. Our model achieves
comparable, better, or state-of-the-art performance over TCNs, TCAN, LSTMs, and
GRUs while requiring fewer parameters on standard emotion recognition datasets.
We publish our code online for easy reproducibility and use in other projects.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07509" title="Abstract">arXiv:2312.07509</a> [<a href="/pdf/2312.07509" title="Download PDF">pdf</a>, <a href="/format/2312.07509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PEEKABOO: Interactive Video Generation via Masked-Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+Y">Yash Jain</a>, 
<a href="/search/cs?searchtype=author&query=Nasery%2C+A">Anshul Nasery</a>, 
<a href="/search/cs?searchtype=author&query=Vineet%2C+V">Vibhav Vineet</a>, 
<a href="/search/cs?searchtype=author&query=Behl%2C+H">Harkirat Behl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project webpage - <a href="https://jinga-lala.github.io/projects/Peekaboo/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently there has been a lot of progress in text-to-video generation, with
state-of-the-art models being capable of generating high quality, realistic
videos. However, these models lack the capability for users to interactively
control and generate videos, which can potentially unlock new areas of
application. As a first step towards this goal, we tackle the problem of
endowing diffusion-based video generation models with interactive
spatio-temporal control over their output. To this end, we take inspiration
from the recent advances in segmentation literature to propose a novel
spatio-temporal masked attention module - Peekaboo. This module is a
training-free, no-inference-overhead addition to off-the-shelf video generation
models which enables spatio-temporal control. We also propose an evaluation
benchmark for the interactive video generation task. Through extensive
qualitative and quantitative evaluation, we establish that Peekaboo enables
control video generation and even obtains a gain of upto 3.8x in mIoU over
baseline models.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07511" title="Abstract">arXiv:2312.07511</a> [<a href="/pdf/2312.07511" title="Download PDF">pdf</a>, <a href="/format/2312.07511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hitchhiker&#x27;s Guide to Geometric GNNs for 3D Atomic Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duval%2C+A">Alexandre Duval</a>, 
<a href="/search/cs?searchtype=author&query=Mathis%2C+S+V">Simon V. Mathis</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+C+K">Chaitanya K. Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+V">Victor Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Miret%2C+S">Santiago Miret</a>, 
<a href="/search/cs?searchtype=author&query=Malliaros%2C+F+D">Fragkiskos D. Malliaros</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+T">Taco Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Lio%2C+P">Pietro Lio</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>, 
<a href="/search/cs?searchtype=author&query=Bronstein%2C+M">Michael Bronstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Recent advances in computational modelling of atomic systems, spanning
molecules, proteins, and materials, represent them as geometric graphs with
atoms embedded as nodes in 3D Euclidean space. In these graphs, the geometric
attributes transform according to the inherent physical symmetries of 3D atomic
systems, including rotations and translations in Euclidean space, as well as
node permutations. In recent years, Geometric Graph Neural Networks have
emerged as the preferred machine learning architecture powering applications
ranging from protein structure prediction to molecular simulations and material
generation. Their specificity lies in the inductive biases they leverage --
such as physical symmetries and chemical properties -- to learn informative
representations of these geometric graphs. In this opinionated paper, we
provide a comprehensive and self-contained overview of the field of Geometric
GNNs for 3D atomic systems. We cover fundamental background material and
introduce a pedagogical taxonomy of Geometric GNN architectures:(1) invariant
networks, (2) equivariant networks in Cartesian basis, (3) equivariant networks
in spherical basis, and (4) unconstrained networks. Additionally, we outline
key datasets and application areas and suggest future research directions. The
objective of this work is to present a structured perspective on the field,
making it accessible to newcomers and aiding practitioners in gaining an
intuition for its mathematical abstractions.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07514" title="Abstract">arXiv:2312.07514</a> [<a href="/pdf/2312.07514" title="Download PDF">pdf</a>, <a href="/format/2312.07514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated and Lightweight Design of Electro-hydraulic Ankle Prosthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yi Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xingjian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+X">Xinyu Tian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shaoping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+R">Rujun Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 21 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">For lower limb amputees, an active ankle joint prosthesis can provide basic
mobility functions. This study focuses on an ankle joint prosthesis system
based on the principle of electric-hydraulic actuation. By analyzing the
characteristics of human gait cycles and the mechanics of ankle joint movement,
a lightweight and integrated ankle joint prosthesis is designed, considering
the requirements for normal ankle joint kinematics and dynamics. The components
of the prosthesis are optimized through simulation and iterative improvements,
while ensuring tight integration within minimal space. The design and
simulation verification of the integrated lightweight prosthesis components are
achieved. This research addresses the contradiction between the high output
capability and the constraints on volume and weight in prosthetic devices.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07517" title="Abstract">arXiv:2312.07517</a> [<a href="/pdf/2312.07517" title="Download PDF">pdf</a>, <a href="/format/2312.07517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Search Optimization with Query Likelihood Boosting and Two-Level  Approximate Search for Edge Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+H">Helian Feng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xin He</a>, 
<a href="/search/cs?searchtype=author&query=Strimel%2C+G+P">Grant P. Strimel</a>, 
<a href="/search/cs?searchtype=author&query=Ghassemi%2C+F">Farhad Ghassemi</a>, 
<a href="/search/cs?searchtype=author&query=Kebarighotbi%2C+A">Ali Kebarighotbi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 figures, accepted at ECI workshop @ CIKM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Databases (cs.DB)

</div>
<p class="mathjax">We present a novel search optimization solution for approximate nearest
neighbor (ANN) search on resource-constrained edge devices. Traditional ANN
approaches fall short in meeting the specific demands of real-world scenarios,
e.g., skewed query likelihood distribution and search on large-scale indices
with a low latency and small footprint. To address these limitations, we
introduce two key components: a Query Likelihood Boosted Tree (QLBT) to
optimize average search latency for frequently used small datasets, and a
two-level approximate search algorithm to enable efficient retrieval with large
datasets on edge devices. We perform thorough evaluation on simulated and real
data and demonstrate QLBT can significantly reduce latency by 15% on real data
and our two-level search algorithm successfully achieve deployable accuracy and
latency on a 10 million dataset for edge devices. In addition, we provide a
comprehensive protocol for configuring and optimizing on-device search
algorithm through extensive empirical studies.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07523" title="Abstract">arXiv:2312.07523</a> [<a href="/pdf/2312.07523" title="Download PDF">pdf</a>, <a href="/format/2312.07523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Healing Distributed Swarm Formation Control Using Image Moments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C+L">C. Lin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ridgley%2C+I+L+D">Israel L. Donato Ridgley</a>, 
<a href="/search/cs?searchtype=author&query=Elwin%2C+M+L">Matthew L. Elwin</a>, 
<a href="/search/cs?searchtype=author&query=Rubenstein%2C+M">Michael Rubenstein</a>, 
<a href="/search/cs?searchtype=author&query=Freeman%2C+R+A">Randy A. Freeman</a>, 
<a href="/search/cs?searchtype=author&query=Lynch%2C+K+M">Kevin M. Lynch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Human-swarm interaction is facilitated by a low-dimensional encoding of the
swarm formation, independent of the (possibly large) number of robots. We
propose using image moments to encode two-dimensional formations of robots.
Each robot knows the desired formation moments, and simultaneously estimates
the current moments of the entire swarm while controlling its motion to better
achieve the desired group moments. The estimator is a distributed optimization,
requiring no centralized processing, and self-healing, meaning that the process
is robust to initialization errors, packet drops, and robots being added to or
removed from the swarm. Our experimental results with a swarm of 50 robots,
suffering nearly 50% packet loss, show that distributed estimation and control
of image moments effectively achieves desired swarm formations.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07526" title="Abstract">arXiv:2312.07526</a> [<a href="/pdf/2312.07526" title="Download PDF">pdf</a>, <a href="/format/2312.07526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RTMO: Towards High-Performance One-Stage Real-Time Multi-Person Pose  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+P">Peng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+T">Tao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yining Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangtai Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenming Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project page: <a href="https://github.com/open-mmlab/mmpose/tree/dev-1.x/projects/rtmo">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Real-time multi-person pose estimation presents significant challenges in
balancing speed and precision. While two-stage top-down methods slow down as
the number of people in the image increases, existing one-stage methods often
fail to simultaneously deliver high accuracy and real-time performance. This
paper introduces RTMO, a one-stage pose estimation framework that seamlessly
integrates coordinate classification by representing keypoints using dual 1-D
heatmaps within the YOLO architecture, achieving accuracy comparable to
top-down methods while maintaining high speed. We propose a dynamic coordinate
classifier and a tailored loss function for heatmap learning, specifically
designed to address the incompatibilities between coordinate classification and
dense prediction models. RTMO outperforms state-of-the-art one-stage pose
estimators, achieving 1.1% higher AP on COCO while operating about 9 times
faster with the same backbone. Our largest model, RTMO-l, attains 74.8% AP on
COCO val2017 and 141 FPS on a single V100 GPU, demonstrating its efficiency and
accuracy. The code and models are available at
https://github.com/open-mmlab/mmpose/tree/dev-1.x/projects/rtmo.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07527" title="Abstract">arXiv:2312.07527</a> [<a href="/pdf/2312.07527" title="Download PDF">pdf</a>, <a href="/format/2312.07527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BaRDa: A Belief and Reasoning Dataset that Separates Factual Accuracy  and Reasoning Ability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Clark%2C+P">Peter Clark</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+B+D">Bhavana Dalvi Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Tafjord%2C+O">Oyvind Tafjord</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While there are numerous benchmarks comparing the performance of modern
language models (LMs), end-task evaluations often conflate notions of *factual
accuracy* ("truth") and *reasoning ability* ("rationality", or "honesty" in the
sense of correctly reporting implications of beliefs). Our goal is a dataset
that clearly distinguishes these two notions. Our approach is to leverage and
extend a collection of human-annotated *entailment trees*, engineered to
express both good and bad chains of reasoning, and using a mixture of true and
false facts, in particular including counterfactual examples, to avoid belief
bias (also known as the "content effect"). The resulting dataset, called BaRDa,
contains 3000 entailments (1787 valid, 1213 invalid), using 6681 true and 2319
false statements. Testing on four GPT-series models,
GPT3(curie)/GPT3(davinici)/3.5/4, we find factual accuracy (truth) scores of
74.1/80.6/82.6/87.1 and reasoning accuracy scores of 63.1/78.0/71.8/79.2. This
shows the clear progression of models towards improved factual accuracy and
entailment reasoning, and the dataset provides a new benchmark that more
cleanly separates and quantifies these two notions.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07529" title="Abstract">arXiv:2312.07529</a> [<a href="/pdf/2312.07529" title="Download PDF">pdf</a>, <a href="/format/2312.07529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topological Obstructions and How to Avoid Them
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esmaeili%2C+B">Babak Esmaeili</a>, 
<a href="/search/cs?searchtype=author&query=Walters%2C+R">Robin Walters</a>, 
<a href="/search/cs?searchtype=author&query=Zimmermann%2C+H">Heiko Zimmermann</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Meent%2C+J">Jan-Willem van de Meent</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Incorporating geometric inductive biases into models can aid interpretability
and generalization, but encoding to a specific geometric structure can be
challenging due to the imposed topological constraints. In this paper, we
theoretically and empirically characterize obstructions to training encoders
with geometric latent spaces. We show that local optima can arise due to
singularities (e.g. self-intersection) or due to an incorrect degree or winding
number. We then discuss how normalizing flows can potentially circumvent these
obstructions by defining multimodal variational distributions. Inspired by this
observation, we propose a new flow-based model that maps data points to
multimodal distributions over geometric spaces and empirically evaluate our
model on 2 domains. We observe improved stability during training and a higher
chance of converging to a homeomorphic encoder.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07530" title="Abstract">arXiv:2312.07530</a> [<a href="/pdf/2312.07530" title="Download PDF">pdf</a>, <a href="/format/2312.07530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly Supervised 3D Object Detection via Multi-Level Visual Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kuan-Chih Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+Y">Yi-Hsuan Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://github.com/kuanchihhuang/VG-W3D">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Weakly supervised 3D object detection aims to learn a 3D detector with lower
annotation cost, e.g., 2D labels. Unlike prior work which still relies on few
accurate 3D annotations, we propose a framework to study how to leverage
constraints between 2D and 3D domains without requiring any 3D labels.
Specifically, we employ visual data from three perspectives to establish
connections between 2D and 3D domains. First, we design a feature-level
constraint to align LiDAR and image features based on object-aware regions.
Second, the output-level constraint is developed to enforce the overlap between
2D and projected 3D box estimations. Finally, the training-level constraint is
utilized by producing accurate and consistent 3D pseudo-labels that align with
the visual data. We conduct extensive experiments on the KITTI dataset to
validate the effectiveness of the proposed three constraints. Without using any
3D labels, our method achieves favorable performance against state-of-the-art
approaches and is competitive with the method that uses 500-frame 3D
annotations. Code and models will be made publicly available at
https://github.com/kuanchihhuang/VG-W3D.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07531" title="Abstract">arXiv:2312.07531</a> [<a href="/pdf/2312.07531" title="Download PDF">pdf</a>, <a href="/format/2312.07531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WHAM: Reconstructing World-grounded Humans with Accurate 3D Motion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shin%2C+S">Soyong Shin</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Juyong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Halilaj%2C+E">Eni Halilaj</a>, 
<a href="/search/cs?searchtype=author&query=Black%2C+M+J">Michael J. Black</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The estimation of 3D human motion from video has progressed rapidly but
current methods still have several key limitations. First, most methods
estimate the human in camera coordinates. Second, prior work on estimating
humans in global coordinates often assumes a flat ground plane and produces
foot sliding. Third, the most accurate methods rely on computationally
expensive optimization pipelines, limiting their use to offline applications.
Finally, existing video-based methods are surprisingly less accurate than
single-frame methods. We address these limitations with WHAM (World-grounded
Humans with Accurate Motion), which accurately and efficiently reconstructs 3D
human motion in a global coordinate system from video. WHAM learns to lift 2D
keypoint sequences to 3D using motion capture data and fuses this with video
features, integrating motion context and visual information. WHAM exploits
camera angular velocity estimated from a SLAM method together with human motion
to estimate the body's global trajectory. We combine this with a contact-aware
trajectory refinement method that lets WHAM capture human motion in diverse
conditions, such as climbing stairs. WHAM outperforms all existing 3D human
motion recovery methods across multiple in-the-wild benchmarks. Code will be
available for research purposes at <a href="http://wham.is.tue.mpg.de/">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07532" title="Abstract">arXiv:2312.07532</a> [<a href="/pdf/2312.07532" title="Download PDF">pdf</a>, <a href="/format/2312.07532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interfacing Foundation Models&#x27; Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xueyan Zou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Mingyu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhengyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Feng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shilong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Aravinthan%2C+A">Arul Aravinthan</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y+J">Yong Jae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lijuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CODE: <a href="https://github.com/UX-Decoder/FIND">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">We present FIND, a generalized interface for aligning foundation models'
embeddings. As shown in teaser figure, a lightweight transformer interface
without tuning any foundation model weights is enough for a unified image
(segmentation) and dataset-level (retrieval) understanding. The proposed
interface has the following favorable attributes: (1) Generalizable. It applies
to various tasks spanning retrieval, segmentation, \textit{etc.}, under the
same architecture and weights. (2) Prototypable. Different tasks are able to be
implemented through prototyping attention masks and embedding types. (3)
Extendable. The proposed interface is adaptive to new tasks, and new models.
(4) Interleavable. With the benefit of multi-task multi-modal training, the
proposed interface creates an interleaved shared embedding space. In light of
the interleaved embedding space, we introduce the FIND-Bench, which introduces
new training and evaluation annotations to the COCO dataset for interleave
segmentation and retrieval. Our approach achieves state-of-the-art performance
on FIND-Bench and competitive performance on standard retrieval and
segmentation settings. The training, evaluation, and demo code as well as the
dataset have been released at https://github.com/UX-Decoder/FIND.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07533" title="Abstract">arXiv:2312.07533</a> [<a href="/pdf/2312.07533" title="Download PDF">pdf</a>, <a href="/format/2312.07533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VILA: On Pre-training for Visual Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Ji Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongxu Yin</a>, 
<a href="/search/cs?searchtype=author&query=Ping%2C+W">Wei Ping</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Molchanov%2C+P">Pavlo Molchanov</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+A">Andrew Tao</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+H">Huizi Mao</a>, 
<a href="/search/cs?searchtype=author&query=Kautz%2C+J">Jan Kautz</a>, 
<a href="/search/cs?searchtype=author&query=Shoeybi%2C+M">Mohammad Shoeybi</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Song Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual language models (VLMs) rapidly progressed with the recent success of
large language models. There have been growing efforts on visual instruction
tuning to extend the LLM with visual inputs, but lacks an in-depth study of the
visual language pre-training process, where the model learns to perform joint
modeling on both modalities. In this work, we examine the design options for
VLM pre-training by augmenting LLM towards VLM through step-by-step
controllable comparisons. We introduce three main findings: (1) freezing LLMs
during pre-training can achieve decent zero-shot performance, but lack
in-context learning capability, which requires unfreezing the LLM; (2)
interleaved pre-training data is beneficial whereas image-text pairs alone are
not optimal; (3) re-blending text-only instruction data to image-text data
during instruction fine-tuning not only remedies the degradation of text-only
tasks, but also boosts VLM task accuracy. With an enhanced pre-training recipe
we build VILA, a Visual Language model family that consistently outperforms the
state-of-the-art models, e.g., LLaVA-1.5, across main benchmarks without bells
and whistles. Multi-modal pre-training also helps unveil appealing properties
of VILA, including multi-image reasoning, enhanced in-context learning, and
better world knowledge.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07535" title="Abstract">arXiv:2312.07535</a> [<a href="/pdf/2312.07535" title="Download PDF">pdf</a>, <a href="/format/2312.07535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Frequency Estimation Algorithms with and without Predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aamand%2C+A">Anders Aamand</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J+Y">Justin Y. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H+L">Huy L&#xea; Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Silwal%2C+S">Sandeep Silwal</a>, 
<a href="/search/cs?searchtype=author&query=Vakilian%2C+A">Ali Vakilian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Estimating frequencies of elements appearing in a data stream is a key task
in large-scale data analysis. Popular sketching approaches to this problem
(e.g., CountMin and CountSketch) come with worst-case guarantees that
probabilistically bound the error of the estimated frequencies for any possible
input. The work of Hsu et al. (2019) introduced the idea of using machine
learning to tailor sketching algorithms to the specific data distribution they
are being run on. In particular, their learning-augmented frequency estimation
algorithm uses a learned heavy-hitter oracle which predicts which elements will
appear many times in the stream. We give a novel algorithm, which in some
parameter regimes, already theoretically outperforms the learning based
algorithm of Hsu et al. without the use of any predictions. Augmenting our
algorithm with heavy-hitter predictions further reduces the error and improves
upon the state of the art. Empirically, our algorithms achieve superior
performance in all experiments compared to prior approaches.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07536" title="Abstract">arXiv:2312.07536</a> [<a href="/pdf/2312.07536" title="Download PDF">pdf</a>, <a href="/format/2312.07536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FreeControl: Training-Free Spatial Control of Any Text-to-Image  Diffusion Model with Any Condition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mo%2C+S">Sicheng Mo</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+F">Fangzhou Mu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K+H">Kuan Heng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yanli Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+B">Bochen Guan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bolei Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://genforce.github.io/freecontrol/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent approaches such as ControlNet offer users fine-grained spatial control
over text-to-image (T2I) diffusion models. However, auxiliary modules have to
be trained for each type of spatial condition, model architecture, and
checkpoint, putting them at odds with the diverse intents and preferences a
human designer would like to convey to the AI models during the content
creation process. In this work, we present FreeControl, a training-free
approach for controllable T2I generation that supports multiple conditions,
architectures, and checkpoints simultaneously. FreeControl designs structure
guidance to facilitate the structure alignment with a guidance image, and
appearance guidance to enable the appearance sharing between images generated
using the same seed. Extensive qualitative and quantitative experiments
demonstrate the superior performance of FreeControl across a variety of
pre-trained T2I models. In particular, FreeControl facilitates convenient
training-free control over many different architectures and checkpoints, allows
the challenging input conditions on which most of the existing training-free
methods fail, and achieves competitive synthesis quality with training-based
approaches.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07537" title="Abstract">arXiv:2312.07537</a> [<a href="/pdf/2312.07537" title="Download PDF">pdf</a>, <a href="/format/2312.07537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FreeInit: Bridging Initialization Gap in Video Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianxing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+C">Chenyang Si</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuming Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Ziqi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://tianxingwu.github.io/pages/FreeInit/">this https URL</a> Code: <a href="https://github.com/TianxingWu/FreeInit">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Though diffusion-based video generation has witnessed rapid progress, the
inference results of existing models still exhibit unsatisfactory temporal
consistency and unnatural dynamics. In this paper, we delve deep into the noise
initialization of video diffusion models, and discover an implicit
training-inference gap that attributes to the unsatisfactory inference quality.
Our key findings are: 1) the spatial-temporal frequency distribution of the
initial latent at inference is intrinsically different from that for training,
and 2) the denoising process is significantly influenced by the low-frequency
components of the initial noise. Motivated by these observations, we propose a
concise yet effective inference sampling strategy, FreeInit, which
significantly improves temporal consistency of videos generated by diffusion
models. Through iteratively refining the spatial-temporal low-frequency
components of the initial latent during inference, FreeInit is able to
compensate the initialization gap between training and inference, thus
effectively improving the subject appearance and temporal consistency of
generation results. Extensive experiments demonstrate that FreeInit
consistently enhances the generation results of various text-to-video
generation models without additional training.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07538" title="Abstract">arXiv:2312.07538</a> [<a href="/pdf/2312.07538" title="Download PDF">pdf</a>, <a href="/format/2312.07538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anatomically Constrained Implicit Face Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chandran%2C+P">Prashanth Chandran</a>, 
<a href="/search/cs?searchtype=author&query=Zoss%2C+G">Gaspard Zoss</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Coordinate based implicit neural representations have gained rapid popularity
in recent years as they have been successfully used in image, geometry and
scene modeling tasks. In this work, we present a novel use case for such
implicit representations in the context of learning anatomically constrained
face models. Actor specific anatomically constrained face models are the state
of the art in both facial performance capture and performance retargeting.
Despite their practical success, these anatomical models are slow to evaluate
and often require extensive data capture to be built. We propose the anatomical
implicit face model; an ensemble of implicit neural networks that jointly learn
to model the facial anatomy and the skin surface with high-fidelity, and can
readily be used as a drop in replacement to conventional blendshape models.
Given an arbitrary set of skin surface meshes of an actor and only a neutral
shape with estimated skull and jaw bones, our method can recover a dense
anatomical substructure which constrains every point on the facial surface. We
demonstrate the usefulness of our approach in several tasks ranging from shape
fitting, shape editing, and performance retargeting.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07539" title="Abstract">arXiv:2312.07539</a> [<a href="/pdf/2312.07539" title="Download PDF">pdf</a>, <a href="/format/2312.07539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HeadArtist: Text-conditioned 3D Head Generation with Self Score  Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Ziyu Wan</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yujun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yibing Song</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+J">Jing Liao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qifeng Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Amazing results are shown in <a href="https://kumapowerliu.github.io/HeadArtist">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This work presents HeadArtist for 3D head generation from text descriptions.
With a landmark-guided ControlNet serving as the generative prior, we come up
with an efficient pipeline that optimizes a parameterized 3D head model under
the supervision of the prior distillation itself. We call such a process self
score distillation (SSD). In detail, given a sampled camera pose, we first
render an image and its corresponding landmarks from the head model, and add
some particular level of noise onto the image. The noisy image, landmarks, and
text condition are then fed into the frozen ControlNet twice for noise
prediction. Two different classifier-free guidance (CFG) weights are applied
during these two predictions, and the prediction difference offers a direction
on how the rendered image can better match the text of interest. Experimental
results suggest that our approach delivers high-quality 3D head sculptures with
adequate geometry and photorealistic appearance, significantly outperforming
state-ofthe-art methods. We also show that the same pipeline well supports
editing the generated heads, including both geometry deformation and appearance
change.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07540" title="Abstract">arXiv:2312.07540</a> [<a href="/pdf/2312.07540" title="Download PDF">pdf</a>, <a href="/format/2312.07540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> diff History for Long-Context Language Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Piterbarg%2C+U">Ulyana Piterbarg</a>, 
<a href="/search/cs?searchtype=author&query=Pinto%2C+L">Lerrel Pinto</a>, 
<a href="/search/cs?searchtype=author&query=Fergus%2C+R">Rob Fergus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Language Models (LMs) offer an exciting solution for general-purpose embodied
control. However, a key technical issue arises when using an LM-based
controller: environment observations must be converted to text, which coupled
with history, leads to prohibitively large textual prompts. As a result, prior
work in LM agents is limited to restricted domains with either small
observation size or minimal needs for interaction history. In this paper, we
introduce a simple and highly effective solution to these issues. We exploit
the fact that consecutive text observations have high similarity and propose to
compress them via the Unix diff command. We demonstrate our approach in
NetHack, a complex rogue-like video game, that requires long-horizon reasoning
for decision-making and is far from solved, particularly for neural agents.
Diff history offers an average of 4x increase in the length of the text-based
interaction history available to the LM. This observational compression along
with the benefits of abstraction yields a 7x improvement in game score on
held-out environment instances over state-of-the-art baselines. It also
outperforms prior agents that use visual observations by over 40%.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07541" title="Abstract">arXiv:2312.07541</a> [<a href="/pdf/2312.07541" title="Download PDF">pdf</a>, <a href="/format/2312.07541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SMERF: Streamable Memory Efficient Radiance Fields for Real-Time  Large-Scene Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duckworth%2C+D">Daniel Duckworth</a>, 
<a href="/search/cs?searchtype=author&query=Hedman%2C+P">Peter Hedman</a>, 
<a href="/search/cs?searchtype=author&query=Reiser%2C+C">Christian Reiser</a>, 
<a href="/search/cs?searchtype=author&query=Zhizhin%2C+P">Peter Zhizhin</a>, 
<a href="/search/cs?searchtype=author&query=Thibert%2C+J">Jean-Fran&#xe7;ois Thibert</a>, 
<a href="/search/cs?searchtype=author&query=Lu%C4%8Di%C4%87%2C+M">Mario Lu&#x10d;i&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Szeliski%2C+R">Richard Szeliski</a>, 
<a href="/search/cs?searchtype=author&query=Barron%2C+J+T">Jonathan T. Barron</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="https://smerf-3d.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Recent techniques for real-time view synthesis have rapidly advanced in
fidelity and speed, and modern methods are capable of rendering
near-photorealistic scenes at interactive frame rates. At the same time, a
tension has arisen between explicit scene representations amenable to
rasterization and neural fields built on ray marching, with state-of-the-art
instances of the latter surpassing the former in quality while being
prohibitively expensive for real-time applications. In this work, we introduce
SMERF, a view synthesis approach that achieves state-of-the-art accuracy among
real-time methods on large scenes with footprints up to 300 m$^2$ at a
volumetric resolution of 3.5 mm$^3$. Our method is built upon two primary
contributions: a hierarchical model partitioning scheme, which increases model
capacity while constraining compute and memory consumption, and a distillation
training strategy that simultaneously yields high fidelity and internal
consistency. Our approach enables full six degrees of freedom (6DOF) navigation
within a web browser and renders in real-time on commodity smartphones and
laptops. Extensive experiments show that our method exceeds the current
state-of-the-art in real-time novel view synthesis by 0.78 dB on standard
benchmarks and 1.78 dB on large scenes, renders frames three orders of
magnitude faster than state-of-the-art radiance field models, and achieves
real-time performance across a wide variety of commodity devices, including
smartphones. We encourage the reader to explore these models in person at our
project website: https://smerf-3d.github.io.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Wed, 13 Dec 23</h3>
<dl>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04711" title="Abstract">arXiv:2312.04711</a> (cross-list from physics.soc-ph) [<a href="/pdf/2312.04711" title="Download PDF">pdf</a>, <a href="/format/2312.04711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Luck, skill, and depth of competition in games and social hierarchies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Jerdee%2C+M">Maximilian Jerdee</a>, 
<a href="/search/physics?searchtype=author&query=Newman%2C+M+E+J">M. E. J. Newman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 7 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Patterns of wins and losses in pairwise contests, such as occur in sports and
games, consumer research and paired comparison studies, and human and animal
social hierarchies, are commonly analyzed using probabilistic models that allow
one to quantify the strength of competitors or predict the outcome of future
contests. Here we generalize this approach to incorporate two additional
features: an element of randomness or luck that leads to upset wins, and a
"depth of competition" variable that measures the complexity of a game or
hierarchy. Fitting the resulting model to a large collection of data sets we
estimate depth and luck in a range of games, sports, and social situations. In
general, we find that social competition tends to be "deep," meaning it has a
pronounced hierarchy with many distinct levels, but also that there is often a
nonzero chance of an upset victory, meaning that dominance challenges can be
won even by significant underdogs. Competition in sports and games, by
contrast, tends to be shallow and in most cases there is little evidence of
upset wins, beyond those already implied by the shallowness of the hierarchy.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06540" title="Abstract">arXiv:2312.06540</a> (cross-list from math.OC) [<a href="/pdf/2312.06540" title="Download PDF">pdf</a>, <a href="/format/2312.06540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence of the Chambolle-Pock Algorithm in the Absence of  Monotonicity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Evens%2C+B">Brecht Evens</a>, 
<a href="/search/math?searchtype=author&query=Latafat%2C+P">Puya Latafat</a>, 
<a href="/search/math?searchtype=author&query=Patrinos%2C+P">Panagiotis Patrinos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The Chambolle-Pock algorithm (CPA), also known as the primal-dual hybrid
gradient method (PDHG), has surged in popularity in the last decade due to its
success in solving convex/monotone structured problems. This work provides
convergence results for problems with varying degrees of (non)monotonicity,
quantified through a so-called oblique weak Minty condition on the associated
primal-dual operator. Our results reveal novel stepsize and relaxation
parameter ranges which do not only depend on the norm of the linear mapping,
but also on its other singular values. In particular, in nonmonotone settings,
in addition to the classical stepsize conditions for CPA, extra bounds on the
stepsizes and relaxation parameters are required. On the other hand, in the
strongly monotone setting, the relaxation parameter is allowed to exceed the
classical upper bound of two. Moreover, sufficient convergence conditions are
obtained when the individual operators belong to the recently introduced class
of semimonotone operators. Since this class of operators encompasses many
traditional operator classes including (hypo)- and co(hypo)monotone operators,
this analysis recovers and extends existing results for CPA. Several examples
are provided for the aforementioned problem classes to demonstrate and
establish tightness of the proposed stepsize ranges.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06669" title="Abstract">arXiv:2312.06669</a> (cross-list from q-bio.QM) [<a href="/pdf/2312.06669" title="Download PDF">pdf</a>, <a href="/ps/2312.06669" title="Download PostScript">ps</a>, <a href="/format/2312.06669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Association Test Based on Kernel-Based Neural Networks for Complex  Genetic Association Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Hou%2C+T">Tingting Hou</a>, 
<a href="/search/q-bio?searchtype=author&query=Jiang%2C+C">Chang Jiang</a>, 
<a href="/search/q-bio?searchtype=author&query=Lu%2C+Q">Qing Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 4 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">The advent of artificial intelligence, especially the progress of deep neural
networks, is expected to revolutionize genetic research and offer unprecedented
potential to decode the complex relationships between genetic variants and
disease phenotypes, which could mark a significant step toward improving our
understanding of the disease etiology. While deep neural networks hold great
promise for genetic association analysis, limited research has been focused on
developing neural-network-based tests to dissect complex genotype-phenotype
associations. This complexity arises from the opaque nature of neural networks
and the absence of defined limiting distributions. We have previously developed
a kernel-based neural network model (KNN) that synergizes the strengths of
linear mixed models with conventional neural networks. KNN adopts a
computationally efficient minimum norm quadratic unbiased estimator (MINQUE)
algorithm and uses KNN structure to capture the complex relationship between
large-scale sequencing data and a disease phenotype of interest. In the KNN
framework, we introduce a MINQUE-based test to assess the joint association of
genetic variants with the phenotype, which considers non-linear and
non-additive effects and follows a mixture of chi-square distributions. We also
construct two additional tests to evaluate and interpret linear and
non-linear/non-additive genetic effects, including interaction effects. Our
simulations show that our method consistently controls the type I error rate
under various conditions and achieves greater power than a commonly used
sequence kernel association test (SKAT), especially when involving non-linear
and interaction effects. When applied to real data from the UK Biobank, our
approach identified genes associated with hippocampal volume, which can be
further replicated and evaluated for their role in the pathogenesis of
Alzheimer's disease.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06711" title="Abstract">arXiv:2312.06711</a> (cross-list from q-fin.PR) [<a href="/pdf/2312.06711" title="Download PDF">pdf</a>, <a href="/format/2312.06711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics Informed Neural Network for Option Pricing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Dhiman%2C+A">Ashish Dhiman</a>, 
<a href="/search/q-fin?searchtype=author&query=Hu%2C+Y">Yibei Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages + references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Pricing of Securities (q-fin.PR)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
<p class="mathjax">We apply a physics-informed deep-learning approach the PINN approach to the
Black-Scholes equation for pricing American and European options. We test our
approach on both simulated as well as real market data, compare it to
analytical/numerical benchmarks. Our model is able to accurately capture the
price behaviour on simulation data, while also exhibiting reasonable
performance for market data. We also experiment with the architecture and
learning process of our PINN model to provide more understanding of convergence
and stability issues that impact performance.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06715" title="Abstract">arXiv:2312.06715</a> (cross-list from physics.comp-ph) [<a href="/pdf/2312.06715" title="Download PDF">pdf</a>, <a href="/format/2312.06715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The improved backward compatible physics-informed neural networks for  reducing error accumulation and applications in data-driven higher-order  rogue waves
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Lin%2C+S">Shuning Lin</a>, 
<a href="/search/physics?searchtype=author&query=Chen%2C+Y">Yong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Numerical Analysis (math.NA); Pattern Formation and Solitons (nlin.PS)

</div>
<p class="mathjax">Due to the dynamic characteristics of instantaneity and steepness, employing
domain decomposition techniques for simulating rogue wave solutions is highly
appropriate. Wherein, the backward compatible PINN (bc-PINN) is a temporally
sequential scheme to solve PDEs over successive time segments while satisfying
all previously obtained solutions. In this work, we propose improvements to the
original bc-PINN algorithm in two aspects based on the characteristics of error
propagation. One is to modify the loss term for ensuring backward compatibility
by selecting the earliest learned solution for each sub-domain as pseudo
reference solution. The other is to adopt the concatenation of solutions
obtained from individual subnetworks as the final form of the predicted
solution. The improved backward compatible PINN (Ibc-PINN) is applied to study
data-driven higher-order rogue waves for the nonlinear Schr\"{o}dinger (NLS)
equation and the AB system to demonstrate the effectiveness and advantages.
Transfer learning and initial condition guided learning (ICGL) techniques are
also utilized to accelerate the training. Moreover, the error analysis is
conducted on each sub-domain and it turns out that the slowdown of Ibc-PINN in
error accumulation speed can yield greater advantages in accuracy. In short,
numerical results fully indicate that Ibc-PINN significantly outperforms
bc-PINN in terms of accuracy and stability without sacrificing efficiency.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06791" title="Abstract">arXiv:2312.06791</a> (cross-list from math.OC) [<a href="/pdf/2312.06791" title="Download PDF">pdf</a>, <a href="/ps/2312.06791" title="Download PostScript">ps</a>, <a href="/format/2312.06791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Polynomial Representations of Physical Objects with Application  to Certifying Correct Packing Configurations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jones%2C+M">Morgan Jones</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper introduces a novel approach for learning polynomial
representations of physical objects. Given a point cloud data set associated
with a physical object, we solve a one-class classification problem to bound
the data points by a polynomial sublevel set while harnessing Sum-of-Squares
(SOS) programming to enforce prior shape knowledge constraints. By representing
objects as polynomial sublevel sets we further show it is possible to construct
a secondary SOS program to certify whether objects are packed correctly, that
is object boundaries do not overlap and are inside some container set. While
not employing reinforcement learning (RL) in this work, our proposed secondary
SOS program does provide a potential surrogate reward function for RL
algorithms, autonomously rewarding agents that propose object rotations and
translations that correctly pack objects within a given container set.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06828" title="Abstract">arXiv:2312.06828</a> (cross-list from stat.ML) [<a href="/pdf/2312.06828" title="Download PDF">pdf</a>, <a href="/ps/2312.06828" title="Download PostScript">ps</a>, <a href="/format/2312.06828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resetting a fixed broken ELBO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Cukier%2C+R+I">Robert I. Cukier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Variational autoencoders (VAEs) are one class of generative probabilistic
latent-variable models designed for inference based on known data. They balance
reconstruction and regularizer terms. A variational approximation produces an
evidence lower bound (ELBO). Multiplying the regularizer term by beta provides
a beta-VAE/ELBO, improving disentanglement of the latent space. However, any
beta value different than unity violates the laws of conditional probability.
To provide a similarly-parameterized VAE, we develop a Renyi (versus Shannon)
entropy VAE, and a variational approximation RELBO that introduces a similar
parameter. The Renyi VAE has an additional Renyi regularizer-like term with a
conditional distribution that is not learned. The term is evaluated essentially
analytically using a Singular Value Decomposition method.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06845" title="Abstract">arXiv:2312.06845</a> (cross-list from physics.space-ph) [<a href="/pdf/2312.06845" title="Download PDF">pdf</a>, <a href="/format/2312.06845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Cadence Thermospheric Density Estimation enabled by Machine  Learning on Solar Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Malik%2C+S+A">Shreshth A. Malik</a>, 
<a href="/search/physics?searchtype=author&query=Walsh%2C+J">James Walsh</a>, 
<a href="/search/physics?searchtype=author&query=Acciarini%2C+G">Giacomo Acciarini</a>, 
<a href="/search/physics?searchtype=author&query=Berger%2C+T+E">Thomas E. Berger</a>, 
<a href="/search/physics?searchtype=author&query=Baydin%2C+A+G">At&#x131;l&#x131;m G&#xfc;ne&#x15f; Baydin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the Machine Learning and the Physical Sciences workshop, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Space Physics (physics.space-ph)</span>; Earth and Planetary Astrophysics (astro-ph.EP); Machine Learning (cs.LG)

</div>
<p class="mathjax">Accurate estimation of thermospheric density is critical for precise modeling
of satellite drag forces in low Earth orbit (LEO). Improving this estimation is
crucial to tasks such as state estimation, collision avoidance, and re-entry
calculations. The largest source of uncertainty in determining thermospheric
density is modeling the effects of space weather driven by solar and
geomagnetic activity. Current operational models rely on ground-based proxy
indices which imperfectly correlate with the complexity of solar outputs and
geomagnetic responses. In this work, we directly incorporate NASA's Solar
Dynamics Observatory (SDO) extreme ultraviolet (EUV) spectral images into a
neural thermospheric density model to determine whether the predictive
performance of the model is increased by using space-based EUV imagery data
instead of, or in addition to, the ground-based proxy indices. We demonstrate
that EUV imagery can enable predictions with much higher temporal resolution
and replace ground-based proxies while significantly increasing performance
relative to current operational models. Our method paves the way for
assimilating EUV image data into operational thermospheric density forecasting
models for use in LEO satellite navigation processes.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06854" title="Abstract">arXiv:2312.06854</a> (cross-list from physics.space-ph) [<a href="/pdf/2312.06854" title="Download PDF">pdf</a>, <a href="/format/2312.06854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Machine Learning Based Approach to Orbit Modelling  Applied to Space Traffic Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Stevenson%2C+E">Emma Stevenson</a>, 
<a href="/search/physics?searchtype=author&query=Rodriguez-Fernandez%2C+V">Victor Rodriguez-Fernandez</a>, 
<a href="/search/physics?searchtype=author&query=Urrutxua%2C+H">Hodei Urrutxua</a>, 
<a href="/search/physics?searchtype=author&query=Morand%2C+V">Vincent Morand</a>, 
<a href="/search/physics?searchtype=author&query=Camacho%2C+D">David Camacho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the 2021 International Association for the Advancement of Space Safety (IAASS) Conf
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc. 11th International Association for the Advancement of Space
  Safety (IAASS 2021) Conf
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Space Physics (physics.space-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper presents a novel methodology for improving the performance of
machine learning based space traffic management tasks through the use of a
pre-trained orbit model. Taking inspiration from BERT-like self-supervised
language models in the field of natural language processing, we introduce
ORBERT, and demonstrate the ability of such a model to leverage large
quantities of readily available orbit data to learn meaningful representations
that can be used to aid in downstream tasks. As a proof of concept of this
approach we consider the task of all vs. all conjunction screening, phrased
here as a machine learning time series classification task. We show that
leveraging unlabelled orbit data leads to improved performance, and that the
proposed approach can be particularly beneficial for tasks where the
availability of labelled data is limited.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06884" title="Abstract">arXiv:2312.06884</a> (cross-list from math.OC) [<a href="/pdf/2312.06884" title="Download PDF">pdf</a>, <a href="/format/2312.06884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An $LDL^T$ Trust-Region Quasi-Newton Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Brust%2C+J+J">Johannes J Brust</a>, 
<a href="/search/math?searchtype=author&query=Gill%2C+P+E">Philip E Gill</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA); Computation (stat.CO)

</div>
<p class="mathjax">For quasi-Newton methods in unconstrained minimization, it is valuable to
develop methods that are robust, i.e., methods that converge on a large number
of problems. Trust-region algorithms are often regarded to be more robust than
line-search methods, however, because trust-region methods are computationally
more expensive, the most popular quasi-Newton implementations use line-search
methods. To fill this gap, we develop a trust-region method that updates an
$LDL^T$ factorization, scales quadratically with the size of the problem, and
is competitive with a conventional line-search method.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06907" title="Abstract">arXiv:2312.06907</a> (cross-list from eess.AS) [<a href="/pdf/2312.06907" title="Download PDF">pdf</a>, <a href="/format/2312.06907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> w2v-SELD: A Sound Event Localization and Detection Framework for  Self-Supervised Spatial Audio Pre-Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Santos%2C+O+L+d">Orlem Lima dos Santos</a>, 
<a href="/search/eess?searchtype=author&query=Rosero%2C+K">Karen Rosero</a>, 
<a href="/search/eess?searchtype=author&query=de+Alencar+Lotufo%2C+R">Roberto de Alencar Lotufo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Sound Event Detection and Localization (SELD) constitutes a complex task that
depends on extensive multichannel audio recordings with annotated sound events
and their respective locations. In this paper, we introduce a self-supervised
approach for SELD adapted from the pre-training methodology of wav2vec 2.0,
which learns representations directly from raw audio data, eliminating the need
for supervision. By applying this approach to SELD, we can leverage a
substantial amount of unlabeled 3D audio data to learn robust representations
of sound events and their locations. Our method comprises two primary stages:
pre-training and fine-tuning. In the pre-training phase, unlabeled 3D audio
datasets are utilized to train our w2v-SELD model, capturing intricate
high-level features and contextual information inherent in audio signals.
Subsequently, in the fine-tuning stage, a smaller dataset with labeled SELD
data fine-tunes the pre-trained model. Experimental results on benchmark
datasets demonstrate the effectiveness of the proposed self-supervised approach
for SELD. The model surpasses baseline systems provided with the datasets and
achieves competitive performance comparable to state-of-the-art supervised
methods. The code and pre-trained parameters of our w2v-SELD model are
available in this repository.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06912" title="Abstract">arXiv:2312.06912</a> (cross-list from cond-mat.stat-mech) [<a href="/pdf/2312.06912" title="Download PDF">pdf</a>, <a href="/format/2312.06912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory-based involution dilemma on square lattices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Huang%2C+C">Chaochao Huang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wang%2C+C">Chaoqian Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 7 figures, accepted for publication in Chaos, Solitons &amp; Fractals
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Mechanics (cond-mat.stat-mech)</span>; Computer Science and Game Theory (cs.GT); Cellular Automata and Lattice Gases (nlin.CG); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">When involution affects individuals, their efforts do not augment resources
but merely compete for limited resources. From entrance exams to company
overtime, such efforts lead to unnecessary costs, undermining group welfare.
Meanwhile, the individual advantages or collective disadvantages from this
unnecessary effort may accumulate over time, such as the long-term validity of
test scores. To identify the role of this memory factor, we propose a
memory-based involution game model. In a more competitive environment, our
findings suggest: (i) with scant social resources, increasing memory length
curbs involution, (ii) with moderate resources, increasing memory length
initially intensifies involution but later reduces it, and (iii) with abundant
social resources, increasing memory length amplifies involution. Conversely, in
a less competitive environment, involution consistently decreases with a larger
memory length. Our research provides insights into mitigating involution by
considering memory effects.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06927" title="Abstract">arXiv:2312.06927</a> (cross-list from econ.TH) [<a href="/pdf/2312.06927" title="Download PDF">pdf</a>, <a href="/ps/2312.06927" title="Download PostScript">ps</a>, <a href="/format/2312.06927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WE economy: Potential of mutual aid distribution based on moral  responsibility and risk vulnerability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Kato%2C+T">Takeshi Kato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Multiagent Systems (cs.MA); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Reducing wealth inequality and disparity is a global challenge. The economic
system is mainly divided into (1) gift and reciprocity, (2) power and
redistribution, (3) market exchange, and (4) mutual aid without reciprocal
obligations. The current inequality stems from a capitalist economy consisting
of (2) and (3). To sublimate (1), which is the human economy, to (4), the
concept of a "mixbiotic society" has been proposed in the philosophical realm.
This is a society in which free and diverse individuals, "I," mix with each
other, recognize their respective "fundamental incapability" and sublimate them
into "WE" solidarity. The economy in this society must have moral
responsibility as a coadventurer and consideration for vulnerability to risk.
Therefore, I focus on two factors of mind perception: moral responsibility and
risk vulnerability, and propose a novel model of wealth distribution following
an econophysical approach. Specifically, I developed a joint-venture model, a
redistribution model in the joint-venture model, and a "WE economy" model. A
simulation comparison of a combination of the joint ventures and redistribution
with the WE economies reveals that WE economies are effective in reducing
inequality and resilient in normalizing wealth distribution as advantages, and
susceptible to free riders as disadvantages. However, this disadvantage can be
compensated for by fostering consensus and fellowship, and by complementing it
with joint ventures. This study essentially presents the effectiveness of moral
responsibility, the complementarity between the WE economy and the joint
economy, and the direction of the economy toward reducing inequality. Future
challenges are to develop the WE economy model based on real economic analysis
and psychology, as well as to promote WE economy fieldwork for worker coops and
platform cooperatives to realize a desirable mixbiotic society.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06976" title="Abstract">arXiv:2312.06976</a> (cross-list from math.OC) [<a href="/pdf/2312.06976" title="Download PDF">pdf</a>, <a href="/format/2312.06976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Network-Aware Asynchronous Distributed ADMM Algorithm for Peer-to-Peer  Energy Trading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yang%2C+Z">Zeyu Yang</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+H">Hao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Networking and Internet Architecture (cs.NI); Systems and Control (eess.SY)

</div>
<p class="mathjax">The increasing uptake of distributed energy resources (DERs) in smart home
prosumers calls for distributed energy management strategies, and the advances
in information and communications technology enable peer-to-peer (P2P) energy
trading and transactive energy management. Many works attempted to solve the
transactive energy management problem using distributed optimization to
preserve the privacy of DERs' operations. But such distributed optimization
requires information exchange among prosumers, often via synchronous
communications, which can be unrealistic in practice. This paper addresses a
transactive energy trading problem for multiple smart home prosumers with
rooftop solar, battery storage, and controllable load, such as heating,
ventilation, and air-conditioning (HVAC) units, considering practical
communication conditions. We formulate a network-aware energy trading
optimization problem, in which a local network operator manages the network
constraints supporting bidirectional energy flows. We develop an asynchronous
distributed alternating direction method of multipliers (ADMM) algorithm to
solve the problem under asynchronous communications, allowing communication
delay and indicating a higher potential for real-world applications. We
validate our design by simulations using real-world data. The results
demonstrate the convergence of our developed asynchronous distributed ADMM
algorithm and show that energy trading reduces the energy cost for smart home
prosumers.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06979" title="Abstract">arXiv:2312.06979</a> (cross-list from eess.IV) [<a href="/pdf/2312.06979" title="Download PDF">pdf</a>, <a href="/ps/2312.06979" title="Download PostScript">ps</a>, <a href="/format/2312.06979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the notion of Hallucinations from the lens of Bias and Validity in  Synthetic CXR Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bhardwaj%2C+G">Gauri Bhardwaj</a>, 
<a href="/search/eess?searchtype=author&query=Govindarajulu%2C+Y">Yuvaraj Govindarajulu</a>, 
<a href="/search/eess?searchtype=author&query=Narayanan%2C+S">Sundaraparipurnan Narayanan</a>, 
<a href="/search/eess?searchtype=author&query=Kulkarni%2C+P">Pavan Kulkarni</a>, 
<a href="/search/eess?searchtype=author&query=Parmar%2C+M">Manojkumar Parmar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 37th Conference on Neural Information Processing Systems (NeurIPS 2023) - "Medical Imaging Meets NeurIPS" Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Medical imaging has revolutionized disease diagnosis, yet the potential is
hampered by limited access to diverse and privacy-conscious datasets.
Open-source medical datasets, while valuable, suffer from data quality and
clinical information disparities. Generative models, such as diffusion models,
aim to mitigate these challenges. At Stanford, researchers explored the utility
of a fine-tuned Stable Diffusion model (RoentGen) for medical imaging data
augmentation. Our work examines specific considerations to expand the Stanford
research question, Could Stable Diffusion Solve a Gap in Medical Imaging Data?
from the lens of bias and validity of the generated outcomes. We leveraged
RoentGen to produce synthetic Chest-XRay (CXR) images and conducted assessments
on bias, validity, and hallucinations. Diagnostic accuracy was evaluated by a
disease classifier, while a COVID classifier uncovered latent hallucinations.
The bias analysis unveiled disparities in classification performance among
various subgroups, with a pronounced impact on the Female Hispanic subgroup.
Furthermore, incorporating race and gender into input prompts exacerbated
fairness issues in the generated images. The quality of synthetic images
exhibited variability, particularly in certain disease classes, where there was
more significant uncertainty compared to the original images. Additionally, we
observed latent hallucinations, with approximately 42% of the images
incorrectly indicating COVID, hinting at the presence of hallucinatory
elements. These identifications provide new research directions towards
interpretability of synthetic CXR images, for further understanding of
associated risks and patient safety in medical applications.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06981" title="Abstract">arXiv:2312.06981</a> (cross-list from math.NT) [<a href="/pdf/2312.06981" title="Download PDF">pdf</a>, <a href="/ps/2312.06981" title="Download PostScript">ps</a>, <a href="/format/2312.06981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear independence of series related to the Thue--Morse sequence along  powers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Coons%2C+M">Michael Coons</a>, 
<a href="/search/math?searchtype=author&query=Tachiya%2C+Y">Yohei Tachiya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Number Theory (math.NT)</span>; Formal Languages and Automata Theory (cs.FL); Combinatorics (math.CO)

</div>
<p class="mathjax">The Thue--Morse sequence $\{t(n)\}_{n\geqslant 1}$ is the indicator function
of the parity of the number of ones in the binary expansion of positive
integers $n$, where $t(n)=1$ (resp. $=0$) if the binary expansion of $n$ has an
odd (resp. even) number of ones. In this paper, we generalize a recent result
of E.~Miyanohara by showing that, for a fixed Pisot or Salem number
$\beta&gt;\sqrt{\varphi}=1.272019649\ldots$, the set of the numbers $$ 1,\quad
\sum_{n\geqslant 1}\frac{t(n)}{\beta^{n}},\quad \sum_{n\geqslant
1}\frac{t(n^2)}{\beta^{n}},\quad \dots, \quad \sum_{n\geqslant
1}\frac{t(n^k)}{\beta^{n}},\quad \dots $$ is linearly independent over the
field $\mathbb{Q}(\beta)$, where $\varphi:=(1+\sqrt{5})/2$ is the golden ratio.
Our result implies that for any $k\geqslant 1$ and for any
$a_1,a_2,\ldots,a_k\in\mathbb{Q}(\beta)$, not all zero, the sequence
\{$a_1t(n)+a_2t(n^2)+\cdots+a_kt(n^k)\}_{n\geqslant 1}$ cannot be eventually
periodic.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07034" title="Abstract">arXiv:2312.07034</a> (cross-list from math.OC) [<a href="/pdf/2312.07034" title="Download PDF">pdf</a>, <a href="/ps/2312.07034" title="Download PostScript">ps</a>, <a href="/format/2312.07034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GNBG-Generated Test Suite for Box-Constrained Numerical Global  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gandomi%2C+A+H">Amir H. Gandomi</a> (1,2), 
<a href="/search/math?searchtype=author&query=Yazdani%2C+D">Danial Yazdani</a> (1), 
<a href="/search/math?searchtype=author&query=Omidvar%2C+M+N">Mohammad Nabi Omidvar</a> (3), 
<a href="/search/math?searchtype=author&query=Deb%2C+K">Kalyanmoy Deb</a> (4) ((1) Faculty of Engineering &amp; Information Technology, University of Technology Sydney, (2) University Research and Innovation Center (EKIK), Obuda University, (3) School of Computing, University of Leeds, and Leeds University Business School, (4) BEACON Center, Michigan State University)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">This document introduces a set of 24 box-constrained numerical global
optimization problem instances, systematically constructed using the
Generalized Numerical Benchmark Generator (GNBG). These instances cover a broad
spectrum of problem features, including varying degrees of modality,
ruggedness, symmetry, conditioning, variable interaction structures, basin
linearity, and deceptiveness. Purposefully designed, this test suite offers
varying difficulty levels and problem characteristics, facilitating rigorous
evaluation and comparative analysis of optimization algorithms. By presenting
these problems, we aim to provide researchers with a structured platform to
assess the strengths and weaknesses of their algorithms against challenges with
known, controlled characteristics. For reproducibility, the MATLAB source code
for this test suite is publicly available.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07102" title="Abstract">arXiv:2312.07102</a> (cross-list from physics.optics) [<a href="/pdf/2312.07102" title="Download PDF">pdf</a>, <a href="/format/2312.07102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calibration-free quantitative phase imaging in multi-core fiber  endoscopes using end-to-end deep learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Sun%2C+J">Jiawei Sun</a>, 
<a href="/search/physics?searchtype=author&query=Zhao%2C+B">Bin Zhao</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+D">Dong Wang</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+Z">Zhigang Wang</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Koukourakis%2C+N">Nektarios Koukourakis</a>, 
<a href="/search/physics?searchtype=author&query=Czarske%2C+J+W">Juergen W. Czarske</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+X">Xuelong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages. 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Artificial Intelligence (cs.AI); Biological Physics (physics.bio-ph); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Quantitative phase imaging (QPI) through multi-core fibers (MCFs) has been an
emerging in vivo label-free endoscopic imaging modality with minimal
invasiveness. However, the computational demands of conventional iterative
phase retrieval algorithms have limited their real-time imaging potential. We
demonstrate a learning-based MCF phase imaging method, that significantly
reduced the phase reconstruction time to 5.5 ms, enabling video-rate imaging at
181 fps. Moreover, we introduce an innovative optical system that automatically
generated the first open-source dataset tailored for MCF phase imaging,
comprising 50,176 paired speckle and phase images. Our trained deep neural
network (DNN) demonstrates robust phase reconstruction performance in
experiments with a mean fidelity of up to 99.8\%. Such an efficient fiber phase
imaging approach can broaden the applications of QPI in hard-to-reach areas.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07128" title="Abstract">arXiv:2312.07128</a> (cross-list from eess.IV) [<a href="/pdf/2312.07128" title="Download PDF">pdf</a>, <a href="/ps/2312.07128" title="Download PostScript">ps</a>, <a href="/format/2312.07128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MS-Twins: Multi-Scale Deep Self-Attention Networks for Medical Image  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+J">Jing Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Although transformer is preferred in natural language processing, few studies
have applied it in the field of medical imaging. For its long-term dependency,
the transformer is expected to contribute to unconventional convolution neural
net conquer their inherent spatial induction bias. The lately suggested
transformer-based partition method only uses the transformer as an auxiliary
module to help encode the global context into a convolutional representation.
There is hardly any study about how to optimum bond self-attention (the kernel
of transformers) with convolution. To solve the problem, the article proposes
MS-Twins (Multi-Scale Twins), which is a powerful segmentation model on account
of the bond of self-attention and convolution. MS-Twins can better capture
semantic and fine-grained information by combining different scales and
cascading features. Compared with the existing network structure, MS-Twins has
made significant progress on the previous method based on the transformer of
two in common use data sets, Synapse and ACDC. In particular, the performance
of MS-Twins on Synapse is 8% higher than SwinUNet. Even compared with nnUNet,
the best entirely convoluted medical image segmentation network, the
performance of MS-Twins on Synapse and ACDC still has a bit advantage.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07161" title="Abstract">arXiv:2312.07161</a> (cross-list from astro-ph.EP) [<a href="/pdf/2312.07161" title="Download PDF">pdf</a>, <a href="/format/2312.07161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-dimensional Convolutional Neural Networks for Detecting Transiting  Exoplanets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=%C3%81lvarez%2C+S+I">Santiago Iglesias &#xc1;lvarez</a>, 
<a href="/search/astro-ph?searchtype=author&query=Alonso%2C+E+D">Enrique D&#xed;ez Alonso</a>, 
<a href="/search/astro-ph?searchtype=author&query=S%C3%A1nchez%2C+M+L">Mar&#xed;a Luisa S&#xe1;nchez</a>, 
<a href="/search/astro-ph?searchtype=author&query=Rodr%C3%ADguez%2C+J+R">Javier Rodr&#xed;guez Rodr&#xed;guez</a>, 
<a href="/search/astro-ph?searchtype=author&query=Lasheras%2C+F+S">Fernando S&#xe1;nchez Lasheras</a>, 
<a href="/search/astro-ph?searchtype=author&query=de+Cos+Juez%2C+F+J">Francisco Javier de Cos Juez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Earth and Planetary Astrophysics (astro-ph.EP)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG)

</div>
<p class="mathjax">The transit method is one of the most relevant exoplanet detection
techniques, which consists of detecting periodic eclipses in the light curves
of stars. This is not always easy due to the presence of noise in the light
curves, which is induced, for example, by the response of a telescope to
stellar flux. For this reason, we aimed to develop an artificial neural network
model that is able to detect these transits in light curves obtained from
different telescopes and surveys. We created artificial light curves with and
without transits to try to mimic those expected for the extended mission of the
Kepler telescope (K2) in order to train and validate a 1D convolutional neural
network model, which was later tested, obtaining an accuracy of 99.02 % and an
estimated error (loss function) of 0.03. These results, among others, helped to
confirm that the 1D CNN is a good choice for working with non-phased-folded
Mandel and Agol light curves with transits. It also reduces the number of light
curves that have to be visually inspected to decide if they present
transit-like signals and decreases the time needed for analyzing each (with
respect to traditional analysis).
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07186" title="Abstract">arXiv:2312.07186</a> (cross-list from stat.ML) [<a href="/pdf/2312.07186" title="Download PDF">pdf</a>, <a href="/ps/2312.07186" title="Download PostScript">ps</a>, <a href="/format/2312.07186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Optimal Sobolev Norm Rates for the Vector-Valued Regularized  Least-Squares Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Li%2C+Z">Zhu Li</a>, 
<a href="/search/stat?searchtype=author&query=Meunier%2C+D">Dimitri Meunier</a>, 
<a href="/search/stat?searchtype=author&query=Mollenhauer%2C+M">Mattes Mollenhauer</a>, 
<a href="/search/stat?searchtype=author&query=Gretton%2C+A">Arthur Gretton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2208.01711">arXiv:2208.01711</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present the first optimal rates for infinite-dimensional vector-valued
ridge regression on a continuous scale of norms that interpolate between $L_2$
and the hypothesis space, which we consider as a vector-valued reproducing
kernel Hilbert space. These rates allow to treat the misspecified case in which
the true regression function is not contained in the hypothesis space. We
combine standard assumptions on the capacity of the hypothesis space with a
novel tensor product construction of vector-valued interpolation spaces in
order to characterize the smoothness of the regression function. Our upper
bound not only attains the same rate as real-valued kernel ridge regression,
but also removes the assumption that the target regression function is bounded.
For the lower bound, we reduce the problem to the scalar setting using a
projection argument. We show that these rates are optimal in most cases and
independent of the dimension of the output space. We illustrate our results for
the special case of vector-valued Sobolev spaces.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07226" title="Abstract">arXiv:2312.07226</a> (cross-list from eess.IV) [<a href="/pdf/2312.07226" title="Download PDF">pdf</a>, <a href="/format/2312.07226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Super-Resolution on Rotationally Scanned Photoacoustic Microscopy Images  Incorporating Scanning Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pan%2C+K">Kai Pan</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+L">Linyang Li</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+L">Li Lin</a>, 
<a href="/search/eess?searchtype=author&query=Cheng%2C+P">Pujin Cheng</a>, 
<a href="/search/eess?searchtype=author&query=Lyu%2C+J">Junyan Lyu</a>, 
<a href="/search/eess?searchtype=author&query=Xi%2C+L">Lei Xi</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+X">Xiaoyin Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Photoacoustic Microscopy (PAM) images integrating the advantages of optical
contrast and acoustic resolution have been widely used in brain studies.
However, there exists a trade-off between scanning speed and image resolution.
Compared with traditional raster scanning, rotational scanning provides good
opportunities for fast PAM imaging by optimizing the scanning mechanism.
Recently, there is a trend to incorporate deep learning into the scanning
process to further increase the scanning speed.Yet, most such attempts are
performed for raster scanning while those for rotational scanning are
relatively rare. In this study, we propose a novel and well-performing
super-resolution framework for rotational scanning-based PAM imaging. To
eliminate adjacent rows' displacements due to subject motion or high-frequency
scanning distortion,we introduce a registration module across odd and even rows
in the preprocessing and incorporate displacement degradation in the training.
Besides, gradient-based patch selection is proposed to increase the probability
of blood vessel patches being selected for training. A Transformer-based
network with a global receptive field is applied for better performance.
Experimental results on both synthetic and real datasets demonstrate the
effectiveness and generalizability of our proposed framework for rotationally
scanned PAM images'super-resolution, both quantitatively and qualitatively.
Code is available at https://github.<a href="/abs/com/1171061">com/1171061</a>5/PAMSR.git.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07282" title="Abstract">arXiv:2312.07282</a> (cross-list from stat.ML) [<a href="/pdf/2312.07282" title="Download PDF">pdf</a>, <a href="/format/2312.07282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Class Probability Matching Using Kernel Methods for Label Shift  Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wen%2C+H">Hongwei Wen</a>, 
<a href="/search/stat?searchtype=author&query=Betken%2C+A">Annika Betken</a>, 
<a href="/search/stat?searchtype=author&query=Hang%2C+H">Hanyuan Hang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In domain adaptation, covariate shift and label shift problems are two
distinct and complementary tasks. In covariate shift adaptation where the
differences in data distribution arise from variations in feature
probabilities, existing approaches naturally address this problem based on
\textit{feature probability matching} (\textit{FPM}). However, for label shift
adaptation where the differences in data distribution stem solely from
variations in class probability, current methods still use FPM on the
$d$-dimensional feature space to estimate the class probability ratio on the
one-dimensional label space. To address label shift adaptation more naturally
and effectively, inspired by a new representation of the source domain's class
probability, we propose a new framework called \textit{class probability
matching} (\textit{CPM}) which matches two class probability functions on the
one-dimensional label space to estimate the class probability ratio,
fundamentally different from FPM operating on the $d$-dimensional feature
space. Furthermore, by incorporating the kernel logistic regression into the
CPM framework to estimate the conditional probability, we propose an algorithm
called \textit{class probability matching using kernel methods}
(\textit{CPMKM}) for label shift adaptation. From the theoretical perspective,
we establish the optimal convergence rates of CPMKM with respect to the
cross-entropy loss for multi-class label shift adaptation. From the
experimental perspective, comparisons on real datasets demonstrate that CPMKM
outperforms existing FPM-based and maximum-likelihood-based algorithms.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07324" title="Abstract">arXiv:2312.07324</a> (cross-list from math.OC) [<a href="/pdf/2312.07324" title="Download PDF">pdf</a>, <a href="/ps/2312.07324" title="Download PostScript">ps</a>, <a href="/format/2312.07324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributionally Robust Infinite-horizon Control: from a pool of samples  to the design of dependable controllers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Brouillon%2C+J">Jean-S&#xe9;bastien Brouillon</a>, 
<a href="/search/math?searchtype=author&query=Martin%2C+A">Andrea Martin</a>, 
<a href="/search/math?searchtype=author&query=Lygeros%2C+J">John Lygeros</a>, 
<a href="/search/math?searchtype=author&query=D%C3%B6rfler%2C+F">Florian D&#xf6;rfler</a>, 
<a href="/search/math?searchtype=author&query=Trecate%2C+G+F">Giancarlo Ferrari Trecate</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We study control of constrained linear systems when faced with only partial
statistical information about the disturbance processes affecting the system
dynamics and the sensor measurements. Specifically, given a finite collection
of disturbance realizations, we consider the problem of designing a stabilizing
control policy with provable safety and performance guarantees in face of the
inevitable mismatch between the true and the empirical distributions. We
capture this discrepancy using Wasserstein ambiguity sets, and we formulate a
distributionally robust (DR) optimal control problem, which provides guarantees
on the expected cost, safety, and stability of the system. To solve this
problem, we first present new results for DR optimization of quadratic
objectives using convex programming, showing that strong duality holds under
mild conditions. Then, by combining our results with the system level
parametrization (SLP) of linear feedback policies, we show that the design
problem can be reduced to a semidefinite optimization problem (SDP).
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07358" title="Abstract">arXiv:2312.07358</a> (cross-list from stat.ML) [<a href="/pdf/2312.07358" title="Download PDF">pdf</a>, <a href="/format/2312.07358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributional Bellman Operators over Mean Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wenliang%2C+L+K">Li Kevin Wenliang</a>, 
<a href="/search/stat?searchtype=author&query=D%C3%A9letang%2C+G">Gr&#xe9;goire D&#xe9;letang</a>, 
<a href="/search/stat?searchtype=author&query=Aitchison%2C+M">Matthew Aitchison</a>, 
<a href="/search/stat?searchtype=author&query=Hutter%2C+M">Marcus Hutter</a>, 
<a href="/search/stat?searchtype=author&query=Ruoss%2C+A">Anian Ruoss</a>, 
<a href="/search/stat?searchtype=author&query=Gretton%2C+A">Arthur Gretton</a>, 
<a href="/search/stat?searchtype=author&query=Rowland%2C+M">Mark Rowland</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose a novel algorithmic framework for distributional reinforcement
learning, based on learning finite-dimensional mean embeddings of return
distributions. We derive several new algorithms for dynamic programming and
temporal-difference learning based on this framework, provide asymptotic
convergence theory, and examine the empirical performance of the algorithms on
a suite of tabular tasks. Further, we show that this approach can be
straightforwardly combined with deep reinforcement learning, and obtain a new
deep RL agent that improves over baseline distributional approaches on the
Arcade Learning Environment.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07387" title="Abstract">arXiv:2312.07387</a> (cross-list from stat.ML) [<a href="/pdf/2312.07387" title="Download PDF">pdf</a>, <a href="/format/2312.07387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wiener Chaos in Kernel Regression: Towards Untangling Aleatoric and  Epistemic Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Faulwasser%2C+T">T. Faulwasser</a>, 
<a href="/search/stat?searchtype=author&query=Molodchyk%2C+O">O. Molodchyk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">Gaussian Processes (GPs) are a versatile method that enables different
approaches towards learning for dynamics and control. Gaussianity assumptions
appear in two dimensions in GPs: The positive semi-definite kernel of the
underlying reproducing kernel Hilbert space is used to construct the
co-variance of a Gaussian distribution over functions, while measurement noise
(i.e. data corruption) is usually modeled as i.i.d. additive Gaussian. In this
note, we relax the latter Gaussianity assumption, i.e., we consider kernel
ridge regression with additive i.i.d. non-Gaussian measurement noise. To apply
the usual kernel trick, we rely on the representation of the uncertainty via
polynomial chaos expansions, which are series expansions for random variables
of finite variance introduced by Norbert Wiener. We derive and discuss the
analytic $\mathcal{L}^2$ solution to the arising Wiener kernel regression.
Considering a polynomial system as numerical example, we show that our approach
allows to untangle the effects of epistemic and aleatoric uncertainties.
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07438" title="Abstract">arXiv:2312.07438</a> (cross-list from quant-ph) [<a href="/pdf/2312.07438" title="Download PDF">pdf</a>, <a href="/ps/2312.07438" title="Download PostScript">ps</a>, <a href="/format/2312.07438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Implementation of Interior-Point Methods for Quantum Relative  Entropy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Karimi%2C+M">Mehdi Karimi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tuncel%2C+L">Levent Tuncel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Mathematical Software (cs.MS); Optimization and Control (math.OC)

</div>
<p class="mathjax">Quantum Relative Entropy (QRE) programming is a recently popular and
challenging class of convex optimization problems with significant applications
in quantum computing and quantum information theory. We are interested in
modern interior point (IP) methods based on optimal self-concordant barriers
for the QRE cone. A range of theoretical and numerical challenges associated
with such barrier functions and the QRE cones have hindered the scalability of
IP methods. To address these challenges, we propose a series of numerical and
linear algebraic techniques and heuristics aimed at enhancing the efficiency of
gradient and Hessian computations for the self-concordant barrier function,
solving linear systems, and performing matrix-vector products. We also
introduce and deliberate about some interesting concepts related to QRE such as
symmetric quantum relative entropy (SQRE). We also introduce a two-phase method
for performing facial reduction that can significantly improve the performance
of QRE programming. Our new techniques have been implemented in the latest
version (DDS 2.2) of the software package DDS. In addition to handling QRE
constraints, DDS accepts any combination of several other conic and non-conic
convex constraints. Our comprehensive numerical experiments encompass several
parts including 1) a comparison of DDS 2.2 with Hypatia for the nearest
correlation matrix problem, 2) using DDS for combining QRE constraints with
various other constraint types, and 3) calculating the key rate for quantum key
distribution (QKD) channels and presenting results for several QKD protocols.
</p>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07460" title="Abstract">arXiv:2312.07460</a> (cross-list from eess.IV) [<a href="/pdf/2312.07460" title="Download PDF">pdf</a>, <a href="/format/2312.07460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empirical Validation of Conformal Prediction for Trustworthy Skin  Lesions Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fayyad%2C+J">Jamil Fayyad</a>, 
<a href="/search/eess?searchtype=author&query=Alijani%2C+S">Shadi Alijani</a>, 
<a href="/search/eess?searchtype=author&query=Najjaran%2C+H">Homayoun Najjaran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Uncertainty quantification is a pivotal field that contributes to the
realization of reliable and robust systems. By providing complementary
information, it becomes instrumental in fortifying safe decisions, particularly
within high-risk applications. Nevertheless, a comprehensive understanding of
the advantages and limitations inherent in various methods within the medical
imaging field necessitates further research coupled with in-depth analysis. In
this paper, we explore Conformal Prediction, an emerging distribution-free
uncertainty quantification technique, along with Monte Carlo Dropout and
Evidential Deep Learning methods. Our comprehensive experiments provide a
comparative performance analysis for skin lesion classification tasks across
the three quantification methods. Furthermore, We present insights into the
effectiveness of each method in handling Out-of-Distribution samples from
domain-shifted datasets. Based on our experimental findings, our conclusion
highlights the robustness and consistent performance of conformal prediction
across diverse conditions. This positions it as the preferred choice for
decision-making in safety-critical applications.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07513" title="Abstract">arXiv:2312.07513</a> (cross-list from eess.AS) [<a href="/pdf/2312.07513" title="Download PDF">pdf</a>, <a href="/format/2312.07513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuroHeed+: Improving Neuro-steered Speaker Extraction with Joint  Auditory Attention Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pan%2C+Z">Zexu Pan</a>, 
<a href="/search/eess?searchtype=author&query=Wichern%2C+G">Gordon Wichern</a>, 
<a href="/search/eess?searchtype=author&query=Germain%2C+F+G">Francois G. Germain</a>, 
<a href="/search/eess?searchtype=author&query=Khurana%2C+S">Sameer Khurana</a>, 
<a href="/search/eess?searchtype=author&query=Roux%2C+J+L">Jonathan Le Roux</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Neuro-steered speaker extraction aims to extract the listener's
brain-attended speech signal from a multi-talker speech signal, in which the
attention is derived from the cortical activity. This activity is usually
recorded using electroencephalography (EEG) devices. Though promising, current
methods often have a high speaker confusion error, where the interfering
speaker is extracted instead of the attended speaker, degrading the listening
experience. In this work, we aim to reduce the speaker confusion error in the
neuro-steered speaker extraction model through a jointly fine-tuned auxiliary
auditory attention detection model. The latter reinforces the consistency
between the extracted target speech signal and the EEG representation, and also
improves the EEG representation. Experimental results show that the proposed
network significantly outperforms the baseline in terms of speaker confusion
and overall signal quality in two-talker scenarios.
</p>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07516" title="Abstract">arXiv:2312.07516</a> (cross-list from quant-ph) [<a href="/pdf/2312.07516" title="Download PDF">pdf</a>, <a href="/format/2312.07516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning finitely correlated states: stability of the spectral  reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Fanizza%2C+M">Marco Fanizza</a>, 
<a href="/search/quant-ph?searchtype=author&query=Galke%2C+N">Niklas Galke</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lumbreras%2C+J">Josep Lumbreras</a>, 
<a href="/search/quant-ph?searchtype=author&query=Rouz%C3%A9%2C+C">Cambyse Rouz&#xe9;</a>, 
<a href="/search/quant-ph?searchtype=author&query=Winter%2C+A">Andreas Winter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27+7 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET); Machine Learning (cs.LG)

</div>
<p class="mathjax">We show that marginals of subchains of length $t$ of any finitely correlated
translation invariant state on a chain can be learned, in trace distance, with
$O(t^2)$ copies -- with an explicit dependence on local dimension, memory
dimension and spectral properties of a certain map constructed from the state
-- and computational complexity polynomial in $t$. The algorithm requires only
the estimation of a marginal of a controlled size, in the worst case bounded by
a multiple of the minimum bond dimension, from which it reconstructs a
translation invariant matrix product operator. In the analysis, a central role
is played by the theory of operator systems. A refined error bound can be
proven for $C^*$-finitely correlated states, which have an operational
interpretation in terms of sequential quantum channels applied to the memory
system. We can also obtain an analogous error bound for a class of matrix
product density operators reconstructible by local marginals. In this case, a
linear number of marginals must be estimated, obtaining a sample complexity of
$\tilde{O}(t^3)$. The learning algorithm also works for states that are only
close to a finitely correlated state, with the potential of providing
competitive algorithms for other interesting families of states.
</p>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07534" title="Abstract">arXiv:2312.07534</a> (cross-list from astro-ph.CO) [<a href="/pdf/2312.07534" title="Download PDF">pdf</a>, <a href="/format/2312.07534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cosmological Field Emulation and Parameter Inference with Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Mudur%2C+N">Nayantara Mudur</a>, 
<a href="/search/astro-ph?searchtype=author&query=Cuesta-Lazaro%2C+C">Carolina Cuesta-Lazaro</a>, 
<a href="/search/astro-ph?searchtype=author&query=Finkbeiner%2C+D+P">Douglas P. Finkbeiner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures, Accepted at the Machine Learning and the Physical Sciences workshop, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cosmology and Nongalactic Astrophysics (astro-ph.CO)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG)

</div>
<p class="mathjax">Cosmological simulations play a crucial role in elucidating the effect of
physical parameters on the statistics of fields and on constraining parameters
given information on density fields. We leverage diffusion generative models to
address two tasks of importance to cosmology -- as an emulator for cold dark
matter density fields conditional on input cosmological parameters $\Omega_m$
and $\sigma_8$, and as a parameter inference model that can return constraints
on the cosmological parameters of an input field. We show that the model is
able to generate fields with power spectra that are consistent with those of
the simulated target distribution, and capture the subtle effect of each
parameter on modulations in the power spectrum. We additionally explore their
utility as parameter inference models and find that we can obtain tight
constraints on cosmological parameters.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Wed, 13 Dec 23</h3>
<dl>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1510.02637" title="Abstract">arXiv:1510.02637</a> (replaced) [<a href="/pdf/1510.02637" title="Download PDF">pdf</a>, <a href="/ps/1510.02637" title="Download PostScript">ps</a>, <a href="/format/1510.02637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Ranking of Lyndon Words and Decoding Lexicographically Minimal  de Bruijn Sequence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kociumaka%2C+T">Tomasz Kociumaka</a>, 
<a href="/search/cs?searchtype=author&query=Radoszewski%2C+J">Jakub Radoszewski</a>, 
<a href="/search/cs?searchtype=author&query=Rytter%2C+W">Wojciech Rytter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Corrected an error in the proof of Theorem 32. Applied comments of reviewers from the journal submission
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SIAM J. Discret. Math. 30(4): 2027-2046 (2016)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1902.01353" title="Abstract">arXiv:1902.01353</a> (replaced) [<a href="/pdf/1902.01353" title="Download PDF">pdf</a>, <a href="/ps/1902.01353" title="Download PostScript">ps</a>, <a href="/format/1902.01353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Session Type System for Asynchronous Unreliable Broadcast  Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kouzapas%2C+D">Dimitrios Kouzapas</a>, 
<a href="/search/cs?searchtype=author&query=Gutkovas%2C+R+F">Ramunas Forsberg Gutkovas</a>, 
<a href="/search/cs?searchtype=author&query=Voinea%2C+A+L">A. Laura Voinea</a>, 
<a href="/search/cs?searchtype=author&query=Gay%2C+S+J">Simon J. Gay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2007.08784" title="Abstract">arXiv:2007.08784</a> (replaced) [<a href="/pdf/2007.08784" title="Download PDF">pdf</a>, <a href="/format/2007.08784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Algorithm for the Planar Two-Center Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+K">Kyungjin Cho</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+E">Eunjin Oh</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haitao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+J">Jie Xue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.04985" title="Abstract">arXiv:2010.04985</a> (replaced) [<a href="/pdf/2010.04985" title="Download PDF">pdf</a>, <a href="/format/2010.04985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Structural Theorem for Local Algorithms with Applications to Coding,  Testing, and Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dall%27Agnol%2C+M">Marcel Dall&#x27;Agnol</a>, 
<a href="/search/cs?searchtype=author&query=Gur%2C+T">Tom Gur</a>, 
<a href="/search/cs?searchtype=author&query=Lachish%2C+O">Oded Lachish</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SIAM J. Comput., 52 (2023), pp. 1413-1463
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2011.10908" title="Abstract">arXiv:2011.10908</a> (replaced) [<a href="/pdf/2011.10908" title="Download PDF">pdf</a>, <a href="/ps/2011.10908" title="Download PostScript">ps</a>, <a href="/format/2011.10908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved quantum data analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=B%C4%83descu%2C+C">Costin B&#x103;descu</a>, 
<a href="/search/quant-ph?searchtype=author&query=O%27Donnell%2C+R">Ryan O&#x27;Donnell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.04089" title="Abstract">arXiv:2105.04089</a> (replaced) [<a href="/pdf/2105.04089" title="Download PDF">pdf</a>, <a href="/ps/2105.04089" title="Download PostScript">ps</a>, <a href="/format/2105.04089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effective Methods of QR-Decompositions of Square Complex Matrices by  Fast Discrete Signal-Induced Heap Transforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Grigoryan%2C+A+M">Artyom M. Grigoryan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 4 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.04133" title="Abstract">arXiv:2110.04133</a> (replaced) [<a href="/pdf/2110.04133" title="Download PDF">pdf</a>, <a href="/format/2110.04133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying disparities in intimate partner violence: a machine learning  method to correct for underreporting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shanmugam%2C+D">Divya Shanmugam</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+K">Kaihua Hou</a>, 
<a href="/search/cs?searchtype=author&query=Pierson%2C+E">Emma Pierson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.06074" title="Abstract">arXiv:2112.06074</a> (replaced) [<a href="/pdf/2112.06074" title="Download PDF">pdf</a>, <a href="/format/2112.06074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Early Stopping for Deep Image Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hengkang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Taihui Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Z">Zhong Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tiancong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+H">Hengyue Liang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Ju Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in TMLR (<a href="https://openreview.net/forum?id=231ZzrLC8X">this https URL</a>)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transactions on Machine Learning Research (TMLR), 2835-8856
  (12/2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.16218" title="Abstract">arXiv:2203.16218</a> (replaced) [<a href="/pdf/2203.16218" title="Download PDF">pdf</a>, <a href="/format/2203.16218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> APG: Adaptive Parameter Generation Network for Click-Through Rate  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Bencheng Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Feng Li</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+H">Hongbo Deng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Bo Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2022, 16 pages; The first two authors contributed equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.04619" title="Abstract">arXiv:2205.04619</a> (replaced) [<a href="/pdf/2205.04619" title="Download PDF">pdf</a>, <a href="/format/2205.04619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Risk Preferences of Learning Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haupt%2C+A">Andreas Haupt</a>, 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+A">Aroon Narayanan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Theoretical Economics (econ.TH)

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.04281" title="Abstract">arXiv:2206.04281</a> (replaced) [<a href="/pdf/2206.04281" title="Download PDF">pdf</a>, <a href="/format/2206.04281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local Spatiotemporal Representation Learning for  Longitudinally-consistent Neuroimage Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+M">Mengwei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+N">Neel Dey</a>, 
<a href="/search/cs?searchtype=author&query=Styner%2C+M+A">Martin A. Styner</a>, 
<a href="/search/cs?searchtype=author&query=Botteron%2C+K">Kelly Botteron</a>, 
<a href="/search/cs?searchtype=author&query=Gerig%2C+G">Guido Gerig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.05575" title="Abstract">arXiv:2206.05575</a> (replaced) [<a href="/pdf/2206.05575" title="Download PDF">pdf</a>, <a href="/ps/2206.05575" title="Download PostScript">ps</a>, <a href="/format/2206.05575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MammoFL: Mammographic Breast Density Estimation using Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Muthukrishnan%2C+R">Ramya Muthukrishnan</a>, 
<a href="/search/eess?searchtype=author&query=Heyler%2C+A">Angelina Heyler</a>, 
<a href="/search/eess?searchtype=author&query=Katti%2C+K">Keshava Katti</a>, 
<a href="/search/eess?searchtype=author&query=Pati%2C+S">Sarthak Pati</a>, 
<a href="/search/eess?searchtype=author&query=Mankowski%2C+W">Walter Mankowski</a>, 
<a href="/search/eess?searchtype=author&query=Alahari%2C+A">Aprupa Alahari</a>, 
<a href="/search/eess?searchtype=author&query=Sanborn%2C+M">Michael Sanborn</a>, 
<a href="/search/eess?searchtype=author&query=Conant%2C+E+F">Emily F. Conant</a>, 
<a href="/search/eess?searchtype=author&query=Scott%2C+C">Christopher Scott</a>, 
<a href="/search/eess?searchtype=author&query=Winham%2C+S">Stacey Winham</a>, 
<a href="/search/eess?searchtype=author&query=Vachon%2C+C">Celine Vachon</a>, 
<a href="/search/eess?searchtype=author&query=Chaudhari%2C+P">Pratik Chaudhari</a>, 
<a href="/search/eess?searchtype=author&query=Kontos%2C+D">Despina Kontos</a>, 
<a href="/search/eess?searchtype=author&query=Bakas%2C+S">Spyridon Bakas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Deep learning, federated learning, mammography, breast density, risk assessment
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.13879" title="Abstract">arXiv:2206.13879</a> (replaced) [<a href="/pdf/2206.13879" title="Download PDF">pdf</a>, <a href="/ps/2206.13879" title="Download PostScript">ps</a>, <a href="/format/2206.13879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal analysis of finite element methods for the stochastic Stokes  equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+B">Buyang Li</a>, 
<a href="/search/math?searchtype=author&query=Ma%2C+S">Shu Ma</a>, 
<a href="/search/math?searchtype=author&query=Sun%2C+W">Weiwei Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.05604" title="Abstract">arXiv:2207.05604</a> (replaced) [<a href="/pdf/2207.05604" title="Download PDF">pdf</a>, <a href="/format/2207.05604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Optimal Trajectory Planning with Interaction with the Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Petrone%2C+V">Vincenzo Petrone</a>, 
<a href="/search/cs?searchtype=author&query=Ferrentino%2C+E">Enrico Ferrentino</a>, 
<a href="/search/cs?searchtype=author&query=Chiacchio%2C+P">Pasquale Chiacchio</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters, vol. 7, no. 4, pp.
  10399-10405, Oct. 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.05622" title="Abstract">arXiv:2207.05622</a> (replaced) [<a href="/pdf/2207.05622" title="Download PDF">pdf</a>, <a href="/format/2207.05622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Dynamic Programming Framework for Optimal Planning of Redundant Robots  Along Prescribed Paths With Kineto-Dynamic Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferrentino%2C+E">Enrico Ferrentino</a>, 
<a href="/search/cs?searchtype=author&query=Savino%2C+H+J">Heitor J. Savino</a>, 
<a href="/search/cs?searchtype=author&query=Franchi%2C+A">Antonio Franchi</a>, 
<a href="/search/cs?searchtype=author&query=Chiacchio%2C+P">Pasquale Chiacchio</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Automation Science and Engineering, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.01711" title="Abstract">arXiv:2208.01711</a> (replaced) [<a href="/pdf/2208.01711" title="Download PDF">pdf</a>, <a href="/ps/2208.01711" title="Download PostScript">ps</a>, <a href="/format/2208.01711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Rates for Regularized Conditional Mean Embedding Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Li%2C+Z">Zhu Li</a>, 
<a href="/search/stat?searchtype=author&query=Meunier%2C+D">Dimitri Meunier</a>, 
<a href="/search/stat?searchtype=author&query=Mollenhauer%2C+M">Mattes Mollenhauer</a>, 
<a href="/search/stat?searchtype=author&query=Gretton%2C+A">Arthur Gretton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Typos &amp; revised argument for the Gaussian kernel. Results unchanged
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.05392" title="Abstract">arXiv:2208.05392</a> (replaced) [<a href="/pdf/2208.05392" title="Download PDF">pdf</a>, <a href="/ps/2208.05392" title="Download PostScript">ps</a>, <a href="/format/2208.05392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive multilevel subset simulation with selective refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Elfverson%2C+D">Daniel Elfverson</a>, 
<a href="/search/math?searchtype=author&query=Scheichl%2C+R">Robert Scheichl</a>, 
<a href="/search/math?searchtype=author&query=Weissmann%2C+S">Simon Weissmann</a>, 
<a href="/search/math?searchtype=author&query=DiazDelaO%2C+F+A">F. Alejandro DiazDelaO</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.01874" title="Abstract">arXiv:2209.01874</a> (replaced) [<a href="/pdf/2209.01874" title="Download PDF">pdf</a>, <a href="/format/2209.01874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Best Decisions Are Not the Best Advice: Making Adherence-Aware  Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grand-Cl%C3%A9ment%2C+J">Julien Grand-Cl&#xe9;ment</a>, 
<a href="/search/cs?searchtype=author&query=Pauphilet%2C+J">Jean Pauphilet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.05166" title="Abstract">arXiv:2209.05166</a> (replaced) [<a href="/pdf/2209.05166" title="Download PDF">pdf</a>, <a href="/format/2209.05166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Domain Incremental Video Highlights Detection with the  LiveFood Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pei%2C+S">Sen Pei</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shixiong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xiaojie Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.09247" title="Abstract">arXiv:2209.09247</a> (replaced) [<a href="/pdf/2209.09247" title="Download PDF">pdf</a>, <a href="/format/2209.09247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weak-signal extraction enabled by deep-neural-network denoising of  diffraction data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Oppliger%2C+J">Jens Oppliger</a>, 
<a href="/search/eess?searchtype=author&query=Denner%2C+M+M">M. Michael Denner</a>, 
<a href="/search/eess?searchtype=author&query=K%C3%BCspert%2C+J">Julia K&#xfc;spert</a>, 
<a href="/search/eess?searchtype=author&query=Frison%2C+R">Ruggero Frison</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Q">Qisi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Morawietz%2C+A">Alexander Morawietz</a>, 
<a href="/search/eess?searchtype=author&query=Ivashko%2C+O">Oleh Ivashko</a>, 
<a href="/search/eess?searchtype=author&query=Dippel%2C+A">Ann-Christin Dippel</a>, 
<a href="/search/eess?searchtype=author&query=von+Zimmermann%2C+M">Martin von Zimmermann</a>, 
<a href="/search/eess?searchtype=author&query=Bia%C5%82o%2C+I">Izabela Bia&#x142;o</a>, 
<a href="/search/eess?searchtype=author&query=Martinelli%2C+L">Leonardo Martinelli</a>, 
<a href="/search/eess?searchtype=author&query=Fauqu%C3%A9%2C+B">Beno&#xee;t Fauqu&#xe9;</a>, 
<a href="/search/eess?searchtype=author&query=Choi%2C+J">Jaewon Choi</a>, 
<a href="/search/eess?searchtype=author&query=Garcia-Fernandez%2C+M">Mirian Garcia-Fernandez</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+K">Ke-Jin Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Christensen%2C+N+B">Niels B. Christensen</a>, 
<a href="/search/eess?searchtype=author&query=Kurosawa%2C+T">Tohru Kurosawa</a>, 
<a href="/search/eess?searchtype=author&query=Momono%2C+N">Naoki Momono</a>, 
<a href="/search/eess?searchtype=author&query=Oda%2C+M">Migaku Oda</a>, 
<a href="/search/eess?searchtype=author&query=Natterer%2C+F+D">Fabian D. Natterer</a>, 
<a href="/search/eess?searchtype=author&query=Fischer%2C+M+H">Mark H. Fischer</a>, 
<a href="/search/eess?searchtype=author&query=Neupert%2C+T">Titus Neupert</a>, 
<a href="/search/eess?searchtype=author&query=Chang%2C+J">Johan Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 10 figures; extended study, additional supplementary information, results unchanged
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Strongly Correlated Electrons (cond-mat.str-el); Superconductivity (cond-mat.supr-con); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.09847" title="Abstract">arXiv:2209.09847</a> (replaced) [<a href="/pdf/2209.09847" title="Download PDF">pdf</a>, <a href="/ps/2209.09847" title="Download PostScript">ps</a>, <a href="/format/2209.09847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rationality and correctness in n-player games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Bastianello%2C+L">Lorenzo Bastianello</a>, 
<a href="/search/econ?searchtype=author&query=Ismail%2C+M+S">Mehmet S. Ismail</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.10045" title="Abstract">arXiv:2209.10045</a> (replaced) [<a href="/pdf/2209.10045" title="Download PDF">pdf</a>, <a href="/format/2209.10045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Lower Bounds for Cap Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tyrrell%2C+F">Fred Tyrrell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Discrete Analysis journal version, 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Number Theory (math.NT)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.01959" title="Abstract">arXiv:2210.01959</a> (replaced) [<a href="/pdf/2210.01959" title="Download PDF">pdf</a>, <a href="/format/2210.01959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detect, Retrieve, Comprehend: A Flexible Framework for Zero-Shot  Document-Level Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McDonald%2C+T">Tavish McDonald</a>, 
<a href="/search/cs?searchtype=author&query=Tsan%2C+B">Brian Tsan</a>, 
<a href="/search/cs?searchtype=author&query=Saini%2C+A">Amar Saini</a>, 
<a href="/search/cs?searchtype=author&query=Ordonez%2C+J">Juanita Ordonez</a>, 
<a href="/search/cs?searchtype=author&query=Gutierrez%2C+L">Luis Gutierrez</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+P">Phan Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Mason%2C+B">Blake Mason</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+B">Brenda Ng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.06434" title="Abstract">arXiv:2210.06434</a> (replaced) [<a href="/pdf/2210.06434" title="Download PDF">pdf</a>, <a href="/ps/2210.06434" title="Download PostScript">ps</a>, <a href="/format/2210.06434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-client Label Propagation for Transductive and Semi-Supervised  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scott%2C+J">Jonathan Scott</a>, 
<a href="/search/cs?searchtype=author&query=Yeo%2C+M">Michelle Yeo</a>, 
<a href="/search/cs?searchtype=author&query=Lampert%2C+C+H">Christoph H. Lampert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.06947" title="Abstract">arXiv:2210.06947</a> (replaced) [<a href="/pdf/2210.06947" title="Download PDF">pdf</a>, <a href="/ps/2210.06947" title="Download PostScript">ps</a>, <a href="/format/2210.06947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized State Estimation In A Dimension-Reduced Linear Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Forsling%2C+R">Robin Forsling</a>, 
<a href="/search/eess?searchtype=author&query=Gustafsson%2C+F">Fredrik Gustafsson</a>, 
<a href="/search/eess?searchtype=author&query=Sjanic%2C+Z">Zoran Sjanic</a>, 
<a href="/search/eess?searchtype=author&query=Hendeby%2C+G">Gustaf Hendeby</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages. Submitted to the IEEE Transactions on Signal and Information Processing over Networks for possible publishing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.09932" title="Abstract">arXiv:2210.09932</a> (replaced) [<a href="/pdf/2210.09932" title="Download PDF">pdf</a>, <a href="/format/2210.09932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making Science Simple: Corpora for the Lay Summarisation of Scientific  Literature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goldsack%2C+T">Tomas Goldsack</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chenghua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Scarton%2C+C">Carolina Scarton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures. Accepted to EMNLP 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.12496" title="Abstract">arXiv:2210.12496</a> (replaced) [<a href="/pdf/2210.12496" title="Download PDF">pdf</a>, <a href="/format/2210.12496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Optimization with Conformal Prediction Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stanton%2C+S">Samuel Stanton</a>, 
<a href="/search/cs?searchtype=author&query=Maddox%2C+W">Wesley Maddox</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+A+G">Andrew Gordon Wilson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> For code, see <a href="https://www.github.com/samuelstanton/conformal-bayesopt.git">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of Machine Learning Research, Volume 206, 959-986,
  PMLR, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.14404" title="Abstract">arXiv:2210.14404</a> (replaced) [<a href="/pdf/2210.14404" title="Download PDF">pdf</a>, <a href="/format/2210.14404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Purification with the Manifold Hypothesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhaoyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hartley%2C+R">Richard Hartley</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+P">Peter Tu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of paper accepted at AAAI 2024 with supplementary materials
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.16386" title="Abstract">arXiv:2210.16386</a> (replaced) [<a href="/pdf/2210.16386" title="Download PDF">pdf</a>, <a href="/format/2210.16386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Stationary Bandits with Auto-Regressive Temporal Dependency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qinyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Golrezaei%2C+N">Negin Golrezaei</a>, 
<a href="/search/cs?searchtype=author&query=Bouneffouf%2C+D">Djallel Bouneffouf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13108" title="Abstract">arXiv:2211.13108</a> (replaced) [<a href="/pdf/2211.13108" title="Download PDF">pdf</a>, <a href="/format/2211.13108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integral Continual Learning Along the Tangent Vector Field of Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T+Y">Tian Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Golatkar%2C+A">Aditya Golatkar</a>, 
<a href="/search/cs?searchtype=author&query=Soatto%2C+S">Stefano Soatto</a>, 
<a href="/search/cs?searchtype=author&query=Achille%2C+A">Alessandro Achille</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01819" title="Abstract">arXiv:2212.01819</a> (replaced) [<a href="/pdf/2212.01819" title="Download PDF">pdf</a>, <a href="/format/2212.01819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Terrain Attention and Multi-Scale Rainfall Guidance For  Flood Image Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Feifei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bing Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qidong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shaoqing Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICIP2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.05909" title="Abstract">arXiv:2212.05909</a> (replaced) [<a href="/e-print/2212.05909" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NFResNet: Multi-scale and U-shaped Networks for Deblurring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mittal%2C+T">Tanish Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+P">Preyansh Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Pahwa%2C+E">Esha Pahwa</a>, 
<a href="/search/cs?searchtype=author&query=Makwana%2C+A">Aarya Makwana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Due to limitations in GPU Compute, We weren't able to test the paper on the popularly used GoPro Dataset which is mostly used for testing image deblurring problems. Afterwards the submission on Arxiv, We observed that we missed comparison of our results with some State-of-the-art papers like ARVo &amp; Gated Spatio-Temporal Attention-Guided Video Deblurring
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07363" title="Abstract">arXiv:2212.07363</a> (replaced) [<a href="/pdf/2212.07363" title="Download PDF">pdf</a>, <a href="/format/2212.07363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correctness Notions for Petri Nets with Identifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+der+Werf%2C+J+M+E+M">Jan Martijn E. M. van der Werf</a>, 
<a href="/search/cs?searchtype=author&query=Rivkin%2C+A">Andrey Rivkin</a>, 
<a href="/search/cs?searchtype=author&query=Montali%2C+M">Marco Montali</a>, 
<a href="/search/cs?searchtype=author&query=Polyvyanyy%2C+A">Artem Polyvyanyy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07679" title="Abstract">arXiv:2212.07679</a> (replaced) [<a href="/pdf/2212.07679" title="Download PDF">pdf</a>, <a href="/format/2212.07679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast and exact fixed-radius neighbor search based on sorting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinye Chen</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCttel%2C+S">Stefan G&#xfc;ttel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2202.01456">arXiv:2202.01456</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.13201" title="Abstract">arXiv:2212.13201</a> (replaced) [<a href="/pdf/2212.13201" title="Download PDF">pdf</a>, <a href="/format/2212.13201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Highlighting Named Entities in Input for Auto-Formulation of  Optimization Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gangwar%2C+N">Neeraj Gangwar</a>, 
<a href="/search/cs?searchtype=author&query=Kani%2C+N">Nickvash Kani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in CICM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02884" title="Abstract">arXiv:2301.02884</a> (replaced) [<a href="/pdf/2301.02884" title="Download PDF">pdf</a>, <a href="/format/2301.02884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TunesFormer: Forming Irish Tunes with Control Codes by Bar Patching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shangda Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaobing Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Feng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Maosong Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 figure, 1 table, accepted by HCMIR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03169" title="Abstract">arXiv:2301.03169</a> (replaced) [<a href="/pdf/2301.03169" title="Download PDF">pdf</a>, <a href="/format/2301.03169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study on the Generality of Neural Network Structures for Monocular  Depth Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bae%2C+J">Jinwoo Bae</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+K">Kyumin Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Im%2C+S">Sunghoon Im</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in TPAMI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.04037" title="Abstract">arXiv:2301.04037</a> (replaced) [<a href="/pdf/2301.04037" title="Download PDF">pdf</a>, <a href="/format/2301.04037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ROBUSfT: Robust Real-Time Shape-from-Template, a C++ Library
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shetab-Bushehri%2C+M">Mohammadreza Shetab-Bushehri</a>, 
<a href="/search/cs?searchtype=author&query=Aranda%2C+M">Miguel Aranda</a>, 
<a href="/search/cs?searchtype=author&query=Mezouar%2C+Y">Youcef Mezouar</a>, 
<a href="/search/cs?searchtype=author&query=Bartoli%2C+A">Adrien Bartoli</a>, 
<a href="/search/cs?searchtype=author&query=Ozgur%2C+E">Erol Ozgur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the arXiv version of an article published in IEEE Transactions on Robotics. Please cite the accepted version: M. Shetab-Bushehri, M. Aranda, Y. Mezouar and E. \"Ozg\"ur, "Lattice-based Shape Tracking and Servoing of Elastic Objects," in IEEE Transactions on Robotics, doi: 10.1109/TRO.2023.3331596
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.08517" title="Abstract">arXiv:2301.08517</a> (replaced) [<a href="/pdf/2301.08517" title="Download PDF">pdf</a>, <a href="/format/2301.08517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cohere: Managing Differential Privacy in Large Scale Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=K%C3%BCchler%2C+N">Nicolas K&#xfc;chler</a>, 
<a href="/search/cs?searchtype=author&query=Opel%2C+E">Emanuel Opel</a>, 
<a href="/search/cs?searchtype=author&query=Lycklama%2C+H">Hidde Lycklama</a>, 
<a href="/search/cs?searchtype=author&query=Viand%2C+A">Alexander Viand</a>, 
<a href="/search/cs?searchtype=author&query=Hithnawi%2C+A">Anwar Hithnawi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in IEEE S&amp;P 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10037" title="Abstract">arXiv:2301.10037</a> (replaced) [<a href="/pdf/2301.10037" title="Download PDF">pdf</a>, <a href="/ps/2301.10037" title="Download PostScript">ps</a>, <a href="/format/2301.10037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyper Hoare Logic: (Dis-)Proving Program Hyperproperties (extended  version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dardinier%2C+T">Thibault Dardinier</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+P">Peter M&#xfc;ller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11093" title="Abstract">arXiv:2301.11093</a> (replaced) [<a href="/pdf/2301.11093" title="Download PDF">pdf</a>, <a href="/format/2301.11093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simple diffusion: End-to-end diffusion for high resolution images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoogeboom%2C+E">Emiel Hoogeboom</a>, 
<a href="/search/cs?searchtype=author&query=Heek%2C+J">Jonathan Heek</a>, 
<a href="/search/cs?searchtype=author&query=Salimans%2C+T">Tim Salimans</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01686" title="Abstract">arXiv:2302.01686</a> (replaced) [<a href="/pdf/2302.01686" title="Download PDF">pdf</a>, <a href="/format/2302.01686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Playing with Data: An Augmented Reality Approach to Interact with  Visualizations of IPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuchong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xuan%2C+Y">Yueming Xuan</a>, 
<a href="/search/cs?searchtype=author&query=Yadav%2C+R">Rahul Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Omrani%2C+A">Adel Omrani</a>, 
<a href="/search/cs?searchtype=author&query=Fjeld%2C+M">Morten Fjeld</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In IFIP Conference on Human-Computer Interaction 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IFIP Conference on Human-Computer Interaction 2023 Aug 28 vol
  14143 (pp. 123-144)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02904" title="Abstract">arXiv:2302.02904</a> (replaced) [<a href="/pdf/2302.02904" title="Download PDF">pdf</a>, <a href="/format/2302.02904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Gauss-Newton for learning over-parameterized models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arbel%2C+M">Michael Arbel</a>, 
<a href="/search/cs?searchtype=author&query=Menegaux%2C+R">Romain Menegaux</a>, 
<a href="/search/cs?searchtype=author&query=Wolinski%2C+P">Pierre Wolinski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04664" title="Abstract">arXiv:2302.04664</a> (replaced) [<a href="/pdf/2302.04664" title="Download PDF">pdf</a>, <a href="/ps/2302.04664" title="Download PostScript">ps</a>, <a href="/format/2302.04664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algebraic characterizations of least model and uniform equivalence of  propositional Krom logic programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anti%C4%87%2C+C">Christian Anti&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06137" title="Abstract">arXiv:2302.06137</a> (replaced) [<a href="/pdf/2302.06137" title="Download PDF">pdf</a>, <a href="/format/2302.06137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximum Coverage in Sublinear Space, Faster
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jaud%2C+S">Stephen Jaud</a>, 
<a href="/search/cs?searchtype=author&query=Wirth%2C+A">Anthony Wirth</a>, 
<a href="/search/cs?searchtype=author&query=Choudhury%2C+F">Farhana Choudhury</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07321" title="Abstract">arXiv:2302.07321</a> (replaced) [<a href="/pdf/2302.07321" title="Download PDF">pdf</a>, <a href="/ps/2302.07321" title="Download PostScript">ps</a>, <a href="/format/2302.07321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Classification-Calibration of Gamma-Phi Losses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wang%2C+Y">Yutong Wang</a>, 
<a href="/search/stat?searchtype=author&query=Scott%2C+C+D">Clayton D. Scott</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appeared in COLT 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08166" title="Abstract">arXiv:2302.08166</a> (replaced) [<a href="/pdf/2302.08166" title="Download PDF">pdf</a>, <a href="/format/2302.08166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Neural Operators on Riemannian Manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+G">Gengxiang Chen</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+X">Xu Liu</a>, 
<a href="/search/math?searchtype=author&query=Meng%2C+Q">Qinglu Meng</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+L">Lu Chen</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+C">Changqing Liu</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+Y">Yingguang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08618" title="Abstract">arXiv:2302.08618</a> (replaced) [<a href="/pdf/2302.08618" title="Download PDF">pdf</a>, <a href="/format/2302.08618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SplitOut: Out-of-the-Box Training-Hijacking Detection in Split Learning  via Outlier Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Erdogan%2C+E">Ege Erdogan</a>, 
<a href="/search/cs?searchtype=author&query=Teksen%2C+U">Unat Teksen</a>, 
<a href="/search/cs?searchtype=author&query=Celiktenyildiz%2C+M+S">Mehmet Salih Celiktenyildiz</a>, 
<a href="/search/cs?searchtype=author&query=Kupcu%2C+A">Alptekin Kupcu</a>, 
<a href="/search/cs?searchtype=author&query=Cicek%2C+A+E">A. Ercument Cicek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09648" title="Abstract">arXiv:2302.09648</a> (replaced) [<a href="/pdf/2302.09648" title="Download PDF">pdf</a>, <a href="/format/2302.09648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wrapyfi: A Python Wrapper for Integrating Robots, Sensors, and  Applications across Multiple Middleware
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abawi%2C+F">Fares Abawi</a>, 
<a href="/search/cs?searchtype=author&query=Allgeuer%2C+P">Philipp Allgeuer</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+D">Di Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wermter%2C+S">Stefan Wermter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at HRI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10096" title="Abstract">arXiv:2302.10096</a> (replaced) [<a href="/pdf/2302.10096" title="Download PDF">pdf</a>, <a href="/ps/2302.10096" title="Download PostScript">ps</a>, <a href="/format/2302.10096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalization-based similarity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anti%C4%87%2C+C">Christian Anti&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11091" title="Abstract">arXiv:2302.11091</a> (replaced) [<a href="/pdf/2302.11091" title="Download PDF">pdf</a>, <a href="/ps/2302.11091" title="Download PostScript">ps</a>, <a href="/format/2302.11091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GTRL: An Entity Group-Aware Temporal Knowledge Graph Representation  Learning Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xing Tang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Ling Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TKDE, 16 pages, and 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00357" title="Abstract">arXiv:2303.00357</a> (replaced) [<a href="/pdf/2303.00357" title="Download PDF">pdf</a>, <a href="/format/2303.00357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collective moderation of hate, toxicity, and extremity in online  discussions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lasser%2C+J">Jana Lasser</a>, 
<a href="/search/cs?searchtype=author&query=Herderich%2C+A">Alina Herderich</a>, 
<a href="/search/cs?searchtype=author&query=Garland%2C+J">Joshua Garland</a>, 
<a href="/search/cs?searchtype=author&query=Aroyehun%2C+S+T">Segun Taofeek Aroyehun</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+D">David Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Galesic%2C+M">Mirta Galesic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00836" title="Abstract">arXiv:2303.00836</a> (replaced) [<a href="/pdf/2303.00836" title="Download PDF">pdf</a>, <a href="/format/2303.00836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensemble flow reconstruction in the atmospheric boundary layer from  spatially limited measurements through latent diffusion models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Rybchuk%2C+A">Alex Rybchuk</a>, 
<a href="/search/physics?searchtype=author&query=Hassanaly%2C+M">Malik Hassanaly</a>, 
<a href="/search/physics?searchtype=author&query=Hamilton%2C+N">Nicholas Hamilton</a>, 
<a href="/search/physics?searchtype=author&query=Doubrawa%2C+P">Paula Doubrawa</a>, 
<a href="/search/physics?searchtype=author&query=Fulton%2C+M+J">Mitchell J. Fulton</a>, 
<a href="/search/physics?searchtype=author&query=Mart%C3%ADnez-Tossas%2C+L+A">Luis A. Mart&#xed;nez-Tossas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 19 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Physics of Fluids, 35, 12 (2023) 126604
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00855" title="Abstract">arXiv:2303.00855</a> (replaced) [<a href="/pdf/2303.00855" title="Download PDF">pdf</a>, <a href="/ps/2303.00855" title="Download PostScript">ps</a>, <a href="/format/2303.00855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grounded Decoding: Guiding Text Generation with Grounded Models for  Embodied Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenlong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+F">Fei Xia</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+D">Dhruv Shah</a>, 
<a href="/search/cs?searchtype=author&query=Driess%2C+D">Danny Driess</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+A">Andy Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Florence%2C+P">Pete Florence</a>, 
<a href="/search/cs?searchtype=author&query=Mordatch%2C+I">Igor Mordatch</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>, 
<a href="/search/cs?searchtype=author&query=Hausman%2C+K">Karol Hausman</a>, 
<a href="/search/cs?searchtype=author&query=Ichter%2C+B">Brian Ichter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00878" title="Abstract">arXiv:2303.00878</a> (replaced) [<a href="/pdf/2303.00878" title="Download PDF">pdf</a>, <a href="/format/2303.00878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Exploration of the Temporal $&#x3b1;$-Shape
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weitbrecht%2C+F">Felix Weitbrecht</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 11 figures; more experiments and bounds
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01092" title="Abstract">arXiv:2303.01092</a> (replaced) [<a href="/pdf/2303.01092" title="Download PDF">pdf</a>, <a href="/ps/2303.01092" title="Download PostScript">ps</a>, <a href="/format/2303.01092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ArCL: Enhancing Contrastive Learning with Augmentation-Robust  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xuyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+T">Tianqi Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yisen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jun Yao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Weiran Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICLR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03358" title="Abstract">arXiv:2303.03358</a> (replaced) [<a href="/pdf/2303.03358" title="Download PDF">pdf</a>, <a href="/format/2303.03358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-Optimal Approximation of Matrix Functions by the Lanczos Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Amsel%2C+N">Noah Amsel</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+T">Tyler Chen</a>, 
<a href="/search/math?searchtype=author&query=Greenbaum%2C+A">Anne Greenbaum</a>, 
<a href="/search/math?searchtype=author&query=Musco%2C+C">Cameron Musco</a>, 
<a href="/search/math?searchtype=author&query=Musco%2C+C">Chris Musco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05996" title="Abstract">arXiv:2303.05996</a> (replaced) [<a href="/pdf/2303.05996" title="Download PDF">pdf</a>, <a href="/format/2303.05996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IEEE 802.11az Indoor Positioning with mmWave
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Picazo-Mart%C3%ADnez%2C+P">Pablo Picazo-Mart&#xed;nez</a>, 
<a href="/search/cs?searchtype=author&query=Barroso-Fern%C3%A1ndez%2C+C">Carlos Barroso-Fern&#xe1;ndez</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADn-P%C3%A9rez%2C+J">Jorge Mart&#xed;n-P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Groshev%2C+M">Milan Groshev</a>, 
<a href="/search/cs?searchtype=author&query=de+la+Oliva%2C+A">Antonio de la Oliva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, magazine submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08459" title="Abstract">arXiv:2303.08459</a> (replaced) [<a href="/pdf/2303.08459" title="Download PDF">pdf</a>, <a href="/format/2303.08459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forecasting Intraday Power Output by a Set of PV Systems using Recurrent  Neural Networks and Physical Covariates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bruneau%2C+P">Pierrick Bruneau</a>, 
<a href="/search/cs?searchtype=author&query=Fiorelli%2C+D">David Fiorelli</a>, 
<a href="/search/cs?searchtype=author&query=Braun%2C+C">Christian Braun</a>, 
<a href="/search/cs?searchtype=author&query=Koster%2C+D">Daniel Koster</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08476" title="Abstract">arXiv:2303.08476</a> (replaced) [<a href="/pdf/2303.08476" title="Download PDF">pdf</a>, <a href="/format/2303.08476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Learning for the Robust Verification of Autonomous Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xingyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Gerasimou%2C+S">Simos Gerasimou</a>, 
<a href="/search/cs?searchtype=author&query=Calinescu%2C+R">Radu Calinescu</a>, 
<a href="/search/cs?searchtype=author&query=Imrie%2C+C">Calum Imrie</a>, 
<a href="/search/cs?searchtype=author&query=Robu%2C+V">Valentin Robu</a>, 
<a href="/search/cs?searchtype=author&query=Flynn%2C+D">David Flynn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Communications Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10028" title="Abstract">arXiv:2303.10028</a> (replaced) [<a href="/pdf/2303.10028" title="Download PDF">pdf</a>, <a href="/format/2303.10028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Connectivity with uncertainty regions given as line segments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cabello%2C+S">Sergio Cabello</a>, 
<a href="/search/cs?searchtype=author&query=Gajser%2C+D">David Gajser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Data Structures and Algorithms (cs.DS); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12920" title="Abstract">arXiv:2303.12920</a> (replaced) [<a href="/pdf/2303.12920" title="Download PDF">pdf</a>, <a href="/format/2303.12920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Virtual Reality Visualization of Hand-Object Interactions to  Support Remote Physical Therapy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di+Qi%2C+T">Trudi Di Qi</a>, 
<a href="/search/cs?searchtype=author&query=Boyd%2C+L">LouAnne Boyd</a>, 
<a href="/search/cs?searchtype=author&query=Fitzpatrick%2C+S">Scott Fitzpatrick</a>, 
<a href="/search/cs?searchtype=author&query=Raswan%2C+M">Meghna Raswan</a>, 
<a href="/search/cs?searchtype=author&query=Cibrian%2C+F">Farnceli Cibrian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 15th International Conference on Ubiquitous
  Computing &amp; Ambient Intelligence (UCAmI 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16852" title="Abstract">arXiv:2303.16852</a> (replaced) [<a href="/pdf/2303.16852" title="Download PDF">pdf</a>, <a href="/format/2303.16852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Schr&#xf6;dinger Bridge Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Shi%2C+Y">Yuyang Shi</a>, 
<a href="/search/stat?searchtype=author&query=De+Bortoli%2C+V">Valentin De Bortoli</a>, 
<a href="/search/stat?searchtype=author&query=Campbell%2C+A">Andrew Campbell</a>, 
<a href="/search/stat?searchtype=author&query=Doucet%2C+A">Arnaud Doucet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01168" title="Abstract">arXiv:2304.01168</a> (replaced) [<a href="/pdf/2304.01168" title="Download PDF">pdf</a>, <a href="/format/2304.01168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepAccident: A Motion and Accident Prediction Benchmark for V2X  Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sukmin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+W">Wenxuan Ji</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+E">Enze Xie</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+C">Chongjian Ge</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junsong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02692" title="Abstract">arXiv:2304.02692</a> (replaced) [<a href="/pdf/2304.02692" title="Download PDF">pdf</a>, <a href="/format/2304.02692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Approach to Optimally Solving Sensor Scheduling and Sensor  Selection Problems in Kalman Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dutta%2C+S">Shamak Dutta</a>, 
<a href="/search/math?searchtype=author&query=Wilde%2C+N">Nils Wilde</a>, 
<a href="/search/math?searchtype=author&query=Smith%2C+S+L">Stephen L. Smith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03907" title="Abstract">arXiv:2304.03907</a> (replaced) [<a href="/pdf/2304.03907" title="Download PDF">pdf</a>, <a href="/format/2304.03907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Nonlinear Control via Finite-dimensional Spectral Dynamic  Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+T">Tongzheng Ren</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhaolin Ren</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Na Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Haitong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bo Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added analysis of Nystrom features, more streamlined proofs, and more extensive numerical studies
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07072" title="Abstract">arXiv:2304.07072</a> (replaced) [<a href="/pdf/2304.07072" title="Download PDF">pdf</a>, <a href="/format/2304.07072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CornerFormer: Boosting Corner Representation for Fine-Grained Structured  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Hongbo Tian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yulong Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Linzhi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+X">Xu Ling</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yue Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jiani Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07699" title="Abstract">arXiv:2304.07699</a> (replaced) [<a href="/pdf/2304.07699" title="Download PDF">pdf</a>, <a href="/format/2304.07699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Clustering Framework for Unsupervised and Semi-supervised New Intent  Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanlei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hua Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+F">Fei Long</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+K">Kai Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE TKDE
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Knowledge and Data Engineering 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12130" title="Abstract">arXiv:2304.12130</a> (replaced) [<a href="/pdf/2304.12130" title="Download PDF">pdf</a>, <a href="/format/2304.12130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstructing Turbulent Flows Using Physics-Aware Spatio-Temporal  Dynamics and Test-Time Refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Chen%2C+S">Shengyu Chen</a>, 
<a href="/search/physics?searchtype=author&query=Bao%2C+T">Tianshu Bao</a>, 
<a href="/search/physics?searchtype=author&query=Givi%2C+P">Peyman Givi</a>, 
<a href="/search/physics?searchtype=author&query=Zheng%2C+C">Can Zheng</a>, 
<a href="/search/physics?searchtype=author&query=Jia%2C+X">Xiaowei Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13107" title="Abstract">arXiv:2304.13107</a> (replaced) [<a href="/pdf/2304.13107" title="Download PDF">pdf</a>, <a href="/ps/2304.13107" title="Download PostScript">ps</a>, <a href="/format/2304.13107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Selective RNN for Device-Free Multi-Room Human Presence Detection  Using WiFi CSI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li-Hsiang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Hsiao%2C+A">An-Hung Hsiao</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+F">Fang-Yu Chu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+K">Kai-Ten Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Instrumentation &amp; Measurement
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14123" title="Abstract">arXiv:2304.14123</a> (replaced) [<a href="/pdf/2304.14123" title="Download PDF">pdf</a>, <a href="/format/2304.14123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MCLFIQ: Mobile Contactless Fingerprint Image Quality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Priesnitz%2C+J">Jannis Priesnitz</a>, 
<a href="/search/cs?searchtype=author&query=Wei%C3%9Fenfeld%2C+A">Axel Wei&#xdf;enfeld</a>, 
<a href="/search/cs?searchtype=author&query=Ruzicka%2C+L">Laurenz Ruzicka</a>, 
<a href="/search/cs?searchtype=author&query=Rathgeb%2C+C">Christian Rathgeb</a>, 
<a href="/search/cs?searchtype=author&query=Strobl%2C+B">Bernhard Strobl</a>, 
<a href="/search/cs?searchtype=author&query=Lessmann%2C+R">Ralph Lessmann</a>, 
<a href="/search/cs?searchtype=author&query=Busch%2C+C">Christoph Busch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14660" title="Abstract">arXiv:2304.14660</a> (replaced) [<a href="/pdf/2304.14660" title="Download PDF">pdf</a>, <a href="/format/2304.14660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment Anything Model for Medical Images?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yuhao Huang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+X">Xin Yang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+L">Lian Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+H">Han Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Chang%2C+A">Ao Chang</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+X">Xinrui Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+R">Rusi Chen</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+J">Junxuan Yu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jiongquan Chen</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+C">Chaoyu Chen</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+S">Sijing Liu</a>, 
<a href="/search/eess?searchtype=author&query=Chi%2C+H">Haozhe Chi</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+X">Xindi Hu</a>, 
<a href="/search/eess?searchtype=author&query=Yue%2C+K">Kejuan Yue</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/eess?searchtype=author&query=Grau%2C+V">Vicente Grau</a>, 
<a href="/search/eess?searchtype=author&query=Fan%2C+D">Deng-Ping Fan</a>, 
<a href="/search/eess?searchtype=author&query=Dong%2C+F">Fajin Dong</a>, 
<a href="/search/eess?searchtype=author&query=Ni%2C+D">Dong Ni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Medical Image Analysis. 23 pages, 18 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01971" title="Abstract">arXiv:2305.01971</a> (replaced) [<a href="/pdf/2305.01971" title="Download PDF">pdf</a>, <a href="/format/2305.01971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> District-scale surface temperatures generated from high-resolution  longitudinal thermal infrared images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Subin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ramani%2C+V">Vasantha Ramani</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+M">Miguel Martin</a>, 
<a href="/search/cs?searchtype=author&query=Arjunan%2C+P">Pandarasamy Arjunan</a>, 
<a href="/search/cs?searchtype=author&query=Chong%2C+A">Adrian Chong</a>, 
<a href="/search/cs?searchtype=author&query=Biljecki%2C+F">Filip Biljecki</a>, 
<a href="/search/cs?searchtype=author&query=Ignatius%2C+M">Marcel Ignatius</a>, 
<a href="/search/cs?searchtype=author&query=Poolla%2C+K">Kameshwar Poolla</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+C">Clayton Miller</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sci Data 10, 859 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02023" title="Abstract">arXiv:2305.02023</a> (replaced) [<a href="/pdf/2305.02023" title="Download PDF">pdf</a>, <a href="/ps/2305.02023" title="Download PostScript">ps</a>, <a href="/format/2305.02023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Topology of Poker
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bartholdi%2C+L">Laurent Bartholdi</a>, 
<a href="/search/math?searchtype=author&query=Mikhailov%2C+R">Roman Mikhailov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added URL of data; corrected remark about contractibility
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Topology (math.AT)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05218" title="Abstract">arXiv:2305.05218</a> (replaced) [<a href="/pdf/2305.05218" title="Download PDF">pdf</a>, <a href="/format/2305.05218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Neural Network-based surrogate model for granular flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Choi%2C+Y">Yongjin Choi</a>, 
<a href="/search/physics?searchtype=author&query=Kumar%2C+K">Krishna Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05398" title="Abstract">arXiv:2305.05398</a> (replaced) [<a href="/pdf/2305.05398" title="Download PDF">pdf</a>, <a href="/format/2305.05398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Approach for Approximating 2-Edge-Connected Spanning Subgraph  and 2-Vertex-Connected Spanning Subgraph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%87ivril%2C+A">Ali &#xc7;ivril</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07402" title="Abstract">arXiv:2305.07402</a> (replaced) [<a href="/pdf/2305.07402" title="Download PDF">pdf</a>, <a href="/format/2305.07402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synergistic Interplay between Search and Large Language Models for  Information Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiazhan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+C">Chongyang Tao</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+X">Xiubo Geng</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+T">Tao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Can Xu</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+G">Guodong Long</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongyan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Daxin Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-print. Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10124" title="Abstract">arXiv:2305.10124</a> (replaced) [<a href="/pdf/2305.10124" title="Download PDF">pdf</a>, <a href="/format/2305.10124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Principal Uncertainty Quantification with Spatial Correlation for Image  Restoration Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belhasin%2C+O">Omer Belhasin</a>, 
<a href="/search/cs?searchtype=author&query=Romano%2C+Y">Yaniv Romano</a>, 
<a href="/search/cs?searchtype=author&query=Freedman%2C+D">Daniel Freedman</a>, 
<a href="/search/cs?searchtype=author&query=Rivlin%2C+E">Ehud Rivlin</a>, 
<a href="/search/cs?searchtype=author&query=Elad%2C+M">Michael Elad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12288" title="Abstract">arXiv:2305.12288</a> (replaced) [<a href="/pdf/2305.12288" title="Download PDF">pdf</a>, <a href="/ps/2305.12288" title="Download PostScript">ps</a>, <a href="/format/2305.12288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Cost-Effective Slag-based Mix Activated with Soda Ash and Hydrated  Lime: A Pilot Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sengupta%2C+J">Jayashree Sengupta</a>, 
<a href="/search/stat?searchtype=author&query=Dhang%2C+N">Nirjhar Dhang</a>, 
<a href="/search/stat?searchtype=author&query=Deb%2C+A">Arghya Deb</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13847" title="Abstract">arXiv:2305.13847</a> (replaced) [<a href="/pdf/2305.13847" title="Download PDF">pdf</a>, <a href="/format/2305.13847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A discontinuous Galerkin approach for atmospheric flows with implicit  condensation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Doppler%2C+S">Sabine Doppler</a>, 
<a href="/search/math?searchtype=author&query=Lederer%2C+P+L">Philip L. Lederer</a>, 
<a href="/search/math?searchtype=author&query=Sch%C3%B6berl%2C+J">Joachim Sch&#xf6;berl</a>, 
<a href="/search/math?searchtype=author&query=von+Wahl%2C+H">Henry von Wahl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15057" title="Abstract">arXiv:2305.15057</a> (replaced) [<a href="/pdf/2305.15057" title="Download PDF">pdf</a>, <a href="/format/2305.15057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear-Time Modeling of Linguistic Structure: An Order-Theoretic  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Amini%2C+A">Afra Amini</a>, 
<a href="/search/cs?searchtype=author&query=Sachan%2C+M">Mrinmaya Sachan</a>, 
<a href="/search/cs?searchtype=author&query=Cotterell%2C+R">Ryan Cotterell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023, 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15404" title="Abstract">arXiv:2305.15404</a> (replaced) [<a href="/pdf/2305.15404" title="Download PDF">pdf</a>, <a href="/format/2305.15404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoMa: Robust Dense Feature Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Edstedt%2C+J">Johan Edstedt</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qiyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%B6kman%2C+G">Georg B&#xf6;kman</a>, 
<a href="/search/cs?searchtype=author&query=Wadenb%C3%A4ck%2C+M">M&#xe5;rten Wadenb&#xe4;ck</a>, 
<a href="/search/cs?searchtype=author&query=Felsberg%2C+M">Michael Felsberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15486" title="Abstract">arXiv:2305.15486</a> (replaced) [<a href="/pdf/2305.15486" title="Download PDF">pdf</a>, <a href="/format/2305.15486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPRING: Studying the Paper and Reasoning to Play Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Prabhumoye%2C+S">Shrimai Prabhumoye</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+S+Y">So Yeon Min</a>, 
<a href="/search/cs?searchtype=author&query=Bisk%2C+Y">Yonatan Bisk</a>, 
<a href="/search/cs?searchtype=author&query=Salakhutdinov%2C+R">Ruslan Salakhutdinov</a>, 
<a href="/search/cs?searchtype=author&query=Azaria%2C+A">Amos Azaria</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+T">Tom Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanzhi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15546" title="Abstract">arXiv:2305.15546</a> (replaced) [<a href="/pdf/2305.15546" title="Download PDF">pdf</a>, <a href="/ps/2305.15546" title="Download PostScript">ps</a>, <a href="/format/2305.15546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regret-Optimal Model-Free Reinforcement Learning for Discounted MDPs  with Short Burn-In Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xiang Ji</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gen Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16318" title="Abstract">arXiv:2305.16318</a> (replaced) [<a href="/pdf/2305.16318" title="Download PDF">pdf</a>, <a href="/format/2305.16318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Referred by Multi-Modality: A Unified Temporal Transformer for Video  Object Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shilin Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Renrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Ziyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenchao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhongjiang He</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Peng Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024. Code is released at <a href="https://github.com/OpenGVLab/MUTR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17421" title="Abstract">arXiv:2305.17421</a> (replaced) [<a href="/pdf/2305.17421" title="Download PDF">pdf</a>, <a href="/format/2305.17421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FoPro-KD: Fourier Prompted Effective Knowledge Distillation for  Long-Tailed Medical Image Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Elbatel%2C+M">Marawan Elbatel</a>, 
<a href="/search/eess?searchtype=author&query=Mart%C3%AD%2C+R">Robert Mart&#xed;</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiaomeng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE TMI, code is available at <a href="https://github.com/xmed-lab/FoPro-KD">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19302" title="Abstract">arXiv:2305.19302</a> (replaced) [<a href="/pdf/2305.19302" title="Download PDF">pdf</a>, <a href="/format/2305.19302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smooth, exact rotational symmetrization for deep learning on point  clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pozdnyakov%2C+S+N">Sergey N. Pozdnyakov</a>, 
<a href="/search/cs?searchtype=author&query=Ceriotti%2C+M">Michele Ceriotti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Materials Science (cond-mat.mtrl-sci); Machine Learning (cs.LG); Chemical Physics (physics.chem-ph)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.20009" title="Abstract">arXiv:2305.20009</a> (replaced) [<a href="/pdf/2305.20009" title="Download PDF">pdf</a>, <a href="/format/2305.20009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Protein Design with Guided Discrete Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gruver%2C+N">Nate Gruver</a>, 
<a href="/search/cs?searchtype=author&query=Stanton%2C+S">Samuel Stanton</a>, 
<a href="/search/cs?searchtype=author&query=Frey%2C+N+C">Nathan C. Frey</a>, 
<a href="/search/cs?searchtype=author&query=Rudner%2C+T+G+J">Tim G. J. Rudner</a>, 
<a href="/search/cs?searchtype=author&query=Hotzel%2C+I">Isidro Hotzel</a>, 
<a href="/search/cs?searchtype=author&query=Lafrance-Vanasse%2C+J">Julien Lafrance-Vanasse</a>, 
<a href="/search/cs?searchtype=author&query=Rajpal%2C+A">Arvind Rajpal</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+K">Kyunghyun Cho</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+A+G">Andrew Gordon Wilson</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Advances in Neural Information Processing Systems 36, December
  10-16, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02099" title="Abstract">arXiv:2306.02099</a> (replaced) [<a href="/pdf/2306.02099" title="Download PDF">pdf</a>, <a href="/format/2306.02099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Surface Neural Implicits with Curvature-Guided Sampling and  Uncertainty-Augmented Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sang%2C+L">Lu Sang</a>, 
<a href="/search/cs?searchtype=author&query=Saroha%2C+A">Abhishek Saroha</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Maolin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Cremers%2C+D">Daniel Cremers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03241" title="Abstract">arXiv:2306.03241</a> (replaced) [<a href="/pdf/2306.03241" title="Download PDF">pdf</a>, <a href="/format/2306.03241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Early Weight Averaging meets High Learning Rates for LLM Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanyal%2C+S">Sunny Sanyal</a>, 
<a href="/search/cs?searchtype=author&query=Neerkaje%2C+A">Atula Neerkaje</a>, 
<a href="/search/cs?searchtype=author&query=Kaddour%2C+J">Jean Kaddour</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Abhishek Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Sanghavi%2C+S">Sujay Sanghavi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 13 figures, presented at NeurIPs 2023 WANT workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04356" title="Abstract">arXiv:2306.04356</a> (replaced) [<a href="/pdf/2306.04356" title="Download PDF">pdf</a>, <a href="/format/2306.04356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Grained Visual Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lingfeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yueze Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinlong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05036" title="Abstract">arXiv:2306.05036</a> (replaced) [<a href="/pdf/2306.05036" title="Download PDF">pdf</a>, <a href="/format/2306.05036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mapping the Challenges of HCI: An Application and Evaluation of ChatGPT  and GPT-4 for Mining Insights at Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oppenlaender%2C+J">Jonas Oppenlaender</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%A4m%C3%A4l%C3%A4inen%2C+J">Joonas H&#xe4;m&#xe4;l&#xe4;inen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 5 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05248" title="Abstract">arXiv:2306.05248</a> (replaced) [<a href="/pdf/2306.05248" title="Download PDF">pdf</a>, <a href="/format/2306.05248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal $L^2$ error analysis of a loosely coupled finite element scheme  for thin-structure interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+B">Buyang Li</a>, 
<a href="/search/math?searchtype=author&query=Sun%2C+W">Weiwei Sun</a>, 
<a href="/search/math?searchtype=author&query=Xie%2C+Y">Yupei Xie</a>, 
<a href="/search/math?searchtype=author&query=Yu%2C+W">Wenshan Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06871" title="Abstract">arXiv:2306.06871</a> (replaced) [<a href="/pdf/2306.06871" title="Download PDF">pdf</a>, <a href="/format/2306.06871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Offline-to-Online Reinforcement Learning with Q-Ensembles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jianye Hao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Z">Zhaopeng Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09124" title="Abstract">arXiv:2306.09124</a> (replaced) [<a href="/pdf/2306.09124" title="Download PDF">pdf</a>, <a href="/format/2306.09124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DIFFender: Diffusion-Based Adversarial Defense against Patch Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+C">Caixin Kang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yinpeng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhengyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+S">Shouwei Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yubo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hang Su</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xingxing Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10711" title="Abstract">arXiv:2306.10711</a> (replaced) [<a href="/pdf/2306.10711" title="Download PDF">pdf</a>, <a href="/format/2306.10711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PLASTIC: Improving Input and Label Plasticity for Sample Efficient  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hojoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+H">Hanseul Cho</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyunseung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Gwak%2C+D">Daehoon Gwak</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Joonkee Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choo%2C+J">Jaegul Choo</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+S">Se-Young Yun</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+C">Chulhee Yun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 6 figures, accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10912" title="Abstract">arXiv:2306.10912</a> (replaced) [<a href="/pdf/2306.10912" title="Download PDF">pdf</a>, <a href="/format/2306.10912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jamming Detection in Low-BER Mobile Indoor Scenarios via Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sciancalepore%2C+S">Savio Sciancalepore</a>, 
<a href="/search/cs?searchtype=author&query=Kusters%2C+F">Fabrice Kusters</a>, 
<a href="/search/cs?searchtype=author&query=Abdelhadi%2C+N+K">Nada Khaled Abdelhadi</a>, 
<a href="/search/cs?searchtype=author&query=Oligeri%2C+G">Gabriele Oligeri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 16 figures, 3 tables; Submitted and under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12153" title="Abstract">arXiv:2306.12153</a> (replaced) [<a href="/pdf/2306.12153" title="Download PDF">pdf</a>, <a href="/format/2306.12153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DIAS: A Comprehensive Dataset and Benchmark for Intracranial Artery  Segmentation in DSA sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+W">Wentao Liu</a>, 
<a href="/search/eess?searchtype=author&query=Tian%2C+T">Tong Tian</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+L">Lemeng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+W">Weijin Xu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Haoyuan Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+W">Wenyi Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Tian%2C+S">Siyu Tian</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+X">Xipeng Pan</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+H">Huihua Yang</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+F">Feng Gao</a>, 
<a href="/search/eess?searchtype=author&query=Deng%2C+Y">Yiming Deng</a>, 
<a href="/search/eess?searchtype=author&query=Su%2C+R">Ruisheng Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12424" title="Abstract">arXiv:2306.12424</a> (replaced) [<a href="/pdf/2306.12424" title="Download PDF">pdf</a>, <a href="/format/2306.12424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VisoGender: A dataset for benchmarking gender bias in image-text pronoun  resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hall%2C+S+M">Siobhan Mackenzie Hall</a>, 
<a href="/search/cs?searchtype=author&query=Abrantes%2C+F+G">Fernanda Gon&#xe7;alves Abrantes</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hanwen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Sodunke%2C+G">Grace Sodunke</a>, 
<a href="/search/cs?searchtype=author&query=Shtedritski%2C+A">Aleksandar Shtedritski</a>, 
<a href="/search/cs?searchtype=author&query=Kirk%2C+H+R">Hannah Rose Kirk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS Datasets and Benchmarks 2023. Data and code available at <a href="https://github.com/oxai/visogender">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13509" title="Abstract">arXiv:2306.13509</a> (replaced) [<a href="/pdf/2306.13509" title="Download PDF">pdf</a>, <a href="/format/2306.13509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring AI-enhanced Shared Control for an Assistive Robotic Arm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pascher%2C+M">Max Pascher</a>, 
<a href="/search/cs?searchtype=author&query=Kronhardt%2C+K">Kirill Kronhardt</a>, 
<a href="/search/cs?searchtype=author&query=Freienstein%2C+J">Jan Freienstein</a>, 
<a href="/search/cs?searchtype=author&query=Gerken%2C+J">Jens Gerken</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Springer LNCS: Trends topics on Engineering Interactive Systems Post-Proceedings of Workshops and Doctoral Symposium at EICS 2023 (Workshop on Engineering Interactive Systems Embedding AI Technologies)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13677" title="Abstract">arXiv:2306.13677</a> (replaced) [<a href="/pdf/2306.13677" title="Download PDF">pdf</a>, <a href="/ps/2306.13677" title="Download PostScript">ps</a>, <a href="/format/2306.13677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Net Metering for Energy Communities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Alahmed%2C+A+S">Ahmed S. Alahmed</a>, 
<a href="/search/eess?searchtype=author&query=Tong%2C+L">Lang Tong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 7 figures, 2 tables. arXiv admin note: text overlap with <a href="/abs/2211.09360">arXiv:2211.09360</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Computer Science and Game Theory (cs.GT); Theoretical Economics (econ.TH); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14284" title="Abstract">arXiv:2306.14284</a> (replaced) [<a href="/pdf/2306.14284" title="Download PDF">pdf</a>, <a href="/ps/2306.14284" title="Download PostScript">ps</a>, <a href="/format/2306.14284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Broadcast Protocols
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fisman%2C+D">Dana Fisman</a>, 
<a href="/search/cs?searchtype=author&query=Izsak%2C+N">Noa Izsak</a>, 
<a href="/search/cs?searchtype=author&query=Jacobs%2C+S">Swen Jacobs</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures, 3 input files of plots
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14435" title="Abstract">arXiv:2306.14435</a> (replaced) [<a href="/pdf/2306.14435" title="Download PDF">pdf</a>, <a href="/format/2306.14435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DragDiffusion: Harnessing Diffusion Models for Interactive Point-based  Image Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yujun Shi</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+C">Chuhui Xue</a>, 
<a href="/search/cs?searchtype=author&query=Liew%2C+J+H">Jun Hao Liew</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jiachun Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hanshu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+V+Y+F">Vincent Y. F. Tan</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+S">Song Bai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is released at <a href="https://github.com/Yujun-Shi/DragDiffusion">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15844" title="Abstract">arXiv:2306.15844</a> (replaced) [<a href="/pdf/2306.15844" title="Download PDF">pdf</a>, <a href="/format/2306.15844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Galerkin method for nonlocal diffusion equations on self-similar domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Medvedev%2C+G+S">Georgi S. Medvedev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Adaptation and Self-Organizing Systems (nlin.AO)

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15993" title="Abstract">arXiv:2306.15993</a> (replaced) [<a href="/pdf/2306.15993" title="Download PDF">pdf</a>, <a href="/format/2306.15993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Condorcet Domains of Degree at most Seven
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akello-Egwell%2C+D">Dolica Akello-Egwell</a>, 
<a href="/search/cs?searchtype=author&query=Leedham-Green%2C+C">Charles Leedham-Green</a>, 
<a href="/search/cs?searchtype=author&query=Litterick%2C+A">Alastair Litterick</a>, 
<a href="/search/cs?searchtype=author&query=Markstr%C3%B6m%2C+K">Klas Markstr&#xf6;m</a>, 
<a href="/search/cs?searchtype=author&query=Riis%2C+S">S&#xf8;ren Riis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Typos corrected, some open problems, a conjecture, and a new figure has been added in the latest version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Theoretical Economics (econ.TH); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16672" title="Abstract">arXiv:2306.16672</a> (replaced) [<a href="/pdf/2306.16672" title="Download PDF">pdf</a>, <a href="/ps/2306.16672" title="Download PostScript">ps</a>, <a href="/format/2306.16672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards understanding the performance of IEEE 802.11p MAC in  heterogeneous traffic conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gayathree%2C+M">MS Gayathree</a>, 
<a href="/search/cs?searchtype=author&query=Manjunath%2C+S">Sreelakshmi Manjunath</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00910" title="Abstract">arXiv:2307.00910</a> (replaced) [<a href="/pdf/2307.00910" title="Download PDF">pdf</a>, <a href="/format/2307.00910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoPL: Contextual Prompt Learning for Vision-Language Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goswami%2C+K">Koustava Goswami</a>, 
<a href="/search/cs?searchtype=author&query=Karanam%2C+S">Srikrishna Karanam</a>, 
<a href="/search/cs?searchtype=author&query=Udhayanan%2C+P">Prateksha Udhayanan</a>, 
<a href="/search/cs?searchtype=author&query=Joseph%2C+K+J">K J Joseph</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+B+V">Balaji Vasan Srinivasan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02879" title="Abstract">arXiv:2307.02879</a> (replaced) [<a href="/pdf/2307.02879" title="Download PDF">pdf</a>, <a href="/ps/2307.02879" title="Download PostScript">ps</a>, <a href="/format/2307.02879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithms for computing norms and characteristic polynomials on general  Drinfeld modules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caruso%2C+X">Xavier Caruso</a> (LFANT), 
<a href="/search/cs?searchtype=author&query=Leudi%C3%A8re%2C+A">Antoine Leudi&#xe8;re</a> (CARAMBA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Number Theory (math.NT)

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05845" title="Abstract">arXiv:2307.05845</a> (replaced) [<a href="/pdf/2307.05845" title="Download PDF">pdf</a>, <a href="/format/2307.05845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PIGEON: Predicting Image Geolocations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haas%2C+L">Lukas Haas</a>, 
<a href="/search/cs?searchtype=author&query=Skreta%2C+M">Michal Skreta</a>, 
<a href="/search/cs?searchtype=author&query=Alberti%2C+S">Silas Alberti</a>, 
<a href="/search/cs?searchtype=author&query=Finn%2C+C">Chelsea Finn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08131" title="Abstract">arXiv:2307.08131</a> (replaced) [<a href="/pdf/2307.08131" title="Download PDF">pdf</a>, <a href="/format/2307.08131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> INFLECT-DGNN: Influencer Prediction with Dynamic Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tiukhova%2C+E">Elena Tiukhova</a>, 
<a href="/search/cs?searchtype=author&query=Penaloza%2C+E">Emiliano Penaloza</a>, 
<a href="/search/cs?searchtype=author&query=%C3%93skarsd%C3%B3ttir%2C+M">Mar&#xed;a &#xd3;skarsd&#xf3;ttir</a>, 
<a href="/search/cs?searchtype=author&query=Baesens%2C+B">Bart Baesens</a>, 
<a href="/search/cs?searchtype=author&query=Snoeck%2C+M">Monique Snoeck</a>, 
<a href="/search/cs?searchtype=author&query=Bravo%2C+C">Cristi&#xe1;n Bravo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15465" title="Abstract">arXiv:2307.15465</a> (replaced) [<a href="/pdf/2307.15465" title="Download PDF">pdf</a>, <a href="/ps/2307.15465" title="Download PostScript">ps</a>, <a href="/format/2307.15465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably secure KEM-based protocols over unauthenticated channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez-Ledesma%2C+R+M">Rodrigo Mart&#xed;n S&#xe1;nchez-Ledesma</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADn%2C+D+D">David Domingo Mart&#xed;n</a>, 
<a href="/search/cs?searchtype=author&query=Chac%C3%B3n%2C+I+B">Iv&#xe1;n Blanco Chac&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Velasco%2C+I+L">Ignacio Luengo Velasco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16164" title="Abstract">arXiv:2307.16164</a> (replaced) [<a href="/pdf/2307.16164" title="Download PDF">pdf</a>, <a href="/format/2307.16164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive learning of density ratios in RKHS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zellinger%2C+W">Werner Zellinger</a>, 
<a href="/search/cs?searchtype=author&query=Kindermann%2C+S">Stefan Kindermann</a>, 
<a href="/search/cs?searchtype=author&query=Pereverzyev%2C+S+V">Sergei V. Pereverzyev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01218" title="Abstract">arXiv:2308.01218</a> (replaced) [<a href="/pdf/2308.01218" title="Download PDF">pdf</a>, <a href="/format/2308.01218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Sequence Matters in Learning -- A Systematic Literature Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Torre%2C+M+V">Manuel Valle Torre</a>, 
<a href="/search/cs?searchtype=author&query=Oertel%2C+C">Catharine Oertel</a>, 
<a href="/search/cs?searchtype=author&query=Specht%2C+M">Marcus Specht</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This version is for personal use and not for redistribution. The final version was published as part of the proceedings of the 14th Learning Analytics and Knowledge Conference (LAK '24). March 18--22, 2024, Kyoto, Japan
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02345" title="Abstract">arXiv:2308.02345</a> (replaced) [<a href="/pdf/2308.02345" title="Download PDF">pdf</a>, <a href="/format/2308.02345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication-Efficient Decentralized Multi-Agent Reinforcement Learning  for Cooperative Adaptive Cruise Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+D">Dong Chen</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+K">Kaixiang Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yongqiang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Yin%2C+X">Xunyuan Yin</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zhaojian Li</a>, 
<a href="/search/eess?searchtype=author&query=Filev%2C+D">Dimitar Filev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02596" title="Abstract">arXiv:2308.02596</a> (replaced) [<a href="/pdf/2308.02596" title="Download PDF">pdf</a>, <a href="/format/2308.02596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting small-world network models: Exploring technical realizations  and the equivalence of the Newman-Watts and Harary models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Son%2C+S">Seora Son</a>, 
<a href="/search/physics?searchtype=author&query=Choi%2C+E+J">Eun Ji Choi</a>, 
<a href="/search/physics?searchtype=author&query=Lee%2C+S+H">Sang Hoon Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures, 1 table
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J. Korean Phys. Soc. 83, 879 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Discrete Mathematics (cs.DM); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03743" title="Abstract">arXiv:2308.03743</a> (replaced) [<a href="/pdf/2308.03743" title="Download PDF">pdf</a>, <a href="/format/2308.03743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Copycat Perceptron: Smashing Barriers Through Collective Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Catania%2C+G">Giovanni Catania</a>, 
<a href="/search/cond-mat?searchtype=author&query=Decelle%2C+A">Aur&#xe9;lien Decelle</a>, 
<a href="/search/cond-mat?searchtype=author&query=Seoane%2C+B">Beatriz Seoane</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 figures in the main, 4 figures in the appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04669" title="Abstract">arXiv:2308.04669</a> (replaced) [<a href="/pdf/2308.04669" title="Download PDF">pdf</a>, <a href="/format/2308.04669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A General Implicit Framework for Fast NeRF Composition and Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ziyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yunlu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuxiang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xiaogang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+C">Changqing Zou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages for main content
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06077" title="Abstract">arXiv:2308.06077</a> (replaced) [<a href="/pdf/2308.06077" title="Download PDF">pdf</a>, <a href="/format/2308.06077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fly-Swat or Cannon? Cost-Effective Language Model Choice via  Meta-Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C5%A0akota%2C+M">Marija &#x160;akota</a>, 
<a href="/search/cs?searchtype=author&query=Peyrard%2C+M">Maxime Peyrard</a>, 
<a href="/search/cs?searchtype=author&query=West%2C+R">Robert West</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06113" title="Abstract">arXiv:2308.06113</a> (replaced) [<a href="/pdf/2308.06113" title="Download PDF">pdf</a>, <a href="/format/2308.06113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Uniform Representation of Classical and Quantum Source Code for Static  Code Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaul%2C+M">Maximilian Kaul</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BCchler%2C+A">Alexander K&#xfc;chler</a>, 
<a href="/search/cs?searchtype=author&query=Banse%2C+C">Christian Banse</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE International Conference on Quantum Computing and Engineering (QCE)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08641" title="Abstract">arXiv:2308.08641</a> (replaced) [<a href="/pdf/2308.08641" title="Download PDF">pdf</a>, <a href="/format/2308.08641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-monotone Sequential Submodular Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shaojie Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jing Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for publication at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09103" title="Abstract">arXiv:2308.09103</a> (replaced) [<a href="/pdf/2308.09103" title="Download PDF">pdf</a>, <a href="/format/2308.09103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient collision avoidance for autonomous vehicles in polygonal  domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jiayu Fan</a>, 
<a href="/search/cs?searchtype=author&query=Murgovski%2C+N">Nikolce Murgovski</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jun Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages,2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09604" title="Abstract">arXiv:2308.09604</a> (replaced) [<a href="/pdf/2308.09604" title="Download PDF">pdf</a>, <a href="/format/2308.09604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Stochastic Variance Reduction Methods for Compositional MiniMax  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xiaokang Pan</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+J">Junwen Duan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongdong Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Youqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Z">Zhe Qu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09895" title="Abstract">arXiv:2308.09895</a> (replaced) [<a href="/pdf/2308.09895" title="Download PDF">pdf</a>, <a href="/format/2308.09895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Transfer from High-Resource to Low-Resource Programming  Languages for Code LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cassano%2C+F">Federico Cassano</a>, 
<a href="/search/cs?searchtype=author&query=Gouwar%2C+J">John Gouwar</a>, 
<a href="/search/cs?searchtype=author&query=Lucchetti%2C+F">Francesca Lucchetti</a>, 
<a href="/search/cs?searchtype=author&query=Schlesinger%2C+C">Claire Schlesinger</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+C+J">Carolyn Jane Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Greenberg%2C+M">Michael Greenberg</a>, 
<a href="/search/cs?searchtype=author&query=Jangda%2C+A">Abhinav Jangda</a>, 
<a href="/search/cs?searchtype=author&query=Guha%2C+A">Arjun Guha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11488" title="Abstract">arXiv:2308.11488</a> (replaced) [<a href="/pdf/2308.11488" title="Download PDF">pdf</a>, <a href="/format/2308.11488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Opening the Vocabulary of Egocentric Actions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+D">Dibyadip Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Sener%2C+F">Fadime Sener</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shugao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+A">Angela Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 camera ready; <a href="https://dibschat.github.io/openvocab-egoAR/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12696" title="Abstract">arXiv:2308.12696</a> (replaced) [<a href="/pdf/2308.12696" title="Download PDF">pdf</a>, <a href="/format/2308.12696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentanglement Learning via Topology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balabin%2C+N">Nikita Balabin</a>, 
<a href="/search/cs?searchtype=author&query=Voronkova%2C+D">Daria Voronkova</a>, 
<a href="/search/cs?searchtype=author&query=Trofimov%2C+I">Ilya Trofimov</a>, 
<a href="/search/cs?searchtype=author&query=Burnaev%2C+E">Evgeny Burnaev</a>, 
<a href="/search/cs?searchtype=author&query=Barannikov%2C+S">Serguei Barannikov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14127" title="Abstract">arXiv:2308.14127</a> (replaced) [<a href="/pdf/2308.14127" title="Download PDF">pdf</a>, <a href="/format/2308.14127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information geometric regularization of the barotropic Euler equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cao%2C+R">Ruijia Cao</a>, 
<a href="/search/math?searchtype=author&query=Sch%C3%A4fer%2C+F">Florian Sch&#xe4;fer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14360" title="Abstract">arXiv:2308.14360</a> (replaced) [<a href="/pdf/2308.14360" title="Download PDF">pdf</a>, <a href="/format/2308.14360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InstructME: An Instruction Guided Music Edit And Remix Framework with  Latent Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bing Han</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Junyu Dai</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+W">Weituo Hao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xinyan He</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Dong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jitong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yanmin Qian</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xuchen Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Demo samples are available at <a href="https://musicedit.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14815" title="Abstract">arXiv:2308.14815</a> (replaced) [<a href="/pdf/2308.14815" title="Download PDF">pdf</a>, <a href="/format/2308.14815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributionally Robust Statistical Verification with Imprecise Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dutta%2C+S">Souradeep Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Caprio%2C+M">Michele Caprio</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+V">Vivian Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cleaveland%2C+M">Matthew Cleaveland</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+K+J">Kuk Jin Jang</a>, 
<a href="/search/cs?searchtype=author&query=Ruchkin%2C+I">Ivan Ruchkin</a>, 
<a href="/search/cs?searchtype=author&query=Sokolsky%2C+O">Oleg Sokolsky</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+I">Insup Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15400" title="Abstract">arXiv:2308.15400</a> (replaced) [<a href="/pdf/2308.15400" title="Download PDF">pdf</a>, <a href="/format/2308.15400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A coupled high-accuracy phase-field fluid-structure interaction  framework for Stokes fluid-filled fracture surrounded by an elastic medium
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=von+Wahl%2C+H">Henry von Wahl</a>, 
<a href="/search/math?searchtype=author&query=Wick%2C+T">Thomas Wick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16139" title="Abstract">arXiv:2308.16139</a> (replaced) [<a href="/pdf/2308.16139" title="Download PDF">pdf</a>, <a href="/format/2308.16139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MedShapeNet -- A Large-Scale Dataset of 3D Medical Shapes for Computer  Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianning Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zongwei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiancheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Pepe%2C+A">Antonio Pepe</a>, 
<a href="/search/cs?searchtype=author&query=Gsaxner%2C+C">Christina Gsaxner</a>, 
<a href="/search/cs?searchtype=author&query=Luijten%2C+G">Gijs Luijten</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+C">Chongyu Qu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tiezheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoxi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Wodzinski%2C+M">Marek Wodzinski</a>, 
<a href="/search/cs?searchtype=author&query=Friedrich%2C+P">Paul Friedrich</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+K">Kangxian Xie</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yuan Jin</a>, 
<a href="/search/cs?searchtype=author&query=Ambigapathy%2C+N">Narmada Ambigapathy</a>, 
<a href="/search/cs?searchtype=author&query=Nasca%2C+E">Enrico Nasca</a>, 
<a href="/search/cs?searchtype=author&query=Solak%2C+N">Naida Solak</a>, 
<a href="/search/cs?searchtype=author&query=Melito%2C+G+M">Gian Marco Melito</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+V+D">Viet Duc Vu</a>, 
<a href="/search/cs?searchtype=author&query=Memon%2C+A+R">Afaque R. Memon</a>, 
<a href="/search/cs?searchtype=author&query=Schlachta%2C+C">Christopher Schlachta</a>, 
<a href="/search/cs?searchtype=author&query=De+Ribaupierre%2C+S">Sandrine De Ribaupierre</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+R">Rajnikant Patel</a>, 
<a href="/search/cs?searchtype=author&query=Eagleson%2C+R">Roy Eagleson</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaojun Chen</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%A4chler%2C+H">Heinrich M&#xe4;chler</a>, 
<a href="/search/cs?searchtype=author&query=Kirschke%2C+J+S">Jan Stefan Kirschke</a>, 
<a href="/search/cs?searchtype=author&query=de+la+Rosa%2C+E">Ezequiel de la Rosa</a>, 
<a href="/search/cs?searchtype=author&query=Christ%2C+P+F">Patrick Ferdinand Christ</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H+B">Hongwei Bran Li</a>, 
<a href="/search/cs?searchtype=author&query=Ellis%2C+D+G">David G. Ellis</a>, 
<a href="/search/cs?searchtype=author&query=Aizenberg%2C+M+R">Michele R. Aizenberg</a>, 
<a href="/search/cs?searchtype=author&query=Gatidis%2C+S">Sergios Gatidis</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BCstner%2C+T">Thomas K&#xfc;stner</a>, 
<a href="/search/cs?searchtype=author&query=Shusharina%2C+N">Nadya Shusharina</a>, 
<a href="/search/cs?searchtype=author&query=Heller%2C+N">Nicholas Heller</a>, 
<a href="/search/cs?searchtype=author&query=Andrearczyk%2C+V">Vincent Andrearczyk</a>, 
<a href="/search/cs?searchtype=author&query=Depeursinge%2C+A">Adrien Depeursinge</a>, 
<a href="/search/cs?searchtype=author&query=Hatt%2C+M">Mathieu Hatt</a>, 
<a href="/search/cs?searchtype=author&query=Sekuboyina%2C+A">Anjany Sekuboyina</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B6ffler%2C+M">Maximilian L&#xf6;ffler</a>, 
<a href="/search/cs?searchtype=author&query=Liebl%2C+H">Hans Liebl</a>, 
<a href="/search/cs?searchtype=author&query=Dorent%2C+R">Reuben Dorent</a>, 
<a href="/search/cs?searchtype=author&query=Vercauteren%2C+T">Tom Vercauteren</a>, 
<a href="/search/cs?searchtype=author&query=Shapey%2C+J">Jonathan Shapey</a>, 
<a href="/search/cs?searchtype=author&query=Kujawa%2C+A">Aaron Kujawa</a>, 
<a href="/search/cs?searchtype=author&query=Cornelissen%2C+S">Stefan Cornelissen</a>,  et al. (110 additional authors not shown)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Databases (cs.DB); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16576" title="Abstract">arXiv:2308.16576</a> (replaced) [<a href="/pdf/2308.16576" title="Download PDF">pdf</a>, <a href="/format/2308.16576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GHuNeRF: Generalizable Human NeRF from a Monocular Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiahao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+G+H">Gim Hee Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Add in more baseline for comparison
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16876" title="Abstract">arXiv:2308.16876</a> (replaced) [<a href="/pdf/2308.16876" title="Download PDF">pdf</a>, <a href="/format/2308.16876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SportsSloMo: A New Benchmark and Baselines for Human-centric Video Frame  Interpolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaben Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Huaizu Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://neu-vi.github.io/SportsSlomo/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02603" title="Abstract">arXiv:2309.02603</a> (replaced) [<a href="/pdf/2309.02603" title="Download PDF">pdf</a>, <a href="/format/2309.02603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detection of Unknown-Unknowns in Human-in-Plant Human-in-Loop Systems  Using Physics Guided Process Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maity%2C+A">Aranyak Maity</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+A">Ayan Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Sandeep Gupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03407" title="Abstract">arXiv:2309.03407</a> (replaced) [<a href="/pdf/2309.03407" title="Download PDF">pdf</a>, <a href="/format/2309.03407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Josephson Parametric Oscillator-Based Ising Machine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Razmkhah%2C+S">Sasan Razmkhah</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kamal%2C+M">Mehdi Kamal</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yoshikawa%2C+N">Nobuyuki Yoshikawa</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pedram%2C+M">Massoud Pedram</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 10 figures, 31 references. Accepted by PRB
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Superconductivity (cond-mat.supr-con); Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03648" title="Abstract">arXiv:2309.03648</a> (replaced) [<a href="/pdf/2309.03648" title="Download PDF">pdf</a>, <a href="/format/2309.03648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Promoting Fairness in GNNs: A Characterization of Stability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yaning Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chunhui Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07870" title="Abstract">arXiv:2309.07870</a> (replaced) [<a href="/pdf/2309.07870" title="Download PDF">pdf</a>, <a href="/format/2309.07870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agents: An Open-source Framework for Autonomous Language Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wangchunshu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y+E">Yuchen Eleanor Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Long Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jialong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tiannan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+S">Shi Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jintian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Ruipu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shiding Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wentao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiangru Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ningyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huajun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+P">Peng Cui</a>, 
<a href="/search/cs?searchtype=author&query=Sachan%2C+M">Mrinmaya Sachan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code available at <a href="https://github.com/aiwaves-cn/agents">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08340" title="Abstract">arXiv:2309.08340</a> (replaced) [<a href="/pdf/2309.08340" title="Download PDF">pdf</a>, <a href="/ps/2309.08340" title="Download PostScript">ps</a>, <a href="/format/2309.08340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formalizing the $\infty$-Categorical Yoneda Lemma
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kudasov%2C+N">Nikolai Kudasov</a>, 
<a href="/search/math?searchtype=author&query=Riehl%2C+E">Emily Riehl</a>, 
<a href="/search/math?searchtype=author&query=Weinberger%2C+J">Jonathan Weinberger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in CPP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Logic in Computer Science (cs.LO); Algebraic Topology (math.AT); Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08769" title="Abstract">arXiv:2309.08769</a> (replaced) [<a href="/pdf/2309.08769" title="Download PDF">pdf</a>, <a href="/format/2309.08769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Use of Multi-Scale Fiducial Markers To Aid Takeoff and Landing  Navigation by Rotorcraft
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jongwon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S+Y">Su Yeon Choi</a>, 
<a href="/search/cs?searchtype=author&query=Bretl%2C+T">Timothy Bretl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 2024 AIAA SciTech
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09357" title="Abstract">arXiv:2309.09357</a> (replaced) [<a href="/pdf/2309.09357" title="Download PDF">pdf</a>, <a href="/format/2309.09357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Talk2Care: Facilitating Asynchronous Patient-Provider Communication with  Large-Language-Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ziqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xuhai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+B">Bingsheng Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Rogers%2C+E">Ethan Rogers</a>, 
<a href="/search/cs?searchtype=author&query=Intille%2C+S">Stephen Intille</a>, 
<a href="/search/cs?searchtype=author&query=Shara%2C+N">Nawar Shara</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+G+G">Guodong Gordon Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dakuo Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under submission to IMWUT'23, 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09431" title="Abstract">arXiv:2309.09431</a> (replaced) [<a href="/pdf/2309.09431" title="Download PDF">pdf</a>, <a href="/format/2309.09431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FactoFormer: Factorized Hyperspectral Transformers with Self-Supervised  Pre-Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohamed%2C+S">Shaheer Mohamed</a>, 
<a href="/search/cs?searchtype=author&query=Haghighat%2C+M">Maryam Haghighat</a>, 
<a href="/search/cs?searchtype=author&query=Fernando%2C+T">Tharindu Fernando</a>, 
<a href="/search/cs?searchtype=author&query=Sridharan%2C+S">Sridha Sridharan</a>, 
<a href="/search/cs?searchtype=author&query=Fookes%2C+C">Clinton Fookes</a>, 
<a href="/search/cs?searchtype=author&query=Moghadam%2C+P">Peyman Moghadam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Transactions on Geoscience and Remote Sensing in December 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10686" title="Abstract">arXiv:2309.10686</a> (replaced) [<a href="/pdf/2309.10686" title="Download PDF">pdf</a>, <a href="/format/2309.10686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interval Signal Temporal Logic from Natural Inclusion Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Baird%2C+L">Luke Baird</a>, 
<a href="/search/eess?searchtype=author&query=Harapanahalli%2C+A">Akash Harapanahalli</a>, 
<a href="/search/eess?searchtype=author&query=Coogan%2C+S">Samuel Coogan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12821" title="Abstract">arXiv:2309.12821</a> (replaced) [<a href="/pdf/2309.12821" title="Download PDF">pdf</a>, <a href="/format/2309.12821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Spectral Theory of Neural Prediction and Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Canatar%2C+A">Abdulkadir Canatar</a>, 
<a href="/search/q-bio?searchtype=author&query=Feather%2C+J">Jenelle Feather</a>, 
<a href="/search/q-bio?searchtype=author&query=Wakhloo%2C+A">Albert Wakhloo</a>, 
<a href="/search/q-bio?searchtype=author&query=Chung%2C+S">SueYeon Chung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First two authors contributed equally. NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13747" title="Abstract">arXiv:2309.13747</a> (replaced) [<a href="/pdf/2309.13747" title="Download PDF">pdf</a>, <a href="/format/2309.13747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Look Ma, no code: fine tuning nnU-Net for the AutoPET II challenge by  only adjusting its JSON plans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Isensee%2C+F">Fabian Isensee</a>, 
<a href="/search/eess?searchtype=author&query=Maier-Hein%2C+K+H">Klaus H.Maier-Hein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13788" title="Abstract">arXiv:2309.13788</a> (replaced) [<a href="/pdf/2309.13788" title="Download PDF">pdf</a>, <a href="/format/2309.13788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can LLM-Generated Misinformation Be Detected?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Canyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+K">Kai Shu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The code, dataset and more resources on LLMs and misinformation will be released on the project website: <a href="https://llm-misinformation.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14585" title="Abstract">arXiv:2309.14585</a> (replaced) [<a href="/pdf/2309.14585" title="Download PDF">pdf</a>, <a href="/format/2309.14585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DifAttack: Query-Efficient Black-Box Attack via Disentangled Feature  Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jun%2C+L">Liu Jun</a>, 
<a href="/search/cs?searchtype=author&query=Jiantao%2C+Z">Zhou Jiantao</a>, 
<a href="/search/cs?searchtype=author&query=Jiandian%2C+Z">Zeng Jiandian</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jinyu Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16512" title="Abstract">arXiv:2309.16512</a> (replaced) [<a href="/pdf/2309.16512" title="Download PDF">pdf</a>, <a href="/format/2309.16512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Complexity to Clarity: Analytical Expressions of Deep Neural  Network Weights via Clifford&#x27;s Geometric Algebra and Convexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pilanci%2C+M">Mert Pilanci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16808" title="Abstract">arXiv:2309.16808</a> (replaced) [<a href="/pdf/2309.16808" title="Download PDF">pdf</a>, <a href="/format/2309.16808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Granularity at Scale: Estimating Neighborhood Socioeconomic Indicators  from High-Resolution Orthographic Imagery and Hybrid Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brewer%2C+E">Ethan Brewer</a>, 
<a href="/search/cs?searchtype=author&query=Valdrighi%2C+G">Giovani Valdrighi</a>, 
<a href="/search/cs?searchtype=author&query=Solunke%2C+P">Parikshit Solunke</a>, 
<a href="/search/cs?searchtype=author&query=Rulff%2C+J">Joao Rulff</a>, 
<a href="/search/cs?searchtype=author&query=Piadyk%2C+Y">Yurii Piadyk</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Z">Zhonghui Lv</a>, 
<a href="/search/cs?searchtype=author&query=Poco%2C+J">Jorge Poco</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+C">Claudio Silva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updating after a round of revisions with IEEE J-STARS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17453" title="Abstract">arXiv:2309.17453</a> (replaced) [<a href="/pdf/2309.17453" title="Download PDF">pdf</a>, <a href="/format/2309.17453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Streaming Language Models with Attention Sinks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+G">Guangxuan Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuandong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Beidi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Song Han</a>, 
<a href="/search/cs?searchtype=author&query=Lewis%2C+M">Mike Lewis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01678" title="Abstract">arXiv:2310.01678</a> (replaced) [<a href="/pdf/2310.01678" title="Download PDF">pdf</a>, <a href="/format/2310.01678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Score dynamics: scaling molecular dynamics with picosecond timesteps via  conditional diffusion model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Hsu%2C+T">Tim Hsu</a>, 
<a href="/search/physics?searchtype=author&query=Sadigh%2C+B">Babak Sadigh</a>, 
<a href="/search/physics?searchtype=author&query=Bulatov%2C+V">Vasily Bulatov</a>, 
<a href="/search/physics?searchtype=author&query=Zhou%2C+F">Fei Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04641" title="Abstract">arXiv:2310.04641</a> (replaced) [<a href="/pdf/2310.04641" title="Download PDF">pdf</a>, <a href="/format/2310.04641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Equitable Peering: A Proposal for a Fair Peering Fee Between  ISPs and Content Providers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nikkhah%2C+A">Ali Nikkhah</a>, 
<a href="/search/cs?searchtype=author&query=Jordan%2C+S">Scott Jordan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for Publication in IEEE Transactions on Network and Service Management
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04816" title="Abstract">arXiv:2310.04816</a> (replaced) [<a href="/pdf/2310.04816" title="Download PDF">pdf</a>, <a href="/format/2310.04816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hacking Generative Models with Differentiable Network Bending
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aldegheri%2C+G">Giacomo Aldegheri</a>, 
<a href="/search/cs?searchtype=author&query=Rogalska%2C+A">Alina Rogalska</a>, 
<a href="/search/cs?searchtype=author&query=Youssef%2C+A">Ahmed Youssef</a>, 
<a href="/search/cs?searchtype=author&query=Iofinova%2C+E">Eugenia Iofinova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures, Machine Learning for Creativity and Design Workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07730" title="Abstract">arXiv:2310.07730</a> (replaced) [<a href="/pdf/2310.07730" title="Download PDF">pdf</a>, <a href="/format/2310.07730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain-Controlled Prompt Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Q">Qinglong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhengqin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuntian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaokang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10773" title="Abstract">arXiv:2310.10773</a> (replaced) [<a href="/pdf/2310.10773" title="Download PDF">pdf</a>, <a href="/format/2310.10773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gotta be SAFE: A New Framework for Molecular Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Noutahi%2C+E">Emmanuel Noutahi</a>, 
<a href="/search/cs?searchtype=author&query=Gabellini%2C+C">Cristian Gabellini</a>, 
<a href="/search/cs?searchtype=author&query=Craig%2C+M">Michael Craig</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+J+S+C">Jonathan S.C Lim</a>, 
<a href="/search/cs?searchtype=author&query=Tossou%2C+P">Prudencio Tossou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code, data and models available at: <a href="https://github.com/datamol-io/safe/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10998" title="Abstract">arXiv:2310.10998</a> (replaced) [<a href="/pdf/2310.10998" title="Download PDF">pdf</a>, <a href="/format/2310.10998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Scalable Graph Neural Network Inference with Node-Adaptive  Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinyi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wentao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Junliang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Yingxia Shao</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q+V+H">Quoc Viet Hung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+B">Bin Cui</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongzhi Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2024 IEEE 40th International Conference on Data Engineering (ICDE). arXiv admin note: substantial text overlap with <a href="/abs/2211.00495">arXiv:2211.00495</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12474" title="Abstract">arXiv:2310.12474</a> (replaced) [<a href="/pdf/2310.12474" title="Download PDF">pdf</a>, <a href="/format/2310.12474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing High-Resolution 3D Generation through Pixel-wise Gradient  Clipping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zijie Pan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiachen Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiatian Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13767" title="Abstract">arXiv:2310.13767</a> (replaced) [<a href="/pdf/2310.13767" title="Download PDF">pdf</a>, <a href="/format/2310.13767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph AI in Medicine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Johnson%2C+R">Ruth Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M+M">Michelle M. Li</a>, 
<a href="/search/cs?searchtype=author&query=Noori%2C+A">Ayush Noori</a>, 
<a href="/search/cs?searchtype=author&query=Queen%2C+O">Owen Queen</a>, 
<a href="/search/cs?searchtype=author&query=Zitnik%2C+M">Marinka Zitnik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14505" title="Abstract">arXiv:2310.14505</a> (replaced) [<a href="/pdf/2310.14505" title="Download PDF">pdf</a>, <a href="/ps/2310.14505" title="Download PostScript">ps</a>, <a href="/format/2310.14505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sentiment analysis with adaptive multi-head attention in Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fanfei Meng</a>, 
<a href="/search/cs?searchtype=author&query=Demeter%2C+D">David Demeter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 4th International Conference on Signal Processing and Machine Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15194" title="Abstract">arXiv:2310.15194</a> (replaced) [<a href="/pdf/2310.15194" title="Download PDF">pdf</a>, <a href="/ps/2310.15194" title="Download PostScript">ps</a>, <a href="/format/2310.15194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How do the resting EEG preprocessing states affect the outcomes of  postprocessing?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Hu%2C+S">Shiang Hu</a>, 
<a href="/search/q-bio?searchtype=author&query=Ruan%2C+J">Jie Ruan</a>, 
<a href="/search/q-bio?searchtype=author&query=Hou%2C+J">Juan Hou</a>, 
<a href="/search/q-bio?searchtype=author&query=Valdes-Sosa%2C+P+A">Pedro Antonio Valdes-Sosa</a>, 
<a href="/search/q-bio?searchtype=author&query=Lv%2C+Z">Zhao Lv</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Human-Computer Interaction (cs.HC); Signal Processing (eess.SP); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15646" title="Abstract">arXiv:2310.15646</a> (replaced) [<a href="/pdf/2310.15646" title="Download PDF">pdf</a>, <a href="/format/2310.15646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mean Teacher DETR with Masked Feature Alignment: A Robust Domain  Adaptive Detection Transformer Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weng%2C+W">Weixi Weng</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chun Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16285" title="Abstract">arXiv:2310.16285</a> (replaced) [<a href="/pdf/2310.16285" title="Download PDF">pdf</a>, <a href="/format/2310.16285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Removing Dust from CMB Observations with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Heurtel-Depeiges%2C+D">David Heurtel-Depeiges</a>, 
<a href="/search/astro-ph?searchtype=author&query=Burkhart%2C+B">Blakesley Burkhart</a>, 
<a href="/search/astro-ph?searchtype=author&query=Ohana%2C+R">Ruben Ohana</a>, 
<a href="/search/astro-ph?searchtype=author&query=Blancard%2C+B+R">Bruno R&#xe9;galdo-Saint Blancard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5+6 pages, 2+3 figures, accepted at the NeurIPS 2023 workshop on "Machine Learning and the Physical Sciences" and selected for a spotlight talk
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cosmology and Nongalactic Astrophysics (astro-ph.CO)</span>; Astrophysics of Galaxies (astro-ph.GA); Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17087" title="Abstract">arXiv:2310.17087</a> (replaced) [<a href="/pdf/2310.17087" title="Download PDF">pdf</a>, <a href="/format/2310.17087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Good regularity creates large learning rate implicit biases: edge of  stability, balancing, and catapult
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhenghao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tuo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+M">Molei Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Dynamical Systems (math.DS); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18368" title="Abstract">arXiv:2310.18368</a> (replaced) [<a href="/pdf/2310.18368" title="Download PDF">pdf</a>, <a href="/format/2310.18368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Muslim-Violence Bias Persists in Debiased GPT Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hemmatian%2C+B">Babak Hemmatian</a>, 
<a href="/search/cs?searchtype=author&query=Baltaji%2C+R">Razan Baltaji</a>, 
<a href="/search/cs?searchtype=author&query=Varshney%2C+L+R">Lav R. Varshney</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages, 2 figures. This work will be presented at MusIML neurips workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19797" title="Abstract">arXiv:2310.19797</a> (replaced) [<a href="/pdf/2310.19797" title="Download PDF">pdf</a>, <a href="/format/2310.19797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DEFT: Dexterous Fine-Tuning for Real-World Hand Policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kannan%2C+A">Aditya Kannan</a>, 
<a href="/search/cs?searchtype=author&query=Shaw%2C+K">Kenneth Shaw</a>, 
<a href="/search/cs?searchtype=author&query=Bahl%2C+S">Shikhar Bahl</a>, 
<a href="/search/cs?searchtype=author&query=Mannam%2C+P">Pragna Mannam</a>, 
<a href="/search/cs?searchtype=author&query=Pathak%2C+D">Deepak Pathak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In CoRL 2023. Website at <a href="https://dexterous-finetuning.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02227" title="Abstract">arXiv:2311.02227</a> (replaced) [<a href="/pdf/2311.02227" title="Download PDF">pdf</a>, <a href="/format/2311.02227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> State-Wise Safe Reinforcement Learning With Pixel Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+S+S">Simon Sinong Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yixuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+R">Ruochen Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qi Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04673" title="Abstract">arXiv:2311.04673</a> (replaced) [<a href="/pdf/2311.04673" title="Download PDF">pdf</a>, <a href="/format/2311.04673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compressive Recovery of Sparse Precision Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Vayer%2C+T">Titouan Vayer</a>, 
<a href="/search/stat?searchtype=author&query=Lasalle%2C+E">Etienne Lasalle</a>, 
<a href="/search/stat?searchtype=author&query=Gribonval%2C+R">R&#xe9;mi Gribonval</a>, 
<a href="/search/stat?searchtype=author&query=Gon%C3%A7alves%2C+P">Paulo Gon&#xe7;alves</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06000" title="Abstract">arXiv:2311.06000</a> (replaced) [<a href="/pdf/2311.06000" title="Download PDF">pdf</a>, <a href="/format/2311.06000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Keystroke Verification Challenge (KVC): Biometric and Fairness Benchmark  Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stragapede%2C+G">Giuseppe Stragapede</a>, 
<a href="/search/cs?searchtype=author&query=Vera-Rodriguez%2C+R">Ruben Vera-Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Tolosana%2C+R">Ruben Tolosana</a>, 
<a href="/search/cs?searchtype=author&query=Morales%2C+A">Aythami Morales</a>, 
<a href="/search/cs?searchtype=author&query=Damer%2C+N">Naser Damer</a>, 
<a href="/search/cs?searchtype=author&query=Fierrez%2C+J">Julian Fierrez</a>, 
<a href="/search/cs?searchtype=author&query=Ortega-Garcia%2C+J">Javier Ortega-Garcia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figure, 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06062" title="Abstract">arXiv:2311.06062</a> (replaced) [<a href="/pdf/2311.06062" title="Download PDF">pdf</a>, <a href="/format/2311.06062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Practical Membership Inference Attacks against Fine-tuned Large Language  Models via Self-prompt Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+W">Wenjie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huandong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chen Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guanghua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+T">Tao Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07289" title="Abstract">arXiv:2311.07289</a> (replaced) [<a href="/pdf/2311.07289" title="Download PDF">pdf</a>, <a href="/format/2311.07289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A probabilistic forecast methodology for volatile electricity prices in  the Australian National Electricity Market
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cornell%2C+C">Cameron Cornell</a>, 
<a href="/search/cs?searchtype=author&query=Dinh%2C+N+T">Nam Trong Dinh</a>, 
<a href="/search/cs?searchtype=author&query=Pourmousavi%2C+S+A">S. Ali Pourmousavi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This manuscript has been accepted for publication in International Journal of Forecasting
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07965" title="Abstract">arXiv:2311.07965</a> (replaced) [<a href="/pdf/2311.07965" title="Download PDF">pdf</a>, <a href="/format/2311.07965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DQR-TTS: Semi-supervised Text-to-speech Synthesis with Dynamic Quantized  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianzong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pengcheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xulong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+N">Ning Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jing Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 21st IEEE International Symposium on Parallel and Distributed Processing with Applications (IEEE ISPA 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08360" title="Abstract">arXiv:2311.08360</a> (replaced) [<a href="/pdf/2311.08360" title="Download PDF">pdf</a>, <a href="/format/2311.08360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Transient Nature of Emergent In-Context Learning in Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+A+K">Aaditya K. Singh</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+S+C+Y">Stephanie C.Y. Chan</a>, 
<a href="/search/cs?searchtype=author&query=Moskovitz%2C+T">Ted Moskovitz</a>, 
<a href="/search/cs?searchtype=author&query=Grant%2C+E">Erin Grant</a>, 
<a href="/search/cs?searchtype=author&query=Saxe%2C+A+M">Andrew M. Saxe</a>, 
<a href="/search/cs?searchtype=author&query=Hill%2C+F">Felix Hill</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08500" title="Abstract">arXiv:2311.08500</a> (replaced) [<a href="/pdf/2311.08500" title="Download PDF">pdf</a>, <a href="/format/2311.08500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Density Steering of Gaussian Mixture Models for Discrete-Time Linear  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Balci%2C+I+M">Isin M. Balci</a>, 
<a href="/search/eess?searchtype=author&query=Bakolas%2C+E">Efstathios Bakolas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09247" title="Abstract">arXiv:2311.09247</a> (replaced) [<a href="/pdf/2311.09247" title="Download PDF">pdf</a>, <a href="/format/2311.09247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing Humans, GPT-4, and GPT-4V On Abstraction and Reasoning Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+M">Melanie Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Palmarini%2C+A+B">Alessandro B. Palmarini</a>, 
<a href="/search/cs?searchtype=author&query=Moskvichev%2C+A">Arseny Moskvichev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Corrected Figure 3 (extra spaces were replaced by commas, which were lost in original formatting)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11143" title="Abstract">arXiv:2311.11143</a> (replaced) [<a href="/pdf/2311.11143" title="Download PDF">pdf</a>, <a href="/format/2311.11143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Goal-Oriented Communications for Remote Inference under Two-Way Delay  with Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ari%2C+C">Cagri Ari</a>, 
<a href="/search/cs?searchtype=author&query=Shisher%2C+M+K+C">Md Kamran Chowdhury Shisher</a>, 
<a href="/search/cs?searchtype=author&query=Uysal%2C+E">Elif Uysal</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yin Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12220" title="Abstract">arXiv:2311.12220</a> (replaced) [<a href="/pdf/2311.12220" title="Download PDF">pdf</a>, <a href="/ps/2311.12220" title="Download PostScript">ps</a>, <a href="/format/2311.12220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NavMarkAR: A Landmark-based Augmented Reality (AR) Wayfinding System for  Enhancing Spatial Learning of Older Adults
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Z">Zhiwen Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Ashour%2C+M">Mojtaba Ashour</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaohe Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Kalantari%2C+S">Saleh Kalantari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13225" title="Abstract">arXiv:2311.13225</a> (replaced) [<a href="/pdf/2311.13225" title="Download PDF">pdf</a>, <a href="/format/2311.13225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeutronOrch: Rethinking Sample-based GNN Training under CPU-GPU  Heterogeneous Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ai%2C+X">Xin Ai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiange Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+C">Chunyu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaoyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Hao Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yu Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Ge Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14364" title="Abstract">arXiv:2311.14364</a> (replaced) [<a href="/pdf/2311.14364" title="Download PDF">pdf</a>, <a href="/format/2311.14364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Depth Poset of a Filtered Lefschetz Complex
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Edelsbrunner%2C+H">Herbert Edelsbrunner</a>, 
<a href="/search/math?searchtype=author&query=Mrozek%2C+M">Marian Mrozek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Topology (math.AT)</span>; Computational Geometry (cs.CG); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14850" title="Abstract">arXiv:2311.14850</a> (replaced) [<a href="/pdf/2311.14850" title="Download PDF">pdf</a>, <a href="/format/2311.14850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TrojanedCM: A Repository of Trojaned Large Language Models of Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hussain%2C+A">Aftab Hussain</a>, 
<a href="/search/cs?searchtype=author&query=Rabin%2C+M+R+I">Md Rafiqul Islam Rabin</a>, 
<a href="/search/cs?searchtype=author&query=Alipour%2C+M+A">Mohammad Amin Alipour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15497" title="Abstract">arXiv:2311.15497</a> (replaced) [<a href="/pdf/2311.15497" title="Download PDF">pdf</a>, <a href="/format/2311.15497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Image Registration: A Hybrid Approach Integrating Deep Learning  and Optimization Functions for Enhanced Precision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Araujo%2C+G">Gabriel De Araujo</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shanlin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaohui Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15971" title="Abstract">arXiv:2311.15971</a> (replaced) [<a href="/pdf/2311.15971" title="Download PDF">pdf</a>, <a href="/format/2311.15971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supply Chain Due Diligence Risk Assessment for the EU: A Network  Approach to estimate expected effectiveness of the planned EU directive
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hurt%2C+J">Jan Hurt</a>, 
<a href="/search/cs?searchtype=author&query=Ledebur%2C+K">Katharina Ledebur</a>, 
<a href="/search/cs?searchtype=author&query=Meyer%2C+B">Birgit Meyer</a>, 
<a href="/search/cs?searchtype=author&query=Friesenbichler%2C+K">Klaus Friesenbichler</a>, 
<a href="/search/cs?searchtype=author&query=Gerschberger%2C+M">Markus Gerschberger</a>, 
<a href="/search/cs?searchtype=author&query=Thurner%2C+S">Stefan Thurner</a>, 
<a href="/search/cs?searchtype=author&query=Klimek%2C+P">Peter Klimek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> see also the visualization under <a href="https://vis.csh.ac.at/scdd-exposure-indicator/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16500" title="Abstract">arXiv:2311.16500</a> (replaced) [<a href="/pdf/2311.16500" title="Download PDF">pdf</a>, <a href="/format/2311.16500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMGA: Multimodal Large Language Model based Generation Assistant
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+B">Bin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiyin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+Y">Yingfan Tao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yitong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jiaya Jia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16516" title="Abstract">arXiv:2311.16516</a> (replaced) [<a href="/pdf/2311.16516" title="Download PDF">pdf</a>, <a href="/format/2311.16516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment Every Out-of-Distribution Object
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenjie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xin Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Y">Yu Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yunhui Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17116" title="Abstract">arXiv:2311.17116</a> (replaced) [<a href="/pdf/2311.17116" title="Download PDF">pdf</a>, <a href="/format/2311.17116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> REF$^2$-NeRF: Reflection and Refraction aware Neural Radiance Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+W">Wooseok Kim</a>, 
<a href="/search/cs?searchtype=author&query=Fukiage%2C+T">Taiki Fukiage</a>, 
<a href="/search/cs?searchtype=author&query=Oishi%2C+T">Takeshi Oishi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17670" title="Abstract">arXiv:2311.17670</a> (replaced) [<a href="/pdf/2311.17670" title="Download PDF">pdf</a>, <a href="/ps/2311.17670" title="Download PostScript">ps</a>, <a href="/format/2311.17670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 2-covers of wide Young diagrams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aharoni%2C+R">Ron Aharoni</a>, 
<a href="/search/math?searchtype=author&query=Berger%2C+E">Eli Berger</a>, 
<a href="/search/math?searchtype=author&query=Guo%2C+H">He Guo</a>, 
<a href="/search/math?searchtype=author&query=Kotlar%2C+D">Daniel Kotlar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages; Added a few more questions and a reference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18130" title="Abstract">arXiv:2311.18130</a> (replaced) [<a href="/pdf/2311.18130" title="Download PDF">pdf</a>, <a href="/format/2311.18130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Trifecta: Three simple techniques for training deeper  Forward-Forward networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dooms%2C+T">Thomas Dooms</a>, 
<a href="/search/cs?searchtype=author&query=Tsang%2C+I+J">Ing Jyh Tsang</a>, 
<a href="/search/cs?searchtype=author&query=Oramas%2C+J">Jose Oramas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18694" title="Abstract">arXiv:2311.18694</a> (replaced) [<a href="/pdf/2311.18694" title="Download PDF">pdf</a>, <a href="/format/2311.18694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balancing Summarization and Change Detection in Graph Streams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Fukushima%2C+S">Shintaro Fukushima</a>, 
<a href="/search/stat?searchtype=author&query=Yamanishi%2C+K">Kenji Yamanishi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, Accepted to 23rd IEEE International Conference on Data Mining (ICDM2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18718" title="Abstract">arXiv:2311.18718</a> (replaced) [<a href="/pdf/2311.18718" title="Download PDF">pdf</a>, <a href="/format/2311.18718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Steering Deep Feature Learning with Backward Aligned Feature Updates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chizat%2C+L">L&#xe9;na&#xef;c Chizat</a>, 
<a href="/search/cs?searchtype=author&query=Netrapalli%2C+P">Praneeth Netrapalli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00258" title="Abstract">arXiv:2312.00258</a> (replaced) [<a href="/pdf/2312.00258" title="Download PDF">pdf</a>, <a href="/format/2312.00258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Precipitation Nowcasting With Spatial And Temporal Transfer Learning  Using Swin-UNETR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kumar%2C+A">Ajitabh Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2311.17961">arXiv:2311.17961</a>; NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00343" title="Abstract">arXiv:2312.00343</a> (replaced) [<a href="/pdf/2312.00343" title="Download PDF">pdf</a>, <a href="/format/2312.00343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenStereo: A Comprehensive Benchmark for Stereo Matching and Strong  Baseline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xianda Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Juntao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yiqun Duan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Long Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02221" title="Abstract">arXiv:2312.02221</a> (replaced) [<a href="/pdf/2312.02221" title="Download PDF">pdf</a>, <a href="/format/2312.02221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Slice3D: Multi-Slice, Occlusion-Revealing, Single View 3D Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yizhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lira%2C+W">Wallace Lira</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mahdavi-Amiri%2C+A">Ali Mahdavi-Amiri</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="https://yizhiwang96.github.io/Slice3D/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02498" title="Abstract">arXiv:2312.02498</a> (replaced) [<a href="/e-print/2312.02498" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provable Reinforcement Learning for Networked Control Systems with  Stochastic Packet Disordering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xue%2C+W">Wenqian Xue</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+Y">Yi Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Lewis%2C+F+L">Frank L. Lewis</a>, 
<a href="/search/eess?searchtype=author&query=Lian%2C+B">Bosen Lian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a wrong version with problem setting and description errors in main sections
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03018" title="Abstract">arXiv:2312.03018</a> (replaced) [<a href="/pdf/2312.03018" title="Download PDF">pdf</a>, <a href="/format/2312.03018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreamVideo: High-Fidelity Image-to-Video Generation with Image Retention  and Text Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiaxi Gu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+P">Panwen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Songcen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaodan Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03033" title="Abstract">arXiv:2312.03033</a> (replaced) [<a href="/pdf/2312.03033" title="Download PDF">pdf</a>, <a href="/format/2312.03033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiDAR-based Person Re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wenxuan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhiyu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yingping Liang</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+Z">Ziheng Xi</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z+C">Zhi Chen Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jianjiang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03594" title="Abstract">arXiv:2312.03594</a> (replaced) [<a href="/pdf/2312.03594" title="Download PDF">pdf</a>, <a href="/format/2312.03594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Task is Worth One Word: Learning with Task Prompts for High-Quality  Versatile Image Inpainting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+J">Junhao Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yanhong Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenran Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chun Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page with code: <a href="https://powerpaint.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03774" title="Abstract">arXiv:2312.03774</a> (replaced) [<a href="/pdf/2312.03774" title="Download PDF">pdf</a>, <a href="/format/2312.03774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OctreeOcc: Efficient and Multi-Granularity Occupancy Prediction Using  Octree Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yuhang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xinge Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yuexin Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03998" title="Abstract">arXiv:2312.03998</a> (replaced) [<a href="/pdf/2312.03998" title="Download PDF">pdf</a>, <a href="/format/2312.03998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Series2Vec: Similarity-based Self-supervised Representation Learning for  Time Series Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Foumani%2C+N+M">Navid Mohammadi Foumani</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C+W">Chang Wei Tan</a>, 
<a href="/search/cs?searchtype=author&query=Webb%2C+G+I">Geoffrey I. Webb</a>, 
<a href="/search/cs?searchtype=author&query=Rezatofighi%2C+H">Hamid Rezatofighi</a>, 
<a href="/search/cs?searchtype=author&query=Salehi%2C+M">Mahsa Salehi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04316" title="Abstract">arXiv:2312.04316</a> (replaced) [<a href="/pdf/2312.04316" title="Download PDF">pdf</a>, <a href="/format/2312.04316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Knowledge-driven Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yeqi Bai</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+P">Pinlong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+L">Licheng Wen</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+D">Daocheng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xuemeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xinyu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Tao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jianfei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xing Gao</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+M">Min Dou</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Botian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Liang He</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04344" title="Abstract">arXiv:2312.04344</a> (replaced) [<a href="/pdf/2312.04344" title="Download PDF">pdf</a>, <a href="/format/2312.04344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Medical Task Performance in GPT-4V: A Comprehensive Study on  Prompt Engineering Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pengcheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Ziyan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhongying Deng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yanzhou Su</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jin Ye</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junjun He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04691" title="Abstract">arXiv:2312.04691</a> (replaced) [<a href="/pdf/2312.04691" title="Download PDF">pdf</a>, <a href="/format/2312.04691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simul-LLM: A Framework for Exploring High-Quality Simultaneous  Translation with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agostinelli%2C+V">Victor Agostinelli</a>, 
<a href="/search/cs?searchtype=author&query=Wild%2C+M">Max Wild</a>, 
<a href="/search/cs?searchtype=author&query=Raffel%2C+M">Matthew Raffel</a>, 
<a href="/search/cs?searchtype=author&query=Fuad%2C+K+A+A">Kazi Ahmed Asif Fuad</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lizhong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04815" title="Abstract">arXiv:2312.04815</a> (replaced) [<a href="/pdf/2312.04815" title="Download PDF">pdf</a>, <a href="/format/2312.04815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Not All Negatives Are Worth Attending to: Meta-Bootstrapping Negative  Sampling Framework for Link Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yakun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Binbin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Meiqi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiqiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+G">Guo Ye</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">Huimei He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04837" title="Abstract">arXiv:2312.04837</a> (replaced) [<a href="/pdf/2312.04837" title="Download PDF">pdf</a>, <a href="/format/2312.04837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Localized Symbolic Knowledge Distillation for Visual Commonsense Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+J+S">Jae Sung Park</a>, 
<a href="/search/cs?searchtype=author&query=Hessel%2C+J">Jack Hessel</a>, 
<a href="/search/cs?searchtype=author&query=Chandu%2C+K+R">Khyathi Raghavi Chandu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P+P">Paul Pu Liang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Ximing Lu</a>, 
<a href="/search/cs?searchtype=author&query=West%2C+P">Peter West</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Youngjae Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qiuyuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianfeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Farhadi%2C+A">Ali Farhadi</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yejin Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Neurips 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05180" title="Abstract">arXiv:2312.05180</a> (replaced) [<a href="/pdf/2312.05180" title="Download PDF">pdf</a>, <a href="/format/2312.05180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PathFinder: Guided Search over Multi-Step Reasoning Paths
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Golovneva%2C+O">Olga Golovneva</a>, 
<a href="/search/cs?searchtype=author&query=O%27Brien%2C+S">Sean O&#x27;Brien</a>, 
<a href="/search/cs?searchtype=author&query=Pasunuru%2C+R">Ramakanth Pasunuru</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianlu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zettlemoyer%2C+L">Luke Zettlemoyer</a>, 
<a href="/search/cs?searchtype=author&query=Fazel-Zarandi%2C+M">Maryam Fazel-Zarandi</a>, 
<a href="/search/cs?searchtype=author&query=Celikyilmaz%2C+A">Asli Celikyilmaz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 R0-FoMo Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05328" title="Abstract">arXiv:2312.05328</a> (replaced) [<a href="/pdf/2312.05328" title="Download PDF">pdf</a>, <a href="/format/2312.05328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bad Students Make Great Teachers: Active Learning Accelerates  Large-Scale Visual Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Evans%2C+T">Talfan Evans</a>, 
<a href="/search/cs?searchtype=author&query=Pathak%2C+S">Shreya Pathak</a>, 
<a href="/search/cs?searchtype=author&query=Merzic%2C+H">Hamza Merzic</a>, 
<a href="/search/cs?searchtype=author&query=Schwarz%2C+J">Jonathan Schwarz</a>, 
<a href="/search/cs?searchtype=author&query=Tanno%2C+R">Ryutaro Tanno</a>, 
<a href="/search/cs?searchtype=author&query=Henaff%2C+O+J">Olivier J. Henaff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05488" title="Abstract">arXiv:2312.05488</a> (replaced) [<a href="/pdf/2312.05488" title="Download PDF">pdf</a>, <a href="/format/2312.05488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Large Language Models Serve as Rational Players in Game Theory? A  Systematic Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Caoyun Fan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jindou Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yaohui Jin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">Hao He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05496" title="Abstract">arXiv:2312.05496</a> (replaced) [<a href="/pdf/2312.05496" title="Download PDF">pdf</a>, <a href="/format/2312.05496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flexible Cross-Modal Steganography via Implicit Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Seoyun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Sojeong Song</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+C+D">Chang D. Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Junmo Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05497" title="Abstract">arXiv:2312.05497</a> (replaced) [<a href="/pdf/2312.05497" title="Download PDF">pdf</a>, <a href="/format/2312.05497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> History Matters: Temporal Knowledge Editing in Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xunjian Yin</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xiaojun Wan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024. 14 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05549" title="Abstract">arXiv:2312.05549</a> (replaced) [<a href="/pdf/2312.05549" title="Download PDF">pdf</a>, <a href="/format/2312.05549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-granularity Causal Structure Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jiaxuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Guoxian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shuyin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoyin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05603" title="Abstract">arXiv:2312.05603</a> (replaced) [<a href="/pdf/2312.05603" title="Download PDF">pdf</a>, <a href="/format/2312.05603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sim-GPT: Text Similarity via GPT Annotated Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+B">Beiming Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shengyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoya Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoyin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hovy%2C+E">Eduard Hovy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05662" title="Abstract">arXiv:2312.05662</a> (replaced) [<a href="/pdf/2312.05662" title="Download PDF">pdf</a>, <a href="/format/2312.05662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Effect of Model Compression on Social Bias in Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gon%C3%A7alves%2C+G">Gustavo Gon&#xe7;alves</a>, 
<a href="/search/cs?searchtype=author&query=Strubell%2C+E">Emma Strubell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Main
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05690" title="Abstract">arXiv:2312.05690</a> (replaced) [<a href="/pdf/2312.05690" title="Download PDF">pdf</a>, <a href="/format/2312.05690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is Ignorance Bliss? The Role of Post Hoc Explanation Faithfulness and  Alignment in Model Trust in Laypeople and Domain Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+T">Tessa Han</a>, 
<a href="/search/cs?searchtype=author&query=Ektefaie%2C+Y">Yasha Ektefaie</a>, 
<a href="/search/cs?searchtype=author&query=Farhat%2C+M">Maha Farhat</a>, 
<a href="/search/cs?searchtype=author&query=Zitnik%2C+M">Marinka Zitnik</a>, 
<a href="/search/cs?searchtype=author&query=Lakkaraju%2C+H">Himabindu Lakkaraju</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05695" title="Abstract">arXiv:2312.05695</a> (replaced) [<a href="/pdf/2312.05695" title="Download PDF">pdf</a>, <a href="/format/2312.05695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Counterattack of CNNs in Self-Supervised Learning: Larger Kernel  Size might be All You Need
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tianjin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianlong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shiwei Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05725" title="Abstract">arXiv:2312.05725</a> (replaced) [<a href="/pdf/2312.05725" title="Download PDF">pdf</a>, <a href="/format/2312.05725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FP8-BERT: Post-Training Quantization for Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianchi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yen%2C+I+E">Ian En-Hsu Yen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dongkuan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05743" title="Abstract">arXiv:2312.05743</a> (replaced) [<a href="/pdf/2312.05743" title="Download PDF">pdf</a>, <a href="/format/2312.05743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building Variable-sized Models via Learngene Pool
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Boyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shiyu Xia</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haokun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kou%2C+Z">Zhiqiang Kou</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+X">Xin Geng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05756" title="Abstract">arXiv:2312.05756</a> (replaced) [<a href="/pdf/2312.05756" title="Download PDF">pdf</a>, <a href="/ps/2312.05756" title="Download PostScript">ps</a>, <a href="/format/2312.05756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A quantitative fusion strategy of stock picking and timing based on  Particle Swarm Optimized-Back Propagation Neural Network and Multivariate  Gaussian-Hidden Markov Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huajian Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Longjian Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jiajian Liang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+W">Weinan Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures, 4 tables, 26 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05799" title="Abstract">arXiv:2312.05799</a> (replaced) [<a href="/pdf/2312.05799" title="Download PDF">pdf</a>, <a href="/format/2312.05799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SGNet: Structure Guided Network via Gradient-Frequency Awareness for  Depth Map Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhengxue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhiqiang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05924" title="Abstract">arXiv:2312.05924</a> (replaced) [<a href="/pdf/2312.05924" title="Download PDF">pdf</a>, <a href="/format/2312.05924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Free Hard-Label Robustness Stealing Attack
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xiaojian Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kejiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+N">Nenghai Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05978" title="Abstract">arXiv:2312.05978</a> (replaced) [<a href="/pdf/2312.05978" title="Download PDF">pdf</a>, <a href="/format/2312.05978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Architecture Codesign for Fast Bragg Peak Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McDermott%2C+L">Luke McDermott</a>, 
<a href="/search/cs?searchtype=author&query=Weitz%2C+J">Jason Weitz</a>, 
<a href="/search/cs?searchtype=author&query=Demler%2C+D">Dmitri Demler</a>, 
<a href="/search/cs?searchtype=author&query=Cummings%2C+D">Daniel Cummings</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+N">Nhan Tran</a>, 
<a href="/search/cs?searchtype=author&query=Duarte%2C+J">Javier Duarte</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in 3rd Annual AAAI Workshop on AI to Accelerate Science and Engineering (AI2ASE)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05994" title="Abstract">arXiv:2312.05994</a> (replaced) [<a href="/pdf/2312.05994" title="Download PDF">pdf</a>, <a href="/format/2312.05994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> mir_ref: A Representation Evaluation Framework for Music Information  Retrieval Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Plachouras%2C+C">Christos Plachouras</a>, 
<a href="/search/cs?searchtype=author&query=Alonso-Jim%C3%A9nez%2C+P">Pablo Alonso-Jim&#xe9;nez</a>, 
<a href="/search/cs?searchtype=author&query=Bogdanov%2C+D">Dmitry Bogdanov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Machine Learning for Audio Workshop, Neural Information Processing Systems (NeurIPS) 2023, New Orleans, LA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Information Retrieval (cs.IR); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06037" title="Abstract">arXiv:2312.06037</a> (replaced) [<a href="/pdf/2312.06037" title="Download PDF">pdf</a>, <a href="/format/2312.06037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodality of AI for Education: Towards Artificial General  Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+G">Gyeong-Geon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Lehong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Latif%2C+E">Ehsan Latif</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yizhu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Bewersdorff%2C+A">Arne Bewersdorff</a>, 
<a href="/search/cs?searchtype=author&query=Nyaaba%2C+M">Matthew Nyaaba</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Shuchen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zihao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+G">Gengchen Mai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tiaming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaoming Zhai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06069" title="Abstract">arXiv:2312.06069</a> (replaced) [<a href="/pdf/2312.06069" title="Download PDF">pdf</a>, <a href="/format/2312.06069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mining Gaze for Contrastive Learning toward Computer-Assisted Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zihao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+D">Dinggang Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> *These authors contributed equally. Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06348" title="Abstract">arXiv:2312.06348</a> (replaced) [<a href="/pdf/2312.06348" title="Download PDF">pdf</a>, <a href="/format/2312.06348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffAIL: Diffusion Adversarial Imitation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bingzheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Guoqiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+T">Teng Pang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yilong Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06363" title="Abstract">arXiv:2312.06363</a> (replaced) [<a href="/pdf/2312.06363" title="Download PDF">pdf</a>, <a href="/format/2312.06363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MMICT: Boosting Multi-Modal Fine-Tuning with In-Context Examples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Enwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yuting Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Ke Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hui Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06409" title="Abstract">arXiv:2312.06409</a> (replaced) [<a href="/pdf/2312.06409" title="Download PDF">pdf</a>, <a href="/format/2312.06409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PointVoxel: A Simple and Effective Pipeline for Multi-View Multi-Modal  3D Human Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhiyu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zhicheng Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wenxuan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yifan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jianjiang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06436" title="Abstract">arXiv:2312.06436</a> (replaced) [<a href="/pdf/2312.06436" title="Download PDF">pdf</a>, <a href="/format/2312.06436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reward Certification for Policy Smoothed Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mu%2C+R">Ronghui Mu</a>, 
<a href="/search/cs?searchtype=author&query=Marcolino%2C+L+S">Leandro Soriano Marcolino</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianle Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanghao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaowei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+W">Wenjie Ruan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper will be presented in AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06552" title="Abstract">arXiv:2312.06552</a> (replaced) [<a href="/pdf/2312.06552" title="Download PDF">pdf</a>, <a href="/format/2312.06552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open Data-Driven Automation of Residential Distribution Grid Modeling  with Minimal Data Requirements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weber%2C+M">Moritz Weber</a>, 
<a href="/search/cs?searchtype=author&query=Janecke%2C+L">Luc Janecke</a>, 
<a href="/search/cs?searchtype=author&query=%C3%87akmak%2C+H+K">H&#xfc;seyin K. &#xc7;akmak</a>, 
<a href="/search/cs?searchtype=author&query=Hagenmeyer%2C+V">Veit Hagenmeyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 12 figures, submitted to IEEE Transactions on Smart Grid
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06564" title="Abstract">arXiv:2312.06564</a> (replaced) [<a href="/pdf/2312.06564" title="Download PDF">pdf</a>, <a href="/format/2312.06564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Promoting Counterfactual Robustness through Diversity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leofante%2C+F">Francesco Leofante</a>, 
<a href="/search/cs?searchtype=author&query=Potyka%2C+N">Nico Potyka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06630" title="Abstract">arXiv:2312.06630</a> (replaced) [<a href="/pdf/2312.06630" title="Download PDF">pdf</a>, <a href="/format/2312.06630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TMT-VIS: Taxonomy-aware Multi-dataset Joint Training for Video Instance  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Rongkun Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+L">Lu Qi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hengshuang Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06635" title="Abstract">arXiv:2312.06635</a> (replaced) [<a href="/pdf/2312.06635" title="Download PDF">pdf</a>, <a href="/format/2312.06635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gated Linear Attention Transformers with Hardware-Efficient Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Songlin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bailin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yikang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Panda%2C+R">Rameswar Panda</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yoon Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> fix code link
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06643" title="Abstract">arXiv:2312.06643</a> (replaced) [<a href="/pdf/2312.06643" title="Download PDF">pdf</a>, <a href="/format/2312.06643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaze Detection and Analysis for Initiating Joint Activity in Industrial  Human-Robot Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prajod%2C+P">Pooja Prajod</a>, 
<a href="/search/cs?searchtype=author&query=Nicora%2C+M+L">Matteo Lavit Nicora</a>, 
<a href="/search/cs?searchtype=author&query=Mondellini%2C+M">Marta Mondellini</a>, 
<a href="/search/cs?searchtype=author&query=Tauro%2C+G">Giovanni Tauro</a>, 
<a href="/search/cs?searchtype=author&query=Vertechy%2C+R">Rocco Vertechy</a>, 
<a href="/search/cs?searchtype=author&query=Malosio%2C+M">Matteo Malosio</a>, 
<a href="/search/cs?searchtype=author&query=Andr%C3%A9%2C+E">Elisabeth Andr&#xe9;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First draft for a paper submitted to Frontiers in Robotics and AI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06648" title="Abstract">arXiv:2312.06648</a> (replaced) [<a href="/pdf/2312.06648" title="Download PDF">pdf</a>, <a href="/format/2312.06648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dense X Retrieval: What Retrieval Granularity Should We Use?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sihao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenhao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+K">Kaixin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xinran Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dong Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item385">Cross-lists</a></li>
<li><a href="#item416">Replacements</a></li>
</ul>
<small>[ total of 644 entries:  <b>1-644</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2312">2312</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
