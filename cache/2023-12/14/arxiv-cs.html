<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Tue 12 Dec 23  to  Wed 13 Dec 23, announced Thu, 14 Dec 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item340">Cross-lists</a></li>
<li><a href="#item400">Replacements</a></li>
</ul>
<small>[ total of 607 entries:  <b>1-607</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Thu, 14 Dec 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07549" title="Abstract">arXiv:2312.07549</a> [<a href="/pdf/2312.07549" title="Download PDF">pdf</a>, <a href="/format/2312.07549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Make-A-Storyboard: A General Framework for Storyboard with Disentangled  and Merged Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+S">Sitong Su</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Litao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Lianli Gao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H+T">Heng Tao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jingkuan Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Story Visualization aims to generate images aligned with story prompts,
reflecting the coherence of storybooks through visual consistency among
characters and scenes.Whereas current approaches exclusively concentrate on
characters and neglect the visual consistency among contextually correlated
scenes, resulting in independent character images without inter-image
coherence.To tackle this issue, we propose a new presentation form for Story
Visualization called Storyboard, inspired by film-making, as illustrated in
Fig.1.Specifically, a Storyboard unfolds a story into visual representations
scene by scene. Within each scene in Storyboard, characters engage in
activities at the same location, necessitating both visually consistent scenes
and characters.For Storyboard, we design a general framework coined as
Make-A-Storyboard that applies disentangled control over the consistency of
contextual correlated characters and scenes and then merge them to form
harmonized images.Extensive experiments demonstrate 1) Effectiveness.the
effectiveness of the method in story alignment, character consistency, and
scene correlation; 2) Generalization. Our method could be seamlessly integrated
into mainstream Image Customization methods, empowering them with the
capability of story visualization.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07550" title="Abstract">arXiv:2312.07550</a> [<a href="/pdf/2312.07550" title="Download PDF">pdf</a>, <a href="/format/2312.07550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding (Un)Intended Memorization in Text-to-Image Generative  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naseh%2C+A">Ali Naseh</a>, 
<a href="/search/cs?searchtype=author&query=Roh%2C+J">Jaechul Roh</a>, 
<a href="/search/cs?searchtype=author&query=Houmansadr%2C+A">Amir Houmansadr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Multimodal machine learning, especially text-to-image models like Stable
Diffusion and DALL-E 3, has gained significance for transforming text into
detailed images.
<br />Despite their growing use and remarkable generative capabilities, there is a
pressing need for a detailed examination of these models' behavior,
particularly with respect to memorization. Historically, memorization in
machine learning has been context-dependent, with diverse definitions emerging
from classification tasks to complex models like Large Language Models (LLMs)
and Diffusion models. Yet, a definitive concept of memorization that aligns
with the intricacies of text-to-image synthesis remains elusive. This
understanding is vital as memorization poses privacy risks yet is essential for
meeting user expectations, especially when generating representations of
underrepresented entities. In this paper, we introduce a specialized definition
of memorization tailored to text-to-image models, categorizing it into three
distinct types according to user expectations. We closely examine the subtle
distinctions between intended and unintended memorization, emphasizing the
importance of balancing user privacy with the generative quality of the model
outputs. Using the Stable Diffusion model, we offer examples to validate our
memorization definitions and clarify their application.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07551" title="Abstract">arXiv:2312.07551</a> [<a href="/pdf/2312.07551" title="Download PDF">pdf</a>, <a href="/format/2312.07551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Model Alignment with Elastic Reset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Noukhovitch%2C+M">Michael Noukhovitch</a>, 
<a href="/search/cs?searchtype=author&query=Lavoie%2C+S">Samuel Lavoie</a>, 
<a href="/search/cs?searchtype=author&query=Strub%2C+F">Florian Strub</a>, 
<a href="/search/cs?searchtype=author&query=Courville%2C+A">Aaron Courville</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Finetuning language models with reinforcement learning (RL), e.g. from human
feedback (HF), is a prominent method for alignment. But optimizing against a
reward model can improve on reward while degrading performance in other areas,
a phenomenon known as reward hacking, alignment tax, or language drift. First,
we argue that commonly-used test metrics are insufficient and instead measure
how different algorithms tradeoff between reward and drift. The standard method
modified the reward with a Kullback-Lieber (KL) penalty between the online and
initial model. We propose Elastic Reset, a new algorithm that achieves higher
reward with less drift without explicitly modifying the training objective. We
periodically reset the online model to an exponentially moving average (EMA) of
itself, then reset the EMA model to the initial model. Through the use of an
EMA, our model recovers quickly after resets and achieves higher reward with
less drift in the same number of steps. We demonstrate that fine-tuning
language models with Elastic Reset leads to state-of-the-art performance on a
small scale pivot-translation benchmark, outperforms all baselines in a
medium-scale RLHF-like IMDB mock sentiment task and leads to a more performant
and more aligned technical QA chatbot with LLaMA-7B. Code available at
github.com/mnoukhov/elastic-reset.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07552" title="Abstract">arXiv:2312.07552</a> [<a href="/pdf/2312.07552" title="Download PDF">pdf</a>, <a href="/format/2312.07552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Intent-Driven Session Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+X">Xinghua Qu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+K">Kaidong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ong%2C+Y">Yew-Soon Ong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Intent-aware session recommendation (ISR) is pivotal in discerning user
intents within sessions for precise predictions. Traditional approaches,
however, face limitations due to their presumption of a uniform number of
intents across all sessions. This assumption overlooks the dynamic nature of
user sessions, where the number and type of intentions can significantly vary.
In addition, these methods typically operate in latent spaces, thus hinder the
model's transparency.Addressing these challenges, we introduce a novel ISR
approach, utilizing the advanced reasoning capabilities of large language
models (LLMs). First, this approach begins by generating an initial prompt that
guides LLMs to predict the next item in a session, based on the varied intents
manifested in user sessions. Then, to refine this process, we introduce an
innovative prompt optimization mechanism that iteratively self-reflects and
adjusts prompts. Furthermore, our prompt selection module, built upon the LLMs'
broad adaptability, swiftly selects the most optimized prompts across diverse
domains. This new paradigm empowers LLMs to discern diverse user intents at a
semantic level, leading to more accurate and interpretable session
recommendations. Our extensive experiments on three real-world datasets
demonstrate the effectiveness of our method, marking a significant advancement
in ISR systems.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07553" title="Abstract">arXiv:2312.07553</a> [<a href="/pdf/2312.07553" title="Download PDF">pdf</a>, <a href="/format/2312.07553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hijacking Context in Large Multi-modal Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeong%2C+J">Joonhyun Jeong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report. Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Recently, Large Multi-modal Models (LMMs) have demonstrated their ability to
understand the visual contents of images given the instructions regarding the
images. Built upon the Large Language Models (LLMs), LMMs also inherit their
abilities and characteristics such as in-context learning where a coherent
sequence of images and texts are given as the input prompt. However, we
identify a new limitation of off-the-shelf LMMs where a small fraction of
incoherent images or text descriptions mislead LMMs to only generate biased
output about the hijacked context, not the originally intended context. To
address this, we propose a pre-filtering method that removes irrelevant
contexts via GPT-4V, based on its robustness towards distribution shift within
the contexts. We further investigate whether replacing the hijacked visual and
textual contexts with the correlated ones via GPT-4V and text-to-image models
can help yield coherent responses.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07556" title="Abstract">arXiv:2312.07556</a> [<a href="/pdf/2312.07556" title="Download PDF">pdf</a>, <a href="/format/2312.07556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning for Short Text Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+M">Mengling Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaochao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+X">Xinting Liao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiaolin Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Short text clustering has been popularly studied for its significance in
mining valuable insights from many short texts. In this paper, we focus on the
federated short text clustering (FSTC) problem, i.e., clustering short texts
that are distributed in different clients, which is a realistic problem under
privacy requirements. Compared with the centralized short text clustering
problem that short texts are stored on a central server, the FSTC problem has
not been explored yet. To fill this gap, we propose a Federated Robust Short
Text Clustering (FSTC) framework. FSTC includes two main modules, i.e., robust
short text clustering module and federated cluster center aggregation module.
The robust short text clustering module aims to train an effective short text
clustering model with local data in each client. We innovatively combine
optimal transport to generate pseudo-labels with Gaussian-uniform mixture model
to ensure the reliability of the pseudo-supervised data. The federated cluster
center aggregation module aims to exchange knowledge across clients without
sharing local raw data in an efficient way. The server aggregates the local
cluster centers from different clients and then sends the global centers back
to all clients in each communication round. Our empirical studies on three
short text clustering datasets demonstrate that FSTC significantly outperforms
the federated short text clustering baselines.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07559" title="Abstract">arXiv:2312.07559</a> [<a href="/pdf/2312.07559" title="Download PDF">pdf</a>, <a href="/format/2312.07559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PaperQA: Retrieval-Augmented Generative Agent for Scientific Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%A1la%2C+J">Jakub L&#xe1;la</a>, 
<a href="/search/cs?searchtype=author&query=O%27Donoghue%2C+O">Odhran O&#x27;Donoghue</a>, 
<a href="/search/cs?searchtype=author&query=Shtedritski%2C+A">Aleksandar Shtedritski</a>, 
<a href="/search/cs?searchtype=author&query=Cox%2C+S">Sam Cox</a>, 
<a href="/search/cs?searchtype=author&query=Rodriques%2C+S+G">Samuel G. Rodriques</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+A+D">Andrew D. White</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) generalize well across language tasks, but
suffer from hallucinations and uninterpretability, making it difficult to
assess their accuracy without ground-truth. Retrieval-Augmented Generation
(RAG) models have been proposed to reduce hallucinations and provide provenance
for how an answer was generated. Applying such models to the scientific
literature may enable large-scale, systematic processing of scientific
knowledge. We present PaperQA, a RAG agent for answering questions over the
scientific literature. PaperQA is an agent that performs information retrieval
across full-text scientific articles, assesses the relevance of sources and
passages, and uses RAG to provide answers. Viewing this agent as a question
answering model, we find it exceeds performance of existing LLMs and LLM agents
on current science QA benchmarks. To push the field closer to how humans
perform research on scientific literature, we also introduce LitQA, a more
complex benchmark that requires retrieval and synthesis of information from
full-text scientific papers across the literature. Finally, we demonstrate
PaperQA's matches expert human researchers on LitQA.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07560" title="Abstract">arXiv:2312.07560</a> [<a href="/pdf/2312.07560" title="Download PDF">pdf</a>, <a href="/ps/2312.07560" title="Download PostScript">ps</a>, <a href="/format/2312.07560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-driven Structure Detection and Information Extraction from Historical  Cadastral Maps (Early 19th Century Franciscean Cadastre in the Province of  Styria) and Current High-resolution Satellite and Aerial Imagery for Remote  Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%C3%B6derle%2C+W">Wolfgang G&#xf6;derle</a>, 
<a href="/search/cs?searchtype=author&query=Macher%2C+C">Christian Macher</a>, 
<a href="/search/cs?searchtype=author&query=Mauthner%2C+K">Katrin Mauthner</a>, 
<a href="/search/cs?searchtype=author&query=Pimas%2C+O">Oliver Pimas</a>, 
<a href="/search/cs?searchtype=author&query=Rampetsreiter%2C+F">Fabian Rampetsreiter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Cadastres from the 19th century are a complex as well as rich source for
historians and archaeologists, whose use presents them with great challenges.
For archaeological and historical remote sensing, we have trained several Deep
Learning models, CNNs as well as Vision Transformers, to extract large-scale
data from this knowledge representation. We present the principle results of
our work here and we present a the demonstrator of our browser-based tool that
allows researchers and public stakeholders to quickly identify spots that
featured buildings in the 19th century Franciscean Cadastre. The tool not only
supports scholars and fellow researchers in building a better understanding of
the settlement history of the region of Styria, it also helps public
administration and fellow citizens to swiftly identify areas of heightened
sensibility with regard to the cultural heritage of the region.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07565" title="Abstract">arXiv:2312.07565</a> [<a href="/pdf/2312.07565" title="Download PDF">pdf</a>, <a href="/format/2312.07565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Use of Smart Hybrid Contracts to Provide Flexibility in  Algorithmic Governance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Molina-Jimenez%2C+C">Carlos Molina-Jimenez</a>, 
<a href="/search/cs?searchtype=author&query=Felizia%2C+S+M">Sandra Milena Felizia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Eleven pages in total. Four pdf figures. Paper accepted for publication in Data and Policy Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">The use of computer technology to automate the enforcement of law is a
promising alternative to simplify bureaucratic procedures. However, careless
automation might result in an inflexible and dehumanise law enforcement system
driven by algorithms that do not account for the particularities of individuals
or minorities. In this paper, we argue that hybrid smart contracts deployed to
monitor rather than to blindly enforce regulations can be used to add
flexibility. Enforcement is a suitable alternative only when prevention is
strictly necessary; however, we argue that in many situations a corrective
approach based on monitoring is more flexible and suitable. To add more
flexibility, the hybrid smart contract can be programmed to stop to request the
intervention of a human or of a group of them when human judgement is needed.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07566" title="Abstract">arXiv:2312.07566</a> [<a href="/pdf/2312.07566" title="Download PDF">pdf</a>, <a href="/ps/2312.07566" title="Download PostScript">ps</a>, <a href="/format/2312.07566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A symbolic-arithmetic for teaching double-black node removal in  red-black trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ehimwenma%2C+K+E">Kennedy E. Ehimwenma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Ze Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hongyu Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">A red-black (RB) tree is a data structure with red and black nodes
coloration. The red and black color of nodes make up the principal component
for balancing a RB tree. A balanced tree has an equal number of black nodes on
any simple path. But when a black leaf node is deleted, a double-black (DB)
node is formed, thus, causing a reduction in black heights and the tree becomes
unbalanced. Rebalancing a RB tree with a DB node is a fairly complex process.
Teaching and learning the removal of DB nodes is also challenging. This paper
introduces a simplified novel method which is a symbolic-algebraic arithmetic
procedure for the removal of DB nodes and the rebalancing of black heights in
RB trees. This simplified approach has enhanced student learning of the DB node
removal in RB trees. Feedback from students showed the learnability,
workability and acceptance of the symbolic-algebraic method in balancing RB
trees after a delete operation.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07571" title="Abstract">arXiv:2312.07571</a> [<a href="/pdf/2312.07571" title="Download PDF">pdf</a>, <a href="/format/2312.07571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating YOLO Models Towards Outdoor Obstacle Detection For  Visually Impaired People
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+C">Chenhao He</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+P">Pramit Saha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The utilization of deep learning-based object detection is an effective
approach to assist visually impaired individuals in avoiding obstacles. In this
paper, we implemented seven different YOLO object detection models
\textit{viz}., YOLO-NAS (small, medium, large), YOLOv8, YOLOv7, YOLOv6, and
YOLOv5 and performed comprehensive evaluation with carefully tuned
hyperparameters, to analyze how these models performed on images containing
common daily-life objects presented on roads and sidewalks. After a systematic
investigation, YOLOv8 was found to be the best model, which reached a precision
of $80\%$ and a recall of $68.2\%$ on a well-known Obstacle Dataset which
includes images from VOC dataset, COCO dataset, and TT100K dataset along with
images collected by the researchers in the field. Despite being the latest
model and demonstrating better performance in many other applications, YOLO-NAS
was found to be suboptimal for the obstacle detection task.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07573" title="Abstract">arXiv:2312.07573</a> [<a href="/pdf/2312.07573" title="Download PDF">pdf</a>, <a href="/format/2312.07573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Arabic Handwritten Text Line Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bouchal%2C+H">Hakim Bouchal</a>, 
<a href="/search/cs?searchtype=author&query=Belaid%2C+A">Ahror Belaid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TAMARICS'2022 Conference held on December 8-11,2022 at University of Tamenghasset,Algeria
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Segmentation of Arabic manuscripts into lines of text and words is an
important step to make recognition systems more efficient and accurate. The
problem of segmentation into text lines is solved since there are carefully
annotated dataset dedicated to this task. However, To the best of our
knowledge, there are no dataset annotating the word position of Arabic texts.
In this paper, we present a new dataset specifically designed for historical
Arabic script in which we annotate position in word level.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07575" title="Abstract">arXiv:2312.07575</a> [<a href="/pdf/2312.07575" title="Download PDF">pdf</a>, <a href="/format/2312.07575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TapTree: Process-Tree Based Host Behavior Modeling and Threat Detection  Framework via Sequential Pattern Mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mamun%2C+M">Mohammad Mamun</a>, 
<a href="/search/cs?searchtype=author&query=Buffett%2C+S">Scott Buffett</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Information and Communications Security. 24th International
  Conference, ICICS 2022, Canterbury, UK, September 5-8, 2022, Proceedings Sep
  2022 Pages 546-565
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Audit logs containing system level events are frequently used for behavior
modeling as they can provide detailed insight into cyber-threat occurrences.
However, mapping low-level system events in audit logs to highlevel behaviors
has been a major challenge in identifying host contextual behavior for the
purpose of detecting potential cyber threats. Relying on domain expert
knowledge may limit its practical implementation. This paper presents TapTree,
an automated process-tree based technique to extract host behavior by compiling
system events' semantic information. After extracting behaviors as system
generated process trees, TapTree integrates event semantics as a representation
of behaviors. To further reduce pattern matching workloads for the analyst,
TapTree aggregates semantically equivalent patterns and optimizes
representative behaviors. In our evaluation against a recent benchmark audit
log dataset (DARPA OpTC), TapTree employs tree pattern queries and sequential
pattern mining techniques to deduce the semantics of connected system events,
achieving high accuracy for behavior abstraction and then Advanced Persistent
Threat (APT) attack detection. Moreover, we illustrate how to update the
baseline model gradually online, allowing it to adapt to new log patterns over
time.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07576" title="Abstract">arXiv:2312.07576</a> [<a href="/pdf/2312.07576" title="Download PDF">pdf</a>, <a href="/format/2312.07576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ECHO: An Automated Contextual Inquiry Framework for Anonymous  Qualitative Studies using Conversational Assistants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dwaraghanath%2C+R">Rishika Dwaraghanath</a>, 
<a href="/search/cs?searchtype=author&query=Majethia%2C+R">Rahul Majethia</a>, 
<a href="/search/cs?searchtype=author&query=Gautam%2C+S">Sanjana Gautam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Qualitative research studies often employ a contextual inquiry, or a field
study that involves in-depth observation and interviews of a small sample of
study participants, in-situ, to gain a robust understanding of the reasons and
circumstances that led to the participant's thoughts, actions, and experiences
regarding the domain of interest. Contextual inquiry, especially in sensitive
data studies, can be a challenging task due to reasons such as participant
privacy, as well as physical constraints such as in-person presence and manual
analysis of the qualitative data gathered. In this work, we discuss Enqu\^ete
Contextuelle Habile Ordinateur (ECHO); a virtual-assistant framework to
automate the erstwhile manual process of conducting contextual inquiries and
analysing the respondents' subjective qualitative data. ECHO automates the
contextual inquiry pipeline, while not compromising on privacy preservation or
response integrity. Its adaptive conversational interface enables respondents
to provide unstructured or semi-structured responses in free-form natural
language, allowing researchers to explore larger narratives in participant
response data. It supports response-driven exploratory questions and automates
coding methodologies for qualitative data, thus enabling the inquirer to dive
deeper into correlated questions and to do better cause-effect analysis. It
focuses on addressing the limitations of manual annotation, bringing
standardisation to free-form text, and eliminating perspective bias amongst
different reviewers of subjective responses. A participatory mental health
study was conducted on 167 young adults bifurcated into two focus groups; one
of which was administered a conventional contextual inquiry, and the other via
ECHO, virtually. ECHO outperformed on participant transparency, response detail
and median time required for end-to-end inquiry completion, per participant.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07577" title="Abstract">arXiv:2312.07577</a> [<a href="/pdf/2312.07577" title="Download PDF">pdf</a>, <a href="/format/2312.07577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Distribution Shift in Tabular Data with TableShift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gardner%2C+J">Josh Gardner</a>, 
<a href="/search/cs?searchtype=author&query=Popovic%2C+Z">Zoran Popovic</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+L">Ludwig Schmidt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Dataset and Benchmarks Track accepted version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Robustness to distribution shift has become a growing concern for text and
image models as they transition from research subjects to deployment in the
real world. However, high-quality benchmarks for distribution shift in tabular
machine learning tasks are still lacking despite the widespread real-world use
of tabular data and differences in the models used for tabular data in
comparison to text and images. As a consequence, the robustness of tabular
models to distribution shift is poorly understood. To address this issue, we
introduce TableShift, a distribution shift benchmark for tabular data.
TableShift contains 15 binary classification tasks in total, each with an
associated shift, and includes a diverse set of data sources, prediction
targets, and distribution shifts. The benchmark covers domains including
finance, education, public policy, healthcare, and civic participation, and is
accessible using only a few lines of Python code via the TableShift API. We
conduct a large-scale study comparing several state-of-the-art tabular data
models alongside robust learning and domain generalization methods on the
benchmark tasks. Our study demonstrates (1) a linear trend between
in-distribution (ID) and out-of-distribution (OOD) accuracy; (2) domain
robustness methods can reduce shift gaps but at the cost of reduced ID
accuracy; (3) a strong relationship between shift gap (difference between ID
and OOD performance) and shifts in the label distribution.
<br />The benchmark data, Python package, model implementations, and more
information about TableShift are available at
https://github.com/mlfoundations/tableshift and https://tableshift.org .
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07579" title="Abstract">arXiv:2312.07579</a> [<a href="/pdf/2312.07579" title="Download PDF">pdf</a>, <a href="/format/2312.07579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross Fertilizing Empathy from Brain to Machine as a Value Alignment  Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gonier%2C+D">Devin Gonier</a>, 
<a href="/search/cs?searchtype=author&query=Adduci%2C+A">Adrian Adduci</a>, 
<a href="/search/cs?searchtype=author&query=LoCascio%2C+C">Cassidy LoCascio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">AI Alignment research seeks to align human and AI goals to ensure independent
actions by a machine are always ethical. This paper argues empathy is necessary
for this task, despite being often neglected in favor of more deductive
approaches. We offer an inside-out approach that grounds morality within the
context of the brain as a basis for algorithmically understanding ethics and
empathy. These arguments are justified via a survey of relevant literature. The
paper concludes with a suggested experimental approach to future research and
some initial experimental observations.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07582" title="Abstract">arXiv:2312.07582</a> [<a href="/pdf/2312.07582" title="Download PDF">pdf</a>, <a href="/format/2312.07582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Automated Support for the Co-Evolution of Meta-Models and  Grammars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weixing Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Blended modeling is an emerging paradigm involving seamless interaction
between multiple notations for the same underlying modeling language. We focus
on a model-driven engineering (MDE) approach based on meta-models to develop
textual languages to improve the blended modeling capabilities of modeling
tools. In this thesis, we propose an approach that can support the co-evolution
of meta-models and grammars as language engineers develop textual languages in
a meta-model-based MDE setting. Firstly, we comprehensively report on the
challenges and limitations of modeling tools that support blended modeling, as
well as opportunities to improve them. Second, we demonstrate how language
engineers can extend Xtext's generator capabilities according to their needs.
Third, we propose a semi-automatic method to transform a language with a
generated grammar into a Python-style language. Finally, we provide a solution
(i.e., GrammarOptimizer) that can support rapid prototyping of languages in
different styles and the co-evolution of meta-models and grammars of evolving
languages.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07583" title="Abstract">arXiv:2312.07583</a> [<a href="/pdf/2312.07583" title="Download PDF">pdf</a>, <a href="/format/2312.07583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification with Partially Private Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zeyu Shen</a>, 
<a href="/search/cs?searchtype=author&query=Krishnaswamy%2C+A">Anilesh Krishnaswamy</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+J">Janardhan Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Munagala%2C+K">Kamesh Munagala</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">In this paper, we consider differentially private classification when some
features are sensitive, while the rest of the features and the label are not.
We adapt the definition of differential privacy naturally to this setting. Our
main contribution is a novel adaptation of AdaBoost that is not only provably
differentially private, but also significantly outperforms a natural benchmark
that assumes the entire data of the individual is sensitive in the experiments.
As a surprising observation, we show that boosting randomly generated
classifiers suffices to achieve high accuracy. Our approach easily adapts to
the classical setting where all the features are sensitive, providing an
alternate algorithm for differentially private linear classification with a
much simpler privacy proof and comparable or higher accuracy than
differentially private logistic regression on real-world datasets.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07584" title="Abstract">arXiv:2312.07584</a> [<a href="/pdf/2312.07584" title="Download PDF">pdf</a>, <a href="/format/2312.07584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DFGET: Displacement-Field Assisted Graph Energy Transmitter for Gland  Instance Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jian%2C+C">Caiqing Jian</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yongbin Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lihui Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Gland instance segmentation is an essential but challenging task in the
diagnosis and treatment of adenocarcinoma. The existing models usually achieve
gland instance segmentation through multi-task learning and boundary loss
constraint. However, how to deal with the problems of gland adhesion and
inaccurate boundary in segmenting the complex samples remains a challenge. In
this work, we propose a displacement-field assisted graph energy transmitter
(DFGET) framework to solve these problems. Specifically, a novel message
passing manner based on anisotropic diffusion is developed to update the node
features, which can distinguish the isomorphic graphs and improve the
expressivity of graph nodes for complex samples. Using such graph framework,
the gland semantic segmentation map and the displacement field (DF) of the
graph nodes are estimated with two graph network branches. With the constraint
of DF, a graph cluster module based on diffusion theory is presented to improve
the intra-class feature consistency and inter-class feature discrepancy, as
well as to separate the adherent glands from the semantic segmentation maps.
Extensive comparison and ablation experiments on the GlaS dataset demonstrate
the superiority of DFGET and effectiveness of the proposed anisotropic message
passing manner and clustering method. Compared to the best comparative model,
DFGET increases the object-Dice and object-F1 score by 2.5% and 3.4%
respectively, while decreases the object-HD by 32.4%, achieving
state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07586" title="Abstract">arXiv:2312.07586</a> [<a href="/pdf/2312.07586" title="Download PDF">pdf</a>, <a href="/format/2312.07586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characteristic Guidance: Non-linear Correction for DDPM at Large  Guidance Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Candi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yuan Lan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">Popular guidance for denoising diffusion probabilistic model (DDPM) linearly
combines distinct conditional models together to provide enhanced control over
samples. However, this approach overlooks nonlinear effects that become
significant when guidance scale is large. To address this issue, we propose
characteristic guidance, a novel method that provides non-linear correction for
classifier-free guided DDPMs. Such correction forces the guided DDPMs to
respect the Fokker-Planck equation of their underlying diffusion process, in a
way that is first-principle, training-free, derivative-free, and compatible
with existing sampling methods. Experiments show that characteristic guidance
is robust to various applications, offers enhanced control over sample
generation, suppresses color and exposure issues even for latent space
sampling, and can handle physics problems such as the phase transitions.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07589" title="Abstract">arXiv:2312.07589</a> [<a href="/pdf/2312.07589" title="Download PDF">pdf</a>, <a href="/format/2312.07589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConvD: Attention Enhanced Dynamic Convolutional Embeddings for Knowledge  Graph Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wenbin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zirui Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Knowledge graphs generally suffer from incompleteness, which can be
alleviated by completing the missing information. Deep knowledge convolutional
embedding models based on neural networks are currently popular methods for
knowledge graph completion. However, most existing methods use external
convolution kernels and traditional plain convolution processes, which limits
the feature interaction capability of the model. In this paper, we propose a
novel dynamic convolutional embedding model ConvD for knowledge graph
completion, which directly reshapes the relation embeddings into multiple
internal convolution kernels to improve the external convolution kernels of the
traditional convolutional embedding model. The internal convolution kernels can
effectively augment the feature interaction between the relation embeddings and
entity embeddings, thus enhancing the model embedding performance. Moreover, we
design a priori knowledge-optimized attention mechanism, which can assign
different contribution weight coefficients to multiple relation convolution
kernels for dynamic convolution to improve the expressiveness of the model
further. Extensive experiments on various datasets show that our proposed model
consistently outperforms the state-of-the-art baseline methods, with average
improvements ranging from 11.30\% to 16.92\% across all model evaluation
metrics. Ablation experiments verify the effectiveness of each component module
of the ConvD model.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07592" title="Abstract">arXiv:2312.07592</a> [<a href="/pdf/2312.07592" title="Download PDF">pdf</a>, <a href="/format/2312.07592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating ChatGPT as a Question Answering System: A Comprehensive  Analysis and Comparison with Existing Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bahak%2C+H">Hossein Bahak</a>, 
<a href="/search/cs?searchtype=author&query=Taheri%2C+F">Farzaneh Taheri</a>, 
<a href="/search/cs?searchtype=author&query=Zojaji%2C+Z">Zahra Zojaji</a>, 
<a href="/search/cs?searchtype=author&query=Kazemi%2C+A">Arefeh Kazemi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the current era, a multitude of language models has emerged to cater to
user inquiries. Notably, the GPT-3.5 Turbo language model has gained
substantial attention as the underlying technology for ChatGPT. Leveraging
extensive parameters, this model adeptly responds to a wide range of questions.
However, due to its reliance on internal knowledge, the accuracy of responses
may not be absolute. This article scrutinizes ChatGPT as a Question Answering
System (QAS), comparing its performance to other existing QASs. The primary
focus is on evaluating ChatGPT's proficiency in extracting responses from
provided paragraphs, a core QAS capability. Additionally, performance
comparisons are made in scenarios without a surrounding passage. Multiple
experiments, exploring response hallucination and considering question
complexity, were conducted on ChatGPT. Evaluation employed well-known Question
Answering (QA) datasets, including SQuAD, NewsQA, and PersianQuAD, across
English and Persian languages. Metrics such as F-score, exact match, and
accuracy were employed in the assessment. The study reveals that, while ChatGPT
demonstrates competence as a generative model, it is less effective in question
answering compared to task-specific models. Providing context improves its
performance, and prompt engineering enhances precision, particularly for
questions lacking explicit answers in provided paragraphs. ChatGPT excels at
simpler factual questions compared to "how" and "why" question types. The
evaluation highlights occurrences of hallucinations, where ChatGPT provides
responses to questions without available answers in the provided context.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07594" title="Abstract">arXiv:2312.07594</a> [<a href="/pdf/2312.07594" title="Download PDF">pdf</a>, <a href="/ps/2312.07594" title="Download PostScript">ps</a>, <a href="/format/2312.07594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Prediction of Hardware Security Properties of HLS Designs Using  Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koufopoulou%2C+A+A">Amalia Artemis Koufopoulou</a>, 
<a href="/search/cs?searchtype=author&query=Papadimitriou%2C+A">Athanasios Papadimitriou</a>, 
<a href="/search/cs?searchtype=author&query=Pikrakis%2C+A">Aggelos Pikrakis</a>, 
<a href="/search/cs?searchtype=author&query=Psarakis%2C+M">Mihalis Psarakis</a>, 
<a href="/search/cs?searchtype=author&query=Hely%2C+D">David Hely</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures, 3 tables, submitted to 2023 IEEE International Symposium on Defect and Fault Tolerance in VLSI and Nanotechnology Systems (DFT)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">High-level synthesis (HLS) tools have provided significant productivity
enhancements to the design flow of digital systems in recent years, resulting
in highly-optimized circuits, in terms of area and latency. Given the evolution
of hardware attacks, which can render them vulnerable, it is essential to
consider security as a significant aspect of the HLS design flow. Yet the need
to evaluate a huge number of functionally equivalent de-signs of the HLS design
space challenges hardware security evaluation methods (e.g., fault injection -
FI campaigns). In this work, we propose an evaluation methodology of hardware
security properties of HLS-produced designs using state-of-the-art Graph Neural
Network (GNN) approaches that achieves significant speedup and better
scalability than typical evaluation methods (such as FI). We demonstrate the
proposed methodology on a Double Modular Redundancy (DMR) coun-termeasure
applied on an AES SBox implementation, en-hanced by diversifying the redundant
modules through HLS directives. The experimental results show that GNNs can be
efficiently trained to predict important hardware security met-rics concerning
fault attacks (e.g., critical and detection error rates), by using regression.
The proposed method predicts the fault vulnerability metrics of the HLS-based
designs with high R-squared scores and achieves huge speedup compared to fault
injection once the training of the GNN is completed.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07598" title="Abstract">arXiv:2312.07598</a> [<a href="/pdf/2312.07598" title="Download PDF">pdf</a>, <a href="/ps/2312.07598" title="Download PostScript">ps</a>, <a href="/format/2312.07598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differential Equation Approximations for Population Games using  Elementary Probability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kara%2C+S">Semih Kara</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+N+C">Nuno C. Martins</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA); Systems and Control (eess.SY); Dynamical Systems (math.DS); Probability (math.PR); Applications (stat.AP)

</div>
<p class="mathjax">Population games model the evolution of strategic interactions among a large
number of uniform agents. Due to the agents' uniformity and quantity, their
aggregate strategic choices can be approximated by the solutions of a class of
ordinary differential equations. This mean-field approach has found to be an
effective tool of analysis. However its current proofs rely on advanced
mathematical techniques, making them less accessible. In this article, we
present a simpler derivation, using only undergraduate-level probability.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07599" title="Abstract">arXiv:2312.07599</a> [<a href="/pdf/2312.07599" title="Download PDF">pdf</a>, <a href="/format/2312.07599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive News and Social Media Linking using BERT for Articles and  Tweets across Dual Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Piotrowski%2C+J">Jan Piotrowski</a>, 
<a href="/search/cs?searchtype=author&query=Wachnicki%2C+M">Marek Wachnicki</a>, 
<a href="/search/cs?searchtype=author&query=Perlik%2C+M">Mateusz Perlik</a>, 
<a href="/search/cs?searchtype=author&query=Podolak%2C+J">Jakub Podolak</a>, 
<a href="/search/cs?searchtype=author&query=Rucki%2C+G">Grzegorz Rucki</a>, 
<a href="/search/cs?searchtype=author&query=Brzozowski%2C+M">Micha&#x142; Brzozowski</a>, 
<a href="/search/cs?searchtype=author&query=Olejnik%2C+P">Pawe&#x142; Olejnik</a>, 
<a href="/search/cs?searchtype=author&query=Koz%C5%82owski%2C+J">Julian Koz&#x142;owski</a>, 
<a href="/search/cs?searchtype=author&query=Noco%C5%84%2C+T">Tomasz Noco&#x144;</a>, 
<a href="/search/cs?searchtype=author&query=Kozie%C5%82%2C+J">Jakub Kozie&#x142;</a>, 
<a href="/search/cs?searchtype=author&query=Gizi%C5%84ski%2C+S">Stanis&#x142;aw Gizi&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Sankowski%2C+P">Piotr Sankowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">X (formerly Twitter) has evolved into a contemporary agora, offering a
platform for individuals to express opinions and viewpoints on current events.
The majority of the topics discussed on Twitter are directly related to ongoing
events, making it an important source for monitoring public discourse. However,
linking tweets to specific news presents a significant challenge due to their
concise and informal nature. Previous approaches, including topic models,
graph-based models, and supervised classifiers, have fallen short in
effectively capturing the unique characteristics of tweets and articles.
<br />Inspired by the success of the CLIP model in computer vision, which employs
contrastive learning to model similarities between images and captions, this
paper introduces a contrastive learning approach for training a representation
space where linked articles and tweets exhibit proximity. We present our
contrastive learning approach, CATBERT (Contrastive Articles Tweets BERT),
leveraging pre-trained BERT models. The model is trained and tested on a
dataset containing manually labeled English and Polish tweets and articles
related to the Russian-Ukrainian war. We evaluate CATBERT's performance against
traditional approaches like LDA, and the novel method based on OpenAI
embeddings, which has not been previously applied to this task. Our findings
indicate that CATBERT demonstrates superior performance in associating tweets
with relevant news articles. Furthermore, we demonstrate the performance of the
models when applied to finding the main topic -- represented by an article --
of the whole cascade of tweets. In this new task, we report the performance of
the different models in dependence on the cascade size.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07603" title="Abstract">arXiv:2312.07603</a> [<a href="/pdf/2312.07603" title="Download PDF">pdf</a>, <a href="/format/2312.07603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cost Minimization for Equilibrium Transition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haoqiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhide Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the proceeding of AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">In this paper, we delve into the problem of using monetary incentives to
encourage players to shift from an initial Nash equilibrium to a more favorable
one within a game. Our main focus revolves around computing the minimum reward
required to facilitate this equilibrium transition. The game involves a single
row player who possesses $m$ strategies and $k$ column players, each endowed
with $n$ strategies. Our findings reveal that determining whether the minimum
reward is zero is NP-complete, and computing the minimum reward becomes
APX-hard. Nonetheless, we bring some positive news, as this problem can be
efficiently handled if either $k$ or $n$ is a fixed constant. Furthermore, we
have devised an approximation algorithm with an additive error that runs in
polynomial time. Lastly, we explore a specific case wherein the utility
functions exhibit single-peaked characteristics, and we successfully
demonstrate that the optimal reward can be computed in polynomial time.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07606" title="Abstract">arXiv:2312.07606</a> [<a href="/pdf/2312.07606" title="Download PDF">pdf</a>, <a href="/format/2312.07606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pedestrian and Passenger Interaction with Autonomous Vehicles: Field  Study in a Crosswalk Scenario
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Izquierdo%2C+R">Rub&#xe9;n Izquierdo</a>, 
<a href="/search/cs?searchtype=author&query=Alonso%2C+J">Javier Alonso</a>, 
<a href="/search/cs?searchtype=author&query=Benderius%2C+O">Ola Benderius</a>, 
<a href="/search/cs?searchtype=author&query=Sotelo%2C+M+%C3%81">Miguel &#xc1;ngel Sotelo</a>, 
<a href="/search/cs?searchtype=author&query=Llorca%2C+D+F">David Fern&#xe1;ndez Llorca</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the IEEE TIV; 13 pages, 13 figures, 7 tables. arXiv admin note: text overlap with <a href="/abs/2307.12708">arXiv:2307.12708</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">This study presents the outcomes of empirical investigations pertaining to
human-vehicle interactions involving an autonomous vehicle equipped with both
internal and external Human Machine Interfaces (HMIs) within a crosswalk
scenario. The internal and external HMIs were integrated with implicit
communication techniques, incorporating a combination of gentle and aggressive
braking maneuvers within the crosswalk. Data were collected through a
combination of questionnaires and quantifiable metrics, including pedestrian
decision to cross related to the vehicle distance and speed. The questionnaire
responses reveal that pedestrians experience enhanced safety perceptions when
the external HMI and gentle braking maneuvers are used in tandem. In contrast,
the measured variables demonstrate that the external HMI proves effective when
complemented by the gentle braking maneuver. Furthermore, the questionnaire
results highlight that the internal HMI enhances passenger confidence only when
paired with the aggressive braking maneuver.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07613" title="Abstract">arXiv:2312.07613</a> [<a href="/pdf/2312.07613" title="Download PDF">pdf</a>, <a href="/format/2312.07613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparison of Online Maneuvers by Authentic and Inauthentic Local News  Organizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lepird%2C+C+S">Christine Sowa Lepird</a>, 
<a href="/search/cs?searchtype=author&query=Carley%2C+K+M">Kathleen M. Carley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Inauthentic local news organizations, otherwise known as pink slime, have
become a serious problem exploiting the trust of local news since their
creation ahead of the 2020 U.S. Presidential election. In this paper, we apply
the BEND framework, a methodology of classifying social media posts as
belonging to sixteen network and narrative maneuvers, to compare and contrast
how pink slime sites and authentic local news sites are shared on Facebook
Pages. It finds that pink slime sites implemented more positive narrative
maneuvers than those of local news sharers. Both news types utilized
distraction but to fulfill separate goals - pink slime used it against local
and state elections while authentic local news focused on national elections
and figureheads. Furthermore, local news employed the neutralize tactic in
order to reduce positive sentiment around national politicians.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07615" title="Abstract">arXiv:2312.07615</a> [<a href="/pdf/2312.07615" title="Download PDF">pdf</a>, <a href="/format/2312.07615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Likelihood-free Inference using Self-supervised Neural  Symmetry Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+D">Deep Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Harris%2C+P+C">Philip C. Harris</a>, 
<a href="/search/cs?searchtype=author&query=Goel%2C+M">Maanas Goel</a>, 
<a href="/search/cs?searchtype=author&query=Desai%2C+M">Malina Desai</a>, 
<a href="/search/cs?searchtype=author&query=Coughlin%2C+M+W">Michael W. Coughlin</a>, 
<a href="/search/cs?searchtype=author&query=Katsavounidis%2C+E">Erik Katsavounidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for Machine Learning and the Physical Sciences Workshop (submission 69) at NeurIPS 2023; for codes, see <a href="https://github.com/ML4GW/summer-projects-2023/blob/neurips-2023/symmetry-informed-flows/README.md">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM)

</div>
<p class="mathjax">Likelihood-free inference is quickly emerging as a powerful tool to perform
fast/effective parameter estimation. We demonstrate a technique of optimizing
likelihood-free inference to make it even faster by marginalizing symmetries in
a physical problem. In this approach, physical symmetries, for example,
time-translation are learned using joint-embedding via self-supervised learning
with symmetry data augmentations. Subsequently, parameter inference is
performed using a normalizing flow where the embedding network is used to
summarize the data before conditioning the parameters. We present this approach
on two simple physical problems and we show faster convergence in a smaller
number of parameters compared to a normalizing flow that does not use a
pre-trained symmetry-informed representation.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07621" title="Abstract">arXiv:2312.07621</a> [<a href="/pdf/2312.07621" title="Download PDF">pdf</a>, <a href="/format/2312.07621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatiotemporal Event Graphs for Dynamic Scene Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Salman Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD thesis, Oxford Brookes University, Examiners: Prof. Dima Damen and Dr. Matthias Rolf, 183 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Dynamic scene understanding is the ability of a computer system to interpret
and make sense of the visual information present in a video of a real-world
scene. In this thesis, we present a series of frameworks for dynamic scene
understanding starting from road event detection from an autonomous driving
perspective to complex video activity detection, followed by continual learning
approaches for the life-long learning of the models. Firstly, we introduce the
ROad event Awareness Dataset (ROAD) for Autonomous Driving, to our knowledge
the first of its kind. Due to the lack of datasets equipped with formally
specified logical requirements, we also introduce the ROad event Awareness
Dataset with logical Requirements (ROAD-R), the first publicly available
dataset for autonomous driving with requirements expressed as logical
constraints, as a tool for driving neurosymbolic research in the area. Next, we
extend event detection to holistic scene understanding by proposing two complex
activity detection methods. In the first method, we present a deformable,
spatiotemporal scene graph approach, consisting of three main building blocks:
action tube detection, a 3D deformable RoI pooling layer designed for learning
the flexible, deformable geometry of the constituent action tubes, and a scene
graph constructed by considering all parts as nodes and connecting them based
on different semantics. In a second approach evolving from the first, we
propose a hybrid graph neural network that combines attention applied to a
graph encoding of the local (short-term) dynamic scene with a temporal graph
modelling the overall long-duration activity. Finally, the last part of the
thesis is about presenting a new continual semi-supervised learning (CSSL)
paradigm.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07622" title="Abstract">arXiv:2312.07622</a> [<a href="/pdf/2312.07622" title="Download PDF">pdf</a>, <a href="/format/2312.07622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mathematical Language Models: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wentao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hanglei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yuyang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junsong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+J">Jiayi Zeng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+M">Mengliang He</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A">Aimin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Liang He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/1705.04146">arXiv:1705.04146</a>, <a href="/abs/2304.10977">arXiv:2304.10977</a>, <a href="/abs/2112.00114">arXiv:2112.00114</a>, <a href="/abs/1905.13319">arXiv:1905.13319</a>, <a href="/abs/2304.12244">arXiv:2304.12244</a>, <a href="/abs/2206.01347">arXiv:2206.01347</a>, <a href="/abs/2006.09265">arXiv:2006.09265</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In recent years, there has been remarkable progress in leveraging Language
Models (LMs), encompassing Pre-trained Language Models (PLMs) and Large-scale
Language Models (LLMs), within the domain of mathematics. This paper conducts a
comprehensive survey of mathematical LMs, systematically categorizing pivotal
research endeavors from two distinct perspectives: tasks and methodologies. The
landscape reveals a large number of proposed mathematical LLMs, which are
further delineated into instruction learning, tool-based methods, fundamental
CoT techniques, and advanced CoT methodologies. In addition, our survey entails
the compilation of over 60 mathematical datasets, including training datasets,
benchmark datasets, and augmented datasets. Addressing the primary challenges
and delineating future trajectories within the field of mathematical LMs, this
survey is positioned as a valuable resource, poised to facilitate and inspire
future innovation among researchers invested in advancing this domain.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07623" title="Abstract">arXiv:2312.07623</a> [<a href="/pdf/2312.07623" title="Download PDF">pdf</a>, <a href="/ps/2312.07623" title="Download PostScript">ps</a>, <a href="/format/2312.07623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supervised Contrastive Learning for Fine-grained Chromosome Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+R">Ruijia Chang</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+S">Suncheng Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chengyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+K">Kui Su</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+D">Dahong Qian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Chromosome recognition is an essential task in karyotyping, which plays a
vital role in birth defect diagnosis and biomedical research. However, existing
classification methods face significant challenges due to the inter-class
similarity and intra-class variation of chromosomes. To address this issue, we
propose a supervised contrastive learning strategy that is tailored to train
model-agnostic deep networks for reliable chromosome classification. This
method enables extracting fine-grained chromosomal embeddings in latent space.
These embeddings effectively expand inter-class boundaries and reduce
intra-class variations, enhancing their distinctiveness in predicting
chromosome types. On top of two large-scale chromosome datasets, we
comprehensively validate the power of our contrastive learning strategy in
boosting cutting-edge deep networks such as Transformers and ResNets. Extensive
results demonstrate that it can significantly improve models' generalization
performance, with an accuracy improvement up to +4.5%. Codes and pretrained
models will be released upon acceptance of this work.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07624" title="Abstract">arXiv:2312.07624</a> [<a href="/pdf/2312.07624" title="Download PDF">pdf</a>, <a href="/format/2312.07624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Proximal Policy Optimization with Upper Confidence Bound
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jingzehua Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Z">Zifeng Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=wang%2C+D">Donglin wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Trust Region Policy Optimization (TRPO) attractively optimizes the policy
while constraining the update of the new policy within a trust region, ensuring
the stability and monotonic optimization. Building on the theoretical
guarantees of trust region optimization, Proximal Policy Optimization (PPO)
successfully enhances the algorithm's sample efficiency and reduces deployment
complexity by confining the update of the new and old policies within a
surrogate trust region. However, this approach is limited by the fixed setting
of surrogate trust region and is not sufficiently adaptive, because there is no
theoretical proof that the optimal clipping bound remains consistent throughout
the entire training process, truncating the ratio of the new and old policies
within surrogate trust region can ensure that the algorithm achieves its best
performance, therefore, exploring and researching a dynamic clip bound for
improving PPO's performance can be quite beneficial. To design an adaptive
clipped trust region and explore the dynamic clip bound's impact on the
performance of PPO, we introduce an adaptive PPO-CLIP (Adaptive-PPO) method
that dynamically explores and exploits the clip bound using a bandit during the
online training process. Furthermore, ample experiments will initially
demonstrate that our Adaptive-PPO exhibits sample efficiency and performance
compared to PPO-CLIP.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07625" title="Abstract">arXiv:2312.07625</a> [<a href="/pdf/2312.07625" title="Download PDF">pdf</a>, <a href="/format/2312.07625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Astrocyte-Enabled Advancements in Spiking Neural Networks for Large  Language Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+G">Guobin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongcheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yiting Dong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jindong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yi Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Within the complex neuroarchitecture of the brain, astrocytes play crucial
roles in development, structure, and metabolism. These cells regulate neural
activity through tripartite synapses, directly impacting cognitive processes
such as learning and memory. Despite the growing recognition of astrocytes'
significance, traditional Spiking Neural Network (SNN) models remain
predominantly neuron-centric, overlooking the profound influence of astrocytes
on neural dynamics. Inspired by these biological insights, we have developed an
Astrocyte-Modulated Spiking Unit (AM-SU), an innovative framework that
integrates neuron-astrocyte interactions into the computational paradigm,
demonstrating wide applicability across various hardware platforms. Our
Astrocyte-Modulated Spiking Neural Network (AM-SNet) exhibits exceptional
performance in tasks involving memory retention and natural language
generation, particularly in handling long-term dependencies and complex
linguistic structures. The design of AM-SNet not only enhances its biological
authenticity but also introduces novel computational dynamics, enabling more
effective processing of complex temporal dependencies. Furthermore, AM-SNet
shows low latency, high throughput, and reduced memory usage in practical
applications, making it highly suitable for resource-constrained environments.
By successfully integrating astrocytic dynamics into intelligent neural
networks, our work narrows the gap between biological plausibility and neural
modeling, laying the groundwork for future biologically-inspired neural
computing research that includes both neurons and astrocytes.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07627" title="Abstract">arXiv:2312.07627</a> [<a href="/pdf/2312.07627" title="Download PDF">pdf</a>, <a href="/ps/2312.07627" title="Download PostScript">ps</a>, <a href="/format/2312.07627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Sentiment Analysis: Perceived vs Induced Sentiments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+A">Aditi Aggarwal</a>, 
<a href="/search/cs?searchtype=author&query=Varshney%2C+D">Deepika Varshney</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+S">Saurabh Patel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Social media has created a global network where people can easily access and
exchange vast information. This information gives rise to a variety of
opinions, reflecting both positive and negative viewpoints. GIFs stand out as a
multimedia format offering a visually engaging way for users to communicate. In
this research, we propose a multimodal framework that integrates visual and
textual features to predict the GIF sentiment. It also incorporates attributes
including face emotion detection and OCR generated captions to capture the
semantic aspects of the GIF. The developed classifier achieves an accuracy of
82.7% on Twitter GIFs, which is an improvement over state-of-the-art models.
Moreover, we have based our research on the ReactionGIF dataset, analysing the
variance in sentiment perceived by the author and sentiment induced in the
reader
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07628" title="Abstract">arXiv:2312.07628</a> [<a href="/pdf/2312.07628" title="Download PDF">pdf</a>, <a href="/format/2312.07628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding a Cluster in Incomplete Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eiben%2C+E">Eduard Eiben</a>, 
<a href="/search/cs?searchtype=author&query=Ganian%2C+R">Robert Ganian</a>, 
<a href="/search/cs?searchtype=author&query=Kanj%2C+I">Iyad Kanj</a>, 
<a href="/search/cs?searchtype=author&query=Ordyniak%2C+S">Sebastian Ordyniak</a>, 
<a href="/search/cs?searchtype=author&query=Szeider%2C+S">Stefan Szeider</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Short version appeared at ESA 2022. arXiv admin note: substantial text overlap with <a href="/abs/1911.01465">arXiv:1911.01465</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study two variants of the fundamental problem of finding a cluster in
incomplete data. In the problems under consideration, we are given a multiset
of incomplete $d$-dimensional vectors over the binary domain and integers $k$
and $r$, and the goal is to complete the missing vector entries so that the
multiset of complete vectors either contains (i) a cluster of $k$ vectors of
radius at most $r$, or (ii) a cluster of $k$ vectors of diameter at most $r$.
We give tight characterizations of the parameterized complexity of the problems
under consideration with respect to the parameters $k$, $r$, and a third
parameter that captures the missing vector entries.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07630" title="Abstract">arXiv:2312.07630</a> [<a href="/pdf/2312.07630" title="Download PDF">pdf</a>, <a href="/format/2312.07630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-trained Universal Medical Image Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Lingxiao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuanzhong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+B">Bingda Tang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinsheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chengpeng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yujiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+R">Rong Han</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Ting Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Self-supervised learning has emerged as a viable method to leverage the
abundance of unlabeled medical imaging data, addressing the challenge of
labeled data scarcity in medical image analysis. In particular, masked image
modeling (MIM) with visual token reconstruction has shown promising results in
the general computer vision (CV) domain and serves as a candidate for medical
image analysis. However, the presence of heterogeneous 2D and 3D medical images
often limits the volume and diversity of training data that can be effectively
used for a single model structure. In this work, we propose a spatially
adaptive convolution (SAC) module, which adaptively adjusts convolution
parameters based on the voxel spacing of the input images. Employing this SAC
module, we build a universal visual tokenizer and a universal Vision
Transformer (ViT) capable of effectively processing a wide range of medical
images with various imaging modalities and spatial properties. Moreover, in
order to enhance the robustness of the visual tokenizer's reconstruction
objective for MIM, we suggest to generalize the discrete token output of the
visual tokenizer to a probabilistic soft token. We show that the generalized
soft token representation can be effectively integrated with the prior
distribution regularization through a constructive interpretation. As a result,
we pre-train a universal visual tokenizer followed by a universal ViT via
visual token reconstruction on 55 public medical image datasets, comprising
over 9 million 2D slices (including over 48,000 3D images). This represents the
largest, most comprehensive, and diverse dataset for pre-training 3D medical
image models to our knowledge. Experimental results on downstream medical image
classification and segmentation tasks demonstrate the superior performance of
our model and improved label efficiency.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07632" title="Abstract">arXiv:2312.07632</a> [<a href="/pdf/2312.07632" title="Download PDF">pdf</a>, <a href="/ps/2312.07632" title="Download PostScript">ps</a>, <a href="/format/2312.07632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximizing Social Welfare in Score-Based Social Distance Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ganian%2C+R">Robert Ganian</a>, 
<a href="/search/cs?searchtype=author&query=Hamm%2C+T">Thekla Hamm</a>, 
<a href="/search/cs?searchtype=author&query=Knop%2C+D">Du&#x161;an Knop</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+S">Sanjukta Roy</a>, 
<a href="/search/cs?searchtype=author&query=Schierreich%2C+%C5%A0">&#x160;imon Schierreich</a>, 
<a href="/search/cs?searchtype=author&query=Such%C3%BD%2C+O">Ond&#x159;ej Such&#xfd;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Short version appeared at TARK 2023. arXiv admin note: substantial text overlap with <a href="/abs/2307.05061">arXiv:2307.05061</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Social distance games have been extensively studied as a coalition formation
model where the utilities of agents in each coalition were captured using a
utility function $u$ that took into account distances in a given social
network. In this paper, we consider a non-normalized score-based definition of
social distance games where the utility function $u^s$ depends on a generic
scoring vector $s$, which may be customized to match the specifics of each
individual application scenario.
<br />As our main technical contribution, we establish the tractability of
computing a welfare-maximizing partitioning of the agents into coalitions on
tree-like networks, for every score-based function $u^s$. We provide more
efficient algorithms when dealing with specific choices of $u^s$ or simpler
networks, and also extend all of these results to computing coalitions that are
Nash stable or individually rational. We view these results as a further strong
indication of the usefulness of the proposed score-based utility function: even
on very simple networks, the problem of computing a welfare-maximizing
partitioning into coalitions remains open for the originally considered
canonical function $u$.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07633" title="Abstract">arXiv:2312.07633</a> [<a href="/pdf/2312.07633" title="Download PDF">pdf</a>, <a href="/format/2312.07633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SE(3)-Invariant Multiparameter Persistent Homology for Chiral-Sensitive  Molecular Property Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Demir%2C+A">Andac Demir</a>, 
<a href="/search/cs?searchtype=author&query=Prael%2C+F">Francis Prael III</a>, 
<a href="/search/cs?searchtype=author&query=Kiziltan%2C+B">Bulent Kiziltan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 AI for Science Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Geometry (cs.CG); Algebraic Topology (math.AT)

</div>
<p class="mathjax">In this study, we present a novel computational method for generating
molecular fingerprints using multiparameter persistent homology (MPPH). This
technique holds considerable significance for drug discovery and materials
science, where precise molecular property prediction is vital. By integrating
SE(3)-invariance with Vietoris-Rips persistent homology, we effectively capture
the three-dimensional representations of molecular chirality. This
non-superimposable mirror image property directly influences the molecular
interactions, serving as an essential factor in molecular property prediction.
We explore the underlying topologies and patterns in molecular structures by
applying Vietoris-Rips persistent homology across varying scales and parameters
such as atomic weight, partial charge, bond type, and chirality. Our method's
efficacy can be improved by incorporating additional parameters such as
aromaticity, orbital hybridization, bond polarity, conjugated systems, as well
as bond and torsion angles. Additionally, we leverage Stochastic Gradient
Langevin Boosting in a Bayesian ensemble of GBDTs to obtain aleatoric and
epistemic uncertainty estimates for gradient boosting models. With these
uncertainty estimates, we prioritize high-uncertainty samples for active
learning and model fine-tuning, benefiting scenarios where data labeling is
costly or time consuming. Compared to conventional GNNs which usually suffer
from oversmoothing and oversquashing, MPPH provides a more comprehensive and
interpretable characterization of molecular data topology. We substantiate our
approach with theoretical stability guarantees and demonstrate its superior
performance over existing state-of-the-art methods in predicting molecular
properties through extensive evaluations on the MoleculeNet benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07635" title="Abstract">arXiv:2312.07635</a> [<a href="/pdf/2312.07635" title="Download PDF">pdf</a>, <a href="/format/2312.07635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clash of the Explainers: Argumentation for Context-Appropriate  Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Methnani%2C+L">Leila Methnani</a>, 
<a href="/search/cs?searchtype=author&query=Dignum%2C+V">Virginia Dignum</a>, 
<a href="/search/cs?searchtype=author&query=Theodorou%2C+A">Andreas Theodorou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 3 figures, Accepted at XAI^3 Workshop at ECAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Understanding when and why to apply any given eXplainable Artificial
Intelligence (XAI) technique is not a straightforward task. There is no single
approach that is best suited for a given context. This paper aims to address
the challenge of selecting the most appropriate explainer given the context in
which an explanation is required. For AI explainability to be effective,
explanations and how they are presented needs to be oriented towards the
stakeholder receiving the explanation. If -- in general -- no single
explanation technique surpasses the rest, then reasoning over the available
methods is required in order to select one that is context-appropriate. Due to
the transparency they afford, we propose employing argumentation techniques to
reach an agreement over the most suitable explainers from a given set of
possible explainers.
<br />In this paper, we propose a modular reasoning system consisting of a given
mental model of the relevant stakeholder, a reasoner component that solves the
argumentation problem generated by a multi-explainer component, and an AI model
that is to be explained suitably to the stakeholder of interest. By formalising
supporting premises -- and inferences -- we can map stakeholder characteristics
to those of explanation techniques. This allows us to reason over the
techniques and prioritise the best one for the given context, while also
offering transparency into the selection decision.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07636" title="Abstract">arXiv:2312.07636</a> [<a href="/pdf/2312.07636" title="Download PDF">pdf</a>, <a href="/format/2312.07636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Go beyond End-to-End Training: Boosting Greedy Local Learning with  Context Supply
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chengting Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fengzhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Hanzhi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Aili Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+E">Erping Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 figures, 12 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
<p class="mathjax">Traditional end-to-end (E2E) training of deep networks necessitates storing
intermediate activations for back-propagation, resulting in a large memory
footprint on GPUs and restricted model parallelization. As an alternative,
greedy local learning partitions the network into gradient-isolated modules and
trains supervisely based on local preliminary losses, thereby providing
asynchronous and parallel training methods that substantially reduce memory
cost. However, empirical experiments reveal that as the number of segmentations
of the gradient-isolated module increases, the performance of the local
learning scheme degrades substantially, severely limiting its expansibility. To
avoid this issue, we theoretically analyze the greedy local learning from the
standpoint of information theory and propose a ContSup scheme, which
incorporates context supply between isolated modules to compensate for
information loss. Experiments on benchmark datasets (i.e. CIFAR, SVHN, STL-10)
achieve SOTA results and indicate that our proposed method can significantly
improve the performance of greedy local learning with minimal memory and
computational overhead, allowing for the boost of the number of isolated
modules. Our codes are available at https://github.com/Tab-ct/ContSup.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07637" title="Abstract">arXiv:2312.07637</a> [<a href="/pdf/2312.07637" title="Download PDF">pdf</a>, <a href="/format/2312.07637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Responsibility in Extensive Form Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Q">Qi Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 38th Annual AAAI Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Two different forms of responsibility, counterfactual and seeing-to-it, have
been extensively discussed in the philosophy and AI in the context of a single
agent or multiple agents acting simultaneously. Although the generalisation of
counterfactual responsibility to a setting where multiple agents act in some
order is relatively straightforward, the same cannot be said about seeing-to-it
responsibility. Two versions of seeing-to-it modality applicable to such
settings have been proposed in the literature. Neither of them perfectly
captures the intuition of responsibility. This paper proposes a definition of
seeing-to-it responsibility for such settings that amalgamate the two
modalities.
<br />This paper shows that the newly proposed notion of responsibility and
counterfactual responsibility are not definable through each other and studies
the responsibility gap for these two forms of responsibility. It shows that
although these two forms of responsibility are not enough to ascribe
responsibility in each possible situation, this gap does not exist if
higher-order responsibility is taken into account.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07638" title="Abstract">arXiv:2312.07638</a> [<a href="/pdf/2312.07638" title="Download PDF">pdf</a>, <a href="/format/2312.07638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teaching Unknown Objects by Leveraging Human Gaze and Augmented Reality  in Human-Robot Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weber%2C+D">Daniel Weber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD Thesis, University of T\"ubingen
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
<p class="mathjax">Robots are becoming increasingly popular in a wide range of environments due
to their exceptional work capacity, precision, efficiency, and scalability.
This development has been further encouraged by advances in Artificial
Intelligence, particularly Machine Learning. By employing sophisticated neural
networks, robots are given the ability to detect and interact with objects in
their vicinity. However, a significant drawback arises from the underlying
dependency on extensive datasets and the availability of substantial amounts of
training data for these object detection models. This issue becomes
particularly problematic when the specific deployment location of the robot and
the surroundings, are not known in advance. The vast and ever-expanding array
of objects makes it virtually impossible to comprehensively cover the entire
spectrum of existing objects using preexisting datasets alone. The goal of this
dissertation was to teach a robot unknown objects in the context of Human-Robot
Interaction (HRI) in order to liberate it from its data dependency, unleashing
it from predefined scenarios. In this context, the combination of eye tracking
and Augmented Reality created a powerful synergy that empowered the human
teacher to communicate with the robot and effortlessly point out objects by
means of human gaze. This holistic approach led to the development of a
multimodal HRI system that enabled the robot to identify and visually segment
the Objects of Interest in 3D space. Through the class information provided by
the human, the robot was able to learn the objects and redetect them at a later
stage. Due to the knowledge gained from this HRI based teaching, the robot's
object detection capabilities exhibited comparable performance to
state-of-the-art object detectors trained on extensive datasets, without being
restricted to predefined classes, showcasing its versatility and adaptability.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07640" title="Abstract">arXiv:2312.07640</a> [<a href="/pdf/2312.07640" title="Download PDF">pdf</a>, <a href="/format/2312.07640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi Armed Bandit based Resource Allocation in Near Memory Processing  Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pandey%2C+S">Shubhang Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Venkatesh%2C+T+G">T G Venkatesh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Recent advances in 3D fabrication have allowed handling the memory
bottlenecks for modern data-intensive applications by bringing the computation
closer to the memory, enabling Near Memory Processing (NMP). Memory Centric
Networks (MCN) are advanced memory architectures that use NMP architectures,
where multiple stacks of the 3D memory units are equipped with simple
processing cores, allowing numerous threads to execute concurrently. The
performance of the NMP is crucially dependent upon the efficient task
offloading and task-to-NMP allocation. Our work presents a multi-armed bandit
(MAB) based approach in formulating an efficient resource allocation strategy
for MCN. Most existing literature concentrates only on one application domain
and optimizing only one metric, i.e., either execution time or power. However,
our solution is more generic and can be applied to diverse application domains.
In our approach, we deploy Upper Confidence Bound (UCB) policy to collect
rewards and eventually use it for regret optimization. We study the following
metrics: instructions per cycle, execution times, NMP core cache misses, packet
latencies, and power consumption. Our study covers various applications from
PARSEC and SPLASH2 benchmarks suite. The evaluation shows that the system's
performance improves by ~11% on average and an average reduction in total power
consumption by ~12%.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07641" title="Abstract">arXiv:2312.07641</a> [<a href="/pdf/2312.07641" title="Download PDF">pdf</a>, <a href="/ps/2312.07641" title="Download PostScript">ps</a>, <a href="/format/2312.07641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Crypto-Ransomware
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kotov%2C+V">Vadim Kotov</a>, 
<a href="/search/cs?searchtype=author&query=Rajpal%2C+M">Mantej Rajpal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Crypto-Ransomware has been increasing in sophistication since it first
appeared in September 2013, leveraging new attack vectors, incorporating
advanced encryption algorithms, and expanding the number of file types it
targets. In this report, we dissect nearly 30 samples of ransomware variants
that have been encountered since September 2013, revealing a trend of
increasing sophistication.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07644" title="Abstract">arXiv:2312.07644</a> [<a href="/pdf/2312.07644" title="Download PDF">pdf</a>, <a href="/format/2312.07644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximation algorithms for k-median problems on complex networks:  theory and practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pozo%2C+R">Roldan Pozo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Finding the k-medianin a network involves identifying a subset of k vertices
that minimize the total distance to all other vertices in a graph. This problem
has been extensively studied in computer science, graph theory, operations
research, and numerous areas due to its significance in a wide range of
applications. While known to be computationally challenging (NP-hard) several
approximation algorithms have been proposed, most with high-order
polynomial-time complexity. However, the graph topology of complex networks
with heavy-tailed degree distributions present characteristics that can be
exploited to yield custom-tailored algorithms. We compare eight algorithms
specifically designed for complex networks and evaluate their performance based
on accuracy and efficiency for problems of varying sizes and application areas.
Rather than relying on a small number of problems, we conduct over 16,000
experiments covering a wide range of network sizes and k-median{} values. While
individual results vary, a few methods provide consistently good results. We
draw general conclusions about how algorithms perform in practice and provide
general guidelines for solutions.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07661" title="Abstract">arXiv:2312.07661</a> [<a href="/pdf/2312.07661" title="Download PDF">pdf</a>, <a href="/format/2312.07661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIP as RNN: Segment Countless Visual Concepts without Training Endeavor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shuyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Runjia Li</a>, 
<a href="/search/cs?searchtype=author&query=Torr%2C+P">Philip Torr</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+X">Xiuye Gu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Siyang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://torrvision.com/clip_as_rnn/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">Existing open-vocabulary image segmentation methods require a fine-tuning
step on mask annotations and/or image-text datasets. Mask labels are
labor-intensive, which limits the number of categories in segmentation
datasets. As a result, the open-vocabulary capacity of pre-trained VLMs is
severely reduced after fine-tuning. However, without fine-tuning, VLMs trained
under weak image-text supervision tend to make suboptimal mask predictions when
there are text queries referring to non-existing concepts in the image. To
alleviate these issues, we introduce a novel recurrent framework that
progressively filters out irrelevant texts and enhances mask quality without
training efforts. The recurrent unit is a two-stage segmenter built upon a VLM
with frozen weights. Thus, our model retains the VLM's broad vocabulary space
and strengthens its segmentation capability. Experimental results show that our
method outperforms not only the training-free counterparts, but also those
fine-tuned with millions of additional data samples, and sets new
state-of-the-art records for both zero-shot semantic and referring image
segmentation tasks. Specifically, we improve the current record by 28.8, 16.0,
and 6.9 mIoU on Pascal VOC, COCO Object, and Pascal Context.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07669" title="Abstract">arXiv:2312.07669</a> [<a href="/pdf/2312.07669" title="Download PDF">pdf</a>, <a href="/format/2312.07669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GMTalker: Gaussian Mixture based Emotional talking video Portraits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yibo Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lizhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+X">Xiang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiaoyan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yebin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://bob35buaa.github.io/GMTalker">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Synthesizing high-fidelity and emotion-controllable talking video portraits,
with audio-lip sync, vivid expression, realistic head pose, and eye blink, is
an important and challenging task in recent years. Most of the existing methods
suffer in achieving personalized precise emotion control or continuously
interpolating between different emotions and generating diverse motion. To
address these problems, we present GMTalker, a Gaussian mixture based emotional
talking portraits generation framework. Specifically, we propose a Gaussian
Mixture based Expression Generator (GMEG) which can construct a continuous and
multi-modal latent space, achieving more flexible emotion manipulation.
Furthermore, we introduce a normalizing flow based motion generator pretrained
on the dataset with a wide-range motion to generate diverse motions. Finally,
we propose a personalized emotion-guided head generator with an Emotion Mapping
Network (EMN) which can synthesize high-fidelity and faithful emotional video
portraits. Both quantitative and qualitative experiments demonstrate our method
outperforms previous methods in image quality, photo-realism, emotion accuracy
and motion diversity.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07671" title="Abstract">arXiv:2312.07671</a> [<a href="/pdf/2312.07671" title="Download PDF">pdf</a>, <a href="/ps/2312.07671" title="Download PostScript">ps</a>, <a href="/format/2312.07671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reacting like Humans: Incorporating Intrinsic Human Behaviors into NAO  through Sound-Based Reactions for Enhanced Sociability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghadami%2C+A">Ali Ghadami</a>, 
<a href="/search/cs?searchtype=author&query=Taghimohammadi%2C+M">Mohammadreza Taghimohammadi</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadzadeh%2C+M">Mohammad Mohammadzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Hosseinipour%2C+M">Mohammad Hosseinipour</a>, 
<a href="/search/cs?searchtype=author&query=Taheri%2C+A">Alireza Taheri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Robots' acceptability among humans and their sociability can be significantly
enhanced by incorporating human-like reactions. Humans can react to
environmental events very quickly and without thinking. An instance where
humans display natural reactions is when they encounter a sudden and loud sound
that startles or frightens them. During such moments, individuals may
instinctively move their hands, turn toward the origin of the sound, and try to
determine the event's cause. This inherent behavior motivated us to explore
this less-studied part of social robotics. In this work, a multi-modal system
composed of an action generator, sound classifier, and YOLO object detector was
designed to sense the environment and, in the presence of sudden loud sounds,
show natural human fear reactions, and finally, locate the fear-causing sound
source in the environment. These unique and valid generated motions and
inferences could imitate intrinsic human reactions and enhance the sociability
of robots. For motion generation, a model based on LSTM and MDN networks was
proposed to synthesize various motions. Also, in the case of sound detection, a
transfer learning model was preferred that used the spectrogram of sound
signals as its input. After developing individual models for sound detection,
motion generation, and image recognition, they were integrated into a
comprehensive fear module that was implemented on the NAO robot. Finally, the
fear module was tested in practical application and two groups of experts and
non-experts filled out a questionnaire to evaluate the performance of the
robot. Given our promising results, this preliminary exploratory research
provides a fresh perspective on social robotics and could be a starting point
for modeling intrinsic human behaviors and emotions in robots.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07679" title="Abstract">arXiv:2312.07679</a> [<a href="/pdf/2312.07679" title="Download PDF">pdf</a>, <a href="/format/2312.07679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Online Learning for Consensus Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Showalter%2C+S">Sam Showalter</a>, 
<a href="/search/cs?searchtype=author&query=Boyd%2C+A">Alex Boyd</a>, 
<a href="/search/cs?searchtype=author&query=Smyth%2C+P">Padhraic Smyth</a>, 
<a href="/search/cs?searchtype=author&query=Steyvers%2C+M">Mark Steyvers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Given a pre-trained classifier and multiple human experts, we investigate the
task of online classification where model predictions are provided for free but
querying humans incurs a cost. In this practical but under-explored setting,
oracle ground truth is not available. Instead, the prediction target is defined
as the consensus vote of all experts. Given that querying full consensus can be
costly, we propose a general framework for online Bayesian consensus
estimation, leveraging properties of the multivariate hypergeometric
distribution. Based on this framework, we propose a family of methods that
dynamically estimate expert consensus from partial feedback by producing a
posterior over expert and model beliefs. Analyzing this posterior induces an
interpretable trade-off between querying cost and classification performance.
We demonstrate the efficacy of our framework against a variety of baselines on
CIFAR-10H and ImageNet-16H, two large-scale crowdsourced datasets.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07680" title="Abstract">arXiv:2312.07680</a> [<a href="/pdf/2312.07680" title="Download PDF">pdf</a>, <a href="/format/2312.07680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> I Open at the Close: A Deep Reinforcement Learning Evaluation of Open  Streets Initiatives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Witter%2C+R+T">R. Teal Witter</a>, 
<a href="/search/cs?searchtype=author&query=Rosenblatt%2C+L">Lucas Rosenblatt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> camera ready for AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">The open streets initiative "opens" streets to pedestrians and bicyclists by
closing them to cars and trucks. The initiative, adopted by many cities across
North America, increases community space in urban environments. But could open
streets also make cities safer and less congested? We study this question by
framing the choice of which streets to open as a reinforcement learning
problem. In order to simulate the impact of opening streets, we first compare
models for predicting vehicle collisions given network and temporal data. We
find that a recurrent graph neural network, leveraging the graph structure and
the short-term temporal dependence of the data, gives the best predictive
performance. Then, with the ability to simulate collisions and traffic, we
frame a reinforcement learning problem to find which streets to open. We
compare the streets in the NYC Open Streets program to those proposed by a
Q-learning algorithm. We find that the streets proposed by the Q-learning
algorithm have reliably better outcomes, while streets in the program have
similar outcomes to randomly selected streets. We present our work as a step
toward principally choosing which streets to open for safer and less congested
cities. All our code and data are available on Github.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07681" title="Abstract">arXiv:2312.07681</a> [<a href="/pdf/2312.07681" title="Download PDF">pdf</a>, <a href="/format/2312.07681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Note on Local Convergence of Iterative Processes for Pipe Network  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luu%2C+H">Huong Luu</a>, 
<a href="/search/cs?searchtype=author&query=Chrobak%2C+M">Marek Chrobak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Analysis of pipe networks involves computing flow rates and pressure
differences on pipe segments in the network, given the external inflow/outflow
values. This analysis can be conducted using iterative methods, among which the
algorithms of Hardy Cross and Newton-Raphson have historically been applied in
practice. In this note, we address the mathematical analysis of the local
convergence of these algorithms. The loop-based Newton-Raphson algorithm
converges quadratically fast, and we provide estimates for its convergence
radius to correct some estimates in the previous literature. In contrast, we
show that the convergence of the Hardy Cross algorithm is only linear. This
provides theoretical confirmation of experimental observations reported earlier
in the literature.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07682" title="Abstract">arXiv:2312.07682</a> [<a href="/pdf/2312.07682" title="Download PDF">pdf</a>, <a href="/format/2312.07682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Online, Adaptive and Unsupervised Regression Framework with Drift  Detection for Label Scarcity Contexts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Richard%2C+R">Rene Richard</a>, 
<a href="/search/cs?searchtype=author&query=Belacel%2C+N">Nabil Belacel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 25 figures, European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECMLPKDD) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In scenarios where obtaining real-time labels proves challenging,
conventional approaches may result in sub-optimal performance. This paper
presents an optimal strategy for streaming contexts with limited labeled data,
introducing an adaptive technique for unsupervised regression. The proposed
method leverages a sparse set of initial labels and introduces an innovative
drift detection mechanism to enable dynamic model adaptations in response to
evolving patterns in the data. To enhance adaptability, we integrate the ADWIN
(ADaptive WINdowing) algorithm with error generalization based on Root Mean
Square Error (RMSE). ADWIN facilitates real-time drift detection, while RMSE
provides a robust measure of model prediction accuracy. This combination
enables our multivariate method to effectively navigate the challenges of
streaming data, continuously adapting to changing patterns while maintaining a
high level of predictive precision. Finally, we evaluate the performance of our
multivariate method across various public datasets, comparing it to
non-adapting baselines. Through comprehensive assessments, we demonstrate the
superior efficacy of our adaptive regression technique for tasks where
obtaining labels in real-time is a significant challenge. The results
underscore the method's capacity to outperform traditional approaches and
highlight its potential in scenarios characterized by label scarcity and
evolving data patterns.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07685" title="Abstract">arXiv:2312.07685</a> [<a href="/pdf/2312.07685" title="Download PDF">pdf</a>, <a href="/format/2312.07685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Perspective of Q-value Estimation on Offline-to-Online Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yinmin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chuming Li</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yazhe Niu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yaodong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Offline-to-online Reinforcement Learning (O2O RL) aims to improve the
performance of offline pretrained policy using only a few online samples. Built
on offline RL algorithms, most O2O methods focus on the balance between RL
objective and pessimism, or the utilization of offline and online samples. In
this paper, from a novel perspective, we systematically study the challenges
that remain in O2O RL and identify that the reason behind the slow improvement
of the performance and the instability of online finetuning lies in the
inaccurate Q-value estimation inherited from offline pretraining. Specifically,
we demonstrate that the estimation bias and the inaccurate rank of Q-value
cause a misleading signal for the policy update, making the standard offline RL
algorithms, such as CQL and TD3-BC, ineffective in the online finetuning. Based
on this observation, we address the problem of Q-value estimation by two
techniques: (1) perturbed value update and (2) increased frequency of Q-value
updates. The first technique smooths out biased Q-value estimation with sharp
peaks, preventing early-stage policy exploitation of sub-optimal actions. The
second one alleviates the estimation bias inherited from offline pretraining by
accelerating learning. Extensive experiments on the MuJoco and Adroit
environments demonstrate that the proposed method, named SO2, significantly
alleviates Q-value estimation issues, and consistently improves the performance
against the state-of-the-art methods by up to 83.1%.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07693" title="Abstract">arXiv:2312.07693</a> [<a href="/pdf/2312.07693" title="Download PDF">pdf</a>, <a href="/ps/2312.07693" title="Download PostScript">ps</a>, <a href="/format/2312.07693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Culture in Blockchain Gaming: Generative AI and Pseudonymous  Engagement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Axelsen%2C+H">Henrik Axelsen</a>, 
<a href="/search/cs?searchtype=author&query=Axelsen%2C+S">Sebastian Axelsen</a>, 
<a href="/search/cs?searchtype=author&query=Licht%2C+V">Valdemar Licht</a>, 
<a href="/search/cs?searchtype=author&query=Potts%2C+J">Jason Potts</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Managing rapidly growing decentralized gaming communities brings unique
challenges at the nexus of cultural economics and technology. This paper
introduces a streamlined analytical framework that utilizes Large Language
Models (LLMs), in this instance open-access generative pre-trained transformer
(GPT) models, offering an efficient solution with deeper insights into
community dynamics. The framework aids moderators in identifying pseudonymous
actor intent, moderating toxic behavior, rewarding desired actions to avoid
unintended consequences of blockchain-based gaming, and gauging community
sentiment as communities venture into metaverse platforms and plan for
hypergrowth. This framework strengthens community controls, eases onboarding,
and promotes a common moral mission across communities while reducing agency
costs by 95 pct. Highlighting the transformative role of generative AI, the
paper emphasizes its potential to redefine the cost of cultural production. It
showcases the utility of GPTs in digital community management, expanding their
implications in cultural economics and transmedia storytelling.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07694" title="Abstract">arXiv:2312.07694</a> [<a href="/pdf/2312.07694" title="Download PDF">pdf</a>, <a href="/format/2312.07694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GP+: A Python Library for Kernel-based learning via Gaussian Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yousefpour%2C+A">Amin Yousefpour</a>, 
<a href="/search/cs?searchtype=author&query=Foumani%2C+Z+Z">Zahra Zanjani Foumani</a>, 
<a href="/search/cs?searchtype=author&query=Shishehbor%2C+M">Mehdi Shishehbor</a>, 
<a href="/search/cs?searchtype=author&query=Mora%2C+C">Carlos Mora</a>, 
<a href="/search/cs?searchtype=author&query=Bostanabad%2C+R">Ramin Bostanabad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">In this paper we introduce GP+, an open-source library for kernel-based
learning via Gaussian processes (GPs) which are powerful statistical models
that are completely characterized by their parametric covariance and mean
functions. GP+ is built on PyTorch and provides a user-friendly and
object-oriented tool for probabilistic learning and inference. As we
demonstrate with a host of examples, GP+ has a few unique advantages over other
GP modeling libraries. We achieve these advantages primarily by integrating
nonlinear manifold learning techniques with GPs' covariance and mean functions.
As part of introducing GP+, in this paper we also make methodological
contributions that (1) enable probabilistic data fusion and inverse parameter
estimation, and (2) equip GPs with parsimonious parametric mean functions which
span mixed feature spaces that have both categorical and quantitative
variables. We demonstrate the impact of these contributions in the context of
Bayesian optimization, multi-fidelity modeling, sensitivity analysis, and
calibration of computer models.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07696" title="Abstract">arXiv:2312.07696</a> [<a href="/pdf/2312.07696" title="Download PDF">pdf</a>, <a href="/ps/2312.07696" title="Download PostScript">ps</a>, <a href="/format/2312.07696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time Network Intrusion Detection via Decision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingdi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hanhan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+Y">Yongsheng Mei</a>, 
<a href="/search/cs?searchtype=author&query=Adam%2C+G">Gina Adam</a>, 
<a href="/search/cs?searchtype=author&query=Bastian%2C+N+D">Nathaniel D. Bastian</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+T">Tian Lan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Many cybersecurity problems that require real-time decision-making based on
temporal observations can be abstracted as a sequence modeling problem, e.g.,
network intrusion detection from a sequence of arriving packets. Existing
approaches like reinforcement learning may not be suitable for such
cybersecurity decision problems, since the Markovian property may not
necessarily hold and the underlying network states are often not observable. In
this paper, we cast the problem of real-time network intrusion detection as
casual sequence modeling and draw upon the power of the transformer
architecture for real-time decision-making. By conditioning a causal decision
transformer on past trajectories, consisting of the rewards, network packets,
and detection decisions, our proposed framework will generate future detection
decisions to achieve the desired return. It enables decision transformers to be
applied to real-time network intrusion detection, as well as a novel tradeoff
between the accuracy and timeliness of detection. The proposed solution is
evaluated on public network intrusion detection datasets and outperforms
several baseline algorithms using reinforcement learning and sequence modeling,
in terms of detection accuracy and timeliness.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07698" title="Abstract">arXiv:2312.07698</a> [<a href="/pdf/2312.07698" title="Download PDF">pdf</a>, <a href="/ps/2312.07698" title="Download PostScript">ps</a>, <a href="/format/2312.07698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning and Citizen Science Approaches for Monitoring the  Changing Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Sulong Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD thesis, Environment and Resources, U Wisconson Madison (2021)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This dissertation will combine new tools and methodologies to answer pressing
questions regarding inundation area and hurricane events in complex,
heterogeneous changing environments. In addition to remote sensing approaches,
citizen science and machine learning are both emerging fields that harness
advancing technology to answer environmental management and disaster response
questions.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07706" title="Abstract">arXiv:2312.07706</a> [<a href="/pdf/2312.07706" title="Download PDF">pdf</a>, <a href="/format/2312.07706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-Optimal Differentially Private k-Core Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhulipala%2C+L">Laxman Dhulipala</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G+Z">George Z. Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q+C">Quanquan C. Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Cryptography and Security (cs.CR); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Recent work by Dhulipala, Liu, Raskhodnikova, Shi, Shun, and
Yu~\cite{DLRSSY22} initiated the study of the $k$-core decomposition problem
under differential privacy. They show that approximate $k$-core numbers can be
output while guaranteeing differential privacy, while only incurring a
multiplicative error of $(2 +\eta)$ (for any constant $\eta &gt;0$) and additive
error of $\poly(\log(n))/\eps$. In this paper, we revisit this problem. Our
main result is an $\eps$-edge differentially private algorithm for $k$-core
decomposition which outputs the core numbers with no multiplicative error and
$O(\text{log}(n)/\eps)$ additive error. This improves upon previous work by a
factor of 2 in the multiplicative error, while giving near-optimal additive
error.
<br />With a little additional work, this implies improved algorithms for densest
subgraph and low out-degree ordering under differential privacy. For low
out-degree ordering, we give an $\eps$-edge differentially private algorithm
which outputs an implicit orientation such that the out-degree of each vertex
is at most $d+O(\log{n}/{\eps})$, where $d$ is the degeneracy of the graph.
This improves upon the best known guarantees for the problem by a factor of $4$
and gives near-optimal additive error. For densest subgraph, we give an
$\eps$-edge differentially private algorithm outputting a subset of nodes that
induces a subgraph of density at least ${D^*}/{2}-O(\text{log}(n)/\eps)$, where
$D^*$ is the density for the optimal subgraph.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07707" title="Abstract">arXiv:2312.07707</a> [<a href="/pdf/2312.07707" title="Download PDF">pdf</a>, <a href="/format/2312.07707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning for System Identification of NDAE-modeled Power Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mei%2C+W">Wenjie Mei</a>, 
<a href="/search/eess?searchtype=author&query=Nadeem%2C+M">Muhammad Nadeem</a>, 
<a href="/search/eess?searchtype=author&query=Bahavarnia%2C+M">MirSaleh Bahavarnia</a>, 
<a href="/search/eess?searchtype=author&query=Taha%2C+A+F">Ahmad F. Taha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Dynamical Systems (math.DS)

</div>
<p class="mathjax">System identification through learning approaches is emerging as a promising
strategy for understanding and simulating dynamical systems, which nevertheless
faces considerable difficulty when confronted with power systems modeled by
differential-algebraic equations (DAEs). This paper introduces a neural network
(NN) framework for effectively learning and simulating solution trajectories of
DAEs. The proposed framework leverages the synergy between Implicit Runge-Kutta
(IRK) time-stepping schemes tailored for DAEs and NNs (including a differential
NN (DNN)). The framework enforces an NN to cooperate with the algebraic
equation of DAEs as hard constraints and is suitable for the identification of
the ordinary differential equation (ODE)-modeled dynamic equation of DAEs using
an existing penalty-based algorithm. Finally, the paper demonstrates the
efficacy and precision of the proposed NN through the identification and
simulation of solution trajectories for the considered DAE-modeled power
system.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07709" title="Abstract">arXiv:2312.07709</a> [<a href="/pdf/2312.07709" title="Download PDF">pdf</a>, <a href="/format/2312.07709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Majority is Not Required: A Rational Analysis of the Private  Double-Spend Attack from a Sub-Majority Adversary
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Georghiades%2C+Y">Yanni Georghiades</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+R">Rajesh Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Kreder%2C+K">Karl Kreder</a>, 
<a href="/search/cs?searchtype=author&query=Vishwanath%2C+S">Sriram Vishwanath</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">We study the incentives behind double-spend attacks on Nakamoto-style
Proof-of-Work cryptocurrencies. In these systems, miners are allowed to choose
which transactions to reference with their block, and a common strategy for
selecting transactions is to simply choose those with the highest fees. This
can be problematic if these transactions originate from an adversary with
substantial (but less than 50\%) computational power, as high-value
transactions can present an incentive for a rational adversary to attempt a
double-spend attack if they expect to profit. The most common mechanism for
deterring double-spend attacks is for the recipients of large transactions to
wait for additional block confirmations (i.e., to increase the attack cost). We
argue that this defense mechanism is not satisfactory, as the security of the
system is contingent on the actions of its users. Instead, we propose that
defending against double-spend attacks should be the responsibility of the
miners; specifically, miners should limit the amount of transaction value they
include in a block (i.e., reduce the attack reward). To this end, we model
cryptocurrency mining as a mean-field game in which we augment the standard
mining reward function to simulate the presence of a rational, double-spending
adversary. We design and implement an algorithm which characterizes the
behavior of miners at equilibrium, and we show that miners who use the
adversary-aware reward function accumulate more wealth than those who do not.
We show that the optimal strategy for honest miners is to limit the amount of
value transferred by each block such that the adversary's expected profit is 0.
Additionally, we examine Bitcoin's resilience to double-spend attacks. Assuming
a 6 block confirmation time, we find that an attacker with at least 25% of the
network mining power can expect to profit from a double-spend attack.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07711" title="Abstract">arXiv:2312.07711</a> [<a href="/pdf/2312.07711" title="Download PDF">pdf</a>, <a href="/format/2312.07711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Large Language Models to Build and Execute Computational  Workflows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duque%2C+A">Alejandro Duque</a>, 
<a href="/search/cs?searchtype=author&query=Syed%2C+A">Abdullah Syed</a>, 
<a href="/search/cs?searchtype=author&query=Day%2C+K+V">Kastan V. Day</a>, 
<a href="/search/cs?searchtype=author&query=Berry%2C+M+J">Matthew J. Berry</a>, 
<a href="/search/cs?searchtype=author&query=Katz%2C+D+S">Daniel S. Katz</a>, 
<a href="/search/cs?searchtype=author&query=Kindratenko%2C+V+V">Volodymyr V. Kindratenko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The recent development of large language models (LLMs) with multi-billion
parameters, coupled with the creation of user-friendly application programming
interfaces (APIs), has paved the way for automatically generating and executing
code in response to straightforward human queries. This paper explores how
these emerging capabilities can be harnessed to facilitate complex scientific
workflows, eliminating the need for traditional coding methods. We present
initial findings from our attempt to integrate Phyloflow with OpenAI's
function-calling API, and outline a strategy for developing a comprehensive
workflow management system based on these concepts.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07718" title="Abstract">arXiv:2312.07718</a> [<a href="/pdf/2312.07718" title="Download PDF">pdf</a>, <a href="/format/2312.07718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CaVE: A Cone-Aligned Approach for Fast Predict-then-optimize with Binary  Linear Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+B">Bo Tang</a>, 
<a href="/search/cs?searchtype=author&query=Khalil%2C+E+B">Elias B. Khalil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">The end-to-end predict-then-optimize framework, also known as
decision-focused learning, has gained popularity for its ability to integrate
optimization into the training procedure of machine learning models that
predict the unknown cost (objective function) coefficients of optimization
problems from contextual instance information. Naturally, most of the problems
of interest in this space can be cast as integer linear programs. In this work,
we focus on binary linear programs (BLPs) and propose a new end-to-end training
method for predict-then-optimize. Our method, Cone-aligned Vector Estimation
(CaVE), aligns the predicted cost vectors with the cone corresponding to the
true optimal solution of a training instance. When the predicted cost vector
lies inside the cone, the optimal solution to the linear relaxation of the
binary problem is optimal w.r.t. to the true cost vector. Not only does this
alignment produce decision-aware learning models, but it also dramatically
reduces training time as it circumvents the need to solve BLPs to compute a
loss function with its gradients. Experiments across multiple datasets show
that our method exhibits a favorable trade-off between training time and
solution quality, particularly with large-scale optimization problems such as
vehicle routing, a hard BLP that has yet to benefit from predict-then-optimize
methods in the literature due to its difficulty.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07721" title="Abstract">arXiv:2312.07721</a> [<a href="/pdf/2312.07721" title="Download PDF">pdf</a>, <a href="/format/2312.07721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Saturn Platform: Foundation Model Operations and Generative AI for  Financial Services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Busson%2C+A+J+G">Antonio J. G. Busson</a>, 
<a href="/search/cs?searchtype=author&query=Gaio%2C+R">Rennan Gaio</a>, 
<a href="/search/cs?searchtype=author&query=Rocha%2C+R+H">Rafael H. Rocha</a>, 
<a href="/search/cs?searchtype=author&query=Evangelista%2C+F">Francisco Evangelista</a>, 
<a href="/search/cs?searchtype=author&query=Rizzi%2C+B">Bruno Rizzi</a>, 
<a href="/search/cs?searchtype=author&query=Carvalho%2C+L">Luan Carvalho</a>, 
<a href="/search/cs?searchtype=author&query=Miceli%2C+R">Rafael Miceli</a>, 
<a href="/search/cs?searchtype=author&query=Rabaioli%2C+M">Marcos Rabaioli</a>, 
<a href="/search/cs?searchtype=author&query=Favaro%2C+D">David Favaro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Saturn is an innovative platform that assists Foundation Model (FM) building
and its integration with IT operations (Ops). It is custom-made to meet the
requirements of data scientists, enabling them to effectively create and
implement FMs while enhancing collaboration within their technical domain. By
offering a wide range of tools and features, Saturn streamlines and automates
different stages of FM development, making it an invaluable asset for data
science teams. This white paper introduces prospective applications of
generative AI models derived from FMs in the financial sector.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07722" title="Abstract">arXiv:2312.07722</a> [<a href="/pdf/2312.07722" title="Download PDF">pdf</a>, <a href="/format/2312.07722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error Analysis for the Implicit Boundary Integral Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhong%2C+Y">Yimin Zhong</a>, 
<a href="/search/math?searchtype=author&query=Ren%2C+K">Kui Ren</a>, 
<a href="/search/math?searchtype=author&query=Runborg%2C+O">Olof Runborg</a>, 
<a href="/search/math?searchtype=author&query=Tsai%2C+R">Richard Tsai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The implicit boundary integral method (IBIM) provides a framework to
construct quadrature rules on regular lattices for integrals over irregular
domain boundaries. This work provides a systematic error analysis for IBIMs on
uniform Cartesian grids for boundaries with different degree of regularities.
We first show that the quadrature error gains an addition order of
$\frac{d-1}{2}$ from the curvature for a strongly convex smooth boundary due to
the ``randomness'' in the signed distances. This gain is discounted for
degenerated convex surfaces. We then extend the error estimate to general
boundaries under some special circumstances, including how quadrature error
depends on the boundary's local geometry relative to the underlying grid.
Bounds on the variance of the quadrature error under random shifts and
rotations of the lattices are also derived.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07723" title="Abstract">arXiv:2312.07723</a> [<a href="/pdf/2312.07723" title="Download PDF">pdf</a>, <a href="/format/2312.07723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Behavioral Analysis Using Instance Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Forest%2C+J">Jeremy Forest</a>, 
<a href="/search/cs?searchtype=author&query=Einhorn%2C+M">Matthew Einhorn</a>, 
<a href="/search/cs?searchtype=author&query=Cleland%2C+T+A">Thomas A. Cleland</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Animal behavior analysis plays a crucial role in various fields, such as life
science and biomedical research. However, the scarcity of available data and
the high cost associated with obtaining a large number of labeled datasets pose
significant challenges. In this research, we propose a novel approach that
leverages instance segmentation-based transfer learning to address these
issues. By capitalizing on fine-tuning the classification head of the instance
segmentation network, we enable the tracking of multiple animals and facilitate
behavior analysis in laboratory-recorded videos. To demonstrate the
effectiveness of our method, we conducted a series of experiments, revealing
that our approach achieves exceptional performance levels, comparable to human
capabilities, across a diverse range of animal behavior analysis tasks.
Moreover, we emphasize the practicality of our solution, as it requires only a
small number of labeled images for training. To facilitate the adoption and
further development of our method, we have developed an open-source
implementation named Annolid (An annotation and instance segmentation-based
multiple animal tracking and behavior analysis package). The codebase is
publicly available on GitHub at https://github.com/cplab/annolid. This resource
serves as a valuable asset for researchers and practitioners interested in
advancing animal behavior analysis through state-of-the-art techniques.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07724" title="Abstract">arXiv:2312.07724</a> [<a href="/pdf/2312.07724" title="Download PDF">pdf</a>, <a href="/format/2312.07724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Restorebot: Towards an Autonomous Robotics Platform for Degraded  Rangeland Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Such%2C+K">Kristen Such</a>, 
<a href="/search/cs?searchtype=author&query=Biggie%2C+H">Harel Biggie</a>, 
<a href="/search/cs?searchtype=author&query=Heckman%2C+C">Christoffer Heckman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 14 figures, Accepted as a Contributed Paper at the 18th International Symposium on Experimental Robotics (ISER 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Degraded rangelands undergo continual shifts in the appearance and
distribution of plant life. The nature of these changes however is subtle:
between seasons seedlings sprout up and some flourish while others perish,
meanwhile, over multiple seasons they experience fluctuating precipitation
volumes and can be grazed by livestock. The nature of these conditioning
variables makes it difficult for ecologists to quantify the efficacy of
intervention techniques under study. To support these observation and
intervention tasks, we develop RestoreBot: a mobile robotic platform designed
for gathering data in degraded rangelands for the purpose of data collection
and intervention in order to support revegetation. Over the course of multiple
deployments, we outline the opportunities and challenges of autonomous data
collection for revegetation and the importance of further effort in this area.
Specifically, we identify that localization, mapping, data association, and
terrain assessment remain open problems for deployment, but that recent
advances in computer vision, sensing, and autonomy offer promising prospects
for autonomous revegetation.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07725" title="Abstract">arXiv:2312.07725</a> [<a href="/pdf/2312.07725" title="Download PDF">pdf</a>, <a href="/format/2312.07725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discretely Nonlinearly Stable Weight-Adjusted Flux Reconstruction  High-Order Method for Compressible Flows on Curvilinear Grids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cicchino%2C+A">Alexander Cicchino</a>, 
<a href="/search/math?searchtype=author&query=Nadarajah%2C+S">Siva Nadarajah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Provable nonlinear stability bounds the discrete approximation and ensures
that the discretization does not diverge. For high-order methods, discrete
nonlinear stability and entropy stability, have been successfully implemented
for discontinuous Galerkin (DG) and residual distribution schemes, where the
stability proofs depend on properties of L2-norms. In this paper, nonlinearly
stable flux reconstruction (NSFR) schemes are developed for three-dimensional
compressible flow in curvilinear coordinates. NSFR is derived by merging the
energy stable FR (ESFR) framework with entropy stable DG schemes. NSFR is
demonstrated to use larger time-steps than DG due to the ESFR correction
functions. NSFR differs from ESFR schemes in the literature since it
incorporates the FR correction functions on the volume terms through the use of
a modified mass matrix. We also prove that discrete kinetic energy stability
cannot be preserved to machine precision for quadrature rules where the surface
quadrature is not a subset of the volume quadrature. This paper also presents
the NSFR modified mass matrix in a weight-adjusted form. This form reduces the
computational cost in curvilinear coordinates through sum-fcatorization and
low-storage techniques. The nonlinear stability properties of the scheme are
verified on a nonsymmetric curvilinear grid for the inviscid Taylor-Green
vortex problem and the correct orders of convergence were obtained for a
manufactured solution. Lastly, we perform a computational cost comparison
between conservative DG, overintegrated DG, and our proposed entropy conserving
NSFR scheme, and find that our proposed entropy conserving NSFR scheme is
computationally competitive with the conservative DG scheme.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07730" title="Abstract">arXiv:2312.07730</a> [<a href="/pdf/2312.07730" title="Download PDF">pdf</a>, <a href="/format/2312.07730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Classification of Financial Transactions Through  Context-Fusion of Transformer-based Embeddings and Taxonomy-aware Attention  Layer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Busson%2C+A+J+G">Antonio J. G. Busson</a>, 
<a href="/search/cs?searchtype=author&query=Rocha%2C+R">Rafael Rocha</a>, 
<a href="/search/cs?searchtype=author&query=Gaio%2C+R">Rennan Gaio</a>, 
<a href="/search/cs?searchtype=author&query=Miceli%2C+R">Rafael Miceli</a>, 
<a href="/search/cs?searchtype=author&query=Pereira%2C+I">Ivan Pereira</a>, 
<a href="/search/cs?searchtype=author&query=de+S.+Moraes%2C+D">Daniel de S. Moraes</a>, 
<a href="/search/cs?searchtype=author&query=Colcher%2C+S">S&#xe9;rgio Colcher</a>, 
<a href="/search/cs?searchtype=author&query=Veiga%2C+A">Alvaro Veiga</a>, 
<a href="/search/cs?searchtype=author&query=Rizzi%2C+B">Bruno Rizzi</a>, 
<a href="/search/cs?searchtype=author&query=Evangelista%2C+F">Francisco Evangelista</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+L">Leandro Santos</a>, 
<a href="/search/cs?searchtype=author&query=Marques%2C+F">Fellipe Marques</a>, 
<a href="/search/cs?searchtype=author&query=Rabaioli%2C+M">Marcos Rabaioli</a>, 
<a href="/search/cs?searchtype=author&query=Feldberg%2C+D">Diego Feldberg</a>, 
<a href="/search/cs?searchtype=author&query=Mattos%2C+D">Debora Mattos</a>, 
<a href="/search/cs?searchtype=author&query=Pasqua%2C+J">Jo&#xe3;o Pasqua</a>, 
<a href="/search/cs?searchtype=author&query=Dias%2C+D">Diogo Dias</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This work proposes the Two-headed DragoNet, a Transformer-based model for
hierarchical multi-label classification of financial transactions. Our model is
based on a stack of Transformers encoder layers that generate contextual
embeddings from two short textual descriptors (merchant name and business
activity), followed by a Context Fusion layer and two output heads that
classify transactions according to a hierarchical two-level taxonomy (macro and
micro categories). Finally, our proposed Taxonomy-aware Attention Layer
corrects predictions that break categorical hierarchy rules defined in the
given taxonomy. Our proposal outperforms classical machine learning methods in
experiments of macro-category classification by achieving an F1-score of 93\%
on a card dataset and 95% on a current account dataset.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07731" title="Abstract">arXiv:2312.07731</a> [<a href="/pdf/2312.07731" title="Download PDF">pdf</a>, <a href="/format/2312.07731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Response to Glaze Purification via IMPRESS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shan%2C+S">Shawn Shan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Stanley Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Haitao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B+Y">Ben Y. Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Recent work proposed a new mechanism to remove protective perturbation added
by Glaze in order to again enable mimicry of art styles from images protected
by Glaze. Despite promising results shown in the original paper, our own tests
with the authors' code demonstrated several limitations of the proposed
purification approach. The main limitations are 1) purification has a limited
effect when tested on artists that are not well-known historical artists
already embedded in original training data, 2) problems in evaluation metrics,
and 3) collateral damage on mimicry result for clean images. We believe these
limitations should be carefully considered in order to understand real world
usability of the purification attack.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07739" title="Abstract">arXiv:2312.07739</a> [<a href="/pdf/2312.07739" title="Download PDF">pdf</a>, <a href="/ps/2312.07739" title="Download PostScript">ps</a>, <a href="/format/2312.07739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coordination of Damping Controllers: A Data-Informed Approach for  Adaptability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zelaya-Arrazabal%2C+F">Francisco Zelaya-Arrazabal</a>, 
<a href="/search/eess?searchtype=author&query=Pulgar-Painemal%2C+H">Hector Pulgar-Painemal</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jingzi Liu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+F">Fangxing Li</a>, 
<a href="/search/eess?searchtype=author&query=Silva-Saravia%2C+H">Horacio Silva-Saravia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This work proposes a data-informed approach for an adaptable coordination of
damping controllers. The novel concept of coordination is based on minimizing
the Total Action, a single metric that measures the system's dynamic response
post-disturbance. This is a performance measure based on the physics of the
power system, which encapsulates the oscillation energy related to synchronous
generators. Deep learning theory is used to propose a Total Action function
approximator, which captures the relationship between the system wide-area
measurements, the status of damping controllers, and the conditions of the
disturbance. By commissioning the switching status (on/off) of damping
controllers in real-time, the oscillation energy is reduced, enhancing the
power system stability. The concept is tested in the Western North America
Power System (wNAPS) and compared with a model-based approach for the
coordination of damping controllers. The data-informed coordination outperforms
the model-based approach, demonstrating exceptional adaptability and
performance to handle multi-modal events. The proposed scheme shows outstanding
reductions in low-frequency oscillations even under various operating
conditions, fault locations, and time delay considerations.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07740" title="Abstract">arXiv:2312.07740</a> [<a href="/pdf/2312.07740" title="Download PDF">pdf</a>, <a href="/format/2312.07740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HAtt-Flow: Hierarchical Attention-Flow Mechanism for Group Activity  Scene Graph Generation in Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chappa%2C+N+V+R">Naga VS Raviteja Chappa</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+P">Pha Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T+H+N">Thi Hoang Ngan Le</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+K">Khoa Luu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Group Activity Scene Graph (GASG) generation is a challenging task in
computer vision, aiming to anticipate and describe relationships between
subjects and objects in video sequences. Traditional Video Scene Graph
Generation (VidSGG) methods focus on retrospective analysis, limiting their
predictive capabilities. To enrich the scene understanding capabilities, we
introduced a GASG dataset extending the JRDB dataset with nuanced annotations
involving \textit{Appearance, Interaction, Position, Relationship, and
Situation} attributes. This work also introduces an innovative approach,
\textbf{H}ierarchical \textbf{Att}ention-\textbf{Flow} (HAtt-Flow) Mechanism,
rooted in flow network theory to enhance GASG performance. Flow-Attention
incorporates flow conservation principles, fostering competition for sources
and allocation for sinks, effectively preventing the generation of trivial
attention. Our proposed approach offers a unique perspective on attention
mechanisms, where conventional "values" and "keys" are transformed into sources
and sinks, respectively, creating a novel framework for attention-based models.
Through extensive experiments, we demonstrate the effectiveness of our
Hatt-Flow model and the superiority of our proposed Flow-Attention mechanism.
This work represents a significant advancement in predictive video scene
understanding, providing valuable insights and techniques for applications that
require real-time relationship prediction in video data.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07742" title="Abstract">arXiv:2312.07742</a> [<a href="/pdf/2312.07742" title="Download PDF">pdf</a>, <a href="/ps/2312.07742" title="Download PostScript">ps</a>, <a href="/format/2312.07742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visible Light Positioning under Luminous Flux Degradation of LEDs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Iddrisu%2C+I">Issifu Iddrisu</a>, 
<a href="/search/cs?searchtype=author&query=Gezici%2C+S">Sinan Gezici</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 5 figures (submitted to IEEE TAES)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The position estimation problem based on received power measurements is
investigated for visible light systems in the presence of luminous flux
degradation of light emitting diodes (LEDs). When the receiver is unaware of
this degradation and performs position estimation accordingly, there exists a
mismatch between the true model and the assumed model. For this scenario, the
misspecified Cram\'er-Rao bound (MCRB) and the mismatched maximum likelihood
(MML) estimator are derived to quantify the performance loss due to this model
mismatch. Also, the Cram\'er-Rao lower bound (CRB) and the maximum likelihood
(ML) estimator are derived when the receiver knows the degradation formula for
the LEDs but does not know the decay rate parameter in that formula. In
addition, in the presence of full knowledge about the degradation formula and
the decay rate parameters, the CRB and the ML estimator are obtained to specify
the best achievable performance. By evaluating the theoretical limits and the
estimators in these three scenarios, we reveal the effects of the information
about the LED degradation model and the decay rate parameters on position
estimation performance. It is shown that the model mismatch can result in
significant degradation in localization performance at high signal-to-noise
ratios, which can be compensated by conducting joint position and decay rate
parameter estimation.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07743" title="Abstract">arXiv:2312.07743</a> [<a href="/pdf/2312.07743" title="Download PDF">pdf</a>, <a href="/format/2312.07743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FULL-W2V: Fully Exploiting Data Reuse for W2V on GPU-Accelerated Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Randall%2C+T">Thomas Randall</a>, 
<a href="/search/cs?searchtype=author&query=Allen%2C+T">Tyler Allen</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+R">Rong Ge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures, 7 tables, the definitive version of this work is published in the Proceedings of the ACM International Conference on Supercomputing 2021, available at <a href="https://doi.org/10.1145/3447818.3460373">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the ACM International Conference on Supercomputing
  (2021) 455-466
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Word2Vec remains one of the highly-impactful innovations in the field of
Natural Language Processing (NLP) that represents latent grammatical and
syntactical information in human text with dense vectors in a low dimension.
Word2Vec has high computational cost due to the algorithm's inherent
sequentiality, intensive memory accesses, and the large vocabularies it
represents. While prior studies have investigated technologies to explore
parallelism and improve memory system performance, they struggle to effectively
gain throughput on powerful GPUs.
<br />We identify memory data access and latency as the primary bottleneck in prior
works on GPUs, which prevents highly optimized kernels from attaining the
architecture's peak performance. We present a novel algorithm, FULL-W2V, which
maximally exploits the opportunities for data reuse in the W2V algorithm and
leverages GPU architecture and resources to reduce access to low memory levels
and improve temporal locality. FULL-W2V is capable of reducing accesses to GPU
global memory significantly, e.g., by more than 89\%, compared to prior
state-of-the-art GPU implementations, resulting in significant performance
improvement that scales across successive hardware generations. Our prototype
implementation achieves 2.97X speedup when ported from Nvidia Pascal P100 to
Volta V100 cards, and outperforms the state-of-the-art by 5.72X on V100 cards
with the same embedding quality. In-depth analysis indicates that the reduction
of memory accesses through register and shared memory caching and
high-throughput shared memory reduction leads to a significantly improved
arithmetic intensity. FULL-W2V can potentially benefit many applications in NLP
and other domains.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07744" title="Abstract">arXiv:2312.07744</a> [<a href="/pdf/2312.07744" title="Download PDF">pdf</a>, <a href="/format/2312.07744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Does Perception Affect Safety: New Metrics and Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaotong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chong%2C+J">Jinger Chong</a>, 
<a href="/search/cs?searchtype=author&query=Youcef-Toumi%2C+K">Kamal Youcef-Toumi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Perception serves as a critical component in the functionality of autonomous
agents. However, the intricate relationship between perception metrics and
robotic metrics remains unclear, leading to ambiguity in the development and
fine-tuning of perception algorithms. In this paper, we introduce a methodology
for quantifying this relationship, taking into account factors such as
detection rate, detection quality, and latency. Furthermore, we introduce two
novel metrics for Human-Robot Collaboration safety predicated upon perception
metrics: Critical Collision Probability (CCP) and Average Collision Probability
(ACP). To validate the utility of these metrics in facilitating algorithm
development and tuning, we develop an attentive processing strategy that
focuses exclusively on key input features. This approach significantly reduces
computational time while preserving a similar level of accuracy. Experimental
results indicate that the implementation of this strategy in an object detector
leads to a maximum reduction of 30.091% in inference time and 26.534% in total
time per frame. Additionally, the strategy lowers the CCP and ACP in a baseline
model by 11.252% and 13.501%, respectively. The source code will be made
publicly available in the final proof version of the manuscript.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07745" title="Abstract">arXiv:2312.07745</a> [<a href="/pdf/2312.07745" title="Download PDF">pdf</a>, <a href="/ps/2312.07745" title="Download PostScript">ps</a>, <a href="/format/2312.07745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-density Electromyography for Effective Gesture-based Control of  Physically Assistive Mobile Manipulators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jehan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shibata%2C+K">Kent Shibata</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+D">Douglas Weber</a>, 
<a href="/search/cs?searchtype=author&query=Erickson%2C+Z">Zackory Erickson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Injury to the cervical spinal cord can cause quadriplegia, impairing muscle
function in all four limbs. People with impaired hand function and mobility
encounter significant difficulties in carrying out essential self-care and
household tasks. Despite the impairment of their neural drive, their volitional
myoelectric activity is often partially preserved. High-density
electromyography (HDEMG) can detect this myoelectric activity, which can serve
as control inputs to assistive devices. Previous HDEMG-controlled robotic
interfaces have primarily been limited to controlling table-mounted robot arms.
These have constrained reach capabilities. Instead, the ability to control
mobile manipulators, which have no such workspace constraints, could allow
individuals with quadriplegia to perform a greater variety of assistive tasks,
thus restoring independence and reducing caregiver workload. In this study, we
introduce a non-invasive wearable HDEMG interface with real-time myoelectric
hand gesture recognition, enabling both coarse and fine control over the
intricate mobility and manipulation functionalities of an 8 degree-of-freedom
mobile manipulator. Our evaluation, involving 13 participants engaging in
challenging self-care and household activities, demonstrates the potential of
our wearable HDEMG system to profoundly enhance user independence by enabling
non-invasive control of a mobile manipulator.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07747" title="Abstract">arXiv:2312.07747</a> [<a href="/pdf/2312.07747" title="Download PDF">pdf</a>, <a href="/ps/2312.07747" title="Download PostScript">ps</a>, <a href="/format/2312.07747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recognizing Hereditary Properties in the Presence of Byzantine Nodes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cifuentes-N%C3%BA%C3%B1ez%2C+D">David Cifuentes-N&#xfa;&#xf1;ez</a>, 
<a href="/search/cs?searchtype=author&query=Montealegre%2C+P">Pedro Montealegre</a>, 
<a href="/search/cs?searchtype=author&query=Rapaport%2C+I">Ivan Rapaport</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Augustine et al. [DISC 2022] initiated the study of distributed graph
algorithms in the presence of Byzantine nodes in the congested clique model. In
this model, there is a set $B$ of Byzantine nodes, where $|B|$ is less than a
third of the total number of nodes. These nodes have complete knowledge of the
network and the state of other nodes, and they conspire to alter the output of
the system. The authors addressed the connectivity problem, showing that it is
solvable under the promise that either the subgraph induced by the honest nodes
is connected, or the graph has $2|B|+1$ connected components.
<br />In the current work, we continue the study of the Byzantine congested clique
model by considering the recognition of other graph properties, specifically
\emph{hereditary properties}. A graph property is \emph{hereditary} if it is
closed under taking induced subgraphs. Examples of hereditary properties
include acyclicity, bipartiteness, planarity, and bounded (chromatic,
independence) number, etc.
<br />For each class of graphs $\mathcal{G}$ satisfying an hereditary property (an
hereditary graph-class), we propose a randomized algorithm which, with high
probability, (1) accepts if the input graph $G$ belongs to $\mathcal{G}$, and
(2) rejects if $G$ contains at least $|B| + 1$ disjoint subgraphs not belonging
to $\mathcal{G}$. The round complexity of our algorithm is
$$\mathcal{O}\left(\left(\dfrac{\log
\left(\left|\mathcal{G}_n\right|\right)}{n}
+|B|\right)\cdot\textrm{polylog}(n)\right),$$ where $\mathcal{G}_n$ is the set
of $n$-node graphs in $\mathcal{G}$.
<br />Finally, we obtain an impossibility result that proves that our result is
tight. Indeed, we consider the hereditary class of acyclic graphs, and we prove
that there is no algorithm that can distinguish between a graph being acyclic
and a graph having $|B|$ disjoint cycles.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07748" title="Abstract">arXiv:2312.07748</a> [<a href="/pdf/2312.07748" title="Download PDF">pdf</a>, <a href="/format/2312.07748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Portability and Scalability Evaluation of Large-Scale Statistical  Modeling and Prediction Software through HPC-Ready Containers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdulah%2C+S">Sameh Abdulah</a>, 
<a href="/search/cs?searchtype=author&query=Ejarque%2C+J">Jorge Ejarque</a>, 
<a href="/search/cs?searchtype=author&query=Marzouk%2C+O">Omar Marzouk</a>, 
<a href="/search/cs?searchtype=author&query=Ltaief%2C+H">Hatem Ltaief</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Ying Sun</a>, 
<a href="/search/cs?searchtype=author&query=Genton%2C+M+G">Marc G. Genton</a>, 
<a href="/search/cs?searchtype=author&query=Badia%2C+R+M">Rosa M. Badia</a>, 
<a href="/search/cs?searchtype=author&query=Keyes%2C+D+E">David E. Keyes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">HPC-based applications often have complex workflows with many software
dependencies that hinder their portability on contemporary HPC architectures.
In addition, these applications often require extraordinary efforts to deploy
and execute at performance potential on new HPC systems, while the users expert
in these applications generally have less expertise in HPC and related
technologies. This paper provides a dynamic solution that facilitates
containerization for transferring HPC software onto diverse parallel systems.
The study relies on the HPC Workflow as a Service (HPCWaaS) paradigm proposed
by the EuroHPC eFlows4HPC project. It offers to deploy workflows through
containers tailored for any of a number of specific HPC systems. Traditional
container image creation tools rely on OS system packages compiled for generic
architecture families (x86\_64, amd64, ppc64, ...) and specific MPI or GPU
runtime library versions. The containerization solution proposed in this paper
leverages HPC Builders such as Spack or Easybuild and multi-platform builders
such as buildx to create a service for automating the creation of container
images for the software specific to each hardware architecture, aiming to
sustain the overall performance of the software. We assess the efficiency of
our proposed solution for porting the geostatistics ExaGeoStat software on
various parallel systems while preserving the computational performance. The
results show that the performance of the generated images is comparable with
the native execution of the software on the same architectures. On the
distributed-memory system, the containerized version can scale up to 256 nodes
without impacting performance.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07751" title="Abstract">arXiv:2312.07751</a> [<a href="/pdf/2312.07751" title="Download PDF">pdf</a>, <a href="/format/2312.07751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Human Language Models: A Need and the Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soni%2C+N">Nikita Soni</a>, 
<a href="/search/cs?searchtype=author&query=Schwartz%2C+H+A">H. Andrew Schwartz</a>, 
<a href="/search/cs?searchtype=author&query=Sedoc%2C+J">Jo&#xe3;o Sedoc</a>, 
<a href="/search/cs?searchtype=author&query=Balasubramanian%2C+N">Niranjan Balasubramanian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">As research in human-centered NLP advances, there is a growing recognition of
the importance of incorporating human and social factors into NLP models. At
the same time, our NLP systems have become heavily reliant on LLMs, most of
which do not model authors. To build NLP systems that can truly understand
human language, we must better integrate human contexts into LLMs. This brings
to the fore a range of design considerations and challenges in terms of what
human aspects to capture, how to represent them, and what modeling strategies
to pursue. To address these, we advocate for three positions toward creating
large human language models (LHLMs) using concepts from psychological and
behavioral sciences: First, LM training should include the human context.
Second, LHLMs should recognize that people are more than their group(s). Third,
LHLMs should be able to account for the dynamic and temporally-dependent nature
of the human context. We refer to relevant advances and present open challenges
that need to be addressed and their possible solutions in realizing these
goals.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07753" title="Abstract">arXiv:2312.07753</a> [<a href="/pdf/2312.07753" title="Download PDF">pdf</a>, <a href="/format/2312.07753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial-based Self-Attention for Table Representation learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jayoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+Y">Yehjin Shin</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+N">Noseong Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Structured data, which constitutes a significant portion of existing data
types, has been a long-standing research topic in the field of machine
learning. Various representation learning methods for tabular data have been
proposed, ranging from encoder-decoder structures to Transformers. Among these,
Transformer-based methods have achieved state-of-the-art performance not only
in tabular data but also in various other fields, including computer vision and
natural language processing. However, recent studies have revealed that
self-attention, a key component of Transformers, can lead to an oversmoothing
issue. We show that Transformers for tabular data also face this problem, and
to address the problem, we propose a novel matrix polynomial-based
self-attention layer as a substitute for the original self-attention layer,
which enhances model scalability. In our experiments with three representative
table learning models equipped with our proposed layer, we illustrate that the
layer effectively mitigates the oversmoothing problem and enhances the
representation performance of the existing methods, outperforming the
state-of-the-art table representation methods.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07755" title="Abstract">arXiv:2312.07755</a> [<a href="/pdf/2312.07755" title="Download PDF">pdf</a>, <a href="/format/2312.07755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing with Language: Wireframing UI Design Intent with Generative  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+S">Sidong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+M">Mingyue Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jieshan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhenchang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chunyang Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Wireframing is a critical step in the UI design process. Mid-fidelity
wireframes offer more impactful and engaging visuals compared to low-fidelity
versions. However, their creation can be time-consuming and labor-intensive,
requiring the addition of actual content and semantic icons. In this paper, we
introduce a novel solution WireGen, to automatically generate mid-fidelity
wireframes with just a brief design intent description using the generative
Large Language Models (LLMs). Our experiments demonstrate the effectiveness of
WireGen in producing 77.5% significantly better wireframes, outperforming two
widely-used in-context learning baselines. A user study with 5 designers
further validates its real-world usefulness, highlighting its potential value
to enhance UI design process.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07759" title="Abstract">arXiv:2312.07759</a> [<a href="/pdf/2312.07759" title="Download PDF">pdf</a>, <a href="/ps/2312.07759" title="Download PostScript">ps</a>, <a href="/format/2312.07759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IDKM: Memory Efficient Neural Network Quantization via Implicit,  Differentiable $k$-Means
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jaffe%2C+S">Sean Jaffe</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A+K">Ambuj K. Singh</a>, 
<a href="/search/cs?searchtype=author&query=Bullo%2C+F">Francesco Bullo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Compressing large neural networks with minimal performance loss is crucial to
enabling their deployment on edge devices. (Cho et al., 2022) proposed a weight
quantization method that uses an attention-based clustering algorithm called
differentiable $k$-means (DKM). Despite achieving state-of-the-art results,
DKM's performance is constrained by its heavy memory dependency. We propose an
implicit, differentiable $k$-means algorithm (IDKM), which eliminates the major
memory restriction of DKM. Let $t$ be the number of $k$-means iterations, $m$
be the number of weight-vectors, and $b$ be the number of bits per cluster
address. IDKM reduces the overall memory complexity of a single $k$-means layer
from $\mathcal{O}(t \cdot m \cdot 2^b)$ to $\mathcal{O}( m \cdot 2^b)$. We also
introduce a variant, IDKM with Jacobian-Free-Backpropagation (IDKM-JFB), for
which the time complexity of the gradient calculation is independent of $t$ as
well. We provide a proof of concept of our methods by showing that, under the
same settings, IDKM achieves comparable performance to DKM with less compute
time and less memory. We also use IDKM and IDKM-JFB to quantize a large neural
network, Resnet18, on hardware where DKM cannot train at all.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07760" title="Abstract">arXiv:2312.07760</a> [<a href="/pdf/2312.07760" title="Download PDF">pdf</a>, <a href="/format/2312.07760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XC-NAS: A New Cellular Encoding Approach for Neural Architecture Search  of Multi-path Convolutional Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Londt%2C+T">Trevor Londt</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiaoying Gao</a>, 
<a href="/search/cs?searchtype=author&query=Andreae%2C+P">Peter Andreae</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+Y">Yi Mei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Australasian Joint Conference on Artificial Intelligence 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Convolutional Neural Networks (CNNs) continue to achieve great success in
classification tasks as innovative techniques and complex multi-path
architecture topologies are introduced. Neural Architecture Search (NAS) aims
to automate the design of these complex architectures, reducing the need for
costly manual design work by human experts. Cellular Encoding (CE) is an
evolutionary computation technique which excels in constructing novel
multi-path topologies of varying complexity and has recently been applied with
NAS to evolve CNN architectures for various classification tasks. However,
existing CE approaches have severe limitations. They are restricted to only one
domain, only partially implement the theme of CE, or only focus on the
micro-architecture search space. This paper introduces a new CE representation
and algorithm capable of evolving novel multi-path CNN architectures of varying
depth, width, and complexity for image and text classification tasks. The
algorithm explicitly focuses on the macro-architecture search space.
Furthermore, by using a surrogate model approach, we show that the algorithm
can evolve a performant CNN architecture in less than one GPU day, thereby
allowing a sufficient number of experiment runs to be conducted to achieve
scientific robustness. Experiment results show that the approach is highly
competitive, defeating several state-of-the-art methods, and is generalisable
to both the image and text domains.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07762" title="Abstract">arXiv:2312.07762</a> [<a href="/pdf/2312.07762" title="Download PDF">pdf</a>, <a href="/format/2312.07762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable factorization of clinical questionnaires to identify  latent factors of psychopathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lam%2C+K+C">Ka Chun Lam</a>, 
<a href="/search/cs?searchtype=author&query=Mahony%2C+B+W">Bridget W Mahony</a>, 
<a href="/search/cs?searchtype=author&query=Raznahan%2C+A">Armin Raznahan</a>, 
<a href="/search/cs?searchtype=author&query=Pereira%2C+F">Francisco Pereira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Applications (stat.AP)

</div>
<p class="mathjax">Psychiatry research seeks to understand the manifestations of psychopathology
in behavior, as measured in questionnaire data, by identifying a small number
of latent factors that explain them. While factor analysis is the traditional
tool for this purpose, the resulting factors may not be interpretable, and may
also be subject to confounding variables. Moreover, missing data are common,
and explicit imputation is often required. To overcome these limitations, we
introduce interpretability constrained questionnaire factorization (ICQF), a
non-negative matrix factorization method with regularization tailored for
questionnaire data. Our method aims to promote factor interpretability and
solution stability. We provide an optimization procedure with theoretical
convergence guarantees, and an automated procedure to detect latent
dimensionality accurately. We validate these procedures using realistic
synthetic data. We demonstrate the effectiveness of our method in a widely used
general-purpose questionnaire, in two independent datasets (the Healthy Brain
Network and Adolescent Brain Cognitive Development studies). Specifically, we
show that ICQF improves interpretability, as defined by domain experts, while
preserving diagnostic information across a range of disorders, and outperforms
competing methods for smaller dataset sizes. This suggests that the
regularization in our method matches domain characteristics. The python
implementation for ICQF is available at
\url{https://github.com/jefferykclam/ICQF}.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07763" title="Abstract">arXiv:2312.07763</a> [<a href="/pdf/2312.07763" title="Download PDF">pdf</a>, <a href="/format/2312.07763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can LLM find the green circle? Investigation and Human-guided tool  manipulation for compositional generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jianfeng He</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+S">Shuo Lei</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+M">Murong Yue</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Linhang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chang-Tien Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The meaning of complex phrases in natural language is composed of their
individual components. The task of compositional generalization evaluates a
model's ability to understand new combinations of components. Previous studies
trained smaller, task-specific models, which exhibited poor generalization.
While large language models (LLMs) exhibit impressive generalization abilities
on many tasks through in-context learning (ICL), their potential for
compositional generalization remains unexplored. In this paper, we first
empirically investigate prevailing ICL methods in compositional generalization.
We find that they struggle with complex compositional questions due to
cumulative errors in long reasoning steps and intricate logic required for
tool-making. Consequently, we propose a human-guided tool manipulation
framework (HTM) that generates tools for sub-questions and integrates multiple
tools. Our method enhances the effectiveness of tool creation and usage with
minimal human effort. Experiments show that our method achieves
state-of-the-art performance on two compositional generalization benchmarks and
outperforms existing methods on the most challenging test split by 70%.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07767" title="Abstract">arXiv:2312.07767</a> [<a href="/pdf/2312.07767" title="Download PDF">pdf</a>, <a href="/format/2312.07767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial Knowledge-Infused Hierarchical Learning: An Application in Flood  Mapping on Earth Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zelin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Tingsong Xiao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+W">Wenchong He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhe Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGSPATIAL 2023 (Best Paper Award)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Deep learning for Earth imagery plays an increasingly important role in
geoscience applications such as agriculture, ecology, and natural disaster
management. Still, progress is often hindered by the limited training labels.
Given Earth imagery with limited training labels, a base deep neural network
model, and a spatial knowledge base with label constraints, our problem is to
infer the full labels while training the neural network. The problem is
challenging due to the sparse and noisy input labels, spatial uncertainty
within the label inference process, and high computational costs associated
with a large number of sample locations. Existing works on neuro-symbolic
models focus on integrating symbolic logic into neural networks (e.g., loss
function, model architecture, and training label augmentation), but these
methods do not fully address the challenges of spatial data (e.g., spatial
uncertainty, the trade-off between spatial granularity and computational
costs). To bridge this gap, we propose a novel Spatial Knowledge-Infused
Hierarchical Learning (SKI-HL) framework that iteratively infers sample labels
within a multi-resolution hierarchy. Our framework consists of a module to
selectively infer labels in different resolutions based on spatial uncertainty
and a module to train neural network parameters with uncertainty-aware
multi-instance learning. Extensive experiments on real-world flood mapping
datasets show that the proposed model outperforms several baseline methods. The
code is available at \url{https://github.com/ZelinXu2000/SKI-HL}.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07769" title="Abstract">arXiv:2312.07769</a> [<a href="/pdf/2312.07769" title="Download PDF">pdf</a>, <a href="/format/2312.07769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incremental hierarchical text clustering methods: a review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Simeone%2C+F">Fernando Simeone</a>, 
<a href="/search/cs?searchtype=author&query=Chaves%2C+M+O">Maik Olher Chaves</a>, 
<a href="/search/cs?searchtype=author&query=Esmin%2C+A">Ahmed Esmin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The growth in Internet usage has contributed to a large volume of
continuously available data, and has created the need for automatic and
efficient organization of the data. In this context, text clustering techniques
are significant because they aim to organize documents according to their
characteristics. More specifically, hierarchical and incremental clustering
techniques can organize dynamic data in a hierarchical form, thus guaranteeing
that this organization is updated and its exploration is facilitated. Based on
the relevance and contemporary nature of the field, this study aims to analyze
various hierarchical and incremental clustering techniques; the main
contribution of this research is the organization and comparison of the
techniques used by studies published between 2010 and 2018 that aimed to texts
documents clustering. We describe the principal concepts related to the
challenge and the different characteristics of these published works in order
to provide a better understanding of the research in this field.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07772" title="Abstract">arXiv:2312.07772</a> [<a href="/pdf/2312.07772" title="Download PDF">pdf</a>, <a href="/format/2312.07772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VR for Acupuncture? Exploring Needs and Opportunities for Acupuncture  Training and Treatment in Virtual Reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Menghe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yarmand%2C+M">Matin Yarmand</a>, 
<a href="/search/cs?searchtype=author&query=Weibel%2C+N">Nadir Weibel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Acupuncture is a form of medicine that involves inserting needles into
targeted areas of the body and requires knowledge of both Traditional Chinese
Medicine (TCM) and Evidence-Based Medicine (EBM). The process of acquiring such
knowledge and using it for practical treatment is challenging due to the need
for a deep understanding of human anatomy and the ability to apply both TCM and
EBM approaches. Visual aids have been introduced to aid in understanding the
alignment of acupuncture points with key elements of the human body, and are
indispensable tools for both learners and expert acupuncturists. However, they
are often not enough to enable effective practice and fail to fully support the
learning process. Novel approaches based on immersive visualization and Virtual
Reality (VR) have shown promise in many healthcare settings due to their unique
advantages in terms of realism and interactions, but it is still unknown
whether and how VR can possibly be beneficial to acupuncture training and
treatment. Following participatory design protocols such as observations and
semi-structured interviews with eight doctors and nine students, we explore the
needs and pain points of current acupuncture workflows at the intersection of
EBM and TCM in China and the United States. We highlight opportunities for
introducing VR in today's acupuncture training and treatment workflows, and
discuss two design approaches that build on 11 specific challenges spanning
education, diagnosis, treatment, and communication.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07773" title="Abstract">arXiv:2312.07773</a> [<a href="/pdf/2312.07773" title="Download PDF">pdf</a>, <a href="/format/2312.07773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exponential Asymptotics using Numerical Rational Approximation in Linear  Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lustri%2C+C+J">Christopher J. Lustri</a>, 
<a href="/search/math?searchtype=author&query=Crew%2C+S+C">Samuel C. Crew</a>, 
<a href="/search/math?searchtype=author&query=Chapman%2C+S+J">S. Jonathan Chapman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 8 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Complex Variables (math.CV)

</div>
<p class="mathjax">Singularly-perturbed ordinary differential equations often exhibit Stokes'
phenomenon, which describes the appearance and disappearance of oscillating
exponentially small terms across curves in the complex plane known as Stokes
curves. These curves originate at singular points in the leading-order solution
to the differential equation. In many important problems, it is impossible to
obtain a closed-form expression for these leading-order solutions, and it is
therefore challenging to locate these singular points. We present evidence that
the analytic leading-order solution of a linear differential equation can be
replaced with a rational approximation based on a numerical leading-order
solution using the adaptive Antoulas-Anderson (AAA) method. We show that the
subsequent exponential asymptotic analysis accurately predicts the
exponentially small behaviour present in the solution. We explore the
limitations of this approach, and show that for sufficiently small values of
the asymptotic parameter, this approach breaks down; however, the range of
validity may be extended by increasing the number of poles in the rational
approximation. We finish by presenting a related nonlinear problem and
discussing the challenges that arise when attempting to apply this method to
nonlinear problems.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07778" title="Abstract">arXiv:2312.07778</a> [<a href="/pdf/2312.07778" title="Download PDF">pdf</a>, <a href="/format/2312.07778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safety-critical Control of Quadrupedal Robots with Rolling Arms for  Autonomous Inspection of Complex Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaemin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jeeseop Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ubellacker%2C+W">Wyatt Ubellacker</a>, 
<a href="/search/cs?searchtype=author&query=Molnar%2C+T+G">Tamas G. Molnar</a>, 
<a href="/search/cs?searchtype=author&query=Ames%2C+A+D">Aaron D. Ames</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a safety-critical control framework tailored for
quadruped robots equipped with a roller arm, particularly when performing
locomotive tasks such as autonomous robotic inspection in complex, multi-tiered
environments. In this study, we consider the problem of operating a quadrupedal
robot in distillation columns, locomoting on column trays and transitioning
between these trays with a roller arm. To address this problem, our framework
encompasses the following key elements: 1) Trajectory generation for seamless
transitions between columns, 2) Foothold re-planning in regions deemed unsafe,
3) Safety-critical control incorporating control barrier functions, 4) Gait
transitions based on safety levels, and 5) A low-level controller. Our
comprehensive framework, comprising these components, enables autonomous and
safe locomotion across multiple layers. We incorporate reduced-order and
full-body models to ensure safety, integrating safety-critical control and
footstep re-planning approaches. We validate the effectiveness of our proposed
framework through practical experiments involving a quadruped robot equipped
with a roller arm, successfully navigating and transitioning between different
levels within the column tray structure.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07779" title="Abstract">arXiv:2312.07779</a> [<a href="/pdf/2312.07779" title="Download PDF">pdf</a>, <a href="/format/2312.07779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tell, don&#x27;t show: Declarative facts influence how LLMs generalize
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meinke%2C+A">Alexander Meinke</a>, 
<a href="/search/cs?searchtype=author&query=Evans%2C+O">Owain Evans</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">We examine how large language models (LLMs) generalize from abstract
declarative statements in their training data. As an illustration, consider an
LLM that is prompted to generate weather reports for London in 2050. One
possibility is that the temperatures in the reports match the mean and variance
of reports from 2023 (i.e. matching the statistics of pretraining). Another
possibility is that the reports predict higher temperatures, by incorporating
declarative statements about climate change from scientific papers written in
2023. An example of such a declarative statement is "global temperatures will
increase by $1^{\circ} \mathrm{C}$ by 2050".
<br />To test the influence of abstract declarative statements, we construct tasks
in which LLMs are finetuned on both declarative and procedural information. We
find that declarative statements influence model predictions, even when they
conflict with procedural information. In particular, finetuning on a
declarative statement $S$ increases the model likelihood for logical
consequences of $S$. The effect of declarative statements is consistent across
three domains: aligning an AI assistant, predicting weather, and predicting
demographic features. Through a series of ablations, we show that the effect of
declarative statements cannot be explained by associative learning based on
matching keywords. Nevertheless, the effect of declarative statements on model
likelihoods is small in absolute terms and increases surprisingly little with
model size (i.e. from 330 million to 175 billion parameters). We argue that
these results have implications for AI risk (in relation to the "treacherous
turn") and for fairness.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07781" title="Abstract">arXiv:2312.07781</a> [<a href="/pdf/2312.07781" title="Download PDF">pdf</a>, <a href="/ps/2312.07781" title="Download PostScript">ps</a>, <a href="/format/2312.07781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combining propensity score methods with variational autoencoders for  generating synthetic data in presence of latent sub-groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farhadyar%2C+K">Kiana Farhadyar</a>, 
<a href="/search/cs?searchtype=author&query=Bonofiglio%2C+F">Federico Bonofiglio</a>, 
<a href="/search/cs?searchtype=author&query=Hackenberg%2C+M">Maren Hackenberg</a>, 
<a href="/search/cs?searchtype=author&query=Zoeller%2C+D">Daniela Zoeller</a>, 
<a href="/search/cs?searchtype=author&query=Binder%2C+H">Harald Binder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In settings requiring synthetic data generation based on a clinical cohort,
e.g., due to data protection regulations, heterogeneity across individuals
might be a nuisance that we need to control or faithfully preserve. The sources
of such heterogeneity might be known, e.g., as indicated by sub-groups labels,
or might be unknown and thus reflected only in properties of distributions,
such as bimodality or skewness. We investigate how such heterogeneity can be
preserved and controlled when obtaining synthetic data from variational
autoencoders (VAEs), i.e., a generative deep learning technique that utilizes a
low-dimensional latent representation. To faithfully reproduce unknown
heterogeneity reflected in marginal distributions, we propose to combine VAEs
with pre-transformations. For dealing with known heterogeneity due to
sub-groups, we complement VAEs with models for group membership, specifically
from propensity score regression. The evaluation is performed with a realistic
simulation design that features sub-groups and challenging marginal
distributions. The proposed approach faithfully recovers the latter, compared
to synthetic data approaches that focus purely on marginal distributions.
Propensity scores add complementary information, e.g., when visualized in the
latent space, and enable sampling of synthetic data with or without sub-group
specific characteristics. We also illustrate the proposed approach with real
data from an international stroke trial that exhibits considerable distribution
differences between study sites, in addition to bimodality. These results
indicate that describing heterogeneity by statistical approaches, such as
propensity score regression, might be more generally useful for complementing
generative deep learning for obtaining synthetic data that faithfully reflects
structure from clinical cohorts.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07783" title="Abstract">arXiv:2312.07783</a> [<a href="/pdf/2312.07783" title="Download PDF">pdf</a>, <a href="/format/2312.07783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BarraCUDA: Bringing Electromagnetic Side Channel Into Play to Steal the  Weights of Neural Networks from NVIDIA GPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Horvath%2C+P">Peter Horvath</a>, 
<a href="/search/cs?searchtype=author&query=Chmielewski%2C+L">Lukasz Chmielewski</a>, 
<a href="/search/cs?searchtype=author&query=Weissbart%2C+L">Leo Weissbart</a>, 
<a href="/search/cs?searchtype=author&query=Batina%2C+L">Lejla Batina</a>, 
<a href="/search/cs?searchtype=author&query=Yarom%2C+Y">Yuval Yarom</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Over the last decade, applications of neural networks have spread to cover
all aspects of life. A large number of companies base their businesses on
building products that use neural networks for tasks such as face recognition,
machine translation, and autonomous cars. They are being used in safety and
security-critical applications like high definition maps and medical
wristbands, or in globally used products like Google Translate and ChatGPT.
Much of the intellectual property underpinning these products is encoded in the
exact configuration of the neural networks. Consequently, protecting these is
of utmost priority to businesses. At the same time, many of these products need
to operate under a strong threat model, in which the adversary has unfettered
physical control of the product.
<br />Past work has demonstrated that with physical access, attackers can reverse
engineer neural networks that run on scalar microcontrollers, like ARM Cortex
M3. However, for performance reasons, neural networks are often implemented on
highly-parallel general purpose graphics processing units (GPGPUs), and so far,
attacks on these have only recovered course-grained information on the
structure of the neural network, but failed to retrieve the weights and biases.
<br />In this work, we present BarraCUDA, a novel attack on GPGPUs that can
completely extract the parameters of neural networks. BarraCUDA uses
correlation electromagnetic analysis to recover the weights and biases in the
convolutional layers of neural networks. We use BarraCUDA to attack the popular
NVIDIA Jetson Nano device, demonstrating successful parameter extraction of
neural networks in a highly parallel and noisy environment.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07786" title="Abstract">arXiv:2312.07786</a> [<a href="/pdf/2312.07786" title="Download PDF">pdf</a>, <a href="/format/2312.07786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Data-driven Method for Safety-critical Control: Designing Control  Barrier Functions from State Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaemin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jeeseop Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ames%2C+A+D">Aaron D. Ames</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper addresses the challenge of integrating explicit hard constraints
into the control barrier function (CBF) framework for ensuring safety in
autonomous systems, including robots. We propose a novel data-driven method to
derive CBFs from these hard constraints in practical scenarios. Our approach
assumes that the forward invariant safe set is either a subset or equal to the
constrained set. The process consists of two main steps. First, we randomly
sample states within the constraint boundaries and identify inputs meeting the
time derivative criteria of the hard constraint; this iterative process
converges using the Jaccard index. Next, we formulate CBFs that enclose the
safe set using the sampled boundaries. This enables the creation of a
control-invariant safe set, approaching the maximum attainable level of control
invariance. This approach, therefore, addresses the complexities posed by
complex autonomous systems with constrained control input spaces, culminating
in a control-invariant safe set that closely approximates the maximal control
invariant set.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07787" title="Abstract">arXiv:2312.07787</a> [<a href="/pdf/2312.07787" title="Download PDF">pdf</a>, <a href="/format/2312.07787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> INRISCO: INcident monitoRing In Smart COmmunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Igartua%2C+M+A">M&#xf3;nica Aguilar Igartua</a>, 
<a href="/search/cs?searchtype=author&query=Almenares%2C+F">Florina Almenares</a>, 
<a href="/search/cs?searchtype=author&query=Redondo%2C+R+P+D">Rebeca P. D&#xed;az Redondo</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADn%2C+M+I">Manuela I. Mart&#xed;n</a>, 
<a href="/search/cs?searchtype=author&query=Forn%C3%A9%2C+J">Jordi Forn&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Campo%2C+C">Celeste Campo</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez%2C+A">Ana Fern&#xe1;ndez</a>, 
<a href="/search/cs?searchtype=author&query=de+la+Cruz%2C+L+J">Luis J. de la Cruz</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa-Rubio%2C+C">Carlos Garc&#xed;a-Rubio</a>, 
<a href="/search/cs?searchtype=author&query=Mar%C3%ADnn%2C+A">Andr&#xe9;s Mar&#xed;nn</a>, 
<a href="/search/cs?searchtype=author&query=Mezher%2C+A+M">Ahmad Mohamad Mezher</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz%2C+D">Daniel D&#xed;az</a>, 
<a href="/search/cs?searchtype=author&query=Cerezo%2C+H">H&#xe9;ctor Cerezo</a>, 
<a href="/search/cs?searchtype=author&query=Rebollo-Monedero%2C+D">David Rebollo-Monedero</a>, 
<a href="/search/cs?searchtype=author&query=Arias%2C+P">Patricia Arias</a>, 
<a href="/search/cs?searchtype=author&query=Rico%2C+F">Francisco Rico</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EEE Access, vol. 8, 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Major advances in information and communication technologies (ICTs) make
citizens to be considered as sensors in motion. Carrying their mobile devices,
moving in their connected vehicles or actively participating in social
networks, citizens provide a wealth of information that, after properly
processing, can support numerous applications for the benefit of the community.
In the context of smart communities, the INRISCO proposal intends for (i) the
early detection of abnormal situations in cities (i.e., incidents), (ii) the
analysis of whether, according to their impact, those incidents are really
adverse for the community; and (iii) the automatic actuation by dissemination
of appropriate information to citizens and authorities. Thus, INRISCO will
identify and report on incidents in traffic (jam, accident) or public
infrastructure (e.g., works, street cut), the occurrence of specific events
that affect other citizens life (e.g., demonstrations, concerts), or
environmental problems (e.g., pollution, bad weather). It is of particular
interest to this proposal the identification of incidents with a social and
economic impact, which affects the quality of life of citizens.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07789" title="Abstract">arXiv:2312.07789</a> [<a href="/pdf/2312.07789" title="Download PDF">pdf</a>, <a href="/ps/2312.07789" title="Download PostScript">ps</a>, <a href="/format/2312.07789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impact of Computer-Based Assessments on the Science&#x27;s Ranks of Secondary  Students
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rodr%C3%ADguez%2C+E+A+S">Eduardo A. Soto Rodr&#xed;guez</a>, 
<a href="/search/cs?searchtype=author&query=Vilas%2C+A+F">Ana Fern&#xe1;ndez Vilas</a>, 
<a href="/search/cs?searchtype=author&query=Redondo%2C+R+P+D">Rebeca P. D&#xed;az Redondo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Appl. Sci. 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">This study reports the impact of examining either with digital or paper-based
tests in science subjects taught across the second-ary level. With our method,
we compare the percentile ranking scores of two cohorts earned in computer- and
paper-based teacher-made assessments to find signals of a testing mode effect.
It was found that overall, at cohort and gender levels, pupils were
rank-ordered equivalently in both testing modes. Furthermore, females and
top-achieving pupils were the two subgroups where the differences between modes
were smaller. The practical implications of these findings are discussed from
the lens of a case study and the doubt about whether regular schools could
afford to deliver high-stakes computer-based tests.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07790" title="Abstract">arXiv:2312.07790</a> [<a href="/pdf/2312.07790" title="Download PDF">pdf</a>, <a href="/ps/2312.07790" title="Download PostScript">ps</a>, <a href="/format/2312.07790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characteristic Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhongjie Yu</a>, 
<a href="/search/cs?searchtype=author&query=Trapp%2C+M">Martin Trapp</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+K">Kristian Kersting</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">In many real-world scenarios, it is crucial to be able to reliably and
efficiently reason under uncertainty while capturing complex relationships in
data. Probabilistic circuits (PCs), a prominent family of tractable
probabilistic models, offer a remedy to this challenge by composing simple,
tractable distributions into a high-dimensional probability distribution.
However, learning PCs on heterogeneous data is challenging and densities of
some parametric distributions are not available in closed form, limiting their
potential use. We introduce characteristic circuits (CCs), a family of
tractable probabilistic models providing a unified formalization of
distributions over heterogeneous data in the spectral domain. The one-to-one
relationship between characteristic functions and probability measures enables
us to learn high-dimensional distributions on heterogeneous data domains and
facilitates efficient probabilistic inference even when no closed-form density
function is available. We show that the structure and parameters of CCs can be
learned efficiently from the data and find that CCs outperform state-of-the-art
density estimators for heterogeneous data domains on common benchmark data
sets.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07795" title="Abstract">arXiv:2312.07795</a> [<a href="/pdf/2312.07795" title="Download PDF">pdf</a>, <a href="/format/2312.07795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Traffic Signal Control Using Lightweight Transformers: An  Offline-to-Online RL Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xingshuai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Di Wu</a>, 
<a href="/search/cs?searchtype=author&query=Boulet%2C+B">Benoit Boulet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Efficient traffic signal control is critical for reducing traffic congestion
and improving overall transportation efficiency. The dynamic nature of traffic
flow has prompted researchers to explore Reinforcement Learning (RL) for
traffic signal control (TSC). Compared with traditional methods, RL-based
solutions have shown preferable performance. However, the application of
RL-based traffic signal controllers in the real world is limited by the low
sample efficiency and high computational requirements of these solutions. In
this work, we propose DTLight, a simple yet powerful lightweight Decision
Transformer-based TSC method that can learn policy from easily accessible
offline datasets. DTLight novelly leverages knowledge distillation to learn a
lightweight controller from a well-trained larger teacher model to reduce
implementation computation. Additionally, it integrates adapter modules to
mitigate the expenses associated with fine-tuning, which makes DTLight
practical for online adaptation with minimal computation and only a few
fine-tuning steps during real deployment. Moreover, DTLight is further enhanced
to be more applicable to real-world TSC problems. Extensive experiments on
synthetic and real-world scenarios show that DTLight pre-trained purely on
offline datasets can outperform state-of-the-art online RL-based methods in
most scenarios. Experiment results also show that online fine-tuning further
improves the performance of DTLight by up to 42.6% over the best online RL
baseline methods. In this work, we also introduce Datasets specifically
designed for TSC with offline RL (referred to as DTRL). Our datasets and code
are publicly available.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07796" title="Abstract">arXiv:2312.07796</a> [<a href="/pdf/2312.07796" title="Download PDF">pdf</a>, <a href="/ps/2312.07796" title="Download PostScript">ps</a>, <a href="/format/2312.07796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing Retrieval-Augmented Generation (RAG) for Uncovering Knowledge  Gaps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hurtado%2C+J+F">Joan Figuerola Hurtado</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">The paper presents a methodology for uncovering knowledge gaps on the
internet using the Retrieval Augmented Generation (RAG) model. By simulating
user search behaviour, the RAG system identifies and addresses gaps in
information retrieval systems. The study demonstrates the effectiveness of the
RAG system in generating relevant suggestions with a consistent accuracy of
93%. The methodology can be applied in various fields such as scientific
discovery, educational enhancement, research development, market analysis,
search engine optimisation, and content development. The results highlight the
value of identifying and understanding knowledge gaps to guide future
endeavours.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07797" title="Abstract">arXiv:2312.07797</a> [<a href="/pdf/2312.07797" title="Download PDF">pdf</a>, <a href="/ps/2312.07797" title="Download PostScript">ps</a>, <a href="/format/2312.07797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sentiment analysis in Tourism: Fine-tuning BERT or sentence embeddings  concatenation?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bouabdallaoui%2C+I">Ibrahim Bouabdallaoui</a>, 
<a href="/search/cs?searchtype=author&query=Guerouate%2C+F">Fatima Guerouate</a>, 
<a href="/search/cs?searchtype=author&query=Bouhaddour%2C+S">Samya Bouhaddour</a>, 
<a href="/search/cs?searchtype=author&query=Saadi%2C+C">Chaimae Saadi</a>, 
<a href="/search/cs?searchtype=author&query=Sbihi%2C+M">Mohammed Sbihi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted manuscript at ICMECE 2022 Conference (Barcelona, Spain)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Undoubtedly that the Bidirectional Encoder representations from Transformers
is the most powerful technique in making Natural Language Processing tasks such
as Named Entity Recognition, Question &amp; Answers or Sentiment Analysis, however,
the use of traditional techniques remains a major potential for the improvement
of recent models, in particular word tokenization techniques and embeddings,
but also the improvement of neural network architectures which are now the core
of each architecture. recent. In this paper, we conduct a comparative study
between Fine-Tuning the Bidirectional Encoder Representations from Transformers
and a method of concatenating two embeddings to boost the performance of a
stacked Bidirectional Long Short-Term Memory-Bidirectional Gated Recurrent
Units model; these two approaches are applied in the context of sentiment
analysis of shopping places in Morocco. A search for the best learning rate was
made at the level of the two approaches, and a comparison of the best
optimizers was made for each sentence embedding combination with regard to the
second approach.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07802" title="Abstract">arXiv:2312.07802</a> [<a href="/pdf/2312.07802" title="Download PDF">pdf</a>, <a href="/format/2312.07802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimation of embedding vectors in high dimensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azar%2C+G+A">Golara Ahmadi Azar</a>, 
<a href="/search/cs?searchtype=author&query=Emami%2C+M">Melika Emami</a>, 
<a href="/search/cs?searchtype=author&query=Fletcher%2C+A">Alyson Fletcher</a>, 
<a href="/search/cs?searchtype=author&query=Rangan%2C+S">Sundeep Rangan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Machine Learning (stat.ML)

</div>
<p class="mathjax">Embeddings are a basic initial feature extraction step in many machine
learning models, particularly in natural language processing. An embedding
attempts to map data tokens to a low-dimensional space where similar tokens are
mapped to vectors that are close to one another by some metric in the embedding
space. A basic question is how well can such embedding be learned? To study
this problem, we consider a simple probability model for discrete data where
there is some "true" but unknown embedding where the correlation of random
variables is related to the similarity of the embeddings. Under this model, it
is shown that the embeddings can be learned by a variant of low-rank
approximate message passing (AMP) method. The AMP approach enables precise
predictions of the accuracy of the estimation in certain high-dimensional
limits. In particular, the methodology provides insight on the relations of key
parameters such as the number of samples per value, the frequency of the terms,
and the strength of the embedding correlation on the probability distribution.
Our theoretical findings are validated by simulations on both synthetic data
and real text data.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07803" title="Abstract">arXiv:2312.07803</a> [<a href="/pdf/2312.07803" title="Download PDF">pdf</a>, <a href="/format/2312.07803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feasible Space Monitoring for Multiple Control Barrier Functions with  application to Large Scale Indoor Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parwana%2C+H">Hardik Parwana</a>, 
<a href="/search/cs?searchtype=author&query=Black%2C+M">Mitchell Black</a>, 
<a href="/search/cs?searchtype=author&query=Hoxha%2C+B">Bardh Hoxha</a>, 
<a href="/search/cs?searchtype=author&query=Okamoto%2C+H">Hideki Okamoto</a>, 
<a href="/search/cs?searchtype=author&query=Fainekos%2C+G">Georgios Fainekos</a>, 
<a href="/search/cs?searchtype=author&query=Prokhorov%2C+D">Danil Prokhorov</a>, 
<a href="/search/cs?searchtype=author&query=Panagou%2C+D">Dimitra Panagou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Quadratic programs (QP) subject to multiple time-dependent control barrier
function (CBF) based constraints have been used to design safety-critical
controllers. However, ensuring the existence of a solution at all times to the
QP subject to multiple CBF constraints is non-trivial. We quantify the feasible
solution space of the QP in terms of its volume. We introduce a novel feasible
space volume monitoring control barrier function that promotes compatibility of
barrier functions and, hence, existence of a solution at all times. We show
empirically that our approach not only enhances feasibility but also exhibits
reduced sensitivity to changes in the hyperparameters such as gains of nominal
controller. Finally, paired with a global planner, we evaluate our controller
for navigation among humans in the AWS Hospital gazebo environment. The
proposed controller is demonstrated to outperform the standard CBF-QP
controller in maintaining feasibility.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07804" title="Abstract">arXiv:2312.07804</a> [<a href="/pdf/2312.07804" title="Download PDF">pdf</a>, <a href="/format/2312.07804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Visualization via Low-Dimensional Posterior Projections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yair%2C+O">Omer Yair</a>, 
<a href="/search/cs?searchtype=author&query=Nehme%2C+E">Elias Nehme</a>, 
<a href="/search/cs?searchtype=author&query=Michaeli%2C+T">Tomer Michaeli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In ill-posed inverse problems, it is commonly desirable to obtain insight
into the full spectrum of plausible solutions, rather than extracting only a
single reconstruction. Information about the plausible solutions and their
likelihoods is encoded in the posterior distribution. However, for
high-dimensional data, this distribution is challenging to visualize. In this
work, we introduce a new approach for estimating and visualizing posteriors by
employing energy-based models (EBMs) over low-dimensional subspaces.
Specifically, we train a conditional EBM that receives an input measurement and
a set of directions that span some low-dimensional subspace of solutions, and
outputs the probability density function of the posterior within that space. We
demonstrate the effectiveness of our method across a diverse range of datasets
and image restoration problems, showcasing its strength in uncertainty
quantification and visualization. As we show, our method outperforms a baseline
that projects samples from a diffusion-based posterior sampler, while being
orders of magnitude faster. Furthermore, it is more accurate than a baseline
that assumes a Gaussian posterior.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07806" title="Abstract">arXiv:2312.07806</a> [<a href="/pdf/2312.07806" title="Download PDF">pdf</a>, <a href="/format/2312.07806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextually Affinitive Neighborhood Refinery for Deep Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chunlin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Ye Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingya Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Previous endeavors in self-supervised learning have enlightened the research
of deep clustering from an instance discrimination perspective. Built upon this
foundation, recent studies further highlight the importance of grouping
semantically similar instances. One effective method to achieve this is by
promoting the semantic structure preserved by neighborhood consistency.
However, the samples in the local neighborhood may be limited due to their
close proximity to each other, which may not provide substantial and diverse
supervision signals. Inspired by the versatile re-ranking methods in the
context of image retrieval, we propose to employ an efficient online re-ranking
process to mine more informative neighbors in a Contextually Affinitive
(ConAff) Neighborhood, and then encourage the cross-view neighborhood
consistency. To further mitigate the intrinsic neighborhood noises near cluster
boundaries, we propose a progressively relaxed boundary filtering strategy to
circumvent the issues brought by noisy neighbors. Our method can be easily
integrated into the generic self-supervised frameworks and outperforms the
state-of-the-art methods on several popular benchmarks.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07813" title="Abstract">arXiv:2312.07813</a> [<a href="/pdf/2312.07813" title="Download PDF">pdf</a>, <a href="/format/2312.07813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On a Foundation Model for Operating Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saxena%2C+D">Divyanshu Saxena</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+N">Nihal Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Donghyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Dwivedula%2C+R">Rohit Dwivedula</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiayi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chenxi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ravula%2C+S">Sriram Ravula</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zichao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Akella%2C+A">Aditya Akella</a>, 
<a href="/search/cs?searchtype=author&query=Angel%2C+S">Sebastian Angel</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+J">Joydeep Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhuri%2C+S">Swarat Chaudhuri</a>, 
<a href="/search/cs?searchtype=author&query=Dillig%2C+I">Isil Dillig</a>, 
<a href="/search/cs?searchtype=author&query=Dimakis%2C+A">Alex Dimakis</a>, 
<a href="/search/cs?searchtype=author&query=Godfrey%2C+P+B">P. Brighten Godfrey</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Daehyeok Kim</a>, 
<a href="/search/cs?searchtype=author&query=Rossbach%2C+C">Chris Rossbach</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Machine Learning for Systems Workshop at 37th NeurIPS Conference, 2023, New Orleans, LA, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Operating Systems (cs.OS)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper lays down the research agenda for a domain-specific foundation
model for operating systems (OSes). Our case for a foundation model revolves
around the observations that several OS components such as CPU, memory, and
network subsystems are interrelated and that OS traces offer the ideal dataset
for a foundation model to grasp the intricacies of diverse OS components and
their behavior in varying environments and workloads. We discuss a wide range
of possibilities that then arise, from employing foundation models as policy
agents to utilizing them as generators and predictors to assist traditional OS
control algorithms. Our hope is that this paper spurs further research into OS
foundation models and creating the next generation of operating systems for the
evolving computing landscape.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07814" title="Abstract">arXiv:2312.07814</a> [<a href="/pdf/2312.07814" title="Download PDF">pdf</a>, <a href="/format/2312.07814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Foundational Multimodal Vision Language AI Assistant for Human  Pathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+M+Y">Ming Y. Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bowen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Williamson%2C+D+F+K">Drew F. K. Williamson</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R+J">Richard J. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ikamura%2C+K">Kenji Ikamura</a>, 
<a href="/search/cs?searchtype=author&query=Gerber%2C+G">Georg Gerber</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+I">Ivy Liang</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+L+P">Long Phi Le</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+T">Tong Ding</a>, 
<a href="/search/cs?searchtype=author&query=Parwani%2C+A+V">Anil V Parwani</a>, 
<a href="/search/cs?searchtype=author&query=Mahmood%2C+F">Faisal Mahmood</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The field of computational pathology has witnessed remarkable progress in the
development of both task-specific predictive models and task-agnostic
self-supervised vision encoders. However, despite the explosive growth of
generative artificial intelligence (AI), there has been limited study on
building general purpose, multimodal AI assistants tailored to pathology. Here
we present PathChat, a vision-language generalist AI assistant for human
pathology using an in-house developed foundational vision encoder pretrained on
100 million histology images from over 100,000 patient cases and 1.18 million
pathology image-caption pairs. The vision encoder is then combined with a
pretrained large language model and the whole system is finetuned on over
250,000 diverse disease agnostic visual language instructions. We compare
PathChat against several multimodal vision language AI assistants as well as
GPT4V, which powers the commercially available multimodal general purpose AI
assistant ChatGPT-4. When relevant clinical context is provided with the
histology image, PathChat achieved a diagnostic accuracy of 87% on
multiple-choice questions based on publicly available cases of diverse tissue
origins and disease models. Additionally, using open-ended questions and human
expert evaluation, we found that overall PathChat produced more accurate and
pathologist-preferable responses to diverse queries related to pathology. As an
interactive and general vision language AI assistant that can flexibly handle
both visual and natural language inputs, PathChat can potentially find
impactful applications in pathology education, research, and human-in-the-loop
clinical decision making.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07818" title="Abstract">arXiv:2312.07818</a> [<a href="/pdf/2312.07818" title="Download PDF">pdf</a>, <a href="/ps/2312.07818" title="Download PostScript">ps</a>, <a href="/format/2312.07818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brain Computer Interface Technology for Future Battlefield
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xiong%2C+G">Guodong Xiong</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+X">Xinyan Ma</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/eess?searchtype=author&query=Cao%2C+J">Jiaqi Cao</a>, 
<a href="/search/eess?searchtype=author&query=Zhong%2C+J">Jian Zhong</a>, 
<a href="/search/eess?searchtype=author&query=Su%2C+Y">Yicong Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">With the development of artificial intelligence and unmanned equipment,
human-machine hybrid formations will be the main focus in future combat
formations. With the development of big data and various situational awareness
technologies, while enhancing the breadth and depth of information,
decision-making has also become more complex. The operation mode of existing
unmanned equipment often requires complex manual input, which is not conducive
to the battlefield environment. How to reduce the cognitive load of information
exchange between soldiers and various unmanned equipment is an important issue
in future intelligent warfare. This paper proposes a brain computer interface
communication system for soldier combat, which takes into account the
characteristics of soldier combat scenarios in design. The stimulation paradigm
is combined with helmets, portable computers, and firearms, and brain computer
interface technology is used to achieve fast, barrier free, and hands-free
communication between humans and machines. Intelligent algorithms are combined
to assist decision-making in fully perceiving and fusing situational
information on the battlefield, and a large amount of data is processed
quickly, understanding and integrating a large amount of data from human and
machine networks, achieving real-time perception of battlefield information,
making intelligent decisions, and achieving the effect of direct control of
drone swarms and other equipment by the human brain to assist in soldier
scenarios.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07819" title="Abstract">arXiv:2312.07819</a> [<a href="/pdf/2312.07819" title="Download PDF">pdf</a>, <a href="/format/2312.07819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Native Language Identification with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Salle%2C+A">Alexandre Salle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present the first experiments on Native Language Identification (NLI)
using LLMs such as GPT-4. NLI is the task of predicting a writer's first
language by analyzing their writings in a second language, and is used in
second language acquisition and forensic linguistics. Our results show that GPT
models are proficient at NLI classification, with GPT-4 setting a new
performance record of 91.7% on the benchmark TOEFL11 test set in a zero-shot
setting. We also show that unlike previous fully-supervised settings, LLMs can
perform NLI without being limited to a set of known classes, which has
practical implications for real-world applications. Finally, we also show that
LLMs can provide justification for their choices, providing reasoning based on
spelling errors, syntactic patterns, and usage of directly translated
linguistic patterns.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07822" title="Abstract">arXiv:2312.07822</a> [<a href="/pdf/2312.07822" title="Download PDF">pdf</a>, <a href="/format/2312.07822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prototypical Self-Explainable Models Without Re-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gautam%2C+S">Srishti Gautam</a>, 
<a href="/search/cs?searchtype=author&query=Boubekki%2C+A">Ahcene Boubekki</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B6hne%2C+M+M+C">Marina M. C. H&#xf6;hne</a>, 
<a href="/search/cs?searchtype=author&query=Kampffmeyer%2C+M+C">Michael C. Kampffmeyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Explainable AI (XAI) has unfolded in two distinct research directions with,
on the one hand, post-hoc methods that explain the predictions of a pre-trained
black-box model and, on the other hand, self-explainable models (SEMs) which
are trained directly to provide explanations alongside their predictions. While
the latter is preferred in most safety-critical scenarios, post-hoc approaches
have received the majority of attention until now, owing to their simplicity
and ability to explain base models without retraining. Current SEMs instead,
require complex architectures and heavily regularized loss functions, thus
necessitating specific and costly training. To address this shortcoming and
facilitate wider use of SEMs, we propose a simple yet efficient universal
method called KMEx (K-Means Explainer), which can convert any existing
pre-trained model into a prototypical SEM. The motivation behind KMEx is to
push towards more transparent deep learning-based decision-making via
class-prototype-based explanations that are guaranteed to be diverse and
trustworthy without retraining the base model. We compare models obtained from
KMEx to state-of-the-art SEMs using an extensive qualitative evaluation to
highlight the strengths and weaknesses of each model, further paving the way
toward a more reliable and objective evaluation of SEMs.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07823" title="Abstract">arXiv:2312.07823</a> [<a href="/pdf/2312.07823" title="Download PDF">pdf</a>, <a href="/format/2312.07823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic-Lens: Instance-Centric Semantic Alignment for Video  Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Q">Qi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Meiqin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jian Jin</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+C">Chao Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">As a critical clue of video super-resolution (VSR), inter-frame alignment
significantly impacts overall performance. However, accurate pixel-level
alignment is a challenging task due to the intricate motion interweaving in the
video. In response to this issue, we introduce a novel paradigm for VSR named
\textbf{Semantic Lens}, predicated on semantic priors drawn from degraded
videos. Specifically, video is modeled as instances, events, and scenes via a
Semantic Extractor. Those semantics assist the Pixel Enhancer in understanding
the recovered contents and generating more realistic visual results. The
distilled global semantics embody the scene information of each frame, while
the instance-specific semantics assemble the spatial-temporal contexts related
to each instance. Furthermore, we devise a \textbf{S}emantics-\textbf{P}owered
\textbf{A}ttention \textbf{C}ross-\textbf{E}mbedding (SPACE) block to bridge
the pixel-level features with semantic knowledge, composed of a \textbf{G}lobal
\textbf{P}erspective \textbf{S}hifter (GPS) and an \textbf{I}nstance-Specific
\textbf{S}emantic \textbf{E}mbedding \textbf{E}ncoder (ISEE). Concretely, the
GPS module generates pairs of affine transformation parameters for pixel-level
feature modulation conditioned on global semantics. After that, the ISEE module
harnesses the attention mechanism to align the adjacent frames in the
instance-centric semantic space. In addition, we incorporate a simple yet
effective pre-alignment module to alleviate the difficulty of model training.
Extensive experiments demonstrate the superiority of our model over existing
state-of-the-art VSR methods.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07824" title="Abstract">arXiv:2312.07824</a> [<a href="/pdf/2312.07824" title="Download PDF">pdf</a>, <a href="/format/2312.07824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Deep Learning-Based System for Automatic Case Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duong%2C+M">Minh Duong</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+L">Long Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Vuong%2C+Y">Yen Vuong</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Trong Le</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Ha-Thanh Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper presents a deep learning-based system for efficient automatic case
summarization. Leveraging state-of-the-art natural language processing
techniques, the system offers both supervised and unsupervised methods to
generate concise and relevant summaries of lengthy legal case documents. The
user-friendly interface allows users to browse the system's database of legal
case documents, select their desired case, and choose their preferred
summarization method. The system generates comprehensive summaries for each
subsection of the legal text as well as an overall summary. This demo
streamlines legal case document analysis, potentially benefiting legal
professionals by reducing workload and increasing efficiency. Future work will
focus on refining summarization techniques and exploring the application of our
methods to other types of legal texts.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07826" title="Abstract">arXiv:2312.07826</a> [<a href="/pdf/2312.07826" title="Download PDF">pdf</a>, <a href="/ps/2312.07826" title="Download PostScript">ps</a>, <a href="/format/2312.07826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Path Tracking with DYC and MPC using LSTM Based Tire Force  Estimator for Four-wheel Independent Steering and Driving Vehicle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Sungjin Lim</a>, 
<a href="/search/cs?searchtype=author&query=Sadiq%2C+B">Bilal Sadiq</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yongsik Jin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sangho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+G">Gyeungho Choi</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+K">Kanghyun Nam</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+Y">Yongseob Lim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Active collision avoidance system plays a crucial role in ensuring the
lateral safety of autonomous vehicles, and it is primarily related to path
planning and tracking control algorithms. In particular, the direct yaw-moment
control (DYC) system can significantly improve the lateral stability of a
vehicle in environments with sudden changes in road conditions. In order to
apply the DYC algorithm, it is very important to accurately consider the
properties of tire forces with complex nonlinearity for control to ensure the
lateral stability of the vehicle. In this study, longitudinal and lateral tire
forces for safety path tracking were simultaneously estimated using a long
short-term memory (LSTM) neural network based estimator. Furthermore, to
improve path tracking performance in case of sudden changes in road conditions,
a system has been developed by combining 4-wheel independent steering (4WIS)
model predictive control (MPC) and 4-wheel independent drive (4WID) direct
yaw-moment control (DYC). The estimation performance of the extended Kalman
filter (EKF), which are commonly used for tire force estimation, was compared.
In addition, the estimated longitudinal and lateral tire forces of each wheel
were applied to the proposed system, and system verification was performed
through simulation using a vehicle dynamics simulator. Consequently, the
proposed method, the integrated path tracking algorithm with DYC and MPC using
the LSTM based estimator, was validated to significantly improve the vehicle
stability in suddenly changing road conditions.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07827" title="Abstract">arXiv:2312.07827</a> [<a href="/pdf/2312.07827" title="Download PDF">pdf</a>, <a href="/format/2312.07827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximate Fully Dynamic Directed Densest Subgraph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Richard Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We give a fully dynamic algorithm maintaining a $(1-\varepsilon)$-approximate
directed densest subgraph in $\tilde{O}(\log^3(n)/\varepsilon^6)$ amortized
time or $\tilde{O}(\log^4(n)/\varepsilon^7)$ per edge update (where $\tilde{O}$
hides $\log\log$ factors), based on earlier work by Chekuri and Quanrud
[<a href="/abs/2210.02611">arXiv:2210.02611</a>]. This result improves on earlier work done by Sawlani and
Wang [<a href="/abs/1907.03037">arXiv:1907.03037</a>], which guarantees $O(\log^5(n)/\varepsilon^7)$ worst
case time for edge insertions and deletions.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07828" title="Abstract">arXiv:2312.07828</a> [<a href="/pdf/2312.07828" title="Download PDF">pdf</a>, <a href="/format/2312.07828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Exploration in Reinforcement Learning: Training Backup Control  Barrier Functions with Zero Training Time Safety Violations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rabiee%2C+P">Pedram Rabiee</a>, 
<a href="/search/eess?searchtype=author&query=Safari%2C+A">Amirsaeid Safari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint submitted to L4DC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Safe reinforcement learning (RL) aims to satisfy safety constraints during
training. However, guaranteeing safety during training remained a challenging
problem. This paper presents a novel framework that integrates Backup Control
Barrier Functions (BCBFs) with reinforcement learning (RL) to enable safe
exploration called RLBUS: Reinforcement Learning Backup Shield. BCBFs
incorporate backup controllers that predict a system's finite-time response,
facilitating online optimization of a control policy that maintains the forward
invariance of a safe subset, while satisfying actuator constraints. Building on
the soft-minimum/soft-maximum CBF method from prior work, which ensures
feasibility and continuity of the BCBF with multiple backup controllers, this
paper proposes integrating these BCBFs with RL. This framework leverages RL to
learn a better backup policy to enlarge the forward invariant set, while
guaranteeing safety during training. By combining backup controllers and RL,
the approach provides safety and feasibility guarantees during training and
enables safe online exploration with zero training-time safety violations. The
method is demonstrated on an inverted pendulum example, where expanding the
forward invariant set through RL allows the pendulum to safely explore larger
regions of state space.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07831" title="Abstract">arXiv:2312.07831</a> [<a href="/pdf/2312.07831" title="Download PDF">pdf</a>, <a href="/format/2312.07831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Abusive Span Detection for Vietnamese Narrative Texts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+N">Nhu-Thanh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+K+T">Khoa Thi-Kim Phan</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D">Duc-Vu Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+N+L">Ngan Luu-Thuy Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at SoICT 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Abuse in its various forms, including physical, psychological, verbal,
sexual, financial, and cultural, has a negative impact on mental health.
However, there are limited studies on applying natural language processing
(NLP) in this field in Vietnam. Therefore, we aim to contribute by building a
human-annotated Vietnamese dataset for detecting abusive content in Vietnamese
narrative texts. We sourced these texts from VnExpress, Vietnam's popular
online newspaper, where readers often share stories containing abusive content.
Identifying and categorizing abusive spans in these texts posed significant
challenges during dataset creation, but it also motivated our research. We
experimented with lightweight baseline models by freezing PhoBERT and
XLM-RoBERTa and using their hidden states in a BiLSTM to assess the complexity
of the dataset. According to our experimental results, PhoBERT outperforms
other models in both labeled and unlabeled abusive span detection tasks. These
results indicate that it has the potential for future improvements.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07833" title="Abstract">arXiv:2312.07833</a> [<a href="/pdf/2312.07833" title="Download PDF">pdf</a>, <a href="/format/2312.07833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable Rivers: A Case Study in the Application of Text-to-Image  Generative Models for Earth Sciences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kupferschmidt%2C+C">C Kupferschmidt</a>, 
<a href="/search/cs?searchtype=author&query=Binns%2C+A+D">A.D. Binns</a>, 
<a href="/search/cs?searchtype=author&query=Kupferschmidt%2C+K+L">K.L. Kupferschmidt</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+G+W">G.W Taylor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Text-to-image (TTI) generative models can be used to generate photorealistic
images from a given text-string input. These models offer great potential to
mitigate challenges to the uptake of machine learning in the earth sciences.
However, the rapid increase in their use has raised questions about fairness
and biases, with most research to-date focusing on social and cultural areas
rather than domain-specific considerations. We conducted a case study for the
earth sciences, focusing on the field of fluvial geomorphology, where we
evaluated subject-area specific biases in the training data and downstream
model performance of Stable Diffusion (v1.5). In addition to perpetuating
Western biases, we found that the training data over-represented scenic
locations, such as famous rivers and waterfalls, and showed serious under- and
over-representation of many morphological and environmental terms. Despite
biased training data, we found that with careful prompting, the Stable
Diffusion model was able to generate photorealistic synthetic river images
reproducing many important environmental and morphological characteristics.
Furthermore, conditional control techniques, such as the use of condition maps
with ControlNet were effective for providing additional constraints on output
images. Despite great potential for the use of TTI models in the earth sciences
field, we advocate for caution in sensitive applications, and advocate for
domain-specific reviews of training data and image generation biases to
mitigate perpetuation of existing biases.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07835" title="Abstract">arXiv:2312.07835</a> [<a href="/pdf/2312.07835" title="Download PDF">pdf</a>, <a href="/format/2312.07835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video Dynamics Prior: An Internal Learning Approach for Robust Video  Enhancements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+G">Gaurav Shrivastava</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Ser-Nam Lim</a>, 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+A">Abhinav Shrivastava</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023; Webpage - <a href="http://www.cs.umd.edu/~gauravsh/vdp.html">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we present a novel robust framework for low-level vision
tasks, including denoising, object removal, frame interpolation, and
super-resolution, that does not require any external training data corpus. Our
proposed approach directly learns the weights of neural modules by optimizing
over the corrupted test sequence, leveraging the spatio-temporal coherence and
internal statistics of videos. Furthermore, we introduce a novel spatial
pyramid loss that leverages the property of spatio-temporal patch recurrence in
a video across the different scales of the video. This loss enhances robustness
to unstructured noise in both the spatial and temporal domains. This further
results in our framework being highly robust to degradation in input frames and
yields state-of-the-art results on downstream tasks such as denoising, object
removal, and frame interpolation. To validate the effectiveness of our
approach, we conduct qualitative and quantitative evaluations on standard video
datasets such as DAVIS, UCF-101, and VIMEO90K-T.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07837" title="Abstract">arXiv:2312.07837</a> [<a href="/pdf/2312.07837" title="Download PDF">pdf</a>, <a href="/format/2312.07837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthetic Data: Can We Trust Statistical Estimators?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Decruyenaere%2C+A">Alexander Decruyenaere</a>, 
<a href="/search/cs?searchtype=author&query=Dehaene%2C+H">Heidelinde Dehaene</a>, 
<a href="/search/cs?searchtype=author&query=Rabaey%2C+P">Paloma Rabaey</a>, 
<a href="/search/cs?searchtype=author&query=Polet%2C+C">Christiaan Polet</a>, 
<a href="/search/cs?searchtype=author&query=Decruyenaere%2C+J">Johan Decruyenaere</a>, 
<a href="/search/cs?searchtype=author&query=Vansteelandt%2C+S">Stijn Vansteelandt</a>, 
<a href="/search/cs?searchtype=author&query=Demeester%2C+T">Thomas Demeester</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">The increasing interest in data sharing makes synthetic data appealing.
However, the analysis of synthetic data raises a unique set of methodological
challenges. In this work, we highlight the importance of inferential utility
and provide empirical evidence against naive inference from synthetic data
(that handles these as if they were really observed). We argue that the rate of
false-positive findings (type 1 error) will be unacceptably high, even when the
estimates are unbiased. One of the reasons is the underestimation of the true
standard error, which may even progressively increase with larger sample sizes
due to slower convergence. This is especially problematic for deep generative
models. Before publishing synthetic data, it is essential to develop
statistical inference tools for such data.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07838" title="Abstract">arXiv:2312.07838</a> [<a href="/pdf/2312.07838" title="Download PDF">pdf</a>, <a href="/format/2312.07838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conflict Transformation and Management. From Cognitive Maps to Value  Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tosunlu%2C+B+H">Berkay H. Tosunlu</a>, 
<a href="/search/cs?searchtype=author&query=Guillaume%2C+J+H+A">Joseph H.A. Guillaume</a>, 
<a href="/search/cs?searchtype=author&query=Tsouki%C3%A0s%2C+A">Alexis Tsouki&#xe0;s</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Conflict transformation and management are complex decision processes with
extremely high stakes at hand and could greatly benefit from formal approaches
to decision support. For this purpose we develop a general framework about how
to use problem structuring methods for such purposes. More precisely we show
how to transform cognitive maps to value trees in order to promote a more
design-oriented approach to decision support aiming at constructing innovative
solutions for conflict management purposes. We show that our findings have a
much wider validity since they allow to move from a descriptive representation
of a problem situation to a more prescriptive one using formal procedures and
models.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07841" title="Abstract">arXiv:2312.07841</a> [<a href="/pdf/2312.07841" title="Download PDF">pdf</a>, <a href="/format/2312.07841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Dynamics Under the Unhinged Loss and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanzhang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+D">Deming Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Junjun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xiangyang Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 62 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Recent works have studied implicit biases in deep learning, especially the
behavior of last-layer features and classifier weights. However, they usually
need to simplify the intermediate dynamics under gradient flow or gradient
descent due to the intractability of loss functions and model architectures. In
this paper, we introduce the unhinged loss, a concise loss function, that
offers more mathematical opportunities to analyze the closed-form dynamics
while requiring as few simplifications or assumptions as possible. The unhinged
loss allows for considering more practical techniques, such as time-vary
learning rates and feature normalization. Based on the layer-peeled model that
views last-layer features as free optimization variables, we conduct a thorough
analysis in the unconstrained, regularized, and spherical constrained cases, as
well as the case where the neural tangent kernel remains invariant. To bridge
the performance of the unhinged loss to that of Cross-Entropy (CE), we
investigate the scenario of fixing classifier weights with a specific
structure, (e.g., a simplex equiangular tight frame). Our analysis shows that
these dynamics converge exponentially fast to a solution depending on the
initialization of features and classifier weights. These theoretical results
not only offer valuable insights, including explicit feature regularization and
rescaled learning rates for enhancing practical training with the unhinged
loss, but also extend their applicability to other loss functions. Finally, we
empirically demonstrate these theoretical results and insights through
extensive experiments.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07842" title="Abstract">arXiv:2312.07842</a> [<a href="/pdf/2312.07842" title="Download PDF">pdf</a>, <a href="/format/2312.07842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A hybrid finite element method for moving-habitat models in two spatial  dimensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=MacDonald%2C+J+S">Jane Shaw MacDonald</a>, 
<a href="/search/math?searchtype=author&query=Bourgault%2C+Y">Yves Bourgault</a>, 
<a href="/search/math?searchtype=author&query=Lutscher%2C+F">Frithjof Lutscher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Moving-habitat models track the density of a population whose suitable
habitat shifts as a consequence of climate change. Whereas most previous
studies in this area consider 1-dimensional space, we derive and study a
spatially 2-dimensional moving-habitat model via reaction-diffusion equations.
The population inhabits the whole space. The suitable habitat is a bounded
region where population growth is positive; the unbounded complement of its
closure is unsuitable with negative growth. The interface between the two
habitat types moves, depicting the movement of the suitable habitat poleward.
Detailed modelling of individual movement behaviour induces a nonstandard
discontinuity in the density across the interface. For the corresponding
semi-discretised system we prove well-posedness for a constant shifting
velocity before constructing an implicit-explicit hybrid finite element method.
In this method, a Lagrange multiplier weakly imposes the jump discontinuity
across the interface. For a stationary interface, we derive optimal a priori
error estimates over a conformal mesh with nonconformal discretisation. We
demonstrate with numerical convergence tests that these results hold for the
moving interface. Finally, we demonstrate the strength of our hybrid finite
element method with two biologically motivated cases, one for a domain with a
curved boundary and the other for non-constant shifting velocity.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07843" title="Abstract">arXiv:2312.07843</a> [<a href="/pdf/2312.07843" title="Download PDF">pdf</a>, <a href="/ps/2312.07843" title="Download PostScript">ps</a>, <a href="/format/2312.07843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foundation Models in Robotics: Applications, Challenges, and the Future
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Firoozi%2C+R">Roya Firoozi</a>, 
<a href="/search/cs?searchtype=author&query=Tucker%2C+J">Johnathan Tucker</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+S">Stephen Tian</a>, 
<a href="/search/cs?searchtype=author&query=Majumdar%2C+A">Anirudha Majumdar</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiankai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuke Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shuran Song</a>, 
<a href="/search/cs?searchtype=author&query=Kapoor%2C+A">Ashish Kapoor</a>, 
<a href="/search/cs?searchtype=author&query=Hausman%2C+K">Karol Hausman</a>, 
<a href="/search/cs?searchtype=author&query=Ichter%2C+B">Brian Ichter</a>, 
<a href="/search/cs?searchtype=author&query=Driess%2C+D">Danny Driess</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Schwager%2C+M">Mac Schwager</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We survey applications of pretrained foundation models in robotics.
Traditional deep learning models in robotics are trained on small datasets
tailored for specific tasks, which limits their adaptability across diverse
applications. In contrast, foundation models pretrained on internet-scale data
appear to have superior generalization capabilities, and in some instances
display an emergent ability to find zero-shot solutions to problems that are
not present in the training data. Foundation models may hold the potential to
enhance various components of the robot autonomy stack, from perception to
decision-making and control. For example, large language models can generate
code or provide common sense reasoning, while vision-language models enable
open-vocabulary visual recognition. However, significant open research
challenges remain, particularly around the scarcity of robot-relevant training
data, safety guarantees and uncertainty quantification, and real-time
execution. In this survey, we study recent papers that have used or built
foundation models to solve robotics problems. We explore how foundation models
contribute to improving robot capabilities in the domains of perception,
decision-making, and control. We discuss the challenges hindering the adoption
of foundation models in robot autonomy and provide opportunities and potential
pathways for future advancements. The GitHub project corresponding to this
paper (Preliminary release. We are committed to further enhancing and updating
this work to ensure its quality and relevance) can be found here:
https://github.com/robotics-survey/Awesome-Robotics-Foundation-Models
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07844" title="Abstract">arXiv:2312.07844</a> [<a href="/pdf/2312.07844" title="Download PDF">pdf</a>, <a href="/format/2312.07844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regional profile of questionable publishing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=You%2C+T">Taekho You</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jinseo Park</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+Y">June Young Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+J">Jinhyuk Yun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures, supplementary information with 8 SI figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Countries and authors in the academic periphery occasionally have been
criticized for contributing to the expansion of questionable publishing because
they share a major fraction of papers in questionable journals. On the other
side, topics preferred by mainstream journals sometimes necessitate large-scale
investigation, which is impossible for developing countries. Thus, local
journals, commonly low-impacted, are essential to sustain the regional academia
for such countries. In this study, we perform an in-depth analysis of the
distribution of questionable publications and journals with their interplay
with countries quantifying the influence of questionable publications regarding
academia's inequality. We find that low-impact journals play a vital role in
the regional academic environment, whereas questionable journals with
equivalent impact publish papers from all over the world, both geographically
and academically. The business model of questionable journals differs from that
of regional journals, and may thus be detrimental to the broader academic
community.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07848" title="Abstract">arXiv:2312.07848</a> [<a href="/pdf/2312.07848" title="Download PDF">pdf</a>, <a href="/ps/2312.07848" title="Download PostScript">ps</a>, <a href="/format/2312.07848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finetuning an LLM on Contextual Knowledge of Classics for Q&amp;A
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Strachan%2C+S+S">Shane Storm Strachan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The open-source publishing of large language models (LLMs) has created many
possibilities for how anyone who understands language and has access to a
computer can interact with significant tools of artificial intelligence,
particularly in the context of learning and knowledge dissemination. However,
the utility of these models in specialized fields like Classics is still
largely unexplored. This project is an attempt to merge the knowledge of
Classics with the capabilities of artificial intelligence by finetuning an LLM
to cater to the specific needs of learners and professionals. The goal of this
project is to develop an LLM that not only reproduces contextual knowledge
accurately but also exhibits a consistent "personality" - and, indeed, has
consistent propriety - to appeal to a diverse audience who possess differing
levels of knowledge. A significant portion of this project was dedicated to
refining the dataset, following the principle of "garbage in, garbage out," to
ensure the model generates relevant, useful, and creative responses when given
a prompt (a statement, question, or single word). After training and
evaluation, my model's ability to handle a vast array of different types of
inputs and prompting exceeded expectations for a 355M parameter model, though
its occasional hallucinations (especially when set with a high temperature),
particularly in its assertions about historical events or its own identity,
make it seem somewhat capricious and more work in the form of continuous
finetuning will be undertaken.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07849" title="Abstract">arXiv:2312.07849</a> [<a href="/pdf/2312.07849" title="Download PDF">pdf</a>, <a href="/format/2312.07849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Encoder-minimal and Decoder-minimal Framework for Remote Sensing Image  Dehazing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yuanbo Wen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+T">Tao Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Ting Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Haze obscures remote sensing images, hindering valuable information
extraction. To this end, we propose RSHazeNet, an encoder-minimal and
decoder-minimal framework for efficient remote sensing image dehazing.
Specifically, regarding the process of merging features within the same level,
we develop an innovative module called intra-level transposed fusion module
(ITFM). This module employs adaptive transposed self-attention to capture
comprehensive context-aware information, facilitating the robust context-aware
feature fusion. Meanwhile, we present a cross-level multi-view interaction
module (CMIM) to enable effective interactions between features from various
levels, mitigating the loss of information due to the repeated sampling
operations. In addition, we propose a multi-view progressive extraction block
(MPEB) that partitions the features into four distinct components and employs
convolution with varying kernel sizes, groups, and dilation factors to
facilitate view-progressive feature learning. Extensive experiments demonstrate
the superiority of our proposed RSHazeNet. We release the source code and all
pre-trained models at \url{https://github.com/chdwyb/RSHazeNet}.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07850" title="Abstract">arXiv:2312.07850</a> [<a href="/pdf/2312.07850" title="Download PDF">pdf</a>, <a href="/format/2312.07850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model Enhanced Multi-Agent Systems for 6G Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+F">Feibo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+L">Li Dong</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yubo Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kezhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+C">Cunhua Pan</a>, 
<a href="/search/cs?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>, 
<a href="/search/cs?searchtype=author&query=Dobre%2C+O+A">Octavia A. Dobre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for possible journal publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The rapid development of the Large Language Model (LLM) presents huge
opportunities for 6G communications, e.g., network optimization and management
by allowing users to input task requirements to LLMs by nature language.
However, directly applying native LLMs in 6G encounters various challenges,
such as a lack of private communication data and knowledge, limited logical
reasoning, evaluation, and refinement abilities. Integrating LLMs with the
capabilities of retrieval, planning, memory, evaluation and reflection in
agents can greatly enhance the potential of LLMs for 6G communications. To this
end, we propose a multi-agent system with customized communication knowledge
and tools for solving communication related tasks using natural language,
comprising three components: (1) Multi-agent Data Retrieval (MDR), which
employs the condensate and inference agents to refine and summarize
communication knowledge from the knowledge base, expanding the knowledge
boundaries of LLMs in 6G communications; (2) Multi-agent Collaborative Planning
(MCP), which utilizes multiple planning agents to generate feasible solutions
for the communication related task from different perspectives based on the
retrieved knowledge; (3) Multi-agent Evaluation and Reflecxion (MER), which
utilizes the evaluation agent to assess the solutions, and applies the
reflexion agent and refinement agent to provide improvement suggestions for
current solutions. Finally, we validate the effectiveness of the proposed
multi-agent system by designing a semantic communication system, as a case
study of 6G communications.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07851" title="Abstract">arXiv:2312.07851</a> [<a href="/pdf/2312.07851" title="Download PDF">pdf</a>, <a href="/ps/2312.07851" title="Download PostScript">ps</a>, <a href="/format/2312.07851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noise in the reverse process improves the approximation capabilities of  diffusion models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elamvazhuthi%2C+K">Karthik Elamvazhuthi</a>, 
<a href="/search/cs?searchtype=author&query=Oymak%2C+S">Samet Oymak</a>, 
<a href="/search/cs?searchtype=author&query=Pasqualetti%2C+F">Fabio Pasqualetti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended preprint for submission to Learning for Dynamics &amp; Control Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">In Score based Generative Modeling (SGMs), the state-of-the-art in generative
modeling, stochastic reverse processes are known to perform better than their
deterministic counterparts. This paper delves into the heart of this
phenomenon, comparing neural ordinary differential equations (ODEs) and neural
stochastic differential equations (SDEs) as reverse processes. We use a control
theoretic perspective by posing the approximation of the reverse process as a
trajectory tracking problem. We analyze the ability of neural SDEs to
approximate trajectories of the Fokker-Planck equation, revealing the
advantages of stochasticity. First, neural SDEs exhibit a powerful regularizing
effect, enabling $L^2$ norm trajectory approximation surpassing the Wasserstein
metric approximation achieved by neural ODEs under similar conditions, even
when the reference vector field or score function is not Lipschitz. Applying
this result, we establish the class of distributions that can be sampled using
score matching in SGMs, relaxing the Lipschitz requirement on the gradient of
the data distribution in existing literature. Second, we show that this
approximation property is preserved when network width is limited to the input
dimension of the network. In this limited width case, the weights act as
control inputs, framing our analysis as a controllability problem for neural
SDEs in probability density space. This sheds light on how noise helps to steer
the system towards the desired solution and illuminates the empirical success
of stochasticity in generative modeling.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07852" title="Abstract">arXiv:2312.07852</a> [<a href="/pdf/2312.07852" title="Download PDF">pdf</a>, <a href="/format/2312.07852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recording provenance of workflow runs with RO-Crate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leo%2C+S">Simone Leo</a>, 
<a href="/search/cs?searchtype=author&query=Crusoe%2C+M+R">Michael R. Crusoe</a>, 
<a href="/search/cs?searchtype=author&query=Rodr%C3%ADguez-Navas%2C+L">Laura Rodr&#xed;guez-Navas</a>, 
<a href="/search/cs?searchtype=author&query=Sirvent%2C+R">Ra&#xfc;l Sirvent</a>, 
<a href="/search/cs?searchtype=author&query=Kanitz%2C+A">Alexander Kanitz</a>, 
<a href="/search/cs?searchtype=author&query=De+Geest%2C+P">Paul De Geest</a>, 
<a href="/search/cs?searchtype=author&query=Wittner%2C+R">Rudolf Wittner</a>, 
<a href="/search/cs?searchtype=author&query=Pireddu%2C+L">Luca Pireddu</a>, 
<a href="/search/cs?searchtype=author&query=Garijo%2C+D">Daniel Garijo</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez%2C+J+M">Jos&#xe9; M. Fern&#xe1;ndez</a>, 
<a href="/search/cs?searchtype=author&query=Colonnelli%2C+I">Iacopo Colonnelli</a>, 
<a href="/search/cs?searchtype=author&query=Gallo%2C+M">Matej Gallo</a>, 
<a href="/search/cs?searchtype=author&query=Ohta%2C+T">Tazro Ohta</a>, 
<a href="/search/cs?searchtype=author&query=Suetake%2C+H">Hirotaka Suetake</a>, 
<a href="/search/cs?searchtype=author&query=Capella-Gutierrez%2C+S">Salvador Capella-Gutierrez</a>, 
<a href="/search/cs?searchtype=author&query=de+Wit%2C+R">Renske de Wit</a>, 
<a href="/search/cs?searchtype=author&query=Kinoshita%2C+B+P">Bruno P. Kinoshita</a>, 
<a href="/search/cs?searchtype=author&query=Soiland-Reyes%2C+S">Stian Soiland-Reyes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 5 figures, 3 tables. Submitted to PLOS ONE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">Recording the provenance of scientific computation results is key to the
support of traceability, reproducibility and quality assessment of data
products. Several data models have been explored to address this need,
providing representations of workflow plans and their executions as well as
means of packaging the resulting information for archiving and sharing.
However, existing approaches tend to lack interoperable adoption across
workflow management systems. In this work we present Workflow Run RO-Crate, an
extension of RO-Crate (Research Object Crate) and Schema.org to capture the
provenance of the execution of computational workflows at different levels of
granularity and bundle together all their associated products (inputs, outputs,
code, etc.). The model is supported by a diverse, open community that runs
regular meetings, discussing development, maintenance and adoption aspects.
Workflow Run RO-Crate is already implemented by several workflow management
systems, allowing interoperable comparisons between workflow runs from
heterogeneous systems. We describe the model, its alignment to standards such
as W3C PROV, and its implementation in six workflow systems. Finally, we
illustrate the application of Workflow Run RO-Crate in two use cases of machine
learning in the digital image analysis domain.
<br />A corresponding RO-Crate for this article is at
https://w3id.org/ro/doi/10.5281/zenodo.10368989
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07853" title="Abstract">arXiv:2312.07853</a> [<a href="/pdf/2312.07853" title="Download PDF">pdf</a>, <a href="/format/2312.07853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Order Structure Based Middle-Feature Learning for Visible-Infrared  Person Re-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Liuxiang Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Si Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+J">Jin-Hao Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Da-Han Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shunzhi Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visible-infrared person re-identification (VI-ReID) aims to retrieve images
of the same persons captured by visible (VIS) and infrared (IR) cameras.
Existing VI-ReID methods ignore high-order structure information of features
while being relatively difficult to learn a reasonable common feature space due
to the large modality discrepancy between VIS and IR images. To address the
above problems, we propose a novel high-order structure based middle-feature
learning network (HOS-Net) for effective VI-ReID. Specifically, we first
leverage a short- and long-range feature extraction (SLE) module to effectively
exploit both short-range and long-range features. Then, we propose a high-order
structure learning (HSL) module to successfully model the high-order
relationship across different local features of each person image based on a
whitened hypergraph network.This greatly alleviates model collapse and enhances
feature representations. Finally, we develop a common feature space learning
(CFL) module to learn a discriminative and reasonable common feature space
based on middle features generated by aligning features from different
modalities and ranges. In particular, a modality-range identity-center
contrastive (MRIC) loss is proposed to reduce the distances between the VIS,
IR, and middle features, smoothing the training process. Extensive experiments
on the SYSU-MM01, RegDB, and LLCM datasets show that our HOS-Net achieves
superior state-of-the-art performance. Our code is available at
\url{https://github.com/Jaulaucoeng/HOS-Net}.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07854" title="Abstract">arXiv:2312.07854</a> [<a href="/pdf/2312.07854" title="Download PDF">pdf</a>, <a href="/format/2312.07854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Models Enable Zero-Shot Pose Estimation for Lower-Limb  Prosthetic Users
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianxun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Iskandar%2C+M+N+S">Muhammad Nur Shahril Iskandar</a>, 
<a href="/search/cs?searchtype=author&query=Chiam%2C+K">Keng-Hwee Chiam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 6 figures. Supplementary documents in source file
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The application of 2D markerless gait analysis has garnered increasing
interest and application within clinical settings. However, its effectiveness
in the realm of lower-limb amputees has remained less than optimal. In
response, this study introduces an innovative zero-shot method employing image
generation diffusion models to achieve markerless pose estimation for
lower-limb prosthetics, presenting a promising solution to gait analysis for
this specific population. Our approach demonstrates an enhancement in detecting
key points on prosthetic limbs over existing methods, and enables clinicians to
gain invaluable insights into the kinematics of lower-limb amputees across the
gait cycle. The outcomes obtained not only serve as a proof-of-concept for the
feasibility of this zero-shot approach but also underscore its potential in
advancing rehabilitation through gait analysis for this unique population.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07855" title="Abstract">arXiv:2312.07855</a> [<a href="/pdf/2312.07855" title="Download PDF">pdf</a>, <a href="/format/2312.07855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Popularity Bias in Session-based Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haowen Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Existing work has revealed that large-scale offline evaluation of recommender
systems for user-item interactions is prone to bias caused by the deployed
system itself, as a form of closed loop feedback. Many adopt the
\textit{propensity} concept to analyze or mitigate this empirical issue. In
this work, we extend the analysis to session-based setup and adapted propensity
calculation to the unique characteristics of session-based recommendation
tasks. Our experiments incorporate neural models and KNN-based models, and
cover both the music and the e-commerce domain. We study the distributions of
propensity and different stratification techniques on different datasets and
find that propensity-related traits are actually dataset-specific. We then
leverage the effect of stratification and achieve promising results compared to
the original models.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07856" title="Abstract">arXiv:2312.07856</a> [<a href="/pdf/2312.07856" title="Download PDF">pdf</a>, <a href="/format/2312.07856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DTL: Disentangled Transfer Learning for Visual Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+M">Minghao Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Ke Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jianxin Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">When pre-trained models become rapidly larger, the cost of fine-tuning on
downstream tasks steadily increases, too. To economically fine-tune these
models, parameter-efficient transfer learning (PETL) is proposed, which only
tunes a tiny subset of trainable parameters to efficiently learn quality
representations. However, current PETL methods are facing the dilemma that
during training the GPU memory footprint is not effectively reduced as
trainable parameters. PETL will likely fail, too, if the full fine-tuning
encounters the out-of-GPU-memory issue. This phenomenon happens because
trainable parameters from these methods are generally entangled with the
backbone, such that a lot of intermediate states have to be stored in GPU
memory for gradient propagation. To alleviate this problem, we introduce
Disentangled Transfer Learning (DTL), which disentangles the trainable
parameters from the backbone using a lightweight Compact Side Network (CSN). By
progressively extracting task-specific information with a few low-rank linear
mappings and appropriately adding the information back to the backbone, CSN
effectively realizes knowledge transfer in various downstream tasks. We
conducted extensive experiments to validate the effectiveness of our method.
The proposed method not only reduces a large amount of GPU memory usage and
trainable parameters, but also outperforms existing PETL methods by a
significant margin in accuracy, achieving new state-of-the-art on several
standard benchmarks.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07857" title="Abstract">arXiv:2312.07857</a> [<a href="/pdf/2312.07857" title="Download PDF">pdf</a>, <a href="/ps/2312.07857" title="Download PostScript">ps</a>, <a href="/format/2312.07857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Selecting the Number of Sensor Scans in Surveillance Operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Weinberg%2C+G+V">Graham V. Weinberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Applications (stat.AP)

</div>
<p class="mathjax">Searching for concealed threats within a surveillance region is an important
role for military sensors. One prominent case is the search for a submarine by
a helicopter deploying a dipping sonar in anti-submarine warfare. Another is
the utilisation of an uncrewed aerial vehicle for remote detection of land
mines. These platforms will deploy an appropriate sensor to search within a
given region for a potential threat. The sensors employed may not provide
continuous surveillance, but may have active periods where the inherent sensor
is scanning for threats. The reasons for disjoint activation periods may be
both functional as well as tactical. Therefore, given a specified search
pattern under which the surveillance platform operates, the question of the
number of sensor scans required becomes relevant for search mission
pre-planning. Hence it is not only important to develop a modelling framework
to assess performance but it is of relevance to consider whether a minimum
number of sensor scans can be determined to guarantee a desired level of
performance. Consequently this paper introduces a framework for this and
illustrates how it can be utilised in practice.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07858" title="Abstract">arXiv:2312.07858</a> [<a href="/pdf/2312.07858" title="Download PDF">pdf</a>, <a href="/format/2312.07858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-myopic Beam Scheduling for Multiple Smart Target Tracking in Phased  Array Radar Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hao%2C+Y">Yuhang Hao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zengfu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Ni%C3%B1o-Mora%2C+J">Jos&#xe9; Ni&#xf1;o-Mora</a>, 
<a href="/search/eess?searchtype=author&query=Fu%2C+J">Jing Fu</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+M">Min Yang</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+Q">Quan Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">A smart target, also referred to as a reactive target, can take maneuvering
motions to hinder radar tracking. We address beam scheduling for tracking
multiple smart targets in phased array radar networks. We aim to mitigate the
performance degradation in previous myopic tracking methods and enhance the
system performance, which is measured by a discounted cost objective related to
the tracking error covariance (TEC) of the targets. The scheduling problem is
formulated as a restless multi-armed bandit problem (RMABP) with state
variables, following the Markov decision process. In particular, the problem
consists of parallel bandit processes. Each bandit process is associated with a
target and evolves with different transition rules for different actions, i.e.,
either the target is tracked or not. We propose a non-myopic, scalable policy
based on Whittle indices for selecting the targets to be tracked at each time.
The proposed policy has a linear computational complexity in the number of
targets and the truncated time horizon in the index computation, and is hence
applicable to large networks with a realistic number of targets. We present
numerical evidence that the model satisfies sufficient conditions for
indexability (existence of the Whittle index) based upon partial conservation
laws, and, through extensive simulations, we validate the effectiveness of the
proposed policy in different scenarios.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07859" title="Abstract">arXiv:2312.07859</a> [<a href="/pdf/2312.07859" title="Download PDF">pdf</a>, <a href="/format/2312.07859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invariant Graph Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhe Xu</a> (1), 
<a href="/search/cs?searchtype=author&query=Pan%2C+M">Menghai Pan</a> (2), 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuzhong Chen</a> (2), 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huiyuan Chen</a> (2), 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yuchen Yan</a> (1), 
<a href="/search/cs?searchtype=author&query=Das%2C+M">Mahashweta Das</a> (2), 
<a href="/search/cs?searchtype=author&query=Tong%2C+H">Hanghang Tong</a> (1) ((1) University of Illinois Urbana-Champaign, (2) Visa Research)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Rationale discovery is defined as finding a subset of the input data that
maximally supports the prediction of downstream tasks. In graph machine
learning context, graph rationale is defined to locate the critical subgraph in
the given graph topology, which fundamentally determines the prediction
results. In contrast to the rationale subgraph, the remaining subgraph is named
the environment subgraph. Graph rationalization can enhance the model
performance as the mapping between the graph rationale and prediction label is
viewed as invariant, by assumption. To ensure the discriminative power of the
extracted rationale subgraphs, a key technique named "intervention" is applied.
The core idea of intervention is that given any changing environment subgraphs,
the semantics from the rationale subgraph is invariant, which guarantees the
correct prediction result. However, most, if not all, of the existing
rationalization works on graph data develop their intervention strategies on
the graph level, which is coarse-grained. In this paper, we propose
well-tailored intervention strategies on graph data. Our idea is driven by the
development of Transformer models, whose self-attention module provides rich
interactions between input nodes. Based on the self-attention module, our
proposed invariant graph Transformer (IGT) can achieve fine-grained, more
specifically, node-level and virtual node-level intervention. Our comprehensive
experiments involve 7 real-world datasets, and the proposed IGT shows
significant performance advantages compared to 13 baseline methods.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07860" title="Abstract">arXiv:2312.07860</a> [<a href="/pdf/2312.07860" title="Download PDF">pdf</a>, <a href="/ps/2312.07860" title="Download PostScript">ps</a>, <a href="/format/2312.07860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Dependent Higher-Order Clique Selection for Artery-Vein  Segmentation by Energy Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kitamura%2C+Y">Yoshiro Kitamura</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanzhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Ito%2C+W">Wataru Ito</a>, 
<a href="/search/cs?searchtype=author&query=Ishikawa%2C+H">Hiroshi Ishikawa</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Computer Vision 117, 142-158(2016)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose a novel segmentation method based on energy minimization of
higher-order potentials. We introduce higher-order terms into the energy to
incorporate prior knowledge on the shape of the segments. The terms encourage
certain sets of pixels to be entirely in one segment or the other. The sets can
for instance be smooth curves in order to help delineate pulmonary vessels,
which are known to run in almost straight lines. The higher-order terms can be
converted to submodular first-order terms by adding auxiliary variables, which
can then be globally minimized using graph cuts. We also determine the weight
of these terms, or the degree of the aforementioned encouragement, in a
principled way by learning from training data with the ground truth. We
demonstrate the effectiveness of the method in a real-world application in
fully-automatic pulmonary artery-vein segmentation in CT images.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07861" title="Abstract">arXiv:2312.07861</a> [<a href="/pdf/2312.07861" title="Download PDF">pdf</a>, <a href="/format/2312.07861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphGuard: Detecting and Counteracting Training Data Misuse in Graph  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">He Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiangwen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+M">Minhui Xue</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shirui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xingliang Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The emergence of Graph Neural Networks (GNNs) in graph data analysis and
their deployment on Machine Learning as a Service platforms have raised
critical concerns about data misuse during model training. This situation is
further exacerbated due to the lack of transparency in local training
processes, potentially leading to the unauthorized accumulation of large
volumes of graph data, thereby infringing on the intellectual property rights
of data owners. Existing methodologies often address either data misuse
detection or mitigation, and are primarily designed for local GNN models rather
than cloud-based MLaaS platforms. These limitations call for an effective and
comprehensive solution that detects and mitigates data misuse without requiring
exact training data while respecting the proprietary nature of such data. This
paper introduces a pioneering approach called GraphGuard, to tackle these
challenges. We propose a training-data-free method that not only detects graph
data misuse but also mitigates its impact via targeted unlearning, all without
relying on the original training data. Our innovative misuse detection
technique employs membership inference with radioactive data, enhancing the
distinguishability between member and non-member data distributions. For
mitigation, we utilize synthetic graphs that emulate the characteristics
previously learned by the target model, enabling effective unlearning even in
the absence of exact graph data. We conduct comprehensive experiments utilizing
four real-world graph datasets to demonstrate the efficacy of GraphGuard in
both detection and unlearning. We show that GraphGuard attains a near-perfect
detection rate of approximately 100% across these datasets with various GNN
models. In addition, it performs unlearning by eliminating the impact of the
unlearned graph with a marginal decrease in accuracy (less than 5%).
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07864" title="Abstract">arXiv:2312.07864</a> [<a href="/pdf/2312.07864" title="Download PDF">pdf</a>, <a href="/format/2312.07864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MMSE Design of RIS-aided Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+W">Wen-Xuan Long</a>, 
<a href="/search/cs?searchtype=author&query=Moretti%2C+M">Marco Moretti</a>, 
<a href="/search/cs?searchtype=author&query=Abrardo%2C+A">Andrea Abrardo</a>, 
<a href="/search/cs?searchtype=author&query=Sanguinetti%2C+L">Luca Sanguinetti</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Rui Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Consider a communication system in which a single antenna user equipment
exchanges information with a multi-antenna base station via a reconfigurable
intelligent surface (RIS) in the presence of spatially correlated channels and
electromagnetic interference (EMI). To exploit the attractive advantages of RIS
technology, accurate configuration of its reflecting elements is crucial. In
this paper, we use statistical knowledge of channels and EMI to optimize the
RIS elements for i) accurate channel estimation and ii) reliable data
transmission. In both cases, our goal is to determine the RIS coefficients that
minimize the mean square error, resulting in the formulation of two non-convex
problems that share the same structure. To solve these two problems, we present
an alternating optimization approach that reliably converges to a locally
optimal solution. The incorporation of the diagonally scaled steepest descent
algorithm, derived from Newton's method, ensures fast convergence with
manageable complexity. Numerical results demonstrate the effectiveness of the
proposed method under various propagation conditions. Notably, it shows
significant advantages over existing alternatives that depend on a sub-optimal
configuration of the RIS and are derived on the basis of different criteria.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07865" title="Abstract">arXiv:2312.07865</a> [<a href="/pdf/2312.07865" title="Download PDF">pdf</a>, <a href="/format/2312.07865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SimAC: A Simple Anti-Customization Method against Text-to-Image  Synthesis of Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Feifei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhentao Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+T">Tianyi Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qidong Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite the success of diffusion-based customization methods on visual
content creation, increasing concerns have been raised about such techniques
from both privacy and political perspectives. To tackle this issue, several
anti-customization methods have been proposed in very recent months,
predominantly grounded in adversarial attacks. Unfortunately, most of these
methods adopt straightforward designs, such as end-to-end optimization with a
focus on adversarially maximizing the original training loss, thereby
neglecting nuanced internal properties intrinsic to the diffusion model, and
even leading to ineffective optimization in some diffusion time steps. In this
paper, we strive to bridge this gap by undertaking a comprehensive exploration
of these inherent properties, to boost the performance of current
anti-customization approaches. Two aspects of properties are investigated: 1)
We examine the relationship between time step selection and the model's
perception in the frequency domain of images and find that lower time steps can
give much more contributions to adversarial noises. This inspires us to propose
an adaptive greedy search for optimal time steps that seamlessly integrates
with existing anti-customization methods. 2) We scrutinize the roles of
features at different layers during denoising and devise a sophisticated
feature-based optimization framework for anti-customization. Experiments on
facial benchmarks demonstrate that our approach significantly increases
identity disruption, thereby enhancing user privacy and security.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07867" title="Abstract">arXiv:2312.07867</a> [<a href="/pdf/2312.07867" title="Download PDF">pdf</a>, <a href="/format/2312.07867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BESTMVQA: A Benchmark Evaluation System for Medical Visual Question  Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+X">Xiaojie Hong</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zixin Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liangzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoli Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Feiyan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Medical Visual Question Answering (Med-VQA) is a very important task in
healthcare industry, which answers a natural language question with a medical
image. Existing VQA techniques in information systems can be directly applied
to solving the task. However, they often suffer from (i) the data insufficient
problem, which makes it difficult to train the state of the arts (SOTAs) for
the domain-specific task, and (ii) the reproducibility problem, that many
existing models have not been thoroughly evaluated in a unified experimental
setup. To address these issues, this paper develops a Benchmark Evaluation
SysTem for Medical Visual Question Answering, denoted by BESTMVQA. Given
self-collected clinical data, our system provides a useful tool for users to
automatically build Med-VQA datasets, which helps overcoming the data
insufficient problem. Users also can conveniently select a wide spectrum of
SOTA models from our model library to perform a comprehensive empirical study.
With simple configurations, our system automatically trains and evaluates the
selected models over a benchmark dataset, and reports the comprehensive results
for users to develop new techniques or perform medical practice. Limitations of
existing work are overcome (i) by the data generation tool, which automatically
constructs new datasets from unstructured clinical data, and (ii) by evaluating
SOTAs on benchmark datasets in a unified experimental setup. The demonstration
video of our system can be found at https://youtu.be/QkEeFlu1x4A. Our code and
data will be available soon.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07868" title="Abstract">arXiv:2312.07868</a> [<a href="/pdf/2312.07868" title="Download PDF">pdf</a>, <a href="/format/2312.07868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph vs. Sequence: An Empirical Study on Knowledge Forms for  Knowledge-Grounded Dialogue
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yizhe Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Heyan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yihang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in EMNLP2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Knowledge-grounded dialogue is a task of generating an informative response
based on both the dialogue history and external knowledge source. In general,
there are two forms of knowledge: manually annotated knowledge graphs and
knowledge text from website. From various evaluation viewpoints, each type of
knowledge has advantages and downsides. To further distinguish the principles
and determinants from the intricate factors, we conduct a thorough experiment
and study on the task to answer three essential questions. The questions
involve the choice of appropriate knowledge form, the degree of mutual effects
between knowledge and the model selection, and the few-shot performance of
knowledge. Supported by statistical shreds of evidence, we offer conclusive
solutions and sensible suggestions for directions and standards of future
research.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07870" title="Abstract">arXiv:2312.07870</a> [<a href="/pdf/2312.07870" title="Download PDF">pdf</a>, <a href="/format/2312.07870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Securing Graph Neural Networks in MLaaS: A Comprehensive Realization of  Query-based Integrity Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xingliang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qi Li</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+M">Minhui Xue</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shirui Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The deployment of Graph Neural Networks (GNNs) within Machine Learning as a
Service (MLaaS) has opened up new attack surfaces and an escalation in security
concerns regarding model-centric attacks. These attacks can directly manipulate
the GNN model parameters during serving, causing incorrect predictions and
posing substantial threats to essential GNN applications. Traditional integrity
verification methods falter in this context due to the limitations imposed by
MLaaS and the distinct characteristics of GNN models.
<br />In this research, we introduce a groundbreaking approach to protect GNN
models in MLaaS from model-centric attacks. Our approach includes a
comprehensive verification schema for GNN's integrity, taking into account both
transductive and inductive GNNs, and accommodating varying pre-deployment
knowledge of the models. We propose a query-based verification technique,
fortified with innovative node fingerprint generation algorithms. To deal with
advanced attackers who know our mechanisms in advance, we introduce randomized
fingerprint nodes within our design. The experimental evaluation demonstrates
that our method can detect five representative adversarial model-centric
attacks, displaying 2 to 4 times greater efficiency compared to baselines.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07871" title="Abstract">arXiv:2312.07871</a> [<a href="/pdf/2312.07871" title="Download PDF">pdf</a>, <a href="/format/2312.07871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MLNet: Mutual Learning Network with Neighborhood Invariance for  Universal Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yanzuo Lu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+M">Meng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+A+J">Andy J Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaohua Xie</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+J">Jian-Huang Lai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024. Code is available at <a href="https://github.com/YanzuoLu/MLNet">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Universal domain adaptation (UniDA) is a practical but challenging problem,
in which information about the relation between the source and the target
domains is not given for knowledge transfer. Existing UniDA methods may suffer
from the problems of overlooking intra-domain variations in the target domain
and difficulty in separating between the similar known and unknown class. To
address these issues, we propose a novel \textbf{Mutual Learning Network
(MLNet)} with neighborhood invariance for UniDA. In our method,
confidence-guided invariant feature learning with self-adaptive neighbor
selection is designed to reduce the intra-domain variations for more
generalizable feature representation. By using the cross-domain mixup scheme
for better unknown-class identification, the proposed method compensates for
the misidentified known-class errors by mutual learning between the closed-set
and open-set classifiers. Extensive experiments on three publicly available
benchmarks demonstrate that our method achieves the best results compared to
the state-of-the-arts in most cases and significantly outperforms the baseline
across all the four settings in UniDA. Code is available at
https://github.com/YanzuoLu/MLNet.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07874" title="Abstract">arXiv:2312.07874</a> [<a href="/pdf/2312.07874" title="Download PDF">pdf</a>, <a href="/format/2312.07874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Entropy-Stable Discontinuous Spectral-Element Methods Using  Tensor-Product Summation-by-Parts Operators on Triangles and Tetrahedra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Montoya%2C+T">Tristan Montoya</a>, 
<a href="/search/math?searchtype=author&query=Zingg%2C+D+W">David W. Zingg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present a new class of efficient and robust discontinuous spectral-element
methods of arbitrary order for nonlinear hyperbolic systems of conservation
laws on curved triangular and tetrahedral unstructured grids. Such
discretizations employ a recently introduced family of sparse tensor-product
summation-by-parts (SBP) operators in collapsed coordinates within an
entropy-stable modal formulation. The proposed algorithms exploit the structure
of such SBP operators alongside that of the Proriol-Koornwinder-Dubiner
polynomial basis, and a weight-adjusted approximation is used to efficiently
invert the local mass matrix for curvilinear elements. Using such techniques,
the number of required entropy-conservative two-point flux evaluations between
pairs of quadrature nodes is significantly reduced relative to existing
entropy-stable formulations using (non-tensor-product) multidimensional SBP
operators, particularly for high polynomial degrees, with an improvement in
time complexity from $\mathcal{O}(p^{2d})$ to $\mathcal{O}(p^{d+1})$, where $p$
is the polynomial degree of the approximation and $d$ is the number of spatial
dimensions. In numerical experiments involving smooth solutions to the
compressible Euler equations, the proposed tensor-product schemes demonstrate
similar levels of accuracy for a given mesh and polynomial degree to those
using multidimensional SBP operators based on symmetric quadrature rules.
Furthermore, both operator families are shown to give rise to entropy-stable
methods which exhibit excellent robustness for under-resolved problems. Such
results suggest that the algorithmic advantages resulting from the use of
tensor-product operators are obtained without compromising accuracy or
robustness, enabling the efficient extension of the benefits of entropy
stability to higher polynomial degrees than previously considered for
triangular and tetrahedral elements.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07875" title="Abstract">arXiv:2312.07875</a> [<a href="/pdf/2312.07875" title="Download PDF">pdf</a>, <a href="/format/2312.07875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhance Sketch Recognition&#x27;s Explainability via Semantic Component-Level  Parsing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+G">Guangming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Siyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianci Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Free-hand sketches are appealing for humans as a universal tool to depict the
visual world. Humans can recognize varied sketches of a category easily by
identifying the concurrence and layout of the intrinsic semantic components of
the category, since humans draw free-hand sketches based a common consensus
that which types of semantic components constitute each sketch category. For
example, an airplane should at least have a fuselage and wings. Based on this
analysis, a semantic component-level memory module is constructed and embedded
in the proposed structured sketch recognition network in this paper. The memory
keys representing semantic components of each sketch category can be
self-learned and enhance the recognition network's explainability. Our proposed
networks can deal with different situations of sketch recognition, i.e., with
or without semantic components labels of strokes. Experiments on the SPG and
SketchIME datasets demonstrate the memory module's flexibility and the
recognition network's explainability. The code and data are available at
https://github.com/GuangmingZhu/SketchESC.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07876" title="Abstract">arXiv:2312.07876</a> [<a href="/pdf/2312.07876" title="Download PDF">pdf</a>, <a href="/format/2312.07876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causality Analysis for Evaluating the Security of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jun Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) such as GPT and Llama2 are increasingly adopted
in many safety-critical applications. Their security is thus essential. Even
with considerable efforts spent on reinforcement learning from human feedback
(RLHF), recent studies have shown that LLMs are still subject to attacks such
as adversarial perturbation and Trojan attacks. Further research is thus needed
to evaluate their security and/or understand the lack of it. In this work, we
propose a framework for conducting light-weight causality-analysis of LLMs at
the token, layer, and neuron level. We applied our framework to open-source
LLMs such as Llama2 and Vicuna and had multiple interesting discoveries. Based
on a layer-level causality analysis, we show that RLHF has the effect of
overfitting a model to harmful prompts. It implies that such security can be
easily overcome by `unusual' harmful prompts. As evidence, we propose an
adversarial perturbation method that achieves 100\% attack success rate on the
red-teaming tasks of the Trojan Detection Competition 2023. Furthermore, we
show the existence of one mysterious neuron in both Llama2 and Vicuna that has
an unreasonably high causal effect on the output. While we are uncertain on why
such a neuron exists, we show that it is possible to conduct a ``Trojan''
attack targeting that particular neuron to completely cripple the LLM, i.e., we
can generate transferable suffixes to prompts that frequently make the LLM
produce meaningless responses.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07877" title="Abstract">arXiv:2312.07877</a> [<a href="/pdf/2312.07877" title="Download PDF">pdf</a>, <a href="/format/2312.07877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment-Based Formal Verification of WiFi Fragmentation and Power Save  Mode
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zilin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Karim%2C+I">Imtiaz Karim</a>, 
<a href="/search/cs?searchtype=author&query=Bertino%2C+E">Elisa Bertino</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 12 figures, the paper has been accepted by Asia CCS' 24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The IEEE 802.11 family of standards, better known as WiFi, is a widely used
protocol utilized by billions of users. Previous works on WiFi formal
verification have mostly focused on the four-way handshake and other security
aspects. However, recent works have uncovered severe vulnerabilities in
functional aspects of WiFi, which can cause information leakage for billions of
devices. No formal analysis method exists able to reason on the functional
aspects of the WiFi protocol. In this paper, we take the first steps in
addressing this gap and present an extensive formal analysis of the functional
aspects of the WiFi protocol, more specifically, the fragmentation and the
power-save-mode process. To achieve this, we design a novel segment-based
formal verification process and introduce a practical threat model (i.e. MAC
spoofing) in Tamarin to reason about the various capabilities of the attacker.
To this end, we verify 68 properties extracted from WiFi protocol
specification, find 3 vulnerabilities from the verification, verify 3 known
attacks, and discover 2 new issues. These vulnerabilities and issues affect 14
commercial devices out of 17 tested cases, showing the prevalence and impact of
the issues. Apart from this, we show that the proposed countermeasures indeed
are sufficient to address the issues. We hope our results and analysis will
help vendors adopt the countermeasures and motivate further research into the
verification of the functional aspects of the WiFi protocol.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07879" title="Abstract">arXiv:2312.07879</a> [<a href="/pdf/2312.07879" title="Download PDF">pdf</a>, <a href="/format/2312.07879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoIE: Chain-of-Instruct Editing for Multi-Attribute Face Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenduo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bowen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Current text-to-image editing models often encounter challenges with smoothly
manipulating multiple attributes using a single instruction. Taking inspiration
from the Chain-of-Thought prompting technique utilized in language models, we
present an innovative concept known as Chain-of-Instruct Editing (CoIE), which
enhances the capabilities of these models through step-by-step editing using a
series of instructions. In particular, in the context of face manipulation, we
leverage the contextual learning abilities of a pretrained Large Language Model
(LLM), such as GPT-4, to generate a sequence of instructions from the original
input, utilizing a purpose-designed 1-shot template. To further improve the
precision of each editing step, we conduct fine-tuning on the editing models
using our self-constructed instruction-guided face editing dataset,
Instruct-CelebA. And additionally, we incorporate a super-resolution module to
mitigate the adverse effects of editability and quality degradation.
Experimental results across various challenging cases confirm the significant
boost in multi-attribute facial image manipulation using chain-of-instruct
editing. This is evident in enhanced editing success rates, measured by CLIPSim
and Coverage metrics, improved by 17.86% and 85.45% respectively, and
heightened controllability indicated by Preserve L1 and Quality metrics,
improved by 11.58% and 4.93% respectively.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07883" title="Abstract">arXiv:2312.07883</a> [<a href="/pdf/2312.07883" title="Download PDF">pdf</a>, <a href="/ps/2312.07883" title="Download PostScript">ps</a>, <a href="/format/2312.07883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multispreads
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krotov%2C+D+S">Denis S. Krotov</a>, 
<a href="/search/cs?searchtype=author&query=Mogilnykh%2C+I+Y">Ivan Yu. Mogilnykh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">The additive one-weight codes over a finite field of non-prime order are
equivalent to special subspace coverings of the points of projective space,
which we call multispreads. The current paper is devoted to characterization of
the parameters of multispreads, which is equivalent to the characterization of
the parameters of additive one-weight codes. We characterize those parameters
for the case of the prime-square order of the field and make a partial
characterization for the prime-cube case and the case of the fourth degree of a
prime.
<br />Keywords: spreads, multispreads, additive codes, one-weight codes, completely
regular codes.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07884" title="Abstract">arXiv:2312.07884</a> [<a href="/pdf/2312.07884" title="Download PDF">pdf</a>, <a href="/format/2312.07884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mutual-Learning Knowledge Distillation for Nighttime UAV Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yufeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+H">Haobo Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+L">Liangliang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+K">Kunhan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+G">Guangze Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Changhong Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Nighttime unmanned aerial vehicle (UAV) tracking has been facilitated with
indispensable plug-and-play low-light enhancers. However, the introduction of
low-light enhancers increases the extra computational burden for the UAV,
significantly hindering the development of real-time UAV applications.
Meanwhile, these state-of-the-art (SOTA) enhancers lack tight coupling with the
advanced daytime UAV tracking approach. To solve the above issues, this work
proposes a novel mutual-learning knowledge distillation framework for nighttime
UAV tracking, i.e., MLKD. This framework is constructed to learn a compact and
fast nighttime tracker via knowledge transferring from the teacher and
knowledge sharing among various students. Specifically, an advanced teacher
based on a SOTA enhancer and a superior tracking backbone is adopted for
guiding the student based only on the tight coupling-aware tracking backbone to
directly extract nighttime object features. To address the biased learning of a
single student, diverse lightweight students with different distillation
methods are constructed to focus on various aspects of the teacher's knowledge.
Moreover, an innovative mutual-learning room is designed to elect the superior
student candidate to assist the remaining students frame-by-frame in the
training phase. Furthermore, the final best student, i.e., MLKD-Track, is
selected through the testing dataset. Extensive experiments demonstrate the
effectiveness and superiority of MLKD and MLKD-Track. The practicality of the
MLKD-Track is verified in real-world tests with different challenging
situations. The code is available at https://github.com/vision4robotics/MLKD.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07885" title="Abstract">arXiv:2312.07885</a> [<a href="/pdf/2312.07885" title="Download PDF">pdf</a>, <a href="/format/2312.07885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RAT: Reinforcement-Learning-Driven and Adaptive Testing for  Vulnerability Discovery in Web Application Firewalls
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amouei%2C+M">Mohammadhossein Amouei</a>, 
<a href="/search/cs?searchtype=author&query=Rezvani%2C+M">Mohsen Rezvani</a>, 
<a href="/search/cs?searchtype=author&query=Fateh%2C+M">Mansoor Fateh</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Dependable and Secure Computing ( Volume: 19,
  Issue: 5, 01 Sept.-Oct. 2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Due to the increasing sophistication of web attacks, Web Application
Firewalls (WAFs) have to be tested and updated regularly to resist the
relentless flow of web attacks. In practice, using a brute-force attack to
discover vulnerabilities is infeasible due to the wide variety of attack
patterns. Thus, various black-box testing techniques have been proposed in the
literature. However, these techniques suffer from low efficiency. This paper
presents Reinforcement-Learning-Driven and Adaptive Testing (RAT), an automated
black-box testing strategy to discover injection vulnerabilities in WAFs. In
particular, we focus on SQL injection and Cross-site Scripting, which have been
among the top ten vulnerabilities over the past decade. More specifically, RAT
clusters similar attack samples together. It then utilizes a reinforcement
learning technique combined with a novel adaptive search algorithm to discover
almost all bypassing attack patterns efficiently. We compare RAT with three
state-of-the-art methods considering their objectives. The experiments show
that RAT performs 33.53% and 63.16% on average better than its counterparts in
discovering the most possible bypassing payloads and reducing the number of
attempts before finding the first bypassing payload when testing
well-configured WAFs, respectively.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07886" title="Abstract">arXiv:2312.07886</a> [<a href="/pdf/2312.07886" title="Download PDF">pdf</a>, <a href="/format/2312.07886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modality Plug-and-Play: Elastic Modality Adaptation in Multimodal LLMs  for Embodied AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Boyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Wei Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large Language Models (LLMs) are capable of reasoning over diverse input data
modalities through pre-trained encoders. However, the growing diversity of
input data modalities prevents incorporating all modalities into LLMs,
especially when LLMs are deployed on resource-constrained edge devices for
embodied AI applications. Instead, a better option is to adaptively involve
only the useful modalities at runtime, depending on the current environmental
contexts and task requirements. For such modality adaptation, existing work
adopts fixed connections between encoders and the LLM's input layer, leading to
high training cost at runtime and ineffective cross-modal interaction. In this
paper, we address these limitations by presenting mPnP-LLM, a new technique
that allows fully elastic, automated and prompt runtime modality adaptation, by
connecting unimodal encoders to a flexible set of last LLM blocks and making
such latent connections fully trainable at runtime. Experiments over the
nuScenes-QA dataset show that mPnP-LLM can achieve up to 3.7x FLOPs reduction
and 30% GPU memory usage reduction, while retaining on-par accuracy with the
existing schemes. Under the same compute budget, mPnP-LLM improves the task
accuracy by up to 4% compared to the best existing scheme.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07887" title="Abstract">arXiv:2312.07887</a> [<a href="/pdf/2312.07887" title="Download PDF">pdf</a>, <a href="/format/2312.07887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learn or Recall? Revisiting Incremental Learning with Pre-trained  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Junhao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+S">Shengjie Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Q">Qianli Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Incremental Learning (IL) has been a long-standing problem in both vision and
Natural Language Processing (NLP) communities. In recent years, as Pre-trained
Language Models (PLMs) have achieved remarkable progress in various NLP
downstream tasks, utilizing PLMs as backbones has become a common practice in
recent research of IL in NLP. Most assume that catastrophic forgetting is the
biggest obstacle to achieving superior IL performance and propose various
techniques to overcome this issue. However, we find that this assumption is
problematic. Specifically, we revisit more than 20 methods on four
classification tasks (Text Classification, Intent Classification, Relation
Extraction, and Named Entity Recognition) under the two most popular IL
settings (Class-Incremental and Task-Incremental) and reveal that most of them
severely underestimate the inherent anti-forgetting ability of PLMs. Based on
the observation, we propose a frustratingly easy method called SEQ* for IL with
PLMs. The results show that SEQ* has competitive or superior performance
compared to state-of-the-art (SOTA) IL methods and requires considerably less
trainable parameters and training time. These findings urge us to revisit the
IL with PLMs and encourage future studies to have a fundamental understanding
of the catastrophic forgetting in PLMs. The data, code and scripts are publicly
available at
https://github.com/zzz47zzz/pretrained-lm-for-incremental-learning.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07894" title="Abstract">arXiv:2312.07894</a> [<a href="/pdf/2312.07894" title="Download PDF">pdf</a>, <a href="/format/2312.07894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimization of Power Control for Autonomous Hybrid Electric Vehicles  with Flexible Power Demand
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kargar%2C+M">Mohammadali Kargar</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+X">Xingyong Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Technology advancement for on-road vehicles has gained significant momentum
in the past decades, particularly in the field of vehicle automation and
powertrain electrification. The optimization of powertrain controls for
autonomous vehicles typically involves a separated consideration of the
vehicle's external dynamics and powertrain dynamics, with one key aspect often
overlooked. This aspect, known as flexible power demand, recognizes that the
powertrain control system does not necessarily have to precisely match the
power requested by the vehicle motion controller at all times. Leveraging this
feature can lead to control designs achieving improved fuel economy by adding
an extra degree of freedom to the powertrain control. The present research
investigates the use of an Approximate Dynamic Programming (ADP) approach to
develop a powertrain controller, which takes into account the flexibility in
power demand within the ADP framework. The formulation is based on an
autonomous hybrid electric vehicle (HEV), while the methodology can also be
applied to other types of vehicles. It is also found that necessary
customization of the ADP algorithm is needed for this particular control
problem to prevent convergence issues. Finally, a case study is presented to
evaluate the effectiveness of the investigated method.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07895" title="Abstract">arXiv:2312.07895</a> [<a href="/pdf/2312.07895" title="Download PDF">pdf</a>, <a href="/ps/2312.07895" title="Download PostScript">ps</a>, <a href="/format/2312.07895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fluid Antenna-Assisted MIMO Transmission Exploiting Statistical CSI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yuqi Ye</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+L">Li You</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kai-Kit Wong</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiqi Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to appear in IEEE Communications Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In conventional multiple-input multiple-output (MIMO) communication systems,
the positions of antennas are fixed. To take full advantage of spatial degrees
of freedom, a new technology called fluid antenna (FA) is proposed to obtain
higher achievable rate and diversity gain. Most existing works on FA exploit
instantaneous channel state information (CSI). However, in FA-assisted systems,
it is difficult to obtain instantaneous CSI since changes in the antenna
position will lead to channel variation. In this letter, we investigate a
FA-assisted MIMO system using relatively slow-varying statistical CSI.
Specifically, in the criterion of rate maximization, we propose an algorithmic
framework for transmit precoding and transmit/receive FAs position designs with
statistical CSI. Simulation results show that our proposed algorithm in
FA-assisted systems significantly outperforms baselines in terms of rate
performance.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07896" title="Abstract">arXiv:2312.07896</a> [<a href="/pdf/2312.07896" title="Download PDF">pdf</a>, <a href="/format/2312.07896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TRACTOR: Traffic Analysis and Classification Tool for Open RAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Groen%2C+J">Joshua Groen</a>, 
<a href="/search/eess?searchtype=author&query=Belgiovine%2C+M">Mauro Belgiovine</a>, 
<a href="/search/eess?searchtype=author&query=Demir%2C+U">Utku Demir</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+B">Brian Kim</a>, 
<a href="/search/eess?searchtype=author&query=Chowdhury%2C+K">Kaushik Chowdhury</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures, 2 tables, submitted to ICC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">5G and beyond cellular networks promise remarkable advancements in bandwidth,
latency, and connectivity. The emergence of Open Radio Access Network (O-RAN)
represents a pivotal direction for the evolution of cellular networks,
inherently supporting machine learning (ML) for network operation control.
Within this framework, RAN Intelligence Controllers (RICs) from one provider
can employ ML models developed by third-party vendors through the acquisition
of key performance indicators (KPIs) from geographically distant base stations
or user equipment (UE). Yet, the development of ML models hinges on the
availability of realistic and robust datasets. In this study, we embark on a
two-fold journey. First, we collect a comprehensive 5G dataset, harnessing
real-world cell phones across diverse applications, locations, and mobility
scenarios. Next, we replicate this traffic within a full-stack srsRAN-based
O-RAN framework on Colosseum, the world's largest radio frequency (RF)
emulator. This process yields a robust and O-RAN compliant KPI dataset
mirroring real-world conditions. We illustrate how such a dataset can fuel the
training of ML models and facilitate the deployment of xApps for traffic slice
classification by introducing a CNN based classifier that achieves accuracy
$&gt;95\%$ offline and $92\%$ online. To accelerate research in this domain, we
provide open-source access to our toolchain and supplementary utilities,
empowering the broader research community to expedite the creation of realistic
and O-RAN compliant datasets.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07898" title="Abstract">arXiv:2312.07898</a> [<a href="/pdf/2312.07898" title="Download PDF">pdf</a>, <a href="/format/2312.07898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensuring End-to-End Security with Fine-grained Access Control for  Connected and Autonomous Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Donghyun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sungho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+R">Ruei-Hau Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jemin Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">As advanced V2X applications emerge in the connected and autonomous vehicle
(CAV), the data communications between in-vehicle end-devices and outside nodes
increase, which make the end-to-end (E2E) security to in-vehicle end-devices as
the urgent issue to be handled. However, the E2E security with fine-grained
access control still remains as a challenging issue for resource-constrained
end-devices since the existing security solutions require complicated key
management and high resource consumption. Therefore, we propose a practical and
secure vehicular communication protocol for the E2E security based on a new
attribute-based encryption (ABE) scheme. In our scheme, the outsourced
computation is provided for encryption, and the computation cost for decryption
constantly remains small, regardless of the number of attributes. The policy
privacy can be ensured by the proposed ABE to support privacy-sensitive V2X
applications, and the existing identity-based signature for outsourced signing
is newly reconstructed. Our scheme achieves the confidentiality, message
authentication, identity anonymity, unlinkability, traceability, and
reconfigurable outsourced computation, and we also show the practical
feasibility of our protocol via the performance evaluation.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07901" title="Abstract">arXiv:2312.07901</a> [<a href="/pdf/2312.07901" title="Download PDF">pdf</a>, <a href="/ps/2312.07901" title="Download PostScript">ps</a>, <a href="/format/2312.07901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Artificial Intelligence Studies in Cartography: A Review and Synthesis  of Methods, Applications, and Ethics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yuhao Kang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Song Gao</a>, 
<a href="/search/cs?searchtype=author&query=Roth%2C+R+E">Robert E. Roth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 98 pages, 7 figures, accepted by the Cartography and Geographic Information Science
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">The past decade has witnessed the rapid development of geospatial artificial
intelligence (GeoAI) primarily due to the ground-breaking achievements in deep
learning and machine learning. A growing number of scholars from cartography
have demonstrated successfully that GeoAI can accelerate previously complex
cartographic design tasks and even enable cartographic creativity in new ways.
Despite the promise of GeoAI, researchers and practitioners have growing
concerns about the ethical issues of GeoAI for cartography. In this paper, we
conducted a systematic content analysis and narrative synthesis of research
studies integrating GeoAI and cartography to summarize current research and
development trends regarding the usage of GeoAI for cartographic design. Based
on this review and synthesis, we first identify dimensions of GeoAI methods for
cartography such as data sources, data formats, map evaluations, and six
contemporary GeoAI models, each of which serves a variety of cartographic
tasks. These models include decision trees, knowledge graph and semantic web
technologies, deep convolutional neural networks, generative adversarial
networks, graph neural networks, and reinforcement learning. Further, we
summarize seven cartographic design applications where GeoAI have been
effectively employed: generalization, symbolization, typography, map reading,
map interpretation, map analysis, and map production. We also raise five
potential ethical challenges that need to be addressed in the integration of
GeoAI for cartography: commodification, responsibility, privacy, bias, and
(together) transparency, explainability, and provenance. We conclude by
identifying four potential research directions for future cartographic research
with GeoAI: GeoAI-enabled active cartographic symbolism, human-in-the-loop
GeoAI for cartography, GeoAI-based mapping-as-a-service, and generative GeoAI
for cartography.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07905" title="Abstract">arXiv:2312.07905</a> [<a href="/pdf/2312.07905" title="Download PDF">pdf</a>, <a href="/ps/2312.07905" title="Download PostScript">ps</a>, <a href="/format/2312.07905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Plant Disease Recognition Datasets in the Age of Deep Learning:  Challenges and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mingle Xu</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J+E">Ji Eun Park</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaehwan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jucheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S">Sook Yoon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submission v1 to a journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Plant disease recognition has witnessed a significant improvement with deep
learning in recent years. Although plant disease datasets are essential and
many relevant datasets are public available, two fundamental questions exist.
First, how to differentiate datasets and further choose suitable public
datasets for specific applications? Second, what kinds of characteristics of
datasets are desired to achieve promising performance in real-world
applications? To address the questions, this study explicitly propose an
informative taxonomy to describe potential plant disease datasets. We further
provide several directions for future, such as creating challenge-oriented
datasets and the ultimate objective deploying deep learning in real-world
applications with satisfactory performance. In addition, existing related
public RGB image datasets are summarized. We believe that this study will
contributing making better datasets and that this study will contribute beyond
plant disease recognition such as plant species recognition. To facilitate the
community, our project is public https://github.com/xml94/PPDRD with the
information of relevant public datasets.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07910" title="Abstract">arXiv:2312.07910</a> [<a href="/pdf/2312.07910" title="Download PDF">pdf</a>, <a href="/format/2312.07910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PromptBench: A Unified Library for Evaluation of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Kaijie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qinlin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jindong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An extension to PromptBench (<a href="/abs/2306.04528">arXiv:2306.04528</a>) for unified evaluation of LLMs using the same name; code: <a href="https://github.com/microsoft/promptbench">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">The evaluation of large language models (LLMs) is crucial to assess their
performance and mitigate potential security risks. In this paper, we introduce
PromptBench, a unified library to evaluate LLMs. It consists of several key
components that are easily used and extended by researchers: prompt
construction, prompt engineering, dataset and model loading, adversarial prompt
attack, dynamic evaluation protocols, and analysis tools. PromptBench is
designed to be an open, general, and flexible codebase for research purposes
that can facilitate original study in creating new benchmarks, deploying
downstream applications, and designing new evaluation protocols. The code is
available at: https://github.com/microsoft/promptbench and will be continuously
supported.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07913" title="Abstract">arXiv:2312.07913</a> [<a href="/pdf/2312.07913" title="Download PDF">pdf</a>, <a href="/format/2312.07913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Text Watermarking in the Era of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Aiwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Leyi Pan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yijian Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingjing Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xuming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+L">Lijie Wen</a>, 
<a href="/search/cs?searchtype=author&query=King%2C+I">Irwin King</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In recent years, significant advancements have been made in the text
generation capabilities of Large Language Models (LLMs), demonstrating
exceptional performance in downstream tasks such as abstract summarization,
dialogue generation, and data-to-text conversion. However, their generative
abilities also pose risks such as the rapid spread of fake news, infringement
of datasets/LLM copyrights, and challenges to academic integrity. Text
watermarking technology emerges as a potential solution. By embedding invisible
yet detectable patterns in generated texts, it helps in tracking and verifying
text origins, thus preventing misuse and piracy.
<br />This survey aims to comprehensively summarize current text watermarking
technologies, covering three main aspects: (1) an overview and comparison of
different text watermarking techniques; (2) evaluation methods for text
watermarking algorithms, including their success rate, impact on text quality,
robustness, and unforgeability; (3) potential applications of text watermarking
technologys. This survey aims to help researchers thoroughly understanding the
text watermarking technologies, thereby fostering further development.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07917" title="Abstract">arXiv:2312.07917</a> [<a href="/pdf/2312.07917" title="Download PDF">pdf</a>, <a href="/format/2312.07917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Designing Multi-UAV aided Wireless Powered Dynamic Communication via  Hierarchical Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z+Y">Ze Yu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+Y+L">Yue Ling Che</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Sheng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+G">Gege Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kaishun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Leung%2C+V+C+M">Victor C. M. Leung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures; Submitted for possible journal publishing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper proposes a novel design on the wireless powered communication
network (WPCN) in dynamic environments under the assistance of multiple
unmanned aerial vehicles (UAVs). Unlike the existing studies, where the
low-power wireless nodes (WNs) often conform to the coherent
harvest-then-transmit protocol, under our newly proposed double-threshold based
WN type updating rule, each WN can dynamically and repeatedly update its WN
type as an E-node for non-linear energy harvesting over time slots or an I-node
for transmitting data over sub-slots. To maximize the total transmission data
size of all the WNs over T slots, each of the UAVs individually determines its
trajectory and binary wireless energy transmission (WET) decisions over times
slots and its binary wireless data collection (WDC) decisions over sub-slots,
under the constraints of each UAV's limited on-board energy and each WN's node
type updating rule. However, due to the UAVs' tightly-coupled trajectories with
their WET and WDC decisions, as well as each WN's time-varying battery energy,
this problem is difficult to solve optimally. We then propose a new multi-agent
based hierarchical deep reinforcement learning (MAHDRL) framework with two
tiers to solve the problem efficiently, where the soft actor critic (SAC)
policy is designed in tier-1 to determine each UAV's continuous trajectory and
binary WET decision over time slots, and the deep-Q learning (DQN) policy is
designed in tier-2 to determine each UAV's binary WDC decisions over sub-slots
under the given UAV trajectory from tier-1. Both of the SAC policy and the DQN
policy are executed distributively at each UAV. Finally, extensive simulation
results are provided to validate the outweighed performance of the proposed
MAHDRL approach over various state-of-the-art benchmarks.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07920" title="Abstract">arXiv:2312.07920</a> [<a href="/pdf/2312.07920" title="Download PDF">pdf</a>, <a href="/format/2312.07920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DrivingGaussian: Composite Gaussian Splatting for Surrounding Dynamic  Autonomous Driving Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaoyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhiwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+X">Xiaojun Shan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongtao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Deqing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present DrivingGaussian, an efficient and effective framework for
surrounding dynamic autonomous driving scenes. For complex scenes with moving
objects, we first sequentially and progressively model the static background of
the entire scene with incremental static 3D Gaussians. We then leverage a
composite dynamic Gaussian graph to handle multiple moving objects,
individually reconstructing each object and restoring their accurate positions
and occlusion relationships within the scene. We further use a LiDAR prior for
Gaussian Splatting to reconstruct scenes with greater details and maintain
panoramic consistency. DrivingGaussian outperforms existing methods in driving
scene reconstruction and enables photorealistic surround-view synthesis with
high-fidelity and multi-camera consistency. The source code and trained models
will be released.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07921" title="Abstract">arXiv:2312.07921</a> [<a href="/pdf/2312.07921" title="Download PDF">pdf</a>, <a href="/format/2312.07921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BinGo: Identifying Security Patches in Binary Code with Graph  Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xu He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+P">Pengbin Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinda Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shiyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qi Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+K">Kun Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by ACM ASIA Conference on Computer and Communications Security (AsiaCCS), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">A timely software update is vital to combat the increasing security
vulnerabilities. However, some software vendors may secretly patch their
vulnerabilities without creating CVE entries or even describing the security
issue in their change log. Thus, it is critical to identify these hidden
security patches and defeat potential N-day attacks. Researchers have employed
various machine learning techniques to identify security patches in open-source
software, leveraging the syntax and semantic features of the software changes
and commit messages. However, all these solutions cannot be directly applied to
the binary code, whose instructions and program flow may dramatically vary due
to different compilation configurations. In this paper, we propose BinGo, a new
security patch detection system for binary code. The main idea is to present
the binary code as code property graphs to enable a comprehensive understanding
of program flow and perform a language model over each basic block of binary
code to catch the instruction semantics. BinGo consists of four phases, namely,
patch data pre-processing, graph extraction, embedding generation, and graph
representation learning. Due to the lack of an existing binary security patch
dataset, we construct such a dataset by compiling the pre-patch and post-patch
source code of the Linux kernel. Our experimental results show BinGo can
achieve up to 80.77% accuracy in identifying security patches between two
neighboring versions of binary code. Moreover, BinGo can effectively reduce the
false positives and false negatives caused by the different compilers and
optimization levels.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07922" title="Abstract">arXiv:2312.07922</a> [<a href="/pdf/2312.07922" title="Download PDF">pdf</a>, <a href="/format/2312.07922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory-Efficient Reversible Spiking Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Spiking neural networks (SNNs) are potential competitors to artificial neural
networks (ANNs) due to their high energy-efficiency on neuromorphic hardware.
However, SNNs are unfolded over simulation time steps during the training
process. Thus, SNNs require much more memory than ANNs, which impedes the
training of deeper SNN models. In this paper, we propose the reversible spiking
neural network to reduce the memory cost of intermediate activations and
membrane potentials during training. Firstly, we extend the reversible
architecture along temporal dimension and propose the reversible spiking block,
which can reconstruct the computational graph and recompute all intermediate
variables in forward pass with a reverse process. On this basis, we adopt the
state-of-the-art SNN models to the reversible variants, namely reversible
spiking ResNet (RevSResNet) and reversible spiking transformer (RevSFormer).
Through experiments on static and neuromorphic datasets, we demonstrate that
the memory cost per image of our reversible SNNs does not increase with the
network depth. On CIFAR10 and CIFAR100 datasets, our RevSResNet37 and
RevSFormer-4-384 achieve comparable accuracies and consume 3.79x and 3.00x
lower GPU memory per image than their counterparts with roughly identical model
complexity and parameters. We believe that this work can unleash the memory
constraints in SNN training and pave the way for training extremely large and
deep SNNs. The code is available at https://github.com/mi804/RevSNN.git.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07925" title="Abstract">arXiv:2312.07925</a> [<a href="/pdf/2312.07925" title="Download PDF">pdf</a>, <a href="/format/2312.07925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polar-Doc: One-Stage Document Dewarping with Multi-Scope Constraints  under Polar Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiguang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiufeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaizhu Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Document dewarping, aiming to eliminate geometric deformation in photographed
documents to benefit text recognition, has made great progress in recent years
but is still far from being solved. While Cartesian coordinates are typically
leveraged by state-of-the-art approaches to learn a group of deformation
control points, such representation is not efficient for dewarping model to
learn the deformation information. In this work, we explore Polar coordinates
representation for each point in document dewarping, namely Polar-Doc. In
contrast to most current works adopting a two-stage pipeline typically, Polar
representation enables a unified point regression framework for both
segmentation and dewarping network in one single stage. Such unification makes
the whole model more efficient to learn under an end-to-end optimization
pipeline, and also obtains a compact representation. Furthermore, we propose a
novel multi-scope Polar-Doc-IOU loss to constrain the relationship among
control points as a grid-based regularization under the Polar representation.
Visual comparisons and quantitative experiments on two benchmarks show that,
with much fewer parameters than the other mainstream counterparts, our
one-stage model with multi-scope constraints achieves new state-of-the-art
performance on both pixel alignment metrics and OCR metrics. Source codes will
be available at \url{*****}.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07929" title="Abstract">arXiv:2312.07929</a> [<a href="/pdf/2312.07929" title="Download PDF">pdf</a>, <a href="/format/2312.07929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust and Performance Incentivizing Algorithms for Multi-Armed Bandits  with Strategic Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esmaeili%2C+S+A">Seyed A. Esmaeili</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+S">Suho Shin</a>, 
<a href="/search/cs?searchtype=author&query=Slivkins%2C+A">Aleksandrs Slivkins</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We consider a variant of the stochastic multi-armed bandit problem.
Specifically, the arms are strategic agents who can improve their rewards or
absorb them. The utility of an agent increases if she is pulled more or absorbs
more of her rewards but decreases if she spends more effort improving her
rewards. Agents have heterogeneous properties, specifically having different
means and able to improve their rewards up to different levels. Further, a
non-empty subset of agents are ''honest'' and in the worst case always give
their rewards without absorbing any part. The principal wishes to obtain a high
revenue (cumulative reward) by designing a mechanism that incentives top level
performance at equilibrium. At the same time, the principal wishes to be robust
and obtain revenue at least at the level of the honest agent with the highest
mean in case of non-equilibrium behaviour. We identify a class of MAB
algorithms which we call performance incentivizing which satisfy a collection
of properties and show that they lead to mechanisms that incentivize top level
performance at equilibrium and are robust under any strategy profile.
Interestingly, we show that UCB is an example of such a MAB algorithm. Further,
in the case where the top performance level is unknown we show that combining
second price auction ideas with performance incentivizing algorithms achieves
performance at least at the second top level while also being robust.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07930" title="Abstract">arXiv:2312.07930</a> [<a href="/pdf/2312.07930" title="Download PDF">pdf</a>, <a href="/format/2312.07930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Optimal Statistical Watermarking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Baihe Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Banghua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hanlin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+D">Jason D. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+J">Jiantao Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Jordan%2C+M+I">Michael I. Jordan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR); Information Theory (cs.IT); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study statistical watermarking by formulating it as a hypothesis testing
problem, a general framework which subsumes all previous statistical
watermarking methods. Key to our formulation is a coupling of the output tokens
and the rejection region, realized by pseudo-random generators in practice,
that allows non-trivial trade-off between the Type I error and Type II error.
We characterize the Uniformly Most Powerful (UMP) watermark in this context. In
the most common scenario where the output is a sequence of $n$ tokens, we
establish matching upper and lower bounds on the number of i.i.d. tokens
required to guarantee small Type I and Type II errors. Our rate scales as
$\Theta(h^{-1} \log (1/h))$ with respect to the average entropy per token $h$
and thus greatly improves the $O(h^{-2})$ rate in the previous works. For
scenarios where the detector lacks knowledge of the model's distribution, we
introduce the concept of model-agnostic watermarking and establish the minimax
bounds for the resultant increase in Type II error. Moreover, we formulate the
robust watermarking problem where user is allowed to perform a class of
perturbation on the generated texts, and characterize the optimal type II error
of robust UMP tests via a linear programming problem. To the best of our
knowledge, this is the first systematic statistical treatment on the
watermarking problem with near-optimal rates in the i.i.d. setting, and might
be of interest for future works.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07931" title="Abstract">arXiv:2312.07931</a> [<a href="/pdf/2312.07931" title="Download PDF">pdf</a>, <a href="/format/2312.07931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Levenshtein Distance Embedding with Poisson Regression for DNA Storage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+A+J+X">Alan J.X. Guo</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Sihan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+M">Mengyi Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wei Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Efficient computation or approximation of Levenshtein distance, a widely-used
metric for evaluating sequence similarity, has attracted significant attention
with the emergence of DNA storage and other biological applications. Sequence
embedding, which maps Levenshtein distance to a conventional distance between
embedding vectors, has emerged as a promising solution. In this paper, a novel
neural network-based sequence embedding technique using Poisson regression is
proposed. We first provide a theoretical analysis of the impact of embedding
dimension on model performance and present a criterion for selecting an
appropriate embedding dimension. Under this embedding dimension, the Poisson
regression is introduced by assuming the Levenshtein distance between sequences
of fixed length following a Poisson distribution, which naturally aligns with
the definition of Levenshtein distance. Moreover, from the perspective of the
distribution of embedding distances, Poisson regression approximates the
negative log likelihood of the chi-squared distribution and offers advancements
in removing the skewness. Through comprehensive experiments on real DNA storage
data, we demonstrate the superior performance of the proposed method compared
to state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07935" title="Abstract">arXiv:2312.07935</a> [<a href="/pdf/2312.07935" title="Download PDF">pdf</a>, <a href="/ps/2312.07935" title="Download PostScript">ps</a>, <a href="/format/2312.07935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing YOLOv8 and Mask RCNN for object segmentation in complex  orchard environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sapkota%2C+R">Ranjan Sapkota</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+D">Dawood Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Karkee%2C+M">Manoj Karkee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Instance segmentation, an important image processing operation for automation
in agriculture, is used to precisely delineate individual objects of interest
within images, which provides foundational information for various automated or
robotic tasks such as selective harvesting and precision pruning. This study
compares the one-stage YOLOv8 and the two-stage Mask R-CNN machine learning
models for instance segmentation under varying orchard conditions across two
datasets. Dataset 1, collected in dormant season, includes images of dormant
apple trees, which were used to train multi-object segmentation models
delineating tree branches and trunks. Dataset 2, collected in the early growing
season, includes images of apple tree canopies with green foliage and immature
(green) apples (also called fruitlet), which were used to train single-object
segmentation models delineating only immature green apples. The results showed
that YOLOv8 performed better than Mask R-CNN, achieving good precision and
near-perfect recall across both datasets at a confidence threshold of 0.5.
Specifically, for Dataset 1, YOLOv8 achieved a precision of 0.90 and a recall
of 0.95 for all classes. In comparison, Mask R-CNN demonstrated a precision of
0.81 and a recall of 0.81 for the same dataset. With Dataset 2, YOLOv8 achieved
a precision of 0.93 and a recall of 0.97. Mask R-CNN, in this single-class
scenario, achieved a precision of 0.85 and a recall of 0.88. Additionally, the
inference times for YOLOv8 were 10.9 ms for multi-class segmentation (Dataset
1) and 7.8 ms for single-class segmentation (Dataset 2), compared to 15.6 ms
and 12.8 ms achieved by Mask R-CNN's, respectively.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07936" title="Abstract">arXiv:2312.07936</a> [<a href="/pdf/2312.07936" title="Download PDF">pdf</a>, <a href="/format/2312.07936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coordinated Intra- and Inter-system Interference Management in  Integrated Satellite Terrestrial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziyue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+M">Min Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiandong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Leveraging the advantage of satellite and terrestrial networks, the
integrated satellite terrestrial networks (ISTNs) can help to achieve seamless
global access and eliminate the digital divide. However, the dense deployment
and frequent handover of satellites aggravate intra- and inter-system
interference, resulting in a decrease in downlink sum rate. To address this
issue, we propose a coordinated intra- and inter-system interference management
algorithm for ISTN. This algorithm coordinates multidimensional interference
through a joint design of inter-satellite handover and resource allocation
method. On the one hand, we take inter-system interference between low earth
orbit (LEO) and geostationary orbit (GEO) satellites as a constraint, and
reduce interference to GEO satellite ground stations (GEO-GS) while ensuring
system capacity through inter-satellite handover. On the other hand, satellite
and terrestrial resource allocation schemes are designed based on the matching
idea, and channel gain and interference to other channels are considered during
the matching process to coordinate co-channel interference. In order to avoid
too many unnecessary handovers, we consider handover scenarios related to
service capabilities and service time to determine the optimal handover target
satellite. Numerical results show that the gap between the results on the
system sum rate obtained by the proposed method and the upper bound is reduced
as the user density increases, and the handover frequency can be significantly
reduced.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07937" title="Abstract">arXiv:2312.07937</a> [<a href="/pdf/2312.07937" title="Download PDF">pdf</a>, <a href="/format/2312.07937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BOTH2Hands: Inferring 3D Hands from Both Text Prompts and Body Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenqian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Molin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuxuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Juze Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jingyi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingya Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The recently emerging text-to-motion advances have spired numerous attempts
for convenient and interactive human motion generation. Yet, existing methods
are largely limited to generating body motions only without considering the
rich two-hand motions, let alone handling various conditions like body dynamics
or texts. To break the data bottleneck, we propose BOTH57M, a novel multi-modal
dataset for two-hand motion generation. Our dataset includes accurate motion
tracking for the human body and hands and provides pair-wised finger-level hand
annotations and body descriptions. We further provide a strong baseline method,
BOTH2Hands, for the novel task: generating vivid two-hand motions from both
implicit body dynamics and explicit text prompts. We first warm up two parallel
body-to-hand and text-to-hand diffusion models and then utilize the
cross-attention transformer for motion blending. Extensive experiments and
cross-validations demonstrate the effectiveness of our approach and dataset for
generating convincing two-hand motions from the hybrid body-and-textual
conditions. Our dataset and code will be disseminated to the community for
future research.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07940" title="Abstract">arXiv:2312.07940</a> [<a href="/pdf/2312.07940" title="Download PDF">pdf</a>, <a href="/ps/2312.07940" title="Download PostScript">ps</a>, <a href="/format/2312.07940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence analysis of Hermite approximations for analytic functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+H">Haiyong Wang</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+L">Lun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we present a rigorous analysis of root-exponential convergence
of Hermite approximations, including projection and interpolation methods, for
functions that are analytic in an infinite strip containing the real axis and
satisfy certain restrictions on the asymptotic behavior at infinity within this
strip. Asymptotically sharp error bounds in the weighted and maximum norms are
derived. The key ingredients of our analysis are some remarkable contour
integral representations for the Hermite coefficients and the remainder of
Hermite spectral interpolations. Further extensions to Gauss--Hermite
quadrature, Hermite spectral differentiations, generalized Hermite spectral
approximations and the scaling factor of Hermite approximation are also
discussed. Numerical experiments confirm our theoretical results.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07941" title="Abstract">arXiv:2312.07941</a> [<a href="/pdf/2312.07941" title="Download PDF">pdf</a>, <a href="/ps/2312.07941" title="Download PostScript">ps</a>, <a href="/format/2312.07941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An efficient algorithm for multiuser sum-rate maximization of  large-scale active RIS-aided MIMO system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+M">Mingjie Shao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Ju Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Active reconfigurable intelligent surface (RIS) is a new RIS architecture
that can reflect and amplify communication signals. It can provide enhanced
performance gain compared to the conventional passive RIS systems that can only
reflect the signals. On the other hand, the design problem of active RIS-aided
systems is more challenging than the passive RIS-aided systems and its
efficient algorithms are less studied. In this paper, we consider the sum rate
maximization problem in the multiuser massive multiple-input single-output
(MISO) downlink with the aid of a large-scale active RIS. Existing approaches
usually resort to general optimization solvers and can be computationally
prohibitive in the considered settings. We propose an efficient block
successive upper bound minimization (BSUM) method, of which each step has a
(semi) closed-form update. Thus, the proposed algorithm has an attractive low
per-iteration complexity. By simulation, our proposed algorithm consumes much
less computation than the existing approaches. In particular, when the MIMO
and/or RIS sizes are large, our proposed algorithm can be orders-of-magnitude
faster than existing approaches.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07942" title="Abstract">arXiv:2312.07942</a> [<a href="/pdf/2312.07942" title="Download PDF">pdf</a>, <a href="/format/2312.07942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Diffusions under Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Q">Qian Yan</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Keqi Han</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+T">Ting Gan</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jiawei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Quanqing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+C">Chuanhui Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">To infer a diffusion network based on observations from historical diffusion
processes, existing approaches assume that observation data contain exact
occurrence time of each node infection, or at least the eventual infection
statuses of nodes in each diffusion process. They determine potential influence
relationships between nodes by identifying frequent sequences, or statistical
correlations, among node infections. In some real-world settings, such as the
spread of epidemics, tracing exact infection times is often infeasible due to a
high cost; even obtaining precise infection statuses of nodes is a challenging
task, since observable symptoms such as headache only partially reveal a node's
true status. In this work, we investigate how to effectively infer a diffusion
network from observation data with uncertainty. Provided with only
probabilistic information about node infection statuses, we formulate the
problem of diffusion network inference as a constrained nonlinear regression
w.r.t. the probabilistic data. An alternating maximization method is designed
to solve this regression problem iteratively, and the improvement of solution
quality in each iteration can be theoretically guaranteed. Empirical studies
are conducted on both synthetic and real-world networks, and the results verify
the effectiveness and efficiency of our approach.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07943" title="Abstract">arXiv:2312.07943</a> [<a href="/pdf/2312.07943" title="Download PDF">pdf</a>, <a href="/format/2312.07943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReFusion: Learning Image Fusion from Reconstruction with Learnable Loss  via Meta-Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+H">Haowen Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zixiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiangshe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yichen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+L">Lilun Deng</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yukun Cui</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shuang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Baisong Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image fusion aims to combine information from multiple source images into a
single and more informative image. A major challenge for deep learning-based
image fusion algorithms is the absence of a definitive ground truth and
distance measurement. Thus, the manually specified loss functions aiming to
steer the model learning, include hyperparameters that need to be manually
thereby limiting the model's flexibility and generalizability to unseen tasks.
To overcome the limitations of designing loss functions for specific fusion
tasks, we propose a unified meta-learning based fusion framework named
ReFusion, which learns optimal fusion loss from reconstructing source images.
ReFusion consists of a fusion module, a loss proposal module, and a
reconstruction module. Compared with the conventional methods with fixed loss
functions, ReFusion employs a parameterized loss function, which is dynamically
adapted by the loss proposal module based on the specific fusion scene and
task. To ensure that the fusion network preserves maximal information from the
source images, makes it possible to reconstruct the original images from the
fusion image, a meta-learning strategy is used to make the reconstruction loss
continually refine the parameters of the loss proposal module. Adaptive
updating is achieved by alternating between inter update, outer update, and
fusion update, where the training of the three components facilitates each
other. Extensive experiments affirm that our method can successfully adapt to
diverse fusion tasks, including infrared-visible, multi-focus, multi-exposure,
and medical image fusion problems. The code will be released.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07945" title="Abstract">arXiv:2312.07945</a> [<a href="/pdf/2312.07945" title="Download PDF">pdf</a>, <a href="/format/2312.07945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear Combination of Exponential Moving Averages for Wireless Channel  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Formis%2C+G">Gabriele Formis</a>, 
<a href="/search/cs?searchtype=author&query=Scanzio%2C+S">Stefano Scanzio</a>, 
<a href="/search/cs?searchtype=author&query=Cena%2C+G">Gianluca Cena</a>, 
<a href="/search/cs?searchtype=author&query=Valenzano%2C+A">Adriano Valenzano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint, 6 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE 21st International Conference on Industrial Informatics
  (INDIN 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The ability to predict the behavior of a wireless channel in terms of the
frame delivery ratio is quite valuable, and permits, e.g., to optimize the
operating parameters of a wireless network at runtime, or to proactively react
to the degradation of the channel quality, in order to meet the stringent
requirements about dependability and end-to-end latency that typically
characterize industrial applications.
<br />In this work, prediction models based on the exponential moving average (EMA)
are investigated in depth, which are proven to outperform other simple
statistical methods and whose performance is nearly as good as artificial
neural networks, but with dramatically lower computational requirements.
Regarding the innovation and motivation of this work, a new model that we
called EMA linear combination (ELC), is introduced, explained, and evaluated
experimentally.
<br />Its prediction accuracy, tested on some databases acquired from a real setup
based on Wi-Fi devices, showed that ELC brings tangible improvements over EMA
in any experimental conditions, the only drawback being a slight increase in
computational complexity.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07946" title="Abstract">arXiv:2312.07946</a> [<a href="/pdf/2312.07946" title="Download PDF">pdf</a>, <a href="/ps/2312.07946" title="Download PostScript">ps</a>, <a href="/format/2312.07946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incremental Computation: What Is the Essence?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y+A">Yanhong A. Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Incremental computation aims to compute more efficiently on changed input by
reusing previously computed results. We give a high-level overview of works on
incremental computation, and highlight the essence underlying all of them,
which we call incrementalization -- the discrete counterpart of differentiation
in calculus. We review the gist of a systematic method for incrementalization,
and a systematic method centered around it, called
Iterate-Incrementalize-Implement, for program design and optimization, as well
as algorithm design and optimization. At a meta-level, with historical contexts
and for future directions, we stress the power of high-level data, control, and
module abstractions in developing new and better algorithms and programs as
well as their precise complexities.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07947" title="Abstract">arXiv:2312.07947</a> [<a href="/pdf/2312.07947" title="Download PDF">pdf</a>, <a href="/format/2312.07947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Differentially Quantized Subspace Perturbation (ADQSP): A  Unified Framework for Privacy-Preserving Distributed Average Consensus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qiongxiu Li</a>, 
<a href="/search/cs?searchtype=author&query=Gundersen%2C+J+S">Jaron Skovsted Gundersen</a>, 
<a href="/search/cs?searchtype=author&query=Lopuhaa-Zwakenberg%2C+M">Milan Lopuhaa-Zwakenberg</a>, 
<a href="/search/cs?searchtype=author&query=Heusdens%2C+R">Richard Heusdens</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Privacy-preserving distributed average consensus has received significant
attention recently due to its wide applicability. Based on the achieved
performances, existing approaches can be broadly classified into perfect
accuracy-prioritized approaches such as secure multiparty computation (SMPC),
and worst-case privacy-prioritized approaches such as differential privacy
(DP). Methods of the first class achieve perfect output accuracy but reveal
some private information, while methods from the second class provide privacy
against the strongest adversary at the cost of a loss of accuracy. In this
paper, we propose a general approach named adaptive differentially quantized
subspace perturbation (ADQSP) which combines quantization schemes with
so-called subspace perturbation. Although not relying on cryptographic
primitives, the proposed approach enjoys the benefits of both
accuracy-prioritized and privacy-prioritized methods and is able to unify them.
More specifically, we show that by varying a single quantization parameter the
proposed method can vary between SMPC-type performances and DP-type
performances. Our results show the potential of exploiting traditional
distributed signal processing tools for providing cryptographic guarantees. In
addition to a comprehensive theoretical analysis, numerical validations are
conducted to substantiate our results.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07948" title="Abstract">arXiv:2312.07948</a> [<a href="/pdf/2312.07948" title="Download PDF">pdf</a>, <a href="/format/2312.07948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Knowledge Proof of Traffic: A Deterministic and Privacy-Preserving  Cross Verification Mechanism for Cooperative Perception Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+Y">Ye Tao</a>, 
<a href="/search/cs?searchtype=author&query=Javanmardi%2C+E">Ehsan Javanmardi</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+P">Pengfei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Nakazato%2C+J">Jin Nakazato</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuze Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Tsukada%2C+M">Manabu Tsukada</a>, 
<a href="/search/cs?searchtype=author&query=Esaki%2C+H">Hiroshi Esaki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Cooperative perception is crucial for connected automated vehicles in
intelligent transportation systems (ITSs); however, ensuring the authenticity
of perception data remains a challenge as the vehicles cannot verify events
that they do not witness independently. Various studies have been conducted on
establishing the authenticity of data, such as trust-based statistical methods
and plausibility-based methods. However, these methods are limited as they
require prior knowledge such as previous sender behaviors or predefined rules
to evaluate the authenticity. To overcome this limitation, this study proposes
a novel approach called zero-knowledge Proof of Traffic (zk-PoT), which
involves generating cryptographic proofs to the traffic observations. Multiple
independent proofs regarding the same vehicle can be deterministically
cross-verified by any receivers without relying on ground truth, probabilistic,
or plausibility evaluations. Additionally, no private information is
compromised during the entire procedure. A full on-board unit software stack
that reflects the behavior of zk-PoT is implemented within a specifically
designed simulator called Flowsim. A comprehensive experimental analysis is
then conducted using synthesized city-scale simulations, which demonstrates
that zk-PoT's cross-verification ratio ranges between 80 % to 96 %, and 80 % of
the verification is achieved in 2 s, with a protocol overhead of approximately
25 %. Furthermore, the analyses of various attacks indicate that most of the
attacks could be prevented, and some, such as collusion attacks, can be
mitigated. The proposed approach can be incorporated into existing works,
including the European Telecommunications Standards Institute (ETSI) and the
International Organization for Standardization (ISO) ITS standards, without
disrupting the backward compatibility.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07950" title="Abstract">arXiv:2312.07950</a> [<a href="/pdf/2312.07950" title="Download PDF">pdf</a>, <a href="/format/2312.07950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CBQ: Cross-Block Quantization for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+X">Xin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhijun Tu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hanting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yehui Tang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zhiwei Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+B">Baoqun Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhe Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Post-training quantization (PTQ) has driven attention to producing efficient
large language models (LLMs) with ultra-low costs. Since hand-craft
quantization parameters lead to low performance in low-bit quantization, recent
methods optimize the quantization parameters through block-wise reconstruction
between the floating-point and quantized models. However, these methods suffer
from two challenges: accumulated errors from independent one-by-one block
quantization and reconstruction difficulties from extreme weight and activation
outliers. To address these two challenges, we propose CBQ, a cross-block
reconstruction-based PTQ method for LLMs. To reduce error accumulation, we
introduce a cross-block dependency with the aid of a homologous reconstruction
scheme to build the long-range dependency between adjacent multi-blocks with
overlapping. To reduce reconstruction difficulty, we design a coarse-to-fine
pre-processing (CFP) to truncate weight outliers and dynamically scale
activation outliers before optimization, and an adaptive rounding scheme,
called LoRA-Rounding, with two low-rank learnable matrixes to further rectify
weight quantization errors. Extensive experiments demonstrate that: (1) CBQ
pushes both activation and weight quantization to low-bit settings W4A4, W4A8,
and W2A16. (2) CBQ achieves better performance than the existing
state-of-the-art methods on various LLMs and benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07951" title="Abstract">arXiv:2312.07951</a> [<a href="/pdf/2312.07951" title="Download PDF">pdf</a>, <a href="/format/2312.07951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic-aware Data Augmentation for Text-to-image Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhaorui Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaizhu Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Data augmentation has been recently leveraged as an effective regularizer in
various vision-language deep neural networks. However, in text-to-image
synthesis (T2Isyn), current augmentation wisdom still suffers from the semantic
mismatch between augmented paired data. Even worse, semantic collapse may occur
when generated images are less semantically constrained. In this paper, we
develop a novel Semantic-aware Data Augmentation (SADA) framework dedicated to
T2Isyn. In particular, we propose to augment texts in the semantic space via an
Implicit Textual Semantic Preserving Augmentation ($ITA$), in conjunction with
a specifically designed Image Semantic Regularization Loss ($L_r$) as Generated
Image Semantic Conservation, to cope well with semantic mismatch and collapse.
As one major contribution, we theoretically show that $ITA$ can certify better
text-image consistency while $L_r$ regularizing the semantics of generated
images would avoid semantic collapse and enhance image quality. Extensive
experiments validate that SADA enhances text-image consistency and improves
image quality significantly in T2Isyn models across various backbones.
Especially, incorporating SADA during the tuning process of Stable Diffusion
models also yields performance improvements.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07953" title="Abstract">arXiv:2312.07953</a> [<a href="/pdf/2312.07953" title="Download PDF">pdf</a>, <a href="/format/2312.07953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Robotic Navigation: An Evaluation of Single and  Multi-Objective Reinforcement Learning Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Young%2C+V">Vicki Young</a>, 
<a href="/search/cs?searchtype=author&query=Hossain%2C+J">Jumman Hossain</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+N">Nirmalya Roy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> REU program project (work in progress)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This study presents a comparative analysis between single-objective and
multi-objective reinforcement learning methods for training a robot to navigate
effectively to an end goal while efficiently avoiding obstacles. Traditional
reinforcement learning techniques, namely Deep Q-Network (DQN), Deep
Deterministic Policy Gradient (DDPG), and Twin Delayed DDPG (TD3), have been
evaluated using the Gazebo simulation framework in a variety of environments
with parameters such as random goal and robot starting locations. These methods
provide a numerical reward to the robot, offering an indication of action
quality in relation to the goal. However, their limitations become apparent in
complex settings where multiple, potentially conflicting, objectives are
present. To address these limitations, we propose an approach employing
Multi-Objective Reinforcement Learning (MORL). By modifying the reward function
to return a vector of rewards, each pertaining to a distinct objective, the
robot learns a policy that effectively balances the different goals, aiming to
achieve a Pareto optimal solution. This comparative study highlights the
potential for MORL in complex, dynamic robotic navigation tasks, setting the
stage for future investigations into more adaptable and robust robotic
behaviors.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07955" title="Abstract">arXiv:2312.07955</a> [<a href="/pdf/2312.07955" title="Download PDF">pdf</a>, <a href="/format/2312.07955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Erasing Self-Supervised Learning Backdoor by Cluster Activation Masking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+S">Shengsheng Qian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+D">Dizhan Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shengjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huaiwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Changsheng Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Researchers have recently found that Self-Supervised Learning (SSL) is
vulnerable to backdoor attacks. The attacker can embed hidden SSL backdoors via
a few poisoned examples in the training dataset and maliciously manipulate the
behavior of downstream models. To defend against SSL backdoor attacks, a
feasible route is to detect and remove the poisonous samples in the training
set. However, the existing SSL backdoor defense method fails to detect the
poisonous samples precisely. In this paper, we propose to erase the SSL
backdoor by cluster activation masking and propose a novel PoisonCAM method.
After obtaining the threat model trained on the poisoned dataset, our method
can precisely detect poisonous samples based on the assumption that masking the
backdoor trigger can effectively change the activation of a downstream
clustering model. In experiments, our PoisonCAM achieves 96% accuracy for
backdoor trigger detection compared to 3% of the state-of-the-art method on
poisoned ImageNet-100. Moreover, our proposed PoisonCAM significantly improves
the performance of the trained SSL model under backdoor attacks compared to the
state-of-the-art method. Our code will be available at
https://github.com/LivXue/PoisonCAM.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07956" title="Abstract">arXiv:2312.07956</a> [<a href="/pdf/2312.07956" title="Download PDF">pdf</a>, <a href="/format/2312.07956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topology-Dependent Privacy Bound For Decentralized Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qiongxiu Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenrui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+C">Changlong Ji</a>, 
<a href="/search/cs?searchtype=author&query=Heusdens%2C+R">Richard Heusdens</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Decentralized Federated Learning (FL) has attracted significant attention due
to its enhanced robustness and scalability compared to its centralized
counterpart. It pivots on peer-to-peer communication rather than depending on a
central server for model aggregation. While prior research has delved into
various factors of decentralized FL such as aggregation methods and
privacy-preserving techniques, one crucial aspect affecting privacy is
relatively unexplored: the underlying graph topology. In this paper, we fill
the gap by deriving a stringent privacy bound for decentralized FL under the
condition that the accuracy is not compromised, highlighting the pivotal role
of graph topology. Specifically, we demonstrate that the minimum privacy loss
at each model aggregation step is dependent on the size of what we term as
'honest components', the maximally connected subgraphs once all untrustworthy
participants are excluded from the networks, which is closely tied to network
robustness. Our analysis suggests that attack-resilient networks will provide a
superior privacy guarantee. We further validate this by studying both Poisson
and power law networks, showing that the latter, being less robust against
attacks, indeed reveals more privacy. In addition to a theoretical analysis, we
consolidate our findings by examining two distinct privacy attacks: membership
inference and gradient inversion.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07959" title="Abstract">arXiv:2312.07959</a> [<a href="/pdf/2312.07959" title="Download PDF">pdf</a>, <a href="/format/2312.07959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An a posteriori error estimate for a 0D/2D coupled model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Albazzal%2C+H">Hussein Albazzal</a>, 
<a href="/search/math?searchtype=author&query=Lozinski%2C+A">Alexei Lozinski</a>, 
<a href="/search/math?searchtype=author&query=Tittarelli%2C+R">Roberta Tittarelli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This work is motivated by the need of efficient numerical simulations of gas
flows in the serpentine channels used in proton-exchange membrane fuel cells.
In particular, we consider the Poisson problem in a 2D domain composed of
several long straight rectangular sections and of several bends corners. In
order to speed up the resolution, we propose a 0D model in the rectangular
parts of the channel and a Finite Element resolution in the bends. To find a
good compromise between precision and time consuming, the challenge is double:
how to choose a suitable position of the interface between the 0D and the 2D
models and how to control the discretization error in the bends. We shall
present an \textit{a posteriori} error estimator based on an equilibrated flux
reconstruction in the subdomains where the Finite Element method is applied.
The estimates give a global upper bound on the error measured in the energy
norm of the difference between the exact and approximate solutions on the whole
domain. They are guaranteed, meaning that they feature no undetermined
constants. (global) Lower bounds for the error are also derived. An adaptive
algorithm is proposed to use smartly the estimator for aforementioned double
challenge. A numerical validation of the estimator and the algorithm completes
the work. \end{abstract}
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07961" title="Abstract">arXiv:2312.07961</a> [<a href="/pdf/2312.07961" title="Download PDF">pdf</a>, <a href="/format/2312.07961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Few-Shot Named Entity Recognition with Boundary Discrimination  and Correlation Purification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+X">Xiaojun Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chunxia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tianxiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Z">Zhendong Niu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Few-shot named entity recognition (NER) aims to recognize novel named
entities in low-resource domains utilizing existing knowledge. However, the
present few-shot NER models assume that the labeled data are all clean without
noise or outliers, and there are few works focusing on the robustness of the
cross-domain transfer learning ability to textual adversarial attacks in
Few-shot NER. In this work, we comprehensively explore and assess the
robustness of few-shot NER models under textual adversarial attack scenario,
and found the vulnerability of existing few-shot NER models. Furthermore, we
propose a robust two-stage few-shot NER method with Boundary Discrimination and
Correlation Purification (BDCP). Specifically, in the span detection stage, the
entity boundary discriminative module is introduced to provide a highly
distinguishing boundary representation space to detect entity spans. In the
entity typing stage, the correlations between entities and contexts are
purified by minimizing the interference information and facilitating
correlation generalization to alleviate the perturbations caused by textual
adversarial attacks. In addition, we construct adversarial examples for
few-shot NER based on public datasets Few-NERD and Cross-Dataset. Comprehensive
evaluations on those two groups of few-shot NER datasets containing adversarial
examples demonstrate the robustness and superiority of the proposed method.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07964" title="Abstract">arXiv:2312.07964</a> [<a href="/pdf/2312.07964" title="Download PDF">pdf</a>, <a href="/format/2312.07964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Three-Filters-to-Normal+: Revisiting Discontinuity Discrimination in  Depth-to-Normal Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jingwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+B">Bohuan Xue</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Deming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+R">Rui Fan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qijun Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This article introduces three-filters-to-normal+ (3F2N+), an extension of our
previous work three-filters-to-normal (3F2N), with a specific focus on
incorporating discontinuity discrimination capability into surface normal
estimators (SNEs). 3F2N+ achieves this capability by utilizing a novel
discontinuity discrimination module (DDM), which combines depth curvature
minimization and correlation coefficient maximization through conditional
random fields (CRFs). To evaluate the robustness of SNEs on noisy data, we
create a large-scale synthetic surface normal (SSN) dataset containing 20
scenarios (ten indoor scenarios and ten outdoor scenarios with and without
random Gaussian noise added to depth images). Extensive experiments demonstrate
that 3F2N+ achieves greater performance than all other geometry-based surface
normal estimators, with average angular errors of 7.85$^\circ$, 8.95$^\circ$,
9.25$^\circ$, and 11.98$^\circ$ on the clean-indoor, clean-outdoor,
noisy-indoor, and noisy-outdoor datasets, respectively. We conduct three
additional experiments to demonstrate the effectiveness of incorporating our
proposed 3F2N+ into downstream robot perception tasks, including freespace
detection, 6D object pose estimation, and point cloud completion. Our source
code and datasets are publicly available at https://mias.group/3F2Nplus.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07966" title="Abstract">arXiv:2312.07966</a> [<a href="/pdf/2312.07966" title="Download PDF">pdf</a>, <a href="/ps/2312.07966" title="Download PostScript">ps</a>, <a href="/format/2312.07966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A multi-sourced data and agent-based approach for complementing Time Use  Surveys in the context of residential human activity and load curve  simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schumann%2C+M">Mathieu Schumann</a>, 
<a href="/search/cs?searchtype=author&query=Reynaud%2C+Q">Quentin Reynaud</a>, 
<a href="/search/cs?searchtype=author&query=Semp%C3%A9%2C+F">Fran&#xe7;ois Semp&#xe9;</a> (OASIS), 
<a href="/search/cs?searchtype=author&query=Guibourdenche%2C+J">Julien Guibourdenche</a> (RIFT, UNIGE), 
<a href="/search/cs?searchtype=author&query=Ly%2C+J">Jean-Baptiste Ly</a> (CPU), 
<a href="/search/cs?searchtype=author&query=Sabouret%2C+N">Nicolas Sabouret</a> (CPU, CPU, CPU)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Building Simulation Conference, Sep 2023, Shangai, China
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">To address the major issues associated with using Time-Use Survey (TUS) for
simulating residential load curves, we present the SMACH approach, which
combines qualitative and quantitative data with agent-based simulation. Our
model consists of autonomous agents assigned with daily tasks. The agents try
to accomplish their assigned tasks to the best of their abilities. Quantitative
data are used to generate tasks assignments. Qualitative studies allow us to
define how agents select, based on plausible cognitive principles, the tasks to
accomplish depending on the context. Our results show a better representation
of weekdays and weekends, a more flexible association of tasks with appliances,
and an improved simulation of load curves compared to real data. Highlights
$\bullet$ Discussion about Time-Use Surveys (TUS) limits and the use of TUS in
activity and energy simulation $\bullet$ Presentation of complementary data
both qualitative and quantitative used to complement TUS data $\bullet$
Proposition of an agent-based approach that balances these limitations
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07969" title="Abstract">arXiv:2312.07969</a> [<a href="/pdf/2312.07969" title="Download PDF">pdf</a>, <a href="/format/2312.07969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ASLseg: Adapting SAM in the Loop for Semi-supervised Liver Tumor  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shiyun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Li Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Pujin Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiaoying Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Liver tumor segmentation is essential for computer-aided diagnosis, surgical
planning, and prognosis evaluation. However, obtaining and maintaining a
large-scale dataset with dense annotations is challenging. Semi-Supervised
Learning (SSL) is a common technique to address these challenges. Recently,
Segment Anything Model (SAM) has shown promising performance in some medical
image segmentation tasks, but it performs poorly for liver tumor segmentation.
In this paper, we propose a novel semi-supervised framework, named ASLseg,
which can effectively adapt the SAM to the SSL setting and combine both
domain-specific and general knowledge of liver tumors. Specifically, the
segmentation model trained with a specific SSL paradigm provides the generated
pseudo-labels as prompts to the fine-tuned SAM. An adaptation network is then
used to refine the SAM-predictions and generate higher-quality pseudo-labels.
Finally, the reliable pseudo-labels are selected to expand the labeled set for
iterative training. Extensive experiments on the LiTS dataset demonstrate
overwhelming performance of our ASLseg.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07970" title="Abstract">arXiv:2312.07970</a> [<a href="/pdf/2312.07970" title="Download PDF">pdf</a>, <a href="/format/2312.07970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Divide and Conquer: Hybrid Pre-training for Person Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yanling Tian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Di Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanshan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large-scale pre-training has proven to be an effective method for improving
performance across different tasks. Current person search methods use ImageNet
pre-trained models for feature extraction, yet it is not an optimal solution
due to the gap between the pre-training task and person search task (as a
downstream task). Therefore, in this paper, we focus on pre-training for person
search, which involves detecting and re-identifying individuals simultaneously.
Although labeled data for person search is scarce, datasets for two sub-tasks
person detection and re-identification are relatively abundant. To this end, we
propose a hybrid pre-training framework specifically designed for person search
using sub-task data only. It consists of a hybrid learning paradigm that
handles data with different kinds of supervisions, and an intra-task alignment
module that alleviates domain discrepancy under limited resources. To the best
of our knowledge, this is the first work that investigates how to support
full-task pre-training using sub-task data. Extensive experiments demonstrate
that our pre-trained model can achieve significant improvements across diverse
protocols, such as person search method, fine-tuning data, pre-training data
and model backbone. For example, our model improves ResNet50 based NAE by 10.3%
relative improvement w.r.t. mAP. Our code and pre-trained models are released
for plug-and-play usage to the person search community.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07971" title="Abstract">arXiv:2312.07971</a> [<a href="/pdf/2312.07971" title="Download PDF">pdf</a>, <a href="/format/2312.07971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LMD: Faster Image Reconstruction with Latent Masking Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhiyuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=yu%2C+z">zhihuan yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianjun Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bowen Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As a class of fruitful approaches, diffusion probabilistic models (DPMs) have
shown excellent advantages in high-resolution image reconstruction. On the
other hand, masked autoencoders (MAEs), as popular self-supervised vision
learners, have demonstrated simpler and more effective image reconstruction and
transfer capabilities on downstream tasks. However, they all require extremely
high training costs, either due to inherent high temporal-dependence (i.e.,
excessively long diffusion steps) or due to artificially low spatial-dependence
(i.e., human-formulated high mask ratio, such as 0.75). To the end, this paper
presents LMD, a faster image reconstruction framework with latent masking
diffusion. First, we propose to project and reconstruct images in latent space
through a pre-trained variational autoencoder, which is theoretically more
efficient than in the pixel-based space. Then, we combine the advantages of
MAEs and DPMs to design a progressive masking diffusion model, which gradually
increases the masking proportion by three different schedulers and reconstructs
the latent features from simple to difficult, without sequentially performing
denoising diffusion as in DPMs or using fixed high masking ratio as in MAEs, so
as to alleviate the high training time-consumption predicament. Our approach
allows for learning high-capacity models and accelerate their training (by 3x
or more) and barely reduces the original accuracy. Inference speed in
downstream tasks also significantly outperforms the previous approaches.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07976" title="Abstract">arXiv:2312.07976</a> [<a href="/pdf/2312.07976" title="Download PDF">pdf</a>, <a href="/ps/2312.07976" title="Download PostScript">ps</a>, <a href="/format/2312.07976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges of YOLO Series for Object Detection in Extremely Heavy Rain:  CALRA Simulator based Synthetic Evaluation Dat a set
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">T. Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+H">H. Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+Y">Y. Lim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, as many studies of autonomous vehicles have been achieved for
levels 4 and 5, there has been also increasing interest in the advancement of
perception, decision, and control technologies, which are the three major
aspects of autonomous vehicles. As for the perception technologies achieving
reliable maneuvering of autonomous vehicles, object detection by using diverse
sensors (e.g., LiDAR, radar, and camera) should be prioritized. These sensors
require to detect objects accurately and quickly in diverse weather conditions,
but they tend to have challenges to consistently detect objects in bad weather
conditions with rain, snow, or fog. Thus, in this study, based on the
experimentally obtained raindrop data from precipitation conditions, we
constructed a novel dataset that could test diverse network model in various
precipitation conditions through the CARLA simulator. Consequently, based on
our novel dataset, YOLO series, a one-stage-detector, was used to
quantitatively verify how much object detection performance could be decreased
under various precipitation conditions from normal to extreme heavy rain
situations.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07979" title="Abstract">arXiv:2312.07979</a> [<a href="/pdf/2312.07979" title="Download PDF">pdf</a>, <a href="/ps/2312.07979" title="Download PostScript">ps</a>, <a href="/format/2312.07979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SLJP: Semantic Extraction based Legal Judgment Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madambakam%2C+P">Prameela Madambakam</a>, 
<a href="/search/cs?searchtype=author&query=Rajmohan%2C+S">Shathanaa Rajmohan</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+H">Himangshu Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+T+A+C+P">Tummepalli Anka Chandrahas Purushotham Gupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Legal Judgment Prediction (LJP) is a judicial assistance system that
recommends the legal components such as applicable statues, prison term and
penalty term by analyzing the given input case document. Indian legal system is
in the need of technical assistance such as artificial intelligence to solve
the crores of pending cases in various courts for years and its being increased
day to day. Most of the existing Indian models did not adequately concentrate
on the semantics embedded in the fact description (FD) that impacts the
decision. The proposed semantic extraction based LJP (SLJP) model provides the
advantages of pretrained transformers for complex unstructured legal case
document understanding and to generate embeddings. The model draws the in-depth
semantics of the given FD at multiple levels i.e., chunk and case document
level by following the divide and conquer approach. It creates the concise view
of the given fact description using the extracted semantics as per the original
court case document structure and predicts judgment using attention mechanism.
We tested the model performance on two available Indian datasets Indian Legal
Documents corpus (ILDC) and Indian Legal Statue Identification (ILSI) and got
promising results. Also shown the highest performance and less performance
degradation for increased epochs than base models on ILDC dataset.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07981" title="Abstract">arXiv:2312.07981</a> [<a href="/pdf/2312.07981" title="Download PDF">pdf</a>, <a href="/ps/2312.07981" title="Download PostScript">ps</a>, <a href="/format/2312.07981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time Series Diffusion Method: A Denoising Diffusion Probabilistic Model  for Vibration Signal Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+H">Haiming Yi</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Lei Hou</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yuhong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Saeed%2C+N+A">Nasser A. Saeed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Sound (cs.SD); Signal Processing (eess.SP)

</div>
<p class="mathjax">Diffusion models have demonstrated robust data generation capabilities in
various research fields. In this paper, a Time Series Diffusion Method (TSDM)
is proposed for vibration signal generation, leveraging the foundational
principles of diffusion models. The TSDM uses an improved U-net architecture
with attention block to effectively segment and extract features from
one-dimensional time series data. It operates based on forward diffusion and
reverse denoising processes for time-series generation. Experimental validation
is conducted using single-frequency, multi-frequency datasets, and bearing
fault datasets. The results show that TSDM can accurately generate the
single-frequency and multi-frequency features in the time series and retain the
basic frequency features for the diffusion generation results of the bearing
fault series. Finally, TSDM is applied to the small sample fault diagnosis of
three public bearing fault datasets, and the results show that the accuracy of
small sample fault diagnosis of the three datasets is improved by 32.380%,
18.355% and 9.298% at most, respectively
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07983" title="Abstract">arXiv:2312.07983</a> [<a href="/pdf/2312.07983" title="Download PDF">pdf</a>, <a href="/format/2312.07983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-perspective Feedback-attention Coupling Model for Continuous-time  Dynamic Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaobo Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhipeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hailong Su</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+J">Jin Che</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhanheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liying Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Recently, representation learning over graph networks has gained popularity,
with various models showing promising results. Despite this, several challenges
persist: 1) most methods are designed for static or discrete-time dynamic
graphs; 2) existing continuous-time dynamic graph algorithms focus on a single
evolving perspective; and 3) many continuous-time dynamic graph approaches
necessitate numerous temporal neighbors to capture long-term dependencies. In
response, this paper introduces the Multi-Perspective Feedback-Attention
Coupling (MPFA) model. MPFA incorporates information from both evolving and raw
perspectives, efficiently learning the interleaved dynamics of observed
processes. The evolving perspective employs temporal self-attention to
distinguish continuously evolving temporal neighbors for information
aggregation. Through dynamic updates, this perspective can capture long-term
dependencies using a small number of temporal neighbors. Meanwhile, the raw
perspective utilizes a feedback attention module with growth characteristic
coefficients to aggregate raw neighborhood information. Experimental results on
a self-organizing dataset and seven public datasets validate the efficacy and
competitiveness of our proposed model.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07987" title="Abstract">arXiv:2312.07987</a> [<a href="/pdf/2312.07987" title="Download PDF">pdf</a>, <a href="/format/2312.07987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SwitchHead: Accelerating Transformers with Mixture-of-Experts Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Csord%C3%A1s%2C+R">R&#xf3;bert Csord&#xe1;s</a>, 
<a href="/search/cs?searchtype=author&query=Pi%C4%99kos%2C+P">Piotr Pi&#x119;kos</a>, 
<a href="/search/cs?searchtype=author&query=Irie%2C+K">Kazuki Irie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">The costly self-attention layers in modern Transformers require memory and
compute quadratic in sequence length. Existing approximation methods usually
underperform and fail to obtain significant speedups in practice. Here we
present SwitchHead - a novel method that reduces both compute and memory
requirements and achieves wall-clock speedup, while matching the language
modeling performance of baseline Transformers with the same parameter budget.
SwitchHead uses Mixture-of-Experts (MoE) layers for the value and output
projections and requires 4 to 8 times fewer attention matrices than standard
Transformers. Our novel attention can also be combined with MoE MLP layers,
resulting in an efficient fully-MoE "SwitchHead" Transformer model. Our code is
public.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07991" title="Abstract">arXiv:2312.07991</a> [<a href="/pdf/2312.07991" title="Download PDF">pdf</a>, <a href="/format/2312.07991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating the Global Aggregation of Local Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mor%2C+A">Alon Mor</a>, 
<a href="/search/cs?searchtype=author&query=Belinkov%2C+Y">Yonatan Belinkov</a>, 
<a href="/search/cs?searchtype=author&query=Kimelfeld%2C+B">Benny Kimelfeld</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Local explanation methods highlight the input tokens that have a considerable
impact on the outcome of classifying the document at hand. For example, the
Anchor algorithm applies a statistical analysis of the sensitivity of the
classifier to changes in the token. Aggregating local explanations over a
dataset provides a global explanation of the model. Such aggregation aims to
detect words with the most impact, giving valuable insights about the model,
like what it has learned in training and which adversarial examples expose its
weaknesses. However, standard aggregation methods bear a high computational
cost: a na\"ive implementation applies a costly algorithm to each token of each
document, and hence, it is infeasible for a simple user running in the scope of
a short analysis session. % We devise techniques for accelerating the global
aggregation of the Anchor algorithm. Specifically, our goal is to compute a set
of top-$k$ words with the highest global impact according to different
aggregation functions. Some of our techniques are lossless and some are lossy.
We show that for a very mild loss of quality, we are able to accelerate the
computation by up to 30$\times$, reducing the computation from hours to
minutes. We also devise and study a probabilistic model that accounts for noise
in the Anchor algorithm and diminishes the bias toward words that are frequent
yet low in impact.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07992" title="Abstract">arXiv:2312.07992</a> [<a href="/pdf/2312.07992" title="Download PDF">pdf</a>, <a href="/format/2312.07992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the privacy of federated Clustering: A Cryptographic View
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qiongxiu Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Lixia Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The privacy concern in federated clustering has attracted considerable
attention in past decades. Many privacy-preserving clustering algorithms
leverage cryptographic techniques like homomorphic encryption or secure
multiparty computation, to guarantee full privacy, i.e., no additional
information is leaked other than the final output. However, given the iterative
nature of clustering algorithms, consistently encrypting intermediate outputs,
such as centroids, hampers efficiency. This paper delves into this intricate
trade-off, questioning the necessity of continuous encryption in iterative
algorithms. Using the federated K-means clustering as an example, we
mathematically formulate the problem of reconstructing input private data from
the intermediate centroids as a classical cryptographic problem called hidden
subset sum problem (HSSP)-extended from an NP-complete problem called subset
sum problem (SSP). Through an in-depth analysis, we show that existing
lattice-based HSSP attacks fail in reconstructing the private data given the
knowledge of intermediate centroids, thus it is secure to reveal them for the
sake of efficiency. To the best of our knowledge, our work is the first to cast
federated clustering's privacy concerns as a cryptographic problem HSSP such
that a concrete and rigorous analysis can be conducted.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07993" title="Abstract">arXiv:2312.07993</a> [<a href="/pdf/2312.07993" title="Download PDF">pdf</a>, <a href="/ps/2312.07993" title="Download PostScript">ps</a>, <a href="/format/2312.07993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified View on Forgetting and Strong Equivalence Notions in Answer  Set Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saribatur%2C+Z+G">Zeynep G. Saribatur</a>, 
<a href="/search/cs?searchtype=author&query=Woltran%2C+S">Stefan Woltran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an extended version of a paper to be published at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Answer Set Programming (ASP) is a prominent rule-based language for knowledge
representation and reasoning with roots in logic programming and non-monotonic
reasoning. The aim to capture the essence of removing (ir)relevant details in
ASP programs led to the investigation of different notions, from strong
persistence (SP) forgetting, to faithful abstractions, and, recently, strong
simplifications, where the latter two can be seen as relaxed and strengthened
notions of forgetting, respectively. Although it was observed that these
notions are related, especially given that they have characterizations through
the semantics for strong equivalence, it remained unclear whether they can be
brought together. In this work, we bridge this gap by introducing a novel
relativized equivalence notion, which is a relaxation of the recent
simplification notion, that is able to capture all related notions from the
literature. We provide necessary and sufficient conditions for relativized
simplifiability, which shows that the challenging part is for when the context
programs do not contain all the atoms to remove. We then introduce an operator
that combines projection and a relaxation of (SP)-forgetting to obtain the
relativized simplifications. We furthermore present complexity results that
complete the overall picture.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07999" title="Abstract">arXiv:2312.07999</a> [<a href="/pdf/2312.07999" title="Download PDF">pdf</a>, <a href="/format/2312.07999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random Serial Dictatorship with Transfers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sundar%2C+S">Sudharsan Sundar</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+E">Eric Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chow%2C+T">Trevor Chow</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Matthew Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)

</div>
<p class="mathjax">It is well known that Random Serial Dictatorship is strategy-proof and leads
to a Pareto-Efficient outcome. We show that this result breaks down when
individuals are allowed to make transfers, and adapt Random Serial Dictatorship
to encompass trades between individuals. Strategic analysis of play under the
new mechanisms we define is given, accompanied by simulations to quantify the
gains from trade.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08000" title="Abstract">arXiv:2312.08000</a> [<a href="/pdf/2312.08000" title="Download PDF">pdf</a>, <a href="/format/2312.08000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoK: On the Security of Non-Fungible Tokens
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+K">Kai Ma</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jintao Huang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+N">Ningyu He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoyu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Non-fungible tokens (NFTs) drive the prosperity of the Web3 ecosystem. By
November 2023, the total market value of NFT projects reached approximately 16
billion USD. Accompanying the success of NFTs are various security issues,
i.e., attacks and scams are prevalent in the ecosystem. While NFTs have
attracted significant attentions from both industry and academia, there is a
lack of understanding of kinds of NFT security issues. The discovery, in-depth
analysis, and systematic categorization of these security issues are of
significant importance for the prosperous development of the NFT ecosystem. To
fill the gap, we performed a systematic literature review related to NFT
security, and we have identified 142 incidents from 213 security reports and 18
academic papers until October 1st, 2023. Through manual analysis of the
compiled security incidents, we have classified them into 12 major categories.
Then we explored potential solutions and mitigation strategies. Drawing from
these analyses, we established the first NFT security reference frame. Except,
we extracted the characteristics of NFT security issues, i.e., the prevalence,
severity, and intractability. We have indicated the gap between industry and
academy for NFT security, and provide further research directions for the
community. This paper, as the first SoK of NFT security, has systematically
explored the security issues within the NFT ecosystem, shedding light on their
root causes, real-world attacks, and potential ways to address them. Our
findings will contribute to the future research of NFT security.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08004" title="Abstract">arXiv:2312.08004</a> [<a href="/pdf/2312.08004" title="Download PDF">pdf</a>, <a href="/format/2312.08004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instance-aware Multi-Camera 3D Object Detection with Structural Priors  Mining and Self-Boosting Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiao%2C+Y">Yang Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Jie%2C+Z">Zequn Jie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shaoxiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lechao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingjing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu-Gang Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Camera-based bird-eye-view (BEV) perception paradigm has made significant
progress in the autonomous driving field. Under such a paradigm, accurate BEV
representation construction relies on reliable depth estimation for
multi-camera images. However, existing approaches exhaustively predict depths
for every pixel without prioritizing objects, which are precisely the entities
requiring detection in the 3D space. To this end, we propose IA-BEV, which
integrates image-plane instance awareness into the depth estimation process
within a BEV-based detector. First, a category-specific structural priors
mining approach is proposed for enhancing the efficacy of monocular depth
generation. Besides, a self-boosting learning strategy is further proposed to
encourage the model to place more emphasis on challenging objects in
computation-expensive temporal stereo matching. Together they provide advanced
depth estimation results for high-quality BEV features construction, benefiting
the ultimate 3D detection. The proposed method achieves state-of-the-art
performances on the challenging nuScenes benchmark, and extensive experimental
results demonstrate the effectiveness of our designs.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08006" title="Abstract">arXiv:2312.08006</a> [<a href="/pdf/2312.08006" title="Download PDF">pdf</a>, <a href="/format/2312.08006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance of linear solvers in tensor-train format on current  multicore architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=R%C3%B6hrig-Z%C3%B6llner%2C+M">Melven R&#xf6;hrig-Z&#xf6;llner</a>, 
<a href="/search/math?searchtype=author&query=Becklas%2C+M+J">Manuel Joey Becklas</a>, 
<a href="/search/math?searchtype=author&query=Thies%2C+J">Jonas Thies</a>, 
<a href="/search/math?searchtype=author&query=Basermann%2C+A">Achim Basermann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 8 figures, submitted to SISC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Software (cs.MS)

</div>
<p class="mathjax">In this paper we discuss the performance of solvers for low-rank linear
systems in the tensor-train format, also known as matrix-product states (MPS)
in physics. We focus on today's many-core CPU systems and the interplay of the
performance and the required linear algebra operations in this setting.
Specifically, we consider the tensor-train GMRES method, the modified
alternating linear scheme (MALS) and the alternating minimal energy (AMEn).
Based on the example of a simple non-symmetric system from discretizing a
multidimensional convection-diffusion equation in, e.g., $50^{10}$ grid points,
we illustrate the computational complexity of the three methods. This shows
that the projection to smaller sub-problems reduces the required number of
floating point operations by orders of magnitude: between GMRES and MALS, and
again between MALS and AMEn. All three methods require similar underlying
linear algebra operations (building blocks). We suggest several building block
improvements regarding orthogonalization steps, singular value decompositions,
and tensor contractions. In addition, we propose a simple generic
preconditioner in the tensor-train format based on a rank-1 approximation of
the operator. Combining all optimizations, we obtain roughly a 5x speedup over
the reference implementation for the fastest method (AMEn) on a current
multi-core CPU.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08007" title="Abstract">arXiv:2312.08007</a> [<a href="/pdf/2312.08007" title="Download PDF">pdf</a>, <a href="/format/2312.08007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling Parts Beyond Objects:Towards Finer-Granularity Referring  Expression Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+T">Tongtian Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yisi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Longteng Guo</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xingjian He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinlong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Referring expression segmentation (RES) aims at segmenting the foreground
masks of the entities that match the descriptive natural language expression.
Previous datasets and methods for classic RES task heavily rely on the prior
assumption that one expression must refer to object-level targets. In this
paper, we take a step further to finer-grained part-level RES task. To promote
the object-level RES task towards finer-grained vision-language understanding,
we put forward a new multi-granularity referring expression segmentation (MRES)
task and construct an evaluation benchmark called RefCOCOm by manual
annotations. By employing our automatic model-assisted data engine, we build
the largest visual grounding dataset namely MRES-32M, which comprises over
32.2M high-quality masks and captions on the provided 1M images. Besides, a
simple yet strong model named UniRES is designed to accomplish the unified
object-level and part-level grounding task. Extensive experiments on our
RefCOCOm for MRES and three datasets (i.e., RefCOCO(+/g) for classic RES task
demonstrate the superiority of our method over previous state-of-the-art
methods. To foster future research into fine-grained visual grounding, our
benchmark RefCOCOm, the MRES-32M dataset and model UniRES will be publicly
available at https://github.com/Rubics-Xuan/MRES
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08008" title="Abstract">arXiv:2312.08008</a> [<a href="/pdf/2312.08008" title="Download PDF">pdf</a>, <a href="/ps/2312.08008" title="Download PostScript">ps</a>, <a href="/format/2312.08008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Nash Equilibria in Zero-Sum Markov Games: A Single Time-scale  Algorithm Under Weak Reachability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ouhamma%2C+R">Reda Ouhamma</a>, 
<a href="/search/cs?searchtype=author&query=Kamgarpour%2C+M">Maryam Kamgarpour</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2303.03100">arXiv:2303.03100</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We consider decentralized learning for zero-sum games, where players only see
their payoff information and are agnostic to actions and payoffs of the
opponent. Previous works demonstrated convergence to a Nash equilibrium in this
setting using double time-scale algorithms under strong reachability
assumptions. We address the open problem of achieving an approximate Nash
equilibrium efficiently with an uncoupled and single time-scale algorithm under
weaker conditions. Our contribution is a rational and convergent algorithm,
utilizing Tsallis-entropy regularization in a value-iteration-based approach.
The algorithm learns an approximate Nash equilibrium in polynomial time,
requiring only the existence of a policy pair that induces an irreducible and
aperiodic Markov chain, thus considerably weakening past assumptions. Our
analysis leverages negative drift inequalities and introduces novel properties
of Tsallis entropy that are of independent interest.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08009" title="Abstract">arXiv:2312.08009</a> [<a href="/pdf/2312.08009" title="Download PDF">pdf</a>, <a href="/format/2312.08009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Supervised Class-Agnostic Motion Prediction with Pseudo Label  Regeneration and BEVMix
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kewei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yizheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhiyu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+K">Ke Xian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhiguo Cao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guosheng Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Class-agnostic motion prediction methods aim to comprehend motion within
open-world scenarios, holding significance for autonomous driving systems.
However, training a high-performance model in a fully-supervised manner always
requires substantial amounts of manually annotated data, which can be both
expensive and time-consuming to obtain. To address this challenge, our study
explores the potential of semi-supervised learning (SSL) for class-agnostic
motion prediction. Our SSL framework adopts a consistency-based self-training
paradigm, enabling the model to learn from unlabeled data by generating pseudo
labels through test-time inference. To improve the quality of pseudo labels, we
propose a novel motion selection and re-generation module. This module
effectively selects reliable pseudo labels and re-generates unreliable ones.
Furthermore, we propose two data augmentation strategies: temporal sampling and
BEVMix. These strategies facilitate consistency regularization in SSL.
Experiments conducted on nuScenes demonstrate that our SSL method can surpass
the self-supervised approach by a large margin by utilizing only a tiny
fraction of labeled data. Furthermore, our method exhibits comparable
performance to weakly and some fully supervised methods. These results
highlight the ability of our method to strike a favorable balance between
annotation costs and performance. Code will be available at
https://github.com/kwwcv/SSMP.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08010" title="Abstract">arXiv:2312.08010</a> [<a href="/pdf/2312.08010" title="Download PDF">pdf</a>, <a href="/format/2312.08010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EZ-CLIP: Efficient Zeroshot Video Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+S">Shahzad Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Chanda%2C+S">Sukalpa Chanda</a>, 
<a href="/search/cs?searchtype=author&query=Rawat%2C+Y+S">Yogesh S Rawat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advancements in large-scale pre-training of visual-language models on
paired image-text data have demonstrated impressive generalization capabilities
for zero-shot tasks. Building on this success, efforts have been made to adapt
these image-based visual-language models, such as CLIP, for videos extending
their zero-shot capabilities to the video domain. While these adaptations have
shown promising results, they come at a significant computational cost and
struggle with effectively modeling the crucial temporal aspects inherent to the
video domain. In this study, we present EZ-CLIP, a simple and efficient
adaptation of CLIP that addresses these challenges. EZ-CLIP leverages temporal
visual prompting for seamless temporal adaptation, requiring no fundamental
alterations to the core CLIP architecture while preserving its remarkable
generalization abilities. Moreover, we introduce a novel learning objective
that guides the temporal visual prompts to focus on capturing motion, thereby
enhancing its learning capabilities from video data. We conducted extensive
experiments on five different benchmark datasets, thoroughly evaluating EZ-CLIP
for zero-shot learning and base-to-novel video action recognition, and also
demonstrating its potential for few-shot generalization.Impressively, with a
mere 5.2 million learnable parameters (as opposed to the 71.1 million in the
prior best model), EZ-CLIP can be efficiently trained on a single GPU,
outperforming existing approaches in several evaluations.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08012" title="Abstract">arXiv:2312.08012</a> [<a href="/pdf/2312.08012" title="Download PDF">pdf</a>, <a href="/format/2312.08012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> uSF: Learning Neural Semantic Field with Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Skorokhodov%2C+V">Vsevolod Skorokhodov</a>, 
<a href="/search/cs?searchtype=author&query=Drozdova%2C+D">Darya Drozdova</a>, 
<a href="/search/cs?searchtype=author&query=Yudin%2C+D">Dmitry Yudin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, there has been an increased interest in NeRF methods which
reconstruct differentiable representation of three-dimensional scenes. One of
the main limitations of such methods is their inability to assess the
confidence of the model in its predictions. In this paper, we propose a new
neural network model for the formation of extended vector representations,
called uSF, which allows the model to predict not only color and semantic label
of each point, but also estimate the corresponding values of uncertainty. We
show that with a small number of images available for training, a model
quantifying uncertainty performs better than a model without such
functionality. Code of the uSF approach is publicly available at
https://github.com/sevashasla/usf/.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08016" title="Abstract">arXiv:2312.08016</a> [<a href="/pdf/2312.08016" title="Download PDF">pdf</a>, <a href="/format/2312.08016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Deep Reinforcement Learning for Dynamic Resource Allocation in  Wireless MEC Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+X">Xin Hao</a>, 
<a href="/search/cs?searchtype=author&query=Yeoh%2C+P+L">Phee Lep Yeoh</a>, 
<a href="/search/cs?searchtype=author&query=She%2C+C">Changyang She</a>, 
<a href="/search/cs?searchtype=author&query=Vucetic%2C+B">Branka Vucetic</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yonghui Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">This paper proposes a blockchain-secured deep reinforcement learning (BC-DRL)
optimization framework for {data management and} resource allocation in
decentralized {wireless mobile edge computing (MEC)} networks. In our
framework, {we design a low-latency reputation-based proof-of-stake (RPoS)
consensus protocol to select highly reliable blockchain-enabled BSs to securely
store MEC user requests and prevent data tampering attacks.} {We formulate the
MEC resource allocation optimization as a constrained Markov decision process
that balances minimum processing latency and denial-of-service (DoS)
probability}. {We use the MEC aggregated features as the DRL input to
significantly reduce the high-dimensionality input of the remaining service
processing time for individual MEC requests. Our designed constrained DRL
effectively attains the optimal resource allocations that are adapted to the
dynamic DoS requirements. We provide extensive simulation results and analysis
to} validate that our BC-DRL framework achieves higher security, reliability,
and resource utilization efficiency than benchmark blockchain consensus
protocols and {MEC} resource allocation algorithms.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08019" title="Abstract">arXiv:2312.08019</a> [<a href="/pdf/2312.08019" title="Download PDF">pdf</a>, <a href="/format/2312.08019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdapEdit: Spatio-Temporal Guided Adaptive Editing Algorithm for  Text-Based Continuity-Sensitive Image Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhiyuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+G">Guoli Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bowen Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the great success of text-conditioned diffusion models in creative
text-to-image generation, various text-driven image editing approaches have
attracted the attentions of many researchers. However, previous works mainly
focus on discreteness-sensitive instructions such as adding, removing or
replacing specific objects, background elements or global styles (i.e., hard
editing), while generally ignoring subject-binding but semantically
fine-changing continuity-sensitive instructions such as actions, poses or
adjectives, and so on (i.e., soft editing), which hampers generative AI from
generating user-customized visual contents. To mitigate this predicament, we
propose a spatio-temporal guided adaptive editing algorithm AdapEdit, which
realizes adaptive image editing by introducing a soft-attention strategy to
dynamically vary the guiding degree from the editing conditions to visual
pixels from both temporal and spatial perspectives. Note our approach has a
significant advantage in preserving model priors and does not require model
training, fine-tuning, extra data, or optimization. We present our results over
a wide variety of raw images and editing instructions, demonstrating
competitive performance and showing it significantly outperforms the previous
approaches.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08020" title="Abstract">arXiv:2312.08020</a> [<a href="/pdf/2312.08020" title="Download PDF">pdf</a>, <a href="/format/2312.08020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Deepfakes Detection with Reconstructed-Blended Images and  Multi-scale Feature Reconstruction Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H+H">Huy H. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chun-Shien Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">ZhiYong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Echizen%2C+I">Isao Echizen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The growing diversity of digital face manipulation techniques has led to an
urgent need for a universal and robust detection technology to mitigate the
risks posed by malicious forgeries. We present a blended-based detection
approach that has robust applicability to unseen datasets. It combines a method
for generating synthetic training samples, i.e., reconstructed blended images,
that incorporate potential deepfake generator artifacts and a detection model,
a multi-scale feature reconstruction network, for capturing the generic
boundary artifacts and noise distribution anomalies brought about by digital
face manipulations. Experiments demonstrated that this approach results in
better performance in both cross-manipulation detection and cross-dataset
detection on unseen data.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08021" title="Abstract">arXiv:2312.08021</a> [<a href="/pdf/2312.08021" title="Download PDF">pdf</a>, <a href="/format/2312.08021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving search relevance of Azure Cognitive Search by Bayesian  optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+N">Nitin Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Ashish Kumar</a>, 
<a href="/search/cs?searchtype=author&query=R%2C+K">Kiran R</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+M">Manish Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Bou%C3%A9%2C+L">Laurent Bou&#xe9;</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Microsoft Journal of Applied Research, Volume 20, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Azure Cognitive Search (ACS) has emerged as a major contender in "Search as a
Service" cloud products in recent years. However, one of the major challenges
for ACS users is to improve the relevance of the search results for their
specific usecases. In this paper, we propose a novel method to find the optimal
ACS configuration that maximizes search relevance for a specific usecase
(product search, document search...) The proposed solution improves key online
marketplace metrics such as click through rates (CTR) by formulating the search
relevance problem as hyperparameter tuning. We have observed significant
improvements in real-world search call to action (CTA) rate in multiple
marketplaces by introducing optimized weights generated from the proposed
approach.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08022" title="Abstract">arXiv:2312.08022</a> [<a href="/pdf/2312.08022" title="Download PDF">pdf</a>, <a href="/format/2312.08022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mono3DVG: 3D Visual Grounding in Monocular Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Y">Yang Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zhitong Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce a novel task of 3D visual grounding in monocular RGB images
using language descriptions with both appearance and geometry information.
Specifically, we build a large-scale dataset, Mono3DRefer, which contains 3D
object targets with their corresponding geometric text descriptions, generated
by ChatGPT and refined manually. To foster this task, we propose Mono3DVG-TR,
an end-to-end transformer-based network, which takes advantage of both the
appearance and geometry information in text embeddings for multi-modal learning
and 3D object localization. Depth predictor is designed to explicitly learn
geometry features. The dual text-guided adapter is proposed to refine
multiscale visual and geometry features of the referred object. Based on
depth-text-visual stacking attention, the decoder fuses object-level geometric
cues and visual appearance into a learnable query. Comprehensive benchmarks and
some insightful analyses are provided for Mono3DVG. Extensive comparisons and
ablation studies show that our method significantly outperforms all baselines.
The dataset and code will be publicly available at:
https://github.com/ZhanYang-nwpu/Mono3DVG.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08027" title="Abstract">arXiv:2312.08027</a> [<a href="/pdf/2312.08027" title="Download PDF">pdf</a>, <a href="/ps/2312.08027" title="Download PostScript">ps</a>, <a href="/format/2312.08027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Helping Language Models Learn More: Multi-dimensional Task Prompt for  Few-shot Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weng%2C+J">Jinta Weng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiarui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yue Hu</a>, 
<a href="/search/cs?searchtype=author&query=Fa%2C+D">Daidong Fa</a>, 
<a href="/search/cs?searchtype=author&query=Xuand%2C+X">Xiaofeng Xuand</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Heyan Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2210.16489">arXiv:2210.16489</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) can be used as accessible and intelligent
chatbots by constructing natural language queries and directly inputting the
prompt into the large language model. However, different prompt' constructions
often lead to uncertainty in the answers and thus make it hard to utilize the
specific knowledge of LLMs (like ChatGPT). To alleviate this, we use an
interpretable structure to explain the prompt learning principle in LLMs, which
certificates that the effectiveness of language models is determined by
position changes of the task's related tokens. Therefore, we propose MTPrompt,
a multi-dimensional task prompt learning method consisting based on
task-related object, summary, and task description information. By
automatically building and searching for appropriate prompts, our proposed
MTPrompt achieves the best results on few-shot samples setting and five
different datasets. In addition, we demonstrate the effectiveness and stability
of our method in different experimental settings and ablation experiments. In
interaction with large language models, embedding more task-related information
into prompts will make it easier to stimulate knowledge embedded in large
language models.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08028" title="Abstract">arXiv:2312.08028</a> [<a href="/pdf/2312.08028" title="Download PDF">pdf</a>, <a href="/ps/2312.08028" title="Download PostScript">ps</a>, <a href="/format/2312.08028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provable Security for the Onion Routing and Mix Network Packet Format  Sphinx
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scherer%2C+P">Philip Scherer</a>, 
<a href="/search/cs?searchtype=author&query=Weis%2C+C">Christiane Weis</a>, 
<a href="/search/cs?searchtype=author&query=Strufe%2C+T">Thorsten Strufe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Onion routing and mix networks are fundamental concepts to provide users with
anonymous access to the Internet. Various corresponding solutions rely on the
efficient Sphinx packet format. However, flaws in Sphinx's underlying proof
strategy were found recently. It is thus currently unclear which guarantees
Sphinx actually provides, and, even worse, there is no suitable proof strategy
available. In this paper, we restore the security foundation for all these
works by building a theoretical framework for Sphinx. We discover that the
previously-used DDH assumption is insufficient for a security proof and show
that the Gap Diffie-Hellman (GDH) assumption is required instead. We apply it
to prove that a slightly adapted version of the Sphinx packet format is secure
under the GDH assumption. Ours is the first work to provide a detailed,
in-depth security proof for Sphinx in this manner. Our adaptations to Sphinx
are necessary, as we demonstrate with an attack on sender privacy that would be
possible otherwise.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08029" title="Abstract">arXiv:2312.08029</a> [<a href="/pdf/2312.08029" title="Download PDF">pdf</a>, <a href="/format/2312.08029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClusterDDPM: An EM clustering framework with Denoising Diffusion  Probabilistic Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jie Yan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhong-yuan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Variational autoencoder (VAE) and generative adversarial networks (GAN) have
found widespread applications in clustering and have achieved significant
success. However, the potential of these approaches may be limited due to VAE's
mediocre generation capability or GAN's well-known instability during
adversarial training. In contrast, denoising diffusion probabilistic models
(DDPMs) represent a new and promising class of generative models that may
unlock fresh dimensions in clustering. In this study, we introduce an
innovative expectation-maximization (EM) framework for clustering using DDPMs.
In the E-step, we aim to derive a mixture of Gaussian priors for the subsequent
M-step. In the M-step, our focus lies in learning clustering-friendly latent
representations for the data by employing the conditional DDPM and matching the
distribution of latent representations to the mixture of Gaussian priors. We
present a rigorous theoretical analysis of the optimization process in the
M-step, proving that the optimizations are equivalent to maximizing the lower
bound of the Q function within the vanilla EM framework under certain
constraints. Comprehensive experiments validate the advantages of the proposed
framework, showcasing superior performance in clustering, unsupervised
conditional generation and latent representation learning.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08030" title="Abstract">arXiv:2312.08030</a> [<a href="/pdf/2312.08030" title="Download PDF">pdf</a>, <a href="/format/2312.08030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incremental Learning of Full-Pose Via-Point Movement Primitives on  Riemannian Manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daab%2C+T">Tilman Daab</a>, 
<a href="/search/cs?searchtype=author&query=Jaquier%2C+N">No&#xe9;mie Jaquier</a>, 
<a href="/search/cs?searchtype=author&query=Dreher%2C+C">Christian Dreher</a>, 
<a href="/search/cs?searchtype=author&query=Meixner%2C+A">Andre Meixner</a>, 
<a href="/search/cs?searchtype=author&query=Krebs%2C+F">Franziska Krebs</a>, 
<a href="/search/cs?searchtype=author&query=Asfour%2C+T">Tamim Asfour</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. 7 pages, 7 figures and 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Movement primitives (MPs) are compact representations of robot skills that
can be learned from demonstrations and combined into complex behaviors.
However, merely equipping robots with a fixed set of innate MPs is insufficient
to deploy them in dynamic and unpredictable environments. Instead, the full
potential of MPs remains to be attained via adaptable, large-scale MP
libraries. In this paper, we propose a set of seven fundamental operations to
incrementally learn, improve, and re-organize MP libraries. To showcase their
applicability, we provide explicit formulations of the spatial operations for
libraries composed of Via-Point Movement Primitives (VMPs). By building on
Riemannian manifold theory, our approach enables the incremental learning of
all parameters of position and orientation VMPs within a library. Moreover, our
approach stores a fixed number of parameters, thus complying with the essential
principles of incremental learning. We evaluate our approach to incrementally
learn a VMP library from motion capture data provided sequentially.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08033" title="Abstract">arXiv:2312.08033</a> [<a href="/pdf/2312.08033" title="Download PDF">pdf</a>, <a href="/format/2312.08033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Top-Class Agreement: Using Divergences to Forecast Performance  under Distribution Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schirmer%2C+M">Mona Schirmer</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nalisnick%2C+E">Eric Nalisnick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Workshop on Distribution Shifts, 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Knowing if a model will generalize to data 'in the wild' is crucial for safe
deployment. To this end, we study model disagreement notions that consider the
full predictive distribution - specifically disagreement based on Hellinger
distance, Jensen-Shannon and Kullback-Leibler divergence. We find that
divergence-based scores provide better test error estimates and detection rates
on out-of-distribution data compared to their top-1 counterparts. Experiments
involve standard vision and foundation models.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08036" title="Abstract">arXiv:2312.08036</a> [<a href="/pdf/2312.08036" title="Download PDF">pdf</a>, <a href="/ps/2312.08036" title="Download PostScript">ps</a>, <a href="/format/2312.08036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoRTEx: Contrastive Learning for Representing Terms via Explanations  with Applications on Constructing Biomedical Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ying%2C+H">Huaiyuan Ying</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhengyun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+S">Sihang Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Sheng Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Objective: Biomedical Knowledge Graphs play a pivotal role in various
biomedical research domains. Concurrently, term clustering emerges as a crucial
step in constructing these knowledge graphs, aiming to identify synonymous
terms. Due to a lack of knowledge, previous contrastive learning models trained
with Unified Medical Language System (UMLS) synonyms struggle at clustering
difficult terms and do not generalize well beyond UMLS terms. In this work, we
leverage the world knowledge from Large Language Models (LLMs) and propose
Contrastive Learning for Representing Terms via Explanations (CoRTEx) to
enhance term representation and significantly improves term clustering.
Materials and Methods: The model training involves generating explanations for
a cleaned subset of UMLS terms using ChatGPT. We employ contrastive learning,
considering term and explanation embeddings simultaneously, and progressively
introduce hard negative samples. Additionally, a ChatGPT-assisted BIRCH
algorithm is designed for efficient clustering of a new ontology. Results: We
established a clustering test set and a hard negative test set, where our model
consistently achieves the highest F1 score. With CoRTEx embeddings and the
modified BIRCH algorithm, we grouped 35,580,932 terms from the Biomedical
Informatics Ontology System (BIOS) into 22,104,559 clusters with O(N) queries
to ChatGPT. Case studies highlight the model's efficacy in handling challenging
samples, aided by information from explanations. Conclusion: By aligning terms
to their explanations, CoRTEx demonstrates superior accuracy over benchmark
models and robustness beyond its training set, and it is suitable for
clustering terms for large-scale biomedical ontologies.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08038" title="Abstract">arXiv:2312.08038</a> [<a href="/pdf/2312.08038" title="Download PDF">pdf</a>, <a href="/format/2312.08038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combined Approximations for Uniform Operational Consistent Query  Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Calautti%2C+M">Marco Calautti</a>, 
<a href="/search/cs?searchtype=author&query=Livshits%2C+E">Ester Livshits</a>, 
<a href="/search/cs?searchtype=author&query=Pieris%2C+A">Andreas Pieris</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+M">Markus Schneider</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Operational consistent query answering (CQA) is a recent framework for CQA
based on revised definitions of repairs, which are built by applying a sequence
of operations (e.g., fact deletions) starting from an inconsistent database
until we reach a database that is consistent w.r.t. the given set of
constraints. It has been recently shown that there are efficient approximations
for computing the percentage of repairs, as well as of sequences of operations
leading to repairs, that entail a given query when we focus on primary keys,
conjunctive queries, and assuming the query is fixed (i.e., in data
complexity). However, it has been left open whether such approximations exist
when the query is part of the input (i.e., in combined complexity). We show
that this is the case when we focus on self-join-free conjunctive queries of
bounded generelized hypertreewidth. We also show that it is unlikely that
efficient approximation schemes exist once we give up one of the adopted
syntactic restrictions, i.e., self-join-freeness or bounding the generelized
hypertreewidth. Towards the desired approximation schemes, we introduce a novel
counting complexity class, called SpanTL, show that each problem in SpanTL
admits an efficient approximation scheme by using a recent approximability
result in the context of tree automata, and then place the problems of interest
in SpanTL.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08039" title="Abstract">arXiv:2312.08039</a> [<a href="/pdf/2312.08039" title="Download PDF">pdf</a>, <a href="/ps/2312.08039" title="Download PostScript">ps</a>, <a href="/format/2312.08039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safeguarding the safeguards: How best to promote AI alignment in the  public interest
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guest%2C+O">Oliver Guest</a>, 
<a href="/search/cs?searchtype=author&query=Aird%2C+M">Michael Aird</a>, 
<a href="/search/cs?searchtype=author&query=h%C3%89igeartaigh%2C+S+%C3%93">Se&#xe1;n &#xd3; h&#xc9;igeartaigh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">AI alignment work is important from both a commercial and a safety lens. With
this paper, we aim to help actors who support alignment efforts to make these
efforts as effective as possible, and to avoid potential adverse effects. We
begin by suggesting that institutions that are trying to act in the public
interest (such as governments) should aim to support specifically alignment
work that reduces accident or misuse risks. We then describe four problems
which might cause alignment efforts to be counterproductive, increasing
large-scale AI risks. We suggest mitigations for each problem. Finally, we make
a broader recommendation that institutions trying to act in the public interest
should think systematically about how to make their alignment efforts as
effective, and as likely to be beneficial, as possible.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08041" title="Abstract">arXiv:2312.08041</a> [<a href="/pdf/2312.08041" title="Download PDF">pdf</a>, <a href="/format/2312.08041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging User Simulation to Develop and Evaluate Conversational  Information Access Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bernard%2C+N">Nolwenn Bernard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 17th ACM International Conference on Web Search and Data Mining (WSDM '24), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">We observe a change in the way users access information, that is, the rise of
conversational information access (CIA) agents. However, the automatic
evaluation of these agents remains an open challenge. Moreover, the training of
CIA agents is cumbersome as it mostly relies on conversational corpora, expert
knowledge, and reinforcement learning. User simulation has been identified as a
promising solution to tackle automatic evaluation and has been previously used
in reinforcement learning. In this research, we investigate how user simulation
can be leveraged in the context of CIA. We organize the work in three parts. We
begin with the identification of requirements for user simulators for training
and evaluating CIA agents and compare existing types of simulator regarding
these. Then, we plan to combine these different types of simulators into a new
hybrid simulator. Finally, we aim to extend simulators to handle more complex
information seeking scenarios.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08042" title="Abstract">arXiv:2312.08042</a> [<a href="/pdf/2312.08042" title="Download PDF">pdf</a>, <a href="/format/2312.08042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing approximate symmetries of complex networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pidnebesna%2C+A">Anna Pidnebesna</a>, 
<a href="/search/cs?searchtype=author&query=Hartman%2C+D">David Hartman</a>, 
<a href="/search/cs?searchtype=author&query=Pokorn%C3%A1%2C+A">Aneta Pokorn&#xe1;</a>, 
<a href="/search/cs?searchtype=author&query=Straka%2C+M">Mat&#x11b;j Straka</a>, 
<a href="/search/cs?searchtype=author&query=Hlinka%2C+J">Jaroslav Hlinka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Discrete Mathematics (cs.DM); Numerical Analysis (math.NA)

</div>
<p class="mathjax">The symmetry of complex networks is a global property that has recently
gained attention since MacArthur et al. 2008 showed that many real-world
networks contain a considerable number of symmetries. These authors work with a
very strict symmetry definition based on the network's automorphism. The
potential problem with this approach is that even a slight change in the
graph's structure can remove or create some symmetry. Recently, Liu 2020
proposed to use an approximate automorphism instead of strict automorphism.
This method can discover symmetries in the network while accepting some minor
imperfections in their structure. The proposed numerical method, however,
exhibits some performance problems and has some limitations while it assumes
the absence of fixed points. In this work, we exploit alternative approaches
recently developed for treating the Graph Matching Problem and propose a
method, which we will refer to as Quadratic Symmetry Approximator (QSA), to
address the aforementioned shortcomings. To test our method, we propose a set
of random graph models suitable for assessing a wide family of approximate
symmetry algorithms. The performance of our method is also demonstrated on
brain networks.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08047" title="Abstract">arXiv:2312.08047</a> [<a href="/pdf/2312.08047" title="Download PDF">pdf</a>, <a href="/ps/2312.08047" title="Download PostScript">ps</a>, <a href="/format/2312.08047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trust and Acceptance of Multi-Robot Systems &quot;in the Wild&quot;. A Roadmap  exemplified within the EU-Project BugWright2
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schroepfer%2C+P">Pete Schroepfer</a>, 
<a href="/search/cs?searchtype=author&query=Schauffel%2C+N">Nathalie Schauffel</a>, 
<a href="/search/cs?searchtype=author&query=Gr%C3%BCndling%2C+J">Jan Gr&#xfc;ndling</a>, 
<a href="/search/cs?searchtype=author&query=Ellwart%2C+T">Thomas Ellwart</a>, 
<a href="/search/cs?searchtype=author&query=Weyers%2C+B">Benjamin Weyers</a>, 
<a href="/search/cs?searchtype=author&query=Pradalier%2C+C">C&#xe9;dric Pradalier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In SCRITA 2023 Workshop Proceedings (<a href="/abs/2311.05401">arXiv:2311.05401</a>) held in conjunction with 32nd IEEE International Conference on Robot &amp; Human Interactive Communication, 28/08 - 31/08 2023, Busan (Korea)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">This paper outlines a roadmap to effectively leverage shared mental models in
multi-robot, multi-stakeholder scenarios, drawing on experiences from the
BugWright2 project. The discussion centers on an autonomous multi-robot systems
designed for ship inspection and maintenance. A significant challenge in the
development and implementation of this system is the calibration of trust. To
address this, the paper proposes that trust calibration can be managed and
optimized through the creation and continual updating of shared and accurate
mental models of the robots. Strategies to promote these mental models,
including cross-training, briefings, debriefings, and task-specific elaboration
and visualization, are examined. Additionally, the crucial role of an
adaptable, distributed, and well-structured user interface (UI) is discussed.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08048" title="Abstract">arXiv:2312.08048</a> [<a href="/pdf/2312.08048" title="Download PDF">pdf</a>, <a href="/format/2312.08048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Inversion for Stable Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xu-Lu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xiao-Yong Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jin-Lin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tian-Yi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhao-Xiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Z">Zhen Lei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Inversion methods, such as Textual Inversion, generate personalized images by
incorporating concepts of interest provided by user images. However, existing
methods often suffer from overfitting issues, where the dominant presence of
inverted concepts leads to the absence of other desired concepts. It stems from
the fact that during inversion, the irrelevant semantics in the user images are
also encoded, forcing the inverted concepts to occupy locations far from the
core distribution in the embedding space. To address this issue, we propose a
method that guides the inversion process towards the core distribution for
compositional embeddings. Additionally, we introduce a spatial regularization
approach to balance the attention on the concepts being composed. Our method is
designed as a post-training approach and can be seamlessly integrated with
other inversion methods. Experimental results demonstrate the effectiveness of
our proposed approach in mitigating the overfitting problem and generating more
diverse and balanced compositions of concepts in the synthesized images. The
source code is available at
https://github.com/zhangxulu1996/Compositional-Inversion.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08051" title="Abstract">arXiv:2312.08051</a> [<a href="/pdf/2312.08051" title="Download PDF">pdf</a>, <a href="/format/2312.08051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Path Finding with Continuous Time Using SAT Modulo Linear  Real Arithmetic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kol%C3%A1rik%2C+T">Tom&#xe1;&#x161; Kol&#xe1;rik</a>, 
<a href="/search/cs?searchtype=author&query=Ratschan%2C+S">Stefan Ratschan</a>, 
<a href="/search/cs?searchtype=author&query=Surynek%2C+P">Pavel Surynek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of the paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">This paper introduces a new approach to solving a continuous-time version of
the multi-agent path finding problem. The algorithm translates the problem into
an extension of the classical Boolean satisfiability problem, satisfiability
modulo theories (SMT), that can be solved by off-the-shelf solvers. This
enables the exploitation of conflict generalization techniques that such
solvers can handle. Computational experiments show that the new approach scales
better with respect to the available computation time than state-of-the art
approaches and is usually able to avoid their exponential behavior on a class
of benchmark problems modeling a typical bottleneck situation.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08052" title="Abstract">arXiv:2312.08052</a> [<a href="/pdf/2312.08052" title="Download PDF">pdf</a>, <a href="/format/2312.08052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Trajectory Representation through Dictionary Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yuanbo Tang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zhiyuan Peng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Trajectory representation learning on a network enhances our understanding of
vehicular traffic patterns and benefits numerous downstream applications.
Existing approaches using classic machine learning or deep learning embed
trajectories as dense vectors, which lack interpretability and are inefficient
to store and analyze in downstream tasks. In this paper, an explainable
trajectory representation learning framework through dictionary learning is
proposed. Given a collection of trajectories on a network, it extracts a
compact dictionary of commonly used subpaths called "pathlets", which optimally
reconstruct each trajectory by simple concatenations. The resulting
representation is naturally sparse and encodes strong spatial semantics.
Theoretical analysis of our proposed algorithm is conducted to provide a
probabilistic bound on the estimation error of the optimal dictionary. A
hierarchical dictionary learning scheme is also proposed to ensure the
algorithm's scalability on large networks, leading to a multi-scale trajectory
representation. Our framework is evaluated on two large-scale real-world taxi
datasets. Compared to previous work, the dictionary learned by our method is
more compact and has better reconstruction rate for new trajectories. We also
demonstrate the promising performance of this method in downstream tasks
including trip time prediction task and data compression.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08053" title="Abstract">arXiv:2312.08053</a> [<a href="/pdf/2312.08053" title="Download PDF">pdf</a>, <a href="/format/2312.08053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kimad: Adaptive Gradient Compression with Bandwidth Awareness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xin%2C+J">Jihao Xin</a>, 
<a href="/search/cs?searchtype=author&query=Ilin%2C+I">Ivan Ilin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shunkang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Canini%2C+M">Marco Canini</a>, 
<a href="/search/cs?searchtype=author&query=Richt%C3%A1rik%2C+P">Peter Richt&#xe1;rik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Information Theory (cs.IT)

</div>
<p class="mathjax">In distributed training, communication often emerges as a bottleneck. In
response, we introduce Kimad, a solution that offers adaptive gradient
compression. By consistently monitoring bandwidth, Kimad refines compression
ratios to match specific neural network layer requirements. Our exhaustive
tests and proofs confirm Kimad's outstanding performance, establishing it as a
benchmark in adaptive compression for distributed deep learning.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08054" title="Abstract">arXiv:2312.08054</a> [<a href="/pdf/2312.08054" title="Download PDF">pdf</a>, <a href="/format/2312.08054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Complete Scene Forecasting from a 4D Dynamic Point Cloud  Sequence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zhuorui Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoran Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+L">Li Yi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024, see <a href="https://scsfnet.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We study a new problem of semantic complete scene forecasting (SCSF) in this
work. Given a 4D dynamic point cloud sequence, our goal is to forecast the
complete scene corresponding to the future next frame along with its semantic
labels. To tackle this challenging problem, we properly model the synergetic
relationship between future forecasting and semantic scene completion through a
novel network named SCSFNet. SCSFNet leverages a hybrid geometric
representation for high-resolution complete scene forecasting. To leverage
multi-frame observation as well as the understanding of scene dynamics to ease
the completion task, SCSFNet introduces an attention-based skip connection
scheme. To ease the need to model occlusion variations and to better focus on
the occluded part, SCSFNet utilizes auxiliary visibility grids to guide the
forecasting task. To evaluate the effectiveness of SCSFNet, we conduct
experiments on various benchmarks including two large-scale indoor benchmarks
we contributed and the outdoor SemanticKITTI benchmark. Extensive experiments
show SCSFNet outperforms baseline methods on multiple metrics by a large
margin, and also prove the synergy between future forecasting and semantic
scene completion.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08055" title="Abstract">arXiv:2312.08055</a> [<a href="/pdf/2312.08055" title="Download PDF">pdf</a>, <a href="/format/2312.08055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breaking the Silence: the Threats of Using LLMs in Software Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sallou%2C+J">June Sallou</a>, 
<a href="/search/cs?searchtype=author&query=Durieux%2C+T">Thomas Durieux</a>, 
<a href="/search/cs?searchtype=author&query=Panichella%2C+A">Annibale Panichella</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the ICSE'24 conference, NIER track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) have gained considerable traction within the
Software Engineering (SE) community, impacting various SE tasks from code
completion to test generation, from program repair to code summarization.
Despite their promise, researchers must still be careful as numerous intricate
factors can influence the outcomes of experiments involving LLMs. This paper
initiates an open discussion on potential threats to the validity of LLM-based
research including issues such as closed-source models, possible data leakage
between LLM training data and research evaluation, and the reproducibility of
LLM-based findings. In response, this paper proposes a set of guidelines
tailored for SE researchers and Language Model (LM) providers to mitigate these
concerns. The implications of the guidelines are illustrated using existing
good practices followed by LLM providers and a practical example for SE
researchers in the context of test case generation.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08056" title="Abstract">arXiv:2312.08056</a> [<a href="/pdf/2312.08056" title="Download PDF">pdf</a>, <a href="/format/2312.08056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge-Aware Artifact Image Synthesis with LLM-Enhanced Prompting and  Multi-Source Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shengguang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenglun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Q">Qi Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Ancient artifacts are an important medium for cultural preservation and
restoration. However, many physical copies of artifacts are either damaged or
lost, leaving a blank space in archaeological and historical studies that calls
for artifact image generation techniques. Despite the significant advancements
in open-domain text-to-image synthesis, existing approaches fail to capture the
important domain knowledge presented in the textual description, resulting in
errors in recreated images such as incorrect shapes and patterns. In this
paper, we propose a novel knowledge-aware artifact image synthesis approach
that brings lost historical objects accurately into their visual forms. We use
a pretrained diffusion model as backbone and introduce three key techniques to
enhance the text-to-image generation framework: 1) we construct prompts with
explicit archaeological knowledge elicited from large language models (LLMs);
2) we incorporate additional textual guidance to correlated historical
expertise in a contrastive manner; 3) we introduce further visual-semantic
constraints on edge and perceptual features that enable our model to learn more
intricate visual details of the artifacts. Compared to existing approaches, our
proposed model produces higher-quality artifact images that align better with
the implicit details and historical knowledge contained within written
documents, thus achieving significant improvements across automatic metrics and
in human evaluation. Our code and data are available at
https://github.com/danielwusg/artifact_diffusion.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08057" title="Abstract">arXiv:2312.08057</a> [<a href="/pdf/2312.08057" title="Download PDF">pdf</a>, <a href="/format/2312.08057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combinatorial Stochastic-Greedy Bandit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fourati%2C+F">Fares Fourati</a>, 
<a href="/search/cs?searchtype=author&query=Quinn%2C+C+J">Christopher John Quinn</a>, 
<a href="/search/cs?searchtype=author&query=Alouini%2C+M">Mohamed-Slim Alouini</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+V">Vaneet Aggarwal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Combinatorics (math.CO); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">We propose a novel combinatorial stochastic-greedy bandit (SGB) algorithm for
combinatorial multi-armed bandit problems when no extra information other than
the joint reward of the selected set of $n$ arms at each time step $t\in [T]$
is observed. SGB adopts an optimized stochastic-explore-then-commit approach
and is specifically designed for scenarios with a large set of base arms.
Unlike existing methods that explore the entire set of unselected base arms
during each selection step, our SGB algorithm samples only an optimized
proportion of unselected arms and selects actions from this subset. We prove
that our algorithm achieves a $(1-1/e)$-regret bound of
$\mathcal{O}(n^{\frac{1}{3}} k^{\frac{2}{3}} T^{\frac{2}{3}}
\log(T)^{\frac{2}{3}})$ for monotone stochastic submodular rewards, which
outperforms the state-of-the-art in terms of the cardinality constraint $k$.
Furthermore, we empirically evaluate the performance of our algorithm in the
context of online constrained social influence maximization. Our results
demonstrate that our proposed approach consistently outperforms the other
algorithms, increasing the performance gap as $k$ grows.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08058" title="Abstract">arXiv:2312.08058</a> [<a href="/pdf/2312.08058" title="Download PDF">pdf</a>, <a href="/format/2312.08058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Event-Triggered Safe Bayesian Optimization on Quadcopters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Holzapfel%2C+A">Antonia Holzapfel</a>, 
<a href="/search/eess?searchtype=author&query=Brunzema%2C+P">Paul Brunzema</a>, 
<a href="/search/eess?searchtype=author&query=Trimpe%2C+S">Sebastian Trimpe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Bayesian optimization (BO) has proven to be a powerful tool for automatically
tuning control parameters without requiring knowledge of the underlying system
dynamics. Safe BO methods, in addition, guarantee safety during the
optimization process, assuming that the underlying objective function does not
change. However, in real-world scenarios, time-variations frequently occur, for
example, due to wear in the system or changes in operation. Utilizing standard
safe BO strategies that do not address time-variations can result in failure as
previous safe decisions may become unsafe over time, which we demonstrate
herein. To address this, we introduce a new algorithm, Event-Triggered SafeOpt
(ETSO), which adapts to changes online solely relying on the observed costs. At
its core, ETSO uses an event trigger to detect significant deviations between
observations and the current surrogate of the objective function. When such
change is detected, the algorithm reverts to a safe backup controller, and
exploration is restarted. In this way, safety is recovered and maintained
across changes. We evaluate ETSO on quadcopter controller tuning, both in
simulation and hardware experiments. ETSO outperforms state-of-the-art safe BO,
achieving superior control performance over time while maintaining safety.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08060" title="Abstract">arXiv:2312.08060</a> [<a href="/pdf/2312.08060" title="Download PDF">pdf</a>, <a href="/format/2312.08060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> C-BEV: Contrastive Bird&#x27;s Eye View Training for Cross-View Image  Retrieval and 3-DoF Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fervers%2C+F">Florian Fervers</a>, 
<a href="/search/cs?searchtype=author&query=Bullinger%2C+S">Sebastian Bullinger</a>, 
<a href="/search/cs?searchtype=author&query=Bodensteiner%2C+C">Christoph Bodensteiner</a>, 
<a href="/search/cs?searchtype=author&query=Arens%2C+M">Michael Arens</a>, 
<a href="/search/cs?searchtype=author&query=Stiefelhagen%2C+R">Rainer Stiefelhagen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">To find the geolocation of a street-view image, cross-view geolocalization
(CVGL) methods typically perform image retrieval on a database of georeferenced
aerial images and determine the location from the visually most similar match.
Recent approaches focus mainly on settings where street-view and aerial images
are preselected to align w.r.t. translation or orientation, but struggle in
challenging real-world scenarios where varying camera poses have to be matched
to the same aerial image. We propose a novel trainable retrieval architecture
that uses bird's eye view (BEV) maps rather than vectors as embedding
representation, and explicitly addresses the many-to-one ambiguity that arises
in real-world scenarios. The BEV-based retrieval is trained using the same
contrastive setting and loss as classical retrieval.
<br />Our method C-BEV surpasses the state-of-the-art on the retrieval task on
multiple datasets by a large margin. It is particularly effective in
challenging many-to-one scenarios, e.g. increasing the top-1 recall on VIGOR's
cross-area split with unknown orientation from 31.1% to 65.0%. Although the
model is supervised only through a contrastive objective applied on image
pairings, it additionally learns to infer the 3-DoF camera pose on the matching
aerial image, and even yields a lower mean pose error than recent methods that
are explicitly trained with metric groundtruth.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08063" title="Abstract">arXiv:2312.08063</a> [<a href="/pdf/2312.08063" title="Download PDF">pdf</a>, <a href="/format/2312.08063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimation of Concept Explanations Should be Uncertainty Aware
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Piratla%2C+V">Vihari Piratla</a>, 
<a href="/search/cs?searchtype=author&query=Heo%2C+J">Juyeon Heo</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Sukriti Singh</a>, 
<a href="/search/cs?searchtype=author&query=Weller%2C+A">Adrian Weller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Model explanations are very valuable for interpreting and debugging
prediction models. We study a specific kind of global explanations called
Concept Explanations, where the goal is to interpret a model using
human-understandable concepts. Recent advances in multi-modal learning
rekindled interest in concept explanations and led to several label-efficient
proposals for estimation. However, existing estimation methods are unstable to
the choice of concepts or dataset that is used for computing explanations. We
observe that instability in explanations is due to high variance in point
estimation of importance scores. We propose an uncertainty aware Bayesian
estimation method, which readily improved reliability of the concept
explanations. We demonstrate with theoretical analysis and empirical evaluation
that explanations computed by our method are more reliable while also being
label-efficient and faithful.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08064" title="Abstract">arXiv:2312.08064</a> [<a href="/pdf/2312.08064" title="Download PDF">pdf</a>, <a href="/format/2312.08064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Impact of Lay User Feedback for Improving AI Fairness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taka%2C+E">Evdoxia Taka</a>, 
<a href="/search/cs?searchtype=author&query=Nakao%2C+Y">Yuri Nakao</a>, 
<a href="/search/cs?searchtype=author&query=Sonoda%2C+R">Ryosuke Sonoda</a>, 
<a href="/search/cs?searchtype=author&query=Yokota%2C+T">Takuya Yokota</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Lin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Stumpf%2C+S">Simone Stumpf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Fairness in AI is a growing concern for high-stakes decision making. Engaging
stakeholders, especially lay users, in fair AI development is promising yet
overlooked. Recent efforts explore enabling lay users to provide AI
fairness-related feedback, but there is still a lack of understanding of how to
integrate users' feedback into an AI model and the impacts of doing so. To
bridge this gap, we collected feedback from 58 lay users on the fairness of a
XGBoost model trained on the Home Credit dataset, and conducted offline
experiments to investigate the effects of retraining models on accuracy, and
individual and group fairness. Our work contributes baseline results of
integrating user fairness feedback in XGBoost, and a dataset and code framework
to bootstrap research in engaging stakeholders in AI fairness. Our discussion
highlights the challenges of employing user feedback in AI fairness and points
the way to a future application area of interactive machine learning.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08066" title="Abstract">arXiv:2312.08066</a> [<a href="/pdf/2312.08066" title="Download PDF">pdf</a>, <a href="/format/2312.08066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Metric for Measuring Data Quality in Classification Applications  (extended version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roxane%2C+J">Jouseau Roxane</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A9bastien%2C+S">Salva S&#xe9;bastien</a>, 
<a href="/search/cs?searchtype=author&query=Chafik%2C+S">Samir Chafik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Data quality is a key element for building and optimizing good learning
models. Despite many attempts to characterize data quality, there is still a
need for rigorous formalization and an efficient measure of the quality from
available observations. Indeed, without a clear understanding of the training
and testing processes, it is hard to evaluate the intrinsic performance of a
model. Besides, tools allowing to measure data quality specific to machine
learning are still lacking. In this paper, we introduce and explain a novel
metric to measure data quality. This metric is based on the correlated
evolution between the classification performance and the deterioration of data.
The proposed method has the major advantage of being model-independent.
Furthermore, we provide an interpretation of each criterion and examples of
assessment levels. We confirm the utility of the proposed metric with intensive
numerical experiments and detail some illustrative cases with controlled and
interpretable qualities.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08069" title="Abstract">arXiv:2312.08069</a> [<a href="/pdf/2312.08069" title="Download PDF">pdf</a>, <a href="/ps/2312.08069" title="Download PostScript">ps</a>, <a href="/format/2312.08069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Spatial Resolution of First-order Ambisonics Using Sparse MDCT  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Likhachov%2C+D">Denis Likhachov</a>, 
<a href="/search/cs?searchtype=author&query=Petrovsky%2C+N">Nick Petrovsky</a>, 
<a href="/search/cs?searchtype=author&query=Azarov%2C+E">Elias Azarov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Associated slides with audio samples <a href="https://effective-sound.com/downloads/ambisonic_upmix.pptx">this https URL</a> Audio samples with visualizations <a href="https://youtu.be/O15zvgWKa6A">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of 16-th International Conference PRIP2023, Minsk,
  2023, P. 122-125
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>

</div>
<p class="mathjax">The paper presents a method for improving spatial resolution of first-order
ambisonic audio. The method is based on time/frequency decomposition of the
audio with subsequent extraction of a directed plane wave from each frequency
component. The method develops the basic ideas of high angular resolution
planewave expansion (HARPEX) and directional audio coding (DirAC) taking
advantage of real-valued sparse decomposition. Real-valued frequency components
as opposed to complex-valued introduce simpler and more stable direction of
arrival estimates, while sparse decomposition introduces an accurate and
unified approach to describing sounds of different nature from transient to
tonal sounds.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08070" title="Abstract">arXiv:2312.08070</a> [<a href="/pdf/2312.08070" title="Download PDF">pdf</a>, <a href="/format/2312.08070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Laser Powered Harvesting System for Table-Top Grown Strawberries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sorour%2C+M">Mohamed Sorour</a>, 
<a href="/search/cs?searchtype=author&query=From%2C+P+J">P&#xe5;l Johan From</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, a novel tool prototype for harvesting table-top grown
strawberries is presented. With robustness against strawberry localization
error of 15mm and average cycle time of 8.02 seconds at 50% of maximum
operational velocity, it provides a promising contribution towards full
automation of strawberry harvesting. In addition, the tool has an overall
fruit-interacting width of 35mm that greatly enhances reach-ability due to the
minimal footprint. A complete harvesting system is also proposed that can be
readily mounted to a mobile platform for field tests. An experimental
demonstration is performed to showcase the new methodology and derive relevant
metrics.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08071" title="Abstract">arXiv:2312.08071</a> [<a href="/pdf/2312.08071" title="Download PDF">pdf</a>, <a href="/format/2312.08071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Novel View Synthesis with View-Dependent Effects from a Single Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bello%2C+J+L+G">Juan Luis Gonzalez Bello</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Munchurl Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Visit our website <a href="https://kaist-viclab.github.io/monovde-site">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">In this paper, we firstly consider view-dependent effects into single
image-based novel view synthesis (NVS) problems. For this, we propose to
exploit the camera motion priors in NVS to model view-dependent appearance or
effects (VDE) as the negative disparity in the scene. By recognizing
specularities "follow" the camera motion, we infuse VDEs into the input images
by aggregating input pixel colors along the negative depth region of the
epipolar lines. Also, we propose a `relaxed volumetric rendering' approximation
that allows computing the densities in a single pass, improving efficiency for
NVS from single images. Our method can learn single-image NVS from image
sequences only, which is a completely self-supervised learning method, for the
first time requiring neither depth nor camera pose annotations. We present
extensive experiment results and show that our proposed method can learn NVS
with VDEs, outperforming the SOTA single-view NVS methods on the RealEstate10k
and MannequinChallenge datasets.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08075" title="Abstract">arXiv:2312.08075</a> [<a href="/pdf/2312.08075" title="Download PDF">pdf</a>, <a href="/format/2312.08075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TERM Model: Tensor Ring Mixture Model for Density Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Ruituo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiani Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Ce Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+A">Anh-Huy Phan</a>, 
<a href="/search/cs?searchtype=author&query=Oseledets%2C+I+V">Ivan V. Oseledets</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yipeng Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Efficient probability density estimation is a core challenge in statistical
machine learning. Tensor-based probabilistic graph methods address
interpretability and stability concerns encountered in neural network
approaches. However, a substantial number of potential tensor permutations can
lead to a tensor network with the same structure but varying expressive
capabilities. In this paper, we take tensor ring decomposition for density
estimator, which significantly reduces the number of permutation candidates
while enhancing expressive capability compared with existing used
decompositions. Additionally, a mixture model that incorporates multiple
permutation candidates with adaptive weights is further designed, resulting in
increased expressive flexibility and comprehensiveness. Different from the
prevailing directions of tensor network structure/permutation search, our
approach provides a new viewpoint inspired by ensemble learning. This approach
acknowledges that suboptimal permutations can offer distinctive information
besides that of optimal permutations. Experiments show the superiority of the
proposed approach in estimating probability density for moderately dimensional
datasets and sampling to capture intricate details.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08076" title="Abstract">arXiv:2312.08076</a> [<a href="/pdf/2312.08076" title="Download PDF">pdf</a>, <a href="/format/2312.08076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably-Correct Safety Protocol for Cooperative Platooning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mair%2C+S">Sebastian Mair</a>, 
<a href="/search/eess?searchtype=author&query=Althoff%2C+M">Matthias Althoff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Cooperative Adaptive Cruise Control (CACC) is a well-studied technology for
forming string-stable vehicle platoons. Ensuring collision avoidance is
particularly difficult in CACC due to the small desired inter-vehicle spacing.
We propose a safety protocol preventing collisions in a provably-correct manner
while still maintaining a small distance to the preceding vehicle, by utilizing
communicated braking capabilities. In addition, the safety of the protocol is
ensured despite possible communication failures. While our concept can be
applied to any CACC system, we particularly consider a class of CACCs, where
the platoon vehicles successively agree on a consensus behavior. Our safety
protocol is evaluated on various scenarios using the CommonRoad benchmark
suite.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08077" title="Abstract">arXiv:2312.08077</a> [<a href="/pdf/2312.08077" title="Download PDF">pdf</a>, <a href="/format/2312.08077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auctions and mass transportation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kolesnikov%2C+A+V">Alexander V. Kolesnikov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Functional Analysis (math.FA)

</div>
<p class="mathjax">In this survey paper we present classical and recent results relating the
auction design and the optimal transportation theory.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08078" title="Abstract">arXiv:2312.08078</a> [<a href="/pdf/2312.08078" title="Download PDF">pdf</a>, <a href="/format/2312.08078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Grained Image-Text Alignment in Medical Imaging Enables Cyclic  Image-Report Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Linlin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yixuan Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">To address these issues, we propose a novel Adaptive patch-word Matching
(AdaMatch) model to correlate chest X-ray (CXR) image regions with words in
medical reports and apply it to CXR-report generation to provide explainability
for the generation process. AdaMatch exploits the fine-grained relation between
adaptive patches and words to provide explanations of specific image regions
with corresponding words. To capture the abnormal regions of varying sizes and
positions, we introduce the Adaptive Patch extraction (AdaPatch) module to
acquire the adaptive patches for these regions adaptively. In order to provide
explicit explainability for CXR-report generation task, we propose an
AdaMatch-based bidirectional large language model for Cyclic CXR-report
generation (AdaMatch-Cyclic). It employs the AdaMatch to obtain the keywords
for CXR images and `keypatches' for medical reports as hints to guide
CXR-report generation. Extensive experiments on two publicly available CXR
datasets prove the effectiveness of our method and its superior performance to
existing methods.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08079" title="Abstract">arXiv:2312.08079</a> [<a href="/pdf/2312.08079" title="Download PDF">pdf</a>, <a href="/format/2312.08079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extending Whisper with prompt tuning to target-speaker ASR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Hao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zhiyuan Peng</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+M">Mingjie Shao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jing Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Ju Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Target-speaker automatic speech recognition (ASR) aims to transcribe the
desired speech of a target speaker from multi-talker overlapped utterances.
Most of the existing target-speaker ASR (TS-ASR) methods involve either
training from scratch or fully fine-tuning a pre-trained model, leading to
significant training costs and becoming inapplicable to large foundation
models. This work leverages prompt tuning, a parameter-efficient fine-tuning
approach, to extend Whisper, a large-scale single-talker ASR model, to TS-ASR.
Experimental results show that prompt tuning can achieve performance comparable
to state-of-the-art full fine-tuning approaches while only requiring about 1%
of task-specific model parameters. Notably, the original Whisper's features,
such as inverse text normalization and timestamp prediction, are retained in
target-speaker ASR, keeping the generated transcriptions natural and
informative.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08084" title="Abstract">arXiv:2312.08084</a> [<a href="/pdf/2312.08084" title="Download PDF">pdf</a>, <a href="/format/2312.08084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Energy based Model Mechanism for Multi-modal Aspect-Based  Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+T">Tianshuo Peng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zuchao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Ping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lefei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hai Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Multi-modal aspect-based sentiment analysis (MABSA) has recently attracted
increasing attention. The span-based extraction methods, such as FSUIE,
demonstrate strong performance in sentiment analysis due to their joint
modeling of input sequences and target labels. However, previous methods still
have certain limitations: (i) They ignore the difference in the focus of visual
information between different analysis targets (aspect or sentiment). (ii)
Combining features from uni-modal encoders directly may not be sufficient to
eliminate the modal gap and can cause difficulties in capturing the image-text
pairwise relevance. (iii) Existing span-based methods for MABSA ignore the
pairwise relevance of target span boundaries. To tackle these limitations, we
propose a novel framework called DQPSA for multi-modal sentiment analysis.
Specifically, our model contains a Prompt as Dual Query (PDQ) module that uses
the prompt as both a visual query and a language query to extract prompt-aware
visual information and strengthen the pairwise relevance between visual
information and the analysis target. Additionally, we introduce an Energy-based
Pairwise Expert (EPE) module that models the boundaries pairing of the analysis
target from the perspective of an Energy-based Model. This expert predicts
aspect or sentiment span based on pairwise stability. Experiments on three
widely used benchmarks demonstrate that DQPSA outperforms previous approaches
and achieves a new state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08085" title="Abstract">arXiv:2312.08085</a> [<a href="/pdf/2312.08085" title="Download PDF">pdf</a>, <a href="/format/2312.08085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Bayesian Inverse Problems With Expensive Likelihoods Using  Constrained Gaussian Processes and Active Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dinkel%2C+M">Maximilian Dinkel</a>, 
<a href="/search/cs?searchtype=author&query=Geitner%2C+C+M">Carolin M. Geitner</a>, 
<a href="/search/cs?searchtype=author&query=Rei%2C+G+R">Gil Robalo Rei</a>, 
<a href="/search/cs?searchtype=author&query=Nitzler%2C+J">Jonas Nitzler</a>, 
<a href="/search/cs?searchtype=author&query=Wall%2C+W+A">Wolfgang A. Wall</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Solving inverse problems using Bayesian methods can become prohibitively
expensive when likelihood evaluations involve complex and large scale numerical
models. A common approach to circumvent this issue is to approximate the
forward model or the likelihood function with a surrogate model. But also
there, due to limited computational resources, only a few training points are
available in many practically relevant cases. Thus, it can be advantageous to
model the additional uncertainties of the surrogate in order to incorporate the
epistemic uncertainty due to limited data. In this paper, we develop a novel
approach to approximate the log likelihood by a constrained Gaussian process
based on prior knowledge about its boundedness. This improves the accuracy of
the surrogate approximation without increasing the number of training samples.
Additionally, we introduce a formulation to integrate the epistemic uncertainty
due to limited training points into the posterior density approximation. This
is combined with a state of the art active learning strategy for selecting
training points, which allows to approximate posterior densities in higher
dimensions very efficiently. We demonstrate the fast convergence of our
approach for a benchmark problem and infer a random field that is discretized
by 30 parameters using only about 1000 model evaluations. In a practically
relevant example, the parameters of a reduced lung model are calibrated based
on flow observations over time and voltage measurements from a coupled
electrical impedance tomography simulation.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08086" title="Abstract">arXiv:2312.08086</a> [<a href="/pdf/2312.08086" title="Download PDF">pdf</a>, <a href="/format/2312.08086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recursive Augmented Fernet (RAF) Token: Alleviating the Pain of Stolen  Tokens
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahaeimehr%2C+R">Reza Rahaeimehr</a> (1), 
<a href="/search/cs?searchtype=author&query=van+Dijk%2C+M">Marten van Dijk</a> (2) ((1) Augusta University, GA, USA (2) University of Connecticut, CT, USA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">A robust authentication and authorization mechanism is imperative in modular
system development, where modularity and modular thinking are pivotal.
Traditional systems often employ identity modules responsible for
authentication and token issuance. Tokens, representing user credentials, offer
advantages such as reduced reliance on passwords, limited lifespan, and scoped
access. Despite these benefits, the "bearer token" problem persists, leaving
systems vulnerable to abuse if tokens are compromised. We propose a token-based
authentication mechanism addressing modular systems' critical bearer token
problem. The proposed mechanism includes a novel RAF (Recursive Augmented
Fernet) token, a blacklist component, and a policy enforcer component. RAF
tokens are one-time-use tokens, like tickets. They carry commands, and the
receiver of an RAF token can issue new tokens using the received RAF token. The
blacklist component guarantees an RAF token can not be approved more than once,
and the policy enforcer checks the compatibility of commands carried by an RAF
token. We introduce two variations of RAF tokens: User-tied RAF, offering
simplicity and compatibility, and Fully-tied RAF, providing enhanced security
through service-specific secret keys. We thoroughly discuss the security
guarantees, technical definitions, and construction of RAF tokens backed by
game-based proofs. We demonstrate a proof of concept in the context of
OpenStack, involving modifications to Keystone and creating an RAFT library.
The experimental results reveal minimal overhead in typical scenarios,
establishing the practicality and effectiveness of RAF. Our experiments show
that the RAF mechanism beats the idea of using short-life Fernet tokens while
providing much better security.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08090" title="Abstract">arXiv:2312.08090</a> [<a href="/pdf/2312.08090" title="Download PDF">pdf</a>, <a href="/format/2312.08090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The State of Pilot Study Reporting in Crowdsourcing: A Reflection on  Best Practices and Guidelines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oppenlaender%2C+J">Jonas Oppenlaender</a>, 
<a href="/search/cs?searchtype=author&query=Abbas%2C+T">Tahir Abbas</a>, 
<a href="/search/cs?searchtype=author&query=Gadiraju%2C+U">Ujwal Gadiraju</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CSCW '24. 45 pages, 17 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Pilot studies are an essential cornerstone of the design of crowdsourcing
campaigns, yet they are often only mentioned in passing in the scholarly
literature. A lack of details surrounding pilot studies in crowdsourcing
research hinders the replication of studies and the reproduction of findings,
stalling potential scientific advances. We conducted a systematic literature
review on the current state of pilot study reporting at the intersection of
crowdsourcing and HCI research. Our review of ten years of literature included
171 articles published in the proceedings of the Conference on Human
Computation and Crowdsourcing (AAAI HCOMP) and the ACM Digital Library. We
found that pilot studies in crowdsourcing research (i.e., crowd pilot studies)
are often under-reported in the literature. Important details, such as the
number of workers and rewards to workers, are often not reported. On the basis
of our findings, we reflect on the current state of practice and formulate a
set of best practice guidelines for reporting crowd pilot studies in
crowdsourcing research. We also provide implications for the design of
crowdsourcing platforms and make practical suggestions for supporting crowd
pilot study reporting.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08092" title="Abstract">arXiv:2312.08092</a> [<a href="/pdf/2312.08092" title="Download PDF">pdf</a>, <a href="/format/2312.08092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A hybrid analysis of LBSN data to early detect anomalies in crowd  dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz-Redondo%2C+R+P">Rebeca P. D&#xed;az-Redondo</a>, 
<a href="/search/cs?searchtype=author&query=Garcia-Rubio%2C+C">Carlos Garcia-Rubio</a>, 
<a href="/search/cs?searchtype=author&query=Vilas%2C+A+F">Ana Fern&#xe1;ndez Vilas</a>, 
<a href="/search/cs?searchtype=author&query=Campo%2C+C">Celeste Campo</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez-Carrion%2C+A">Alicia Rodriguez-Carrion</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Future Generation Computer Systems, 2020, vol. 109, p. 83-94
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Undoubtedly, Location-based Social Networks (LBSNs) provide an interesting
source of geo-located data that we have previously used to obtain patterns of
the dynamics of crowds throughout urban areas. According to our previous
results, activity in LBSNs reflects the real activity in the city. Therefore,
unexpected behaviors in the social media activity are a trustful evidence of
unexpected changes of the activity in the city. In this paper we introduce a
hybrid solution to early detect these changes based on applying a combination
of two approaches, the use of entropy analysis and clustering techniques, on
the data gathered from LBSNs. In particular, we have performed our experiments
over a data set collected from Instagram for seven months in New York City,
obtaining promising results.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08094" title="Abstract">arXiv:2312.08094</a> [<a href="/pdf/2312.08094" title="Download PDF">pdf</a>, <a href="/format/2312.08094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3DGEN: A GAN-based approach for generating novel 3D models from image  data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schnepf%2C+A">Antoine Schnepf</a>, 
<a href="/search/cs?searchtype=author&query=Vasile%2C+F">Flavian Vasile</a>, 
<a href="/search/cs?searchtype=author&query=Tanielian%2C+U">Ugo Tanielian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to NeurIPS 2022 Machine Learning for Creativity and Design Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The recent advances in text and image synthesis show a great promise for the
future of generative models in creative fields. However, a less explored area
is the one of 3D model generation, with a lot of potential applications to game
design, video production, and physical product design. In our paper, we present
3DGEN, a model that leverages the recent work on both Neural Radiance Fields
for object reconstruction and GAN-based image generation. We show that the
proposed architecture can generate plausible meshes for objects of the same
category as the training images and compare the resulting meshes with the
state-of-the-art baselines, leading to visible uplifts in generation quality.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08096" title="Abstract">arXiv:2312.08096</a> [<a href="/pdf/2312.08096" title="Download PDF">pdf</a>, <a href="/format/2312.08096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Incentive Mechanism for Federated Learning Based on Multiple Resource  Exchange
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+R">Ruonan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Han Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">GuoPeng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Federated Learning (FL) is a distributed machine learning paradigm that
addresses privacy concerns in machine learning and still guarantees high test
accuracy. However, achieving the necessary accuracy by having all clients
participate in FL is impractical, given the constraints of client local
computing resource. In this paper, we introduce a multi-user collaborative
computing framework, categorizing users into two roles: model owners (MOs) and
data owner (DOs). Without resorting to monetary incentives, an MO can encourage
more DOs to join in FL by allowing the DOs to offload extra local computing
tasks to the MO for execution. This exchange of "data" for "computing
resources" streamlines the incentives for clients to engage more effectively in
FL. We formulate the interaction between MO and DOs as an optimization problem,
and the objective is to effectively utilize the communication and computing
resource of the MO and DOs to minimize the time to complete an FL task. The
proposed problem is a mixed integer nonlinear programming (MINLP) with high
computational complexity. We first decompose it into two distinct subproblems,
namely the client selection problem and the resource allocation problem to
segregate the integer variables from the continuous variables. Then, an
effective iterative algorithm is proposed to solve problem. Simulation results
demonstrate that the proposed collaborative computing framework can achieve an
accuracy of more than 95\% while minimizing the overall time to complete an FL
task.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08098" title="Abstract">arXiv:2312.08098</a> [<a href="/pdf/2312.08098" title="Download PDF">pdf</a>, <a href="/format/2312.08098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Socialbots Modeling Based on Structural Information  Principles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xianghua Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Angsheng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The importance of effective detection is underscored by the fact that
socialbots imitate human behavior to propagate misinformation, leading to an
ongoing competition between socialbots and detectors. Despite the rapid
advancement of reactive detectors, the exploration of adversarial socialbot
modeling remains incomplete, significantly hindering the development of
proactive detectors. To address this issue, we propose a mathematical
Structural Information principles-based Adversarial Socialbots Modeling
framework, namely SIASM, to enable more accurate and effective modeling of
adversarial behaviors. First, a heterogeneous graph is presented to integrate
various users and rich activities in the original social network and measure
its dynamic uncertainty as structural entropy. By minimizing the
high-dimensional structural entropy, a hierarchical community structure of the
social network is generated and referred to as the optimal encoding tree.
Secondly, a novel method is designed to quantify influence by utilizing the
assigned structural entropy, which helps reduce the computational cost of SIASM
by filtering out uninfluential users. Besides, a new conditional structural
entropy is defined between the socialbot and other users to guide the follower
selection for network influence maximization. Extensive and comparative
experiments on both homogeneous and heterogeneous social networks demonstrate
that, compared with state-of-the-art baselines, the proposed SIASM framework
yields substantial performance improvements in terms of network influence (up
to 16.32%) and sustainable stealthiness (up to 16.29%) when evaluated against a
robust detector with 90% accuracy.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08101" title="Abstract">arXiv:2312.08101</a> [<a href="/pdf/2312.08101" title="Download PDF">pdf</a>, <a href="/format/2312.08101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Security aspects in Smart Meters: Analysis and Prevention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Redondo%2C+R+P+D">Rebeca P. D&#xed;az Redondo</a>, 
<a href="/search/cs?searchtype=author&query=Vilas%2C+A+F">Ana Fern&#xe1;ndez Vilas</a>, 
<a href="/search/cs?searchtype=author&query=Reis%2C+G+F+d">Gabriel Fern&#xe1;ndez dos Reis</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sensors, 2020, vol. 20, no 14, p. 3977
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Smart meters are of the basic elements in the so-called Smart Grid. These
devices, connected to the Internet, keep bidirectional communication with other
devices in the Smart Grid structure to allow remote readings and maintenance.
As any other device connected to a network, smart meters become vulnerable to
attacks with different purposes, like stealing data or altering readings.
Nowadays, it is becoming more and more popular to buy and plug-and-play smart
meters, additionally to those installed by the energy providers, to directly
monitor the energy consumption at home. This option inherently entails security
risks that are under the responsibility of householders. In this paper, we
focus on an open solution based on Smartpi 2.0 devices with two purposes. On
the one hand, we propose a network configuration and different data flows to
exchange data (energy readings) in the home. These flows are designed to
support collaborative among the devices in order to prevent external attacks
and attempts of corrupting the data. On the other hand, we check the
vulnerability by performing two kind of attacks (denial of service and stealing
and changing data by using a malware). We conclude that, as expected, these
devices are vulnerable to these attacks, but we provide mechanisms to detect
both of them and to solve, by applying cooperation techniques
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08103" title="Abstract">arXiv:2312.08103</a> [<a href="/pdf/2312.08103" title="Download PDF">pdf</a>, <a href="/format/2312.08103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning for the Multi-Dimensional Bin Packing Problem:  Literature Review and Empirical Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenjie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Changjun Fan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jincai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">The Bin Packing Problem (BPP) is a well-established combinatorial
optimization (CO) problem. Since it has many applications in our daily life,
e.g. logistics and resource allocation, people are seeking efficient bin
packing algorithms. On the other hand, researchers have been making constant
advances in machine learning (ML), which is famous for its efficiency. In this
article, we first formulate BPP, introducing its variants and practical
constraints. Then, a comprehensive survey on ML for multi-dimensional BPP is
provided. We further collect some public benchmarks of 3D BPP, and evaluate
some online methods on the Cutting Stock Dataset. Finally, we share our
perspective on challenges and future directions in BPP. To the best of our
knowledge, this is the first systematic review of ML-related methods for BPP.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08104" title="Abstract">arXiv:2312.08104</a> [<a href="/pdf/2312.08104" title="Download PDF">pdf</a>, <a href="/ps/2312.08104" title="Download PostScript">ps</a>, <a href="/format/2312.08104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectrophotometers for Labs: a Cost-efficient Solution based on  Smartphones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez%2C+C+B">Carlos Balado S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Redondo%2C+R+P+D">Rebeca P. D&#xed;az Redondo</a>, 
<a href="/search/cs?searchtype=author&query=Vilas%2C+A+F">Ana Fern&#xe1;ndez Vilas</a>, 
<a href="/search/cs?searchtype=author&query=Berm%C3%BAdez%2C+A+M+S">Angel M. S&#xe1;nchez Berm&#xfa;dez</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Applications in Engineering Education, 2019, vol. 27, no
  2, p. 371-379
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In this paper we introduce a proposal to provide students in labs with an
alternative to the traditional visible range spectrophotometers, whose
acquisition and maintenance entails high costs, based on smartphones. Our
solution faced two aspects. On the one hand, the software for the smartphone,
able to perform the typical functionalities of the traditional
spectrophotometers. On the other hand, the portable peripheral support needed
to capture the images to be analyzed in the smartphone. The promising results
allow this solution to be applied in Bring Your Own Devices (BYOD) contexts.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08107" title="Abstract">arXiv:2312.08107</a> [<a href="/pdf/2312.08107" title="Download PDF">pdf</a>, <a href="/format/2312.08107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Optimal Transport of Abstractions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Felekis%2C+Y">Yorgos Felekis</a>, 
<a href="/search/cs?searchtype=author&query=Zennaro%2C+F+M">Fabio Massimo Zennaro</a>, 
<a href="/search/cs?searchtype=author&query=Branchini%2C+N">Nicola Branchini</a>, 
<a href="/search/cs?searchtype=author&query=Damoulas%2C+T">Theodoros Damoulas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Causal abstraction (CA) theory establishes formal criteria for relating
multiple structural causal models (SCMs) at different levels of granularity by
defining maps between them. These maps have significant relevance for
real-world challenges such as synthesizing causal evidence from multiple
experimental environments, learning causally consistent representations at
different resolutions, and linking interventions across multiple SCMs. In this
work, we propose COTA, the first method to learn abstraction maps from
observational and interventional data without assuming complete knowledge of
the underlying SCMs. In particular, we introduce a multi-marginal Optimal
Transport (OT) formulation that enforces do-calculus causal constraints,
together with a cost function that relies on interventional information. We
extensively evaluate COTA on synthetic and real world problems, and showcase
its advantages over non-causal, independent and aggregated COTA formulations.
Finally, we demonstrate the efficiency of our method as a data augmentation
tool by comparing it against the state-of-the-art CA learning framework, which
assumes fully specified SCMs, on a real-world downstream task.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08109" title="Abstract">arXiv:2312.08109</a> [<a href="/pdf/2312.08109" title="Download PDF">pdf</a>, <a href="/ps/2312.08109" title="Download PostScript">ps</a>, <a href="/format/2312.08109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Construction of $(&#x3c3;,&#x3b4;)$-cyclic codes over a non-chain ring and  their applications in DNA codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Ashutosh Singh</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+P">Priyanka Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Prakash%2C+O">Om Prakash</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">For a prime $p$ and a positive integer $m$, let $\mathbb{F}_{p^m}$ be the
finite field of characteristic $p$, and
$\mathfrak{R}_l:=\mathbb{F}_{p^m}[v]/\langle v^l-v\rangle$ be a non-chain ring.
In this paper, we study the $(\sigma,\delta)$-cyclic codes over
$\mathfrak{R}_l$. Further, we study the application of these codes in finding
DNA codes. Towards this, we first define a Gray map to find classical codes
over $\mathbb{F}_{p^m}$ using codes over the ring $\mathfrak{R}_l$. Later, we
find the conditions for a code to be reversible and a DNA code using $(\sigma,
\delta)$-cyclic code. Finally, this algebraic method provides many classical
and DNA codes of better parameters.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08111" title="Abstract">arXiv:2312.08111</a> [<a href="/pdf/2312.08111" title="Download PDF">pdf</a>, <a href="/format/2312.08111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Better Morphed Face Images without Ghosting Artifacts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seibold%2C+C">Clemens Seibold</a>, 
<a href="/search/cs?searchtype=author&query=Hilsmann%2C+A">Anna Hilsmann</a>, 
<a href="/search/cs?searchtype=author&query=Eisert%2C+P">Peter Eisert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at VISAPP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Automatic generation of morphed face images often produces ghosting artifacts
due to poorly aligned structures in the input images. Manual processing can
mitigate these artifacts. However, this is not feasible for the generation of
large datasets, which are required for training and evaluating robust morphing
attack detectors. In this paper, we propose a method for automatic prevention
of ghosting artifacts based on a pixel-wise alignment during morph generation.
We evaluate our proposed method on state-of-the-art detectors and show that our
morphs are harder to detect, particularly, when combined with
style-transfer-based improvement of low-level image characteristics.
Furthermore, we show that our approach does not impair the biometric quality,
which is essential for high quality morphs.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08117" title="Abstract">arXiv:2312.08117</a> [<a href="/pdf/2312.08117" title="Download PDF">pdf</a>, <a href="/ps/2312.08117" title="Download PostScript">ps</a>, <a href="/format/2312.08117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory Simulations, Security and Optimization in a Verified Compiler
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Monniaux%2C+D">David Monniaux</a> (VERIMAG - IMAG)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Certified Programs and Proofs 2024, Jan 2024, London, United Kingdom, France
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Current compilers implement security features and optimizations that require
nontrivial semantic reasoning about pointers and memory allocation: the program
after the insertion of the security feature, or after applying the
optimization, must simulate the original program despite a different memory
layout. In this article, we illustrate such reasoning on pointer allocations
through memory extensions and injections, as well as fine points on undefined
values, by explaining how we implemented and proved correct two security
features (stack canaries and pointer authentication) and one optimization (tail
recursion elimination) in the CompCert formally verified compiler.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08118" title="Abstract">arXiv:2312.08118</a> [<a href="/pdf/2312.08118" title="Download PDF">pdf</a>, <a href="/format/2312.08118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Radiance Fields for Transparent Object Using Visual Hull
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoon%2C+H">Heechan Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seungkyu Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unlike opaque object, novel view synthesis of transparent object is a
challenging task, because transparent object refracts light of background
causing visual distortions on the transparent object surface along the
viewpoint change. Recently introduced Neural Radiance Fields (NeRF) is a view
synthesis method. Thanks to its remarkable performance improvement, lots of
following applications based on NeRF in various topics have been developed.
However, if an object with a different refractive index is included in a scene
such as transparent object, NeRF shows limited performance because refracted
light ray at the surface of the transparent object is not appropriately
considered. To resolve the problem, we propose a NeRF-based method consisting
of the following three steps: First, we reconstruct a three-dimensional shape
of a transparent object using visual hull. Second, we simulate the refraction
of the rays inside of the transparent object according to Snell's law. Last, we
sample points through refracted rays and put them into NeRF. Experimental
evaluation results demonstrate that our method addresses the limitation of
conventional NeRF with transparent objects.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08127" title="Abstract">arXiv:2312.08127</a> [<a href="/pdf/2312.08127" title="Download PDF">pdf</a>, <a href="/ps/2312.08127" title="Download PostScript">ps</a>, <a href="/format/2312.08127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random relay selection based heuristic optimization model for the  scheduling and effective resource allocation in the cognitive radio network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%2C+A">Aravindkumaran S</a>, 
<a href="/search/cs?searchtype=author&query=Saraswady%2C+D">D. Saraswady</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Cognitive Radio Network (CRN) provides effective capabilities for resource
allocation with the valuable spectrum resources in the network. It provides the
effective allocation of resources to the unlicensed users or Secondary Users
(SUs) to access the spectrum those are unused by the licensed users or Primary
Users (Pus). This paper develops an Optimal Relay Selection scheme with the
spectrum-sharing scheme in CRN. The proposed Cross-Layer Spider Swarm Shifting
is implemented in CRN for the optimal relay selection with Spider Swarm
Optimization (SSO). The shortest path is estimated with the data shifting model
for the data transmission path in the CRN. This study examines a cognitive
relay network (CRN) with interference restrictions imposed by a mobile end user
(MU). Half-duplex communication is used in the proposed system model between a
single primary user (PU) and a single secondary user (SU). Between the SU
source and SU destination, an amplify and forward (AF) relaying mechanism is
also used. While other nodes (SU Source, SU relays, and PU) are supposed to be
immobile in this scenario, the mobile end user (SU destination) is assumed to
travel at high vehicle speeds. The suggested method achieves variety by placing
a selection combiner at the SU destination and dynamically selecting the
optimal relay for transmission based on the greatest signal-to-noise (SNR)
ratio. The performance of the proposed Cross-Layer Spider Swarm Shifting model
is compared with the Spectrum Sharing Optimization with QoS Guarantee (SSO-QG).
The comparative analysis expressed that the proposed Cross-Layer Spider Swarm
Shifting model delay is reduced by 15% compared with SSO-QG. Additionally, the
proposed Cross-Layer Spider Swarm Shifting exhibits the improved network
performance of ~25% higher throughput compared with SSO-QG.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08128" title="Abstract">arXiv:2312.08128</a> [<a href="/pdf/2312.08128" title="Download PDF">pdf</a>, <a href="/format/2312.08128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clockwork Diffusion: Efficient Generation With Model-Step Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Habibian%2C+A">Amirhossein Habibian</a>, 
<a href="/search/cs?searchtype=author&query=Ghodrati%2C+A">Amir Ghodrati</a>, 
<a href="/search/cs?searchtype=author&query=Fathima%2C+N">Noor Fathima</a>, 
<a href="/search/cs?searchtype=author&query=Sautiere%2C+G">Guillaume Sautiere</a>, 
<a href="/search/cs?searchtype=author&query=Garrepalli%2C+R">Risheek Garrepalli</a>, 
<a href="/search/cs?searchtype=author&query=Porikli%2C+F">Fatih Porikli</a>, 
<a href="/search/cs?searchtype=author&query=Petersen%2C+J">Jens Petersen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This work aims to improve the efficiency of text-to-image diffusion models.
While diffusion models use computationally expensive UNet-based denoising
operations in every generation step, we identify that not all operations are
equally relevant for the final output quality. In particular, we observe that
UNet layers operating on high-res feature maps are relatively sensitive to
small perturbations. In contrast, low-res feature maps influence the semantic
layout of the final image and can often be perturbed with no noticeable change
in the output. Based on this observation, we propose Clockwork Diffusion, a
method that periodically reuses computation from preceding denoising steps to
approximate low-res feature maps at one or more subsequent steps. For multiple
baselines, and for both text-to-image generation and image editing, we
demonstrate that Clockwork leads to comparable or improved perceptual scores
with drastically reduced computational complexity. As an example, for Stable
Diffusion v1.5 with 8 DPM++ steps we save 32% of FLOPs with negligible FID and
CLIP change.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08130" title="Abstract">arXiv:2312.08130</a> [<a href="/pdf/2312.08130" title="Download PDF">pdf</a>, <a href="/format/2312.08130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reservoir Computing with Colloidal Mixtures of ZnO and Proteinoids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fortulan%2C+R">Raphael Fortulan</a>, 
<a href="/search/cs?searchtype=author&query=Kheirabadi%2C+N+R">Noushin Raeisi Kheirabadi</a>, 
<a href="/search/cs?searchtype=author&query=Mougkogiannis%2C+P">Panagiotis Mougkogiannis</a>, 
<a href="/search/cs?searchtype=author&query=Chiolerio%2C+A">Alessandro Chiolerio</a>, 
<a href="/search/cs?searchtype=author&query=Adamatzky%2C+A">Andrew Adamatzky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
<p class="mathjax">Liquid computers use incompressible fluids for computational processes. Here
we present experimental laboratory prototypes of liquid computers using
colloids composed of zinc oxide (ZnO) nanoparticles and microspheres containing
thermal proteins (proteinoids). The choice of proteinoids is based on their
distinctive neuron-like electrical behaviour and their similarity to
protocells. In addition, ZnO nanoparticles are chosen for their non-trivial
electrical properties. Our research demonstrates the successful extraction of
2-, 4- and 8-bit logic functions in ZnO proteinoid colloids. Our analysis shows
that each material has a distinct set of logic functions, and that the
complexity of the expressions is directly related to each material present in a
mixture. These findings provide a basis for the development of future hybris
liquid devices capable of general purpose computing.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08134" title="Abstract">arXiv:2312.08134</a> [<a href="/pdf/2312.08134" title="Download PDF">pdf</a>, <a href="/format/2312.08134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MToP: A MATLAB Optimization Platform for Evolutionary Multitasking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanchi Li</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+W">Wenyin Gong</a>, 
<a href="/search/cs?searchtype=author&query=Ming%2C+F">Fei Ming</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tingyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuijia Li</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Qiong Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Evolutionary multitasking (EMT) has been attracting much attention over the
past years. It aims to handle multiple optimization tasks simultaneously within
limited computing resources assisted by inter-task knowledge transfer
techniques. Numerous multitask evolutionary algorithms (MTEAs) for solving
multitask optimization (MTO) problems have been proposed in the EMT field, but
there lacks a comprehensive software platform to help researchers evaluate MTEA
performance on benchmark MTO problems as well as explore real-world
applications. To address this issue, we introduce the first open-source
optimization platform, named MTO-Platform (MToP), for EMT. It incorporates more
than 30 MTEAs, more than 150 MTO problem cases with real-world applications,
and more than 10 performance metrics. Moreover, for comparing MTEAs with
traditional evolutionary algorithms, we modified more than 30 popular
single-task evolutionary algorithms to be able to solve MTO problems in MToP.
MToP is a user-friendly tool with a graphical user interface that makes it easy
to analyze results, export data, and plot schematics. More importantly, MToP is
extensible, allowing users to develop new algorithms and define new problems.
The source code of MToP is available at https://github.com/intLyc/MTO-Platform.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08136" title="Abstract">arXiv:2312.08136</a> [<a href="/pdf/2312.08136" title="Download PDF">pdf</a>, <a href="/format/2312.08136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProNeRF: Learning Efficient Projection-Aware Ray Sampling for  Fine-Grained Implicit Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bello%2C+J+L+G">Juan Luis Gonzalez Bello</a>, 
<a href="/search/cs?searchtype=author&query=Bui%2C+M+V">Minh-Quan Viet Bui</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Munchurl Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Visit our project website at <a href="https://kaist-viclab.github.io/pronerf-site/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Recent advances in neural rendering have shown that, albeit slow, implicit
compact models can learn a scene's geometries and view-dependent appearances
from multiple views. To maintain such a small memory footprint but achieve
faster inference times, recent works have adopted `sampler' networks that
adaptively sample a small subset of points along each ray in the implicit
neural radiance fields. Although these methods achieve up to a 10$\times$
reduction in rendering time, they still suffer from considerable quality
degradation compared to the vanilla NeRF. In contrast, we propose ProNeRF,
which provides an optimal trade-off between memory footprint (similar to NeRF),
speed (faster than HyperReel), and quality (better than K-Planes). ProNeRF is
equipped with a novel projection-aware sampling (PAS) network together with a
new training strategy for ray exploration and exploitation, allowing for
efficient fine-grained particle sampling. Our ProNeRF yields state-of-the-art
metrics, being 15-23x faster with 0.65dB higher PSNR than NeRF and yielding
0.95dB higher PSNR than the best published sampler-based method, HyperReel. Our
exploration and exploitation training strategy allows ProNeRF to learn the full
scenes' color and density distributions while also learning efficient ray
sampling focused on the highest-density regions. We provide extensive
experimental results that support the effectiveness of our method on the widely
adopted forward-facing and 360 datasets, LLFF and Blender, respectively.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08138" title="Abstract">arXiv:2312.08138</a> [<a href="/pdf/2312.08138" title="Download PDF">pdf</a>, <a href="/ps/2312.08138" title="Download PostScript">ps</a>, <a href="/format/2312.08138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proceedings of the Sixth International Conference on Applied Category  Theory 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Staton%2C+S">Sam Staton</a> (University of Oxford), 
<a href="/search/cs?searchtype=author&query=Vasilakopoulou%2C+C">Christina Vasilakopoulou</a> (National Technical University of Athens)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 397, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">The Sixth International Conference on Applied Category Theory took place at
the University of Maryland, 31 July -- 4 August 2023. This conference follows
the previous meetings at Leiden (2018), Oxford (2019), MIT (2020, fully
online), Cambridge (2021) and Glasgow (2022). The conference comprised
contributed talks, a poster session, an industry showcase session, and a
session where junior researchers who had attended the Adjoint School presented
the results of their research at the school. Information regarding the
conference may be found at (https://act2023.github.io/). The contributions to
ACT2023 ranged from pure to applied and included contributions in a wide range
of disciplines in science and engineering. Submission to ACT 2023 had three
tracks: extended abstracts, software demonstrations, and proceedings. Only
papers submitted to the proceedings track were considered for publication in
this volume.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08140" title="Abstract">arXiv:2312.08140</a> [<a href="/pdf/2312.08140" title="Download PDF">pdf</a>, <a href="/format/2312.08140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GVE-LPA: Fast Label Propagation Algorithm (LPA) for Community Detection  in Shared Memory Setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sahu%2C+S">Subhajit Sahu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures, 1 table. arXiv admin note: text overlap with <a href="/abs/2312.04876">arXiv:2312.04876</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
<p class="mathjax">Community detection is the problem of identifying natural divisions in
networks. Efficient parallel algorithms for this purpose are crucial in various
applications, particularly as datasets grow to substantial scales. This
technical report presents an optimized parallel implementation of the Label
Propagation Algorithm (LPA), a high speed community detection method, for
shared memory multicore systems. On a server equipped with dual 16-core Intel
Xeon Gold 6226R processors, our LPA, which we term as GVE-LPA, outperforms
FLPA, igraph LPA, and NetworKit LPA by 97,000x, 118, 000x, and 40x respectively
- achieving a processing rate of 1.4B edges/s on a 3.8B edge graph. In
addition, GVE-LPA scales at a rate of 1.7x every doubling of threads.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08143" title="Abstract">arXiv:2312.08143</a> [<a href="/pdf/2312.08143" title="Download PDF">pdf</a>, <a href="/format/2312.08143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Representation of the Activation Space in Deep Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akumu%2C+T">Tanya Akumu</a>, 
<a href="/search/cs?searchtype=author&query=Cintas%2C+C">Celia Cintas</a>, 
<a href="/search/cs?searchtype=author&query=Tadesse%2C+G+A">Girmaw Abebe Tadesse</a>, 
<a href="/search/cs?searchtype=author&query=Oshingbesan%2C+A">Adebayo Oshingbesan</a>, 
<a href="/search/cs?searchtype=author&query=Speakman%2C+S">Skyler Speakman</a>, 
<a href="/search/cs?searchtype=author&query=McFowland%2C+E">Edward McFowland III</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The representations of the activation space of deep neural networks (DNNs)
are widely utilized for tasks like natural language processing, anomaly
detection and speech recognition. Due to the diverse nature of these tasks and
the large size of DNNs, an efficient and task-independent representation of
activations becomes crucial. Empirical p-values have been used to quantify the
relative strength of an observed node activation compared to activations
created by already-known inputs. Nonetheless, keeping raw data for these
calculations increases memory resource consumption and raises privacy concerns.
To this end, we propose a model-agnostic framework for creating representations
of activations in DNNs using node-specific histograms to compute p-values of
observed activations without retaining already-known inputs. Our proposed
approach demonstrates promising potential when validated with multiple network
architectures across various downstream tasks and compared with the kernel
density estimates and brute-force empirical baselines. In addition, the
framework reduces memory usage by 30% with up to 4 times faster p-value
computing time while maintaining state of-the-art detection power in downstream
tasks such as the detection of adversarial attacks and synthesized content.
Moreover, as we do not persist raw data at inference time, we could potentially
reduce susceptibility to attacks and privacy issues.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08146" title="Abstract">arXiv:2312.08146</a> [<a href="/pdf/2312.08146" title="Download PDF">pdf</a>, <a href="/format/2312.08146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-accuracy Vision-Based Attitude Estimation System for Air-Bearing  Spacecraft Simulators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ornati%2C+F">Fabio Ornati</a>, 
<a href="/search/cs?searchtype=author&query=Di+Domenico%2C+G">Gianfranco Di Domenico</a>, 
<a href="/search/cs?searchtype=author&query=Panicucci%2C+P">Paolo Panicucci</a>, 
<a href="/search/cs?searchtype=author&query=Topputo%2C+F">Francesco Topputo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Air-bearing platforms for simulating the rotational dynamics of satellites
require highly precise ground truth systems. Unfortunately, commercial motion
capture systems used for this scope are complex and expensive. This paper shows
a novel and versatile method to compute the attitude of rotational air-bearing
platforms using a monocular camera and sets of fiducial markers. The work
proposes a geometry-based iterative algorithm that is significantly more
accurate than other literature methods that involve the solution of the
Perspective-n-Point problem. Additionally, auto-calibration procedures to
perform a preliminary estimation of the system parameters are shown. The
developed methodology is deployed onto a Raspberry Pi 4 micro-computer and
tested with a set of LED markers. Data obtained with this setup are compared
against computer simulations of the same system to understand and validate the
attitude estimation performances. Simulation results show expected 1-sigma
accuracies in the order of $\sim$ 12 arcsec and $\sim$ 37 arcsec for about- and
cross-boresight rotations of the platform, and average latency times of 6 ms.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08150" title="Abstract">arXiv:2312.08150</a> [<a href="/pdf/2312.08150" title="Download PDF">pdf</a>, <a href="/format/2312.08150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active learning with biased non-response to label requests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Robinson%2C+T">Thomas Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Tax%2C+N">Niek Tax</a>, 
<a href="/search/cs?searchtype=author&query=Mudd%2C+R">Richard Mudd</a>, 
<a href="/search/cs?searchtype=author&query=Guy%2C+I">Ido Guy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">Active learning can improve the efficiency of training prediction models by
identifying the most informative new labels to acquire. However, non-response
to label requests can impact active learning's effectiveness in real-world
contexts. We conceptualise this degradation by considering the type of
non-response present in the data, demonstrating that biased non-response is
particularly detrimental to model performance. We argue that this sort of
non-response is particularly likely in contexts where the labelling process, by
nature, relies on user interactions. To mitigate the impact of biased
non-response, we propose a cost-based correction to the sampling strategy--the
Upper Confidence Bound of the Expected Utility (UCB-EU)--that can, plausibly,
be applied to any active learning algorithm. Through experiments, we
demonstrate that our method successfully reduces the harm from labelling
non-response in many settings. However, we also characterise settings where the
non-response bias in the annotations remains detrimental under UCB-EU for
particular sampling methods and data generating processes. Finally, we evaluate
our method on a real-world dataset from e-commerce platform Taobao. We show
that UCB-EU yields substantial performance improvements to conversion models
that are trained on clicked impressions. Most generally, this research serves
to both better conceptualise the interplay between types of non-response and
model improvements via active learning, and to provide a practical, easy to
implement correction that helps mitigate model degradation.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08156" title="Abstract">arXiv:2312.08156</a> [<a href="/pdf/2312.08156" title="Download PDF">pdf</a>, <a href="/format/2312.08156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Okapi: A Lightweight Architecture for Secure Speculation Exploiting  Locality of Memory Accesses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schmitz%2C+P">Philipp Schmitz</a>, 
<a href="/search/cs?searchtype=author&query=Jauch%2C+T">Tobias Jauch</a>, 
<a href="/search/cs?searchtype=author&query=Wezel%2C+A">Alex Wezel</a>, 
<a href="/search/cs?searchtype=author&query=Fadiheh%2C+M+R">Mohammad R. Fadiheh</a>, 
<a href="/search/cs?searchtype=author&query=Tiemann%2C+T">Thore Tiemann</a>, 
<a href="/search/cs?searchtype=author&query=Heller%2C+J">Jonah Heller</a>, 
<a href="/search/cs?searchtype=author&query=Eisenbarth%2C+T">Thomas Eisenbarth</a>, 
<a href="/search/cs?searchtype=author&query=Stoffel%2C+D">Dominik Stoffel</a>, 
<a href="/search/cs?searchtype=author&query=Kunz%2C+W">Wolfgang Kunz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">This paper introduces Okapi, an innovative hardware/software cross-layer
architecture designed to mitigate Transient Execution Side Channel (TES)
attacks, including Spectre variants, in modern computing systems. A key
contribution of Okapi is a set of security features building upon each other to
offer various trade-offs between performance and security. At its core, Okapi
allows for speculative data accesses if the targeted memory region has already
been accessed non-speculatively before in the same trust domain. It delays
first-time accesses until the speculation is resolved.
<br />Okapi stands out for its flexibility in security implementation. For
environments with less stringent security needs, Okapi's features can be
deactivated to eliminate performance overhead. When activated, the hardware
modifications alone provide robust protection against transient execution
attacks at a thread-level granularity, including all universal read gadgets
like Spectre-PHT and Spectre-BTB. This incurs an average performance overhead
of only 3.6 % for the SPEC CPU2017 benchmark suite.
<br />On top, Okapi introduces the OkapiReset instruction for additional
software-level security support. This instruction, which can be manually
inserted by developers or automatically via a compiler extension, allows for
fully secure speculation and for trust domain sizes smaller than a thread.
While the manual insertion of OkapiReset incurs an additional 0.6 % performance
overhead, the automated compiler extension approach results in a 23.1 %
overhead for making a cryptographic library fully secure. With an approximate
0.4 % hardware overhead, Okapi provides a highly scalable and adaptable
solution for secure speculation in state-of-the-art processor design.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08157" title="Abstract">arXiv:2312.08157</a> [<a href="/pdf/2312.08157" title="Download PDF">pdf</a>, <a href="/format/2312.08157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CIDR: A Cooperative Integrated Dynamic Refining Method for Minimal  Feature Removal Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Taolin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongyang Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaofeng He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The minimal feature removal problem in the post-hoc explanation area aims to
identify the minimal feature set (MFS). Prior studies using the greedy
algorithm to calculate the minimal feature set lack the exploration of feature
interactions under a monotonic assumption which cannot be satisfied in general
scenarios. In order to address the above limitations, we propose a Cooperative
Integrated Dynamic Refining method (CIDR) to efficiently discover minimal
feature sets. Specifically, we design Cooperative Integrated Gradients (CIG) to
detect interactions between features. By incorporating CIG and characteristics
of the minimal feature set, we transform the minimal feature removal problem
into a knapsack problem. Additionally, we devise an auxiliary Minimal Feature
Refinement algorithm to determine the minimal feature set from numerous
candidate sets. To the best of our knowledge, our work is the first to address
the minimal feature removal problem in the field of natural language
processing. Extensive experiments demonstrate that CIDR is capable of tracing
representative minimal feature sets with improved interpretability across
various models and datasets.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08158" title="Abstract">arXiv:2312.08158</a> [<a href="/pdf/2312.08158" title="Download PDF">pdf</a>, <a href="/format/2312.08158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Quantum Learning with co-Management in a Multi-tenant  Quantum System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%27Onofrio%2C+A">Anthony D&#x27;Onofrio Jr.</a>, 
<a href="/search/cs?searchtype=author&query=Hossain%2C+A">Amir Hossain</a>, 
<a href="/search/cs?searchtype=author&query=Santana%2C+L">Lesther Santana</a>, 
<a href="/search/cs?searchtype=author&query=Machlovi%2C+N">Naseem Machlovi</a>, 
<a href="/search/cs?searchtype=author&query=Stein%2C+S">Samuel Stein</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Ang Li</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Ying Mao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE BigData 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The rapid advancement of quantum computing has pushed classical designs into
the quantum domain, breaking physical boundaries for computing-intensive and
data-hungry applications. Given its immense potential, quantum-based computing
systems have attracted increasing attention with the hope that some systems may
provide a quantum speedup. For example, variational quantum algorithms have
been proposed for quantum neural networks to train deep learning models on
qubits, achieving promising results. Existing quantum learning architectures
and systems rely on single, monolithic quantum machines with abundant and
stable resources, such as qubits. However, fabricating a large, monolithic
quantum device is considerably more challenging than producing an array of
smaller devices. In this paper, we investigate a distributed quantum system
that combines multiple quantum machines into a unified system. We propose
DQuLearn, which divides a quantum learning task into multiple subtasks. Each
subtask can be executed distributively on individual quantum machines, with the
results looping back to classical machines for subsequent training iterations.
Additionally, our system supports multiple concurrent clients and dynamically
manages their circuits according to the runtime status of quantum workers.
Through extensive experiments, we demonstrate that DQuLearn achieves similar
accuracies with significant runtime reduction, by up to 68.7% and an increase
per-second circuit processing speed, by up to 3.99 times, in a 4-worker
multi-tenant setting.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08160" title="Abstract">arXiv:2312.08160</a> [<a href="/pdf/2312.08160" title="Download PDF">pdf</a>, <a href="/ps/2312.08160" title="Download PostScript">ps</a>, <a href="/format/2312.08160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Evaluating the Security of Wearable Devices in the Internet of  Medical Things
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vaseghi%2C+Y">Yas Vaseghi</a>, 
<a href="/search/cs?searchtype=author&query=Behara%2C+B">Behnaz Behara</a>, 
<a href="/search/cs?searchtype=author&query=Delrobaei%2C+M">Mehdi Delrobaei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The work was accepted for publication at the 11th RSI International Conference on Robotics and Mechatronics (ICRoM), Tehran, Iran, Dec. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The Internet of Medical Things (IoMT) offers a promising solution to improve
patient health and reduce human error. Wearable smart infusion pumps that
accurately administer medication and integrate with electronic health records
are an example of technology that can improve healthcare. They can even alert
healthcare professionals or remote servers during operational failure,
preventing distressing incidents. However, as the number of connected medical
devices increases, the risk of cyber threats also increases. Wearable
medication devices based on IoT attached to patients' bodies are prone to
significant cyber threats. Being connected to the Internet exposes these
devices to potential harm, which could disrupt or degrade device performance
and harm patients. To ensure patient safety and well-being, it is crucial to
establish secure data authentication for internet-connected medical devices. It
is also important to note that the wearability option of such devices might
downgrade the computational resources, making them more susceptible to security
risks. This paper implements a security approach to a wearable infusion pump.
We discuss practical challenges in implementing security-enabled devices and
propose initial solutions to mitigate cyber threats.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08161" title="Abstract">arXiv:2312.08161</a> [<a href="/pdf/2312.08161" title="Download PDF">pdf</a>, <a href="/ps/2312.08161" title="Download PostScript">ps</a>, <a href="/format/2312.08161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The mentor-child paradigm for individuals with autism spectrum disorders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dubois-Sage%2C+M">Marion Dubois-Sage</a>, 
<a href="/search/cs?searchtype=author&query=Jacquet%2C+B">Baptiste Jacquet</a>, 
<a href="/search/cs?searchtype=author&query=Jamet%2C+F">Frank Jamet</a>, 
<a href="/search/cs?searchtype=author&query=Baratgin%2C+J">Jean Baratgin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Our aim is to analyze the relevance of the mentor-child paradigm with a robot
for individuals with Autism Spectrum Disorders, and the adaptations required.
This method could allow a more reliable evaluation of the socio-cognitive
abilities of individuals with autism, which may have been underestimated due to
pragmatic factors.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08162" title="Abstract">arXiv:2312.08162</a> [<a href="/pdf/2312.08162" title="Download PDF">pdf</a>, <a href="/format/2312.08162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smart Energy Management with Optimized Prosumerism for Achieving Dynamic  Net-Zero Balance in Electrified Road Transport Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ayaz%2C+F">Ferheen Ayaz</a>, 
<a href="/search/eess?searchtype=author&query=Nekovee%2C+M">Maziar Nekovee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The increasing number of Electric Vehicles (EVs) have led to rising energy
demands which aggregates the burden on grid supply. A few solutions have been
proposed to reduce grid load, for example, using storage systems for storing
surplus energy from EVs or time-scheduling supply. These solutions are costly
and limited to specific regions and times. This paper proposes a smart energy
management solution for a massively electrified road transport network. It
comprises of energy supplies from grid, charging stations, renewable sources
and EVs connected by 5G-enabled aggregators. We propose EVs as prosumers, which
are energy consumers but also supply back their surplus energy via
Vehicle-to-Grid (V2G) technology. We use machine learning to forecast hourly
energy output from renewable sources, surplus supply from EVs and their
demands. A grid cost minimization using Mixed Integer Linear Programming
solution is proposed to dynamically alter supply according to demand and energy
provision from EVs. The upper bounds of surplus supply and demand of EVs are
theoretically derived. An incentive distribution mechanism is presented to
reward EVs offering their surplus supply and to discourage them to become
selfish which is analyzed using Prisoner's dilemma game. The paper also
presents an optimum number of charging stations on a road. Simulation results
show that the proposed solution can effectively meet the demand requirements
even if the supply from grid is limited, and can averagely reduce 38.21% of
grid load. It results in 5.3% of average cost reduction compared with
optimization without prosumers. The proposed penalty charge for CO2 emissions
results in over 50% cost reduction by using renewable resources in the proposed
solution as compared to fossil fuels. The communication and computation
complexity of the proposed solution is reduced by 5G-enabled aggregator.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08168" title="Abstract">arXiv:2312.08168</a> [<a href="/pdf/2312.08168" title="Download PDF">pdf</a>, <a href="/format/2312.08168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chat-3D v2: Bridging 3D Scene and Large Language Models with Object  Identifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haifeng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zehan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Rongjie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Luping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xize Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+T">Tao Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhou Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent research has evidenced the significant potentials of Large Language
Models (LLMs) in handling challenging tasks within 3D scenes. However, current
models are constrained to addressing object-centric tasks, where each
question-answer pair focuses solely on an individual object. In real-world
applications, users may pose queries involving multiple objects or expect for
answers that precisely reference various objects. We introduce the use of
object identifiers to freely reference objects during a conversation. While
this solution appears straightforward, it presents two main challenges: 1) How
to establish a reliable one-to-one correspondence between each object and its
identifier? 2) How to incorporate complex spatial relationships among dozens of
objects into the embedding space of the LLM? To address these challenges, we
propose a two-stage alignment method, which involves learning an
attribute-aware token and a relation-aware token for each object. These tokens
capture the object's attributes and spatial relationships with surrounding
objects in the 3D scene. Once the alignment is established, we can fine-tune
our model on various downstream tasks using instruction tuning. Experiments
conducted on traditional datasets like ScanQA, ScanRefer, and Nr3D/Sr3D
showcase the effectiveness of our proposed method. Additionally, we create a 3D
scene captioning dataset annotated with rich object identifiers, with the
assistant of GPT-4. This dataset aims to further explore the capability of
object identifiers in effective object referencing and precise scene
understanding.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08176" title="Abstract">arXiv:2312.08176</a> [<a href="/pdf/2312.08176" title="Download PDF">pdf</a>, <a href="/format/2312.08176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ASC: Adaptive Scale Feature Map Compression for Deep Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+T">Tian-Sheuan Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Hardware Architecture (cs.AR); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Deep-learning accelerators are increasingly in demand; however, their
performance is constrained by the size of the feature map, leading to high
bandwidth requirements and large buffer sizes. We propose an adaptive scale
feature map compression technique leveraging the unique properties of the
feature map. This technique adopts independent channel indexing given the weak
channel correlation and utilizes a cubical-like block shape to benefit from
strong local correlations. The method further optimizes compression using a
switchable endpoint mode and adaptive scale interpolation to handle unimodal
data distributions, both with and without outliers. This results in 4$\times$
and up to 7.69$\times$ compression rates for 16-bit data in constant and
variable bitrates, respectively. Our hardware design minimizes area cost by
adjusting interpolation scales, which facilitates hardware sharing among
interpolation points. Additionally, we introduce a threshold concept for
straightforward interpolation, preventing the need for intricate hardware. The
TSMC 28nm implementation showcases an equivalent gate count of 6135 for the
8-bit version. Furthermore, the hardware architecture scales effectively, with
only a sublinear increase in area cost. Achieving a 32$\times$ throughput
increase meets the theoretical bandwidth of DDR5-6400 at just 7.65$\times$ the
hardware cost.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08177" title="Abstract">arXiv:2312.08177</a> [<a href="/pdf/2312.08177" title="Download PDF">pdf</a>, <a href="/ps/2312.08177" title="Download PostScript">ps</a>, <a href="/format/2312.08177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advanced Image Segmentation Techniques for Neural Activity Detection via  C-fos Immediate Early Gene Expression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+P">Peilin Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper investigates the application of advanced image segmentation
techniques to analyze C-fos immediate early gene expression, a crucial marker
for neural activity. Due to the complexity and high variability of neural
circuits, accurate segmentation of C-fos images is paramount for the
development of new insights into neural function. Amidst this backdrop, this
research aims to improve accuracy and minimize manual intervention in C-fos
image segmentation by leveraging the capabilities of CNNs and the Unet model.
We describe the development of a novel workflow for the segmentation process
involving Convolutional Neural Networks (CNNs) and the Unet model,
demonstrating their efficiency in various image segmentation tasks. Our
workflow incorporates pre-processing steps such as cropping, image feature
extraction, and clustering for the training dataset selection. We used an
AutoEncoder model to extract features and implement constrained clustering to
identify similarities and differences in image types. Additionally, we utilized
manual and automatic labeling approaches to enhance the performance of our
model. We demonstrated the effectiveness of our method in distinguishing areas
with significant C-fos expression from normal tissue areas. Lastly, we
implemented a modified Unet network for the detection of C-fos expressions.
This research contributes to the development of more efficient and automated
image segmentation methods, advancing the understanding of neural function in
neuroscience research.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08182" title="Abstract">arXiv:2312.08182</a> [<a href="/pdf/2312.08182" title="Download PDF">pdf</a>, <a href="/ps/2312.08182" title="Download PostScript">ps</a>, <a href="/format/2312.08182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preliminary Guidelines for Electrode Positioning in Noninvasive Deep  Brain Stimulation via Temporally Interfering Electric Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zibandepour%2C+M">Mobina Zibandepour</a>, 
<a href="/search/eess?searchtype=author&query=Shojaei%2C+A">Akram Shojaei</a>, 
<a href="/search/eess?searchtype=author&query=Larki%2C+A+A">Arash Abbasi Larki</a>, 
<a href="/search/eess?searchtype=author&query=Delrobaei%2C+M">Mehdi Delrobaei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint version of the work accepted for publication at the 11th RSI International Conference on Robotics and Mechatronics (ICRoM), Tehran, Iran, Dec. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Advancements in neurosurgical robotics have improved medical procedures,
particularly deep brain stimulation, where robots combine human and machine
intelligence to precisely implant electrodes in the brain. While effective,
this procedure carries risks and side effects. Noninvasive deep brain
stimulation (NIDBS) offers promise by making brain stimulation safer, more
affordable, and accessible. However, NIDBS lacks guidelines for electrode
placement. This study explores adapting robotic principles to enhance the
accuracy of NIDBS targeting and provides preliminary guidelines for
transcranial electrode placement. Safety is also emphasized, ensuring a balance
between therapeutic effectiveness and patient safety by maintaining electric
fields within safe limits.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08187" title="Abstract">arXiv:2312.08187</a> [<a href="/pdf/2312.08187" title="Download PDF">pdf</a>, <a href="/ps/2312.08187" title="Download PostScript">ps</a>, <a href="/format/2312.08187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Completing Priceable Committees: Utilitarian and Representation  Guarantees for Proportional Multiwinner Voting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brill%2C+M">Markus Brill</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Jannik Peters</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">When selecting committees based on preferences of voters, a variety of
different criteria can be considered. Two natural objectives are maximizing the
utilitarian welfare (the sum of voters' utilities) and coverage (the number of
represented voters) of the selected committee. Previous work has studied the
impact on utilitarian welfare and coverage when requiring the committee to
satisfy minimal requirements such as justified representation or weak
proportionality. In this paper, we consider the impact of imposing much more
demanding proportionality axioms. We identify a class of voting rules that
achieve strong guarantees on utilitarian welfare and coverage when combined
with appropriate completions. This class is defined via a weakening of
priceability and contains prominent rules such as the Method of Equal Shares.
We show that committees selected by these rules (i) can be completed to achieve
optimal coverage and (ii) can be completed to achieve an asymptotically optimal
approximation to the utilitarian welfare if they additionally satisfy EJR+.
Answering an open question of Elkind et al. (2022), we use the Greedy Justified
Candidate Rule to obtain the best possible utilitarian guarantee subject to
proportionality. We also consider completion methods suggested in the
participatory budgeting literature and other objectives besides welfare and
coverage.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08189" title="Abstract">arXiv:2312.08189</a> [<a href="/pdf/2312.08189" title="Download PDF">pdf</a>, <a href="/format/2312.08189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GuardRails: Automated Suggestions for Clarifying Ambiguous Purpose  Statements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pawagi%2C+M">Mrigank Pawagi</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Viraj Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Before implementing a function, programmers are encouraged to write a purpose
statement i.e., a short, natural-language explanation of what the function
computes. A purpose statement may be ambiguous i.e., it may fail to specify the
intended behaviour when two or more inequivalent computations are plausible on
certain inputs. Our paper makes four contributions. First, we propose a novel
heuristic that suggests such inputs using Large Language Models (LLMs). Using
these suggestions, the programmer may choose to clarify the purpose statement
(e.g., by providing a functional example that specifies the intended behaviour
on such an input). Second, to assess the quality of inputs suggested by our
heuristic, and to facilitate future research, we create an open dataset of
purpose statements with known ambiguities. Third, we compare our heuristic
against GitHub Copilot's Chat feature, which can suggest similar inputs when
prompted to generate unit tests. Fourth, we provide an open-source
implementation of our heuristic as an extension to Visual Studio Code for the
Python programming language, where purpose statements and functional examples
are specified as docstrings and doctests respectively. We believe that this
tool will be particularly helpful to novice programmers and instructors.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08192" title="Abstract">arXiv:2312.08192</a> [<a href="/pdf/2312.08192" title="Download PDF">pdf</a>, <a href="/format/2312.08192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PAD: Self-Supervised Pre-Training with Patchwise-Scale Adapter for  Infrared Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+K">Kun Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Jinyong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yu Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+S">Shiming Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+C">Chunhong Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Self-supervised learning (SSL) for RGB images has achieved significant
success, yet there is still limited research on SSL for infrared images,
primarily due to three prominent challenges: 1) the lack of a suitable
large-scale infrared pre-training dataset, 2) the distinctiveness of non-iconic
infrared images rendering common pre-training tasks like masked image modeling
(MIM) less effective, and 3) the scarcity of fine-grained textures making it
particularly challenging to learn general image features. To address these
issues, we construct a Multi-Scene Infrared Pre-training (MSIP) dataset
comprising 178,756 images, and introduce object-sensitive random RoI cropping,
an image preprocessing method, to tackle the challenge posed by non-iconic
images. To alleviate the impact of weak textures on feature learning, we
propose a pre-training paradigm called Pre-training with ADapter (PAD), which
uses adapters to learn domain-specific features while freezing parameters
pre-trained on ImageNet to retain the general feature extraction capability.
This new paradigm is applicable to any transformer-based SSL method.
Furthermore, to achieve more flexible coordination between pre-trained and
newly-learned features in different layers and patches, a patchwise-scale
adapter with dynamically learnable scale factors is introduced. Extensive
experiments on three downstream tasks show that PAD, with only 1.23M
pre-trainable parameters, outperforms other baseline paradigms including
continual full pre-training on MSIP. Our code and dataset are available at
https://github.com/casiatao/PAD.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08194" title="Abstract">arXiv:2312.08194</a> [<a href="/pdf/2312.08194" title="Download PDF">pdf</a>, <a href="/format/2312.08194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SVInvNet: A Densely Connected Encoder-Decoder Architecture for Seismic  Velocity Inversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khatounabad%2C+M+N">Mojtaba Najafi Khatounabad</a>, 
<a href="/search/cs?searchtype=author&query=Keles%2C+H+Y">Hacer Yalim Keles</a>, 
<a href="/search/cs?searchtype=author&query=Kadioglu%2C+S">Selma Kadioglu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 11 figures, submitted to IEEE Transactions on Geoscience and Remote Sensing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Geophysics (physics.geo-ph)

</div>
<p class="mathjax">This study presents a deep learning-based approach to seismic velocity
inversion problem, focusing on both noisy and noiseless training datasets of
varying sizes. Our Seismic Velocity Inversion Network (SVInvNet) introduces a
novel architecture that contains a multi-connection encoder-decoder structure
enhanced with dense blocks. This design is specifically tuned to effectively
process complex information, crucial for addressing the challenges of
non-linear seismic velocity inversion. For training and testing, we created
diverse seismic velocity models, including multi-layered, faulty, and salt dome
categories. We also investigated how different kinds of ambient noise, both
coherent and stochastic, and the size of the training dataset affect learning
outcomes. SVInvNet is trained on datasets ranging from 750 to 6,000 samples and
is tested using a large benchmark dataset of 12,000 samples. Despite its fewer
parameters compared to the baseline, SVInvNet achieves superior performance
with this dataset. The outcomes of the SVInvNet are additionally compared to
those of the Full Waveform Inversion (FWI) method. The comparative analysis
clearly reveals the effectiveness of the proposed model.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08195" title="Abstract">arXiv:2312.08195</a> [<a href="/pdf/2312.08195" title="Download PDF">pdf</a>, <a href="/format/2312.08195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concept-centric Personalization with Large-scale Diffusion Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+P">Pu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Feng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tianrui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Q">Qing Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
<p class="mathjax">Despite large-scale diffusion models being highly capable of generating
diverse open-world content, they still struggle to match the photorealism and
fidelity of concept-specific generators. In this work, we present the task of
customizing large-scale diffusion priors for specific concepts as
concept-centric personalization. Our goal is to generate high-quality
concept-centric images while maintaining the versatile controllability inherent
to open-world models, enabling applications in diverse tasks such as
concept-centric stylization and image translation. To tackle these challenges,
we identify catastrophic forgetting of guidance prediction from diffusion
priors as the fundamental issue. Consequently, we develop a guidance-decoupled
personalization framework specifically designed to address this task. We
propose Generalized Classifier-free Guidance (GCFG) as the foundational theory
for our framework. This approach extends Classifier-free Guidance (CFG) to
accommodate an arbitrary number of guidances, sourced from a variety of
conditions and models. Employing GCFG enables us to separate conditional
guidance into two distinct components: concept guidance for fidelity and
control guidance for controllability. This division makes it feasible to train
a specialized model for concept guidance, while ensuring both control and
unconditional guidance remain intact. We then present a null-text
Concept-centric Diffusion Model as a concept-specific generator to learn
concept guidance without the need for text annotations. Code will be available
at https://github.com/PRIV-Creation/Concept-centric-Personalization.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08198" title="Abstract">arXiv:2312.08198</a> [<a href="/pdf/2312.08198" title="Download PDF">pdf</a>, <a href="/format/2312.08198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Model-Based Data Acquisition for Subjective Multi-Task NLP  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kanclerz%2C+K">Kamil Kanclerz</a>, 
<a href="/search/cs?searchtype=author&query=Bielaniewicz%2C+J">Julita Bielaniewicz</a>, 
<a href="/search/cs?searchtype=author&query=Gruza%2C+M">Marcin Gruza</a>, 
<a href="/search/cs?searchtype=author&query=Kocon%2C+J">Jan Kocon</a>, 
<a href="/search/cs?searchtype=author&query=Wo%C5%BAniak%2C+S">Stanis&#x142;aw Wo&#x17a;niak</a>, 
<a href="/search/cs?searchtype=author&query=Kazienko%2C+P">Przemys&#x142;aw Kazienko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Data annotated by humans is a source of knowledge by describing the
peculiarities of the problem and therefore fueling the decision process of the
trained model. Unfortunately, the annotation process for subjective natural
language processing (NLP) problems like offensiveness or emotion detection is
often very expensive and time-consuming. One of the inevitable risks is to
spend some of the funds and annotator effort on annotations that do not provide
any additional knowledge about the specific task. To minimize these costs, we
propose a new model-based approach that allows the selection of tasks annotated
individually for each text in a multi-task scenario. The experiments carried
out on three datasets, dozens of NLP tasks, and thousands of annotations show
that our method allows up to 40% reduction in the number of annotations with
negligible loss of knowledge. The results also emphasize the need to collect a
diverse amount of data required to efficiently train a model, depending on the
subjectivity of the annotation task. We also focused on measuring the relation
between subjective tasks by evaluating the model in single-task and multi-task
scenarios. Moreover, for some datasets, training only on the labels predicted
by our model improved the efficiency of task selection as a self-supervised
learning regularization technique.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08200" title="Abstract">arXiv:2312.08200</a> [<a href="/pdf/2312.08200" title="Download PDF">pdf</a>, <a href="/format/2312.08200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPD-DDPM: Denoising Diffusion Probabilistic Models in the Symmetric  Positive Definite Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunchen Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhou Yu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+G">Gaoqi He</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yunhang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Ke Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shaohui Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Symmetric positive definite~(SPD) matrices have shown important value and
applications in statistics and machine learning, such as FMRI analysis and
traffic prediction. Previous works on SPD matrices mostly focus on
discriminative models, where predictions are made directly on $E(X|y)$, where
$y$ is a vector and $X$ is an SPD matrix. However, these methods are
challenging to handle for large-scale data, as they need to access and process
the whole data. In this paper, inspired by denoising diffusion probabilistic
model~(DDPM), we propose a novel generative model, termed SPD-DDPM, by
introducing Gaussian distribution in the SPD space to estimate $E(X|y)$.
Moreover, our model is able to estimate $p(X)$ unconditionally and flexibly
without giving $y$. On the one hand, the model conditionally learns $p(X|y)$
and utilizes the mean of samples to obtain $E(X|y)$ as a prediction. On the
other hand, the model unconditionally learns the probability distribution of
the data $p(X)$ and generates samples that conform to this distribution.
Furthermore, we propose a new SPD net which is much deeper than the previous
networks and allows for the inclusion of conditional factors. Experiment
results on toy data and real taxi data demonstrate that our models effectively
fit the data distribution both unconditionally and unconditionally and provide
accurate predictions.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08201" title="Abstract">arXiv:2312.08201</a> [<a href="/pdf/2312.08201" title="Download PDF">pdf</a>, <a href="/format/2312.08201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient solution of sequences of parametrized Lyapunov equations with  applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Palitta%2C+D">Davide Palitta</a>, 
<a href="/search/math?searchtype=author&query=Tomljanovi%C4%87%2C+Z">Zoran Tomljanovi&#x107;</a>, 
<a href="/search/math?searchtype=author&query=Naki%C4%87%2C+I">Ivica Naki&#x107;</a>, 
<a href="/search/math?searchtype=author&query=Saak%2C+J">Jens Saak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Sequences of parametrized Lyapunov equations can be encountered in many
application settings. Moreover, solutions of such equations are often
intermediate steps of an overall procedure whose main goal is the computation
of quantities of the form $f(X)$ where $X$ denotes the solution of a Lyapunov
equation. We are interested in addressing problems where the parameter
dependency of the coefficient matrix is encoded as a low-rank modification to a
\emph{seed}, fixed matrix. We propose two novel numerical procedures that fully
exploit such a common structure. The first one builds upon recycling Krylov
techniques, and it is well-suited for small dimensional problems as it makes
use of dense numerical linear algebra tools. The second algorithm can instead
address large-scale problems by relying on state-of-the-art projection
techniques based on the extended Krylov subspace. We test the new algorithms on
several problems arising in the study of damped vibrational systems and the
analyses of output synchronization problems for multi-agent systems. Our
results show that the algorithms we propose are superior to state-of-the-art
techniques as they are able to remarkably speed up the computation of accurate
solutions.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08207" title="Abstract">arXiv:2312.08207</a> [<a href="/pdf/2312.08207" title="Download PDF">pdf</a>, <a href="/format/2312.08207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Black-box Membership Inference Attacks against Fine-tuned Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pang%2C+Y">Yan Pang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianhao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">With the rapid advancement of diffusion-based image-generative models, the
quality of generated images has become increasingly photorealistic. Moreover,
with the release of high-quality pre-trained image-generative models, a growing
number of users are downloading these pre-trained models to fine-tune them with
downstream datasets for various image-generation tasks. However, employing such
powerful pre-trained models in downstream tasks presents significant privacy
leakage risks. In this paper, we propose the first reconstruction-based
membership inference attack framework, tailored for recent diffusion models,
and in the more stringent black-box access setting. Considering four distinct
attack scenarios and three types of attacks, this framework is capable of
targeting any popular conditional generator model, achieving high precision,
evidenced by an impressive AUC of $0.95$.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08212" title="Abstract">arXiv:2312.08212</a> [<a href="/pdf/2312.08212" title="Download PDF">pdf</a>, <a href="/format/2312.08212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LAMM: Label Alignment for Multi-Modal Prompt Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jingsheng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+J">Jiacheng Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+S">Suncheng Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zefang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+K">Ke Ji</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+M">Mingye Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yuzhuo Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024 Main Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the success of pre-trained visual-language (VL) models such as CLIP in
visual representation tasks, transferring pre-trained models to downstream
tasks has become a crucial paradigm. Recently, the prompt tuning paradigm,
which draws inspiration from natural language processing (NLP), has made
significant progress in VL field. However, preceding methods mainly focus on
constructing prompt templates for text and visual inputs, neglecting the gap in
class label representations between the VL models and downstream tasks. To
address this challenge, we introduce an innovative label alignment method named
\textbf{LAMM}, which can dynamically adjust the category embeddings of
downstream datasets through end-to-end training. Moreover, to achieve a more
appropriate label distribution, we propose a hierarchical loss, encompassing
the alignment of the parameter space, feature space, and logits space. We
conduct experiments on 11 downstream vision datasets and demonstrate that our
method significantly improves the performance of existing multi-modal prompt
learning models in few-shot scenarios, exhibiting an average accuracy
improvement of 2.31(\%) compared to the state-of-the-art methods on 16 shots.
Moreover, our methodology exhibits the preeminence in continual learning
compared to other prompt tuning methods. Importantly, our method is synergistic
with existing prompt tuning methods and can boost the performance on top of
them. Our code and dataset will be publicly available at
https://github.com/gaojingsheng/LAMM.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08213" title="Abstract">arXiv:2312.08213</a> [<a href="/pdf/2312.08213" title="Download PDF">pdf</a>, <a href="/format/2312.08213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerated Event-Based Feature Detection and Compression for  Surveillance Video Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Freeman%2C+A+C">Andrew C. Freeman</a>, 
<a href="/search/cs?searchtype=author&query=Mayer-Patel%2C+K">Ketan Mayer-Patel</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+M">Montek Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The strong temporal consistency of surveillance video enables compelling
compression performance with traditional methods, but downstream vision
applications operate on decoded image frames with a high data rate. Since it is
not straightforward for applications to extract information on temporal
redundancy from the compressed video representations, we propose a novel system
which conveys temporal redundancy within a sparse decompressed representation.
We leverage a video representation framework called ADDER to transcode framed
videos to sparse, asynchronous intensity samples. We introduce mechanisms for
content adaptation, lossy compression, and asynchronous forms of classical
vision algorithms. We evaluate our system on the VIRAT surveillance video
dataset, and we show a median 43.7% speed improvement in FAST feature detection
compared to OpenCV. We run the same algorithm as OpenCV, but only process
pixels that receive new asynchronous events, rather than process every pixel in
an image frame. Our work paves the way for upcoming neuromorphic sensors and is
amenable to future applications with spiking neural networks.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08214" title="Abstract">arXiv:2312.08214</a> [<a href="/pdf/2312.08214" title="Download PDF">pdf</a>, <a href="/format/2312.08214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Precoding for ORIS-Assisted MIMO Multi-User VLC System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atashbar%2C+M">Mahmoud Atashbar</a>, 
<a href="/search/cs?searchtype=author&query=Ghazijahani%2C+H+A">Hamed Alizadeh Ghazijahani</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Y+L">Yong Liang Guan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhaojie Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we study a multi-user visible light communication (VLC) system
assisted with optical reflecting intelligent surface (ORIS). Joint precoding
and alignment matrices are designed to maximize the average
signal-to-interference plus noise ratio (SINR) criteria. Considering the
constraints of the constant mean transmission power of LEDs and the power
associated with all users, an optimization problem is proposed. To solve this
problem, we utilize an alternating optimization algorithm to optimize the
precoding and alignment matrices. The simulation results demonstrate that the
resultant SINR of the proposed method outperforms ZF and MMSE precoding
algorithms.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08220" title="Abstract">arXiv:2312.08220</a> [<a href="/pdf/2312.08220" title="Download PDF">pdf</a>, <a href="/format/2312.08220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EventAid: Benchmarking Event-aided Image/Video Enhancement Algorithms  with Real-captured Hybrid Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+P">Peiqi Duan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yixin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+H">Hanyue Lou</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+M">Minggui Teng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Boxin Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Event cameras are emerging imaging technology that offers advantages over
conventional frame-based imaging sensors in dynamic range and sensing speed.
Complementing the rich texture and color perception of traditional image
frames, the hybrid camera system of event and frame-based cameras enables
high-performance imaging. With the assistance of event cameras, high-quality
image/video enhancement methods make it possible to break the limits of
traditional frame-based cameras, especially exposure time, resolution, dynamic
range, and frame rate limits. This paper focuses on five event-aided image and
video enhancement tasks (i.e., event-based video reconstruction, event-aided
high frame rate video reconstruction, image deblurring, image super-resolution,
and high dynamic range image reconstruction), provides an analysis of the
effects of different event properties, a real-captured and ground truth labeled
benchmark dataset, a unified benchmarking of state-of-the-art methods, and an
evaluation for two mainstream event simulators. In detail, this paper collects
a real-captured evaluation dataset EventAid for five event-aided image/video
enhancement tasks, by using "Event-RGB" multi-camera hybrid system, taking into
account scene diversity and spatiotemporal synchronization. We further perform
quantitative and visual comparisons for state-of-the-art algorithms, provide a
controlled experiment to analyze the performance limit of event-aided image
deblurring methods, and discuss open problems to inspire future research.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08221" title="Abstract">arXiv:2312.08221</a> [<a href="/pdf/2312.08221" title="Download PDF">pdf</a>, <a href="/format/2312.08221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curriculum-Enhanced Residual Soft An-Isotropic Normalization for  Over-smoothness in Deep GNNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qirong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shuling Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinlong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Longkun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yang-Geng Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite Graph neural networks' significant performance gain over many classic
techniques in various graph-related downstream tasks, their successes are
restricted in shallow models due to over-smoothness and the difficulties of
optimizations among many other issues. In this paper, to alleviate the
over-smoothing issue, we propose a soft graph normalization method to preserve
the diversities of node embeddings and prevent indiscrimination due to possible
over-closeness. Combined with residual connections, we analyze the reason why
the method can effectively capture the knowledge in both input graph structures
and node features even with deep networks. Additionally, inspired by Curriculum
Learning that learns easy examples before the hard ones, we propose a novel
label-smoothing-based learning framework to enhance the optimization of deep
GNNs, which iteratively smooths labels in an auxiliary graph and constructs
many gradual non-smooth tasks for extracting increasingly complex knowledge and
gradually discriminating nodes from coarse to fine. The method arguably reduces
the risk of overfitting and generalizes better results. Finally, extensive
experiments are carried out to demonstrate the effectiveness and potential of
the proposed model and learning framework through comparison with twelve
existing baselines including the state-of-the-art methods on twelve real-world
node classification benchmarks.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08223" title="Abstract">arXiv:2312.08223</a> [<a href="/pdf/2312.08223" title="Download PDF">pdf</a>, <a href="/format/2312.08223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Patch-wise Graph Contrastive Learning for Image Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jung%2C+C">Chanyong Jung</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+G">Gihyun Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J+C">Jong Chul Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, patch-wise contrastive learning is drawing attention for the image
translation by exploring the semantic correspondence between the input and
output images. To further explore the patch-wise topology for high-level
semantic understanding, here we exploit the graph neural network to capture the
topology-aware features. Specifically, we construct the graph based on the
patch-wise similarity from a pretrained encoder, whose adjacency matrix is
shared to enhance the consistency of patch-wise relation between the input and
the output. Then, we obtain the node feature from the graph neural network, and
enhance the correspondence between the nodes by increasing mutual information
using the contrastive loss. In order to capture the hierarchical semantic
structure, we further propose the graph pooling. Experimental results
demonstrate the state-of-art results for the image translation thanks to the
semantic encoding by the constructed graphs.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08224" title="Abstract">arXiv:2312.08224</a> [<a href="/pdf/2312.08224" title="Download PDF">pdf</a>, <a href="/format/2312.08224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GLOP: Learning Global Partition and Local Construction for Solving  Large-scale Routing Problems in Real-time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Haoran Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiarui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+H">Helan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhiguang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fanzhang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The recent end-to-end neural solvers have shown promise for small-scale
routing problems but suffered from limited real-time scaling-up performance.
This paper proposes GLOP (Global and Local Optimization Policies), a unified
hierarchical framework that efficiently scales toward large-scale routing
problems. GLOP partitions large routing problems into Travelling Salesman
Problems (TSPs) and TSPs into Shortest Hamiltonian Path Problems. For the first
time, we hybridize non-autoregressive neural heuristics for coarse-grained
problem partitions and autoregressive neural heuristics for fine-grained route
constructions, leveraging the scalability of the former and the meticulousness
of the latter. Experimental results show that GLOP achieves competitive and
state-of-the-art real-time performance on large-scale routing problems,
including TSP, ATSP, CVRP, and PCTSP.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08230" title="Abstract">arXiv:2312.08230</a> [<a href="/pdf/2312.08230" title="Download PDF">pdf</a>, <a href="/format/2312.08230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Partial Symmetry Detection for 3D Geometry using Contrastive Learning  with Geodesic Point Cloud Patches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kobsik%2C+G">Gregor Kobsik</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+I">Isaak Lim</a>, 
<a href="/search/cs?searchtype=author&query=Kobbelt%2C+L">Leif Kobbelt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Symmetry detection, especially partial and extrinsic symmetry, is essential
for various downstream tasks, like 3D geometry completion, segmentation,
compression and structure-aware shape encoding or generation. In order to
detect partial extrinsic symmetries, we propose to learn rotation, reflection,
translation and scale invariant local shape features for geodesic point cloud
patches via contrastive learning, which are robust across multiple classes and
generalize over different datasets. We show that our approach is able to
extract multiple valid solutions for this ambiguous problem. Furthermore, we
introduce a novel benchmark test for partial extrinsic symmetry detection to
evaluate our method. Lastly, we incorporate the detected symmetries together
with a region growing algorithm to demonstrate a downstream task with the goal
of computing symmetry-aware partitions of 3D shapes. To our knowledge, we are
the first to propose a self-supervised data-driven method for partial extrinsic
symmetry detection.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08232" title="Abstract">arXiv:2312.08232</a> [<a href="/pdf/2312.08232" title="Download PDF">pdf</a>, <a href="/format/2312.08232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Green Operations of SWIPT Networks: The Role of End-User Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rizzo%2C+G">Gianluca Rizzo</a>, 
<a href="/search/cs?searchtype=author&query=Marsan%2C+M+A">Marco Ajmone Marsan</a>, 
<a href="/search/cs?searchtype=author&query=Esposito%2C+C">Christian Esposito</a>, 
<a href="/search/cs?searchtype=author&query=Boi%2C+B">Biagio Boi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The manuscript has already been submitted to Journal on 7-12-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Internet of Things (IoT) devices often come with batteries of limited
capacity that are not easily replaceable or rechargeable, and that constrain
significantly the sensing, computing, and communication tasks that they can
perform. The Simultaneous Wireless Information and Power Transfer (SWIPT)
paradigm addresses this issue by delivering power wirelessly to
energy-harvesting IoT devices with the same signal used for information
transfer. For their peculiarity, these networks require specific
energy-efficient planning and management approaches. However, to date, it is
not clear what are the most effective strategies for managing a SWIPT network
for energy efficiency. In this paper, we address this issue by developing an
analytical model based on stochastic geometry, accounting for the statistics of
user-perceived performance and base station scheduling. We formulate an
optimization problem for deriving the energy optimal configuration as a
function of the main system parameters, and we propose a genetic algorithm
approach to solve it. Our results enable a first-order evaluation of the most
effective strategies for energy-efficient provisioning of power and
communications in a SWIPT network. We show that the service capacity brought
about by users brings energy-efficient dynamic network provisioning strategies
that radically differ from those of networks with no wireless power transfer.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08234" title="Abstract">arXiv:2312.08234</a> [<a href="/pdf/2312.08234" title="Download PDF">pdf</a>, <a href="/format/2312.08234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond the Label Itself: Latent Labels Enhance Semi-supervised Point  Cloud Panoptic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yujun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhizhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yanyun Qu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yuan Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">As the exorbitant expense of labeling autopilot datasets and the growing
trend of utilizing unlabeled data, semi-supervised segmentation on point clouds
becomes increasingly imperative. Intuitively, finding out more ``unspoken
words'' (i.e., latent instance information) beyond the label itself should be
helpful to improve performance. In this paper, we discover two types of latent
labels behind the displayed label embedded in LiDAR and image data. First, in
the LiDAR Branch, we propose a novel augmentation, Cylinder-Mix, which is able
to augment more yet reliable samples for training. Second, in the Image Branch,
we propose the Instance Position-scale Learning (IPSL) Module to learn and fuse
the information of instance position and scale, which is from a 2D pre-trained
detector and a type of latent label obtained from 3D to 2D projection. Finally,
the two latent labels are embedded into the multi-modal panoptic segmentation
network. The ablation of the IPSL module demonstrates its robust adaptability,
and the experiments evaluated on SemanticKITTI and nuScenes demonstrate that
our model outperforms the state-of-the-art method, LaserMix.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08235" title="Abstract">arXiv:2312.08235</a> [<a href="/pdf/2312.08235" title="Download PDF">pdf</a>, <a href="/format/2312.08235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of Psychographic Indicators via LIWC and Their Correlation with  CTR for Instagram Ads
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Inoue%2C+K">Kenjiro Inoue</a>, 
<a href="/search/cs?searchtype=author&query=Yoshida%2C+M">Mitsuo Yoshida</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WI-IAT 2023 Workshop: The 8th International Workshop on Application of Big Data for Computational Social Science (ABCSS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Digital Libraries (cs.DL)

</div>
<p class="mathjax">The online advertising industry continues to grow and accounts for over 40%
of global advertising spending. Online display advertising consists of images
and text, and advertisers maximize sales revenue by contacting consumers
through advertisements and encouraging them to make purchases. In today's
society, where products are becoming more homogenized and needs are
diversifying, appealing to consumer psychology through advertisements is
becoming increasingly important. However, it is not sufficiently clear what
kind of appeal influences consumer psychology. In this study, we quantified the
appeal of the text in advertisements for health products and cosmetics, which
were actually delivered in Instagram advertisements (one of display
advertisements), by applying linguistic inquiry and word count (LIWC). The
correlation between click-through rate (CTR) and the text was analyzed. The
results showed that negative appeals that arouse consumer anxiety and a sense
of crisis were related to CTR.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08237" title="Abstract">arXiv:2312.08237</a> [<a href="/pdf/2312.08237" title="Download PDF">pdf</a>, <a href="/ps/2312.08237" title="Download PostScript">ps</a>, <a href="/format/2312.08237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Brussels Effect to Gravity Assists: Understanding the Evolution of  the GDPR-Inspired Personal Information Protection Law in China
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenlong Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiahong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">This paper explores the evolution of China's Personal Information Protection
Law (PIPL) and situates it within the context of global data protection
development. It draws inspiration from the theory of 'Brussels Effect' and its
precedents, that describes the extraterritorial influence of EU regulations.
Our objective is not to provide a commentary on China's legal development but
to illuminate the intricate dynamics between the Chinese law and the EU's GDPR.
It is argued that the trajectory of China's Personal Information Protection Law
calls into question the applicability of the Brussels Effect: while the GDPR's
imprint on the PIPL is evident, a deeper analysis unveils China's nuanced,
non-linear adoption that diverges from many assumptions of the Brussels Effect
and similar theories. The evolution of the GDPR-inspired PIPL is not as a
straightforward outcome of the Brussels Effect but as a nuanced, intricate
interplay of external influence and domestic dynamics. We introduce a
complementary theory of 'gravity assist' which portrays China's strategic
instrumentalisation of the GDPR as a template to shape its unique data
protection landscape. Our conceptual framework highlights how China navigates
through a patchwork of internal considerations, international standards, and
strategic choices, ultimately sculpting a data protection regime that has a
similar appearance to the GDPR but aligns with its distinct political, cultural
and legal landscape. This reveals much about how China takes in the
foundational premises of data protection that are inherently built in Europe's
cherishment of the rule of law, democracy and human rights on the one hand, and
the evaluation of data protection as a fundamental right.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08238" title="Abstract">arXiv:2312.08238</a> [<a href="/pdf/2312.08238" title="Download PDF">pdf</a>, <a href="/ps/2312.08238" title="Download PostScript">ps</a>, <a href="/format/2312.08238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Laboratory test results underwater navigation system for environmental  control devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Grekov%2C+A+N">A.N. Grekov</a>, 
<a href="/search/eess?searchtype=author&query=Pasynkov%2C+M+A">M.A Pasynkov</a>, 
<a href="/search/eess?searchtype=author&query=Peliushenko%2C+.+S+S">. S.S. Peliushenko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages 6 Figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Environmental control systems. 2020. Issue. 3 (41). pp. 65-75
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The work analyzes existing methods for increasing the accuracy of determining
weekend navigation parameters of unmanned underwater vehicles. It is proposed
to retrofit the navigation system with an additional hydrodynamic tilt unit,
which will increase accuracy of coordinate determination. A prototype of the
proposed system was made, and algorithmic software for it. Analysis of typical
MEMS errors has been completed accelerometers and gyroscopes. To estimate
stochastic errors, the Allan variation method was tested using a set of real
data obtained on a prototype as input parameters. A model of stochastic errors
of all measuring channels has been constructed
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08240" title="Abstract">arXiv:2312.08240</a> [<a href="/pdf/2312.08240" title="Download PDF">pdf</a>, <a href="/format/2312.08240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CenterGrasp: Object-Aware Implicit Representation Learning for  Simultaneous Shape Reconstruction and 6-DoF Grasp Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chisari%2C+E">Eugenio Chisari</a>, 
<a href="/search/cs?searchtype=author&query=Heppert%2C+N">Nick Heppert</a>, 
<a href="/search/cs?searchtype=author&query=Welschehold%2C+T">Tim Welschehold</a>, 
<a href="/search/cs?searchtype=author&query=Burgard%2C+W">Wolfram Burgard</a>, 
<a href="/search/cs?searchtype=author&query=Valada%2C+A">Abhinav Valada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to RA-L. Video, code and models available at <a href="http://centergrasp.cs.uni-freiburg.de">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Reliable object grasping is a crucial capability for autonomous robots.
However, many existing grasping approaches focus on general clutter removal
without explicitly modeling objects and thus only relying on the visible local
geometry. We introduce CenterGrasp, a novel framework that combines object
awareness and holistic grasping. CenterGrasp learns a general object prior by
encoding shapes and valid grasps in a continuous latent space. It consists of
an RGB-D image encoder that leverages recent advances to detect objects and
infer their pose and latent code, and a decoder to predict shape and grasps for
each object in the scene. We perform extensive experiments on simulated as well
as real-world cluttered scenes and demonstrate strong scene reconstruction and
6-DoF grasp-pose estimation performance. Compared to the state of the art,
CenterGrasp achieves an improvement of 38.5 mm in shape reconstruction and 33
percentage points on average in grasp success. We make the code and trained
models publicly available at <a href="http://centergrasp.cs.uni-freiburg.de.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08245" title="Abstract">arXiv:2312.08245</a> [<a href="/pdf/2312.08245" title="Download PDF">pdf</a>, <a href="/ps/2312.08245" title="Download PostScript">ps</a>, <a href="/format/2312.08245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combinatorial Stationary Prophet Inequalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patel%2C+N">Neel Patel</a>, 
<a href="/search/cs?searchtype=author&query=Wajc%2C+D">David Wajc</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Numerous recent papers have studied the tension between thickening and
clearing a market in (uncertain, online) long-time horizon Markovian settings.
In particular, (Aouad and Sarita{\c{c}} EC'20, Collina et al. WINE'20, Kessel
et al. EC'22) studied what the latter referred to as the Stationary Prophet
Inequality Problem, due to its similarity to the classic finite-time horizon
prophet inequality problem. These works all consider unit-demand buyers.
Mirroring the long line of work on the classic prophet inequality problem
subject to combinatorial constraints, we initiate the study of the stationary
prophet inequality problem subject to combinatorially-constrained buyers.
<br />Our results can be summarized succinctly as unearthing an algorithmic
connection between contention resolution schemes (CRS) and stationary prophet
inequalities. While the classic prophet inequality problem has a tight
connection to online CRS (Feldman et al. SODA'16, Lee and Singla ESA'18), we
show that for the stationary prophet inequality problem, offline CRS play a
similarly central role. We show that, up to small constant factors, the best
(ex-ante) competitive ratio achievable for the combinatorial prophet inequality
equals the best possible balancedness achievable by offline CRS for the same
combinatorial constraints.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08248" title="Abstract">arXiv:2312.08248</a> [<a href="/pdf/2312.08248" title="Download PDF">pdf</a>, <a href="/format/2312.08248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Generative AI for Intelligent Transportation Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Huan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Intelligent transportation systems play a crucial role in modern traffic
management and optimization, greatly improving traffic efficiency and safety.
With the rapid development of generative artificial intelligence (Generative
AI) technologies in the fields of image generation and natural language
processing, generative AI has also played a crucial role in addressing key
issues in intelligent transportation systems, such as data sparsity, difficulty
in observing abnormal scenarios, and in modeling data uncertainty. In this
review, we systematically investigate the relevant literature on generative AI
techniques in addressing key issues in different types of tasks in intelligent
transportation systems. First, we introduce the principles of different
generative AI techniques, and their potential applications. Then, we classify
tasks in intelligent transportation systems into four types: traffic
perception, traffic prediction, traffic simulation, and traffic
decision-making. We systematically illustrate how generative AI techniques
addresses key issues in these four different types of tasks. Finally, we
summarize the challenges faced in applying generative AI to intelligent
transportation systems, and discuss future research directions based on
different application scenarios.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08250" title="Abstract">arXiv:2312.08250</a> [<a href="/pdf/2312.08250" title="Download PDF">pdf</a>, <a href="/format/2312.08250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Robot Program Synthesis Through Environmental Context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qidi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Liwei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xin Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Program synthesis aims to automatically generate an executable program that
conforms to the given specification. Recent advancements have demonstrated that
deep neural methodologies and large-scale pretrained language models are highly
proficient in capturing program semantics. For robot programming, prior works
have facilitated program synthesis by incorporating global environments.
However, the assumption of acquiring a comprehensive understanding of the
entire environment is often excessively challenging to achieve. In this work,
we present a framework that learns to synthesize a program by rectifying
potentially erroneous code segments, with the aid of partially observed
environments. To tackle the issue of inadequate attention to partial
observations, we propose to first learn an environment embedding space that can
implicitly evaluate the impacts of each program token based on the
precondition. Furthermore, by employing a graph structure, the model can
aggregate both environmental and syntactic information flow and furnish smooth
program rectification guidance. Extensive experimental evaluations and ablation
studies on the partially observed VizDoom domain authenticate that our method
offers superior generalization capability across various tasks and greater
robustness when encountering noises.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08256" title="Abstract">arXiv:2312.08256</a> [<a href="/pdf/2312.08256" title="Download PDF">pdf</a>, <a href="/format/2312.08256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Compact and Semantic Latent Space for Disentangled and Controllable  Image Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lesn%C3%A9%2C+G">Gwilherm Lesn&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Gousseau%2C+Y">Yann Gousseau</a>, 
<a href="/search/cs?searchtype=author&query=Ladjal%2C+S">Sa&#xef;d Ladjal</a>, 
<a href="/search/cs?searchtype=author&query=Newson%2C+A">Alasdair Newson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advances in the field of generative models and in particular
generative adversarial networks (GANs) have lead to substantial progress for
controlled image editing, especially compared with the pre-deep learning era.
Despite their powerful ability to apply realistic modifications to an image,
these methods often lack properties like disentanglement (the capacity to edit
attributes independently). In this paper, we propose an auto-encoder which
re-organizes the latent space of StyleGAN, so that each attribute which we wish
to edit corresponds to an axis of the new latent space, and furthermore that
the latent axes are decorrelated, encouraging disentanglement. We work in a
compressed version of the latent space, using Principal Component Analysis,
meaning that the parameter complexity of our autoencoder is reduced, leading to
short training times ($\sim$ 45 mins). Qualitative and quantitative results
demonstrate the editing capabilities of our approach, with greater
disentanglement than competing methods, while maintaining fidelity to the
original image with respect to identity. Our autoencoder architecture simple
and straightforward, facilitating implementation.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08259" title="Abstract">arXiv:2312.08259</a> [<a href="/pdf/2312.08259" title="Download PDF">pdf</a>, <a href="/format/2312.08259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of reconstruction of functions with rough edges from discrete  Radon data in $\mathbb R^2$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Katsevich%2C+A">Alexander Katsevich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We study the accuracy of reconstruction of a family of functions
$f_\epsilon(x)$, $x\in\mathbb R^2$, $\epsilon\to0$, from their discrete Radon
transform data sampled with step size $O(\epsilon)$. For each $\epsilon&gt;0$
sufficiently small, the function $f_\epsilon$ has a jump across a rough
boundary $\mathcal S_\epsilon$, which is modeled by an $O(\epsilon)$-size
perturbation of a smooth boundary $\mathcal S$. The function $H_0$, which
describes the perturbation, is assumed to be of bounded variation. Let
$f_\epsilon^{\text{rec}}$ denote the reconstruction, which is computed by
interpolating discrete data and substituting it into a continuous inversion
formula. We prove that
$(f_\epsilon^{\text{rec}}-K_\epsilon*f_\epsilon)(x_0+\epsilon\check
x)=O(\epsilon^{1/2}\ln(1/\epsilon))$, where $x_0\in\mathcal S$ and $K_\epsilon$
is an easily computable kernel.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08268" title="Abstract">arXiv:2312.08268</a> [<a href="/pdf/2312.08268" title="Download PDF">pdf</a>, <a href="/format/2312.08268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Multi-Object Pose Estimation using Multi-Resolution Deformable  Attention and Query Aggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Periyasamy%2C+A+S">Arul Selvam Periyasamy</a>, 
<a href="/search/cs?searchtype=author&query=Tsaturyan%2C+V">Vladimir Tsaturyan</a>, 
<a href="/search/cs?searchtype=author&query=Behnke%2C+S">Sven Behnke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE International Conference on Robotic Computing (IRC), Laguna Hills, USA, December 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Object pose estimation is a long-standing problem in computer vision.
Recently, attention-based vision transformer models have achieved
state-of-the-art results in many computer vision applications. Exploiting the
permutation-invariant nature of the attention mechanism, a family of vision
transformer models formulate multi-object pose estimation as a set prediction
problem. However, existing vision transformer models for multi-object pose
estimation rely exclusively on the attention mechanism. Convolutional neural
networks, on the other hand, hard-wire various inductive biases into their
architecture. In this paper, we investigate incorporating inductive biases in
vision transformer models for multi-object pose estimation, which facilitates
learning long-range dependencies while circumventing the costly global
attention. In particular, we use multi-resolution deformable attention, where
the attention operation is performed only between a few deformed reference
points. Furthermore, we propose a query aggregation mechanism that enables
increasing the number of object queries without increasing the computational
complexity. We evaluate the proposed model on the challenging YCB-Video dataset
and report state-of-the-art results.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08274" title="Abstract">arXiv:2312.08274</a> [<a href="/pdf/2312.08274" title="Download PDF">pdf</a>, <a href="/format/2312.08274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-throughput Biomedical Relation Extraction for Semi-Structured Web  Articles Empowered by Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Songchi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Sheng Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Objective: To develop a high-throughput biomedical relation extraction system
that takes advantage of the large language models' (LLMs) reading comprehension
ability and biomedical world knowledge in a scalable and evidential manner.
Methods: We formulate the relation extraction task as a simple binary
classification problem for large language models such as ChatGPT. Specifically,
LLMs make the decision based on the external corpus and its world knowledge,
giving the reason for the judgment to factual verification. This method is
tailored for semi-structured web articles, wherein we designate the main title
as the tail entity and explicitly incorporate it into the context, and the
potential head entities are matched based on a biomedical thesaurus. Moreover,
lengthy contents are sliced into text chunks, embedded, and retrieved with
additional embedding models, ensuring compatibility with the context window
size constraints of available open-source LLMs. Results: Using an open-source
LLM, we extracted 304315 relation triplets of three distinct relation types
from four reputable biomedical websites. To assess the efficacy of the basic
pipeline employed for biomedical relation extraction, we curated a benchmark
dataset annotated by a medical expert. Evaluation results indicate that the
pipeline exhibits performance comparable to that of GPT-4. Case studies further
illuminate challenges faced by contemporary LLMs in the context of biomedical
relation extraction for semi-structured web articles. Conclusion: The proposed
method has demonstrated its effectiveness in leveraging the strengths of LLMs
for high-throughput biomedical relation extraction. Its adaptability is
evident, as it can be seamlessly extended to diverse semi-structured biomedical
websites, facilitating the extraction of various types of biomedical relations
with ease.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08280" title="Abstract">arXiv:2312.08280</a> [<a href="/pdf/2312.08280" title="Download PDF">pdf</a>, <a href="/format/2312.08280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New High-Order Numerical Methods for Hyperbolic Systems of Nonlinear  PDEs with Uncertainties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chertock%2C+A">Alina Chertock</a>, 
<a href="/search/math?searchtype=author&query=Herty%2C+M">Michael Herty</a>, 
<a href="/search/math?searchtype=author&query=Iskhakov%2C+A+S">Arsen S. Iskhakov</a>, 
<a href="/search/math?searchtype=author&query=Janajra%2C+S">Safa Janajra</a>, 
<a href="/search/math?searchtype=author&query=Kurganov%2C+A">Alexander Kurganov</a>, 
<a href="/search/math?searchtype=author&query=Lukacova-Medvidova%2C+M">Maria Lukacova-Medvidova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we develop new high-order numerical methods for hyperbolic
systems of nonlinear partial differential equations (PDEs) with uncertainties.
The new approach is realized in the semi-discrete finite-volume framework and
it is based on fifth-order weighted essentially non-oscillatory (WENO)
interpolations in (multidimensional) random space combined with second-order
piecewise linear reconstruction in physical space. Compared with spectral
approximations in the random space, the presented methods are essentially
non-oscillatory as they do not suffer from the Gibbs phenomenon while still
achieving a high-order accuracy. The new methods are tested on a number of
numerical examples for both the Euler equations of gas dynamics and the
Saint-Venant system of shallow-water equations. In the latter case, the methods
are also proven to be well-balanced and positivity-preserving.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08282" title="Abstract">arXiv:2312.08282</a> [<a href="/pdf/2312.08282" title="Download PDF">pdf</a>, <a href="/format/2312.08282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompting LLMs with content plans to enhance the summarization of  scientific articles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Creo%2C+A">Aldan Creo</a> (1), 
<a href="/search/cs?searchtype=author&query=Lama%2C+M">Manuel Lama</a> (1), 
<a href="/search/cs?searchtype=author&query=Vidal%2C+J+C">Juan C. Vidal</a> (1) ((1) Singular Research Center on Intelligent Technologies (CiTIUS), Universidade de Santiago de Compostela, Santiago de Compostela, Spain)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents novel prompting techniques to improve the performance of
automatic summarization systems for scientific articles. Scientific article
summarization is highly challenging due to the length and complexity of these
documents. We conceive, implement, and evaluate prompting techniques that
provide additional contextual information to guide summarization systems.
Specifically, we feed summarizers with lists of key terms extracted from
articles, such as author keywords or automatically generated keywords. Our
techniques are tested with various summarization models and input texts.
Results show performance gains, especially for smaller models summarizing
sections separately. This evidences that prompting is a promising approach to
overcoming the limitations of less powerful systems. Our findings introduce a
new research direction of using prompts to aid smaller models.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08287" title="Abstract">arXiv:2312.08287</a> [<a href="/pdf/2312.08287" title="Download PDF">pdf</a>, <a href="/format/2312.08287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the verification of Embeddings using Hybrid Markov Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shakya%2C+A">Anup Shakya</a>, 
<a href="/search/cs?searchtype=author&query=Magar%2C+A+T">Abisha Thapa Magar</a>, 
<a href="/search/cs?searchtype=author&query=Sarkhel%2C+S">Somdeb Sarkhel</a>, 
<a href="/search/cs?searchtype=author&query=Venugopal%2C+D">Deepak Venugopal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, Proceedings of 23rd IEEE International Conference on Data Mining 2023 (ICDM'23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The standard approach to verify representations learned by Deep Neural
Networks is to use them in specific tasks such as classification or regression,
and measure their performance based on accuracy in such tasks. However, in many
cases, we would want to verify more complex properties of a learned
representation. To do this, we propose a framework based on a probabilistic
first-order language, namely, Hybrid Markov Logic Networks (HMLNs) where we
specify properties over embeddings mixed with symbolic domain knowledge. We
present an approach to learn parameters for the properties within this
framework. Further, we develop a verification method to test embeddings in this
framework by encoding this task as a Mixed Integer Linear Program for which we
can leverage existing state-of-the-art solvers. We illustrate verification in
Graph Neural Networks, Deep Knowledge Tracing and Intelligent Tutoring Systems
to demonstrate the generality of our approach.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08288" title="Abstract">arXiv:2312.08288</a> [<a href="/pdf/2312.08288" title="Download PDF">pdf</a>, <a href="/format/2312.08288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Sample Synthesis-based Debiasing of Classifier in Limited Data  Setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arora%2C+P">Piyush Arora</a>, 
<a href="/search/cs?searchtype=author&query=Mazumder%2C+P">Pratik Mazumder</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning models are known to suffer from the problem of bias, and
researchers have been exploring methods to address this issue. However, most of
these methods require prior knowledge of the bias and are not always practical.
In this paper, we focus on a more practical setting with no prior information
about the bias. Generally, in this setting, there are a large number of
bias-aligned samples that cause the model to produce biased predictions and a
few bias-conflicting samples that do not conform to the bias. If the training
data is limited, the influence of the bias-aligned samples may become even
stronger on the model predictions, and we experimentally demonstrate that
existing debiasing techniques suffer severely in such cases. In this paper, we
examine the effects of unknown bias in small dataset regimes and present a
novel approach to mitigate this issue. The proposed approach directly addresses
the issue of the extremely low occurrence of bias-conflicting samples in
limited data settings through the synthesis of hybrid samples that can be used
to reduce the effect of bias. We perform extensive experiments on several
benchmark datasets and experimentally demonstrate the effectiveness of our
proposed approach in addressing any unknown bias in the presence of limited
data. Specifically, our approach outperforms the vanilla, LfF, LDD, and DebiAN
debiasing methods by absolute margins of 10.39%, 9.08%, 8.07%, and 9.67% when
only 10% of the Corrupted CIFAR-10 Type 1 dataset is available with a
bias-conflicting sample ratio of 0.05.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08291" title="Abstract">arXiv:2312.08291</a> [<a href="/pdf/2312.08291" title="Download PDF">pdf</a>, <a href="/format/2312.08291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VQ-HPS: Human Pose and Shape Estimation in a Vector-Quantized Latent  Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fiche%2C+G">Gu&#xe9;nol&#xe9; Fiche</a>, 
<a href="/search/cs?searchtype=author&query=Leglaive%2C+S">Simon Leglaive</a>, 
<a href="/search/cs?searchtype=author&query=Alameda-Pineda%2C+X">Xavier Alameda-Pineda</a>, 
<a href="/search/cs?searchtype=author&query=Agudo%2C+A">Antonio Agudo</a>, 
<a href="/search/cs?searchtype=author&query=Moreno-Noguer%2C+F">Francesc Moreno-Noguer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human Pose and Shape Estimation (HPSE) from RGB images can be broadly
categorized into two main groups: parametric and non-parametric approaches.
Parametric techniques leverage a low-dimensional statistical body model for
realistic results, whereas recent non-parametric methods achieve higher
precision by directly regressing the 3D coordinates of the human body. Despite
their strengths, both approaches face limitations: the parameters of
statistical body models pose challenges as regression targets, and predicting
3D coordinates introduces computational complexities and issues related to
smoothness. In this work, we take a novel approach to address the HPSE problem.
We introduce a unique method involving a low-dimensional discrete latent
representation of the human mesh, framing HPSE as a classification task.
Instead of predicting body model parameters or 3D vertex coordinates, our focus
is on forecasting the proposed discrete latent representation, which can be
decoded into a registered human mesh. This innovative paradigm offers two key
advantages: firstly, predicting a low-dimensional discrete representation
confines our predictions to the space of anthropomorphic poses and shapes;
secondly, by framing the problem as a classification task, we can harness the
discriminative power inherent in neural networks. Our proposed model, VQ-HPS, a
transformer-based architecture, forecasts the discrete latent representation of
the mesh, trained through minimizing a cross-entropy loss. Our results
demonstrate that VQ-HPS outperforms the current state-of-the-art non-parametric
approaches while yielding results as realistic as those produced by parametric
methods. This highlights the significant potential of the classification
approach for HPSE.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08298" title="Abstract">arXiv:2312.08298</a> [<a href="/pdf/2312.08298" title="Download PDF">pdf</a>, <a href="/format/2312.08298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Venn: Resource Management Across Federated Learning Jobs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiachen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+F">Fan Lai</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+D">Ding Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+M">Mosharaf Chowdhury</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 15 figrues
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, federated learning (FL) has emerged as a promising approach
for machine learning (ML) and data science across distributed edge devices.
With the increasing popularity of FL, resource contention between multiple FL
jobs training on the same device population is increasing as well. Scheduling
edge resources among multiple FL jobs is different from GPU scheduling for
cloud ML because of the ephemeral nature and planetary scale of participating
devices as well as the overlapping resource requirements of diverse FL jobs.
Existing resource managers for FL jobs opt for random assignment of devices to
FL jobs for simplicity and scalability, which leads to poor performance. In
this paper, we present Venn, an FL resource manager, that efficiently schedules
ephemeral, heterogeneous devices among many FL jobs, with the goal of reducing
their average job completion time (JCT). Venn formulates the Intersection
Resource Scheduling (IRS) problem to identify complex resource contention among
multiple FL jobs. Then, Venn proposes a contention-aware scheduling heuristic
to minimize the average scheduling delay. Furthermore, it proposes a
resource-aware device-to-job matching heuristic that focuses on optimizing
response collection time by mitigating stragglers. Our evaluation shows that,
compared to the state-of-the-art FL resource managers, Venn improves the
average JCT by up to 1.88X.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08299" title="Abstract">arXiv:2312.08299</a> [<a href="/pdf/2312.08299" title="Download PDF">pdf</a>, <a href="/format/2312.08299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conceptualizing Suicidal Behavior: Utilizing Explanations of Predicted  Outcomes to Analyze Longitudinal Social Media Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V+M">Van Minh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nur%2C+N">Nasheen Nur</a>, 
<a href="/search/cs?searchtype=author&query=Stern%2C+W">William Stern</a>, 
<a href="/search/cs?searchtype=author&query=Mercer%2C+T">Thomas Mercer</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+C">Chiradeep Sen</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharyya%2C+S">Siddhartha Bhattacharyya</a>, 
<a href="/search/cs?searchtype=author&query=Tumbiolo%2C+V">Victor Tumbiolo</a>, 
<a href="/search/cs?searchtype=author&query=Goh%2C+S+J">Seng Jhing Goh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for ICMLA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">The COVID-19 pandemic has escalated mental health crises worldwide, with
social isolation and economic instability contributing to a rise in suicidal
behavior. Suicide can result from social factors such as shame, abuse,
abandonment, and mental health conditions like depression, Post-Traumatic
Stress Disorder (PTSD), Attention-Deficit/Hyperactivity Disorder (ADHD),
anxiety disorders, and bipolar disorders. As these conditions develop, signs of
suicidal ideation may manifest in social media interactions. Analyzing social
media data using artificial intelligence (AI) techniques can help identify
patterns of suicidal behavior, providing invaluable insights for suicide
prevention agencies, professionals, and broader community awareness
initiatives. Machine learning algorithms for this purpose require large volumes
of accurately labeled data. Previous research has not fully explored the
potential of incorporating explanations in analyzing and labeling longitudinal
social media data. In this study, we employed a model explanation method, Layer
Integrated Gradients, on top of a fine-tuned state-of-the-art language model,
to assign each token from Reddit users' posts an attribution score for
predicting suicidal ideation. By extracting and analyzing attributions of
tokens from the data, we propose a methodology for preliminary screening of
social media posts for suicidal ideation without using large language models
during inference.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08301" title="Abstract">arXiv:2312.08301</a> [<a href="/pdf/2312.08301" title="Download PDF">pdf</a>, <a href="/format/2312.08301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and Control of an Energy Accumulative Hopping Robot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Burns%2C+S">Samuel Burns</a>, 
<a href="/search/cs?searchtype=author&query=Woodward%2C+M">Matthew Woodward</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Jumping and hopping locomotion are efficient means of traversing unstructured
rugged terrain with the former being the focus of roboticists. This focus has
led to significant performance and understanding in jumping robots but with
limited practical applications as they require significant time between jumps
to store energy, thus relegating jumping to a secondary role in locomotion.
Hopping locomotion, however, can preserve and transfer energy to subsequent
hops without long energy storage periods. Therefore, hopping has the potential
to be far more energy efficient and agile than jumping. However, to date, only
a single untethered hopping robot exists with limited payload and hopping
heights (&lt; 1 meter). This is due to the added design and control complexity
inherent in the requirements to input energy during dynamic locomotion and
control the orientation of the system throughout the hopping cycle, resulting
in low energy input and control torques; a redevelopment from basic principles
is necessary to advance the capabilities of hopping robots. Here we report
hopping robot design principles for efficient and robust systems with high
energy input and control torques that are validated through analytical,
simulation, and experimental results. The resulting robot (MultiMo-MHR) can hop
nearly 4 meters (&gt; 6 times the current state-of-the-art); and is only limited
by the impact mechanics and not energy input. The results also directly
contradict a recent work that concluded hopping with aerodynamic energy input
would be less efficient than flight for hops greater than 0.4 meters.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08303" title="Abstract">arXiv:2312.08303</a> [<a href="/pdf/2312.08303" title="Download PDF">pdf</a>, <a href="/format/2312.08303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Toxic Content Detection by Bootstrapping and Distilling Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qiong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yiming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+C">Cheng Cao</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zheng Du</a>, 
<a href="/search/cs?searchtype=author&query=Psounis%2C+K">Konstantinos Psounis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Toxic content detection is crucial for online services to remove
inappropriate content that violates community standards. To automate the
detection process, prior works have proposed varieties of machine learning (ML)
approaches to train Language Models (LMs) for toxic content detection. However,
both their accuracy and transferability across datasets are limited. Recently,
Large Language Models (LLMs) have shown promise in toxic content detection due
to their superior zero-shot and few-shot in-context learning ability as well as
broad transferability on ML tasks. However, efficiently designing prompts for
LLMs remains challenging. Moreover, the high run-time cost of LLMs may hinder
their deployments in production. To address these challenges, in this work, we
propose BD-LLM, a novel and efficient approach to Bootstrapping and Distilling
LLMs for toxic content detection. Specifically, we design a novel prompting
method named Decision-Tree-of-Thought (DToT) to bootstrap LLMs' detection
performance and extract high-quality rationales. DToT can automatically select
more fine-grained context to re-prompt LLMs when their responses lack
confidence. Additionally, we use the rationales extracted via DToT to fine-tune
student LMs. Our experimental results on various datasets demonstrate that DToT
can improve the accuracy of LLMs by up to 4.6%. Furthermore, student LMs
fine-tuned with rationales extracted via DToT outperform baselines on all
datasets with up to 16.9\% accuracy improvement, while being more than 60x
smaller than conventional LLMs. Finally, we observe that student LMs fine-tuned
with rationales exhibit better cross-dataset transferability.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08305" title="Abstract">arXiv:2312.08305</a> [<a href="/pdf/2312.08305" title="Download PDF">pdf</a>, <a href="/format/2312.08305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConChain: A Scheme for Contention-free and Attack Resilient BlockChain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bappy%2C+F+H">Faisal Haque Bappy</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+T">Tariqul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Zaman%2C+T+S">Tarannum Shaila Zaman</a>, 
<a href="/search/cs?searchtype=author&query=Sajid%2C+M+S+I">Md Sajidul Islam Sajid</a>, 
<a href="/search/cs?searchtype=author&query=Pritom%2C+M+M+A">Mir Mehedi Ahsan Pritom</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Although blockchains have become widely popular for their use in
cryptocurrencies, they are now becoming pervasive as more traditional
applications adopt blockchain to ensure data security. Despite being a secured
network, blockchains have some tradeoffs such as high latency, low throughput,
and transaction failures. One of the core problems behind these is improper
management of "conflicting transactions", which is also known as "contention".
When there is a large pool of pending transactions in a blockchain and some of
them are conflicting, a situation of contention occurs, and as a result, the
latency of the network increases, and a substantial amount of resources are
wasted which results in low throughput and transaction failures. In this paper,
we proposed ConChain, a novel blockchain scheme that combines transaction
parallelism and an intelligent dependency manager to minimize conflicting
transactions in blockchain networks as well as improve performance. ConChain is
also capable of ensuring proper defense against major attacks due to
contention.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08309" title="Abstract">arXiv:2312.08309</a> [<a href="/pdf/2312.08309" title="Download PDF">pdf</a>, <a href="/format/2312.08309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FASTEN: Towards a FAult-tolerant and STorage EfficieNt Cloud: Balancing  Between Replication and Deduplication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S">Sabbir Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Nahiduzzaman%2C+M">Md Nahiduzzaman</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+T">Tariqul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Bappy%2C+F+H">Faisal Haque Bappy</a>, 
<a href="/search/cs?searchtype=author&query=Zaman%2C+T+S">Tarannum Shaila Zaman</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+R">Raiful Hasan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">With the surge in cloud storage adoption, enterprises face challenges
managing data duplication and exponential data growth. Deduplication mitigates
redundancy, yet maintaining redundancy ensures high availability, incurring
storage costs. Balancing these aspects is a significant research concern. We
propose FASTEN, a distributed cloud storage scheme ensuring efficiency,
security, and high availability. FASTEN achieves fault tolerance by dispersing
data subsets optimally across servers and maintains redundancy for high
availability. Experimental results show FASTEN's effectiveness in fault
tolerance, cost reduction, batch auditing, and file and block-level
deduplication. It outperforms existing systems with low time complexity, strong
fault tolerance, and commendable deduplication performance.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08317" title="Abstract">arXiv:2312.08317</a> [<a href="/pdf/2312.08317" title="Download PDF">pdf</a>, <a href="/format/2312.08317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Engineering-assisted Malware Dynamic Analysis Using GPT-4
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+P">Pei Yan</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+S">Shunquan Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Miaohui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiwu Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Dynamic analysis methods effectively identify shelled, wrapped, or obfuscated
malware, thereby preventing them from invading computers. As a significant
representation of dynamic malware behavior, the API (Application Programming
Interface) sequence, comprised of consecutive API calls, has progressively
become the dominant feature of dynamic analysis methods. Though there have been
numerous deep learning models for malware detection based on API sequences, the
quality of API call representations produced by those models is limited. These
models cannot generate representations for unknown API calls, which weakens
both the detection performance and the generalization. Further, the concept
drift phenomenon of API calls is prominent. To tackle these issues, we
introduce a prompt engineering-assisted malware dynamic analysis using GPT-4.
In this method, GPT-4 is employed to create explanatory text for each API call
within the API sequence. Afterward, the pre-trained language model BERT is used
to obtain the representation of the text, from which we derive the
representation of the API sequence. Theoretically, this proposed method is
capable of generating representations for all API calls, excluding the
necessity for dataset training during the generation process. Utilizing the
representation, a CNN-based detection model is designed to extract the feature.
We adopt five benchmark datasets to validate the performance of the proposed
model. The experimental results reveal that the proposed detection algorithm
performs better than the state-of-the-art method (TextCNN). Specifically, in
cross-database experiments and few-shot learning experiments, the proposed
model achieves excellent detection performance and almost a 100% recall rate
for malware, verifying its superior generalization performance. The code is
available at: github.com/yan-scnu/Prompted_Dynamic_Detection.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08323" title="Abstract">arXiv:2312.08323</a> [<a href="/pdf/2312.08323" title="Download PDF">pdf</a>, <a href="/format/2312.08323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PnPNet: Pull-and-Push Networks for Volumetric Segmentation with Boundary  Confusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=You%2C+X">Xin You</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Ming Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Minghui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanxiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yun Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 Figures, 8 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Precise boundary segmentation of volumetric images is a critical task for
image-guided diagnosis and computer-assisted intervention, especially for
boundary confusion in clinical practice. However, U-shape networks cannot
effectively resolve this challenge due to the lack of boundary shape
constraints. Besides, existing methods of refining boundaries overemphasize the
slender structure, which results in the overfitting phenomenon due to networks'
limited abilities to model tiny objects. In this paper, we reconceptualize the
mechanism of boundary generation by encompassing the interaction dynamics with
adjacent regions. Moreover, we propose a unified network termed PnPNet to model
shape characteristics of the confused boundary region. Core ingredients of
PnPNet contain the pushing and pulling branches. Specifically, based on
diffusion theory, we devise the semantic difference module (SDM) from the
pushing branch to squeeze the boundary region. Explicit and implicit
differential information inside SDM significantly boost representation
abilities for inter-class boundaries. Additionally, motivated by the K-means
algorithm, the class clustering module (CCM) from the pulling branch is
introduced to stretch the intersected boundary region. Thus, pushing and
pulling branches will shrink and enlarge the boundary uncertainty respectively.
They furnish two adversarial forces to promote models to output a more precise
delineation of boundaries. We carry out experiments on three challenging public
datasets and one in-house dataset, containing three types of boundary confusion
in model predictions. Experimental results demonstrate the superiority of
PnPNet over other segmentation networks, especially on evaluation metrics of HD
and ASSD. Besides, pushing and pulling branches can serve as plug-and-play
modules to enhance classic U-shape baseline models. Codes are available.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08330" title="Abstract">arXiv:2312.08330</a> [<a href="/pdf/2312.08330" title="Download PDF">pdf</a>, <a href="/format/2312.08330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preparing VVC for Streaming: A Fast Multi-Rate Encoding Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiqun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Amirpour%2C+H">Hadi Amirpour</a>, 
<a href="/search/cs?searchtype=author&query=Abdoli%2C+M">Mohsen Abdoli</a>, 
<a href="/search/cs?searchtype=author&query=Timmerer%2C+C">Christian Timmerer</a>, 
<a href="/search/cs?searchtype=author&query=Guionnet%2C+T">Thomas Guionnet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by VCIP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">The integration of advanced video codecs into the streaming pipeline is
growing in response to the increasing demand for high quality video content.
However, the significant computational demand for advanced codecs like
Versatile Video Coding (VVC) poses challenges for service providers, including
longer encoding time and higher encoding cost. This challenge becomes even more
pronounced in streaming, as the same content needs to be encoded at multiple
bitrates (also known as representations) to accommodate different network
conditions. To accelerate the encoding process of multiple representations of
the same content in VVC, we employ the encoding map of a single representation,
known as the reference representation, and utilize its partitioning structure
to accelerate the encoding of the remaining representations, referred to as
dependent representations. To ensure compatibility with parallel processing, we
designate the lowest bitrate representation as the reference representation.
The experimental results indicate a substantial improvement in the encoding
time for the dependent representations, achieving an average reduction of 40%,
while maintaining a minimal average quality drop of only 0.43 in Video
Multi-method Assessment Fusion (VMAF). This improvement is observed when
utilizing Versatile Video Encoder (VVenC), an open and optimized VVC encoder
implementation.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08334" title="Abstract">arXiv:2312.08334</a> [<a href="/pdf/2312.08334" title="Download PDF">pdf</a>, <a href="/format/2312.08334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LD-SDM: Language-Driven Hierarchical Species Distribution Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sastry%2C+S">Srikumar Sastry</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+X">Xin Xing</a>, 
<a href="/search/cs?searchtype=author&query=Dhakal%2C+A">Aayush Dhakal</a>, 
<a href="/search/cs?searchtype=author&query=Khanal%2C+S">Subash Khanal</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+A">Adeel Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Jacobs%2C+N">Nathan Jacobs</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We focus on the problem of species distribution modeling using global-scale
presence-only data. Most previous studies have mapped the range of a given
species using geographical and environmental features alone. To capture a
stronger implicit relationship between species, we encode the taxonomic
hierarchy of species using a large language model. This enables range mapping
for any taxonomic rank and unseen species without additional supervision.
Further, we propose a novel proximity-aware evaluation metric that enables
evaluating species distribution models using any pixel-level representation of
ground-truth species range map. The proposed metric penalizes the predictions
of a model based on its proximity to the ground truth. We describe the
effectiveness of our model by systematically evaluating on the task of species
range prediction, zero-shot prediction and geo-feature regression against the
state-of-the-art. Results show our model outperforms the strong baselines when
trained with a variety of multi-label learning losses.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08338" title="Abstract">arXiv:2312.08338</a> [<a href="/pdf/2312.08338" title="Download PDF">pdf</a>, <a href="/format/2312.08338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Global Latent Neural Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tanay%2C+T">Thomas Tanay</a>, 
<a href="/search/cs?searchtype=author&query=Maggioni%2C+M">Matteo Maggioni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">A recent trend among generalizable novel view synthesis methods is to learn a
rendering operator acting over single camera rays. This approach is promising
because it removes the need for explicit volumetric rendering, but it
effectively treats target images as collections of independent pixels. Here, we
propose to learn a global rendering operator acting over all camera rays
jointly. We show that the right representation to enable such rendering is the
5-dimensional plane sweep volume, consisting of the projection of the input
images on a set of planes facing the target camera. Based on this
understanding, we introduce our Convolutional Global Latent Renderer (ConvGLR),
an efficient convolutional architecture that performs the rendering operation
globally in a low-resolution latent space. Experiments on various datasets
under sparse and generalizable setups show that our approach consistently
outperforms existing methods by significant margins.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08344" title="Abstract">arXiv:2312.08344</a> [<a href="/pdf/2312.08344" title="Download PDF">pdf</a>, <a href="/format/2312.08344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FoundationPose: Unified 6D Pose Estimation and Tracking of Novel Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+B">Bowen Wen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kautz%2C+J">Jan Kautz</a>, 
<a href="/search/cs?searchtype=author&query=Birchfield%2C+S">Stan Birchfield</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">We present FoundationPose, a unified foundation model for 6D object pose
estimation and tracking, supporting both model-based and model-free setups. Our
approach can be instantly applied at test-time to a novel object without
fine-tuning, as long as its CAD model is given, or a small number of reference
images are captured. We bridge the gap between these two setups with a neural
implicit representation that allows for effective novel view synthesis, keeping
the downstream pose estimation modules invariant under the same unified
framework. Strong generalizability is achieved via large-scale synthetic
training, aided by a large language model (LLM), a novel transformer-based
architecture, and contrastive learning formulation. Extensive evaluation on
multiple public datasets involving challenging scenarios and objects indicate
our unified approach outperforms existing methods specialized for each task by
a large margin. In addition, it even achieves comparable results to
instance-level methods despite the reduced assumptions. Project page:
https://nvlabs.github.io/FoundationPose/
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08356" title="Abstract">arXiv:2312.08356</a> [<a href="/pdf/2312.08356" title="Download PDF">pdf</a>, <a href="/format/2312.08356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CUTTANA: Scalable Graph Partitioning for Faster Distributed Graph  Databases and Analytics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hajidehi%2C+M+R">Milad Rezaei Hajidehi</a>, 
<a href="/search/cs?searchtype=author&query=Sridhar%2C+S">Sraavan Sridhar</a>, 
<a href="/search/cs?searchtype=author&query=Seltzer%2C+M">Margo Seltzer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint version, Under-review, Code available after reviews
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Graph partitioning plays a pivotal role in various distributed graph
processing applications, including graph analytics, graph neural network
training, and distributed graph databases. Graphs that require distributed
settings are often too large to fit in the main memory of a single machine.
This challenge renders traditional in-memory graph partitioners infeasible,
leading to the emergence of streaming solutions. Streaming partitioners produce
lower-quality partitions because they work from partial information and must
make premature decisions before they have a complete view of a vertex's
neighborhood. We introduce CUTTANA, a streaming graph partitioner that
partitions massive graphs (Web/Twitter scale) with superior quality compared to
existing streaming solutions. CUTTANA uses a novel buffering technique that
prevents the premature assignment of vertices to partitions and a scalable
coarsening and refinement technique that enables a complete graph view,
improving the intermediate assignment made by a streaming partitioner. We
implemented a parallel version for CUTTANA that offers nearly the same
partitioning latency as existing streaming partitioners.
<br />Our experimental analysis shows that CUTTANA consistently yields better
partitioning quality than existing state-of-the-art streaming vertex
partitioners in terms of both edge-cut and communication volume metrics. We
also evaluate the workload latencies that result from using CUTTANA and other
partitioners in distributed graph analytics and databases. CUTTANA outperforms
the other methods in most scenarios (algorithms, datasets). In analytics
applications, CUTTANA improves runtime performance by up to 59% compared to
various streaming partitioners (HDRF, Fennel, Ginger, HeiStream). In graph
database tasks, CUTTANA results in higher query throughput by up to 23%,
without hurting tail latency.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08358" title="Abstract">arXiv:2312.08358</a> [<a href="/pdf/2312.08358" title="Download PDF">pdf</a>, <a href="/format/2312.08358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributional Preference Learning: Understanding and Accounting for  Hidden Context in RLHF
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Siththaranjan%2C+A">Anand Siththaranjan</a>, 
<a href="/search/cs?searchtype=author&query=Laidlaw%2C+C">Cassidy Laidlaw</a>, 
<a href="/search/cs?searchtype=author&query=Hadfield-Menell%2C+D">Dylan Hadfield-Menell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">In practice, preference learning from human feedback depends on incomplete
data with hidden context. Hidden context refers to data that affects the
feedback received, but which is not represented in the data used to train a
preference model. This captures common issues of data collection, such as
having human annotators with varied preferences, cognitive processes that
result in seemingly irrational behavior, and combining data labeled according
to different criteria. We prove that standard applications of preference
learning, including reinforcement learning from human feedback (RLHF),
implicitly aggregate over hidden contexts according to a well-known voting rule
called Borda count. We show this can produce counter-intuitive results that are
very different from other methods which implicitly aggregate via expected
utility. Furthermore, our analysis formalizes the way that preference learning
from users with diverse values tacitly implements a social choice function. A
key implication of this result is that annotators have an incentive to
misreport their preferences in order to influence the learned model, leading to
vulnerabilities in the deployment of RLHF. As a step towards mitigating these
problems, we introduce a class of methods called distributional preference
learning (DPL). DPL methods estimate a distribution of possible score values
for each alternative in order to better account for hidden context.
Experimental results indicate that applying DPL to RLHF for LLM chatbots
identifies hidden context in the data and significantly reduces subsequent
jailbreak vulnerability. Our code and data are available at
https://github.com/cassidylaidlaw/hidden-context
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08361" title="Abstract">arXiv:2312.08361</a> [<a href="/pdf/2312.08361" title="Download PDF">pdf</a>, <a href="/format/2312.08361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Inference and Fine-tuning of Large Language Models Over The  Internet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borzunov%2C+A">Alexander Borzunov</a>, 
<a href="/search/cs?searchtype=author&query=Ryabinin%2C+M">Max Ryabinin</a>, 
<a href="/search/cs?searchtype=author&query=Chumachenko%2C+A">Artem Chumachenko</a>, 
<a href="/search/cs?searchtype=author&query=Baranchuk%2C+D">Dmitry Baranchuk</a>, 
<a href="/search/cs?searchtype=author&query=Dettmers%2C+T">Tim Dettmers</a>, 
<a href="/search/cs?searchtype=author&query=Belkada%2C+Y">Younes Belkada</a>, 
<a href="/search/cs?searchtype=author&query=Samygin%2C+P">Pavel Samygin</a>, 
<a href="/search/cs?searchtype=author&query=Raffel%2C+C">Colin Raffel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Conference on Neural Information Processing Systems (NeurIPS) 2023. 20 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Large language models (LLMs) are useful in many NLP tasks and become more
capable with size, with the best open-source models having over 50 billion
parameters. However, using these 50B+ models requires high-end hardware, making
them inaccessible to most researchers. In this work, we investigate methods for
cost-efficient inference and fine-tuning of LLMs, comparing local and
distributed strategies. We observe that a large enough model (50B+) can run
efficiently even on geodistributed devices in a consumer-grade network. This
could allow running LLM efficiently by pooling together idle compute resources
of multiple research groups and volunteers. We address two open problems: (1)
how to perform inference and fine-tuning reliably if any device can disconnect
abruptly and (2) how to partition LLMs between devices with uneven hardware,
joining and leaving at will. In order to do that, we develop special
fault-tolerant inference algorithms and load-balancing protocols that
automatically assign devices to maximize the total system throughput. We
showcase these algorithms in Petals - a decentralized system that runs Llama 2
(70B) and BLOOM (176B) over the Internet up to 10x faster than offloading for
interactive generation. We evaluate the performance of our system in simulated
conditions and a real-world setup spanning two continents.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08363" title="Abstract">arXiv:2312.08363</a> [<a href="/pdf/2312.08363" title="Download PDF">pdf</a>, <a href="/ps/2312.08363" title="Download PostScript">ps</a>, <a href="/format/2312.08363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Computational Hardness of Quantum One-Wayness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cavalar%2C+B">Bruno Cavalar</a>, 
<a href="/search/cs?searchtype=author&query=Goldin%2C+E">Eli Goldin</a>, 
<a href="/search/cs?searchtype=author&query=Gray%2C+M">Matthew Gray</a>, 
<a href="/search/cs?searchtype=author&query=Hall%2C+P">Peter Hall</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yanyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pelecanos%2C+A">Angelos Pelecanos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Abstract modified to fit ArXiv requirements
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computational Complexity (cs.CC); Quantum Physics (quant-ph)

</div>
<p class="mathjax">There is a large body of work studying what forms of computational hardness
are needed to realize classical cryptography. In particular, one-way functions
and pseudorandom generators can be built from each other, and thus require
equivalent computational assumptions to be realized. Furthermore, the existence
of either of these primitives implies that $\rm{P} \neq \rm{NP}$, which gives a
lower bound on the necessary hardness.
<br />One can also define versions of each of these primitives with quantum output:
respectively one-way state generators and pseudorandom state generators. Unlike
in the classical setting, it is not known whether either primitive can be built
from the other. Although it has been shown that pseudorandom state generators
for certain parameter regimes can be used to build one-way state generators,
the implication has not been previously known in full generality. Furthermore,
to the best of our knowledge, the existence of one-way state generators has no
known implications in complexity theory.
<br />We show that pseudorandom states compressing $n$ bits to $\log n + 1$ qubits
can be used to build one-way state generators and pseudorandom states
compressing $n$ bits to $\omega(\log n)$ qubits are one-way state generators.
This is a nearly optimal result since pseudorandom states with fewer than $c
\log n$-qubit output can be shown to exist unconditionally. We also show that
any one-way state generator can be broken by a quantum algorithm with classical
access to a $\rm{PP}$ oracle.
<br />An interesting implication of our results is that a $t(n)$-copy one-way state
generator exists unconditionally, for every $t(n) = o(n/\log n)$. This
contrasts nicely with the previously known fact that $O(n)$-copy one-way state
generators require computational hardness. We also outline a new route towards
a black-box separation between one-way state generators and quantum bit
commitments.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08364" title="Abstract">arXiv:2312.08364</a> [<a href="/pdf/2312.08364" title="Download PDF">pdf</a>, <a href="/format/2312.08364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> View-Dependent Octree-based Mesh Extraction in Unbounded Scenes for  Procedural Synthetic Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zeyu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Raistrick%2C+A">Alexander Raistrick</a>, 
<a href="/search/cs?searchtype=author&query=Lipson%2C+L">Lahav Lipson</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jia Deng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Procedural synthetic data generation has received increasing attention in
computer vision. Procedural signed distance functions (SDFs) are a powerful
tool for modeling large-scale detailed scenes, but existing mesh extraction
methods have artifacts or performance profiles that limit their use for
synthetic data. We propose OcMesher, a mesh extraction algorithm that
efficiently handles high-detail unbounded scenes with perfect view-consistency,
with easy export to downstream real-time engines. The main novelty of our
solution is an algorithm to construct an octree based on a given SDF and
multiple camera views. We performed extensive experiments, and show our
solution produces better synthetic data for training and evaluation of computer
vision models.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08365" title="Abstract">arXiv:2312.08365</a> [<a href="/pdf/2312.08365" title="Download PDF">pdf</a>, <a href="/format/2312.08365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Invitation to Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jaeger%2C+B">Bernhard Jaeger</a>, 
<a href="/search/cs?searchtype=author&query=Geiger%2C+A">Andreas Geiger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Training a deep neural network to maximize a target objective has become the
standard recipe for successful machine learning over the last decade. These
networks can be optimized with supervised learning, if the target objective is
differentiable. For many interesting problems, this is however not the case.
Common objectives like intersection over union (IoU), bilingual evaluation
understudy (BLEU) score or rewards cannot be optimized with supervised
learning. A common workaround is to define differentiable surrogate losses,
leading to suboptimal solutions with respect to the actual objective.
Reinforcement learning (RL) has emerged as a promising alternative for
optimizing deep neural networks to maximize non-differentiable objectives in
recent years. Examples include aligning large language models via human
feedback, code generation, object detection or control problems. This makes RL
techniques relevant to the larger machine learning audience. The subject is,
however, time intensive to approach due to the large range of methods, as well
as the often very theoretical presentation. In this introduction, we take an
alternative approach, different from classic reinforcement learning textbooks.
Rather than focusing on tabular problems, we introduce reinforcement learning
as a generalization of supervised learning, which we first apply to
non-differentiable objectives and later to temporal problems. Assuming only
basic knowledge of supervised learning, the reader will be able to understand
state-of-the-art deep RL algorithms like proximal policy optimization (PPO)
after reading this tutorial.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08366" title="Abstract">arXiv:2312.08366</a> [<a href="/pdf/2312.08366" title="Download PDF">pdf</a>, <a href="/format/2312.08366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> See, Say, and Segment: Teaching LMMs to Overcome False Premises
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tsung-Han Wu</a>, 
<a href="/search/cs?searchtype=author&query=Biamby%2C+G">Giscard Biamby</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+D">David Chan</a>, 
<a href="/search/cs?searchtype=author&query=Dunlap%2C+L">Lisa Dunlap</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+R">Ritwik Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xudong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+J+E">Joseph E. Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Darrell%2C+T">Trevor Darrell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://see-say-segment.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Current open-source Large Multimodal Models (LMMs) excel at tasks such as
open-vocabulary language grounding and segmentation but can suffer under false
premises when queries imply the existence of something that is not actually
present in the image. We observe that existing methods that fine-tune an LMM to
segment images significantly degrade their ability to reliably determine
("see") if an object is present and to interact naturally with humans ("say"),
a form of catastrophic forgetting. In this work, we propose a cascading and
joint training approach for LMMs to solve this task, avoiding catastrophic
forgetting of previous skills. Our resulting model can "see" by detecting
whether objects are present in an image, "say" by telling the user if they are
not, proposing alternative queries or correcting semantic errors in the query,
and finally "segment" by outputting the mask of the desired objects if they
exist. Additionally, we introduce a novel False Premise Correction benchmark
dataset, an extension of existing RefCOCO(+/g) referring segmentation datasets
(which we call FP-RefCOCO(+/g)). The results show that our method not only
detects false premises up to 55% better than existing approaches, but under
false premise conditions produces relative cIOU improvements of more than 31%
over baselines, and produces natural language feedback judged helpful up to 67%
of the time.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08367" title="Abstract">arXiv:2312.08367</a> [<a href="/pdf/2312.08367" title="Download PDF">pdf</a>, <a href="/format/2312.08367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VLAP: Efficient Video-Language Alignment via Frame Prompting and  Distilling for Video Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xijun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Junbang Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chun-Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+K">Kenan Deng</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+Y">Yu Lou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Ming Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shan Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this work, we propose an efficient Video-Language Alignment via
Frame-Prompting and Distilling (VLAP) network. Our VLAP model addresses both
efficient frame sampling and effective cross-modal alignment in a unified way.
In our VLAP network, we design a new learnable question-aware Frame-Prompter
together with a new cross-modal distillation (QFormer-Distiller) module.
Pre-trained large image-language models have shown promising results on
problems such as visual question answering. However, how to efficiently and
effectively sample image frames when adapting pre-trained large image-language
model to video-language alignment is still the major challenge. Compared with
prior work, our VLAP model demonstrates the capability of selecting key frames
with critical contents, thus improving the video-language alignment accuracy
while reducing the inference latency (+3.3% on NExT-QA Temporal with 3.0X speed
up). Overall, our VLAP network outperforms (e.g. +4.6% on STAR Interaction and
+2.2% on STAR average with 3.0X speed up, ours 2-frames out-perform SeViLA
4-frames on VLEP with 4.2X speed up) the state-of-the-art methods on the video
question-answering benchmarks.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08371" title="Abstract">arXiv:2312.08371</a> [<a href="/pdf/2312.08371" title="Download PDF">pdf</a>, <a href="/format/2312.08371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PTT: Point-Trajectory Transformer for Efficient Temporal 3D Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kuan-Chih Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+W">Weijie Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+Y">Yi-Hsuan Tsai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://github.com/kuanchihhuang/PTT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent temporal LiDAR-based 3D object detectors achieve promising performance
based on the two-stage proposal-based approach. They generate 3D box candidates
from the first-stage dense detector, followed by different temporal aggregation
methods. However, these approaches require per-frame objects or whole point
clouds, posing challenges related to memory bank utilization. Moreover, point
clouds and trajectory features are combined solely based on concatenation,
which may neglect effective interactions between them. In this paper, we
propose a point-trajectory transformer with long short-term memory for
efficient temporal 3D object detection. To this end, we only utilize point
clouds of current-frame objects and their historical trajectories as input to
minimize the memory bank storage requirement. Furthermore, we introduce modules
to encode trajectory features, focusing on long short-term and future-aware
perspectives, and then effectively aggregate them with point cloud features. We
conduct extensive experiments on the large-scale Waymo dataset to demonstrate
that our approach performs well against state-of-the-art methods. Code and
models will be made publicly available at https://github.com/kuanchihhuang/PTT.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08372" title="Abstract">arXiv:2312.08372</a> [<a href="/pdf/2312.08372" title="Download PDF">pdf</a>, <a href="/format/2312.08372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAM-guided Graph Cut for 3D Instance Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Haoyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">He Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Sida Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yujun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Ruizhen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaowei Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://zju3dv.github.io/sam_graph">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper addresses the challenge of 3D instance segmentation by
simultaneously leveraging 3D geometric and multi-view image information. Many
previous works have applied deep learning techniques to 3D point clouds for
instance segmentation. However, these methods often failed to generalize to
various types of scenes due to the scarcity and low-diversity of labeled 3D
point cloud data. Some recent works have attempted to lift 2D instance
segmentations to 3D within a bottom-up framework. The inconsistency in 2D
instance segmentations among views can substantially degrade the performance of
3D segmentation. In this work, we introduce a novel 3D-to-2D query framework to
effectively exploit 2D segmentation models for 3D instance segmentation.
Specifically, we pre-segment the scene into several superpoints in 3D,
formulating the task into a graph cut problem. The superpoint graph is
constructed based on 2D segmentation models, where node features are obtained
from multi-view image features and edge weights are computed based on
multi-view segmentation results, enabling the better generalization ability. To
process the graph, we train a graph neural network using pseudo 3D labels from
2D segmentation models. Experimental results on the ScanNet, ScanNet++ and
KITTI-360 datasets demonstrate that our method achieves robust segmentation
performance and can generalize across different types of scenes. Our project
page is available at https://zju3dv.github.io/sam_graph.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Thu, 14 Dec 23</h3>
<dl>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16426" title="Abstract">arXiv:2307.16426</a> (cross-list from eess.IV) [<a href="/pdf/2307.16426" title="Download PDF">pdf</a>, <a href="/format/2307.16426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High Dynamic Range Image Reconstruction via Deep Explicit Polynomial  Curve Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tang%2C+J">Jiaqi Tang</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+X">Xiaogang Xu</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+S">Sixing Hu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Ying-Cong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Due to limited camera capacities, digital images usually have a narrower
dynamic illumination range than real-world scene radiance. To resolve this
problem, High Dynamic Range (HDR) reconstruction is proposed to recover the
dynamic range to better represent real-world scenes. However, due to different
physical imaging parameters, the tone-mapping functions between images and real
radiance are highly diverse, which makes HDR reconstruction extremely
challenging. Existing solutions can not explicitly clarify a corresponding
relationship between the tone-mapping function and the generated HDR image, but
this relationship is vital when guiding the reconstruction of HDR images. To
address this problem, we propose a method to explicitly estimate the tone
mapping function and its corresponding HDR image in one network. Firstly, based
on the characteristics of the tone mapping function, we construct a model by a
polynomial to describe the trend of the tone curve. To fit this curve, we use a
learnable network to estimate the coefficients of the polynomial. This curve
will be automatically adjusted according to the tone space of the Low Dynamic
Range (LDR) image, and reconstruct the real HDR image. Besides, since all
current datasets do not provide the corresponding relationship between the tone
mapping function and the LDR image, we construct a new dataset with both
synthetic and real images. Extensive experiments show that our method
generalizes well under different tone-mapping functions and achieves SOTA
performance.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07546" title="Abstract">arXiv:2312.07546</a> (cross-list from eess.SP) [<a href="/pdf/2312.07546" title="Download PDF">pdf</a>, <a href="/ps/2312.07546" title="Download PostScript">ps</a>, <a href="/format/2312.07546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoding Working-Memory Load During n-Back Task Performance from High  Channel NIRS Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kothe%2C+C">Christian Kothe</a> (1), 
<a href="/search/eess?searchtype=author&query=Hanada%2C+G">Grant Hanada</a> (1), 
<a href="/search/eess?searchtype=author&query=Mullen%2C+S">Sean Mullen</a> (1), 
<a href="/search/eess?searchtype=author&query=Mullen%2C+T">Tim Mullen</a> (1) ((1) Intheon, La Jolla, United States)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 9 figures. Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Near-infrared spectroscopy (NIRS) can measure neural activity through blood
oxygenation changes in the brain in a wearable form factor, enabling unique
applications for research in and outside the lab. NIRS has proven capable of
measuring cognitive states such as mental workload, often using machine
learning (ML) based brain-computer interfaces (BCIs). To date, NIRS research
has largely relied on probes with under ten to several hundred channels,
although recently a new class of wearable NIRS devices with thousands of
channels has emerged. This poses unique challenges for ML classification, as
NIRS is typically limited by few training trials which results in severely
under-determined estimation problems. So far, it is not well understood how
such high-resolution data is best leveraged in practical BCIs and whether
state-of-the-art (SotA) or better performance can be achieved. To address these
questions, we propose an ML strategy to classify working-memory load that
relies on spatio-temporal regularization and transfer learning from other
subjects in a combination that has not been used in previous NIRS BCIs. The
approach can be interpreted as an end-to-end generalized linear model and
allows for a high degree of interpretability using channel-level or cortical
imaging approaches. We show that using the proposed methodology, it is possible
to achieve SotA decoding performance with high-resolution NIRS data. We also
replicated several SotA approaches on our dataset of 43 participants wearing a
3198 dual-channel NIRS device while performing the n-Back task and show that
these existing methods struggle in the high-channel regime and are largely
outperformed by the proposed method. Our approach helps establish high-channel
NIRS devices as a viable platform for SotA BCI and opens new applications using
this class of headset while also enabling high-resolution model imaging and
interpretation.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07547" title="Abstract">arXiv:2312.07547</a> (cross-list from q-bio.NC) [<a href="/pdf/2312.07547" title="Download PDF">pdf</a>, <a href="/format/2312.07547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Inference and Intentional Behaviour
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Friston%2C+K+J">Karl J. Friston</a>, 
<a href="/search/q-bio?searchtype=author&query=Salvatori%2C+T">Tommaso Salvatori</a>, 
<a href="/search/q-bio?searchtype=author&query=Isomura%2C+T">Takuya Isomura</a>, 
<a href="/search/q-bio?searchtype=author&query=Tschantz%2C+A">Alexander Tschantz</a>, 
<a href="/search/q-bio?searchtype=author&query=Kiefer%2C+A">Alex Kiefer</a>, 
<a href="/search/q-bio?searchtype=author&query=Verbelen%2C+T">Tim Verbelen</a>, 
<a href="/search/q-bio?searchtype=author&query=Koudahl%2C+M">Magnus Koudahl</a>, 
<a href="/search/q-bio?searchtype=author&query=Paul%2C+A">Aswin Paul</a>, 
<a href="/search/q-bio?searchtype=author&query=Parr%2C+T">Thomas Parr</a>, 
<a href="/search/q-bio?searchtype=author&query=Razi%2C+A">Adeel Razi</a>, 
<a href="/search/q-bio?searchtype=author&query=Kagan%2C+B">Brett Kagan</a>, 
<a href="/search/q-bio?searchtype=author&query=Buckley%2C+C+L">Christopher L. Buckley</a>, 
<a href="/search/q-bio?searchtype=author&query=Ramstead%2C+M+J+D">Maxwell J. D. Ramstead</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advances in theoretical biology suggest that basal cognition and
sentient behaviour are emergent properties of in vitro cell cultures and
neuronal networks, respectively. Such neuronal networks spontaneously learn
structured behaviours in the absence of reward or reinforcement. In this paper,
we characterise this kind of self-organisation through the lens of the free
energy principle, i.e., as self-evidencing. We do this by first discussing the
definitions of reactive and sentient behaviour in the setting of active
inference, which describes the behaviour of agents that model the consequences
of their actions. We then introduce a formal account of intentional behaviour,
that describes agents as driven by a preferred endpoint or goal in latent
state-spaces. We then investigate these forms of (reactive, sentient, and
intentional) behaviour using simulations. First, we simulate the aforementioned
in vitro experiments, in which neuronal cultures spontaneously learn to play
Pong, by implementing nested, free energy minimising processes. The simulations
are then used to deconstruct the ensuing predictive behaviour, leading to the
distinction between merely reactive, sentient, and intentional behaviour, with
the latter formalised in terms of inductive planning. This distinction is
further studied using simple machine learning benchmarks (navigation in a grid
world and the Tower of Hanoi problem), that show how quickly and efficiently
adaptive behaviour emerges under an inductive form of active inference.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07561" title="Abstract">arXiv:2312.07561</a> (cross-list from eess.SP) [<a href="/pdf/2312.07561" title="Download PDF">pdf</a>, <a href="/format/2312.07561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Annotating sleep states in children from wrist-worn accelerometer data  using Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ram%2C+A">Ashwin Ram</a>, 
<a href="/search/eess?searchtype=author&query=S.%2C+S+S+V">Sundar Sripada V. S.</a>, 
<a href="/search/eess?searchtype=author&query=Keshari%2C+S">Shuvam Keshari</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+Z">Zizhe Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Sleep detection and annotation are crucial for researchers to understand
sleep patterns, especially in children. With modern wrist-worn watches
comprising built-in accelerometers, sleep logs can be collected. However, the
annotation of these logs into distinct sleep events: onset and wakeup, proves
to be challenging. These annotations must be automated, precise, and scalable.
We propose to model the accelerometer data using different machine learning
(ML) techniques such as support vectors, boosting, ensemble methods, and more
complex approaches involving LSTMs and Region-based CNNs. Later, we aim to
evaluate these approaches using the Event Detection Average Precision (EDAP)
score (similar to the IOU metric) to eventually compare the predictive power
and model performance.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07570" title="Abstract">arXiv:2312.07570</a> (cross-list from quant-ph) [<a href="/pdf/2312.07570" title="Download PDF">pdf</a>, <a href="/ps/2312.07570" title="Download PostScript">ps</a>, <a href="/format/2312.07570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Private Information Retrieval from Coded Storage Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Allaix%2C+M">Matteo Allaix</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the summary part of an article collection-based PhD thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">In the era of extensive data growth, robust and efficient mechanisms are
needed to store and manage vast amounts of digital information, such as Data
Storage Systems (DSSs). Concurrently, privacy concerns have arisen, leading to
the development of techniques like Private Information Retrieval (PIR) to
enable data access while preserving privacy. A PIR protocol allows users to
retrieve information from a database without revealing the specifics of their
query or the data they are accessing.
<br />With the advent of quantum computing, researchers have explored the potential
of using quantum systems to enhance privacy in information retrieval. In a
Quantum Private Information Retrieval (QPIR) protocol, a user can retrieve
information from a database by downloading quantum systems from multiple
servers, while ensuring that the servers remain oblivious to the specific
information being accessed. This scenario offers a unique advantage by
leveraging the inherent properties of quantum systems to provide enhanced
privacy guarantees and improved communication rates compared to classical PIR
protocols.
<br />In this thesis we consider the QPIR setting where the queries and the coded
storage systems are classical, while the responses from the servers are
quantum. This problem was treated by Song et al. for replicated storage and
different collusion patterns. This thesis aims to develop QPIR protocols for
coded storage by combining known classical PIR protocols with quantum
communication algorithms, achieving enhanced privacy and communication costs.
We consider different storage codes and robustness assumptions, and we prove
that the achieved communication cost is always lower than the classical
counterparts.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07580" title="Abstract">arXiv:2312.07580</a> (cross-list from eess.IV) [<a href="/pdf/2312.07580" title="Download PDF">pdf</a>, <a href="/ps/2312.07580" title="Download PostScript">ps</a>, <a href="/format/2312.07580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COVID-19 Detection Using Slices Processing Techniques and a Modified  Xception Classifier from Computed Tomography Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Morani%2C+K">Kenan Morani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2207.00259">arXiv:2207.00259</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper extends our previous method for COVID-19 diagnosis, proposing an
enhanced solution for detecting COVID-19 from computed tomography (CT) images.
To decrease model misclassifications, two key steps of image processing were
employed. Firstly, the uppermost and lowermost slices were removed, preserving
sixty percent of each patient's slices. Secondly, all slices underwent manual
cropping to emphasize the lung areas. Subsequently, resized CT scans (224 by
224) were input into an Xception transfer learning model. Leveraging Xception's
architecture and pre-trained weights, the modified model achieved binary
classification. Promising results on the COV19-CT database showcased higher
validation accuracy and macro F1 score at both the slice and patient levels
compared to our previous solution and alternatives on the same dataset.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07601" title="Abstract">arXiv:2312.07601</a> (cross-list from eess.SP) [<a href="/pdf/2312.07601" title="Download PDF">pdf</a>, <a href="/format/2312.07601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-contact Multimodal Indoor Human Monitoring Systems: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+L+N">Le Ngu Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Susarla%2C+P">Praneeth Susarla</a>, 
<a href="/search/eess?searchtype=author&query=Mukherjee%2C+A">Anirban Mukherjee</a>, 
<a href="/search/eess?searchtype=author&query=Ca%C3%B1ellas%2C+M+L">Manuel Lage Ca&#xf1;ellas</a>, 
<a href="/search/eess?searchtype=author&query=Casado%2C+C+%C3%81">Constantino &#xc1;lvarez Casado</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+X">Xiaoting Wu</a>, 
<a href="/search/eess?searchtype=author&query=Silv%C3%A9n%2C+O">Olli~Silv&#xe9;n</a>, 
<a href="/search/eess?searchtype=author&query=Jayagopi%2C+D+B">Dinesh Babu Jayagopi</a>, 
<a href="/search/eess?searchtype=author&query=L%C3%B3pez%2C+M+B">Miguel Bordallo L&#xf3;pez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Indoor human monitoring systems leverage a wide range of sensors, including
cameras, radio devices, and inertial measurement units, to collect extensive
data from users and the environment. These sensors contribute diverse data
modalities, such as video feeds from cameras, received signal strength
indicators and channel state information from WiFi devices, and three-axis
acceleration data from inertial measurement units. In this context, we present
a comprehensive survey of multimodal approaches for indoor human monitoring
systems, with a specific focus on their relevance in elderly care. Our survey
primarily highlights non-contact technologies, particularly cameras and radio
devices, as key components in the development of indoor human monitoring
systems. Throughout this article, we explore well-established techniques for
extracting features from multimodal data sources. Our exploration extends to
methodologies for fusing these features and harnessing multiple modalities to
improve the accuracy and robustness of machine learning models. Furthermore, we
conduct comparative analysis across different data modalities in diverse human
monitoring tasks and undertake a comprehensive examination of existing
multimodal datasets. This extensive survey not only highlights the significance
of indoor human monitoring systems but also affirms their versatile
applications. In particular, we emphasize their critical role in enhancing the
quality of elderly care, offering valuable insights into the development of
non-contact monitoring solutions applicable to the needs of aging populations.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07602" title="Abstract">arXiv:2312.07602</a> (cross-list from eess.SP) [<a href="/pdf/2312.07602" title="Download PDF">pdf</a>, <a href="/format/2312.07602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sense, Predict, Adapt, Repeat: A Blueprint for Design of New Adaptive  AI-Centric Sensing Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hor%2C+S">Soheil Hor</a>, 
<a href="/search/eess?searchtype=author&query=Arbabian%2C+A">Amin Arbabian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">As Moore's Law loses momentum, improving size, performance, and efficiency of
processors has become increasingly challenging, ending the era of predictable
improvements in hardware performance. Meanwhile, the widespread incorporation
of high-definition sensors in consumer devices and autonomous technologies has
fueled a significant upsurge in sensory data. Current global trends reveal that
the volume of generated data already exceeds human consumption capacity, making
AI algorithms the primary consumers of data worldwide. To address this, a novel
approach to designing AI-centric sensing systems is needed that can bridge the
gap between the increasing capabilities of high-definition sensors and the
limitations of AI processors. This paper provides an overview of efficient
sensing and perception methods in both AI and sensing domains, emphasizing the
necessity of co-designing AI algorithms and sensing systems for dynamic
perception. The proposed approach involves a framework for designing and
analyzing dynamic AI-in-the-loop sensing systems, suggesting a fundamentally
new method for designing adaptive sensing systems through inference-time
AI-to-sensor feedback and end-to-end efficiency and performance optimization.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07609" title="Abstract">arXiv:2312.07609</a> (cross-list from eess.SP) [<a href="/pdf/2312.07609" title="Download PDF">pdf</a>, <a href="/format/2312.07609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IndoorGNN: A Graph Neural Network based approach for Indoor Localization  using WiFi RSSI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Vishwakarma%2C+R">Rahul Vishwakarma</a>, 
<a href="/search/eess?searchtype=author&query=Joshi%2C+R+B">Rucha Bhalchandra Joshi</a>, 
<a href="/search/eess?searchtype=author&query=Mishra%2C+S">Subhankar Mishra</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Lecture Notes in Computer Science, vol 14418, year 2023. Springer,
  Cham
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Indoor localization is the process of determining the location of a person or
object inside a building. Potential usage of indoor localization includes
navigation, personalization, safety and security, and asset tracking. Commonly
used technologies for indoor localization include WiFi, Bluetooth, RFID, and
Ultra-wideband. Among these, WiFi's Received Signal Strength Indicator
(RSSI)-based localization is preferred because of widely available WiFi Access
Points (APs). We have two main contributions. First, we develop our method,
'IndoorGNN' which involves using a Graph Neural Network (GNN) based algorithm
in a supervised manner to classify a specific location into a particular region
based on the RSSI values collected at that location. Most of the ML algorithms
that perform this classification require a large number of labeled data points
(RSSI vectors with location information). Collecting such data points is a
labor-intensive and time-consuming task. To overcome this challenge, as our
second contribution, we demonstrate the performance of IndoorGNN on the
restricted dataset. It shows a comparable prediction accuracy to that of the
complete dataset. We performed experiments on the UJIIndoorLoc and MNAV
datasets, which are real-world standard indoor localization datasets. Our
experiments show that IndoorGNN gives better location prediction accuracies
when compared with state-of-the-art existing conventional as well as GNN-based
methods for this same task. It continues to outperform these algorithms even
with restricted datasets. It is noteworthy that its performance does not
decrease a lot with a decrease in the number of available data points. Our
method can be utilized for navigation and wayfinding in complex indoor
environments, asset tracking and building management, enhancing mobile
applications with location-based services, and improving safety and security
during emergencies.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07631" title="Abstract">arXiv:2312.07631</a> (cross-list from physics.med-ph) [<a href="/pdf/2312.07631" title="Download PDF">pdf</a>, <a href="/format/2312.07631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-driven projection tomography with multicore fibre-optic cell rotation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Sun%2C+J">Jiawei Sun</a>, 
<a href="/search/physics?searchtype=author&query=Yang%2C+B">Bin Yang</a>, 
<a href="/search/physics?searchtype=author&query=Koukourakis%2C+N">Nektarios Koukourakis</a>, 
<a href="/search/physics?searchtype=author&query=Guck%2C+J">Jochen Guck</a>, 
<a href="/search/physics?searchtype=author&query=Czarske%2C+J+W">Juergen W. Czarske</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV); Biological Physics (physics.bio-ph); Optics (physics.optics)

</div>
<p class="mathjax">Optical tomography has emerged as a non-invasive imaging method, providing
three-dimensional insights into subcellular structures and thereby enabling a
deeper understanding of cellular functions, interactions, and processes.
Conventional optical tomography methods are constrained by a limited
illumination scanning range, leading to anisotropic resolution and incomplete
imaging of cellular structures. To overcome this problem, we employ a compact
multi-core fibre-optic cell rotator system that facilitates precise optical
manipulation of cells within a microfluidic chip, achieving full-angle
projection tomography with isotropic resolution. Moreover, we demonstrate an
AI-driven tomographic reconstruction workflow, which can be a paradigm shift
from conventional computational methods, often demanding manual processing, to
a fully autonomous process. The performance of the proposed cell rotation
tomography approach is validated through the three-dimensional reconstruction
of cell phantoms and HL60 human cancer cells. The versatility of this
learning-based tomographic reconstruction workflow paves the way for its broad
application across diverse tomographic imaging modalities, including but not
limited to flow cytometry tomography and acoustic rotation tomography.
Therefore, this AI-driven approach can propel advancements in cell biology,
aiding in the inception of pioneering therapeutics, and augmenting early-stage
cancer diagnostics.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07658" title="Abstract">arXiv:2312.07658</a> (cross-list from quant-ph) [<a href="/pdf/2312.07658" title="Download PDF">pdf</a>, <a href="/format/2312.07658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The hardness of quantum spin dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Park%2C+C">Chae-Yeun Park</a>, 
<a href="/search/quant-ph?searchtype=author&query=Casares%2C+P+A+M">Pablo A. M. Casares</a>, 
<a href="/search/quant-ph?searchtype=author&query=Arrazola%2C+J+M">Juan Miguel Arrazola</a>, 
<a href="/search/quant-ph?searchtype=author&query=Huh%2C+J">Joonsuk Huh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9+21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Statistical Mechanics (cond-mat.stat-mech); Computational Complexity (cs.CC)

</div>
<p class="mathjax">Recent experiments demonstrated quantum computational advantage in random
circuit sampling and Gaussian boson sampling. However, it is unclear whether
these experiments can lead to practical applications even after considerable
research effort. On the other hand, simulating the quantum coherent dynamics of
interacting spins has been considered as a potential first useful application
of quantum computers, providing a possible quantum advantage. Despite evidence
that simulating the dynamics of hundreds of interacting spins is challenging
for classical computers, concrete proof is yet to emerge. We address this
problem by proving that sampling from the output distribution generated by a
wide class of quantum spin Hamiltonians is a hard problem for classical
computers. Our proof is based on the Taylor series of the output probability,
which contains the permanent of a matrix as a coefficient when bipartite spin
interactions are considered. We devise a classical algorithm that extracts the
coefficient using an oracle estimating the output probability. Since
calculating the permanent is #P-hard, such an oracle does not exist unless the
polynomial hierarchy collapses. With an anticoncentration conjecture, the
hardness of the sampling task is also proven. Based on our proof, we estimate
that an instance involving about 200 spins will be challenging for classical
devices but feasible for intermediate-scale quantum computers with
fault-tolerant qubits.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07705" title="Abstract">arXiv:2312.07705</a> (cross-list from q-bio.NC) [<a href="/pdf/2312.07705" title="Download PDF">pdf</a>, <a href="/format/2312.07705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brain-optimized inference improves reconstructions of fMRI brain  activity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Kneeland%2C+R">Reese Kneeland</a>, 
<a href="/search/q-bio?searchtype=author&query=Ojeda%2C+J">Jordyn Ojeda</a>, 
<a href="/search/q-bio?searchtype=author&query=St-Yves%2C+G">Ghislain St-Yves</a>, 
<a href="/search/q-bio?searchtype=author&query=Naselaris%2C+T">Thomas Naselaris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures, submitted to the 2023 AAAI Workshop on Brain Encoding and Decoding. arXiv admin note: text overlap with <a href="/abs/2306.00927">arXiv:2306.00927</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The release of large datasets and developments in AI have led to dramatic
improvements in decoding methods that reconstruct seen images from human brain
activity. We evaluate the prospect of further improving recent decoding methods
by optimizing for consistency between reconstructions and brain activity during
inference. We sample seed reconstructions from a base decoding method, then
iteratively refine these reconstructions using a brain-optimized encoding model
that maps images to brain activity. At each iteration, we sample a small
library of images from an image distribution (a diffusion model) conditioned on
a seed reconstruction from the previous iteration. We select those that best
approximate the measured brain activity when passed through our encoding model,
and use these images for structural guidance during the generation of the small
library in the next iteration. We reduce the stochasticity of the image
distribution at each iteration, and stop when a criterion on the "width" of the
image distribution is met. We show that when this process is applied to recent
decoding methods, it outperforms the base decoding method as measured by human
raters, a variety of image feature metrics, and alignment to brain activity.
These results demonstrate that reconstruction quality can be significantly
improved by explicitly aligning decoding distributions to brain activity
distributions, even when the seed reconstruction is output from a
state-of-the-art decoding algorithm. Interestingly, the rate of refinement
varies systematically across visual cortex, with earlier visual areas generally
converging more slowly and preferring narrower image distributions, relative to
higher-level brain areas. Brain-optimized inference thus offers a succinct and
novel method for improving reconstructions and exploring the diversity of
representations across visual brain areas.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07729" title="Abstract">arXiv:2312.07729</a> (cross-list from eess.IV) [<a href="/pdf/2312.07729" title="Download PDF">pdf</a>, <a href="/ps/2312.07729" title="Download PostScript">ps</a>, <a href="/format/2312.07729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MedYOLO: A Medical Image Object Detection Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sobek%2C+J">Joseph Sobek</a>, 
<a href="/search/eess?searchtype=author&query=Inojosa%2C+J+R+M">Jose R. Medina Inojosa</a>, 
<a href="/search/eess?searchtype=author&query=Inojosa%2C+B+J+M">Betsy J. Medina Inojosa</a>, 
<a href="/search/eess?searchtype=author&query=Rassoulinejad-Mousavi%2C+S+M">S. M. Rassoulinejad-Mousavi</a>, 
<a href="/search/eess?searchtype=author&query=Conte%2C+G+M">Gian Marco Conte</a>, 
<a href="/search/eess?searchtype=author&query=Lopez-Jimenez%2C+F">Francisco Lopez-Jimenez</a>, 
<a href="/search/eess?searchtype=author&query=Erickson%2C+B+J">Bradley J. Erickson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Artificial intelligence-enhanced identification of organs, lesions, and other
structures in medical imaging is typically done using convolutional neural
networks (CNNs) designed to make voxel-accurate segmentations of the region of
interest. However, the labels required to train these CNNs are time-consuming
to generate and require attention from subject matter experts to ensure
quality. For tasks where voxel-level precision is not required, object
detection models offer a viable alternative that can reduce annotation effort.
Despite this potential application, there are few options for general purpose
object detection frameworks available for 3-D medical imaging. We report on
MedYOLO, a 3-D object detection framework using the one-shot detection method
of the YOLO family of models and designed for use with medical imaging. We
tested this model on four different datasets: BRaTS, LIDC, an abdominal organ
Computed Tomography (CT) dataset, and an ECG-gated heart CT dataset. We found
our models achieve high performance on commonly present medium and large-sized
structures such as the heart, liver, and pancreas even without hyperparameter
tuning. However, the models struggle with very small or rarely present
structures.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07737" title="Abstract">arXiv:2312.07737</a> (cross-list from math.DS) [<a href="/pdf/2312.07737" title="Download PDF">pdf</a>, <a href="/format/2312.07737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability of Ecological Systems: A Theoretical Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+C">Can Chen</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+X">Xu-Wen Wang</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+Y">Yang-Yu Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 57 pages, 14 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The stability of ecological systems is a fundamental concept in ecology,
which offers profound insights into species coexistence, biodiversity, and
community persistence. In this article, we provide a systematic and
comprehensive review on the theoretical frameworks for analyzing the stability
of ecological systems. Notably, we survey various stability notions, including
linear stability, sign stability, diagonal stability, D-stability, total
stability, structural stability, and higher-order stability. For each of these
stability notions, we examine necessary or sufficient conditions for achieving
such stability and demonstrate the intricate interplay of these conditions on
the network structures of ecological systems. Finally, we explore the future
prospects of these stability notions.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07770" title="Abstract">arXiv:2312.07770</a> (cross-list from math.OC) [<a href="/pdf/2312.07770" title="Download PDF">pdf</a>, <a href="/ps/2312.07770" title="Download PostScript">ps</a>, <a href="/format/2312.07770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Time-Inconsistency in Mean Field Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bayraktar%2C+E">Erhan Bayraktar</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+Z">Zhenhua Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Science and Game Theory (cs.GT); Probability (math.PR)

</div>
<p class="mathjax">We investigate an infinite-horizon time-inconsistent mean-field game (MFG) in
a discrete time setting. We first present a classic equilibrium for the MFG and
its associated existence result. This classic equilibrium aligns with the
conventional equilibrium concept studied in MFG literature when the context is
time-consistent. Then we demonstrate that while this equilibrium produces an
approximate optimal strategy when applied to the related $N$-agent games, it
does so solely in a precommitment sense. Therefore, it cannot function as a
genuinely approximate equilibrium strategy from the perspective of a
sophisticated agent within the $N$-agent game. To address this limitation, we
propose a new consistent equilibrium concept in both the MFG and the $N$-agent
game. We show that a consistent equilibrium in the MFG can indeed function as
an approximate consistent equilibrium in the $N$-agent game. Additionally, we
analyze the convergence of consistent equilibria for $N$-agent games toward a
consistent MFG equilibrium as $N$ tends to infinity.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07784" title="Abstract">arXiv:2312.07784</a> (cross-list from eess.IV) [<a href="/pdf/2312.07784" title="Download PDF">pdf</a>, <a href="/format/2312.07784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust MRI Reconstruction by Smoothed Unrolling (SMUG)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liang%2C+S">Shijun Liang</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+V+H+M">Van Hoang Minh Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Jia%2C+J">Jinghan Jia</a>, 
<a href="/search/eess?searchtype=author&query=Alkhouri%2C+I">Ismail Alkhouri</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+S">Sijia Liu</a>, 
<a href="/search/eess?searchtype=author&query=Ravishankar%2C+S">Saiprasad Ravishankar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">As the popularity of deep learning (DL) in the field of magnetic resonance
imaging (MRI) continues to rise, recent research has indicated that DL-based
MRI reconstruction models might be excessively sensitive to minor input
disturbances, including worst-case additive perturbations. This sensitivity
often leads to unstable, aliased images. This raises the question of how to
devise DL techniques for MRI reconstruction that can be robust to train-test
variations. To address this problem, we propose a novel image reconstruction
framework, termed Smoothed Unrolling (SMUG), which advances a deep
unrolling-based MRI reconstruction model using a randomized smoothing
(RS)-based robust learning approach. RS, which improves the tolerance of a
model against input noises, has been widely used in the design of adversarial
defense approaches for image classification tasks. Yet, we find that the
conventional design that applies RS to the entire DL-based MRI model is
ineffective. In this paper, we show that SMUG and its variants address the
above issue by customizing the RS process based on the unrolling architecture
of a DL-based MRI reconstruction model. Compared to the vanilla RS approach, we
show that SMUG improves the robustness of MRI reconstruction with respect to a
diverse set of instability sources, including worst-case and random noise
perturbations to input measurements, varying measurement sampling rates, and
different numbers of unrolling steps. Furthermore, we theoretically analyze the
robustness of our method in the presence of perturbations.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07788" title="Abstract">arXiv:2312.07788</a> (cross-list from math-ph) [<a href="/pdf/2312.07788" title="Download PDF">pdf</a>, <a href="/format/2312.07788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wasserstein speed limits for Langevin systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math-ph?searchtype=author&query=Sabbagh%2C+R">Ralph Sabbagh</a>, 
<a href="/search/math-ph?searchtype=author&query=Miangolarra%2C+O+M">Olga Movilla Miangolarra</a>, 
<a href="/search/math-ph?searchtype=author&query=Georgiou%2C+T+T">Tryphon T. Georgiou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Physics (math-ph)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">Physical systems transition between states with finite speed that is limited
by energetic costs. In this Letter, we derive bounds on transition times for
general Langevin systems that admit a decomposition into reversible and
irreversible dynamics, in terms of the Wasserstein distance between states and
the energetic costs associated with respective reversible and irreversible
currents. For illustration we discuss Brownian particles subject to arbitrary
forcing.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07792" title="Abstract">arXiv:2312.07792</a> (cross-list from math.ST) [<a href="/pdf/2312.07792" title="Download PDF">pdf</a>, <a href="/format/2312.07792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially private projection-depth-based medians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ramsay%2C+K">Kelly Ramsay</a>, 
<a href="/search/math?searchtype=author&query=Spicker%2C+D">Dylan Spicker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">We develop $(\epsilon,\delta)$-differentially private projection-depth-based
medians using the propose-test-release (PTR) and exponential mechanisms. Under
general conditions on the input parameters and the population measure, (e.g. we
do not assume any moment bounds), we quantify the probability the test in PTR
fails, as well as the cost of privacy via finite sample deviation bounds. We
demonstrate our main result on the canonical projection-depth-based median. In
the Gaussian setting, we show that the resulting deviation bound matches the
known lower bound for private Gaussian mean estimation, up to a polynomial
function of the condition number of the covariance matrix. In the Cauchy
setting, we show that the ``outlier error amplification'' effect resulting from
the heavy tails outweighs the cost of privacy. This result is then verified via
numerical simulations. Additionally, we present results on general PTR
mechanisms and a uniform concentration result on the projected spacings of
order statistics.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07821" title="Abstract">arXiv:2312.07821</a> (cross-list from quant-ph) [<a href="/pdf/2312.07821" title="Download PDF">pdf</a>, <a href="/format/2312.07821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Radio Signal Classification by Adversarially Robust Quantum Machine  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Wu%2C+Y">Yanqiu Wu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Adermann%2C+E">Eromanga Adermann</a>, 
<a href="/search/quant-ph?searchtype=author&query=Thapa%2C+C">Chandra Thapa</a>, 
<a href="/search/quant-ph?searchtype=author&query=Camtepe%2C+S">Seyit Camtepe</a>, 
<a href="/search/quant-ph?searchtype=author&query=Suzuki%2C+H">Hajime Suzuki</a>, 
<a href="/search/quant-ph?searchtype=author&query=Usman%2C+M">Muhammad Usman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Radio signal classification plays a pivotal role in identifying the
modulation scheme used in received radio signals, which is essential for
demodulation and proper interpretation of the transmitted information.
Researchers have underscored the high susceptibility of ML algorithms for radio
signal classification to adversarial attacks. Such vulnerability could result
in severe consequences, including misinterpretation of critical messages,
interception of classified information, or disruption of communication
channels. Recent advancements in quantum computing have revolutionized theories
and implementations of computation, bringing the unprecedented development of
Quantum Machine Learning (QML). It is shown that quantum variational
classifiers (QVCs) provide notably enhanced robustness against classical
adversarial attacks in image classification. However, no research has yet
explored whether QML can similarly mitigate adversarial threats in the context
of radio signal classification. This work applies QVCs to radio signal
classification and studies their robustness to various adversarial attacks. We
also propose the novel application of the approximate amplitude encoding (AAE)
technique to encode radio signal data efficiently. Our extensive simulation
results present that attacks generated on QVCs transfer well to CNN models,
indicating that these adversarial examples can fool neural networks that they
are not explicitly designed to attack. However, the converse is not true. QVCs
primarily resist the attacks generated on CNNs. Overall, with comprehensive
simulations, our results shed new light on the growing field of QML by bridging
knowledge gaps in QAML in radio signal classification and uncovering the
advantages of applying QML methods in practical applications.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07832" title="Abstract">arXiv:2312.07832</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2312.07832" title="Download PDF">pdf</a>, <a href="/ps/2312.07832" title="Download PostScript">ps</a>, <a href="/format/2312.07832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Denoising diffusion-based synthetic generation of three-dimensional (3D)  anisotropic microstructures from two-dimensional (2D) micrographs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Lee%2C+K">Kang-Hyun Lee</a>, 
<a href="/search/cond-mat?searchtype=author&query=Yun%2C+G+J">Gun Jin Yun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Integrated computational materials engineering (ICME) has significantly
enhanced the systemic analysis of the relationship between microstructure and
material properties, paving the way for the development of high-performance
materials. However, analyzing microstructure-sensitive material behavior
remains challenging due to the scarcity of three-dimensional (3D)
microstructure datasets. Moreover, this challenge is amplified if the
microstructure is anisotropic, as this results in anisotropic material
properties as well. In this paper, we present a framework for reconstruction of
anisotropic microstructures solely based on two-dimensional (2D) micrographs
using conditional diffusion-based generative models (DGMs). The proposed
framework involves spatial connection of multiple 2D conditional DGMs, each
trained to generate 2D microstructure samples for three different orthogonal
planes. The connected multiple reverse diffusion processes then enable
effective modeling of a Markov chain for transforming noise into a 3D
microstructure sample. Furthermore, a modified harmonized sampling is employed
to enhance the sample quality while preserving the spatial connection between
the slices of anisotropic microstructure samples in 3D space. To validate the
proposed framework, the 2D-to-3D reconstructed anisotropic microstructure
samples are evaluated in terms of both the spatial correlation function and the
physical material behavior. The results demonstrate that the framework is
capable of reproducing not only the statistical distribution of material phases
but also the material properties in 3D space. This highlights the potential
application of the proposed 2D-to-3D reconstruction framework in establishing
microstructure-property linkages, which could aid high-throughput material
design for future studies
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07839" title="Abstract">arXiv:2312.07839</a> (cross-list from math.ST) [<a href="/pdf/2312.07839" title="Download PDF">pdf</a>, <a href="/ps/2312.07839" title="Download PostScript">ps</a>, <a href="/format/2312.07839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimax-optimal estimation for sparse multi-reference alignment with  collision-free signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ghosh%2C+S">Subhro Ghosh</a>, 
<a href="/search/math?searchtype=author&query=Mukherjee%2C+S+S">Soumendu Sundar Mukherjee</a>, 
<a href="/search/math?searchtype=author&query=Pan%2C+J+B">Jing Bin Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Probability (math.PR); Machine Learning (stat.ML)

</div>
<p class="mathjax">The Multi-Reference Alignment (MRA) problem aims at the recovery of an
unknown signal from repeated observations under the latent action of a group of
cyclic isometries, in the presence of additive noise of high intensity
$\sigma$. It is a more tractable version of the celebrated cryo EM model. In
the crucial high noise regime, it is known that its sample complexity scales as
$\sigma^6$. Recent investigations have shown that for the practically
significant setting of sparse signals, the sample complexity of the maximum
likelihood estimator asymptotically scales with the noise level as $\sigma^4$.
In this work, we investigate minimax optimality for signal estimation under the
MRA model for so-called collision-free signals. In particular, this signal
class covers the setting of generic signals of dilute sparsity (wherein the
support size $s=O(L^{1/3})$, where $L$ is the ambient dimension.
<br />We demonstrate that the minimax optimal rate of estimation in for the sparse
MRA problem in this setting is $\sigma^2/\sqrt{n}$, where $n$ is the sample
size. In particular, this widely generalizes the sample complexity asymptotics
for the restricted MLE in this setting, establishing it as the statistically
optimal estimator. Finally, we demonstrate a concentration inequality for the
restricted MLE on its deviations from the ground truth.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07882" title="Abstract">arXiv:2312.07882</a> (cross-list from stat.ME) [<a href="/pdf/2312.07882" title="Download PDF">pdf</a>, <a href="/format/2312.07882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A non-parametric approach for estimating consumer valuation  distributions using second price auctions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Mukherjee%2C+S">Sourav Mukherjee</a>, 
<a href="/search/stat?searchtype=author&query=Patra%2C+R+K">Rohit K Patra</a>, 
<a href="/search/stat?searchtype=author&query=Khare%2C+K">Kshitij Khare</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Computer Science and Game Theory (cs.GT); Applications (stat.AP)

</div>
<p class="mathjax">We focus on online second price auctions, where bids are made sequentially,
and the winning bidder pays the maximum of the second-highest bid and a seller
specified reserve price. For many such auctions, the seller does not see all
the bids or the total number of bidders accessing the auction, and only
observes the current selling prices throughout the course of the auction. We
develop a novel non-parametric approach to estimate the underlying consumer
valuation distribution based on this data. Previous non-parametric approaches
in the literature only use the final selling price and assume knowledge of the
total number of bidders. The resulting estimate, in particular, can be used by
the seller to compute the optimal profit-maximizing price for the product. Our
approach is free of tuning parameters, and we demonstrate its computational and
statistical efficiency in a variety of simulation settings, and also on an Xbox
7-day auction dataset on eBay.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07889" title="Abstract">arXiv:2312.07889</a> (cross-list from math.OC) [<a href="/pdf/2312.07889" title="Download PDF">pdf</a>, <a href="/format/2312.07889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Isogeometric Topology Optimization of Shell Structures based on  PHT-splines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wen%2C+Z">Zepeng Wen</a>, 
<a href="/search/math?searchtype=author&query=Pan%2C+Q">Qiong Pan</a>, 
<a href="/search/math?searchtype=author&query=Zhai%2C+X">Xiaoya Zhai</a>, 
<a href="/search/math?searchtype=author&query=Kang%2C+H">Hongmei Kang</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+F">Falai Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computational Engineering, Finance, and Science (cs.CE); Computational Geometry (cs.CG); Graphics (cs.GR)

</div>
<p class="mathjax">This paper proposes an Adaptive Isogeometric Topology Optimization framework
for shell structures based on PHT-splines (PHT-AITO). In this framework, the
design domain, displacement, and density are represented by PHT-splines.
Leveraging the local refinement capability of PHT-splines, mesh elements
defining the density function are adaptively refined to achieve a suitable
resolution at the interface between solid and void regions. This addresses the
issue of excessive degrees of freedom resulting from global refinement. The
refinement of the mesh elements is driven by their density. During the
optimization of the density on a refined mesh, the initial value of the density
is inherited from the optimization results on the previous mesh to accelerate
the iteration process and maintain the stability of the optimized structure.
Numerical experiments on various shell structures have verified the
effectiveness of PHT-AITO. Compared with isogeometric topology optimization
based on tensor-product splines, PHT-AITO can significantly reduce the degrees
of freedom in the optimization problem, thereby improving computational
efficiency.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07899" title="Abstract">arXiv:2312.07899</a> (cross-list from q-bio.QM) [<a href="/pdf/2312.07899" title="Download PDF">pdf</a>, <a href="/ps/2312.07899" title="Download PostScript">ps</a>, <a href="/format/2312.07899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Morphological Profiling for Drug Discovery in the Era of Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Tang%2C+Q">Qiaosi Tang</a>, 
<a href="/search/q-bio?searchtype=author&query=Ratnayake%2C+R">Ranjala Ratnayake</a>, 
<a href="/search/q-bio?searchtype=author&query=Seabra%2C+G">Gustavo Seabra</a>, 
<a href="/search/q-bio?searchtype=author&query=Jiang%2C+Z">Zhe Jiang</a>, 
<a href="/search/q-bio?searchtype=author&query=Fang%2C+R">Ruogu Fang</a>, 
<a href="/search/q-bio?searchtype=author&query=Cui%2C+L">Lina Cui</a>, 
<a href="/search/q-bio?searchtype=author&query=Ding%2C+Y">Yousong Ding</a>, 
<a href="/search/q-bio?searchtype=author&query=Kahveci%2C+T">Tamer Kahveci</a>, 
<a href="/search/q-bio?searchtype=author&query=Bian%2C+J">Jiang Bian</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+C">Chenglong Li</a>, 
<a href="/search/q-bio?searchtype=author&query=Luesch%2C+H">Hendrik Luesch</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+Y">Yanjun Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 5 figure, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Morphological profiling is a valuable tool in phenotypic drug discovery. The
advent of high-throughput automated imaging has enabled the capturing of a wide
range of morphological features of cells or organisms in response to
perturbations at the single-cell resolution. Concurrently, significant advances
in machine learning and deep learning, especially in computer vision, have led
to substantial improvements in analyzing large-scale high-content images at
high-throughput. These efforts have facilitated understanding of compound
mechanism-of-action (MOA), drug repurposing, characterization of cell
morphodynamics under perturbation, and ultimately contributing to the
development of novel therapeutics. In this review, we provide a comprehensive
overview of the recent advances in the field of morphological profiling. We
summarize the image profiling analysis workflow, survey a broad spectrum of
analysis strategies encompassing feature engineering- and deep learning-based
approaches, and introduce publicly available benchmark datasets. We place a
particular emphasis on the application of deep learning in this pipeline,
covering cell segmentation, image representation learning, and multimodal
learning. Additionally, we illuminate the application of morphological
profiling in phenotypic drug discovery and highlight potential challenges and
opportunities in this field.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07911" title="Abstract">arXiv:2312.07911</a> (cross-list from eess.IV) [<a href="/pdf/2312.07911" title="Download PDF">pdf</a>, <a href="/ps/2312.07911" title="Download PostScript">ps</a>, <a href="/format/2312.07911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Projective Parallel Single-Pixel Imaging: 3D Structured Light Scanning  Under Global Illumination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yuxi Li</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+H">Hongzhi Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+H">Huijie Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xudong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages,13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We present projective parallel single-pixel imaging (pPSI), a 3D photography
method that provides a robust and efficient way to analyze the light transport
behavior and enables separation of light effect due to global illumination,
thereby achieving 3D structured light scanning under global illumination. The
light transport behavior is described by the light transport coefficients
(LTC), which contain complete information for a projector camera pair, and is a
4D data set. However, the capture of LTC is generally time consuming. The 4D
LTC in pPSI are reduced to projection functions, thereby enabling a highly
efficient data capture process. We introduce the local maximum constraint,
which provides constraint for the location of candidate correspondence matching
points when projections are captured. Local slice extension (LSE) method is
introduced to accelerate the capture of projection functions. Optimization is
conducted for pPSI under several situations. The number of projection functions
required for pPSI is optimized and the influence of capture ratio in LSE on the
accuracy of the correspondence matching points is investigated. Discussions and
experiments include two typical kinds of global illuminations:
inter-reflections and subsurface scattering. The proposed method is validated
with several challenging scenarios, and outperforms the state-of-the-art
methods.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07928" title="Abstract">arXiv:2312.07928</a> (cross-list from eess.SP) [<a href="/pdf/2312.07928" title="Download PDF">pdf</a>, <a href="/ps/2312.07928" title="Download PostScript">ps</a>, <a href="/format/2312.07928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian inversion of GPR waveforms for uncertainty-aware sub-surface  material characterization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Aziz%2C+I">Ishfaq Aziz</a>, 
<a href="/search/eess?searchtype=author&query=Soltanaghai%2C+E">Elahe Soltanaghai</a>, 
<a href="/search/eess?searchtype=author&query=Watts%2C+A">Adam Watts</a>, 
<a href="/search/eess?searchtype=author&query=Alipour%2C+M">Mohamad Alipour</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Total 30 pages, 17 Figures. This paper has been submitted to a journal but has not been published yet
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Applications (stat.AP)

</div>
<p class="mathjax">Accurate estimation of sub-surface properties like moisture content and depth
of layers is crucial for applications spanning sub-surface condition
monitoring, precision agriculture, and effective wildfire risk assessment. Soil
in nature is often covered by overlaying surface material, making its
characterization using conventional methods challenging. In addition, the
estimation of the properties of the overlaying layer is crucial for
applications like wildfire assessment. This study thus proposes a Bayesian
model-updating-based approach for ground penetrating radar (GPR) waveform
inversion to predict sub-surface properties like the moisture contents and
depths of the soil layer and overlaying material accumulated above the soil.
The dielectric permittivity of material layers were predicted with the proposed
method, along with other parameters, including depth and electrical
conductivity of layers. The proposed Bayesian model updating approach yields
probabilistic estimates of these parameters that can provide information about
the confidence and uncertainty related to the estimates. The methodology was
evaluated for a diverse range of experimental data collected through laboratory
and field investigations. Laboratory investigations included variations in soil
moisture values and depth of the top layer (or overlaying material), and the
field investigation included measurement of field soil moisture for sixteen
days. The results demonstrated predictions consistent with time-domain
reflectometry (TDR) measurements and conventional gravimetric tests. The top
layer depth could also be predicted with reasonable accuracy. The proposed
method provides a promising approach for uncertainty-aware sub-surface
parameter estimation that can enable decision-making for risk assessment across
a wide range of applications.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07932" title="Abstract">arXiv:2312.07932</a> (cross-list from quant-ph) [<a href="/pdf/2312.07932" title="Download PDF">pdf</a>, <a href="/format/2312.07932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Framework Based on Variational Quantum Algorithms:  Revolutionizing Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+Y">Yixiong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Image classification is a crucial task in machine learning. In recent years,
this field has witnessed rapid development, with a series of image
classification models being proposed and achieving state-of-the-art (SOTA)
results. Parallelly, with the advancement of quantum technologies, quantum
machine learning has attracted a lot of interest. In particular, a class of
algorithms known as variational quantum algorithms (VQAs) has been extensively
studied to improve the performance of classical machine learning. In this
paper, we propose a novel image classification framework using VQAs. The major
advantage of our framework is the elimination of the need for the global
pooling operation typically performed at the end of classical image
classification models. While global pooling can help to reduce computational
complexity, it often results in a significant loss of information. By removing
the global pooling module before the output layer, our approach allows for
effectively capturing more discriminative features and fine-grained details in
images, leading to improved classification performance. Moreover, employing
VQAs enables our framework to have fewer parameters compared to the classical
framework, even in the absence of global pooling, which makes it more
advantageous in preventing overfitting. We apply our method to different SOTA
image classification models and demonstrate the superiority of the proposed
quantum architecture over its classical counterpart through a series of
experiments on public datasets.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07934" title="Abstract">arXiv:2312.07934</a> (cross-list from eess.IV) [<a href="/pdf/2312.07934" title="Download PDF">pdf</a>, <a href="/format/2312.07934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Real World Stereo Image Super-Resolution via Hybrid Degradation  Model and Discriminator for Implied Stereo Image Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Yuanbo Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Xue%2C+Y">Yuyang Xue</a>, 
<a href="/search/eess?searchtype=author&query=Bi%2C+J">Jiang Bi</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+W">Wenlin He</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xinlin Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jiajun Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Deng%2C+W">Wei Deng</a>, 
<a href="/search/eess?searchtype=author&query=Nie%2C+R">Ruofeng Nie</a>, 
<a href="/search/eess?searchtype=author&query=Lan%2C+J">Junlin Lan</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+Q">Qinquan Gao</a>, 
<a href="/search/eess?searchtype=author&query=Tong%2C+T">Tong Tong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Real-world stereo image super-resolution has a significant influence on
enhancing the performance of computer vision systems. Although existing methods
for single-image super-resolution can be applied to improve stereo images,
these methods often introduce notable modifications to the inherent disparity,
resulting in a loss in the consistency of disparity between the original and
the enhanced stereo images. To overcome this limitation, this paper proposes a
novel approach that integrates a implicit stereo information discriminator and
a hybrid degradation model. This combination ensures effective enhancement
while preserving disparity consistency. The proposed method bridges the gap
between the complex degradations in real-world stereo domain and the simpler
degradations in real-world single-image super-resolution domain. Our results
demonstrate impressive performance on synthetic and real datasets, enhancing
visual perception while maintaining disparity consistency. The complete code is
available at the following \href{https://github.com/fzuzyb/SCGLANet}{link}.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07952" title="Abstract">arXiv:2312.07952</a> (cross-list from stat.ML) [<a href="/pdf/2312.07952" title="Download PDF">pdf</a>, <a href="/format/2312.07952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-learning to Calibrate Gaussian Processes with Deep Kernels for  Regression Uncertainty Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Iwata%2C+T">Tomoharu Iwata</a>, 
<a href="/search/stat?searchtype=author&query=Kumagai%2C+A">Atsutoshi Kumagai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Although Gaussian processes (GPs) with deep kernels have been successfully
used for meta-learning in regression tasks, its uncertainty estimation
performance can be poor. We propose a meta-learning method for calibrating deep
kernel GPs for improving regression uncertainty estimation performance with a
limited number of training data. The proposed method meta-learns how to
calibrate uncertainty using data from various tasks by minimizing the test
expected calibration error, and uses the knowledge for unseen tasks. We design
our model such that the adaptation and calibration for each task can be
performed without iterative procedures, which enables effective meta-learning.
In particular, a task-specific uncalibrated output distribution is modeled by a
GP with a task-shared encoder network, and it is transformed to a calibrated
one using a cumulative density function of a task-specific Gaussian mixture
model (GMM). By integrating the GP and GMM into our neural network-based model,
we can meta-learn model parameters in an end-to-end fashion. Our experiments
demonstrate that the proposed method improves uncertainty estimation
performance while keeping high regression performance compared with the
existing methods using real-world datasets in few-shot settings.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07962" title="Abstract">arXiv:2312.07962</a> (cross-list from math.CO) [<a href="/pdf/2312.07962" title="Download PDF">pdf</a>, <a href="/format/2312.07962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Treewidth is Polynomial in Maximum Degree on Graphs Excluding a Planar  Induced Minor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bonnet%2C+%C3%89">&#xc9;douard Bonnet</a>, 
<a href="/search/math?searchtype=author&query=Hodor%2C+J">J&#x119;drzej Hodor</a>, 
<a href="/search/math?searchtype=author&query=Korhonen%2C+T">Tuukka Korhonen</a>, 
<a href="/search/math?searchtype=author&query=Masa%C5%99%C3%ADk%2C+T">Tom&#xe1;&#x161; Masa&#x159;&#xed;k</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">A graph $G$ contains a graph $H$ as an induced minor if $H$ can be obtained
from $G$ by vertex deletions and edge contractions. We show that for every
$k$-vertex planar graph $H$, every graph $G$ excluding $H$ as an induced minor
has treewidth at most $\Delta(G)^{2^{O(k)}}$ where $\Delta(G)$ denotes the
maximum degree of $G$. Previously, Korhonen [JCTB '23] has shown the upper
bound of $k^{O(1)} 2^{\Delta(G)^5}$ whose dependence in $\Delta(G)$ is
exponential. More precisely, we show that every graph $G$ excluding as induced
minors a $k$-vertex planar graph and a $q$-vertex graph has treewidth at most
$k^{O(1)} \cdot \Delta(G)^{f(q)}$ with $f(q) = 2^{O(q)}$. A direct consequence
of our result is that for every hereditary graph class $\mathcal C$, if graphs
of $\mathcal C$ have treewidth bounded by a function of their maximum degree,
then they in fact have treewidth polynomial in their maximum degree.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07965" title="Abstract">arXiv:2312.07965</a> (cross-list from eess.IV) [<a href="/pdf/2312.07965" title="Download PDF">pdf</a>, <a href="/format/2312.07965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pneumonia Detection on chest X-ray images Using Ensemble of Deep  Convolutional Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mabrouk%2C+A">Alhassan Mabrouk</a>, 
<a href="/search/eess?searchtype=author&query=Redondo%2C+R+P+D">Rebeca P. D&#xed;az Redondo</a>, 
<a href="/search/eess?searchtype=author&query=Dahou%2C+A">Abdelghani Dahou</a>, 
<a href="/search/eess?searchtype=author&query=Elaziz%2C+M+A">Mohamed Abd Elaziz</a>, 
<a href="/search/eess?searchtype=author&query=Kayed%2C+M">Mohammed Kayed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 figures, journal
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Applied Sciences, 2022, vol. 12, no 13, p. 6448
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Pneumonia is a life-threatening lung infection resulting from several
different viral infections. Identifying and treating pneumonia on chest X-ray
images can be difficult due to its similarity to other pulmonary diseases.
Thus, the existing methods for predicting pneumonia cannot attain substantial
levels of accuracy. Therefore, this paper presents a computer-aided
classification of pneumonia, coined as Ensemble Learning (EL), to simplify the
diagnosis process on chest X-ray images. Our proposal is based on Convolutional
Neural Network (CNN) models, which are pre-trained CNN models that have been
recently employed to enhance the performance of many medical tasks instead of
training CNN models from scratch. We propose to use three well-known CNN
pre-trained (DenseNet169, MobileNetV2 and Vision Transformer) using the
ImageNet database. Then, these models are trained on the chest X-ray data set
using fine-tuning. Finally, the results are obtained by combining the extracted
features from these three models during the experimental phase. The proposed EL
approach outperforms other existing state-of-the-art methods, and it obtains an
accuracy of 93.91% and a F1-Score of 93.88% on the testing phase.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07977" title="Abstract">arXiv:2312.07977</a> (cross-list from q-bio.CB) [<a href="/pdf/2312.07977" title="Download PDF">pdf</a>, <a href="/format/2312.07977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling non-genetic information dynamics in cells using reservoir  computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Niraula%2C+D">Dipesh Niraula</a> (1), 
<a href="/search/q-bio?searchtype=author&query=Naqa%2C+I+E">Issam El Naqa</a> (1), 
<a href="/search/q-bio?searchtype=author&query=Tuszynski%2C+J+A">Jack Adam Tuszynski</a> (2), 
<a href="/search/q-bio?searchtype=author&query=Gatenby%2C+R+A">Robert A. Gatenby</a> (3) ((1) Department of Machine Learning, Moffitt Cancer Center, Tampa, FL, USA (2) Departments of Physics and Oncology, University of Alberta, Edmonton, AB, CAN (3) Departments of Radiology and Integrated Mathematical Oncology, Moffitt Cancer Center, Tampa, FL, USA)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main text: 18 pages, 1 table, and 8 figures; Supplementary materials: 14 pages, 18 figures; Link to Source code and Data included
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cell Behavior (q-bio.CB)</span>; Machine Learning (cs.LG); Biological Physics (physics.bio-ph)

</div>
<p class="mathjax">Virtually all cells use energy and ion-specific membrane pumps to maintain
large transmembrane gradients of Na$^+$, K$^+$, Cl$^-$, Mg$^{++}$, and
Ca$^{++}$. Although they consume up to 1/3 of a cell's energy budget, the
corresponding evolutionary benefit of transmembrane ion gradients remain
unclear. Here, we propose that ion gradients enable a dynamic and versatile
biological system that acquires, analyzes, and responds to environmental
information. We hypothesize environmental signals are transmitted into the cell
by ion fluxes along pre-existing gradients through gated ion-specific membrane
channels. The consequent changes of cytoplasmic ion concentration can generate
a local response and orchestrate global or regional responses through wire-like
ion fluxes along pre-existing and self-assembling cytoskeleton to engage the
endoplasmic reticulum, mitochondria, and nucleus.
<br />Here, we frame our hypothesis through a quasi-physical (Cell-Reservoir) model
that treats intra-cellular ion-based information dynamics as a sub-cellular
process permitting spatiotemporally resolved cellular response that is also
capable of learning complex nonlinear dynamical cellular behavior. We
demonstrate the proposed ion dynamics permits rapid dissemination of response
to information extrinsic perturbations that is consistent with experimental
observations.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08034" title="Abstract">arXiv:2312.08034</a> (cross-list from eess.IV) [<a href="/pdf/2312.08034" title="Download PDF">pdf</a>, <a href="/format/2312.08034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Individualized Deepfake Detection Exploiting Traces Due to Double  Neural-Network Operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rahman%2C+M">Mushfiqur Rahman</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+R">Runze Liu</a>, 
<a href="/search/eess?searchtype=author&query=Wong%2C+C">Chau-Wai Wong</a>, 
<a href="/search/eess?searchtype=author&query=Dai%2C+H">Huaiyu Dai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">In today's digital landscape, journalists urgently require tools to verify
the authenticity of facial images and videos depicting specific public figures
before incorporating them into news stories. Existing deepfake detectors are
not optimized for this detection task when an image is associated with a
specific and identifiable individual. This study focuses on the deepfake
detection of facial images of individual public figures. We propose to
condition the proposed detector on the identity of the identified individual
given the advantages revealed by our theory-driven simulations. While most
detectors in the literature rely on perceptible or imperceptible artifacts
present in deepfake facial images, we demonstrate that the detection
performance can be improved by exploiting the idempotency property of neural
networks. In our approach, the training process involves double neural-network
operations where we pass an authentic image through a deepfake simulating
network twice. Experimental results show that the proposed method improves the
area under the curve (AUC) from 0.92 to 0.94 and reduces its standard deviation
by 17\%. For evaluating the detection performance of individual public figures,
a facial image dataset with individuals' names is required, a criterion not met
by the current deepfake datasets. To address this, we curated a dataset
comprising 32k images featuring 45 public figures, which we intend to release
to the public after the paper is published.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08044" title="Abstract">arXiv:2312.08044</a> (cross-list from quant-ph) [<a href="/pdf/2312.08044" title="Download PDF">pdf</a>, <a href="/ps/2312.08044" title="Download PostScript">ps</a>, <a href="/format/2312.08044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strong Error Bounds for Trotter &amp; Strang-Splittings and Their  Implications for Quantum Chemistry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Burgarth%2C+D">Daniel Burgarth</a>, 
<a href="/search/quant-ph?searchtype=author&query=Facchi%2C+P">Paolo Facchi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hahn%2C+A">Alexander Hahn</a>, 
<a href="/search/quant-ph?searchtype=author&query=Johnsson%2C+M">Mattias Johnsson</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yuasa%2C+K">Kazuya Yuasa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 49 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Mathematical Physics (math-ph); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Efficient error estimates for the Trotter product formula are central in
quantum computing, mathematical physics, and numerical simulations. However,
the Trotter error's dependency on the input state and its application to
unbounded operators remains unclear. Here, we present a general theory for
error estimation, including higher-order product formulas, with explicit input
state dependency. Our approach overcomes two limitations of the existing
operator-norm estimates in the literature. First, previous bounds are too
pessimistic as they quantify the worst-case scenario. Second, previous bounds
become trivial for unbounded operators and cannot be applied to a wide class of
Trotter scenarios, including atomic and molecular Hamiltonians. Our method
enables analytical treatment of Trotter errors in chemistry simulations,
illustrated through a case study on the hydrogen atom. Our findings reveal: (i)
for states with fat-tailed energy distribution, such as low-angular-momentum
states of the hydrogen atom, the Trotter error scales worse than expected
(sublinearly) in the number of Trotter steps; (ii) certain states do not admit
an advantage in the scaling from higher-order Trotterization, and thus, the
higher-order Trotter hierarchy breaks down for these states, including the
hydrogen atom's ground state; (iii) the scaling of higher-order Trotter bounds
might depend on the order of the Hamiltonians in the Trotter product for states
with fat-tailed energy distribution. Physically, the enlarged Trotter error is
caused by the atom's ionization due to the Trotter dynamics. Mathematically, we
find that certain domain conditions are not satisfied by some states so higher
moments of the potential and kinetic energies diverge. Our analytical error
analysis agrees with numerical simulations, indicating that we can estimate the
state-dependent Trotter error scaling genuinely.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08074" title="Abstract">arXiv:2312.08074</a> (cross-list from math.OC) [<a href="/pdf/2312.08074" title="Download PDF">pdf</a>, <a href="/format/2312.08074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PySCIPOpt-ML: Embedding Trained Machine Learning Models into  Mixed-Integer Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Turner%2C+M">Mark Turner</a>, 
<a href="/search/math?searchtype=author&query=Chmiela%2C+A">Antonia Chmiela</a>, 
<a href="/search/math?searchtype=author&query=Koch%2C+T">Thorsten Koch</a>, 
<a href="/search/math?searchtype=author&query=Winkler%2C+M">Michael Winkler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">A standard tool for modelling real-world optimisation problems is
mixed-integer programming (MIP). However, for many of these problems there is
either incomplete information describing variable relations, or the relations
between variables are highly complex. To overcome both these hurdles, machine
learning (ML) models are often used and embedded in the MIP as surrogate models
to represent these relations. Due to the large amount of available ML
frameworks, formulating ML models into MIPs is highly non-trivial. In this
paper we propose a tool for the automatic MIP formulation of trained ML models,
allowing easy integration of ML constraints into MIPs. In addition, we
introduce a library of MIP instances with embedded ML constraints. The project
is available at https://github.com/Opt-Mucca/PySCIPOpt-ML.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08083" title="Abstract">arXiv:2312.08083</a> (cross-list from stat.ML) [<a href="/pdf/2312.08083" title="Download PDF">pdf</a>, <a href="/ps/2312.08083" title="Download PostScript">ps</a>, <a href="/format/2312.08083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training of Neural Networks with Uncertain Data, A Mixture of Experts  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Luttner%2C+L">Lucas Luttner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper presents the "Uncertainty-aware Mixture of Experts" (uMoE), a
novel approach designed to address aleatoric uncertainty in the training of
predictive models based on Neural Networks (NNs). While existing methods
primarily focus on managing uncertainty during infer-ence, uMoE integrates
uncertainty directly into the train-ing process. The uMoE approach adopts a
"Divide and Conquer" paradigm to partition the uncertain input space into more
manageable subspaces. It consists of Expert components, each trained solely on
the portion of input uncertainty corresponding to their subspace. On top of the
Experts, a Gating Unit, guided by additional infor-mation about the
distribution of uncertain inputs across these subspaces, learns to weight the
Experts to minimize deviations from the ground truth. Our results highlight
that uMoE significantly outperforms baseline methods in handling data
uncertainty. Furthermore, we conducted a robustness analysis, illustrating its
capability to adapt to varying levels of uncertainty and suggesting optimal
threshold parameters. This innovative approach holds wide applicability across
diverse data-driven domains, in-cluding biomedical signal processing,
autonomous driv-ing, and production quality control.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08132" title="Abstract">arXiv:2312.08132</a> (cross-list from eess.AS) [<a href="/pdf/2312.08132" title="Download PDF">pdf</a>, <a href="/ps/2312.08132" title="Download PostScript">ps</a>, <a href="/format/2312.08132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultra Low Complexity Deep Learning Based Noise Suppression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shetu%2C+S+S">Shrishti Saha Shetu</a>, 
<a href="/search/eess?searchtype=author&query=Chakrabarty%2C+S">Soumitro Chakrabarty</a>, 
<a href="/search/eess?searchtype=author&query=Thiergart%2C+O">Oliver Thiergart</a>, 
<a href="/search/eess?searchtype=author&query=Mabande%2C+E">Edwin Mabande</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper introduces an innovative method for reducing the computational
complexity of deep neural networks in real-time speech enhancement on
resource-constrained devices. The proposed approach utilizes a two-stage
processing framework, employing channelwise feature reorientation to reduce the
computational load of convolutional operations. By combining this with a
modified power law compression technique for enhanced perceptual quality, this
approach achieves noise suppression performance comparable to state-of-the-art
methods with significantly less computational requirements. Notably, our
algorithm exhibits 3 to 4 times less computational complexity and memory usage
than prior state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08135" title="Abstract">arXiv:2312.08135</a> (cross-list from math.ST) [<a href="/pdf/2312.08135" title="Download PDF">pdf</a>, <a href="/format/2312.08135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Perspective On Denoising Based On Optimal Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Trillos%2C+N+G">Nicolas Garcia Trillos</a>, 
<a href="/search/math?searchtype=author&query=Sen%2C+B">Bodhisattva Sen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">In the standard formulation of the denoising problem, one is given a
probabilistic model relating a latent variable $\Theta \in \Omega \subset
\mathbb{R}^m \; (m\ge 1)$ and an observation $Z \in \mathbb{R}^d$ according to:
$Z \mid \Theta \sim p(\cdot\mid \Theta)$ and $\Theta \sim G^*$, and the goal is
to construct a map to recover the latent variable from the observation. The
posterior mean, a natural candidate for estimating $\Theta$ from $Z$, attains
the minimum Bayes risk (under the squared error loss) but at the expense of
over-shrinking the $Z$, and in general may fail to capture the geometric
features of the prior distribution $G^*$ (e.g., low dimensionality,
discreteness, sparsity, etc.). To rectify these drawbacks, in this paper we
take a new perspective on this denoising problem that is inspired by optimal
transport (OT) theory and use it to propose a new OT-based denoiser at the
population level setting. We rigorously prove that, under general assumptions
on the model, our OT-based denoiser is well-defined and unique, and is closely
connected to solutions to a Monge OT problem. We then prove that, under
appropriate identifiability assumptions on the model, our OT-based denoiser can
be recovered solely from information of the marginal distribution of $Z$ and
the posterior mean of the model, after solving a linear relaxation problem over
a suitable space of couplings that is reminiscent of a standard multimarginal
OT (MOT) problem. In particular, thanks to Tweedie's formula, when the
likelihood model $\{ p(\cdot \mid \theta) \}_{\theta \in \Omega}$ is an
exponential family of distributions, the OT-based denoiser can be recovered
solely from the marginal distribution of $Z$. In general, our family of OT-like
relaxations is of interest in its own right and for the denoising problem
suggests alternative numerical methods inspired by the rich literature on
computational OT.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08147" title="Abstract">arXiv:2312.08147</a> (cross-list from math.AP) [<a href="/pdf/2312.08147" title="Download PDF">pdf</a>, <a href="/format/2312.08147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A cross-diffusion system modelling rivaling gangs: global existence of  bounded solutions and FCT stabilization for numerical simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fuest%2C+M">Mario Fuest</a>, 
<a href="/search/math?searchtype=author&query=Heydari%2C+S">Shahin Heydari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 20 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">For the gang territoriality model \begin{align*} \begin{cases} u_t = D_u
\Delta u + \chi_u \nabla \cdot (u \nabla w), \\ v_t = D_v \Delta v + \chi_v
\nabla \cdot (v \nabla z), \\ w_t = -w + \frac{v}{1+v}, \\ z_t = -z +
\frac{u}{1+u}, \end{cases} \end{align*} where $u$ and $v$ denote the densities
of two rivaling gangs which spray graffiti (with densities $z$ and $w$,
respectively) and partially move away from the other gang's graffiti, we
construct global, bounded classical solutions. By making use of quantitative
global estimates, we prove that these solutions converge to homogeneous steady
states if $\|u_0\|_{L^\infty(\Omega)}$ and $\|v_0\|_{L^\infty(\Omega)}$ are
sufficiently small. Moreover, we perform numerical experiments which show that
for different choices of parameters, the system may become diffusion- or
convection-dominated, where in the former case the solutions converge toward
constant steady states while in the later case nontrivial asymptotic behavior
such as segregation is observed. In order to perform these experiments, we
apply a nonlinear finite element flux-corrected transport method (FEM-FCT)
which is positivity-preserving. Then, we treat the nonlinearities in both the
system and the proposed nonlinear scheme simultaneously using fixed-point
iteration.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08149" title="Abstract">arXiv:2312.08149</a> (cross-list from math.AP) [<a href="/pdf/2312.08149" title="Download PDF">pdf</a>, <a href="/ps/2312.08149" title="Download PostScript">ps</a>, <a href="/format/2312.08149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal convergence rates for the spectrum of the graph Laplacian on  Poisson point clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Armstrong%2C+S">Scott Armstrong</a>, 
<a href="/search/math?searchtype=author&query=Venkatraman%2C+R">Raghavendra Venkatraman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We prove optimal convergence rates for eigenvalues and eigenvectors of the
graph Laplacian on Poisson point clouds. Our results are valid down to the
critical percolation threshold, yielding error estimates for relatively sparse
graphs.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08153" title="Abstract">arXiv:2312.08153</a> (cross-list from physics.comp-ph) [<a href="/pdf/2312.08153" title="Download PDF">pdf</a>, <a href="/format/2312.08153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $&#x3c1;$-Diffusion: A diffusion-based density estimation framework for  computational physics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Cai%2C+M+X">Maxwell X. Cai</a>, 
<a href="/search/physics?searchtype=author&query=Lee%2C+K+L+K">Kin Long Kelvin Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures, accepted for publication at the NeurIPS 2023 workshop "Machine Learning and the Physical Sciences"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In physics, density $\rho(\cdot)$ is a fundamentally important scalar
function to model, since it describes a scalar field or a probability density
function that governs a physical process. Modeling $\rho(\cdot)$ typically
scales poorly with parameter space, however, and quickly becomes prohibitively
difficult and computationally expensive. One promising avenue to bypass this is
to leverage the capabilities of denoising diffusion models often used in
high-fidelity image generation to parameterize $\rho(\cdot)$ from existing
scientific data, from which new samples can be trivially sampled from. In this
paper, we propose $\rho$-Diffusion, an implementation of denoising diffusion
probabilistic models for multidimensional density estimation in physics, which
is currently in active development and, from our results, performs well on
physically motivated 2D and 3D density functions. Moreover, we propose a novel
hashing technique that allows $\rho$-Diffusion to be conditioned by arbitrary
amounts of physical parameters of interest.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08174" title="Abstract">arXiv:2312.08174</a> (cross-list from econ.EM) [<a href="/pdf/2312.08174" title="Download PDF">pdf</a>, <a href="/format/2312.08174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Double Machine Learning for Static Panel Models with Fixed Effects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Clarke%2C+P">Paul Clarke</a>, 
<a href="/search/econ?searchtype=author&query=Polselli%2C+A">Annalivia Polselli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 5 tables, 5 figure, 2 appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics (econ.EM)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Machine Learning (ML) algorithms are powerful data-driven tools for
approximating high-dimensional or non-linear nuisance functions which are
useful in practice because the true functional form of the predictors is
ex-ante unknown. In this paper, we develop estimators of policy interventions
from panel data which allow for non-linear effects of the confounding
regressors, and investigate the performance of these estimators using three
well-known ML algorithms, specifically, LASSO, classification and regression
trees, and random forests. We use Double Machine Learning (DML) (Chernozhukov
et al., 2018) for the estimation of causal effects of homogeneous treatments
with unobserved individual heterogeneity (fixed effects) and no unobserved
confounding by extending Robinson (1988)'s partially linear regression model.
We develop three alternative approaches for handling unobserved individual
heterogeneity based on extending the within-group estimator, first-difference
estimator, and correlated random effect estimator (Mundlak, 1978) for
non-linear models. Using Monte Carlo simulations, we find that conventional
least squares estimators can perform well even if the data generating process
is non-linear, but there are substantial performance gains in terms of bias
reduction under a process where the true effect of the regressors is non-linear
and discontinuous. However, for the same scenarios, we also find -- despite
extensive hyperparameter tuning -- inference to be problematic for both
tree-based learners because these lead to highly non-normal estimator
distributions and the estimator variance being severely under-estimated. This
contradicts the performance of trees in other circumstances and requires
further investigation. Finally, we provide an illustrative example of DML for
observational panel data showing the impact of the introduction of the national
minimum wage in the UK.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08193" title="Abstract">arXiv:2312.08193</a> (cross-list from eess.IV) [<a href="/pdf/2312.08193" title="Download PDF">pdf</a>, <a href="/format/2312.08193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Adversarial Framework to Improve Adversarial Robustness for  Diabetic Retinopathy Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mukherjee%2C+S">Samrat Mukherjee</a>, 
<a href="/search/eess?searchtype=author&query=Bandyopadhyay%2C+D">Dibyanayan Bandyopadhyay</a>, 
<a href="/search/eess?searchtype=author&query=Gain%2C+B">Baban Gain</a>, 
<a href="/search/eess?searchtype=author&query=Ekbal%2C+A">Asif Ekbal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Diabetic Retinopathy (DR) is a prevalent illness associated with Diabetes
which, if left untreated, can result in irreversible blindness. Deep Learning
based systems are gradually being introduced as automated support for clinical
diagnosis. Since healthcare has always been an extremely important domain
demanding error-free performance, any adversaries could pose a big threat to
the applicability of such systems. In this work, we use Universal Adversarial
Perturbations (UAPs) to quantify the vulnerability of Medical Deep Neural
Networks (DNNs) for detecting DR. To the best of our knowledge, this is the
very first attempt that works on attacking complete fine-grained classification
of DR images using various UAPs. Also, as a part of this work, we use UAPs to
fine-tune the trained models to defend against adversarial samples. We
experiment on several models and observe that the performance of such models
towards unseen adversarial attacks gets boosted on average by $3.41$
Cohen-kappa value and maximum by $31.92$ Cohen-kappa value. The performance
degradation on normal data upon ensembling the fine-tuned models was found to
be statistically insignificant using t-test, highlighting the benefits of
UAP-based adversarial fine-tuning.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08227" title="Abstract">arXiv:2312.08227</a> (cross-list from stat.ML) [<a href="/pdf/2312.08227" title="Download PDF">pdf</a>, <a href="/format/2312.08227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Gradient Flow based on the Sliced Wasserstein  Distance for Non-Parametric Generative Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sebag%2C+I">Ilana Sebag</a>, 
<a href="/search/stat?searchtype=author&query=PYDI%2C+M+S">Muni Sreenivas PYDI</a>, 
<a href="/search/stat?searchtype=author&query=Franceschi%2C+J">Jean-Yves Franceschi</a>, 
<a href="/search/stat?searchtype=author&query=Rakotomamonjy%2C+A">Alain Rakotomamonjy</a>, 
<a href="/search/stat?searchtype=author&query=Gartrell%2C+M">Mike Gartrell</a>, 
<a href="/search/stat?searchtype=author&query=Atif%2C+J">Jamal Atif</a>, 
<a href="/search/stat?searchtype=author&query=Allauzen%2C+A">Alexandre Allauzen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Safeguarding privacy in sensitive training data is paramount, particularly in
the context of generative modeling. This is done through either differentially
private stochastic gradient descent, or with a differentially private metric
for training models or generators. In this paper, we introduce a novel
differentially private generative modeling approach based on parameter-free
gradient flows in the space of probability measures. The proposed algorithm is
a new discretized flow which operates through a particle scheme, utilizing
drift derived from the sliced Wasserstein distance and computed in a private
manner. Our experiments show that compared to a generator-based model, our
proposed model can generate higher-fidelity data at a low privacy budget,
offering a viable alternative to generator-based approaches.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08244" title="Abstract">arXiv:2312.08244</a> (cross-list from cond-mat.dis-nn) [<a href="/pdf/2312.08244" title="Download PDF">pdf</a>, <a href="/ps/2312.08244" title="Download PostScript">ps</a>, <a href="/format/2312.08244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Capacity of the treelike sign perceptrons neural networks with one  hidden layer -- RDT based upper bounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Stojnic%2C+M">Mihailo Stojnic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Information Theory (cs.IT); Mathematical Physics (math-ph); Probability (math.PR); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study the capacity of \emph{sign} perceptrons neural networks (SPNN) and
particularly focus on 1-hidden layer \emph{treelike committee machine} (TCM)
architectures. Similarly to what happens in the case of a single perceptron
neuron, it turns out that, in a statistical sense, the capacity of a
corresponding multilayered network architecture consisting of multiple
\emph{sign} perceptrons also undergoes the so-called phase transition (PT)
phenomenon. This means: (i) for certain range of system parameters (size of
data, number of neurons), the network can be properly trained to accurately
memorize \emph{all} elements of the input dataset; and (ii) outside the region
such a training does not exist. Clearly, determining the corresponding phase
transition curve that separates these regions is an extraordinary task and
among the most fundamental questions related to the performance of any network.
Utilizing powerful mathematical engine called Random Duality Theory (RDT), we
establish a generic framework for determining the upper bounds on the 1-hidden
layer TCM SPNN capacity. Moreover, we do so for \emph{any} given (odd) number
of neurons. We further show that the obtained results \emph{exactly} match the
replica symmetry predictions of \cite{EKTVZ92,BHS92}, thereby proving that the
statistical physics based results are not only nice estimates but also
mathematically rigorous bounds as well. Moreover, for $d\leq 5$, we obtain the
capacity values that improve on the best known rigorous ones of
\cite{MitchDurb89}, thereby establishing a first, mathematically rigorous,
progress in well over 30 years.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08255" title="Abstract">arXiv:2312.08255</a> (cross-list from eess.IV) [<a href="/pdf/2312.08255" title="Download PDF">pdf</a>, <a href="/format/2312.08255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OCTDL: Optical Coherence Tomography Dataset for Image-Based Deep  Learning Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kulyabin%2C+M">Mikhail Kulyabin</a>, 
<a href="/search/eess?searchtype=author&query=Zhdanov%2C+A">Aleksei Zhdanov</a>, 
<a href="/search/eess?searchtype=author&query=Nikiforova%2C+A">Anastasia Nikiforova</a>, 
<a href="/search/eess?searchtype=author&query=Stepichev%2C+A">Andrey Stepichev</a>, 
<a href="/search/eess?searchtype=author&query=Kuznetsova%2C+A">Anna Kuznetsova</a>, 
<a href="/search/eess?searchtype=author&query=Ronkin%2C+M">Mikhail Ronkin</a>, 
<a href="/search/eess?searchtype=author&query=Borisov%2C+V">Vasilii Borisov</a>, 
<a href="/search/eess?searchtype=author&query=Bogachev%2C+A">Alexander Bogachev</a>, 
<a href="/search/eess?searchtype=author&query=Korotkich%2C+S">Sergey Korotkich</a>, 
<a href="/search/eess?searchtype=author&query=Constable%2C+P+A">Paul A Constable</a>, 
<a href="/search/eess?searchtype=author&query=Maier%2C+A">Andreas Maier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Optical coherence tomography (OCT) is a non-invasive imaging technique with
extensive clinical applications in ophthalmology. OCT enables the visualization
of the retinal layers, playing a vital role in the early detection and
monitoring of retinal diseases. OCT uses the principle of light wave
interference to create detailed images of the retinal microstructures, making
it a valuable tool for diagnosing ocular conditions. This work presents an
open-access OCT dataset (OCTDL) comprising over 1600 high-resolution OCT images
labeled according to disease group and retinal pathology. The dataset consists
of OCT records of patients with Age-related Macular Degeneration (AMD),
Diabetic Macular Edema (DME), Epiretinal Membrane (ERM), Retinal Artery
Occlusion (RAO), Retinal Vein Occlusion (RVO), and Vitreomacular Interface
Disease (VID). The images were acquired with an Optovue Avanti RTVue XR using
raster scanning protocols with dynamic scan length and image resolution. Each
retinal b-scan was acquired by centering on the fovea and interpreted and
cataloged by an experienced retinal specialist. In this work, we applied Deep
Learning classification techniques to this new open-access dataset.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08257" title="Abstract">arXiv:2312.08257</a> (cross-list from stat.ML) [<a href="/pdf/2312.08257" title="Download PDF">pdf</a>, <a href="/ps/2312.08257" title="Download PostScript">ps</a>, <a href="/format/2312.08257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> \emph{Lifted} RDT based capacity analysis of the 1-hidden layer treelike  \emph{sign} perceptrons neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Stojnic%2C+M">Mihailo Stojnic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Information Theory (cs.IT); Machine Learning (cs.LG); Mathematical Physics (math-ph); Probability (math.PR)

</div>
<p class="mathjax">We consider the memorization capabilities of multilayered \emph{sign}
perceptrons neural networks (SPNNs). A recent rigorous upper-bounding capacity
characterization, obtained in \cite{Stojnictcmspnncaprdt23} utilizing the
Random Duality Theory (RDT), demonstrated that adding neurons in a network
configuration may indeed be very beneficial. Moreover, for particular
\emph{treelike committee machines} (TCM) architectures with $d\leq 5$ neurons
in the hidden layer, \cite{Stojnictcmspnncaprdt23} made a very first
mathematically rigorous progress in over 30 years by lowering the previously
best known capacity bounds of \cite{MitchDurb89}. Here, we first establish that
the RDT bounds from \cite{Stojnictcmspnncaprdt23} scale as $\sim \sqrt{d}$ and
can not on their own \emph{universally} (over the entire range of $d$) beat the
best known $\sim \log(d)$ scaling of the bounds from \cite{MitchDurb89}. After
recognizing that the progress from \cite{Stojnictcmspnncaprdt23} is therefore
promising, but yet without a complete concretization, we then proceed by
considering the recently developed fully lifted RDT (fl RDT) as an alternative.
While the fl RDT is indeed a powerful juggernaut, it typically relies on heavy
numerical evaluations. To avoid such heavy numerics, we here focus on a
simplified, \emph{partially lifted}, variant and show that it allows for very
neat, closed form, analytical capacity characterizations. Moreover, we obtain
the concrete capacity bounds that \emph{universally} improve for \emph{any} $d$
over the best known ones of \cite{MitchDurb89}.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08262" title="Abstract">arXiv:2312.08262</a> (cross-list from math.CO) [<a href="/pdf/2312.08262" title="Download PDF">pdf</a>, <a href="/format/2312.08262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Leaf Function of Penrose P2 Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Porrier%2C+C">Carole Porrier</a>, 
<a href="/search/math?searchtype=author&query=Mass%C3%A9%2C+A+B">Alexandre Blondin Mass&#xe9;</a>, 
<a href="/search/math?searchtype=author&query=Goupil%2C+A">Alain Goupil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We study a graph-theoretic problem in the Penrose P2-graphs which are the
dual graphs of Penrose tilings by kites and darts. Using substitutions, local
isomorphism and other properties of Penrose tilings, we construct a family of
arbitrarily large induced subtrees of Penrose graphs with the largest possible
number of leaves for a given number $n$ of vertices. These subtrees are called
fully leafed induced subtrees. We denote their number of leaves $L_{P2}(n)$ for
any non-negative integer $n$, and the sequence
$\left(L_{P2}(n)\right)_{n\in\mathbb{N}}$ is called the leaf function of
Penrose P2-graphs. We present exact and recursive formulae for $L_{P2}(n)$, as
well as an infinite sequence of fully leafed induced subtrees, which are
caterpillar graphs. In particular, our proof relies on the construction of a
finite graded poset of 3-internal-regular subtrees.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08264" title="Abstract">arXiv:2312.08264</a> (cross-list from eess.SP) [<a href="/pdf/2312.08264" title="Download PDF">pdf</a>, <a href="/format/2312.08264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kunyu: A High-Performing Global Weather Model Beyond Regression Losses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ni%2C+Z">Zekun Ni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">Over the past year, data-driven global weather forecasting has emerged as a
new alternative to traditional numerical weather prediction. This innovative
approach yields forecasts of comparable accuracy at a tiny fraction of
computational costs. Regrettably, as far as I know, existing models exclusively
rely on regression losses, producing forecasts with substantial blurring. Such
blurring, although compromises practicality, enjoys an unfair advantage on
evaluation metrics. In this paper, I present Kunyu, a global data-driven
weather forecasting model which delivers accurate predictions across a
comprehensive array of atmospheric variables at 0.35{\deg} resolution. With
both regression and adversarial losses integrated in its training framework,
Kunyu generates forecasts with enhanced clarity and realism. Its performance
outpaces even ECMWF HRES in some aspects such as the estimation of anomaly
extremes, while remaining competitive with ECMWF HRES on evaluation metrics
such as RMSE and ACC. Kunyu is an important step forward in closing the utility
gap between numerical and data-driven weather prediction.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08267" title="Abstract">arXiv:2312.08267</a> (cross-list from eess.IV) [<a href="/pdf/2312.08267" title="Download PDF">pdf</a>, <a href="/format/2312.08267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TABSurfer: a Hybrid Deep Learning Architecture for Subcortical  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cao%2C+A">Aaron Cao</a>, 
<a href="/search/eess?searchtype=author&query=Rao%2C+V+M">Vishwanatha M. Rao</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+K">Kejia Liu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+X">Xinru Liu</a>, 
<a href="/search/eess?searchtype=author&query=Laine%2C+A+F">Andrew F. Laine</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+J">Jia Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Subcortical segmentation remains challenging despite its important
applications in quantitative structural analysis of brain MRI scans. The most
accurate method, manual segmentation, is highly labor intensive, so automated
tools like FreeSurfer have been adopted to handle this task. However, these
traditional pipelines are slow and inefficient for processing large datasets.
In this study, we propose TABSurfer, a novel 3D patch-based CNN-Transformer
hybrid deep learning model designed for superior subcortical segmentation
compared to existing state-of-the-art tools. To evaluate, we first demonstrate
TABSurfer's consistent performance across various T1w MRI datasets with
significantly shorter processing times compared to FreeSurfer. Then, we
validate against manual segmentations, where TABSurfer outperforms FreeSurfer
based on the manual ground truth. In each test, we also establish TABSurfer's
advantage over a leading deep learning benchmark, FastSurferVINN. Together,
these studies highlight TABSurfer's utility as a powerful tool for fully
automated subcortical segmentation with high fidelity.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08286" title="Abstract">arXiv:2312.08286</a> (cross-list from math.DS) [<a href="/pdf/2312.08286" title="Download PDF">pdf</a>, <a href="/format/2312.08286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolutionary Games on Infinite Strategy Sets: Convergence to Nash  Equilibria via Dissipativity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Anderson%2C+B+G">Brendon G. Anderson</a>, 
<a href="/search/math?searchtype=author&query=Sojoudi%2C+S">Somayeh Sojoudi</a>, 
<a href="/search/math?searchtype=author&query=Arcak%2C+M">Murat Arcak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Computer Science and Game Theory (cs.GT); Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">We consider evolutionary dynamics for population games in which players have
a continuum of strategies at their disposal. Models in this setting amount to
infinite-dimensional differential equations evolving on the manifold of
probability measures. We generalize dissipativity theory for evolutionary games
from finite to infinite strategy sets that are compact metric spaces, and
derive sufficient conditions for the stability of Nash equilibria under the
infinite-dimensional dynamics. The resulting analysis is applicable to a broad
class of evolutionary games, and is modular in the sense that the pertinent
conditions on the dynamics and the game's payoff structure can be verified
independently. By specializing our theory to the class of monotone games, we
recover as special cases existing stability results for the Brown-von
Neumann-Nash and impartial pairwise comparison dynamics. We also extend our
theory to models with dynamic payoffs, further broadening the applicability of
our framework. We illustrate our theory using a variety of case studies,
including a novel, continuous variant of the war of attrition game.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08290" title="Abstract">arXiv:2312.08290</a> (cross-list from eess.IV) [<a href="/pdf/2312.08290" title="Download PDF">pdf</a>, <a href="/format/2312.08290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PhenDiff: Revealing Invisible Phenotypes with Conditional Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bourou%2C+A">Anis Bourou</a>, 
<a href="/search/eess?searchtype=author&query=Boyer%2C+T">Thomas Boyer</a>, 
<a href="/search/eess?searchtype=author&query=Daupin%2C+K">K&#xe9;vin Daupin</a>, 
<a href="/search/eess?searchtype=author&query=Dubreuil%2C+V">V&#xe9;ronique Dubreuil</a>, 
<a href="/search/eess?searchtype=author&query=De+Thonel%2C+A">Aur&#xe9;lie De Thonel</a>, 
<a href="/search/eess?searchtype=author&query=Mezger%2C+V">Val&#xe9;rie Mezger</a>, 
<a href="/search/eess?searchtype=author&query=Genovesio%2C+A">Auguste Genovesio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Over the last five years, deep generative models have gradually been adopted
for various tasks in biological research. Notably, image-to-image translation
methods showed to be effective in revealing subtle phenotypic cell variations
otherwise invisible to the human eye. Current methods to achieve this goal
mainly rely on Generative Adversarial Networks (GANs). However, these models
are known to suffer from some shortcomings such as training instability and
mode collapse. Furthermore, the lack of robustness to invert a real image into
the latent of a trained GAN prevents flexible editing of real images. In this
work, we propose PhenDiff, an image-to-image translation method based on
conditional diffusion models to identify subtle phenotypes in microscopy
images. We evaluate this approach on biological datasets against previous work
such as CycleGAN. We show that PhenDiff outperforms this baseline in terms of
quality and diversity of the generated images. We then apply this method to
display invisible phenotypic changes triggered by a rare neurodevelopmental
disorder on microscopy images of organoids. Altogether, we demonstrate that
PhenDiff is able to perform high quality biological image-to-image translation
allowing to spot subtle phenotype variations on a real image.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08295" title="Abstract">arXiv:2312.08295</a> (cross-list from astro-ph.IM) [<a href="/pdf/2312.08295" title="Download PDF">pdf</a>, <a href="/format/2312.08295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring Atmospheric Properties of Exoplanets with Flow Matching and  Neural Importance Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Gebhard%2C+T+D">Timothy D. Gebhard</a>, 
<a href="/search/astro-ph?searchtype=author&query=Wildberger%2C+J">Jonas Wildberger</a>, 
<a href="/search/astro-ph?searchtype=author&query=Dax%2C+M">Maximilian Dax</a>, 
<a href="/search/astro-ph?searchtype=author&query=Angerhausen%2C+D">Daniel Angerhausen</a>, 
<a href="/search/astro-ph?searchtype=author&query=Quanz%2C+S+P">Sascha P. Quanz</a>, 
<a href="/search/astro-ph?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the "AI to Accelerate Science and Engineering (AI2ASE)" workshop at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Earth and Planetary Astrophysics (astro-ph.EP); Machine Learning (cs.LG)

</div>
<p class="mathjax">Atmospheric retrievals (AR) characterize exoplanets by estimating atmospheric
parameters from observed light spectra, typically by framing the task as a
Bayesian inference problem. However, traditional approaches such as nested
sampling are computationally expensive, thus sparking an interest in solutions
based on machine learning (ML). In this ongoing work, we first explore flow
matching posterior estimation (FMPE) as a new ML-based method for AR and find
that, in our case, it is more accurate than neural posterior estimation (NPE),
but less accurate than nested sampling. We then combine both FMPE and NPE with
importance sampling, in which case both methods outperform nested sampling in
terms of accuracy and simulation efficiency. Going forward, our analysis
suggests that simulation-based inference with likelihood-based importance
sampling provides a framework for accurate and efficient AR that may become a
valuable tool not only for the analysis of observational data from existing
telescopes, but also for the development of new missions and instruments.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08307" title="Abstract">arXiv:2312.08307</a> (cross-list from physics.chem-ph) [<a href="/pdf/2312.08307" title="Download PDF">pdf</a>, <a href="/format/2312.08307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EquiReact: An equivariant neural network for chemical reactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=van+Gerwen%2C+P">Puck van Gerwen</a>, 
<a href="/search/physics?searchtype=author&query=Briling%2C+K+R">Ksenia R. Briling</a>, 
<a href="/search/physics?searchtype=author&query=Bunne%2C+C">Charlotte Bunne</a>, 
<a href="/search/physics?searchtype=author&query=Somnath%2C+V+R">Vignesh Ram Somnath</a>, 
<a href="/search/physics?searchtype=author&query=Laplaza%2C+R">Ruben Laplaza</a>, 
<a href="/search/physics?searchtype=author&query=Krause%2C+A">Andreas Krause</a>, 
<a href="/search/physics?searchtype=author&query=Corminboeuf%2C+C">Clemence Corminboeuf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages + SI (6 pages)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Equivariant neural networks have considerably improved the accuracy and
data-efficiency of predictions of molecular properties. Building on this
success, we introduce EquiReact, an equivariant neural network to infer
properties of chemical reactions, built from three-dimensional structures of
reactants and products. We illustrate its competitive performance on the
prediction of activation barriers on the GDB7-22-TS, Cyclo-23-TS and
Proparg-21-TS datasets with different regimes according to the inclusion of
atom-mapping information. We show that, compared to state-of-the-art models for
reaction property prediction, EquiReact offers: (i) a flexible model with
reduced sensitivity between atom-mapping regimes, (ii) better extrapolation
capabilities to unseen chemistries, (iii) impressive prediction errors for
datasets exhibiting subtle variations in three-dimensional geometries of
reactants/products, (iv) reduced sensitivity to geometry quality and (iv)
excellent data efficiency.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08310" title="Abstract">arXiv:2312.08310</a> (cross-list from quant-ph) [<a href="/pdf/2312.08310" title="Download PDF">pdf</a>, <a href="/format/2312.08310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum simulation of highly-oscillatory many-body Hamiltonians for  near-term devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+G">Guannan Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Foroozandeh%2C+M">Mohammadali Foroozandeh</a>, 
<a href="/search/quant-ph?searchtype=author&query=Budd%2C+C">Chris Budd</a>, 
<a href="/search/quant-ph?searchtype=author&query=Singh%2C+P">Pranav Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 53 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Numerical Analysis (math.NA); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">We develop a fourth-order Magnus expansion based quantum algorithm for the
simulation of many-body problems involving two-level quantum systems with
time-dependent Hamiltonians, $\mathcal{H}(t)$. A major hurdle in the
utilization of the Magnus expansion is the appearance of a commutator term
which leads to prohibitively long circuits. We present a technique for
eliminating this commutator and find that a single time-step of the resulting
algorithm is only marginally costlier than that required for time-stepping with
a time-independent Hamiltonian, requiring only three additional single-qubit
layers. For a large class of Hamiltonians appearing in liquid-state nuclear
magnetic resonance (NMR) applications, we further exploit symmetries of the
Hamiltonian and achieve a surprising reduction in the expansion, whereby a
single time-step of our fourth-order method has a circuit structure and cost
that is identical to that required for a fourth-order Trotterized time-stepping
procedure for time-independent Hamiltonians. Moreover, our algorithms are able
to take time-steps that are larger than the wavelength of oscillation of the
time-dependent Hamiltonian, making them particularly suited for
highly-oscillatory controls. The resulting quantum circuits have shorter depths
for all levels of accuracy when compared to first and second-order Trotterized
methods, as well as other fourth-order Trotterized methods, making the proposed
algorithm a suitable candidate for simulation of time-dependent Hamiltonians on
near-term quantum devices.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08335" title="Abstract">arXiv:2312.08335</a> (cross-list from math.OC) [<a href="/pdf/2312.08335" title="Download PDF">pdf</a>, <a href="/format/2312.08335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fractional, semilinear, and sparse optimal control: a priori error  bounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bersetche%2C+F">Francisco Bersetche</a>, 
<a href="/search/math?searchtype=author&query=Fuica%2C+F">Francisco Fuica</a>, 
<a href="/search/math?searchtype=author&query=Otarola%2C+E">Enrique Otarola</a>, 
<a href="/search/math?searchtype=author&query=Quero%2C+D">Daniel Quero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this work, we use the integral definition of the fractional Laplace
operator and study a sparse optimal control problem involving a fractional,
semilinear, and elliptic partial differential equation as state equation;
control constraints are also considered. We establish the existence of optimal
solutions and first and second order optimality conditions. We also analyze
regularity properties for optimal variables. We propose and analyze two finite
element strategies of discretization: a fully discrete scheme, where the
control variable is discretized with piecewise constant functions, and a
semidiscrete scheme, where the control variable is not discretized. For both
discretization schemes, we analyze convergence properties and a priori error
bounds.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08343" title="Abstract">arXiv:2312.08343</a> (cross-list from eess.IV) [<a href="/pdf/2312.08343" title="Download PDF">pdf</a>, <a href="/ps/2312.08343" title="Download PostScript">ps</a>, <a href="/format/2312.08343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ehancing CT Image synthesis from multi-modal MRI data based on a  multi-task neural network framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xin%2C+Z">Zhuoyao Xin</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+C">Christopher Wu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+D">Dong Liu</a>, 
<a href="/search/eess?searchtype=author&query=Gu%2C+C">Chunming Gu</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+J">Jia Guo</a>, 
<a href="/search/eess?searchtype=author&query=Hua%2C+J">Jun Hua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Image segmentation, real-value prediction, and cross-modal translation are
critical challenges in medical imaging. In this study, we propose a versatile
multi-task neural network framework, based on an enhanced Transformer U-Net
architecture, capable of simultaneously, selectively, and adaptively addressing
these medical image tasks. Validation is performed on a public repository of
human brain MR and CT images. We decompose the traditional problem of
synthesizing CT images into distinct subtasks, which include skull
segmentation, Hounsfield unit (HU) value prediction, and image sequential
reconstruction. To enhance the framework's versatility in handling multi-modal
data, we expand the model with multiple image channels. Comparisons between
synthesized CT images derived from T1-weighted and T2-Flair images were
conducted, evaluating the model's capability to integrate multi-modal
information from both morphological and pixel value perspectives.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08355" title="Abstract">arXiv:2312.08355</a> (cross-list from math.CO) [<a href="/pdf/2312.08355" title="Download PDF">pdf</a>, <a href="/ps/2312.08355" title="Download PostScript">ps</a>, <a href="/format/2312.08355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disconnected cuts in 4-connected planar graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Preez%2C+B+D">Brandon Du Preez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Let $G=(V,E)$ be a connected graph. A subset $S\subset V$ is a cut of $G$ if
$G-S$ is disconnected. A near triangulation is a 2-connected plane graph that
has at most one face that is not a triangle. In this paper, we explore minimal
cuts of 4-connected planar graphs. Our main result is that every minimal cut of
a 4-connected planar graph $G$ is connected if and only if $G$ is a
near-triangulation. We use this result to sketch a linear-time algorithm for
finding a disconnected cut of a 4-connected planar graph.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08360" title="Abstract">arXiv:2312.08360</a> (cross-list from math.CO) [<a href="/pdf/2312.08360" title="Download PDF">pdf</a>, <a href="/format/2312.08360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the existence of some completely regular codes in Hamming graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Krotov%2C+D+S">Denis S. Krotov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We solve several first questions in the table of small parameters of
completely regular (CR) codes in Hamming graphs $H(n,q)$. The most uplifting
result is the existence of a $\{13,6,1;1,6,9\}$-CR code in $H(n,2)$, $n\ge 13$.
We also establish the non-existence of a $\{11,4;3,6\}$-code and a
$\{10,3;4,7\}$-code in $H(12,2)$ and $H(13,2)$. A partition of the complement
of the quaternary Hamming code of length~$5$ into $4$-cliques is found, which
can be used to construct completely regular codes with covering radius $1$ by
known constructions. Additionally we discuss the parameters
$\{24,21,10;1,4,12\}$ of a putative completely regular code in $H(24,2)$ and
show the nonexistence of such a code in $H(8,4)$.
<br />Keywords: Hamming graph, equitable partition, completely regular code
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08369" title="Abstract">arXiv:2312.08369</a> (cross-list from stat.ML) [<a href="/pdf/2312.08369" title="Download PDF">pdf</a>, <a href="/format/2312.08369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Effective Horizon Explains Deep RL Performance in Stochastic  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Laidlaw%2C+C">Cassidy Laidlaw</a>, 
<a href="/search/stat?searchtype=author&query=Zhu%2C+B">Banghua Zhu</a>, 
<a href="/search/stat?searchtype=author&query=Russell%2C+S">Stuart Russell</a>, 
<a href="/search/stat?searchtype=author&query=Dragan%2C+A">Anca Dragan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Reinforcement learning (RL) theory has largely focused on proving minimax
sample complexity bounds. These require strategic exploration algorithms that
use relatively limited function classes for representing the policy or value
function. Our goal is to explain why deep RL algorithms often perform well in
practice, despite using random exploration and much more expressive function
classes like neural networks. Our work arrives at an explanation by showing
that many stochastic MDPs can be solved by performing only a few steps of value
iteration on the random policy's Q function and then acting greedily. When this
is true, we find that it is possible to separate the exploration and learning
components of RL, making it much easier to analyze. We introduce a new RL
algorithm, SQIRL, that iteratively learns a near-optimal policy by exploring
randomly to collect rollouts and then performing a limited number of steps of
fitted-Q iteration over those rollouts. Any regression algorithm that satisfies
basic in-distribution generalization properties can be used in SQIRL to
efficiently solve common MDPs. This can explain why deep RL works neural
networks, since it is empirically established that neural networks generalize
well in-distribution. Furthermore, SQIRL explains why random exploration works
well in practice, since we show many environments can be solved by estimating
the random policy's Q-function and then applying zero or a few steps of value
iteration. We leverage SQIRL to derive instance-dependent sample complexity
bounds for RL that are exponential only in an "effective horizon" of lookahead
and on the complexity of the class used for function approximation.
Empirically, we also find that SQIRL performance strongly correlates with PPO
and DQN performance in a variety of stochastic environments, supporting that
our theoretical analysis is predictive of practical performance.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Thu, 14 Dec 23</h3>
<dl>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2007.10863" title="Abstract">arXiv:2007.10863</a> (replaced) [<a href="/pdf/2007.10863" title="Download PDF">pdf</a>, <a href="/format/2007.10863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Outer approximations of core points for integer programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shahverdi%2C+N">Naghmeh Shahverdi</a>, 
<a href="/search/math?searchtype=author&query=Bremner%2C+D">David Bremner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fix right hand sides of constraints for example ILP on p. 15. 60-&amp;gt;59, 2-&amp;gt;1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computational Geometry (cs.CG)

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2008.07324" title="Abstract">arXiv:2008.07324</a> (replaced) [<a href="/pdf/2008.07324" title="Download PDF">pdf</a>, <a href="/format/2008.07324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligence Primer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fezer%2C+K">Karl Fezer</a>, 
<a href="/search/cs?searchtype=author&query=Sloss%2C+A">Andrew Sloss</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 12 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.02787" title="Abstract">arXiv:2010.02787</a> (replaced) [<a href="/pdf/2010.02787" title="Download PDF">pdf</a>, <a href="/format/2010.02787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficiently Approximating Vertex Cover on Scale-Free Networks with  Underlying Hyperbolic Geometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bl%C3%A4sius%2C+T">Thomas Bl&#xe4;sius</a>, 
<a href="/search/cs?searchtype=author&query=Friedrich%2C+T">Tobias Friedrich</a>, 
<a href="/search/cs?searchtype=author&query=Katzmann%2C+M">Maximilian Katzmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2011.14159" title="Abstract">arXiv:2011.14159</a> (replaced) [<a href="/pdf/2011.14159" title="Download PDF">pdf</a>, <a href="/format/2011.14159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Delegated RingCT: faster anonymous transactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morais%2C+R">Rui Morais</a>, 
<a href="/search/cs?searchtype=author&query=Crocker%2C+P">Paul Crocker</a>, 
<a href="/search/cs?searchtype=author&query=de+Sousa%2C+S+M">Simao Melo de Sousa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2101.11992" title="Abstract">arXiv:2101.11992</a> (replaced) [<a href="/pdf/2101.11992" title="Download PDF">pdf</a>, <a href="/format/2101.11992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Acting in Delayed Environments with Non-Stationary Markov Policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Derman%2C+E">Esther Derman</a>, 
<a href="/search/cs?searchtype=author&query=Dalal%2C+G">Gal Dalal</a>, 
<a href="/search/cs?searchtype=author&query=Mannor%2C+S">Shie Mannor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in ICLR 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.04110" title="Abstract">arXiv:2103.04110</a> (replaced) [<a href="/pdf/2103.04110" title="Download PDF">pdf</a>, <a href="/format/2103.04110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symplectic GARK methods for partitioned Hamiltonian systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=G%C3%BCnther%2C+M">Michael G&#xfc;nther</a>, 
<a href="/search/math?searchtype=author&query=Sandu%2C+A">Adrian Sandu</a>, 
<a href="/search/math?searchtype=author&query=Sch%C3%A4fers%2C+K">Kevin Sch&#xe4;fers</a>, 
<a href="/search/math?searchtype=author&query=Zanna%2C+A">Antonella Zanna</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.11003" title="Abstract">arXiv:2103.11003</a> (replaced) [<a href="/pdf/2103.11003" title="Download PDF">pdf</a>, <a href="/format/2103.11003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially private inference via noisy optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Avella-Medina%2C+M">Marco Avella-Medina</a>, 
<a href="/search/math?searchtype=author&query=Bradshaw%2C+C">Casey Bradshaw</a>, 
<a href="/search/math?searchtype=author&query=Loh%2C+P">Po-Ling Loh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Annals of Statistics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.13389" title="Abstract">arXiv:2103.13389</a> (replaced) [<a href="/pdf/2103.13389" title="Download PDF">pdf</a>, <a href="/format/2103.13389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Novel Scene Compositions from Single Images and Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sushko%2C+V">Vadim Sushko</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gall%2C+J">Juergen Gall</a>, 
<a href="/search/cs?searchtype=author&query=Khoreva%2C+A">Anna Khoreva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Computer Vision and Image Understanding: <a href="https://www.sciencedirect.com/science/article/pii/S1077314223002680.">this https URL</a> Code repository: <a href="https://github.com/boschresearch/one-shot-synthesis">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.12156" title="Abstract">arXiv:2104.12156</a> (replaced) [<a href="/pdf/2104.12156" title="Download PDF">pdf</a>, <a href="/ps/2104.12156" title="Download PostScript">ps</a>, <a href="/format/2104.12156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sequential composition of answer set programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anti%C4%87%2C+C">Christian Anti&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2009.05774">arXiv:2009.05774</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Discrete Mathematics (cs.DM); Logic in Computer Science (cs.LO); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.00984" title="Abstract">arXiv:2105.00984</a> (replaced) [<a href="/pdf/2105.00984" title="Download PDF">pdf</a>, <a href="/ps/2105.00984" title="Download PostScript">ps</a>, <a href="/format/2105.00984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Playing Stochastically in Weighted Timed Games to Emulate Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Monmege%2C+B">Benjamin Monmege</a>, 
<a href="/search/cs?searchtype=author&query=Parreaux%2C+J">Julie Parreaux</a>, 
<a href="/search/cs?searchtype=author&query=Reynier%2C+P">Pierre-Alain Reynier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.06174" title="Abstract">arXiv:2106.06174</a> (replaced) [<a href="/pdf/2106.06174" title="Download PDF">pdf</a>, <a href="/ps/2106.06174" title="Download PostScript">ps</a>, <a href="/format/2106.06174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Competition on Dynamic Optimization Problems Generated by Generalized  Moving Peaks Benchmark (GMPB)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yazdani%2C+D">Danial Yazdani</a> (1), 
<a href="/search/cs?searchtype=author&query=Mavrovouniotis%2C+M">Michalis Mavrovouniotis</a> (2), 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changhe Li</a> (3), 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Wenjian Luo</a> (4), 
<a href="/search/cs?searchtype=author&query=Omidvar%2C+M+N">Mohammad Nabi Omidvar</a> (5), 
<a href="/search/cs?searchtype=author&query=Gandomi%2C+A+H">Amir H. Gandomi</a> (6), 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+T">Trung Thanh Nguyen</a> (7), 
<a href="/search/cs?searchtype=author&query=Branke%2C+J">Juergen Branke</a> (8), 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaodong Li</a> (9), 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shengxiang Yang</a> (10), 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xin Yao</a> (11) ((1) Faculty of Engineering &amp; Information Technology, University of Technology Sydney,(2) ERATOSTHENES Centre of Excellence, (3) School of Automation, China University of Geosciences, (4) Guangdong Provincial Key Laboratory of Novel Security Intelligence Technologies, School of Computer Science and Technology, Harbin Institute of Technology and Peng Cheng Laboratory, (5) School of Computing, University of Leeds, and Leeds University Business School, (6) Faculty of Engineering &amp; Information Technology, University of Technology Sydney and University Research and Innovation Center (EKIK), Obuda University, (7) Liverpool Logistics, Offshore and Marine (LOOM) Research Institute, Faculty of Engineering and Technology, School of Engineering, Liverpool John Moores University, (8) Warwick Business school, University of Warwick, (9) School of Science (Computer Science), RMIT University, (10) Center for Computational Intelligence (CCI), School of Computer Science and Informatics, De Montfort University, (11) Research Institute of Trustworthy Autonomous Systems (RITAS), and Guangdong Provincial Key Laboratory of Brain inspired Intelligent Computation, Department of Computer Science and Engineering, Southern University of Science and Technology, and CERCIA, School of Computer Science, University of Birmingham)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the support document for CEC 2024 competition on Dynamic Optimization Problems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.01559" title="Abstract">arXiv:2107.01559</a> (replaced) [<a href="/pdf/2107.01559" title="Download PDF">pdf</a>, <a href="/format/2107.01559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smoothed Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Ao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Lirong Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 Page main text + Appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.01785" title="Abstract">arXiv:2107.01785</a> (replaced) [<a href="/pdf/2107.01785" title="Download PDF">pdf</a>, <a href="/format/2107.01785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Bounds for Codes Correcting Insertions and Deletions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yasunaga%2C+K">Kenji Yasunaga</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 2 fugures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.10756" title="Abstract">arXiv:2107.10756</a> (replaced) [<a href="/e-print/2107.10756" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Text-to-Face GAN -ST^2FG
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oza%2C+M">Manan Oza</a>, 
<a href="/search/cs?searchtype=author&query=Chanda%2C+S">Sukalpa Chanda</a>, 
<a href="/search/cs?searchtype=author&query=Doermann%2C+D">David Doermann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Experiments needs to be redone
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.05901" title="Abstract">arXiv:2110.05901</a> (replaced) [<a href="/pdf/2110.05901" title="Download PDF">pdf</a>, <a href="/ps/2110.05901" title="Download PostScript">ps</a>, <a href="/format/2110.05901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Popular matchings with weighted voters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heeger%2C+K">Klaus Heeger</a>, 
<a href="/search/cs?searchtype=author&query=Cseh%2C+%C3%81">&#xc1;gnes Cseh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.10522" title="Abstract">arXiv:2112.10522</a> (replaced) [<a href="/pdf/2112.10522" title="Download PDF">pdf</a>, <a href="/format/2112.10522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Ranking Quality and Fairness in Swiss-System Chess Tournaments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sauer%2C+P">Pascal Sauer</a>, 
<a href="/search/cs?searchtype=author&query=Cseh%2C+%C3%81">&#xc1;gnes Cseh</a>, 
<a href="/search/cs?searchtype=author&query=Lenzner%2C+P">Pascal Lenzner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.12312" title="Abstract">arXiv:2201.12312</a> (replaced) [<a href="/pdf/2201.12312" title="Download PDF">pdf</a>, <a href="/ps/2201.12312" title="Download PostScript">ps</a>, <a href="/format/2201.12312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Isomorphism testing of $k$-spanning tournaments is Fixed Parameter  Tractable
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Arvind%2C+V">Vikraman Arvind</a>, 
<a href="/search/math?searchtype=author&query=Ponomarenko%2C+I">Ilia Ponomarenko</a>, 
<a href="/search/math?searchtype=author&query=Ryabov%2C+G">Grigory Ryabov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.12674" title="Abstract">arXiv:2201.12674</a> (replaced) [<a href="/pdf/2201.12674" title="Download PDF">pdf</a>, <a href="/format/2201.12674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rewiring with Positional Encodings for Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Br%C3%BCel-Gabrielsson%2C+R">Rickard Br&#xfc;el-Gabrielsson</a>, 
<a href="/search/cs?searchtype=author&query=Yurochkin%2C+M">Mikhail Yurochkin</a>, 
<a href="/search/cs?searchtype=author&query=Solomon%2C+J">Justin Solomon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.06660" title="Abstract">arXiv:2202.06660</a> (replaced) [<a href="/pdf/2202.06660" title="Download PDF">pdf</a>, <a href="/ps/2202.06660" title="Download PostScript">ps</a>, <a href="/format/2202.06660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Obvious Manipulability for Single-Parameter Agents and Bilateral  Trade
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Archbold%2C+T">Thomas Archbold</a>, 
<a href="/search/cs?searchtype=author&query=de+Keijzer%2C+B">Bart de Keijzer</a>, 
<a href="/search/cs?searchtype=author&query=Ventre%2C+C">Carmine Ventre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.13306" title="Abstract">arXiv:2202.13306</a> (replaced) [<a href="/pdf/2202.13306" title="Download PDF">pdf</a>, <a href="/ps/2202.13306" title="Download PostScript">ps</a>, <a href="/format/2202.13306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heroes in oriented complete multipartite graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aboulker%2C+P">Pierre Aboulker</a>, 
<a href="/search/math?searchtype=author&query=Aubian%2C+G">Guillaume Aubian</a>, 
<a href="/search/math?searchtype=author&query=Charbit%2C+P">Pierre Charbit</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.00867" title="Abstract">arXiv:2205.00867</a> (replaced) [<a href="/e-print/2205.00867" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Capturing High-order Structures on Motif-based Graph Nerual Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kejia Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> some metric have problem
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.02528" title="Abstract">arXiv:2205.02528</a> (replaced) [<a href="/pdf/2205.02528" title="Download PDF">pdf</a>, <a href="/format/2205.02528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On inherent limitations in robustness and performance for a class of  prescribed-time algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Aldana-L%C3%B3pez%2C+R">Rodrigo Aldana-L&#xf3;pez</a>, 
<a href="/search/eess?searchtype=author&query=Seeber%2C+R">Richard Seeber</a>, 
<a href="/search/eess?searchtype=author&query=Haimovich%2C+H">Hernan Haimovich</a>, 
<a href="/search/eess?searchtype=author&query=G%C3%B3mez-Guti%C3%A9rrez%2C+D">David G&#xf3;mez-Guti&#xe9;rrez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.15203" title="Abstract">arXiv:2205.15203</a> (replaced) [<a href="/pdf/2205.15203" title="Download PDF">pdf</a>, <a href="/format/2205.15203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exponentials as Substitutions and the Cost of Cut Elimination in Linear  Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Accattoli%2C+B">Beniamino Accattoli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.07553" title="Abstract">arXiv:2206.07553</a> (replaced) [<a href="/pdf/2206.07553" title="Download PDF">pdf</a>, <a href="/format/2206.07553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the fast convergence of minibatch heavy ball momentum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bollapragada%2C+R">Raghu Bollapragada</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tyler Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ward%2C+R">Rachel Ward</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Numerical Analysis (math.NA); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.10503" title="Abstract">arXiv:2206.10503</a> (replaced) [<a href="/pdf/2206.10503" title="Download PDF">pdf</a>, <a href="/format/2206.10503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On a certified VMS-Smagorinsky Reduced Basis model with LPS pressure  stabilisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Rebollo%2C+T+C">Tom&#xe1;s Chac&#xf3;n Rebollo</a>, 
<a href="/search/math?searchtype=author&query=%C3%81vila%2C+E+D">Enrique Delgado &#xc1;vila</a>, 
<a href="/search/math?searchtype=author&query=M%C3%A1rmol%2C+M+G">Macarena G&#xf3;mez M&#xe1;rmol</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.06503" title="Abstract">arXiv:2207.06503</a> (replaced) [<a href="/pdf/2207.06503" title="Download PDF">pdf</a>, <a href="/format/2207.06503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Randomly pivoted Cholesky: Practical approximation of a kernel matrix  with few entry evaluations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+Y">Yifan Chen</a>, 
<a href="/search/math?searchtype=author&query=Epperly%2C+E+N">Ethan N. Epperly</a>, 
<a href="/search/math?searchtype=author&query=Tropp%2C+J+A">Joel A. Tropp</a>, 
<a href="/search/math?searchtype=author&query=Webber%2C+R+J">Robert J. Webber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.10823" title="Abstract">arXiv:2207.10823</a> (replaced) [<a href="/pdf/2207.10823" title="Download PDF">pdf</a>, <a href="/format/2207.10823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Sealed-bid Auction with Fund Binding: Preventing Maximum Bidding Price  Leakage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chin%2C+K">Kota Chin</a>, 
<a href="/search/cs?searchtype=author&query=Emura%2C+K">Keita Emura</a>, 
<a href="/search/cs?searchtype=author&query=Omote%2C+K">Kazumasa Omote</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+S">Shingo Sato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.13176" title="Abstract">arXiv:2207.13176</a> (replaced) [<a href="/pdf/2207.13176" title="Download PDF">pdf</a>, <a href="/format/2207.13176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Privacy Risks of Adversarial VR Game Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nair%2C+V">Vivek Nair</a>, 
<a href="/search/cs?searchtype=author&query=Garrido%2C+G+M">Gonzalo Munilla Garrido</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dawn Song</a>, 
<a href="/search/cs?searchtype=author&query=O%27Brien%2C+J+F">James F. O&#x27;Brien</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Learn more at <a href="https://rdi.berkeley.edu/metaverse/metadata">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 23rd Privacy Enhancing Technologies Symposium (2023) 238-256
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.01832" title="Abstract">arXiv:2209.01832</a> (replaced) [<a href="/pdf/2209.01832" title="Download PDF">pdf</a>, <a href="/format/2209.01832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lattice-based shape tracking and servoing of elastic objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shetab-Bushehri%2C+M">Mohammadreza Shetab-Bushehri</a>, 
<a href="/search/cs?searchtype=author&query=Aranda%2C+M">Miguel Aranda</a>, 
<a href="/search/cs?searchtype=author&query=Mezouar%2C+Y">Youcef Mezouar</a>, 
<a href="/search/cs?searchtype=author&query=Ozgur%2C+E">Erol Ozgur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the arXiv version of an article published in IEEE Transactions on Robotics. Please cite the accepted version: M. Shetab-Bushehri, M. Aranda, Y. Mezouar and E. \"Ozg\"ur, "Lattice-based Shape Tracking and Servoing of Elastic Objects," in IEEE Transactions on Robotics, doi: 10.1109/TRO.2023.3331596
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.08716" title="Abstract">arXiv:2209.08716</a> (replaced) [<a href="/pdf/2209.08716" title="Download PDF">pdf</a>, <a href="/format/2209.08716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GLARE: A Dataset for Traffic Sign Detection in Sun Glare
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gray%2C+N">Nicholas Gray</a>, 
<a href="/search/cs?searchtype=author&query=Moraes%2C+M">Megan Moraes</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Alex Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+A">Allen Tian</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+K">Kurt Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Haoyi Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhishan Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.10187" title="Abstract">arXiv:2209.10187</a> (replaced) [<a href="/pdf/2209.10187" title="Download PDF">pdf</a>, <a href="/format/2209.10187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the convex formulations of robust Markov decision processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Grand-Cl%C3%A9ment%2C+J">Julien Grand-Cl&#xe9;ment</a>, 
<a href="/search/math?searchtype=author&query=Petrik%2C+M">Marek Petrik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.11871" title="Abstract">arXiv:2209.11871</a> (replaced) [<a href="/pdf/2209.11871" title="Download PDF">pdf</a>, <a href="/ps/2209.11871" title="Download PostScript">ps</a>, <a href="/format/2209.11871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cem Mil Podcasts: A Spoken Portuguese Document Corpus For Multi-modal,  Multi-lingual and Multi-Dialect Information Access Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garmash%2C+E">Ekaterina Garmash</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+E">Edgar Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Clifton%2C+A">Ann Clifton</a>, 
<a href="/search/cs?searchtype=author&query=Correia%2C+J">Joana Correia</a>, 
<a href="/search/cs?searchtype=author&query=Jat%2C+S">Sharmistha Jat</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Winstead Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+R">Rosie Jones</a>, 
<a href="/search/cs?searchtype=author&query=Karlgren%2C+J">Jussi Karlgren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 1 figure
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Volume 14163 of Lecture Notes in Computer Science, pages 48-59,
  Springer, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.14227" title="Abstract">arXiv:2209.14227</a> (replaced) [<a href="/pdf/2209.14227" title="Download PDF">pdf</a>, <a href="/format/2209.14227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UTC Time, Formally Verified
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Almeida+Borges%2C+A">Ana de Almeida Borges</a>, 
<a href="/search/cs?searchtype=author&query=Bedmar%2C+M+G">Mireia Gonz&#xe1;lez Bedmar</a>, 
<a href="/search/cs?searchtype=author&query=Rodr%C3%ADguez%2C+J+C">Juan Conejero Rodr&#xed;guez</a>, 
<a href="/search/cs?searchtype=author&query=Reyes%2C+E+H">Eduardo Hermo Reyes</a>, 
<a href="/search/cs?searchtype=author&query=Bu%C3%B1uel%2C+J+C">Joaquim Casals Bu&#xf1;uel</a>, 
<a href="/search/cs?searchtype=author&query=Joosten%2C+J+J">Joost J. Joosten</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of the 13th ACM SIGPLAN International Conference on
  Certified Programs and Proofs (CPP 24), January 15--16, 2024, London, UK.
  ACM, New York, NY, USA, 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.03962" title="Abstract">arXiv:2210.03962</a> (replaced) [<a href="/pdf/2210.03962" title="Download PDF">pdf</a>, <a href="/format/2210.03962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Power Random Access for Timely Status Update: Packet-based or  Connection-based?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chan%2C+T">Tse-Tin Chan</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jian Feng</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+H">Haoyuan Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.11194" title="Abstract">arXiv:2210.11194</a> (replaced) [<a href="/pdf/2210.11194" title="Download PDF">pdf</a>, <a href="/format/2210.11194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controller-Guided Partial Label Consistency Regularization with  Unlabeled Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qian-Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bowen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Mingyan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianxiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zimo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shu-Tao Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.12150" title="Abstract">arXiv:2210.12150</a> (replaced) [<a href="/pdf/2210.12150" title="Download PDF">pdf</a>, <a href="/format/2210.12150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formalizing Chemical Physics using the Lean Theorem Prover
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bobbin%2C+M+P">Maxwell P. Bobbin</a>, 
<a href="/search/cs?searchtype=author&query=Sharlin%2C+S">Samiha Sharlin</a>, 
<a href="/search/cs?searchtype=author&query=Feyzishendi%2C+P">Parivash Feyzishendi</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+A+H">An Hong Dang</a>, 
<a href="/search/cs?searchtype=author&query=Wraback%2C+C+M">Catherine M. Wraback</a>, 
<a href="/search/cs?searchtype=author&query=Josephson%2C+T+R">Tyler R. Josephson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.04118" title="Abstract">arXiv:2211.04118</a> (replaced) [<a href="/pdf/2211.04118" title="Download PDF">pdf</a>, <a href="/format/2211.04118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConsPrompt: Exploiting Contrastive Samples for Fewshot Prompt Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weng%2C+J">Jinta Weng</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yifan Deng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+d+D">d Donghao Li</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+H">Hao You</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yue Hu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Heyan Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01789" title="Abstract">arXiv:2212.01789</a> (replaced) [<a href="/pdf/2212.01789" title="Download PDF">pdf</a>, <a href="/format/2212.01789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiscale Structure Guided Diffusion for Image Deblurring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+M">Mengwei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Delbracio%2C+M">Mauricio Delbracio</a>, 
<a href="/search/cs?searchtype=author&query=Talebi%2C+H">Hossein Talebi</a>, 
<a href="/search/cs?searchtype=author&query=Gerig%2C+G">Guido Gerig</a>, 
<a href="/search/cs?searchtype=author&query=Milanfar%2C+P">Peyman Milanfar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera ready for ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.03323" title="Abstract">arXiv:2212.03323</a> (replaced) [<a href="/pdf/2212.03323" title="Download PDF">pdf</a>, <a href="/format/2212.03323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Receding Horizon Planning with Rule Hierarchies for Autonomous Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Veer%2C+S">Sushant Veer</a>, 
<a href="/search/cs?searchtype=author&query=Leung%2C+K">Karen Leung</a>, 
<a href="/search/cs?searchtype=author&query=Cosner%2C+R">Ryan Cosner</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuxiao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Karkus%2C+P">Peter Karkus</a>, 
<a href="/search/cs?searchtype=author&query=Pavone%2C+M">Marco Pavone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09512" title="Abstract">arXiv:2212.09512</a> (replaced) [<a href="/pdf/2212.09512" title="Download PDF">pdf</a>, <a href="/format/2212.09512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Label Smoothing on Multi-hop Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhangyue Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiannian Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yiguang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhao Cao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures, accepted by CCL2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00736" title="Abstract">arXiv:2301.00736</a> (replaced) [<a href="/pdf/2301.00736" title="Download PDF">pdf</a>, <a href="/format/2301.00736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed moving average field guided learning for spatio-temporal data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Curato%2C+I+V">Imma Valentina Curato</a>, 
<a href="/search/stat?searchtype=author&query=Furat%2C+O">Orkun Furat</a>, 
<a href="/search/stat?searchtype=author&query=Proietti%2C+L">Lorenzo Proietti</a>, 
<a href="/search/stat?searchtype=author&query=Stroeh%2C+B">Bennet Stroeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.04037" title="Abstract">arXiv:2301.04037</a> (replaced) [<a href="/pdf/2301.04037" title="Download PDF">pdf</a>, <a href="/format/2301.04037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ROBUSfT: Robust Real-Time Shape-from-Template, a C++ Library
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shetab-Bushehri%2C+M">Mohammadreza Shetab-Bushehri</a>, 
<a href="/search/cs?searchtype=author&query=Aranda%2C+M">Miguel Aranda</a>, 
<a href="/search/cs?searchtype=author&query=Mezouar%2C+Y">Youcef Mezouar</a>, 
<a href="/search/cs?searchtype=author&query=Bartoli%2C+A">Adrien Bartoli</a>, 
<a href="/search/cs?searchtype=author&query=Ozgur%2C+E">Erol Ozgur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the arXiv version of an article published in Image and Vision Computing. Please cite the accepted version: M. Shetab-Bushehri, M. Aranda, E. Ozgur, Y. Mezouar and Adrien Bartoli "ROBUSfT: Robust Real-Time Shape-from-Template, a C++ Library," in Image and Vision Computing, doi: 10.1016/j.imavis.2023.104867
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07700" title="Abstract">arXiv:2301.07700</a> (replaced) [<a href="/pdf/2301.07700" title="Download PDF">pdf</a>, <a href="/ps/2301.07700" title="Download PostScript">ps</a>, <a href="/format/2301.07700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention2Minority: A salient instance inference-based multiple instance  learning for classifying small lesions in whole slide images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+Z">Ziyu Su</a>, 
<a href="/search/cs?searchtype=author&query=Rezapour%2C+M">Mostafa Rezapour</a>, 
<a href="/search/cs?searchtype=author&query=Sajjad%2C+U">Usama Sajjad</a>, 
<a href="/search/cs?searchtype=author&query=Gurcan%2C+M+N">Metin Nafi Gurcan</a>, 
<a href="/search/cs?searchtype=author&query=Niazi%2C+M+K+K">Muhammad Khalid Khan Niazi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10814" title="Abstract">arXiv:2301.10814</a> (replaced) [<a href="/pdf/2301.10814" title="Download PDF">pdf</a>, <a href="/format/2301.10814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Protein-Ligand Binding Energy Prediction via Neural Euler&#x27;s  Rotation Equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Jin%2C+W">Wengong Jin</a>, 
<a href="/search/q-bio?searchtype=author&query=Sarkizova%2C+S">Siranush Sarkizova</a>, 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+X">Xun Chen</a>, 
<a href="/search/q-bio?searchtype=author&query=Hacohen%2C+N">Nir Hacohen</a>, 
<a href="/search/q-bio?searchtype=author&query=Uhler%2C+C">Caroline Uhler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11573" title="Abstract">arXiv:2301.11573</a> (replaced) [<a href="/pdf/2301.11573" title="Download PDF">pdf</a>, <a href="/format/2301.11573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the optimality of Kalman Filter for Fault Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+J">Jinming Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+Y">Yucai Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12361" title="Abstract">arXiv:2301.12361</a> (replaced) [<a href="/pdf/2301.12361" title="Download PDF">pdf</a>, <a href="/format/2301.12361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Harmony: Denoising and Nuclear-Norm Wasserstein Adaptation for  Enhanced Domain Transfer in Graph-Structured Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Mengxi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Rostami%2C+M">Mohammad Rostami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13428" title="Abstract">arXiv:2301.13428</a> (replaced) [<a href="/pdf/2301.13428" title="Download PDF">pdf</a>, <a href="/format/2301.13428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrast and Clustering: Learning Neighborhood Pair Representation for  Source-free Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiangbin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yonggang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingjian Li</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+H">Haojie Fang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Journal articles
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01403" title="Abstract">arXiv:2302.01403</a> (replaced) [<a href="/pdf/2302.01403" title="Download PDF">pdf</a>, <a href="/format/2302.01403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Relation Alignment for Scene Graph Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bicheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+R">Renjie Liao</a>, 
<a href="/search/cs?searchtype=author&query=Sigal%2C+L">Leonid Sigal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04581" title="Abstract">arXiv:2302.04581</a> (replaced) [<a href="/pdf/2302.04581" title="Download PDF">pdf</a>, <a href="/format/2302.04581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Reduction from Chores Allocation to Job Scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Segal-Halevi%2C+E">Erel Segal-Halevi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of paper accepted to EC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06258" title="Abstract">arXiv:2302.06258</a> (replaced) [<a href="/pdf/2302.06258" title="Download PDF">pdf</a>, <a href="/ps/2302.06258" title="Download PostScript">ps</a>, <a href="/format/2302.06258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recognizability in S-adic shifts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%A9al%2C+M">Marie-Pierre B&#xe9;al</a> (LIGM), 
<a href="/search/cs?searchtype=author&query=Perrin%2C+D">Dominique Perrin</a> (LIGM), 
<a href="/search/cs?searchtype=author&query=Restivo%2C+A">Antonio Restivo</a>, 
<a href="/search/cs?searchtype=author&query=Steiner%2C+W">Wolfgang Steiner</a> (IRIF (UMR\_8243))
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07350" title="Abstract">arXiv:2302.07350</a> (replaced) [<a href="/pdf/2302.07350" title="Download PDF">pdf</a>, <a href="/format/2302.07350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph schemas as abstractions for transfer learning, inference, and  planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guntupalli%2C+J+S">J. Swaroop Guntupalli</a>, 
<a href="/search/cs?searchtype=author&query=Raju%2C+R+V">Rajkumar Vasudeva Raju</a>, 
<a href="/search/cs?searchtype=author&query=Kushagra%2C+S">Shrinu Kushagra</a>, 
<a href="/search/cs?searchtype=author&query=Wendelken%2C+C">Carter Wendelken</a>, 
<a href="/search/cs?searchtype=author&query=Sawyer%2C+D">Danny Sawyer</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+I">Ishan Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Guangyao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%A1zaro-Gredilla%2C+M">Miguel L&#xe1;zaro-Gredilla</a>, 
<a href="/search/cs?searchtype=author&query=George%2C+D">Dileep George</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 figures in main paper, 13 pages and 8 figures in appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10915" title="Abstract">arXiv:2302.10915</a> (replaced) [<a href="/pdf/2302.10915" title="Download PDF">pdf</a>, <a href="/format/2302.10915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conformers are All You Need for Visual Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+O">Oscar Chang</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+H">Hank Liao</a>, 
<a href="/search/cs?searchtype=author&query=Serdyuk%2C+D">Dmitriy Serdyuk</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Ankit Shah</a>, 
<a href="/search/cs?searchtype=author&query=Siohan%2C+O">Olivier Siohan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14407" title="Abstract">arXiv:2302.14407</a> (replaced) [<a href="/pdf/2302.14407" title="Download PDF">pdf</a>, <a href="/format/2302.14407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Choice of Noninformative Priors for Thompson Sampling in  Multiparameter Bandit Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jongyeong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Chiang%2C+C">Chao-Kai Chiang</a>, 
<a href="/search/cs?searchtype=author&query=Sugiyama%2C+M">Masashi Sugiyama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 55 pages, TBA AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00879" title="Abstract">arXiv:2303.00879</a> (replaced) [<a href="/pdf/2303.00879" title="Download PDF">pdf</a>, <a href="/ps/2303.00879" title="Download PostScript">ps</a>, <a href="/format/2303.00879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Categorical magnitude and entropy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+S">Stephanie Chen</a>, 
<a href="/search/math?searchtype=author&query=Vigneaux%2C+J+P">Juan Pablo Vigneaux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, published in GSI 2023 conference proceedings
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In: Nielsen, F., Barbaresco, F. (eds) Geometric Science of
  Information. GSI 2023. Lecture Notes in Computer Science, vol 14071.
  Springer, Cham
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02491" title="Abstract">arXiv:2303.02491</a> (replaced) [<a href="/pdf/2303.02491" title="Download PDF">pdf</a>, <a href="/format/2303.02491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Electrical Flows for Polylogarithmic Competitive Oblivious Routing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goranci%2C+G">Gramoz Goranci</a>, 
<a href="/search/cs?searchtype=author&query=Henzinger%2C+M">Monika Henzinger</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%A4cke%2C+H">Harald R&#xe4;cke</a>, 
<a href="/search/cs?searchtype=author&query=Sachdeva%2C+S">Sushant Sachdeva</a>, 
<a href="/search/cs?searchtype=author&query=Sricharan%2C+A+R">A. R. Sricharan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ITCS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02618" title="Abstract">arXiv:2303.02618</a> (replaced) [<a href="/pdf/2303.02618" title="Download PDF">pdf</a>, <a href="/format/2303.02618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensemble Reinforcement Learning: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yanjie Song</a>, 
<a href="/search/cs?searchtype=author&query=Suganthan%2C+P+N">P. N. Suganthan</a>, 
<a href="/search/cs?searchtype=author&query=Pedrycz%2C+W">Witold Pedrycz</a>, 
<a href="/search/cs?searchtype=author&query=Ou%2C+J">Junwei Ou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yongming He</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingwu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yutong Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02904" title="Abstract">arXiv:2303.02904</a> (replaced) [<a href="/pdf/2303.02904" title="Download PDF">pdf</a>, <a href="/format/2303.02904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social Cue Detection and Analysis Using Transfer Entropy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Haoyang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Croft%2C+E+A">Elizabeth A. Croft</a>, 
<a href="/search/cs?searchtype=author&query=Burke%2C+M+G">Michael G. Burke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures. Preprint. To be published in Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction (HRI '24), March 11--14, 2024, Boulder, CO, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05397" title="Abstract">arXiv:2303.05397</a> (replaced) [<a href="/pdf/2303.05397" title="Download PDF">pdf</a>, <a href="/format/2303.05397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TOLD: A Novel Two-Stage Overlap-Aware Framework for Speaker Diarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zhihao Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiliang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06510" title="Abstract">arXiv:2303.06510</a> (replaced) [<a href="/pdf/2303.06510" title="Download PDF">pdf</a>, <a href="/format/2303.06510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E2CoPre: Energy Efficient and Cooperative Collision Avoidance for UAV  Swarms with Trajectory Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shuangyao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haibo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhiyi Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09797" title="Abstract">arXiv:2303.09797</a> (replaced) [<a href="/pdf/2303.09797" title="Download PDF">pdf</a>, <a href="/format/2303.09797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MMFace4D: A Large-Scale Multi-Modal 4D Face Dataset for Audio-Driven 3D  Face Animation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haozhe Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jia Jia</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+J">Junliang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiangyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jelo Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures. This paper has been submitted to IEEE Transaction on MultiMedia, which is the extension of our MM2023 paper <a href="/abs/2308.05428">arXiv:2308.05428</a>. The dataset is now publicly available, see Project page at <a href="https://wuhaozhe.github.io/mmface4d/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10554" title="Abstract">arXiv:2303.10554</a> (replaced) [<a href="/pdf/2303.10554" title="Download PDF">pdf</a>, <a href="/ps/2303.10554" title="Download PostScript">ps</a>, <a href="/format/2303.10554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inexact Newton Methods for Solving Generalized Equations on Riemannian  Manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Louzeiro%2C+M+S">Mauricio S. Louzeiro</a>, 
<a href="/search/math?searchtype=author&query=Silva%2C+G+N">Gilson N. Silva</a>, 
<a href="/search/math?searchtype=author&query=Yuan%2C+J">Jinyun Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11420" title="Abstract">arXiv:2303.11420</a> (replaced) [<a href="/pdf/2303.11420" title="Download PDF">pdf</a>, <a href="/format/2303.11420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ADCNet: Learning from Raw Radar Data via Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+B">Bo Yang</a>, 
<a href="/search/eess?searchtype=author&query=Khatri%2C+I">Ishan Khatri</a>, 
<a href="/search/eess?searchtype=author&query=Happold%2C+M">Michael Happold</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+C">Chulong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Update 12/13/2023: upgrade organization and presentation of the paper, adding appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17728" title="Abstract">arXiv:2303.17728</a> (replaced) [<a href="/pdf/2303.17728" title="Download PDF">pdf</a>, <a href="/ps/2303.17728" title="Download PostScript">ps</a>, <a href="/format/2303.17728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of GPT and BERT-based models on identifying protein-protein  interactions in biomedical text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rehana%2C+H">Hasin Rehana</a>, 
<a href="/search/cs?searchtype=author&query=%C3%87am%2C+N+B">Nur Bengisu &#xc7;am</a>, 
<a href="/search/cs?searchtype=author&query=Basmaci%2C+M">Mert Basmaci</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jie Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Jemiyo%2C+C">Christianah Jemiyo</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yongqun He</a>, 
<a href="/search/cs?searchtype=author&query=%C3%96zg%C3%BCr%2C+A">Arzucan &#xd6;zg&#xfc;r</a>, 
<a href="/search/cs?searchtype=author&query=Hur%2C+J">Junguk Hur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00432" title="Abstract">arXiv:2304.00432</a> (replaced) [<a href="/pdf/2304.00432" title="Download PDF">pdf</a>, <a href="/format/2304.00432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Reachability Calibration with Conformal Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Muthali%2C+A">Anish Muthali</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+H">Haotian Shen</a>, 
<a href="/search/eess?searchtype=author&query=Deglurkar%2C+S">Sampada Deglurkar</a>, 
<a href="/search/eess?searchtype=author&query=Lim%2C+M+H">Michael H. Lim</a>, 
<a href="/search/eess?searchtype=author&query=Roelofs%2C+R">Rebecca Roelofs</a>, 
<a href="/search/eess?searchtype=author&query=Faust%2C+A">Aleksandra Faust</a>, 
<a href="/search/eess?searchtype=author&query=Tomlin%2C+C">Claire Tomlin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01075" title="Abstract">arXiv:2304.01075</a> (replaced) [<a href="/pdf/2304.01075" title="Download PDF">pdf</a>, <a href="/format/2304.01075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conformal Prediction Regions for Time Series using Linear  Complementarity Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cleaveland%2C+M">Matthew Cleaveland</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+I">Insup Lee</a>, 
<a href="/search/eess?searchtype=author&query=Pappas%2C+G+J">George J. Pappas</a>, 
<a href="/search/eess?searchtype=author&query=Lindemann%2C+L">Lars Lindemann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01652" title="Abstract">arXiv:2304.01652</a> (replaced) [<a href="/pdf/2304.01652" title="Download PDF">pdf</a>, <a href="/ps/2304.01652" title="Download PostScript">ps</a>, <a href="/format/2304.01652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Barrier Function-based Distributed Symbolic Controller for Multi-Agent  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sundarsingh%2C+D+S">David Smith Sundarsingh</a>, 
<a href="/search/eess?searchtype=author&query=Das%2C+R">Ratnangshu Das</a>, 
<a href="/search/eess?searchtype=author&query=Saoud%2C+A">Adnane Saoud</a>, 
<a href="/search/eess?searchtype=author&query=Jagtap%2C+P">Pushpak Jagtap</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Provided analysis on conservatism of the controller
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07699" title="Abstract">arXiv:2304.07699</a> (replaced) [<a href="/pdf/2304.07699" title="Download PDF">pdf</a>, <a href="/format/2304.07699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Clustering Framework for Unsupervised and Semi-supervised New Intent  Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanlei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hua Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+F">Fei Long</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+K">Kai Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE TKDE
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Knowledge and Data Engineering 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07939" title="Abstract">arXiv:2304.07939</a> (replaced) [<a href="/pdf/2304.07939" title="Download PDF">pdf</a>, <a href="/format/2304.07939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging sparse and shared feature activations for disentangled  representation learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fumero%2C+M">Marco Fumero</a>, 
<a href="/search/cs?searchtype=author&query=Wenzel%2C+F">Florian Wenzel</a>, 
<a href="/search/cs?searchtype=author&query=Zancato%2C+L">Luca Zancato</a>, 
<a href="/search/cs?searchtype=author&query=Achille%2C+A">Alessandro Achille</a>, 
<a href="/search/cs?searchtype=author&query=Rodol%C3%A0%2C+E">Emanuele Rodol&#xe0;</a>, 
<a href="/search/cs?searchtype=author&query=Soatto%2C+S">Stefano Soatto</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>, 
<a href="/search/cs?searchtype=author&query=Locatello%2C+F">Francesco Locatello</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08083" title="Abstract">arXiv:2304.08083</a> (replaced) [<a href="/pdf/2304.08083" title="Download PDF">pdf</a>, <a href="/format/2304.08083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VCD: Visual Causality Discovery for Cross-Modal Question Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Ying Tan</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jingzhou Luo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weixing Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures. arXiv admin note: substantial text overlap with <a href="/abs/2207.12647">arXiv:2207.12647</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08485" title="Abstract">arXiv:2304.08485</a> (replaced) [<a href="/pdf/2304.08485" title="Download PDF">pdf</a>, <a href="/format/2304.08485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Instruction Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haotian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y+J">Yong Jae Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Oral; project page: <a href="https://llava-vl.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09329" title="Abstract">arXiv:2304.09329</a> (replaced) [<a href="/pdf/2304.09329" title="Download PDF">pdf</a>, <a href="/format/2304.09329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Transmit with Provable Guarantees in Wireless Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boning Li</a>, 
<a href="/search/cs?searchtype=author&query=Perazzone%2C+J">Jake Perazzone</a>, 
<a href="/search/cs?searchtype=author&query=Swami%2C+A">Ananthram Swami</a>, 
<a href="/search/cs?searchtype=author&query=Segarra%2C+S">Santiago Segarra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10464" title="Abstract">arXiv:2304.10464</a> (replaced) [<a href="/pdf/2304.10464" title="Download PDF">pdf</a>, <a href="/format/2304.10464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Plan with Natural Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yiduo Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yaobo Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenfei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenshan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongyan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+N">Nan Duan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Large Language Model, Learning from feedback, Planning and Reasoning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11125" title="Abstract">arXiv:2304.11125</a> (replaced) [<a href="/pdf/2304.11125" title="Download PDF">pdf</a>, <a href="/format/2304.11125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implementing and Evaluating Security in O-RAN: Interfaces, Intelligence,  and Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Groen%2C+J">Joshua Groen</a>, 
<a href="/search/cs?searchtype=author&query=DOro%2C+S">Salvatore DOro</a>, 
<a href="/search/cs?searchtype=author&query=Demir%2C+U">Utku Demir</a>, 
<a href="/search/cs?searchtype=author&query=Bonati%2C+L">Leonardo Bonati</a>, 
<a href="/search/cs?searchtype=author&query=Polese%2C+M">Michele Polese</a>, 
<a href="/search/cs?searchtype=author&query=Melodia%2C+T">Tommaso Melodia</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+K">Kaushik Chowdhury</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, 1 table, submitted to IEEE Network Magazine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12477" title="Abstract">arXiv:2304.12477</a> (replaced) [<a href="/pdf/2304.12477" title="Download PDF">pdf</a>, <a href="/format/2304.12477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Dynamic Programming Decompositions of Static Risk Measures in Markov  Decision Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hau%2C+J+L">Jia Lin Hau</a>, 
<a href="/search/math?searchtype=author&query=Delage%2C+E">Erick Delage</a>, 
<a href="/search/math?searchtype=author&query=Ghavamzadeh%2C+M">Mohammad Ghavamzadeh</a>, 
<a href="/search/math?searchtype=author&query=Petrik%2C+M">Marek Petrik</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Advances in Neural Information Processing Systems (Neurips), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12683" title="Abstract">arXiv:2304.12683</a> (replaced) [<a href="/pdf/2304.12683" title="Download PDF">pdf</a>, <a href="/format/2304.12683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imaging a moving point source from multi-frequency data measured at one  and sparse observation points (part II): near-field case in 3D
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ma%2C+G">Guanqiu Ma</a>, 
<a href="/search/math?searchtype=author&query=Guo%2C+H">Hongxia Guo</a>, 
<a href="/search/math?searchtype=author&query=Hu%2C+G">Guanghui Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2212.14236">arXiv:2212.14236</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13850" title="Abstract">arXiv:2304.13850</a> (replaced) [<a href="/pdf/2304.13850" title="Download PDF">pdf</a>, <a href="/format/2304.13850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do SSL Models Have D&#xe9;j&#xe0; Vu? A Case of Unintended Memorization in  Self-supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meehan%2C+C">Casey Meehan</a>, 
<a href="/search/cs?searchtype=author&query=Bordes%2C+F">Florian Bordes</a>, 
<a href="/search/cs?searchtype=author&query=Vincent%2C+P">Pascal Vincent</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhuri%2C+K">Kamalika Chaudhuri</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Chuan Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14365" title="Abstract">arXiv:2304.14365</a> (replaced) [<a href="/pdf/2304.14365" title="Download PDF">pdf</a>, <a href="/format/2304.14365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Occ3D: A Large-Scale 3D Occupancy Prediction Benchmark for Autonomous  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+X">Xiaoyu Tian</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+T">Tao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+L">Longfei Yun</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yucheng Mao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Huitong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yilun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hang Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02148" title="Abstract">arXiv:2305.02148</a> (replaced) [<a href="/pdf/2305.02148" title="Download PDF">pdf</a>, <a href="/ps/2305.02148" title="Download PostScript">ps</a>, <a href="/format/2305.02148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Supervised Segmentation of Functional Tissue Units at the Cellular  Level
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sydorskyi%2C+V">Volodymyr Sydorskyi</a>, 
<a href="/search/eess?searchtype=author&query=Krashenyi%2C+I">Igor Krashenyi</a>, 
<a href="/search/eess?searchtype=author&query=Sakva%2C+D">Denis Sakva</a>, 
<a href="/search/eess?searchtype=author&query=Zarichkovyi%2C+O">Oleksandr Zarichkovyi</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IT&amp;I-WS 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03520" title="Abstract">arXiv:2305.03520</a> (replaced) [<a href="/pdf/2305.03520" title="Download PDF">pdf</a>, <a href="/ps/2305.03520" title="Download PostScript">ps</a>, <a href="/format/2305.03520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-Aware Semantic Similarity Measurement for Unsupervised Word  Sense Disambiguation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martinez-Gil%2C+J">Jorge Martinez-Gil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03969" title="Abstract">arXiv:2305.03969</a> (replaced) [<a href="/pdf/2305.03969" title="Download PDF">pdf</a>, <a href="/ps/2305.03969" title="Download PostScript">ps</a>, <a href="/format/2305.03969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Compression and Deadline Optimization for Wireless Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Maojun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dongzhu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+R">Richeng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+G">Guangxu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+C">Caijun Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Quek%2C+T+Q+S">Tony Q.S. Quek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, accepted by IEEE Transactions on Mobile Computing (TMC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05959" title="Abstract">arXiv:2305.05959</a> (replaced) [<a href="/pdf/2305.05959" title="Download PDF">pdf</a>, <a href="/format/2305.05959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survey of Code Search Based on Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yutao Xie</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiayi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hande Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhonghai Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 10 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM Transactions on Software Engineering and Methodology 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06152" title="Abstract">arXiv:2305.06152</a> (replaced) [<a href="/pdf/2305.06152" title="Download PDF">pdf</a>, <a href="/format/2305.06152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure-CLIP: Towards Scene Graph Knowledge to Enhance Multi-modal  Structured Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yufeng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiji Tang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rongsheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weijie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhou Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+T">Tangjie Lv</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhipeng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wen Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024, <a href="https://github.com/zjukg/Structure-CLIP">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06161" title="Abstract">arXiv:2305.06161</a> (replaced) [<a href="/pdf/2305.06161" title="Download PDF">pdf</a>, <a href="/format/2305.06161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StarCoder: may the source be with you!
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Raymond Li</a>, 
<a href="/search/cs?searchtype=author&query=Allal%2C+L+B">Loubna Ben Allal</a>, 
<a href="/search/cs?searchtype=author&query=Zi%2C+Y">Yangtian Zi</a>, 
<a href="/search/cs?searchtype=author&query=Muennighoff%2C+N">Niklas Muennighoff</a>, 
<a href="/search/cs?searchtype=author&query=Kocetkov%2C+D">Denis Kocetkov</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+C">Chenghao Mou</a>, 
<a href="/search/cs?searchtype=author&query=Marone%2C+M">Marc Marone</a>, 
<a href="/search/cs?searchtype=author&query=Akiki%2C+C">Christopher Akiki</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Chim%2C+J">Jenny Chim</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zheltonozhskii%2C+E">Evgenii Zheltonozhskii</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+T+Y">Terry Yue Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Thomas Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dehaene%2C+O">Olivier Dehaene</a>, 
<a href="/search/cs?searchtype=author&query=Davaadorj%2C+M">Mishig Davaadorj</a>, 
<a href="/search/cs?searchtype=author&query=Lamy-Poirier%2C+J">Joel Lamy-Poirier</a>, 
<a href="/search/cs?searchtype=author&query=Monteiro%2C+J">Jo&#xe3;o Monteiro</a>, 
<a href="/search/cs?searchtype=author&query=Shliazhko%2C+O">Oleh Shliazhko</a>, 
<a href="/search/cs?searchtype=author&query=Gontier%2C+N">Nicolas Gontier</a>, 
<a href="/search/cs?searchtype=author&query=Meade%2C+N">Nicholas Meade</a>, 
<a href="/search/cs?searchtype=author&query=Zebaze%2C+A">Armel Zebaze</a>, 
<a href="/search/cs?searchtype=author&query=Yee%2C+M">Ming-Ho Yee</a>, 
<a href="/search/cs?searchtype=author&query=Umapathi%2C+L+K">Logesh Kumar Umapathi</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jian Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lipkin%2C+B">Benjamin Lipkin</a>, 
<a href="/search/cs?searchtype=author&query=Oblokulov%2C+M">Muhtasham Oblokulov</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiruo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Murthy%2C+R">Rudra Murthy</a>, 
<a href="/search/cs?searchtype=author&query=Stillerman%2C+J">Jason Stillerman</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+S+S">Siva Sankalp Patel</a>, 
<a href="/search/cs?searchtype=author&query=Abulkhanov%2C+D">Dmitry Abulkhanov</a>, 
<a href="/search/cs?searchtype=author&query=Zocca%2C+M">Marco Zocca</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+M">Manan Dey</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhihan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fahmy%2C+N">Nour Fahmy</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharyya%2C+U">Urvashi Bhattacharyya</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenhao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Swayam Singh</a>, 
<a href="/search/cs?searchtype=author&query=Luccioni%2C+S">Sasha Luccioni</a>, 
<a href="/search/cs?searchtype=author&query=Villegas%2C+P">Paulo Villegas</a>, 
<a href="/search/cs?searchtype=author&query=Kunakov%2C+M">Maxim Kunakov</a>, 
<a href="/search/cs?searchtype=author&query=Zhdanov%2C+F">Fedor Zhdanov</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+M">Manuel Romero</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+T">Tony Lee</a>, 
<a href="/search/cs?searchtype=author&query=Timor%2C+N">Nadav Timor</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jennifer Ding</a>, 
<a href="/search/cs?searchtype=author&query=Schlesinger%2C+C">Claire Schlesinger</a>, 
<a href="/search/cs?searchtype=author&query=Schoelkopf%2C+H">Hailey Schoelkopf</a>, 
<a href="/search/cs?searchtype=author&query=Ebert%2C+J">Jan Ebert</a>, 
<a href="/search/cs?searchtype=author&query=Dao%2C+T">Tri Dao</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+M">Mayank Mishra</a>,  et al. (15 additional authors not shown)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Programming Languages (cs.PL); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06408" title="Abstract">arXiv:2305.06408</a> (replaced) [<a href="/pdf/2305.06408" title="Download PDF">pdf</a>, <a href="/format/2305.06408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Batch Active Learning Using Continual Learning Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Arnav Das</a>, 
<a href="/search/cs?searchtype=author&query=Bhatt%2C+G">Gantavya Bhatt</a>, 
<a href="/search/cs?searchtype=author&query=Bhalerao%2C+M">Megh Bhalerao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+V">Vianne Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Rui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Bilmes%2C+J">Jeff Bilmes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appeared in TMLR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09515" title="Abstract">arXiv:2305.09515</a> (replaced) [<a href="/pdf/2305.09515" title="Download PDF">pdf</a>, <a href="/format/2305.09515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AR-Diffusion: Auto-Regressive Diffusion Model for Text Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhihao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yeyun Gong</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yelong Shen</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+J">Jian Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hai-Tao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juntao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhongyu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jian Guo</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+N">Nan Duan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weizhu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accept By NIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10108" title="Abstract">arXiv:2305.10108</a> (replaced) [<a href="/pdf/2305.10108" title="Download PDF">pdf</a>, <a href="/ps/2305.10108" title="Download PostScript">ps</a>, <a href="/format/2305.10108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> List 3-Coloring on Comb-Convex and Caterpillar-Convex Bipartite Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C5%9Een%2C+B+B">Banu Baklan &#x15e;en</a>, 
<a href="/search/cs?searchtype=author&query=Diner%2C+%C3%96+Y">&#xd6;znur Ya&#x15f;ar Diner</a>, 
<a href="/search/cs?searchtype=author&query=Erlebach%2C+T">Thomas Erlebach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An extended abstract of the paper appears in the proceedings of the 29th International Computing and Combinatorics Conference (COCOON 2023)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> LNCS 14422, Springer, 2023, pp. 168-181
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10697" title="Abstract">arXiv:2305.10697</a> (replaced) [<a href="/pdf/2305.10697" title="Download PDF">pdf</a>, <a href="/format/2305.10697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Blessing of Heterogeneity in Federated Q-Learning: Linear Speedup  and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Woo%2C+J">Jiin Woo</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+G">Gauri Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+Y">Yuejie Chi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Short version at ICML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18290" title="Abstract">arXiv:2305.18290</a> (replaced) [<a href="/pdf/2305.18290" title="Download PDF">pdf</a>, <a href="/format/2305.18290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Direct Preference Optimization: Your Language Model is Secretly a Reward  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rafailov%2C+R">Rafael Rafailov</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Archit Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+E">Eric Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Ermon%2C+S">Stefano Ermon</a>, 
<a href="/search/cs?searchtype=author&query=Manning%2C+C+D">Christopher D. Manning</a>, 
<a href="/search/cs?searchtype=author&query=Finn%2C+C">Chelsea Finn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19414" title="Abstract">arXiv:2305.19414</a> (replaced) [<a href="/pdf/2305.19414" title="Download PDF">pdf</a>, <a href="/format/2305.19414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Training of Energy-Based Models Using Jarzynski Equality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carbone%2C+D">Davide Carbone</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+M">Mengjian Hua</a>, 
<a href="/search/cs?searchtype=author&query=Coste%2C+S">Simon Coste</a>, 
<a href="/search/cs?searchtype=author&query=Vanden-Eijnden%2C+E">Eric Vanden-Eijnden</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Numerical Analysis (math.NA); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01808" title="Abstract">arXiv:2306.01808</a> (replaced) [<a href="/pdf/2306.01808" title="Download PDF">pdf</a>, <a href="/format/2306.01808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Morphology Edge Attention Network and Optimal Geometric Matching  Connection model for vascular segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhu%2C+Y">Yuntao Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Qiao%2C+Y">Yuxuan Qiao</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+X">Xiaoping Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03061" title="Abstract">arXiv:2306.03061</a> (replaced) [<a href="/pdf/2306.03061" title="Download PDF">pdf</a>, <a href="/format/2306.03061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structured Voronoi Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amini%2C+A">Afra Amini</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Li Du</a>, 
<a href="/search/cs?searchtype=author&query=Cotterell%2C+R">Ryan Cotterell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04064" title="Abstract">arXiv:2306.04064</a> (replaced) [<a href="/pdf/2306.04064" title="Download PDF">pdf</a>, <a href="/format/2306.04064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transferable Adversarial Robustness for Categorical Data via Universal  Robust Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kireev%2C+K">Klim Kireev</a>, 
<a href="/search/cs?searchtype=author&query=Andriushchenko%2C+M">Maksym Andriushchenko</a>, 
<a href="/search/cs?searchtype=author&query=Troncoso%2C+C">Carmela Troncoso</a>, 
<a href="/search/cs?searchtype=author&query=Flammarion%2C+N">Nicolas Flammarion</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07050" title="Abstract">arXiv:2306.07050</a> (replaced) [<a href="/pdf/2306.07050" title="Download PDF">pdf</a>, <a href="/format/2306.07050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Token Pruning for Object Detection and Instance Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yifei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gehrig%2C+M">Mathias Gehrig</a>, 
<a href="/search/cs?searchtype=author&query=Messikommer%2C+N">Nico Messikommer</a>, 
<a href="/search/cs?searchtype=author&query=Cannici%2C+M">Marco Cannici</a>, 
<a href="/search/cs?searchtype=author&query=Scaramuzza%2C+D">Davide Scaramuzza</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Winter Conference on Applications of Computer Vision (WACV
  2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09332" title="Abstract">arXiv:2306.09332</a> (replaced) [<a href="/pdf/2306.09332" title="Download PDF">pdf</a>, <a href="/ps/2306.09332" title="Download PostScript">ps</a>, <a href="/format/2306.09332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fit Like You Sample: Sample-Efficient Generalized Score Matching from  Fast Mixing Diffusions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yilong Qin</a>, 
<a href="/search/cs?searchtype=author&query=Risteski%2C+A">Andrej Risteski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09337" title="Abstract">arXiv:2306.09337</a> (replaced) [<a href="/pdf/2306.09337" title="Download PDF">pdf</a>, <a href="/format/2306.09337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Proxemics: A Prior for 3D Social Interaction from Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+L">Lea M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+V">Vickie Ye</a>, 
<a href="/search/cs?searchtype=author&query=Pavlakos%2C+G">Georgios Pavlakos</a>, 
<a href="/search/cs?searchtype=author&query=Black%2C+M">Michael Black</a>, 
<a href="/search/cs?searchtype=author&query=Kanazawa%2C+A">Angjoo Kanazawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: muelea.github.io/buddi
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10599" title="Abstract">arXiv:2306.10599</a> (replaced) [<a href="/pdf/2306.10599" title="Download PDF">pdf</a>, <a href="/ps/2306.10599" title="Download PostScript">ps</a>, <a href="/format/2306.10599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Study of Untangling Patterns of Two-Class Dependency Cycles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Q">Qiong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuwen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Huan Ji</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaotian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Peng Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint accepted for publication in Empirical Software Engineering, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13427" title="Abstract">arXiv:2306.13427</a> (replaced) [<a href="/pdf/2306.13427" title="Download PDF">pdf</a>, <a href="/format/2306.13427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Robustness Analysis to Structured Channel Tampering Over  Secure-by-Design Consensus Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fabris%2C+M">Marco Fabris</a>, 
<a href="/search/eess?searchtype=author&query=Zelazo%2C+D">Daniel Zelazo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures, this paper has been also accepted for a joint publication on the IEEE Conference on Decision and Control 2023 Marina Bay Sands, Singapore
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in IEEE Control Systems Letters, vol. 7, pp. 2011-2016, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14209" title="Abstract">arXiv:2306.14209</a> (replaced) [<a href="/pdf/2306.14209" title="Download PDF">pdf</a>, <a href="/format/2306.14209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep image prior inpainting of ancient frescoes in the Mediterranean  Alpine arc
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Merizzi%2C+F">Fabio Merizzi</a>, 
<a href="/search/cs?searchtype=author&query=Saillard%2C+P">Perrine Saillard</a>, 
<a href="/search/cs?searchtype=author&query=Acquier%2C+O">Oceane Acquier</a>, 
<a href="/search/cs?searchtype=author&query=Morotti%2C+E">Elena Morotti</a>, 
<a href="/search/cs?searchtype=author&query=Piccolomini%2C+E+L">Elena Loli Piccolomini</a>, 
<a href="/search/cs?searchtype=author&query=Calatroni%2C+L">Luca Calatroni</a>, 
<a href="/search/cs?searchtype=author&query=Dess%C3%AC%2C+R+M">Rosa Maria Dess&#xec;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17462" title="Abstract">arXiv:2306.17462</a> (replaced) [<a href="/pdf/2306.17462" title="Download PDF">pdf</a>, <a href="/format/2306.17462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CausalVLR: A Toolbox and Benchmark for Visual-Linguistic Causal  Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weixing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Liang Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CausalVLR: A Toolbox and Benchmark for Visual-Linguistic Causal Reasoning. <a href="https://github.com/HCPLab-SYSU/CausalVLR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02345" title="Abstract">arXiv:2307.02345</a> (replaced) [<a href="/pdf/2307.02345" title="Download PDF">pdf</a>, <a href="/format/2307.02345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLQL: Logistic Likelihood Q-Learning for Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lv%2C+O">Outongyi Lv</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bingxin Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07293" title="Abstract">arXiv:2307.07293</a> (replaced) [<a href="/pdf/2307.07293" title="Download PDF">pdf</a>, <a href="/ps/2307.07293" title="Download PostScript">ps</a>, <a href="/format/2307.07293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StegoHound: A Novel Multi-Approaches Method for Efficient and Effective  Identification and Extraction of Digital Evidence Masked by Steganographic  Techniques in WAV and MP3 Files
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghanem%2C+M+C">Mohamed C. Ghanem</a>, 
<a href="/search/cs?searchtype=author&query=Uribarri%2C+M+D">Maider D. Uribarri</a>, 
<a href="/search/cs?searchtype=author&query=Djemai%2C+R">Ramzi Djemai</a>, 
<a href="/search/cs?searchtype=author&query=Dunsin%2C+D">Dipo Dunsin</a>, 
<a href="/search/cs?searchtype=author&query=Araujo%2C+I+I">Istteffanny I. Araujo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Journal of Information Security and Cybercrimes Research- Post Review V3.1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10705" title="Abstract">arXiv:2307.10705</a> (replaced) [<a href="/pdf/2307.10705" title="Download PDF">pdf</a>, <a href="/format/2307.10705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TwinLiteNet: An Efficient and Lightweight Model for Driveable Area and  Lane Segmentation in Self-Driving Cars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Che%2C+Q+H">Quang Huy Che</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+P">Dinh Phuc Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+M+Q">Minh Quan Pham</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+D+K">Duc Khai Lam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by MAPR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12971" title="Abstract">arXiv:2307.12971</a> (replaced) [<a href="/pdf/2307.12971" title="Download PDF">pdf</a>, <a href="/format/2307.12971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Big Data -- Supply Chain Management Framework for Forecasting: Data  Preprocessing and Machine Learning Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jahin%2C+M+A">Md Abrar Jahin</a>, 
<a href="/search/cs?searchtype=author&query=Shovon%2C+M+S+H">Md Sakib Hossain Shovon</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+J">Jungpil Shin</a>, 
<a href="/search/cs?searchtype=author&query=Ridoy%2C+I+A">Istiyaque Ahmed Ridoy</a>, 
<a href="/search/cs?searchtype=author&query=Tomioka%2C+Y">Yoichi Tomioka</a>, 
<a href="/search/cs?searchtype=author&query=Mridha%2C+M+F">M. F. Mridha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00031" title="Abstract">arXiv:2308.00031</a> (replaced) [<a href="/pdf/2308.00031" title="Download PDF">pdf</a>, <a href="/format/2308.00031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning for Generative AI: State of the Art,  Opportunities and Open Research Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Franceschelli%2C+G">Giorgio Franceschelli</a>, 
<a href="/search/cs?searchtype=author&query=Musolesi%2C+M">Mirco Musolesi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 2 figures, 2 tables - Updated with the most recent papers plus improvements in figures and tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03977" title="Abstract">arXiv:2308.03977</a> (replaced) [<a href="/pdf/2308.03977" title="Download PDF">pdf</a>, <a href="/format/2308.03977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PUG: Photorealistic and Semantically Controllable Synthetic Data for  Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bordes%2C+F">Florian Bordes</a>, 
<a href="/search/cs?searchtype=author&query=Shekhar%2C+S">Shashank Shekhar</a>, 
<a href="/search/cs?searchtype=author&query=Ibrahim%2C+M">Mark Ibrahim</a>, 
<a href="/search/cs?searchtype=author&query=Bouchacourt%2C+D">Diane Bouchacourt</a>, 
<a href="/search/cs?searchtype=author&query=Vincent%2C+P">Pascal Vincent</a>, 
<a href="/search/cs?searchtype=author&query=Morcos%2C+A+S">Ari S. Morcos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05170" title="Abstract">arXiv:2308.05170</a> (replaced) [<a href="/pdf/2308.05170" title="Download PDF">pdf</a>, <a href="/format/2308.05170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FPGA Resource-aware Structured Pruning for Real-Time Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramhorst%2C+B">Benjamin Ramhorst</a>, 
<a href="/search/cs?searchtype=author&query=Loncar%2C+V">Vladimir Loncar</a>, 
<a href="/search/cs?searchtype=author&query=Constantinides%2C+G+A">George A. Constantinides</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07707" title="Abstract">arXiv:2308.07707</a> (replaced) [<a href="/pdf/2308.07707" title="Download PDF">pdf</a>, <a href="/format/2308.07707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Machine Unlearning Without Retraining Through Selective Synaptic  Dampening
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Foster%2C+J">Jack Foster</a>, 
<a href="/search/cs?searchtype=author&query=Schoepf%2C+S">Stefan Schoepf</a>, 
<a href="/search/cs?searchtype=author&query=Brintrup%2C+A">Alexandra Brintrup</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a main track paper at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08742" title="Abstract">arXiv:2308.08742</a> (replaced) [<a href="/pdf/2308.08742" title="Download PDF">pdf</a>, <a href="/format/2308.08742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PMET: Precise Model Editing in a Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaopeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shasha Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shezheng Song</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jie Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09065" title="Abstract">arXiv:2308.09065</a> (replaced) [<a href="/pdf/2308.09065" title="Download PDF">pdf</a>, <a href="/format/2308.09065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discretization-Induced Dirichlet Posterior for Robust Uncertainty  Quantification on Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xuanlong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Franchi%2C+G">Gianni Franchi</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jindong Gu</a>, 
<a href="/search/cs?searchtype=author&query=Aldea%2C+E">Emanuel Aldea</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages with main paper and supplymentary material. Accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09888" title="Abstract">arXiv:2308.09888</a> (replaced) [<a href="/pdf/2308.09888" title="Download PDF">pdf</a>, <a href="/format/2308.09888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Estimating the Gradient of the Expected Information Gain in Bayesian  Experimental Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ao%2C+Z">Ziqiao Ao</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+J">Jinglai Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14075" title="Abstract">arXiv:2308.14075</a> (replaced) [<a href="/pdf/2308.14075" title="Download PDF">pdf</a>, <a href="/format/2308.14075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FaceCoresetNet: Differentiable Coresets for Face Set Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shapira%2C+G">Gil Shapira</a>, 
<a href="/search/cs?searchtype=author&query=Keller%2C+Y">Yosi Keller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14490" title="Abstract">arXiv:2308.14490</a> (replaced) [<a href="/pdf/2308.14490" title="Download PDF">pdf</a>, <a href="/format/2308.14490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient least squares approximation and collocation methods using  radial basis functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhou%2C+Y">Yiqing Zhou</a>, 
<a href="/search/math?searchtype=author&query=Huybrechs%2C+D">Daan Huybrechs</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15444" title="Abstract">arXiv:2308.15444</a> (replaced) [<a href="/pdf/2308.15444" title="Download PDF">pdf</a>, <a href="/format/2308.15444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the hardness of inclusion-wise minimal separators enumeration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brosse%2C+C">Caroline Brosse</a>, 
<a href="/search/cs?searchtype=author&query=Defrain%2C+O">Oscar Defrain</a>, 
<a href="/search/cs?searchtype=author&query=Kurita%2C+K">Kazuhiro Kurita</a>, 
<a href="/search/cs?searchtype=author&query=Limouzy%2C+V">Vincent Limouzy</a>, 
<a href="/search/cs?searchtype=author&query=Uno%2C+T">Takeaki Uno</a>, 
<a href="/search/cs?searchtype=author&query=Wasa%2C+K">Kunihiro Wasa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00752" title="Abstract">arXiv:2309.00752</a> (replaced) [<a href="/pdf/2309.00752" title="Download PDF">pdf</a>, <a href="/format/2309.00752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Affine-Transformation-Invariant Image Classification by Differentiable  Arithmetic Distribution Module
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zijie Tan</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+G">Guanfang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chenqiu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Basu%2C+A">Anup Basu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01226" title="Abstract">arXiv:2309.01226</a> (replaced) [<a href="/pdf/2309.01226" title="Download PDF">pdf</a>, <a href="/format/2309.01226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Saturn: An Optimized Data System for Large Model Deep Learning Workloads
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nagrecha%2C+K">Kabir Nagrecha</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Arun Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at VLDB '24. Code available: <a href="https://github.com/knagrecha/saturn.">this https URL</a> 12 pages + 3 pages references + 2 pages appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01922" title="Abstract">arXiv:2309.01922</a> (replaced) [<a href="/pdf/2309.01922" title="Download PDF">pdf</a>, <a href="/ps/2309.01922" title="Download PostScript">ps</a>, <a href="/format/2309.01922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regret Analysis of Policy Gradient Algorithm for Infinite Horizon  Average Reward Markov Decision Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+Q">Qinbo Bai</a>, 
<a href="/search/cs?searchtype=author&query=Mondal%2C+W+U">Washim Uddin Mondal</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+V">Vaneet Aggarwal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02784" title="Abstract">arXiv:2309.02784</a> (replaced) [<a href="/pdf/2309.02784" title="Download PDF">pdf</a>, <a href="/format/2309.02784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Norm Tweaking: High-performance Low-bit Quantization of Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qingyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+X">Xiangxiang Chu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03206" title="Abstract">arXiv:2309.03206</a> (replaced) [<a href="/pdf/2309.03206" title="Download PDF">pdf</a>, <a href="/ps/2309.03206" title="Download PostScript">ps</a>, <a href="/format/2309.03206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A note on $t$-designs in isodual codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Awada%2C+M">Madoka Awada</a>, 
<a href="/search/math?searchtype=author&query=Miezaki%2C+T">Tsuyoshi Miezaki</a>, 
<a href="/search/math?searchtype=author&query=Munemasa%2C+A">Akihiro Munemasa</a>, 
<a href="/search/math?searchtype=author&query=Nakasora%2C+H">Hiroyuki Nakasora</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages. arXiv admin note: text overlap with <a href="/abs/2303.16349">arXiv:2303.16349</a>. substantial text overlap with <a href="/abs/2305.03285">arXiv:2305.03285</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Information Theory (cs.IT); Group Theory (math.GR); Number Theory (math.NT)

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03999" title="Abstract">arXiv:2309.03999</a> (replaced) [<a href="/pdf/2309.03999" title="Download PDF">pdf</a>, <a href="/format/2309.03999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapting Self-Supervised Representations to Multi-Domain Setups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalibhat%2C+N">Neha Kalibhat</a>, 
<a href="/search/cs?searchtype=author&query=Sharpe%2C+S">Sam Sharpe</a>, 
<a href="/search/cs?searchtype=author&query=Goodsitt%2C+J">Jeremy Goodsitt</a>, 
<a href="/search/cs?searchtype=author&query=Bruss%2C+B">Bayan Bruss</a>, 
<a href="/search/cs?searchtype=author&query=Feizi%2C+S">Soheil Feizi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at BMVC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04856" title="Abstract">arXiv:2309.04856</a> (replaced) [<a href="/pdf/2309.04856" title="Download PDF">pdf</a>, <a href="/format/2309.04856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AmbientFlow: Invertible generative models from incomplete, noisy  measurements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kelkar%2C+V+A">Varun A. Kelkar</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+R">Rucha Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+A">Arindam Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Anastasio%2C+M+A">Mark A. Anastasio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Transactions on Machine Learning Research (TMLR). OpenReview: <a href="https://openreview.net/forum?id=txpYITR8oa">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06260" title="Abstract">arXiv:2309.06260</a> (replaced) [<a href="/pdf/2309.06260" title="Download PDF">pdf</a>, <a href="/format/2309.06260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Discretization-Consistent Closure Schemes for Large Eddy  Simulation Using Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Beck%2C+A">Andrea Beck</a>, 
<a href="/search/physics?searchtype=author&query=Kurz%2C+M">Marius Kurz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 14 figures. Accepted Manuscript. This article may be downloaded for personal use only. Any other use requires prior permission of the author and AIP Publishing. This article appeared in Physics of Fluids 35 (2023) and may be found at <a href="https://doi.org/10.1063/5.0176223">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Physics of Fluids 35 (2023) 125122
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07856" title="Abstract">arXiv:2309.07856</a> (replaced) [<a href="/pdf/2309.07856" title="Download PDF">pdf</a>, <a href="/format/2309.07856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SMARTFEAT: Efficient Feature Construction through Feature-Level  Foundation Model Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+B">Bolin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Jagadish%2C+H+V">H. V. Jagadish</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08200" title="Abstract">arXiv:2309.08200</a> (replaced) [<a href="/pdf/2309.08200" title="Download PDF">pdf</a>, <a href="/format/2309.08200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TF-SepNet: An Efficient 1D Kernel Design in CNNs for Low-Complexity  Acoustic Scene Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yiqiang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peihong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shengchen Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 2024 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08340" title="Abstract">arXiv:2309.08340</a> (replaced) [<a href="/pdf/2309.08340" title="Download PDF">pdf</a>, <a href="/format/2309.08340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formalizing the $\infty$-Categorical Yoneda Lemma
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kudasov%2C+N">Nikolai Kudasov</a>, 
<a href="/search/math?searchtype=author&query=Riehl%2C+E">Emily Riehl</a>, 
<a href="/search/math?searchtype=author&query=Weinberger%2C+J">Jonathan Weinberger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in CPP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Logic in Computer Science (cs.LO); Algebraic Topology (math.AT); Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08912" title="Abstract">arXiv:2309.08912</a> (replaced) [<a href="/pdf/2309.08912" title="Download PDF">pdf</a>, <a href="/format/2309.08912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Delving into Multimodal Prompting for Fine-grained Visual Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Junyao Gao</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xiaoyu Du</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shengfeng He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zechao Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09866" title="Abstract">arXiv:2309.09866</a> (replaced) [<a href="/pdf/2309.09866" title="Download PDF">pdf</a>, <a href="/format/2309.09866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Generalization with Fourier Transform and Soft Thresholding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pan%2C+H">Hongyi Pan</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Zheyuan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+X">Xin Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Jha%2C+D">Debesh Jha</a>, 
<a href="/search/eess?searchtype=author&query=Cetin%2C+A+E">Ahmet Enis Cetin</a>, 
<a href="/search/eess?searchtype=author&query=Spampinato%2C+C">Concetto Spampinato</a>, 
<a href="/search/eess?searchtype=author&query=Bagci%2C+U">Ulas Bagci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10245" title="Abstract">arXiv:2309.10245</a> (replaced) [<a href="/pdf/2309.10245" title="Download PDF">pdf</a>, <a href="/format/2309.10245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Natural Language Dataset Generation Framework for Visualizations Powered  by Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ko%2C+H">Hyung-Kwon Ko</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+H">Hyeon Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+G">Gwanmo Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D+H">Dae Hyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+N+W">Nam Wook Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Juho Kim</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+J">Jinwook Seo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10441" title="Abstract">arXiv:2309.10441</a> (replaced) [<a href="/pdf/2309.10441" title="Download PDF">pdf</a>, <a href="/format/2309.10441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coreset selection can accelerate quantum machine learning models with  provable generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Huang%2C+Y">Yiming Huang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+H">Huiyuan Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Du%2C+Y">Yuxuan Du</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yuan%2C+X">Xiao Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12350" title="Abstract">arXiv:2309.12350</a> (replaced) [<a href="/pdf/2309.12350" title="Download PDF">pdf</a>, <a href="/format/2309.12350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Internet of Things Adoption Challenges in Manufacturing Firms:  A Delphi Fuzzy Analytical Hierarchy Process Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shahriar%2C+H">Hasan Shahriar</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+S">Md. Saiful Islam</a>, 
<a href="/search/cs?searchtype=author&query=Jahin%2C+M+A">Md Abrar Jahin</a>, 
<a href="/search/cs?searchtype=author&query=Ridoy%2C+I+A">Istiyaque Ahmed Ridoy</a>, 
<a href="/search/cs?searchtype=author&query=Prottoy%2C+R+R">Raihan Rafi Prottoy</a>, 
<a href="/search/cs?searchtype=author&query=Abid%2C+A">Adiba Abid</a>, 
<a href="/search/cs?searchtype=author&query=Mridha%2C+M+F">M. F. Mridha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14534" title="Abstract">arXiv:2309.14534</a> (replaced) [<a href="/pdf/2309.14534" title="Download PDF">pdf</a>, <a href="/format/2309.14534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teach AI How to Code: Using Large Language Models as Teachable Agents  for Programming Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hyoungwook Jin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seonghee Lee</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+H">Hyungyu Shin</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Juho Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14585" title="Abstract">arXiv:2309.14585</a> (replaced) [<a href="/pdf/2309.14585" title="Download PDF">pdf</a>, <a href="/format/2309.14585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DifAttack: Query-Efficient Black-Box Attack via Disentangled Feature  Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jun%2C+L">Liu Jun</a>, 
<a href="/search/cs?searchtype=author&query=Jiantao%2C+Z">Zhou Jiantao</a>, 
<a href="/search/cs?searchtype=author&query=Jiandian%2C+Z">Zeng Jiandian</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jinyu Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in AAAI'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14876" title="Abstract">arXiv:2309.14876</a> (replaced) [<a href="/pdf/2309.14876" title="Download PDF">pdf</a>, <a href="/ps/2309.14876" title="Download PostScript">ps</a>, <a href="/format/2309.14876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> APPRAISE: a governance framework for innovation with AI systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dey%2C+D">Diptish Dey</a>, 
<a href="/search/cs?searchtype=author&query=Bhaumik%2C+D">Debarati Bhaumik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00429" title="Abstract">arXiv:2310.00429</a> (replaced) [<a href="/pdf/2310.00429" title="Download PDF">pdf</a>, <a href="/format/2310.00429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Stability of Iterative Retraining of Generative Models on their  own Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bertrand%2C+Q">Quentin Bertrand</a>, 
<a href="/search/cs?searchtype=author&query=Bose%2C+A+J">Avishek Joey Bose</a>, 
<a href="/search/cs?searchtype=author&query=Duplessis%2C+A">Alexandre Duplessis</a>, 
<a href="/search/cs?searchtype=author&query=Jiralerspong%2C+M">Marco Jiralerspong</a>, 
<a href="/search/cs?searchtype=author&query=Gidel%2C+G">Gauthier Gidel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00975" title="Abstract">arXiv:2310.00975</a> (replaced) [<a href="/pdf/2310.00975" title="Download PDF">pdf</a>, <a href="/ps/2310.00975" title="Download PostScript">ps</a>, <a href="/format/2310.00975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance Analysis of Synchronous Motor Drives under Concurrent Errors  in Position and Current Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pramod%2C+P">Prerit Pramod</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01217" title="Abstract">arXiv:2310.01217</a> (replaced) [<a href="/pdf/2310.01217" title="Download PDF">pdf</a>, <a href="/format/2310.01217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ScaLearn: Simple and Highly Parameter-Efficient Task Transfer by  Learning to Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frohmann%2C+M">Markus Frohmann</a>, 
<a href="/search/cs?searchtype=author&query=Holtermann%2C+C">Carolin Holtermann</a>, 
<a href="/search/cs?searchtype=author&query=Masoudian%2C+S">Shahed Masoudian</a>, 
<a href="/search/cs?searchtype=author&query=Lauscher%2C+A">Anne Lauscher</a>, 
<a href="/search/cs?searchtype=author&query=Rekabsaz%2C+N">Navid Rekabsaz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02161" title="Abstract">arXiv:2310.02161</a> (replaced) [<a href="/pdf/2310.02161" title="Download PDF">pdf</a>, <a href="/format/2310.02161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Selenite: Scaffolding Online Sensemaking with Comprehensive Overviews  Elicited from Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+M+X">Michael Xieyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tongshuang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianying Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F+M">Franklin Mingzhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Kittur%2C+A">Aniket Kittur</a>, 
<a href="/search/cs?searchtype=author&query=Myers%2C+B+A">Brad A. Myers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02739" title="Abstract">arXiv:2310.02739</a> (replaced) [<a href="/pdf/2310.02739" title="Download PDF">pdf</a>, <a href="/format/2310.02739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> uTalk: Bridging the Gap Between Humans and AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azzuni%2C+H">Hussam Azzuni</a>, 
<a href="/search/cs?searchtype=author&query=Jamal%2C+S">Sharim Jamal</a>, 
<a href="/search/cs?searchtype=author&query=Elsaddik%2C+A">Abdulmotaleb Elsaddik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02948" title="Abstract">arXiv:2310.02948</a> (replaced) [<a href="/pdf/2310.02948" title="Download PDF">pdf</a>, <a href="/format/2310.02948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HappyFeat -- An interactive and efficient BCI framework for clinical  applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Desbois%2C+A">Arthur Desbois</a>, 
<a href="/search/q-bio?searchtype=author&query=Venot%2C+T">Tristan Venot</a>, 
<a href="/search/q-bio?searchtype=author&query=De+Vico+Fallani%2C+F">Fabrizio De Vico Fallani</a>, 
<a href="/search/q-bio?searchtype=author&query=Corsi%2C+M">Marie-Constance Corsi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures, 1 table, "Annex" section
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03149" title="Abstract">arXiv:2310.03149</a> (replaced) [<a href="/pdf/2310.03149" title="Download PDF">pdf</a>, <a href="/format/2310.03149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attributing Learned Concepts in Neural Networks to Training Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Konz%2C+N">Nicholas Konz</a>, 
<a href="/search/cs?searchtype=author&query=Godfrey%2C+C">Charles Godfrey</a>, 
<a href="/search/cs?searchtype=author&query=Shapiro%2C+M">Madelyn Shapiro</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+J">Jonathan Tu</a>, 
<a href="/search/cs?searchtype=author&query=Kvinge%2C+H">Henry Kvinge</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+D">Davis Brown</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ATTRIB Workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04353" title="Abstract">arXiv:2310.04353</a> (replaced) [<a href="/pdf/2310.04353" title="Download PDF">pdf</a>, <a href="/format/2310.04353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Language-Agent Approach to Formal Theorem-Proving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thakur%2C+A">Amitayush Thakur</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yeming Wen</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhuri%2C+S">Swarat Chaudhuri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04796" title="Abstract">arXiv:2310.04796</a> (replaced) [<a href="/pdf/2310.04796" title="Download PDF">pdf</a>, <a href="/format/2310.04796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerate Multi-Agent Reinforcement Learning in Zero-Sum Games with  Subgame Curriculum Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiayu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zelai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunfei Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jiaming Song</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Huazhong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+F">Fei Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yi Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04925" title="Abstract">arXiv:2310.04925</a> (replaced) [<a href="/pdf/2310.04925" title="Download PDF">pdf</a>, <a href="/format/2310.04925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Crystal-GFN: sampling crystals with desirable properties and constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=AI4Science%2C+M">Mila AI4Science</a>, 
<a href="/search/cs?searchtype=author&query=Hernandez-Garcia%2C+A">Alex Hernandez-Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Duval%2C+A">Alexandre Duval</a>, 
<a href="/search/cs?searchtype=author&query=Volokhova%2C+A">Alexandra Volokhova</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+D">Divya Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Carrier%2C+P+L">Pierre Luc Carrier</a>, 
<a href="/search/cs?searchtype=author&query=Benabed%2C+Y">Yasmine Benabed</a>, 
<a href="/search/cs?searchtype=author&query=Koziarski%2C+M">Micha&#x142; Koziarski</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+V">Victor Schmidt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main paper (10 pages) + references + appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04926" title="Abstract">arXiv:2310.04926</a> (replaced) [<a href="/pdf/2310.04926" title="Download PDF">pdf</a>, <a href="/ps/2310.04926" title="Download PostScript">ps</a>, <a href="/format/2310.04926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Further results on generalized cellular automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Castillo-Ramirez%2C+A">Alonso Castillo-Ramirez</a>, 
<a href="/search/math?searchtype=author&query=de+los+Santos+Ba%C3%B1os%2C+L">Luguis de los Santos Ba&#xf1;os</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Group Theory (math.GR)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05718" title="Abstract">arXiv:2310.05718</a> (replaced) [<a href="/pdf/2310.05718" title="Download PDF">pdf</a>, <a href="/format/2310.05718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EdVAE: Mitigating Codebook Collapse with Evidential Discrete Variational  Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baykal%2C+G">Gulcin Baykal</a>, 
<a href="/search/cs?searchtype=author&query=Kandemir%2C+M">Melih Kandemir</a>, 
<a href="/search/cs?searchtype=author&query=Unal%2C+G">Gozde Unal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to Pattern Recognition
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06470" title="Abstract">arXiv:2310.06470</a> (replaced) [<a href="/pdf/2310.06470" title="Download PDF">pdf</a>, <a href="/format/2310.06470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Focus on Local Regions for Query-based Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongbin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yamei Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shuai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+B">Bo Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07154" title="Abstract">arXiv:2310.07154</a> (replaced) [<a href="/pdf/2310.07154" title="Download PDF">pdf</a>, <a href="/format/2310.07154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Because Some Sighted People, They Don&#x27;t Know What the Heck You&#x27;re  Talking About:&quot; A Study of Blind TikTokers&#x27; Infrastructuring Work to Build  Independence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Y">Yao Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Carroll%2C+J+M">John M. Carroll</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CSCW'24, 29 pages, 2 figures, and 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07718" title="Abstract">arXiv:2310.07718</a> (replaced) [<a href="/pdf/2310.07718" title="Download PDF">pdf</a>, <a href="/ps/2310.07718" title="Download PostScript">ps</a>, <a href="/format/2310.07718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long-term and Real-time High-speed Underwater Wireless Optical  Communications in Deep Sea
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jialiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sujing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Ziqi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+G">Guanjun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yonggang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shanguo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Optics (physics.optics)

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08320" title="Abstract">arXiv:2310.08320</a> (replaced) [<a href="/pdf/2310.08320" title="Download PDF">pdf</a>, <a href="/format/2310.08320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defending Our Privacy With Backdoors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hintersdorf%2C+D">Dominik Hintersdorf</a>, 
<a href="/search/cs?searchtype=author&query=Struppek%2C+L">Lukas Struppek</a>, 
<a href="/search/cs?searchtype=author&query=Neider%2C+D">Daniel Neider</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+K">Kristian Kersting</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09053" title="Abstract">arXiv:2310.09053</a> (replaced) [<a href="/pdf/2310.09053" title="Download PDF">pdf</a>, <a href="/format/2310.09053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DATT: Deep Adaptive Trajectory Tracking for Quadrotor Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kevin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Rana%2C+R">Rwik Rana</a>, 
<a href="/search/cs?searchtype=author&query=Spitzer%2C+A">Alexander Spitzer</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+G">Guanya Shi</a>, 
<a href="/search/cs?searchtype=author&query=Boots%2C+B">Byron Boots</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10101" title="Abstract">arXiv:2310.10101</a> (replaced) [<a href="/pdf/2310.10101" title="Download PDF">pdf</a>, <a href="/ps/2310.10101" title="Download PostScript">ps</a>, <a href="/format/2310.10101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random-order Contention Resolution via Continuous Induction: Tightness  for Bipartite Matching under Vertex Arrivals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=MacRury%2C+C">Calum MacRury</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Will Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10410" title="Abstract">arXiv:2310.10410</a> (replaced) [<a href="/pdf/2310.10410" title="Download PDF">pdf</a>, <a href="/format/2310.10410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Loci-Segmented: Improving Scene Segmentation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Traub%2C+M">Manuel Traub</a>, 
<a href="/search/cs?searchtype=author&query=Becker%2C+F">Frederic Becker</a>, 
<a href="/search/cs?searchtype=author&query=Sauter%2C+A">Adrian Sauter</a>, 
<a href="/search/cs?searchtype=author&query=Otte%2C+S">Sebastian Otte</a>, 
<a href="/search/cs?searchtype=author&query=Butz%2C+M+V">Martin V. Butz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10594" title="Abstract">arXiv:2310.10594</a> (replaced) [<a href="/pdf/2310.10594" title="Download PDF">pdf</a>, <a href="/format/2310.10594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion2Language, unsupervised learning of synchronized semantic motion  segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Radouane%2C+K">Karim Radouane</a>, 
<a href="/search/cs?searchtype=author&query=Tchechmedjiev%2C+A">Andon Tchechmedjiev</a>, 
<a href="/search/cs?searchtype=author&query=Lagarde%2C+J">Julien Lagarde</a>, 
<a href="/search/cs?searchtype=author&query=Ranwez%2C+S">Sylvie Ranwez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at Neural Computing and Applications
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neural Comput &amp; Applic (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10659" title="Abstract">arXiv:2310.10659</a> (replaced) [<a href="/pdf/2310.10659" title="Download PDF">pdf</a>, <a href="/format/2310.10659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Machine Unlearning for Backdoor Attacks in Deep Learning  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peixin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+M">Mingtian Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12004" title="Abstract">arXiv:2310.12004</a> (replaced) [<a href="/pdf/2310.12004" title="Download PDF">pdf</a>, <a href="/format/2310.12004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Super-resolution Via Latent Diffusion: A Sampling-space Mixture Of  Experts And Frequency-augmented Decoder Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+F">Feng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+J">Jinxi Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiao Han</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wei Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20545" title="Abstract">arXiv:2310.20545</a> (replaced) [<a href="/pdf/2310.20545" title="Download PDF">pdf</a>, <a href="/format/2310.20545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing accuracy and diversity: a multi-task approach to forecast  combinations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Felici%2C+G">Giovanni Felici</a>, 
<a href="/search/cs?searchtype=author&query=Sudoso%2C+A+M">Antonio M. Sudoso</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01314" title="Abstract">arXiv:2311.01314</a> (replaced) [<a href="/pdf/2311.01314" title="Download PDF">pdf</a>, <a href="/format/2311.01314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recommendations by Concise User Profiles from Review Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Torbati%2C+G+H">Ghazaleh Haratinezhad Torbati</a>, 
<a href="/search/cs?searchtype=author&query=Tigunova%2C+A">Anna Tigunova</a>, 
<a href="/search/cs?searchtype=author&query=Yates%2C+A">Andrew Yates</a>, 
<a href="/search/cs?searchtype=author&query=Weikum%2C+G">Gerhard Weikum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02546" title="Abstract">arXiv:2311.02546</a> (replaced) [<a href="/pdf/2311.02546" title="Download PDF">pdf</a>, <a href="/ps/2311.02546" title="Download PostScript">ps</a>, <a href="/format/2311.02546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Second-Order Convergence of Biased Policy Gradient Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mu%2C+S">Siqiao Mu</a>, 
<a href="/search/cs?searchtype=author&query=Klabjan%2C+D">Diego Klabjan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02582" title="Abstract">arXiv:2311.02582</a> (replaced) [<a href="/pdf/2311.02582" title="Download PDF">pdf</a>, <a href="/ps/2311.02582" title="Download PostScript">ps</a>, <a href="/format/2311.02582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RecAGT: Shard Testable Codes with Adaptive Group Testing for Malicious  Nodes Identification in Sharding Permissioned Blockchain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dong-Yang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lingzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Can Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 23rd International Conference on Algorithms and Architectures for Parallel Processing (ICA3PP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03426" title="Abstract">arXiv:2311.03426</a> (replaced) [<a href="/pdf/2311.03426" title="Download PDF">pdf</a>, <a href="/format/2311.03426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GQKVA: Efficient Pre-training of Transformers by Grouping Queries, Keys,  and Values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Javadi%2C+F">Farnoosh Javadi</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+W">Walid Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Hajimolahoseini%2C+H">Habib Hajimolahoseini</a>, 
<a href="/search/cs?searchtype=author&query=Ataiefard%2C+F">Foozhan Ataiefard</a>, 
<a href="/search/cs?searchtype=author&query=Hassanpour%2C+M">Mohammad Hassanpour</a>, 
<a href="/search/cs?searchtype=author&query=Asani%2C+S">Saina Asani</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+A">Austin Wen</a>, 
<a href="/search/cs?searchtype=author&query=Awad%2C+O+M">Omar Mohamed Awad</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kangling Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05608" title="Abstract">arXiv:2311.05608</a> (replaced) [<a href="/pdf/2311.05608" title="Download PDF">pdf</a>, <a href="/format/2311.05608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FigStep: Jailbreaking Large Vision-language Models via Typographic  Visual Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yichen Gong</a>, 
<a href="/search/cs?searchtype=author&query=Ran%2C+D">Delong Ran</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Conglei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cong%2C+T">Tianshuo Cong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Anyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+S">Sisi Duan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoyun Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08059" title="Abstract">arXiv:2311.08059</a> (replaced) [<a href="/pdf/2311.08059" title="Download PDF">pdf</a>, <a href="/format/2311.08059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FS-Net: Full Scale Network and Adaptive Threshold for Improving  Extraction of Micro-Retinal Vessel Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Getahun%2C+M+N">Melaku N. Getahun</a>, 
<a href="/search/eess?searchtype=author&query=Rogov%2C+O+Y">Oleg Y. Rogov</a>, 
<a href="/search/eess?searchtype=author&query=Dylov%2C+D+V">Dmitry V. Dylov</a>, 
<a href="/search/eess?searchtype=author&query=Somov%2C+A">Andrey Somov</a>, 
<a href="/search/eess?searchtype=author&query=Bouridane%2C+A">Ahmed Bouridane</a>, 
<a href="/search/eess?searchtype=author&query=Hamoudi%2C+R">Rifat Hamoudi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures, under consideration at Pattern Recognition Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08836" title="Abstract">arXiv:2311.08836</a> (replaced) [<a href="/pdf/2311.08836" title="Download PDF">pdf</a>, <a href="/format/2311.08836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Gender Bias in the Translation of Gender-Neutral Languages  into English
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rarrick%2C+S">Spencer Rarrick</a>, 
<a href="/search/cs?searchtype=author&query=Naik%2C+R">Ranjita Naik</a>, 
<a href="/search/cs?searchtype=author&query=Poudel%2C+S">Sundar Poudel</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhary%2C+V">Vishal Chowdhary</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09088" title="Abstract">arXiv:2311.09088</a> (replaced) [<a href="/pdf/2311.09088" title="Download PDF">pdf</a>, <a href="/format/2311.09088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Co-ML: Collaborative Machine Learning Model Building for Developing  Dataset Design Practices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tseng%2C+T">Tiffany Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Davidson%2C+M+J">Matt J. Davidson</a>, 
<a href="/search/cs?searchtype=author&query=Morales-Navarro%2C+L">Luis Morales-Navarro</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J+K">Jennifer King Chen</a>, 
<a href="/search/cs?searchtype=author&query=Delaney%2C+V">Victoria Delaney</a>, 
<a href="/search/cs?searchtype=author&query=Leibowitz%2C+M">Mark Leibowitz</a>, 
<a href="/search/cs?searchtype=author&query=Beason%2C+J">Jazbo Beason</a>, 
<a href="/search/cs?searchtype=author&query=Shapiro%2C+R+B">R. Benjamin Shapiro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10529" title="Abstract">arXiv:2311.10529</a> (replaced) [<a href="/pdf/2311.10529" title="Download PDF">pdf</a>, <a href="/format/2311.10529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment Anything Model with Uncertainty Rectification for Auto-Prompting  Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yichi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shiyao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yuan Qi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11183" title="Abstract">arXiv:2311.11183</a> (replaced) [<a href="/pdf/2311.11183" title="Download PDF">pdf</a>, <a href="/format/2311.11183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deploying and Evaluating LLMs to Program Service Mobile Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zichao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lucchetti%2C+F">Francesca Lucchetti</a>, 
<a href="/search/cs?searchtype=author&query=Schlesinger%2C+C">Claire Schlesinger</a>, 
<a href="/search/cs?searchtype=author&query=Saxena%2C+Y">Yash Saxena</a>, 
<a href="/search/cs?searchtype=author&query=Freeman%2C+A">Anders Freeman</a>, 
<a href="/search/cs?searchtype=author&query=Modak%2C+S">Sadanand Modak</a>, 
<a href="/search/cs?searchtype=author&query=Guha%2C+A">Arjun Guha</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+J">Joydeep Biswas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> paper preprint, 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11204" title="Abstract">arXiv:2311.11204</a> (replaced) [<a href="/pdf/2311.11204" title="Download PDF">pdf</a>, <a href="/format/2311.11204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collectively Simplifying Trajectories in a Database: A Query Accuracy  Driven Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+C">Cheng Long</a>, 
<a href="/search/cs?searchtype=author&query=Cong%2C+G">Gao Cong</a>, 
<a href="/search/cs?searchtype=author&query=Jensen%2C+C+S">Christian S. Jensen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by ICDE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13435" title="Abstract">arXiv:2311.13435</a> (replaced) [<a href="/pdf/2311.13435" title="Download PDF">pdf</a>, <a href="/format/2311.13435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PG-Video-LLaVA: Pixel Grounding Large Video-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Munasinghe%2C+S">Shehan Munasinghe</a>, 
<a href="/search/cs?searchtype=author&query=Thushara%2C+R">Rusiru Thushara</a>, 
<a href="/search/cs?searchtype=author&query=Maaz%2C+M">Muhammad Maaz</a>, 
<a href="/search/cs?searchtype=author&query=Rasheed%2C+H+A">Hanoona Abdul Rasheed</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Salman Khan</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+M">Mubarak Shah</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+F">Fahad Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13517" title="Abstract">arXiv:2311.13517</a> (replaced) [<a href="/pdf/2311.13517" title="Download PDF">pdf</a>, <a href="/format/2311.13517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning-Based Relaxation of Completeness Requirements for Data Entry  Forms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belgacem%2C+H">Hichem Belgacem</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaochen Li</a>, 
<a href="/search/cs?searchtype=author&query=Bianculli%2C+D">Domenico Bianculli</a>, 
<a href="/search/cs?searchtype=author&query=Briand%2C+L+C">Lionel C. Briand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication by ACM Transactions on Software Engineering and Methodology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14521" title="Abstract">arXiv:2311.14521</a> (replaced) [<a href="/pdf/2311.14521" title="Download PDF">pdf</a>, <a href="/format/2311.14521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GaussianEditor: Swift and Controllable 3D Editing with Gaussian  Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiwen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zilong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Feng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaofeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yikai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhongang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huaping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guosheng Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://buaacyw.github.io/gaussian-editor/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15317" title="Abstract">arXiv:2311.15317</a> (replaced) [<a href="/pdf/2311.15317" title="Download PDF">pdf</a>, <a href="/format/2311.15317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Graph Prompt: Toward a Unification of Pre-Training and  Downstream Tasks on Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xingtong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zemin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sihong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinming Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extension of "GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks". arXiv admin note: substantial text overlap with <a href="/abs/2302.08043">arXiv:2302.08043</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16080" title="Abstract">arXiv:2311.16080</a> (replaced) [<a href="/pdf/2311.16080" title="Download PDF">pdf</a>, <a href="/format/2311.16080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XLB: A Differentiable Massively Parallel Lattice Boltzmann Library in  Python
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Ataei%2C+M">Mohammadmehdi Ataei</a>, 
<a href="/search/physics?searchtype=author&query=Salehipour%2C+H">Hesam Salehipour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16342" title="Abstract">arXiv:2311.16342</a> (replaced) [<a href="/pdf/2311.16342" title="Download PDF">pdf</a>, <a href="/format/2311.16342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matrix Multiplication in Quadratic Time and Energy? Towards a  Fine-Grained Energy-Centric Church-Turing Thesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valiant%2C+G">Gregory Valiant</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16442" title="Abstract">arXiv:2311.16442</a> (replaced) [<a href="/pdf/2311.16442" title="Download PDF">pdf</a>, <a href="/format/2311.16442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling Fast 2-bit LLM on GPUs: Memory Alignment and Asynchronous  Dequantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shiyao Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiaming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+Y">Yaoxiu Lian</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+G">Guohao Dai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17929" title="Abstract">arXiv:2311.17929</a> (replaced) [<a href="/pdf/2311.17929" title="Download PDF">pdf</a>, <a href="/format/2311.17929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Online Communities: Graph Deep Learning on Anonymous Voting Networks  to Identify Sybils in Polycentric Governance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=DuPont%2C+Q">Quinn DuPont</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18020" title="Abstract">arXiv:2311.18020</a> (replaced) [<a href="/pdf/2311.18020" title="Download PDF">pdf</a>, <a href="/ps/2311.18020" title="Download PostScript">ps</a>, <a href="/format/2311.18020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Regulation of Dynamical Systems to Solutions of Constrained  Optimization Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yiting Chen</a>, 
<a href="/search/eess?searchtype=author&query=Cothren%2C+L">Liliaokeawawa Cothren</a>, 
<a href="/search/eess?searchtype=author&query=Cortes%2C+J">Jorge Cortes</a>, 
<a href="/search/eess?searchtype=author&query=Dall%27Anese%2C+E">Emiliano Dall&#x27;Anese</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for publication on IEEE Control Systems Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18188" title="Abstract">arXiv:2311.18188</a> (replaced) [<a href="/pdf/2311.18188" title="Download PDF">pdf</a>, <a href="/format/2311.18188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging cache to enable SLU on tiny devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Benazir%2C+A">Afsara Benazir</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Z">Zhiming Xu</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+F+X">Felix Xiaozhu Lin</a> (University of Virginia)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00102" title="Abstract">arXiv:2312.00102</a> (replaced) [<a href="/pdf/2312.00102" title="Download PDF">pdf</a>, <a href="/ps/2312.00102" title="Download PostScript">ps</a>, <a href="/format/2312.00102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedEmb: A Vertical and Hybrid Federated Learning Algorithm using Network  And Feature Embedding Aggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fanfei Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lele Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Proceedings on Engineering Sciences
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings on Engineering Sciences, 2620-2832, 2023/10
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00812" title="Abstract">arXiv:2312.00812</a> (replaced) [<a href="/pdf/2312.00812" title="Download PDF">pdf</a>, <a href="/format/2312.00812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empowering Autonomous Driving with Large Language Models: A Safety  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yixuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+R">Ruochen Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Lang%2C+C">Chengtian Lang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+S+S">Sinong Simon Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaoran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhuoran Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qi Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures, baseline added in the experiment
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01241" title="Abstract">arXiv:2312.01241</a> (replaced) [<a href="/pdf/2312.01241" title="Download PDF">pdf</a>, <a href="/format/2312.01241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Just-in-Time Security Patch Detection -- LLM At the Rescue for Data  Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xunzhu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenghan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kisub Kim</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Haoye Tian</a>, 
<a href="/search/cs?searchtype=author&query=Ezzini%2C+S">Saad Ezzini</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+J">Jacques Klein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01479" title="Abstract">arXiv:2312.01479</a> (replaced) [<a href="/pdf/2312.01479" title="Download PDF">pdf</a>, <a href="/format/2312.01479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenVoice: Versatile Instant Voice Cloning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zengyi Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenliang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xumin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xin Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02142" title="Abstract">arXiv:2312.02142</a> (replaced) [<a href="/pdf/2312.02142" title="Download PDF">pdf</a>, <a href="/format/2312.02142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object Recognition as Next Token Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+K">Kaiyu Yue</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bor-Chun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Geiping%2C+J">Jonas Geiping</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hengduo Li</a>, 
<a href="/search/cs?searchtype=author&query=Goldstein%2C+T">Tom Goldstein</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Ser-Nam Lim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> update the intro fig and refs; auto-regression for recognition
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02462" title="Abstract">arXiv:2312.02462</a> (replaced) [<a href="/pdf/2312.02462" title="Download PDF">pdf</a>, <a href="/ps/2312.02462" title="Download PostScript">ps</a>, <a href="/format/2312.02462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dimensionality Reduction and Dynamical Mode Recognition of Circular  Arrays of Flame Oscillators Using Deep Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weiming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> research paper (18 pages, 1 table 10 figures) with supplementary material (8 pages, 1 table, 5 figures)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03038" title="Abstract">arXiv:2312.03038</a> (replaced) [<a href="/pdf/2312.03038" title="Download PDF">pdf</a>, <a href="/ps/2312.03038" title="Download PostScript">ps</a>, <a href="/format/2312.03038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample-based Dynamic Hierarchical Transformer with Layer and Head  Flexibility via Contextual Bandit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fanfei Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lele Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, accepted by Proceedings on Engineering Sciences, Vol.6, 2620-2832
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03919" title="Abstract">arXiv:2312.03919</a> (replaced) [<a href="/pdf/2312.03919" title="Download PDF">pdf</a>, <a href="/ps/2312.03919" title="Download PostScript">ps</a>, <a href="/format/2312.03919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Indivisibility and uniform computational strength
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gill%2C+K">Kenneth Gill</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 4 figures. This work extends the results of Sections 1.2 and 1.3 of the author's Ph.D. thesis at Penn State University. Version 3: fix Proposition 3.3, misc improvements
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03940" title="Abstract">arXiv:2312.03940</a> (replaced) [<a href="/pdf/2312.03940" title="Download PDF">pdf</a>, <a href="/format/2312.03940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PECANN: Parallel Efficient Clustering with Graph-Based Approximate  Nearest Neighbor Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shangdi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Engels%2C+J">Joshua Engels</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yihao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shun%2C+J">Julian Shun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04008" title="Abstract">arXiv:2312.04008</a> (replaced) [<a href="/e-print/2312.04008" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Natural-language-driven Simulation Benchmark and Copilot for Efficient  Production of Object Interactions in Virtual Road Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kairui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zihao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Gengjie Lin</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Haotian Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+D">Die Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Jibin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhecheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fupeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Z">Ziyun Bai</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Di Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Section 7-9 have some formatting errors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04334" title="Abstract">arXiv:2312.04334</a> (replaced) [<a href="/pdf/2312.04334" title="Download PDF">pdf</a>, <a href="/format/2312.04334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Perceptual Evaluation Framework for Lighting Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Giroux%2C+J">Justine Giroux</a>, 
<a href="/search/cs?searchtype=author&query=Dastjerdi%2C+M+R+K">Mohammad Reza Karimi Dastjerdi</a>, 
<a href="/search/cs?searchtype=author&query=Hold-Geoffroy%2C+Y">Yannick Hold-Geoffroy</a>, 
<a href="/search/cs?searchtype=author&query=Vazquez-Corral%2C+J">Javier Vazquez-Corral</a>, 
<a href="/search/cs?searchtype=author&query=Lalonde%2C+J">Jean-Fran&#xe7;ois Lalonde</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04730" title="Abstract">arXiv:2312.04730</a> (replaced) [<a href="/pdf/2312.04730" title="Download PDF">pdf</a>, <a href="/format/2312.04730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeceptPrompt: Exploiting LLM-driven Code Generation via Adversarial  Natural Language Instructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fangzhou Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaogeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chaowei Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05139" title="Abstract">arXiv:2312.05139</a> (replaced) [<a href="/pdf/2312.05139" title="Download PDF">pdf</a>, <a href="/ps/2312.05139" title="Download PostScript">ps</a>, <a href="/format/2312.05139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clearing Financial Networks with Derivatives: From Intractability to  Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ioannidis%2C+S+D">Stavros D. Ioannidis</a>, 
<a href="/search/cs?searchtype=author&query=de+Keijzer%2C+B">Bart de Keijzer</a>, 
<a href="/search/cs?searchtype=author&query=Ventre%2C+C">Carmine Ventre</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Computational Engineering, Finance, and Science (cs.CE); Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05259" title="Abstract">arXiv:2312.05259</a> (replaced) [<a href="/pdf/2312.05259" title="Download PDF">pdf</a>, <a href="/ps/2312.05259" title="Download PostScript">ps</a>, <a href="/format/2312.05259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing the Passenger Flow for Airport Security Check
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fanfei Meng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaotian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Chaoyu Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05799" title="Abstract">arXiv:2312.05799</a> (replaced) [<a href="/pdf/2312.05799" title="Download PDF">pdf</a>, <a href="/format/2312.05799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SGNet: Structure Guided Network via Gradient-Frequency Awareness for  Depth Map Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhengxue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhiqiang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06036" title="Abstract">arXiv:2312.06036</a> (replaced) [<a href="/pdf/2312.06036" title="Download PDF">pdf</a>, <a href="/format/2312.06036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Competitions and Benchmarks: towards impactful challenges with  post-challenge papers, benchmarks and other dissemination actions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marot%2C+A">Antoine Marot</a>, 
<a href="/search/cs?searchtype=author&query=Rousseau%2C+D">David Rousseau</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhen Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5th chapter of book "AI Competitions and Benchmarks: the science behind the contests" see: <a href="https://sites.google.com/chalearn.">this https URL</a> org/book/home
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06060" title="Abstract">arXiv:2312.06060</a> (replaced) [<a href="/pdf/2312.06060" title="Download PDF">pdf</a>, <a href="/ps/2312.06060" title="Download PostScript">ps</a>, <a href="/format/2312.06060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear Time-History Analysis of Soil-Structure Systems Incorporating  Frequency-Dependent Impedance Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghahari%2C+S+F">S. Farid Ghahari</a>, 
<a href="/search/cs?searchtype=author&query=Ghofrani%2C+A">Alborz Ghofrani</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Taciroglu%2C+E">Ertugrul Taciroglu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06141" title="Abstract">arXiv:2312.06141</a> (replaced) [<a href="/pdf/2312.06141" title="Download PDF">pdf</a>, <a href="/format/2312.06141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survey on Memory-Augmented Neural Networks: Cognitive Insights to AI  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khosla%2C+S">Savya Khosla</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yifei He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06448" title="Abstract">arXiv:2312.06448</a> (replaced) [<a href="/pdf/2312.06448" title="Download PDF">pdf</a>, <a href="/format/2312.06448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Publishing Strategies on a Base Layer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bar-On%2C+Y">Yogev Bar-On</a>, 
<a href="/search/cs?searchtype=author&query=Mansour%2C+Y">Yishay Mansour</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be presented at Financial Cryptography and Data Security 2024 (FC 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06585" title="Abstract">arXiv:2312.06585</a> (replaced) [<a href="/pdf/2312.06585" title="Download PDF">pdf</a>, <a href="/format/2312.06585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Human Data: Scaling Self-Training for Problem-Solving with  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Avi Singh</a>, 
<a href="/search/cs?searchtype=author&query=Co-Reyes%2C+J+D">John D. Co-Reyes</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+R">Rishabh Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Anand%2C+A">Ankesh Anand</a>, 
<a href="/search/cs?searchtype=author&query=Patil%2C+P">Piyush Patil</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P+J">Peter J. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Harrison%2C+J">James Harrison</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaehoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kelvin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Parisi%2C+A">Aaron Parisi</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Abhishek Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Alemi%2C+A">Alex Alemi</a>, 
<a href="/search/cs?searchtype=author&query=Rizkowsky%2C+A">Alex Rizkowsky</a>, 
<a href="/search/cs?searchtype=author&query=Nova%2C+A">Azade Nova</a>, 
<a href="/search/cs?searchtype=author&query=Adlam%2C+B">Ben Adlam</a>, 
<a href="/search/cs?searchtype=author&query=Bohnet%2C+B">Bernd Bohnet</a>, 
<a href="/search/cs?searchtype=author&query=Elsayed%2C+G">Gamaleldin Elsayed</a>, 
<a href="/search/cs?searchtype=author&query=Sedghi%2C+H">Hanie Sedghi</a>, 
<a href="/search/cs?searchtype=author&query=Mordatch%2C+I">Igor Mordatch</a>, 
<a href="/search/cs?searchtype=author&query=Simpson%2C+I">Isabelle Simpson</a>, 
<a href="/search/cs?searchtype=author&query=Gur%2C+I">Izzeddin Gur</a>, 
<a href="/search/cs?searchtype=author&query=Snoek%2C+J">Jasper Snoek</a>, 
<a href="/search/cs?searchtype=author&query=Pennington%2C+J">Jeffrey Pennington</a>, 
<a href="/search/cs?searchtype=author&query=Hron%2C+J">Jiri Hron</a>, 
<a href="/search/cs?searchtype=author&query=Kenealy%2C+K">Kathleen Kenealy</a>, 
<a href="/search/cs?searchtype=author&query=Swersky%2C+K">Kevin Swersky</a>, 
<a href="/search/cs?searchtype=author&query=Mahajan%2C+K">Kshiteej Mahajan</a>, 
<a href="/search/cs?searchtype=author&query=Culp%2C+L">Laura Culp</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Lechao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Bileschi%2C+M+L">Maxwell L. Bileschi</a>, 
<a href="/search/cs?searchtype=author&query=Constant%2C+N">Noah Constant</a>, 
<a href="/search/cs?searchtype=author&query=Novak%2C+R">Roman Novak</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Rosanne Liu</a>, 
<a href="/search/cs?searchtype=author&query=Warkentin%2C+T">Tris Warkentin</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yundi Qian</a>, 
<a href="/search/cs?searchtype=author&query=Dyer%2C+E">Ethan Dyer</a>, 
<a href="/search/cs?searchtype=author&query=Neyshabur%2C+B">Behnam Neyshabur</a>, 
<a href="/search/cs?searchtype=author&query=Sohl-Dickstein%2C+J">Jascha Sohl-Dickstein</a>, 
<a href="/search/cs?searchtype=author&query=Fiedel%2C+N">Noah Fiedel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First three authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06853" title="Abstract">arXiv:2312.06853</a> (replaced) [<a href="/pdf/2312.06853" title="Download PDF">pdf</a>, <a href="/format/2312.06853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLF-Bench: Benchmark for Interactive Learning from Language Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+C">Ching-An Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Kolobov%2C+A">Andrey Kolobov</a>, 
<a href="/search/cs?searchtype=author&query=Misra%2C+D">Dipendra Misra</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+A">Allen Nie</a>, 
<a href="/search/cs?searchtype=author&query=Swaminathan%2C+A">Adith Swaminathan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06968" title="Abstract">arXiv:2312.06968</a> (replaced) [<a href="/pdf/2312.06968" title="Download PDF">pdf</a>, <a href="/format/2312.06968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hallucination Augmented Contrastive Learning for Multimodal Large  Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chaoya Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haiyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+M">Mengfan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaxing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+W">Wei Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+M">Ming Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qinghao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Ji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shikun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06978" title="Abstract">arXiv:2312.06978</a> (replaced) [<a href="/pdf/2312.06978" title="Download PDF">pdf</a>, <a href="/format/2312.06978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLASS-M: Adaptive stain separation-based contrastive learning with  pseudo-labeling for histopathological image classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bodong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Manoochehri%2C+H">Hamid Manoochehri</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+M+M">Man Minh Ho</a>, 
<a href="/search/cs?searchtype=author&query=Fooladgar%2C+F">Fahimeh Fooladgar</a>, 
<a href="/search/cs?searchtype=author&query=Chong%2C+Y">Yosep Chong</a>, 
<a href="/search/cs?searchtype=author&query=Knudsen%2C+B+S">Beatrice S. Knudsen</a>, 
<a href="/search/cs?searchtype=author&query=Sirohi%2C+D">Deepika Sirohi</a>, 
<a href="/search/cs?searchtype=author&query=Tasdizen%2C+T">Tolga Tasdizen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06988" title="Abstract">arXiv:2312.06988</a> (replaced) [<a href="/pdf/2312.06988" title="Download PDF">pdf</a>, <a href="/format/2312.06988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MWSIS: Multimodal Weakly Supervised Instance Segmentation with 2D Box  Annotations for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+G">Guangfeng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuzhi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+W">Wenlong Liao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tao He</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+P">Pai Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07107" title="Abstract">arXiv:2312.07107</a> (replaced) [<a href="/pdf/2312.07107" title="Download PDF">pdf</a>, <a href="/format/2312.07107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Logic of Doxastic Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Junli Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Naumov%2C+P">Pavel Naumov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 38th Annual AAAI Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07160" title="Abstract">arXiv:2312.07160</a> (replaced) [<a href="/pdf/2312.07160" title="Download PDF">pdf</a>, <a href="/format/2312.07160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audience Prospecting for Dynamic-Product-Ads in Native Advertising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abutbul%2C+E">Eliran Abutbul</a>, 
<a href="/search/cs?searchtype=author&query=Kaplan%2C+Y">Yohay Kaplan</a>, 
<a href="/search/cs?searchtype=author&query=Krasne%2C+N">Naama Krasne</a>, 
<a href="/search/cs?searchtype=author&query=Somekh%2C+O">Oren Somekh</a>, 
<a href="/search/cs?searchtype=author&query=David%2C+O">Or David</a>, 
<a href="/search/cs?searchtype=author&query=Duvdevany%2C+O">Omer Duvdevany</a>, 
<a href="/search/cs?searchtype=author&query=Segal%2C+E">Evgeny Segal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proc. IeeeBigData'2023 (Industry and Government Program)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07180" title="Abstract">arXiv:2312.07180</a> (replaced) [<a href="/pdf/2312.07180" title="Download PDF">pdf</a>, <a href="/format/2312.07180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-Aware Iteration Policy Network for Efficient Optical Flow  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+R">Ri Cheng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ruian He</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xuhao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shili Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+W">Weimin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Bo Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2024, Association for the Advancement of Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07186" title="Abstract">arXiv:2312.07186</a> (replaced) [<a href="/pdf/2312.07186" title="Download PDF">pdf</a>, <a href="/ps/2312.07186" title="Download PostScript">ps</a>, <a href="/format/2312.07186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Optimal Sobolev Norm Rates for the Vector-Valued Regularized  Least-Squares Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Li%2C+Z">Zhu Li</a>, 
<a href="/search/stat?searchtype=author&query=Meunier%2C+D">Dimitri Meunier</a>, 
<a href="/search/stat?searchtype=author&query=Mollenhauer%2C+M">Mattes Mollenhauer</a>, 
<a href="/search/stat?searchtype=author&query=Gretton%2C+A">Arthur Gretton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fixed typo + format Table 1. arXiv admin note: text overlap with <a href="/abs/2208.01711">arXiv:2208.01711</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07285" title="Abstract">arXiv:2312.07285</a> (replaced) [<a href="/pdf/2312.07285" title="Download PDF">pdf</a>, <a href="/format/2312.07285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forced Exploration in Bandit Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+H">Han Qi</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+F">Fei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Li Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07424" title="Abstract">arXiv:2312.07424</a> (replaced) [<a href="/pdf/2312.07424" title="Download PDF">pdf</a>, <a href="/format/2312.07424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Well Does GPT-4V(ision) Adapt to Distribution Shifts? A Preliminary  Investigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhongyi Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Guanglin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Rundong He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jindong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tailin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yilong Yin</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Salman Khan</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+L">Lina Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tongliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 62 pages, 39 figures, preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07439" title="Abstract">arXiv:2312.07439</a> (replaced) [<a href="/pdf/2312.07439" title="Download PDF">pdf</a>, <a href="/format/2312.07439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BIRB: A Generalization Benchmark for Information Retrieval in  Bioacoustics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamer%2C+J">Jenny Hamer</a>, 
<a href="/search/cs?searchtype=author&query=Triantafillou%2C+E">Eleni Triantafillou</a>, 
<a href="/search/cs?searchtype=author&query=van+Merri%C3%ABnboer%2C+B">Bart van Merri&#xeb;nboer</a>, 
<a href="/search/cs?searchtype=author&query=Kahl%2C+S">Stefan Kahl</a>, 
<a href="/search/cs?searchtype=author&query=Klinck%2C+H">Holger Klinck</a>, 
<a href="/search/cs?searchtype=author&query=Denton%2C+T">Tom Denton</a>, 
<a href="/search/cs?searchtype=author&query=Dumoulin%2C+V">Vincent Dumoulin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07472" title="Abstract">arXiv:2312.07472</a> (replaced) [<a href="/pdf/2312.07472" title="Download PDF">pdf</a>, <a href="/format/2312.07472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MP5: A Multi-modal Open-ended Embodied System in Minecraft via Active  Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yiran Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+E">Enshen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qichang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhenfei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+L">Lu Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruimao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jing Shao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project URL: <a href="https://iranqin.github.io/MP5.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item340">Cross-lists</a></li>
<li><a href="#item400">Replacements</a></li>
</ul>
<small>[ total of 607 entries:  <b>1-607</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2312">2312</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
