<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Wed  6 Dec 23  to  Thu  7 Dec 23, announced Fri,  8 Dec 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item385">Cross-lists</a></li>
<li><a href="#item425">Replacements</a></li>
</ul>
<small>[ total of 636 entries:  <b>1-636</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Fri,  8 Dec 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03705" title="Abstract">arXiv:2312.03705</a> [<a href="/pdf/2312.03705" title="Download PDF">pdf</a>, <a href="/format/2312.03705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Process for Topic Modelling Via Word Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ulloa%2C+D+S">Diego Salda&#xf1;a Ulloa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This work combines algorithms based on word embeddings, dimensionality
reduction, and clustering. The objective is to obtain topics from a set of
unclassified texts. The algorithm to obtain the word embeddings is the BERT
model, a neural network architecture widely used in NLP tasks. Due to the high
dimensionality, a dimensionality reduction technique called UMAP is used. This
method manages to reduce the dimensions while preserving part of the local and
global information of the original data. K-Means is used as the clustering
algorithm to obtain the topics. Then, the topics are evaluated using the TF-IDF
statistics, Topic Diversity, and Topic Coherence to get the meaning of the
words on the clusters. The results of the process show good values, so the
topic modeling of this process is a viable option for classifying or clustering
texts without labels.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03706" title="Abstract">arXiv:2312.03706</a> [<a href="/pdf/2312.03706" title="Download PDF">pdf</a>, <a href="/ps/2312.03706" title="Download PostScript">ps</a>, <a href="/format/2312.03706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Evaluation of State-of-the-Art Large Language Models for Sarcasm  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Juliann Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Sarcasm, as defined by Merriam-Webster, is the use of words by someone who
means the opposite of what he is trying to say. In the field of sentimental
analysis of Natural Language Processing, the ability to correctly identify
sarcasm is necessary for understanding people's true opinions. Because the use
of sarcasm is often context-based, previous research has used language
representation models, such as Support Vector Machine (SVM) and Long Short-Term
Memory (LSTM), to identify sarcasm with contextual-based information. Recent
innovations in NLP have provided more possibilities for detecting sarcasm. In
BERT: Pre-training of Deep Bidirectional Transformers for Language
Understanding, Jacob Devlin et al. (2018) introduced a new language
representation model and demonstrated higher precision in interpreting
contextualized language. As proposed by Hazarika et al. (2018), CASCADE is a
context-driven model that produces good results for detecting sarcasm. This
study analyzes a Reddit corpus using these two state-of-the-art models and
evaluates their performance against baseline models to find the ideal approach
to sarcasm detection.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03707" title="Abstract">arXiv:2312.03707</a> [<a href="/pdf/2312.03707" title="Download PDF">pdf</a>, <a href="/ps/2312.03707" title="Download PostScript">ps</a>, <a href="/format/2312.03707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-label Text Classification using GloVe and Neural Network Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongren Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Ten pages, refined from my course assignment
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This study addresses the challenges of multi-label text classification. The
difficulties arise from imbalanced data sets, varied text lengths, and numerous
subjective feature labels. Existing solutions include traditional machine
learning and deep neural networks for predictions. However, both approaches
have their limitations. Traditional machine learning often overlooks the
associations between words, while deep neural networks, despite their better
classification performance, come with increased training complexity and time.
This paper proposes a method utilizing the bag-of-words model approach based on
the GloVe model and the CNN-BiLSTM network. The principle is to use the word
vector matrix trained by the GloVe model as the input for the text embedding
layer. Given that the GloVe model requires no further training, the neural
network model can be trained more efficiently. The method achieves an accuracy
rate of 87.26% on the test set and an F1 score of 0.8737, showcasing promising
results.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03708" title="Abstract">arXiv:2312.03708</a> [<a href="/pdf/2312.03708" title="Download PDF">pdf</a>, <a href="/format/2312.03708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Abstraction via exemplars? A representational case study on lexical  category inference in BERT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Misra%2C+K">Kanishka Misra</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+N">Najoung Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2-page abstract, to appear in BUCLD48
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Exemplar based accounts are often considered to be in direct opposition to
pure linguistic abstraction in explaining language learners' ability to
generalize to novel expressions. However, the recent success of neural network
language models on linguistically sensitive tasks suggests that perhaps
abstractions can arise via the encoding of exemplars. We provide empirical
evidence for this claim by adapting an existing experiment that studies how an
LM (BERT) generalizes the usage of novel tokens that belong to lexical
categories such as Noun/Verb/Adjective/Adverb from exposure to only a single
instance of their usage. We analyze the representational behavior of the novel
tokens in these experiments, and find that BERT's capacity to generalize to
unseen expressions involving the use of these novel tokens constitutes the
movement of novel token representations towards regions of known category
exemplars in two-dimensional space. Our results suggest that learners' encoding
of exemplars can indeed give rise to abstraction like behavior.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03709" title="Abstract">arXiv:2312.03709</a> [<a href="/pdf/2312.03709" title="Download PDF">pdf</a>, <a href="/format/2312.03709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UID as a Guiding Metric for Automated Authorship Obfuscation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abegg%2C+N">Nicholas Abegg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Protecting the anonymity of authors has become a difficult task given the
rise of automated authorship attributors. These attributors are capable of
attributing the author of a text amongst a pool of authors with great accuracy.
In order to counter the rise of these automated attributors, there has also
been a rise of automated obfuscators. These obfuscators are capable of taking
some text, perturbing the text in some manner, and, if successful, deceive an
automated attributor in misattributing the wrong author. We devised three novel
authorship obfuscation methods that utilized a Psycho-linguistic theory known
as Uniform Information Density (UID) theory. This theory states that humans
evenly distribute information amongst speech or text so as to maximize
efficiency. Utilizing this theory in our three obfuscation methods, we
attempted to see how successfully we could deceive two separate attributors.
Obfuscating 50 human and 50 GPT-3 generated articles from the TuringBench
dataset, we observed how well each method did on deceiving the attributors.
While the quality of the obfuscation in terms of semantic preservation and
sensical changes was high, we were not able to find any evidence to indicate
UID was a viable guiding metric for obfuscation. However, due to restrictions
in time we were unable to test a large enough sample of article or tune the
parameters for our attributors to comment conclusively on UID in obfuscation.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03710" title="Abstract">arXiv:2312.03710</a> [<a href="/pdf/2312.03710" title="Download PDF">pdf</a>, <a href="/format/2312.03710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Don&#x27;t Overlook the Grammatical Gender: Bias Evaluation for Hindi-English  Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+P">Pushpdeep Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WiNLP Workshop, EMNLP 2023. This is a non-archival extended abstract version, to cite please refer to our complete paper: <a href="/abs/2311.03767">arXiv:2311.03767</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Neural Machine Translation (NMT) models, though state-of-the-art for
translation, often reflect social biases, particularly gender bias. Existing
evaluation benchmarks primarily focus on English as the source language of
translation. For source languages other than English, studies often employ
gender-neutral sentences for bias evaluation, whereas real-world sentences
frequently contain gender information in different forms. Therefore, it makes
more sense to evaluate for bias using such source sentences to determine if NMT
models can discern gender from the grammatical gender cues rather than relying
on biased associations. To illustrate this, we create two gender-specific
sentence sets in Hindi to automatically evaluate gender bias in various
Hindi-English (HI-EN) NMT systems. We emphasise the significance of tailoring
bias evaluation test sets to account for grammatical gender markers in the
source language.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03715" title="Abstract">arXiv:2312.03715</a> [<a href="/pdf/2312.03715" title="Download PDF">pdf</a>, <a href="/format/2312.03715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sentiment Analysis of Twitter Posts on Global Conflicts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sasikumar%2C+U">Ujwal Sasikumar</a>, 
<a href="/search/cs?searchtype=author&query=Zaman%2C+A">Ank Zaman</a>, 
<a href="/search/cs?searchtype=author&query=Mawlood-Yunis%2C+A">Abdul-Rahman Mawlood-Yunis</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+P">Prosenjit Chatterjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Sentiment analysis of social media data is an emerging field with vast
applications in various domains. In this study, we developed a sentiment
analysis model to analyze social media sentiment, especially tweets, during
global conflicting scenarios. To establish our research experiment, we
identified a recent global dispute incident on Twitter and collected around
31,000 filtered Tweets for several months to analyze human sentiment worldwide.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03716" title="Abstract">arXiv:2312.03716</a> [<a href="/pdf/2312.03716" title="Download PDF">pdf</a>, <a href="/format/2312.03716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Co-guiding for Multi-intent Spoken Language Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+B">Bowen Xing</a>, 
<a href="/search/cs?searchtype=author&query=Tsang%2C+I+W">Ivor W. Tsang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI). arXiv admin note: substantial text overlap with <a href="/abs/2210.10375">arXiv:2210.10375</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent graph-based models for multi-intent SLU have obtained promising
results through modeling the guidance from the prediction of intents to the
decoding of slot filling. However, existing methods (1) only model the
unidirectional guidance from intent to slot, while there are bidirectional
inter-correlations between intent and slot; (2) adopt homogeneous graphs to
model the interactions between the slot semantics nodes and intent label nodes,
which limit the performance. In this paper, we propose a novel model termed
Co-guiding Net, which implements a two-stage framework achieving the mutual
guidances between the two tasks. In the first stage, the initial estimated
labels of both tasks are produced, and then they are leveraged in the second
stage to model the mutual guidances. Specifically, we propose two heterogeneous
graph attention networks working on the proposed two heterogeneous semantics
label graphs, which effectively represent the relations among the semantics
nodes and label nodes. Besides, we further propose Co-guiding-SCL Net, which
exploits the single-task and dual-task semantics contrastive relations. For the
first stage, we propose single-task supervised contrastive learning, and for
the second stage, we propose co-guiding supervised contrastive learning, which
considers the two tasks' mutual guidances in the contrastive learning
procedure. Experiment results on multi-intent SLU show that our model
outperforms existing models by a large margin, obtaining a relative improvement
of 21.3% over the previous best model on MixATIS dataset in overall accuracy.
We also evaluate our model on the zero-shot cross-lingual scenario and the
results show that our model can relatively improve the state-of-the-art model
by 33.5% on average in terms of overall accuracy for the total 9 languages.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03718" title="Abstract">arXiv:2312.03718</a> [<a href="/pdf/2312.03718" title="Download PDF">pdf</a>, <a href="/format/2312.03718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models in Law: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+J">Jinqi Lai</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+W">Wensheng Gan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiayang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zhenlian Qi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The advent of artificial intelligence (AI) has significantly impacted the
traditional judicial industry. Moreover, recently, with the development of
AI-generated content (AIGC), AI and law have found applications in various
domains, including image recognition, automatic text generation, and
interactive chat. With the rapid emergence and growing popularity of large
models, it is evident that AI will drive transformation in the traditional
judicial industry. However, the application of legal large language models
(LLMs) is still in its nascent stage. Several challenges need to be addressed.
In this paper, we aim to provide a comprehensive survey of legal LLMs. We not
only conduct an extensive survey of LLMs, but also expose their applications in
the judicial system. We first provide an overview of AI technologies in the
legal field and showcase the recent research in LLMs. Then, we discuss the
practical implementation presented by legal LLMs, such as providing legal
advice to users and assisting judges during trials. In addition, we explore the
limitations of legal LLMs, including data, algorithms, and judicial practice.
Finally, we summarize practical recommendations and propose future development
directions to address these challenges.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03719" title="Abstract">arXiv:2312.03719</a> [<a href="/pdf/2312.03719" title="Download PDF">pdf</a>, <a href="/ps/2312.03719" title="Download PostScript">ps</a>, <a href="/format/2312.03719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing AI Chatbots Performance in Comprehensive Standardized Test  Preparation; A Case Study with GRE
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abu-Haifa%2C+M">Mohammad Abu-Haifa</a>, 
<a href="/search/cs?searchtype=author&query=Etawi%2C+B">Bara&#x27;a Etawi</a>, 
<a href="/search/cs?searchtype=author&query=Alkhatatbeh%2C+H">Huthaifa Alkhatatbeh</a>, 
<a href="/search/cs?searchtype=author&query=Ababneh%2C+A">Ayman Ababneh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 Pages, 6 figures, and 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This research paper presents a comprehensive evaluation of the performance of
three artificial 10 intelligence chatbots: Bing, ChatGPT, and GPT-4, in
addressing standardized test questions. Graduate record examination, known as
GRE, serves as a case study in this paper, encompassing both quantitative
reasoning and verbal skills. A total of 137 quantitative reasoning questions,
featuring diverse styles and 157 verbal questions categorized into varying
levels of difficulty (easy, medium, and hard) were administered to assess the
chatbots' capabilities. This paper provides a detailed examination of the
results and their implications for the utilization of artificial intelligence
in standardized test preparation by presenting the performance of each chatbot
across various skills and styles tested in the exam. Additionally, this paper
explores the proficiency of artificial intelligence in addressing image-based
questions and illustrates the uncertainty level of each chatbot. The results
reveal varying degrees of success across the chatbots, demonstrating the
influence of model sophistication and training data. GPT-4 emerged as the most
proficient, especially in complex language understanding tasks, highlighting
the evolution of artificial intelligence in language comprehension and its
ability to pass the exam with a high score.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03720" title="Abstract">arXiv:2312.03720</a> [<a href="/pdf/2312.03720" title="Download PDF">pdf</a>, <a href="/ps/2312.03720" title="Download PostScript">ps</a>, <a href="/format/2312.03720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Negotiating with LLMS: Prompt Hacks, Skill Gaps, and Reasoning Deficits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schneider%2C+J">Johannes Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Haag%2C+S">Steffi Haag</a>, 
<a href="/search/cs?searchtype=author&query=Kruse%2C+L+C">Leona Chandra Kruse</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models LLMs like ChatGPT have reached the 100 Mio user barrier
in record time and might increasingly enter all areas of our life leading to a
diverse set of interactions between those Artificial Intelligence models and
humans. While many studies have discussed governance and regulations
deductively from first-order principles, few studies provide an inductive,
data-driven lens based on observing dialogues between humans and LLMs
especially when it comes to non-collaborative, competitive situations that have
the potential to pose a serious threat to people. In this work, we conduct a
user study engaging over 40 individuals across all age groups in price
negotiations with an LLM. We explore how people interact with an LLM,
investigating differences in negotiation outcomes and strategies. Furthermore,
we highlight shortcomings of LLMs with respect to their reasoning capabilities
and, in turn, susceptiveness to prompt hacking, which intends to manipulate the
LLM to make agreements that are against its instructions or beyond any
rationality. We also show that the negotiated prices humans manage to achieve
span a broad range, which points to a literacy gap in effectively interacting
with LLMs.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03721" title="Abstract">arXiv:2312.03721</a> [<a href="/pdf/2312.03721" title="Download PDF">pdf</a>, <a href="/ps/2312.03721" title="Download PostScript">ps</a>, <a href="/format/2312.03721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Robustness of Model-Graded Evaluations and Automated  Interpretability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lermen%2C+S">Simon Lermen</a>, 
<a href="/search/cs?searchtype=author&query=Kvapil%2C+O">Ond&#x159;ej Kvapil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">There has been increasing interest in evaluations of language models for a
variety of risks and characteristics. Evaluations relying on natural language
understanding for grading can often be performed at scale by using other
language models. We test the robustness of these model-graded evaluations to
injections on different datasets including a new Deception Eval. These
injections resemble direct communication between the testee and the evaluator
to change their grading. We extrapolate that future, more intelligent models
might manipulate or cooperate with their evaluation model. We find significant
susceptibility to these injections in state-of-the-art commercial models on all
examined evaluations. Furthermore, similar injections can be used on automated
interpretability frameworks to produce misleading model-written explanations.
The results inspire future work and should caution against unqualified trust in
evaluations and automated interpretability.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03722" title="Abstract">arXiv:2312.03722</a> [<a href="/pdf/2312.03722" title="Download PDF">pdf</a>, <a href="/format/2312.03722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging AI-derived Data for Carbon Accounting: Information Extraction  from Alternative Sources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oladeji%2C+O">Olamide Oladeji</a>, 
<a href="/search/cs?searchtype=author&query=Mousavi%2C+S+S">Seyed Shahabeddin Mousavi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Carbon accounting is a fundamental building block in our global path to
emissions reduction and decarbonization, yet many challenges exist in achieving
reliable and trusted carbon accounting measures. We motivate that carbon
accounting not only needs to be more data-driven, but also more
methodologically sound. We discuss the need for alternative, more diverse data
sources that can play a significant role on our path to trusted carbon
accounting procedures and elaborate on not only why, but how Artificial
Intelligence (AI) in general and Natural Language Processing (NLP) in
particular can unlock reasonable access to a treasure trove of alternative data
sets in light of the recent advances in the field that better enable the
utilization of unstructured data in this process. We present a case study of
the recent developments on real-world data via an NLP-powered analysis using
OpenAI's GPT API on financial and shipping data. We conclude the paper with a
discussion on how these methods and approaches can be integrated into a broader
framework for AI-enabled integrative carbon accounting.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03723" title="Abstract">arXiv:2312.03723</a> [<a href="/pdf/2312.03723" title="Download PDF">pdf</a>, <a href="/format/2312.03723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT Application In Summarizing An Evolution Of Deep Learning  Techniques In Imaging: A Qualitative Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarraf%2C+A">Arman Sarraf</a>, 
<a href="/search/cs?searchtype=author&query=Abbaspour%2C+A">Amirabbas Abbaspour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The pursuit of article or text summarization has captured the attention of
natural language processing (NLP) practitioners, presenting itself as a
formidable challenge. ChatGPT 3.5 exhibits the capacity to condense the content
of up to 3000 tokens into a single page, aiming to retain pivotal information
from a given text across diverse themes. In a conducted qualitative research
endeavor, we selected seven scientific articles and employed the publicly
available ChatGPT service to generate summaries of these articles.
Subsequently, we engaged six co-authors of the articles in a survey, presenting
five questions to evaluate the quality of the summaries compared to the
original content. The findings revealed that the summaries produced by ChatGPT
effectively encapsulated the crucial information present in the articles,
preserving the principal message of each manuscript. Nonetheless, there was a
slight diminishment in the technical depth of the summaries as opposed to the
original articles. As a result, our conclusion underscores ChatGPT's text
summarization capability as a potent tool for extracting essential insights in
a manner more aligned with reporting than purely scientific discourse.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03724" title="Abstract">arXiv:2312.03724</a> [<a href="/pdf/2312.03724" title="Download PDF">pdf</a>, <a href="/format/2312.03724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DP-OPT: Make Large Language Model Your Privacy-Preserving Prompt  Engineer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Junyuan Hong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J+T">Jiachen T. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenhui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhangheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) have emerged as dominant tools for various
tasks, particularly when tailored for a specific target by prompt tuning.
Nevertheless, concerns surrounding data privacy present obstacles due to the
tuned prompts' dependency on sensitive private information. A practical
solution is to host a local LLM and optimize a soft prompt privately using
data. Yet, hosting a local model becomes problematic when model ownership is
protected. Alternative methods, like sending data to the model's provider for
training, intensify these privacy issues facing an untrusted provider. In this
paper, we present a novel solution called Differentially-Private Offsite Prompt
Tuning (DP-OPT) to address this challenge. Our approach involves tuning a
discrete prompt on the client side and then applying it to the desired cloud
models. We demonstrate that prompts suggested by LLMs themselves can be
transferred without compromising performance significantly. To ensure that the
prompts do not leak private information, we introduce the first private prompt
generation mechanism, by a differentially-private (DP) ensemble of in-context
learning with private demonstrations. With DP-OPT, generating
privacy-preserving prompts by Vicuna-7b can yield competitive performance
compared to non-private in-context learning on GPT3.5 or local private prompt
tuning. Codes are available at https://github.com/VITA-Group/DP-OPT .
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03725" title="Abstract">arXiv:2312.03725</a> [<a href="/pdf/2312.03725" title="Download PDF">pdf</a>, <a href="/format/2312.03725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCStory: Self-supervised and Continual Online Story Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S">Susik Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Y">Yu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongha Lee</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jiawei Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at WWW'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a framework SCStory for online story discovery, that helps people
digest rapidly published news article streams in real-time without human
annotations. To organize news article streams into stories, existing approaches
directly encode the articles and cluster them based on representation
similarity. However, these methods yield noisy and inaccurate story discovery
results because the generic article embeddings do not effectively reflect the
story-indicative semantics in an article and cannot adapt to the rapidly
evolving news article streams. SCStory employs self-supervised and continual
learning with a novel idea of story-indicative adaptive modeling of news
article streams. With a lightweight hierarchical embedding module that first
learns sentence representations and then article representations, SCStory
identifies story-relevant information of news articles and uses them to
discover stories. The embedding module is continuously updated to adapt to
evolving news streams with a contrastive learning objective, backed up by two
unique techniques, confidence-aware memory replay and prioritized-augmentation,
employed for label absence and data scarcity problems. Thorough experiments on
real and the latest news data sets demonstrate that SCStory outperforms
existing state-of-the-art algorithms for unsupervised online story discovery.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03726" title="Abstract">arXiv:2312.03726</a> [<a href="/pdf/2312.03726" title="Download PDF">pdf</a>, <a href="/format/2312.03726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretation modeling: Social grounding of sentences by reasoning over  their implicit moral judgments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Allein%2C+L">Liesbeth Allein</a>, 
<a href="/search/cs?searchtype=author&query=Tru%C5%9Fc%C7%8E%2C+M+M">Maria Mihaela Tru&#x15f;c&#x1ce;</a>, 
<a href="/search/cs?searchtype=author&query=Moens%2C+M">Marie-Francine Moens</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The social and implicit nature of human communication ramifies readers'
understandings of written sentences. Single gold-standard interpretations
rarely exist, challenging conventional assumptions in natural language
processing. This work introduces the interpretation modeling (IM) task which
involves modeling several interpretations of a sentence's underlying semantics
to unearth layers of implicit meaning. To obtain these, IM is guided by
multiple annotations of social relation and common ground - in this work
approximated by reader attitudes towards the author and their understanding of
moral judgments subtly embedded in the sentence. We propose a number of
modeling strategies that rely on one-to-one and one-to-many generation methods
that take inspiration from the philosophical study of interpretation. A
first-of-its-kind IM dataset is curated to support experiments and analyses.
The modeling results, coupled with scrutiny of the dataset, underline the
challenges of IM as conflicting and complex interpretations are socially
plausible. This interplay of diverse readings is affirmed by automated and
human evaluations on the generated interpretations. Finally, toxicity analyses
in the generated interpretations demonstrate the importance of IM for refining
filters of content and assisting content moderators in safeguarding the safety
in online discourse.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03727" title="Abstract">arXiv:2312.03727</a> [<a href="/pdf/2312.03727" title="Download PDF">pdf</a>, <a href="/format/2312.03727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Content-Localization based System for Analyzing Sentiment and Hate  Behaviors in Low-Resource Dialectal Arabic: English to Levantine and Gulf
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alzamzami%2C+F">Fatimah Alzamzami</a>, 
<a href="/search/cs?searchtype=author&query=Saddik%2C+A+E">Abdulmotaleb El Saddik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Even though online social movements can quickly become viral on social media,
languages can be a barrier to timely monitoring and analyzing the underlying
online social behaviors (OSB). This is especially true for under-resourced
languages on social media like dialectal Arabic; the primary language used by
Arabs on social media. Therefore, it is crucial to provide solutions to
efficiently exploit resources from high-resourced languages to solve
language-dependent OSB analysis in under-resourced languages. This paper
proposes to localize content of resources in high-resourced languages into
under-resourced Arabic dialects. Content localization goes beyond content
translation that converts text from one language to another; content
localization adapts culture, language nuances and regional preferences from one
language to a specific language/dialect. Automating understanding of the
natural and familiar day-to-day expressions in different regions, is the key to
achieve a wider analysis of OSB especially for smart cities. In this paper, we
utilize content-localization based neural machine translation to develop
sentiment and hate classifiers for two low-resourced Arabic dialects: Levantine
and Gulf. Not only this but we also leverage unsupervised learning to
facilitate the analysis of sentiment and hate predictions by inferring hidden
topics from the corresponding data and providing coherent interpretations of
those topics in their native language/dialects. The experimental evaluations
and proof-of-concept COVID-19 case study on real data have validated the
effectiveness of our proposed system in precisely distinguishing sentiments and
accurately identifying hate content in both Levantine and Gulf Arabic dialects.
Our findings shed light on the importance of considering the unique nature of
dialects within the same language and ignoring the dialectal aspect would lead
to misleading analysis.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03728" title="Abstract">arXiv:2312.03728</a> [<a href="/pdf/2312.03728" title="Download PDF">pdf</a>, <a href="/ps/2312.03728" title="Download PostScript">ps</a>, <a href="/format/2312.03728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real Customization or Just Marketing: Are Customized Versions of Chat  GPT Useful?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garrido-Merch%C3%A1n%2C+E+C">Eduardo C. Garrido-Merch&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Arroyo-Barrig%C3%BCete%2C+J+L">Jose L. Arroyo-Barrig&#xfc;ete</a>, 
<a href="/search/cs?searchtype=author&query=Borr%C3%A1s-Pala%2C+F">Francisco Borr&#xe1;s-Pala</a>, 
<a href="/search/cs?searchtype=author&query=Escobar-Torres%2C+L">Leandro Escobar-Torres</a>, 
<a href="/search/cs?searchtype=author&query=de+Ibarreta%2C+C+M">Carlos Mart&#xed;nez de Ibarreta</a>, 
<a href="/search/cs?searchtype=author&query=Ortiz-Lozano%2C+J+M">Jose Mar&#xed;a Ortiz-Lozano</a>, 
<a href="/search/cs?searchtype=author&query=Rua-Vieites%2C+A">Antonio Rua-Vieites</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 1 figure, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs), as the case of OpenAI ChatGPT-4 Turbo, are
revolutionizing several industries, including higher education. In this
context, LLMs can be personalized through a fine-tuning process to meet the
student demands on every particular subject, like statistics. Recently, OpenAI
has launched the possibility to fine-tune their model with a natural language
web interface, enabling the possibility to create customized GPT version
deliberately conditioned to meet the demands of a specific task. The objective
of this research is to assess the potential of the customized GPTs that have
recently been launched by OpenAI. After developing a Business Statistics
Virtual Professor (BSVP), tailored for students at the Universidad Pontificia
Comillas, its behavior was evaluated and compared with that of ChatGPT-4 Turbo.
The results lead to several conclusions. Firstly, a substantial modification in
the style of communication was observed. Following the instructions it was
trained with, BSVP provided responses in a more relatable and friendly tone,
even incorporating a few minor jokes. Secondly, and this is a matter of
relevance, when explicitly asked for something like, "I would like to practice
a programming exercise similar to those in R practice 4," BSVP was capable of
providing a far superior response: having access to contextual documentation,
it could fulfill the request, something beyond ChatGPT-4 Turbo's capabilities.
On the downside, the response times were generally higher. Lastly, regarding
overall performance, quality, depth, and alignment with the specific content of
the course, no statistically significant differences were observed in the
responses between BSVP and ChatGPT-4 Turbo. It appears that customized
assistants trained with prompts present advantages as virtual aids for
students, yet they do not constitute a substantial improvement over ChatGPT-4
Turbo.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03729" title="Abstract">arXiv:2312.03729</a> [<a href="/pdf/2312.03729" title="Download PDF">pdf</a>, <a href="/format/2312.03729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cognitive Dissonance: Why Do Language Model Outputs Disagree with  Internal Representations of Truthfulness?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kevin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Casper%2C+S">Stephen Casper</a>, 
<a href="/search/cs?searchtype=author&query=Hadfield-Menell%2C+D">Dylan Hadfield-Menell</a>, 
<a href="/search/cs?searchtype=author&query=Andreas%2C+J">Jacob Andreas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Neural language models (LMs) can be used to evaluate the truth of factual
statements in two ways: they can be either queried for statement probabilities,
or probed for internal representations of truthfulness. Past work has found
that these two procedures sometimes disagree, and that probes tend to be more
accurate than LM outputs. This has led some researchers to conclude that LMs
"lie" or otherwise encode non-cooperative communicative intents. Is this an
accurate description of today's LMs, or can query-probe disagreement arise in
other ways? We identify three different classes of disagreement, which we term
confabulation, deception, and heterogeneity. In many cases, the superiority of
probes is simply attributable to better calibration on uncertain answers rather
than a greater fraction of correct, high-confidence answers. In some cases,
queries and probes perform better on different subsets of inputs, and accuracy
can further be improved by ensembling the two. Code is available at
github.com/lingo-mit/lm-truthfulness.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03730" title="Abstract">arXiv:2312.03730</a> [<a href="/pdf/2312.03730" title="Download PDF">pdf</a>, <a href="/format/2312.03730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FakeWatch ElectionShield: A Benchmarking Framework to Detect Fake News  for Credible US Elections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+T">Tahniat Khan</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M">Mizanur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Chatrath%2C+V">Veronica Chatrath</a>, 
<a href="/search/cs?searchtype=author&query=Bamgbose%2C+O">Oluwanifemi Bamgbose</a>, 
<a href="/search/cs?searchtype=author&query=Raza%2C+S">Shaina Raza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In today's technologically driven world, the spread of fake news,
particularly during crucial events such as elections, presents an increasing
challenge to the integrity of information. To address this challenge, we
introduce FakeWatch ElectionShield, an innovative framework carefully designed
to detect fake news. We have created a novel dataset of North American
election-related news articles through a blend of advanced language models
(LMs) and thorough human verification, for precision and relevance. We propose
a model hub of LMs for identifying fake news. Our goal is to provide the
research community with adaptable and accurate classification models in
recognizing the dynamic nature of misinformation. Extensive evaluation of fake
news classifiers on our dataset and a benchmark dataset shows our that while
state-of-the-art LMs slightly outperform the traditional ML models, classical
models are still competitive with their balance of accuracy, explainability,
and computational efficiency. This research sets the foundation for future
studies to address misinformation related to elections.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03731" title="Abstract">arXiv:2312.03731</a> [<a href="/pdf/2312.03731" title="Download PDF">pdf</a>, <a href="/format/2312.03731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultiGPrompt for Multi-Task Pre-Training and Prompting on Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xingtong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinming Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Graphs can inherently model interconnected objects on the Web, thereby
facilitating a series of Web applications, such as web analyzing and content
recommendation. Recently, Graph Neural Networks (GNNs) have emerged as a
mainstream technique for graph representation learning. However, their efficacy
within an end-to-end supervised framework is significantly tied to the
availabilityof task-specific labels. To mitigate labeling costs and enhance
robustness in few-shot settings, pre-training on self-supervised tasks has
emerged as a promising method, while prompting has been proposed to further
narrow the objective gap between pretext and downstream tasks. Although there
has been some initial exploration of prompt-based learning on graphs, they
primarily leverage a single pretext task, resulting in a limited subset of
general knowledge that could be learned from the pre-training data. Hence, in
this paper, we propose MultiGPrompt, a novel multi-task pre-training and
prompting framework to exploit multiple pretext tasks for more comprehensive
pre-trained knowledge. First, in pre-training, we design a set of pretext
tokens to synergize multiple pretext tasks. Second, we propose a dual-prompt
mechanism consisting of composed and open prompts to leverage task-specific and
global pre-training knowledge, to guide downstream tasks in few-shot settings.
Finally, we conduct extensive experiments on six public datasets to evaluate
and analyze MultiGPrompt.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03732" title="Abstract">arXiv:2312.03732</a> [<a href="/pdf/2312.03732" title="Download PDF">pdf</a>, <a href="/format/2312.03732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Rank Stabilization Scaling Factor for Fine-Tuning with LoRA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalajdzievski%2C+D">Damjan Kalajdzievski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">As large language models (LLMs) have become increasingly compute and memory
intensive, parameter-efficient fine-tuning (PEFT) methods are now a common
strategy to fine-tune LLMs. A popular PEFT method is Low-Rank Adapters (LoRA),
which adds trainable low-rank "adapters" to selected layers. Each adapter
consists of a low-rank matrix product, multiplicatively scaled by a
rank-dependent factor. This scaling factor, which divides adapters by a factor
of the rank, results in slowed learning and stunted performance for LoRA with
higher-rank adapters. Consequently, the use of LoRA in practice has generally
been limited to very low ranks. In this work, we study the impact of the
scaling factor on the learning process and prove that LoRA adapters should be
divided by a factor of the square root of the rank. Modifying LoRA with the
appropriate scaling factor, which we call the rank-stabilized LoRA (rsLoRA)
method, easily provides for a fine-tuning compute/performance trade-off, where
larger ranks can be used to trade off increased computational resources during
training for better fine-tuning performance, with no change in inference
computing cost.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03733" title="Abstract">arXiv:2312.03733</a> [<a href="/pdf/2312.03733" title="Download PDF">pdf</a>, <a href="/ps/2312.03733" title="Download PostScript">ps</a>, <a href="/format/2312.03733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Methods to Estimate Large Language Model Confidence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kotelanski%2C+M">Maia Kotelanski</a>, 
<a href="/search/cs?searchtype=author&query=Gallo%2C+R">Robert Gallo</a>, 
<a href="/search/cs?searchtype=author&query=Nayak%2C+A">Ashwin Nayak</a>, 
<a href="/search/cs?searchtype=author&query=Savage%2C+T">Thomas Savage</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models have difficulty communicating uncertainty, which is a
significant obstacle to applying LLMs to complex medical tasks. This study
evaluates methods to measure LLM confidence when suggesting a diagnosis for
challenging clinical vignettes. GPT4 was asked a series of challenging case
questions using Chain of Thought and Self Consistency prompting. Multiple
methods were investigated to assess model confidence and evaluated on their
ability to predict the models observed accuracy. The methods evaluated were
Intrinsic Confidence, SC Agreement Frequency and CoT Response Length. SC
Agreement Frequency correlated with observed accuracy, yielding a higher Area
under the Receiver Operating Characteristic Curve compared to Intrinsic
Confidence and CoT Length analysis. SC agreement is the most useful proxy for
model confidence, especially for medical diagnosis. Model Intrinsic Confidence
and CoT Response Length exhibit a weaker ability to differentiate between
correct and incorrect answers, preventing them from being reliable and
interpretable markers for model confidence. We conclude GPT4 has a limited
ability to assess its own diagnostic accuracy. SC Agreement Frequency is the
most useful method to measure GPT4 confidence.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03734" title="Abstract">arXiv:2312.03734</a> [<a href="/pdf/2312.03734" title="Download PDF">pdf</a>, <a href="/format/2312.03734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditional Prompt Tuning for Multimodal Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+R">Ruixiang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingbo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Changwen Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We show that the representation of one modality can effectively guide the
prompting of another modality for parameter-efficient multimodal fusion.
Specifically, we first encode one modality and use its representation as a
prior to conditionally prompt all frozen layers of the other modality. This is
achieved by disentangling the vanilla prompt vectors into three types of
specialized prompts that adaptively capture global-level and instance-level
features. To better produce the instance-wise prompt, we introduce the mixture
of prompt experts (MoPE) to dynamically route each instance to the most
suitable prompt experts for encoding. We further study a regularization term to
avoid degenerated prompt expert routing. Thanks to our design, our method can
effectively transfer the pretrained knowledge in unimodal encoders for
downstream multimodal tasks. Compared with vanilla prompting, we show that our
MoPE-based conditional prompting is more expressive, thereby scales better with
training data and the total number of prompts. We also demonstrate that our
prompt tuning is architecture-agnostic, thereby offering high modularity.
Extensive experiments over three multimodal datasets demonstrate
state-of-the-art results, matching or surpassing the performance achieved
through fine-tuning, while only necessitating 0.7% of the trainable parameters.
Code will be released: https://github.com/songrise/ConditionalPrompt.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03735" title="Abstract">arXiv:2312.03735</a> [<a href="/pdf/2312.03735" title="Download PDF">pdf</a>, <a href="/format/2312.03735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing State of the Art in Language Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herel%2C+D">David Herel</a>, 
<a href="/search/cs?searchtype=author&query=Mikolov%2C+T">Tomas Mikolov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generalization is arguably the most important goal of statistical language
modeling research. Publicly available benchmarks and papers published with an
open-source code have been critical to advancing the field. However, it is
often very difficult, and sometimes even impossible, to reproduce the results
fully as reported in publications. In this paper, we propose a simple framework
that should help advance the state of the art in language modeling in terms of
generalization. We propose to publish not just the code, but also probabilities
on dev and test sets with future publications so that one can easily add the
new model into an ensemble. This has crucial advantages: it is much easier to
determine whether a newly proposed model is actually complementary to the
current baseline. Therefore, instead of inventing new names for the old tricks,
the scientific community can advance faster. Finally, this approach promotes
diversity of ideas: one does not need to create an individual model that is the
new state of the art to attract attention; it will be sufficient to develop a
new model that learns patterns which other models do not. Thus, even a
suboptimal model can be found to have value. Remarkably, our approach has
yielded new state-of-the-art results across various language modeling
benchmarks up to 10%.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03736" title="Abstract">arXiv:2312.03736</a> [<a href="/pdf/2312.03736" title="Download PDF">pdf</a>, <a href="/ps/2312.03736" title="Download PostScript">ps</a>, <a href="/format/2312.03736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> De-identification of clinical free text using natural language  processing: A systematic review of current approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kova%C4%8Devi%C4%87%2C+A">Aleksandar Kova&#x10d;evi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Ba%C5%A1aragin%2C+B">Bojana Ba&#x161;aragin</a>, 
<a href="/search/cs?searchtype=author&query=Milo%C5%A1evi%C4%87%2C+N">Nikola Milo&#x161;evi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Nenadi%C4%87%2C+G">Goran Nenadi&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Artificial Intelligence in Medicine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Digital Libraries (cs.DL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Background: Electronic health records (EHRs) are a valuable resource for
data-driven medical research. However, the presence of protected health
information (PHI) makes EHRs unsuitable to be shared for research purposes.
De-identification, i.e. the process of removing PHI is a critical step in
making EHR data accessible. Natural language processing has repeatedly
demonstrated its feasibility in automating the de-identification process.
Objectives: Our study aims to provide systematic evidence on how the
de-identification of clinical free text has evolved in the last thirteen years,
and to report on the performances and limitations of the current
state-of-the-art systems. In addition, we aim to identify challenges and
potential research opportunities in this field. Methods: A systematic search in
PubMed, Web of Science and the DBLP was conducted for studies published between
January 2010 and February 2023. Titles and abstracts were examined to identify
the relevant studies. Selected studies were then analysed in-depth, and
information was collected on de-identification methodologies, data sources, and
measured performance. Results: A total of 2125 publications were identified for
the title and abstract screening. 69 studies were found to be relevant. Machine
learning (37 studies) and hybrid (26 studies) approaches are predominant, while
six studies relied only on rules. Majority of the approaches were trained and
evaluated on public corpora. The 2014 i2b2/UTHealth corpus is the most
frequently used (36 studies), followed by the 2006 i2b2 (18 studies) and 2016
CEGS N-GRID (10 studies) corpora.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03737" title="Abstract">arXiv:2312.03737</a> [<a href="/pdf/2312.03737" title="Download PDF">pdf</a>, <a href="/ps/2312.03737" title="Download PostScript">ps</a>, <a href="/format/2312.03737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generic NLI approach for Classification of Sentiment Associated with  Therapies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kanagasabai%2C+R">Rajaraman Kanagasabai</a>, 
<a href="/search/cs?searchtype=author&query=Veeramani%2C+A">Anitha Veeramani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Workshop on Social Media Mining for Health 2023 (#SMM4H)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper describes our system for addressing SMM4H 2023 Shared Task 2 on
"Classification of sentiment associated with therapies (aspect-oriented)". In
our work, we adopt an approach based on Natural language inference (NLI) to
formulate this task as a sentence pair classification problem, and train
transformer models to predict sentiment associated with a therapy on a given
text. Our best model achieved 75.22\% F1-score which was 11\% (4\%) more than
the mean (median) score of all teams' submissions.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03738" title="Abstract">arXiv:2312.03738</a> [<a href="/pdf/2312.03738" title="Download PDF">pdf</a>, <a href="/ps/2312.03738" title="Download PostScript">ps</a>, <a href="/format/2312.03738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Syntactic Fusion: Enhancing Aspect-Level Sentiment Analysis Through  Multi-Tree Graph Integration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sunny%2C+J">Jane Sunny</a>, 
<a href="/search/cs?searchtype=author&query=Padraig%2C+T">Tom Padraig</a>, 
<a href="/search/cs?searchtype=author&query=Terry%2C+R">Roggie Terry</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+W">Woods Ali</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent progress in aspect-level sentiment classification has been propelled
by the incorporation of graph neural networks (GNNs) leveraging syntactic
structures, particularly dependency trees. Nevertheless, the performance of
these models is often hampered by the innate inaccuracies of parsing
algorithms. To mitigate this challenge, we introduce SynthFusion, an innovative
graph ensemble method that amalgamates predictions from multiple parsers. This
strategy blends diverse dependency relations prior to the application of GNNs,
enhancing robustness against parsing errors while avoiding extra computational
burdens. SynthFusion circumvents the pitfalls of overparameterization and
diminishes the risk of overfitting, prevalent in models with stacked GNN
layers, by optimizing graph connectivity. Our empirical evaluations on the
SemEval14 and Twitter14 datasets affirm that SynthFusion not only outshines
models reliant on single dependency trees but also eclipses alternative
ensemble techniques, achieving this without an escalation in model complexity.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03739" title="Abstract">arXiv:2312.03739</a> [<a href="/pdf/2312.03739" title="Download PDF">pdf</a>, <a href="/ps/2312.03739" title="Download PostScript">ps</a>, <a href="/format/2312.03739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Syntax-Informed Interactive Model for Comprehensive Aspect-Based  Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Galen%2C+U">Ullman Galen</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+F">Frey Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+W">Woods Ali</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Aspect-based sentiment analysis (ABSA), a nuanced task in text analysis,
seeks to discern sentiment orientation linked to specific aspect terms in text.
Traditional approaches often overlook or inadequately model the explicit
syntactic structures of sentences, crucial for effective aspect term
identification and sentiment determination. Addressing this gap, we introduce
an innovative model: Syntactic Dependency Enhanced Multi-Task Interaction
Architecture (SDEMTIA) for comprehensive ABSA. Our approach innovatively
exploits syntactic knowledge (dependency relations and types) using a
specialized Syntactic Dependency Embedded Interactive Network (SDEIN). We also
incorporate a novel and efficient message-passing mechanism within a multi-task
learning framework to bolster learning efficacy. Our extensive experiments on
benchmark datasets showcase our model's superiority, significantly surpassing
existing methods. Additionally, incorporating BERT as an auxiliary feature
extractor further enhances our model's performance.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03740" title="Abstract">arXiv:2312.03740</a> [<a href="/pdf/2312.03740" title="Download PDF">pdf</a>, <a href="/format/2312.03740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompting in Autoregressive Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhandari%2C+P">Prabin Bhandari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Autoregressive Large Language Models have transformed the landscape of
Natural Language Processing. Pre-train and prompt paradigm has replaced the
conventional approach of pre-training and fine-tuning for many downstream NLP
tasks. This shift has been possible largely due to LLMs and innovative
prompting techniques. LLMs have shown great promise for a variety of downstream
tasks owing to their vast parameters and huge datasets that they are
pre-trained on. However, in order to fully realize their potential, their
outputs must be guided towards the desired outcomes. Prompting, in which a
specific input or instruction is provided to guide the LLMs toward the intended
output, has become a tool for achieving this goal. In this paper, we discuss
the various prompting techniques that have been applied to fully harness the
power of LLMs. We present a taxonomy of existing literature on prompting
techniques and provide a concise survey based on this taxonomy. Further, we
identify some open problems in the realm of prompting in autoregressive LLMs
which could serve as a direction for future research.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03741" title="Abstract">arXiv:2312.03741</a> [<a href="/pdf/2312.03741" title="Download PDF">pdf</a>, <a href="/format/2312.03741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing Generative Chatbots Based on Process Requirements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lins%2C+L+F">Luis Fernando Lins</a>, 
<a href="/search/cs?searchtype=author&query=Nascimento%2C+N">Nathalia Nascimento</a>, 
<a href="/search/cs?searchtype=author&query=Alencar%2C+P">Paulo Alencar</a>, 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+T">Toacy Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Cowan%2C+D">Donald Cowan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE BigData
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
<p class="mathjax">Business processes are commonly represented by modelling languages, such as
Event-driven Process Chain (EPC), Yet Another Workflow Language (YAWL), and the
most popular standard notation for modelling business processes, the Business
Process Model and Notation (BPMN). Most recently, chatbots, programs that allow
users to interact with a machine using natural language, have been increasingly
used for business process execution support. A recent category of chatbots
worth mentioning is generative-based chatbots, powered by Large Language Models
(LLMs) such as OpenAI's Generative Pre-Trained Transformer (GPT) model and
Google's Pathways Language Model (PaLM), which are trained on billions of
parameters and support conversational intelligence. However, it is not clear
whether generative-based chatbots are able to understand and meet the
requirements of constructs such as those provided by BPMN for process execution
support. This paper presents a case study to compare the performance of
prominent generative models, GPT and PaLM, in the context of process execution
support. The research sheds light into the challenging problem of using
conversational approaches supported by generative chatbots as a means to
understand process-aware modelling notations and support users to execute their
tasks.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03742" title="Abstract">arXiv:2312.03742</a> [<a href="/pdf/2312.03742" title="Download PDF">pdf</a>, <a href="/format/2312.03742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clinical Risk Prediction Using Language Models: Benefits And  Considerations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Acharya%2C+A">Angeela Acharya</a>, 
<a href="/search/cs?searchtype=author&query=Shrestha%2C+S">Sulabh Shrestha</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Anyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Conte%2C+J">Joseph Conte</a>, 
<a href="/search/cs?searchtype=author&query=Avramovic%2C+S">Sanja Avramovic</a>, 
<a href="/search/cs?searchtype=author&query=Sikdar%2C+S">Siddhartha Sikdar</a>, 
<a href="/search/cs?searchtype=author&query=Anastasopoulos%2C+A">Antonios Anastasopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Sanmay Das</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The utilization of Electronic Health Records (EHRs) for clinical risk
prediction is on the rise. However, strict privacy regulations limit access to
comprehensive health records, making it challenging to apply standard machine
learning algorithms in practical real-world scenarios. Previous research has
addressed this data limitation by incorporating medical ontologies and
employing transfer learning methods. In this study, we investigate the
potential of leveraging language models (LMs) as a means to incorporate
supplementary domain knowledge for improving the performance of various
EHR-based risk prediction tasks. Unlike applying LMs to unstructured EHR data
such as clinical notes, this study focuses on using textual descriptions within
structured EHR to make predictions exclusively based on that information. We
extensively compare against previous approaches across various data types and
sizes. We find that employing LMs to represent structured EHRs, such as
diagnostic histories, leads to improved or at least comparable performance in
diverse risk prediction tasks. Furthermore, LM-based approaches offer numerous
advantages, including few-shot learning, the capability to handle previously
unseen medical concepts, and adaptability to various medical vocabularies.
Nevertheless, we underscore, through various experiments, the importance of
being cautious when employing such models, as concerns regarding the
reliability of LMs persist.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03743" title="Abstract">arXiv:2312.03743</a> [<a href="/pdf/2312.03743" title="Download PDF">pdf</a>, <a href="/ps/2312.03743" title="Download PostScript">ps</a>, <a href="/format/2312.03743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Easy Data Augmentation in Sentiment Analysis of Cyberbullying
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wirawan%2C+A">Alwan Wirawan</a>, 
<a href="/search/cs?searchtype=author&query=Cahyono%2C+H+D">Hasan Dwi Cahyono</a>, 
<a href="/search/cs?searchtype=author&query=Winarno">Winarno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Instagram, a social media platform, has in the vicinity of 2 billion active
users in 2023. The platform allows users to post photos and videos with one
another. However, cyberbullying remains a significant problem for about 50% of
young Indonesians. To address this issue, sentiment analysis for comment
filtering uses a Support Vector Machine (SVM) and Easy Data Augmentation (EDA).
EDA will augment the dataset, enabling robust prediction and analysis of
cyberbullying by introducing more variation. Based on the tests, SVM
combination with EDA results in a 2.52% increase in the k-Fold Cross Validation
score. Our proposed approach shows an improved accuracy of 92.5%, 2.5% higher
than that of the existing state-of-the-art method. To maintain the
reproducibility and replicability of this research, the source code can be
accessed at uns.id/eda_svm.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03744" title="Abstract">arXiv:2312.03744</a> [<a href="/pdf/2312.03744" title="Download PDF">pdf</a>, <a href="/ps/2312.03744" title="Download PostScript">ps</a>, <a href="/format/2312.03744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic interactive group decision making method on two-dimensional  language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yukun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2311.18116">arXiv:2311.18116</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">The language evaluation information of the interactive group decision method
at present is based on the one-dimension language variable. At the same time,
multi-attribute group decision making method based on two-dimension linguistic
information only use single-stage and static evaluation method. In this paper,
we propose a dynamic group decision making method based on two-dimension
linguistic information, combining dynamic interactive group decision making
methods with two-dimensional language evaluation information The method first
use Two-Dimensional Uncertain Linguistic Generalized Weighted Aggregation
(DULGWA) Operators to aggregate the preference information of each decision
maker, then adopting dynamic information entropy method to obtain weights of
attributes at each stage. Finally we propose the group consistency index to
quantify the termination conditions of group interaction. One example is given
to verify the developed approach and to demonstrate its effectiveness
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03746" title="Abstract">arXiv:2312.03746</a> [<a href="/pdf/2312.03746" title="Download PDF">pdf</a>, <a href="/ps/2312.03746" title="Download PostScript">ps</a>, <a href="/format/2312.03746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Large Language Model Creativity from a Literary Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shanahan%2C+M">Murray Shanahan</a>, 
<a href="/search/cs?searchtype=author&query=Clarke%2C+C">Catherine Clarke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper assesses the potential for large language models (LLMs) to serve
as assistive tools in the creative writing process, by means of a single,
in-depth case study. In the course of the study, we develop interactive and
multi-voice prompting strategies that interleave background descriptions (scene
setting, plot elements), instructions that guide composition, samples of text
in the target style, and critical discussion of the given samples. We
qualitatively evaluate the results from a literary critical perspective, as
well as from the standpoint of computational creativity (a sub-field of
artificial intelligence). Our findings lend support to the view that the
sophistication of the results that can be achieved with an LLM mirrors the
sophistication of the prompting.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03747" title="Abstract">arXiv:2312.03747</a> [<a href="/pdf/2312.03747" title="Download PDF">pdf</a>, <a href="/format/2312.03747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classifying patient voice in social media data using neural networks: A  comparison of AI models on different data sources and therapeutic domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lysandrou%2C+G">Giorgos Lysandrou</a>, 
<a href="/search/cs?searchtype=author&query=Owen%2C+R+E">Roma English Owen</a>, 
<a href="/search/cs?searchtype=author&query=Popovic%2C+V">Vanja Popovic</a>, 
<a href="/search/cs?searchtype=author&query=Brun%2C+G+L">Grant Le Brun</a>, 
<a href="/search/cs?searchtype=author&query=Alex%2C+B">Beatrice Alex</a>, 
<a href="/search/cs?searchtype=author&query=Fairley%2C+E+A+L">Elizabeth A. L. Fairley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 1 figure, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">It is essential that healthcare professionals and members of the healthcare
community can access and easily understand patient experiences in the real
world, so that care standards can be improved and driven towards personalised
drug treatment. Social media platforms and message boards are deemed suitable
sources of patient experience information, as patients have been observed to
discuss and exchange knowledge, look for and provide support online. This paper
tests the hypothesis that not all online patient experience information can be
treated and collected in the same way, as a result of the inherent differences
in the way individuals talk about their journeys, in different therapeutic
domains and or data sources.
<br />We used linguistic analysis to understand and identify similarities between
datasets, across patient language, between data sources (Reddit, SocialGist)
and therapeutic domains (cardiovascular, oncology, immunology, neurology). We
detected common vocabulary used by patients in the same therapeutic domain
across data sources, except for immunology patients, who use unique vocabulary
between the two data sources, and compared to all other datasets. We combined
linguistically similar datasets to train classifiers (CNN, transformer) to
accurately identify patient experience posts from social media, a task we refer
to as patient voice classification. The cardiovascular and neurology
transformer classifiers perform the best in their respective comparisons for
the Reddit data source, achieving F1-scores of 0.865 and 1.0 respectively. The
overall best performing classifier is the transformer classifier trained on all
data collected for this experiment, achieving F1-scores ranging between 0.863
and 0.995 across all therapeutic domain and data source specific test datasets.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03748" title="Abstract">arXiv:2312.03748</a> [<a href="/pdf/2312.03748" title="Download PDF">pdf</a>, <a href="/format/2312.03748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applying Large Language Models and Chain-of-Thought for Automatic  Scoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+G">Gyeong-Geon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Latif%2C+E">Ehsan Latif</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xuansheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ninghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaoming Zhai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study investigates the application of large language models (LLMs),
specifically GPT-3.5 and GPT-4, with Chain-of-Though (CoT)in the automatic
scoring of student-written responses to science assessments. We focused on
overcoming the challenges of accessibility, technical complexity, and lack of
explainability that have previously limited the use of automatic assessment
tools among researchers and educators. We used a testing dataset comprising six
assessment tasks (three binomial and three trinomial) with 1,650 student
responses. We employed six prompt engineering strategies, combining zero-shot
or few-shot learning with CoT, either alone or alongside item stem and scoring
rubrics. Results indicated that few-shot (acc = .67) outperformed zero-shot
learning (acc = .60), with 12.6\% increase. CoT, when used without item stem
and scoring rubrics, did not significantly affect scoring accuracy (acc = .60).
However, CoT prompting paired with contextual item stems and rubrics proved to
be a significant contributor to scoring accuracy (13.44\% increase for
zero-shot; 3.7\% increase for few-shot). Using a novel approach PPEAS, we found
a more balanced accuracy across different proficiency categories, highlighting
the importance of domain-specific reasoning in enhancing the effectiveness of
LLMs in scoring tasks. Additionally, we also found that GPT-4 demonstrated
superior performance over GPT-3.5 in various scoring tasks, showing 8.64\%
difference. The study revealed that the single-call strategy with GPT-4,
particularly using greedy sampling, outperformed other approaches, including
ensemble voting strategies. This study demonstrates the potential of LLMs in
facilitating automatic scoring, emphasizing that CoT enhances accuracy,
particularly when used with item stem and scoring rubrics.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03749" title="Abstract">arXiv:2312.03749</a> [<a href="/pdf/2312.03749" title="Download PDF">pdf</a>, <a href="/format/2312.03749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conceptual Engineering Using Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Allen%2C+B+P">Bradley P. Allen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 1 figure, Extended Abstract accepted for presentation at the 5th Conference on Philosophy of Artificial Intelligence (PhiAI 2023), for associated code and data see <a href="https://github.com/bradleypallen/zero-shot-classifiers-for-conceptual-engineering">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">We describe a method, based on Jennifer Nado's definition of classification
procedures as targets of conceptual engineering, that implements such
procedures using a large language model. We then apply this method using data
from the Wikidata knowledge graph to evaluate concept definitions from two
paradigmatic conceptual engineering projects: the International Astronomical
Union's redefinition of PLANET and Haslanger's ameliorative analysis of WOMAN.
We discuss implications of this work for the theory and practice of conceptual
engineering. The code and data can be found on GitHub.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03750" title="Abstract">arXiv:2312.03750</a> [<a href="/pdf/2312.03750" title="Download PDF">pdf</a>, <a href="/ps/2312.03750" title="Download PostScript">ps</a>, <a href="/format/2312.03750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing the Influence of Fake News in the 2024 Elections: A  Comprehensive Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M">Mizanur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Raza%2C+S">Shaina Raza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This work introduces a dataset focused on fake news in US political speeches,
specifically examining racial slurs and biases. By scraping and annotating
40,000 news articles, using advanced NLP tools and human verification, we
provide a nuanced understanding of misinformation in political discourse. The
dataset, designed for machine learning and bias analysis, is a critical
resource for researchers, policymakers, and educators. It facilitates the
development of strategies against misinformation and enhances media literacy,
marking a significant contribution to the study of fake news and political
communication. Our dataset, focusing on the analysis of fake news in the
context of the 2024 elections, is publicly accessible for community to work on
fake news identification. Our dataset, focusing on the analysis of fake news in
the context of the 2024 elections, is publicly accessible.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03751" title="Abstract">arXiv:2312.03751</a> [<a href="/pdf/2312.03751" title="Download PDF">pdf</a>, <a href="/format/2312.03751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Which linguistic cues make people fall for fake news? A comparison of  cognitive and affective processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lutz%2C+B">Bernhard Lutz</a>, 
<a href="/search/cs?searchtype=author&query=Adam%2C+M">Marc Adam</a>, 
<a href="/search/cs?searchtype=author&query=Feuerriegel%2C+S">Stefan Feuerriegel</a>, 
<a href="/search/cs?searchtype=author&query=Pr%C3%B6llochs%2C+N">Nicolas Pr&#xf6;llochs</a>, 
<a href="/search/cs?searchtype=author&query=Neumann%2C+D">Dirk Neumann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Fake news on social media has large, negative implications for society.
However, little is known about what linguistic cues make people fall for fake
news and, hence, how to design effective countermeasures for social media. In
this study, we seek to understand which linguistic cues make people fall for
fake news. Linguistic cues (e.g., adverbs, personal pronouns, positive emotion
words, negative emotion words) are important characteristics of any text and
also affect how people process real vs. fake news. Specifically, we compare the
role of linguistic cues across both cognitive processing (related to careful
thinking) and affective processing (related to unconscious automatic
evaluations). To this end, we performed a within-subject experiment where we
collected neurophysiological measurements of 42 subjects while these read a
sample of 40 real and fake news articles. During our experiment, we measured
cognitive processing through eye fixations, and affective processing in situ
through heart rate variability. We find that users engage more in cognitive
processing for longer fake news articles, while affective processing is more
pronounced for fake news written in analytic words. To the best of our
knowledge, this is the first work studying the role of linguistic cues in fake
news processing. Altogether, our findings have important implications for
designing online platforms that encourage users to engage in careful thinking
and thus prevent them from falling for fake news.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03752" title="Abstract">arXiv:2312.03752</a> [<a href="/pdf/2312.03752" title="Download PDF">pdf</a>, <a href="/format/2312.03752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Scoring of Students&#x27; Science Writing Using Hybrid Neural  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Latif%2C+E">Ehsan Latif</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaoming Zhai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This study explores the efficacy of a multi-perspective hybrid neural network
(HNN) for scoring student responses in science education with an analytic
rubric. We compared the accuracy of the HNN model with four ML approaches
(BERT, AACR, Naive Bayes, and Logistic Regression). The results have shown that
HHN achieved 8%, 3%, 1%, and 0.12% higher accuracy than Naive Bayes, Logistic
Regression, AACR, and BERT, respectively, for five scoring aspects (p&lt;0.001).
The overall HNN's perceived accuracy (M = 96.23%, SD = 1.45%) is comparable to
the (training and inference) expensive BERT model's accuracy (M = 96.12%, SD =
1.52%). We also have observed that HNN is x2 more efficient in training and
inferencing than BERT and has comparable efficiency to the lightweight but less
accurate Naive Bayes model. Our study confirmed the accuracy and efficiency of
using HNN to score students' science writing automatically.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03753" title="Abstract">arXiv:2312.03753</a> [<a href="/pdf/2312.03753" title="Download PDF">pdf</a>, <a href="/ps/2312.03753" title="Download PostScript">ps</a>, <a href="/format/2312.03753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> English to Arabic machine translation of mathematical documents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eddahibi%2C+M">Mustapha Eddahibi</a>, 
<a href="/search/cs?searchtype=author&query=Mensouri%2C+M">Mohammed Mensouri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper is about the development of a machine translation system tailored
specifically for LATEX mathematical documents. The system focuses on
translating English LATEX mathematical documents into Arabic LATEX, catering to
the growing demand for multilingual accessibility in scientific and
mathematical literature. With the vast proliferation of LATEX mathematical
documents the need for an efficient and accurate translation system has become
increasingly essential. This paper addresses the necessity for a robust
translation tool that enables seamless communication and comprehension of
complex mathematical content across language barriers. The proposed system
leverages a Transformer model as the core of the translation system, ensuring
enhanced accuracy and fluency in the translated Arabic LATEX documents.
Furthermore, the integration of RyDArab, an Arabic mathematical TEX extension,
along with a rule-based translator for Arabic mathematical expressions,
contributes to the precise rendering of complex mathematical symbols and
equations in the translated output. The paper discusses the architecture,
methodology, of the developed system, highlighting its efficacy in bridging the
language gap in the domain of mathematical documentation
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03755" title="Abstract">arXiv:2312.03755</a> [<a href="/pdf/2312.03755" title="Download PDF">pdf</a>, <a href="/format/2312.03755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-real-time Earthquake-induced Fatality Estimation using Crowdsourced  Data and Large-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenguang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Engler%2C+D">Davis Engler</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuechun Li</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">James Hou</a>, 
<a href="/search/cs?searchtype=author&query=Wald%2C+D+J">David J. Wald</a>, 
<a href="/search/cs?searchtype=author&query=Jaiswal%2C+K">Kishor Jaiswal</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Susu Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">When a damaging earthquake occurs, immediate information about casualties is
critical for time-sensitive decision-making by emergency response and aid
agencies in the first hours and days. Systems such as Prompt Assessment of
Global Earthquakes for Response (PAGER) by the U.S. Geological Survey (USGS)
were developed to provide a forecast within about 30 minutes of any significant
earthquake globally. Traditional systems for estimating human loss in disasters
often depend on manually collected early casualty reports from global media, a
process that's labor-intensive and slow with notable time delays. Recently,
some systems have employed keyword matching and topic modeling to extract
relevant information from social media. However, these methods struggle with
the complex semantics in multilingual texts and the challenge of interpreting
ever-changing, often conflicting reports of death and injury numbers from
various unverified sources on social media platforms. In this work, we
introduce an end-to-end framework to significantly improve the timeliness and
accuracy of global earthquake-induced human loss forecasting using
multi-lingual, crowdsourced social media. Our framework integrates (1) a
hierarchical casualty extraction model built upon large language models, prompt
design, and few-shot learning to retrieve quantitative human loss claims from
social media, (2) a physical constraint-aware, dynamic-truth discovery model
that discovers the truthful human loss from massive noisy and potentially
conflicting human loss claims, and (3) a Bayesian updating loss projection
model that dynamically updates the final loss estimation using discovered
truths. We test the framework in real-time on a series of global earthquake
events in 2021 and 2022 and show that our framework streamlines casualty data
retrieval, achieving speed and accuracy comparable to manual methods by USGS.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03756" title="Abstract">arXiv:2312.03756</a> [<a href="/pdf/2312.03756" title="Download PDF">pdf</a>, <a href="/format/2312.03756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LineConGraphs: Line Conversation Graphs for Effective Emotion  Recognition using Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+G+S">Gokul S Krishnan</a>, 
<a href="/search/cs?searchtype=author&query=Padi%2C+S">Sarala Padi</a>, 
<a href="/search/cs?searchtype=author&query=Greenberg%2C+C+S">Craig S. Greenberg</a>, 
<a href="/search/cs?searchtype=author&query=Ravindran%2C+B">Balaraman Ravindran</a>, 
<a href="/search/cs?searchtype=author&query=Manoch%2C+D">Dinesh Manoch</a>, 
<a href="/search/cs?searchtype=author&query=Sriram%2C+R+D">Ram D.Sriram</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Emotion Recognition in Conversations (ERC) is a critical aspect of affective
computing, and it has many practical applications in healthcare, education,
chatbots, and social media platforms. Earlier approaches for ERC analysis
involved modeling both speaker and long-term contextual information using graph
neural network architectures. However, it is ideal to deploy
speaker-independent models for real-world applications. Additionally, long
context windows can potentially create confusion in recognizing the emotion of
an utterance in a conversation. To overcome these limitations, we propose novel
line conversation graph convolutional network (LineConGCN) and graph attention
(LineConGAT) models for ERC analysis. These models are speaker-independent and
built using a graph construction strategy for conversations -- line
conversation graphs (LineConGraphs). The conversational context in
LineConGraphs is short-term -- limited to one previous and future utterance,
and speaker information is not part of the graph. We evaluate the performance
of our proposed models on two benchmark datasets, IEMOCAP and MELD, and show
that our LineConGAT model outperforms the state-of-the-art methods with an
F1-score of 64.58% and 76.50%. Moreover, we demonstrate that embedding
sentiment shift information into line conversation graphs further enhances the
ERC performance in the case of GCN models.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03758" title="Abstract">arXiv:2312.03758</a> [<a href="/pdf/2312.03758" title="Download PDF">pdf</a>, <a href="/format/2312.03758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stock Movement and Volatility Prediction from Tweets, Macroeconomic  Factors and Historical Prices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shengkun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">YangXiao Bai</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+T">Taoran Ji</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+K">Kaiqun Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Linhan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chang-Tien Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Predicting stock market is vital for investors and policymakers, acting as a
barometer of the economic health. We leverage social media data, a potent
source of public sentiment, in tandem with macroeconomic indicators as
government-compiled statistics, to refine stock market predictions. However,
prior research using tweet data for stock market prediction faces three
challenges. First, the quality of tweets varies widely. While many are filled
with noise and irrelevant details, only a few genuinely mirror the actual
market scenario. Second, solely focusing on the historical data of a particular
stock without considering its sector can lead to oversight. Stocks within the
same industry often exhibit correlated price behaviors. Lastly, simply
forecasting the direction of price movement without assessing its magnitude is
of limited value, as the extent of the rise or fall truly determines
profitability. In this paper, diverging from the conventional methods, we
pioneer an ECON. The framework has following advantages: First, ECON has an
adept tweets filter that efficiently extracts and decodes the vast array of
tweet data. Second, ECON discerns multi-level relationships among stocks,
sectors, and macroeconomic factors through a self-aware mechanism in semantic
space. Third, ECON offers enhanced accuracy in predicting substantial stock
price fluctuations by capitalizing on stock price movement. We showcase the
state-of-the-art performance of our proposed model using a dataset,
specifically curated by us, for predicting stock market movements and
volatility.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03759" title="Abstract">arXiv:2312.03759</a> [<a href="/pdf/2312.03759" title="Download PDF">pdf</a>, <a href="/ps/2312.03759" title="Download PostScript">ps</a>, <a href="/format/2312.03759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How should the advent of large language models affect the practice of  science?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Binz%2C+M">Marcel Binz</a>, 
<a href="/search/cs?searchtype=author&query=Alaniz%2C+S">Stephan Alaniz</a>, 
<a href="/search/cs?searchtype=author&query=Roskies%2C+A">Adina Roskies</a>, 
<a href="/search/cs?searchtype=author&query=Aczel%2C+B">Balazs Aczel</a>, 
<a href="/search/cs?searchtype=author&query=Bergstrom%2C+C+T">Carl T. Bergstrom</a>, 
<a href="/search/cs?searchtype=author&query=Allen%2C+C">Colin Allen</a>, 
<a href="/search/cs?searchtype=author&query=Schad%2C+D">Daniel Schad</a>, 
<a href="/search/cs?searchtype=author&query=Wulff%2C+D">Dirk Wulff</a>, 
<a href="/search/cs?searchtype=author&query=West%2C+J+D">Jevin D. West</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shiffrin%2C+R+M">Richard M. Shiffrin</a>, 
<a href="/search/cs?searchtype=author&query=Gershman%2C+S+J">Samuel J. Gershman</a>, 
<a href="/search/cs?searchtype=author&query=Popov%2C+V">Ven Popov</a>, 
<a href="/search/cs?searchtype=author&query=Bender%2C+E+M">Emily M. Bender</a>, 
<a href="/search/cs?searchtype=author&query=Marelli%2C+M">Marco Marelli</a>, 
<a href="/search/cs?searchtype=author&query=Botvinick%2C+M+M">Matthew M. Botvinick</a>, 
<a href="/search/cs?searchtype=author&query=Akata%2C+Z">Zeynep Akata</a>, 
<a href="/search/cs?searchtype=author&query=Schulz%2C+E">Eric Schulz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Digital Libraries (cs.DL)

</div>
<p class="mathjax">Large language models (LLMs) are being increasingly incorporated into
scientific workflows. However, we have yet to fully grasp the implications of
this integration. How should the advent of large language models affect the
practice of science? For this opinion piece, we have invited four diverse
groups of scientists to reflect on this query, sharing their perspectives and
engaging in debate. Schulz et al. make the argument that working with LLMs is
not fundamentally different from working with human collaborators, while Bender
et al. argue that LLMs are often misused and over-hyped, and that their
limitations warrant a focus on more specialized, easily interpretable tools.
Marelli et al. emphasize the importance of transparent attribution and
responsible use of LLMs. Finally, Botvinick and Gershman advocate that humans
should retain responsibility for determining the scientific roadmap. To
facilitate the discussion, the four perspectives are complemented with a
response from each group. By putting these different perspectives in
conversation, we aim to bring attention to important considerations within the
academic community regarding the adoption of LLMs and their impact on both
current and future scientific practices.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03762" title="Abstract">arXiv:2312.03762</a> [<a href="/pdf/2312.03762" title="Download PDF">pdf</a>, <a href="/format/2312.03762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Colour versus Shape Goal Misgeneralization in Reinforcement Learning: A  Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramanauskas%2C+K">Karolis Ramanauskas</a>, 
<a href="/search/cs?searchtype=author&query=%C5%9Eim%C5%9Fek%2C+%C3%96">&#xd6;zg&#xfc;r &#x15e;im&#x15f;ek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ATTRIB: Workshop on Attributing Model Behavior at Scale at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We explore colour versus shape goal misgeneralization originally demonstrated
by Di Langosco et al. (2022) in the Procgen Maze environment, where, given an
ambiguous choice, the agents seem to prefer generalization based on colour
rather than shape. After training over 1,000 agents in a simplified version of
the environment and evaluating them on over 10 million episodes, we conclude
that the behaviour can be attributed to the agents learning to detect the goal
object through a specific colour channel. This choice is arbitrary.
Additionally, we show how, due to underspecification, the preferences can
change when retraining the agents using exactly the same procedure except for
using a different random seed for the training run. Finally, we demonstrate the
existence of outliers in out-of-distribution behaviour based on training random
seed alone.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03763" title="Abstract">arXiv:2312.03763</a> [<a href="/pdf/2312.03763" title="Download PDF">pdf</a>, <a href="/format/2312.03763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian3Diff: 3D Gaussian Diffusion for 3D Full Head Synthesis and  Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yushi Lan</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+F">Feitong Tan</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+D">Di Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qiangeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Genova%2C+K">Kyle Genova</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zeng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Fanello%2C+S">Sean Fanello</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+R">Rohit Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Funkhouser%2C+T">Thomas Funkhouser</a>, 
<a href="/search/cs?searchtype=author&query=Loy%2C+C+C">Chen Change Loy</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yinda Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a novel framework for generating photorealistic 3D human head and
subsequently manipulating and reposing them with remarkable flexibility. The
proposed approach leverages an implicit function representation of 3D human
heads, employing 3D Gaussians anchored on a parametric face model. To enhance
representational capabilities and encode spatial information, we embed a
lightweight tri-plane payload within each Gaussian rather than directly storing
color and opacity. Additionally, we parameterize the Gaussians in a 2D UV space
via a 3DMM, enabling effective utilization of the diffusion model for 3D head
avatar generation. Our method facilitates the creation of diverse and realistic
3D human heads with fine-grained editing over facial features and expressions.
Extensive experiments demonstrate the effectiveness of our method.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03764" title="Abstract">arXiv:2312.03764</a> [<a href="/pdf/2312.03764" title="Download PDF">pdf</a>, <a href="/format/2312.03764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Similarity-based Knowledge Transfer for Cross-Domain Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Serrano%2C+S+A">Sergio A. Serrano</a>, 
<a href="/search/cs?searchtype=author&query=Martinez-Carranza%2C+J">Jose Martinez-Carranza</a>, 
<a href="/search/cs?searchtype=author&query=Sucar%2C+L+E">L. Enrique Sucar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Transferring knowledge in cross-domain reinforcement learning is a
challenging setting in which learning is accelerated by reusing knowledge from
a task with different observation and/or action space. However, it is often
necessary to carefully select the source of knowledge for the receiving end to
benefit from the transfer process. In this article, we study how to measure the
similarity between cross-domain reinforcement learning tasks to select a source
of knowledge that will improve the performance of the learning agent. We
developed a semi-supervised alignment loss to match different spaces with a set
of encoder-decoders, and use them to measure similarity and transfer policies
across tasks. In comparison to prior works, our method does not require data to
be aligned, paired or collected by expert policies. Experimental results, on a
set of varied Mujoco control tasks, show the robustness of our method in
effectively selecting and transferring knowledge, without the supervision of a
tailored set of source tasks.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03766" title="Abstract">arXiv:2312.03766</a> [<a href="/pdf/2312.03766" title="Download PDF">pdf</a>, <a href="/format/2312.03766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mismatch Quest: Visual and Textual Feedback for Image-Text Misalignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gordon%2C+B">Brian Gordon</a>, 
<a href="/search/cs?searchtype=author&query=Bitton%2C+Y">Yonatan Bitton</a>, 
<a href="/search/cs?searchtype=author&query=Shafir%2C+Y">Yonatan Shafir</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+R">Roopal Garg</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lischinski%2C+D">Dani Lischinski</a>, 
<a href="/search/cs?searchtype=author&query=Cohen-Or%2C+D">Daniel Cohen-Or</a>, 
<a href="/search/cs?searchtype=author&query=Szpektor%2C+I">Idan Szpektor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">While existing image-text alignment models reach high quality binary
assessments, they fall short of pinpointing the exact source of misalignment.
In this paper, we present a method to provide detailed textual and visual
explanation of detected misalignments between text-image pairs. We leverage
large language models and visual grounding models to automatically construct a
training set that holds plausible misaligned captions for a given image and
corresponding textual explanations and visual indicators. We also publish a new
human curated test set comprising ground-truth textual and visual misalignment
annotations. Empirical results show that fine-tuning vision language models on
our training set enables them to articulate misalignments and visually indicate
them within images, outperforming strong baselines both on the binary alignment
classification and the explanation generation tasks. Our method code and human
curated test set are available at: https://mismatch-quest.github.io/
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03767" title="Abstract">arXiv:2312.03767</a> [<a href="/pdf/2312.03767" title="Download PDF">pdf</a>, <a href="/format/2312.03767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unknown Sample Discovery for Source Free Open Set Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jahan%2C+C+S">Chowdhury Sadman Jahan</a>, 
<a href="/search/cs?searchtype=author&query=Savakis%2C+A">Andreas Savakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Open Set Domain Adaptation (OSDA) aims to adapt a model trained on a source
domain to a target domain that undergoes distribution shift and contains
samples from novel classes outside the source domain. Source-free OSDA
(SF-OSDA) techniques eliminate the need to access source domain samples, but
current SF-OSDA methods utilize only the known classes in the target domain for
adaptation, and require access to the entire target domain even during
inference after adaptation, to make the distinction between known and unknown
samples. In this paper, we introduce Unknown Sample Discovery (USD) as an
SF-OSDA method that utilizes a temporally ensembled teacher model to conduct
known-unknown target sample separation and adapts the student model to the
target domain over all classes using co-training and temporal consistency
between the teacher and the student. USD promotes Jensen-Shannon distance (JSD)
as an effective measure for known-unknown sample separation. Our
teacher-student framework significantly reduces error accumulation resulting
from imperfect known-unknown sample separation, while curriculum guidance helps
to reliably learn the distinction between target known and target unknown
subspaces. USD appends the target model with an unknown class node, thus
readily classifying a target sample into any of the known or unknown classes in
subsequent post-adaptation inference stages. Empirical results show that USD is
superior to existing SF-OSDA methods and is competitive with current OSDA
models that utilize both source and target domains during adaptation.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03769" title="Abstract">arXiv:2312.03769</a> [<a href="/pdf/2312.03769" title="Download PDF">pdf</a>, <a href="/format/2312.03769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT vs Human for Scientific Reviews: A Dual Source Review on  Applications of ChatGPT in Science
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenxi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Varghese%2C+A+J">Alan John Varghese</a>, 
<a href="/search/cs?searchtype=author&query=Oommen%2C+V">Vivek Oommen</a>, 
<a href="/search/cs?searchtype=author&query=Karniadakis%2C+G+E">George Em Karniadakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The new polymath Large Language Models (LLMs) can speed-up greatly scientific
reviews, possibly using more unbiased quantitative metrics, facilitating
cross-disciplinary connections, and identifying emerging trends and research
gaps by analyzing large volumes of data. However, at the present time, they
lack the required deep understanding of complex methodologies, they have
difficulty in evaluating innovative claims, and they are unable to assess
ethical issues and conflicts of interest. Herein, we consider 13 GPT-related
papers across different scientific domains, reviewed by a human reviewer and
SciSpace, a large language model, with the reviews evaluated by three distinct
types of evaluators, namely GPT-3.5, a crowd panel, and GPT-4. We found that
50% of SciSpace's responses to objective questions align with those of a human
reviewer, with GPT-4 (informed evaluator) often rating the human reviewer
higher in accuracy, and SciSpace higher in structure, clarity, and
completeness. In subjective questions, the uninformed evaluators (GPT-3.5 and
crowd panel) showed varying preferences between SciSpace and human responses,
with the crowd panel showing a preference for the human responses. However,
GPT-4 rated them equally in accuracy and structure but favored SciSpace for
completeness.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03771" title="Abstract">arXiv:2312.03771</a> [<a href="/pdf/2312.03771" title="Download PDF">pdf</a>, <a href="/format/2312.03771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreamInpainter: Text-Guided Subject-Driven Image Inpainting with  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shaoan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zhisheng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+K+C+K">Kelvin C.K. Chan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yandong Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yanwu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+T">Tingbo Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This study introduces Text-Guided Subject-Driven Image Inpainting, a novel
task that combines text and exemplar images for image inpainting. While both
text and exemplar images have been used independently in previous efforts,
their combined utilization remains unexplored. Simultaneously accommodating
both conditions poses a significant challenge due to the inherent balance
required between editability and subject fidelity. To tackle this challenge, we
propose a two-step approach DreamInpainter. First, we compute dense subject
features to ensure accurate subject replication. Then, we employ a
discriminative token selection module to eliminate redundant subject details,
preserving the subject's identity while allowing changes according to other
conditions such as mask shape and text prompts. Additionally, we introduce a
decoupling regularization technique to enhance text control in the presence of
exemplar images. Our extensive experiments demonstrate the superior performance
of our method in terms of visual quality, identity preservation, and text
control, showcasing its effectiveness in the context of text-guided
subject-driven image inpainting.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03772" title="Abstract">arXiv:2312.03772</a> [<a href="/pdf/2312.03772" title="Download PDF">pdf</a>, <a href="/format/2312.03772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffusionAtlas: High-Fidelity Consistent Diffusion Video Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+S">Shao-Yu Chang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hwann-Tzong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tyng-Luh Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a diffusion-based video editing framework, namely DiffusionAtlas,
which can achieve both frame consistency and high fidelity in editing video
object appearance. Despite the success in image editing, diffusion models still
encounter significant hindrances when it comes to video editing due to the
challenge of maintaining spatiotemporal consistency in the object's appearance
across frames. On the other hand, atlas-based techniques allow propagating
edits on the layered representations consistently back to frames. However, they
often struggle to create editing effects that adhere correctly to the
user-provided textual or visual conditions due to the limitation of editing the
texture atlas on a fixed UV mapping field. Our method leverages a
visual-textual diffusion model to edit objects directly on the diffusion
atlases, ensuring coherent object identity across frames. We design a loss term
with atlas-based constraints and build a pretrained text-driven diffusion model
as pixel-wise guidance for refining shape distortions and correcting texture
deviations. Qualitative and quantitative experiments show that our method
outperforms state-of-the-art methods in achieving consistent high-fidelity
video-object editing.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03774" title="Abstract">arXiv:2312.03774</a> [<a href="/pdf/2312.03774" title="Download PDF">pdf</a>, <a href="/format/2312.03774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OctreeOcc: Efficient and Multi-Granularity Occupancy Prediction Using  Octree Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yuhang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xinge Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yuexin Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Occupancy prediction has increasingly garnered attention in recent years for
its fine-grained understanding of 3D scenes. Traditional approaches typically
rely on dense, regular grid representations, which often leads to excessive
computational demands and a loss of spatial details for small objects. This
paper introduces OctreeOcc, an innovative 3D occupancy prediction framework
that leverages the octree representation to adaptively capture valuable
information in 3D, offering variable granularity to accommodate object shapes
and semantic regions of varying sizes and complexities. In particular, we
incorporate image semantic information to improve the accuracy of initial
octree structures and design an effective rectification mechanism to refine the
octree structure iteratively. Our extensive evaluations show that OctreeOcc not
only surpasses state-of-the-art methods in occupancy prediction, but also
achieves a 15%-24% reduction in computational overhead compared to
dense-grid-based methods.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03775" title="Abstract">arXiv:2312.03775</a> [<a href="/pdf/2312.03775" title="Download PDF">pdf</a>, <a href="/format/2312.03775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FAAC: Facial Animation Generation with Anchor Frame and Conditional  Control for Superior Fidelity and Editability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linze Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Sunqi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+H">Hengjun Pu</a>, 
<a href="/search/cs?searchtype=author&query=Bing%2C+Z">Zhaodong Bing</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+T">Tianzhu Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liangyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jiajun Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Over recent years, diffusion models have facilitated significant advancements
in video generation. Yet, the creation of face-related videos still confronts
issues such as low facial fidelity, lack of frame consistency, limited
editability and uncontrollable human poses. To address these challenges, we
introduce a facial animation generation method that enhances both face identity
fidelity and editing capabilities while ensuring frame consistency. This
approach incorporates the concept of an anchor frame to counteract the
degradation of generative ability in original text-to-image models when
incorporating a motion module. We propose two strategies towards this
objective: training-free and training-based anchor frame methods. Our method's
efficacy has been validated on multiple representative DreamBooth and LoRA
models, delivering substantial improvements over the original outcomes in terms
of facial fidelity, text-to-image editability, and video motion. Moreover, we
introduce conditional control using a 3D parametric face model to capture
accurate facial movements and expressions. This solution augments the creative
possibilities for facial animation generation through the integration of
multiple control signals. For additional samples, please visit
https://anonymous.4open.science/r/FAAC.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03776" title="Abstract">arXiv:2312.03776</a> [<a href="/pdf/2312.03776" title="Download PDF">pdf</a>, <a href="/format/2312.03776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tri-Level Model for Hybrid Renewable Energy Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hosseini%2C+E">Eghbal Hosseini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In practical scenarios, addressing real-world challenges often entails the
incorporation of diverse renewable energy sources, such as solar, energy
storage systems, and greenhouse gas emissions. The core purpose of these
interconnected systems is to optimize a multitude of factors and objectives
concurrently. Hence, it is imperative to formulate models that comprehensively
cover all these objectives. This paper introduces tri-level mathematical models
for Hybrid Renewable Energy Systems (HRESs), offering a framework to
concurrently tackle diverse objectives and decision-making levels within the
realm of renewable energy integration. The proposed model seeks to maximize the
efficiency of solar PV, enhance the performance of energy storage systems, and
minimize greenhouse gas emissions.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03777" title="Abstract">arXiv:2312.03777</a> [<a href="/pdf/2312.03777" title="Download PDF">pdf</a>, <a href="/format/2312.03777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Robustness of Large Multimodal Models Against Image Adversarial  Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+X">Xuanimng Cui</a>, 
<a href="/search/cs?searchtype=author&query=Aparcedo%2C+A">Alejandro Aparcedo</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+Y+K">Young Kyun Jang</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Ser-Nam Lim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advances in instruction tuning have led to the development of
State-of-the-Art Large Multimodal Models (LMMs). Given the novelty of these
models, the impact of visual adversarial attacks on LMMs has not been
thoroughly examined. We conduct a comprehensive study of the robustness of
various LMMs against different adversarial attacks, evaluated across tasks
including image classification, image captioning, and Visual Question Answer
(VQA). We find that in general LMMs are not robust to visual adversarial
inputs. However, our findings suggest that context provided to the model via
prompts, such as questions in a QA pair helps to mitigate the effects of visual
adversarial inputs. Notably, the LMMs evaluated demonstrated remarkable
resilience to such attacks on the ScienceQA task with only an 8.10% drop in
performance compared to their visual counterparts which dropped 99.73%. We also
propose a new approach to real-world image classification which we term query
decomposition. By incorporating existence queries into our input prompt we
observe diminished attack effectiveness and improvements in image
classification accuracy. This research highlights a previously under-explored
facet of LMM robustness and sets the stage for future work aimed at
strengthening the resilience of multimodal systems in adversarial environments.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03779" title="Abstract">arXiv:2312.03779</a> [<a href="/pdf/2312.03779" title="Download PDF">pdf</a>, <a href="/ps/2312.03779" title="Download PostScript">ps</a>, <a href="/format/2312.03779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Public emotional dynamics toward AIGC content generation across social  media platform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Q">Qinglan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiayi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Given the widespread popularity of interactive AI models like ChatGPT, public
opinion on emerging artificial intelligence generated content(AIGC) has been
extensively debated. Pessimists believe that AIGC will replace humans in the
future, and optimists think that it will further liberate productivity. Public
emotions play a crucial role on social media platforms. They can provide
valuable insights into the public's opinions, attitudes, and behaviors. There
is a lack of research on the analysis of social group emotions triggered by
AIGC content, and even more on the cross-platform differences of group
emotions. This study fills the research gap by connecting the theory of group
dynamics with emotions in social media. Specifically, we develop a scientific
group emotion calculation and visualization system based on chains of
communication. The system is capable of crawling data in real time and
presenting the current state of group emotions in a fine-grained manner. We
then analyze which group dynamic factors drive different public emotions
towards nine AIGC products on the three most popular social media platforms in
China. Finally, we obtain four main findings. First, Douyin is the only
platform with negative group emotion on emerging AI technologies. Second, Weibo
users prefer extreme emotions more than others. Third, the group emotion varies
by education and age. It is negatively correlated with senior high school or
lower and 25 or younger, and positively correlated with bachelor's degree or
higher and 26-35. Fourth, the group emotion polarization increases with more
posts without comments and celebrity publishers. By analyzing the key dynamic
factors of group emotions to AIGC on various social media platforms, we can
improve our products and services, develop more effective marketing strategies,
and create more accurate and effective AI models to solve complex problems.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03780" title="Abstract">arXiv:2312.03780</a> [<a href="/pdf/2312.03780" title="Download PDF">pdf</a>, <a href="/ps/2312.03780" title="Download PostScript">ps</a>, <a href="/format/2312.03780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting the Transportation Activities of Construction Waste Hauling  Trucks: An Input-Output Hidden Markov Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongtai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+B">Boyi Lei</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Ke Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Luna Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Construction waste hauling trucks (CWHTs), as one of the most commonly seen
heavy-duty vehicles in major cities around the globe, are usually subject to a
series of regulations and spatial-temporal access restrictions because they not
only produce significant NOx and PM emissions but also causes on-road fugitive
dust. The timely and accurate prediction of CWHTs' destinations and dwell times
play a key role in effective environmental management. To address this
challenge, we propose a prediction method based on an interpretable
activity-based model, input-output hidden Markov model (IOHMM), and validate it
on 300 CWHTs in Chengdu, China. Contextual factors are considered in the model
to improve its prediction power. Results show that the IOHMM outperforms
several baseline models, including Markov chains, linear regression, and long
short-term memory. Factors influencing the predictability of CWHTs'
transportation activities are also explored using linear regression models.
Results suggest the proposed model holds promise in assisting authorities by
predicting the upcoming transportation activities of CWHTs and administering
intervention in a timely and effective manner.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03781" title="Abstract">arXiv:2312.03781</a> [<a href="/pdf/2312.03781" title="Download PDF">pdf</a>, <a href="/format/2312.03781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lite-Mind: Towards Efficient and Versatile Brain Representation Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+Z">Zixuan Gong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+D">Duoqian Miao</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+G">Guangyin Bao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Liang Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Research in decoding visual information from the brain, particularly through
the non-invasive fMRI method, is rapidly progressing. The challenge arises from
the limited data availability and the low signal-to-noise ratio of fMRI
signals, leading to a low-precision task of fMRI-to-image retrieval.
State-of-the-art MindEye remarkably improves fMRI-to-image retrieval
performance by leveraging a deep MLP with a high parameter count orders of
magnitude, i.e., a 996M MLP Backbone per subject, to align fMRI embeddings to
the final hidden layer of CLIP's vision transformer. However, significant
individual variations exist among subjects, even within identical experimental
setups, mandating the training of subject-specific models. The substantial
parameters pose significant challenges in deploying fMRI decoding on practical
devices, especially with the necessitating of specific models for each subject.
To this end, we propose Lite-Mind, a lightweight, efficient, and versatile
brain representation network based on discrete Fourier transform, that
efficiently aligns fMRI voxels to fine-grained information of CLIP. Our
experiments demonstrate that Lite-Mind achieves an impressive 94.3%
fMRI-to-image retrieval accuracy on the NSD dataset for Subject 1, with 98.7%
fewer parameters than MindEye. Lite-Mind is also proven to be able to be
migrated to smaller brain datasets and establishes a new state-of-the-art for
zero-shot classification on the GOD dataset. The code is available at
https://github.com/gongzix/Lite-Mind.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03782" title="Abstract">arXiv:2312.03782</a> [<a href="/pdf/2312.03782" title="Download PDF">pdf</a>, <a href="/format/2312.03782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Novel class discovery meets foundation models for 3D semantic  segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Riz%2C+L">Luigi Riz</a>, 
<a href="/search/cs?searchtype=author&query=Saltori%2C+C">Cristiano Saltori</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ricci%2C+E">Elisa Ricci</a>, 
<a href="/search/cs?searchtype=author&query=Poiesi%2C+F">Fabio Poiesi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2303.11610">arXiv:2303.11610</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The task of Novel Class Discovery (NCD) in semantic segmentation entails
training a model able to accurately segment unlabelled (novel) classes, relying
on the available supervision from annotated (base) classes. Although
extensively investigated in 2D image data, the extension of the NCD task to the
domain of 3D point clouds represents a pioneering effort, characterized by
assumptions and challenges that are not present in the 2D case. This paper
represents an advancement in the analysis of point cloud data in four
directions. Firstly, it introduces the novel task of NCD for point cloud
semantic segmentation. Secondly, it demonstrates that directly transposing the
only existing NCD method for 2D image semantic segmentation to 3D data yields
suboptimal results. Thirdly, a new NCD approach based on online clustering,
uncertainty estimation, and semantic distillation is presented. Lastly, a novel
evaluation protocol is proposed to rigorously assess the performance of NCD in
point cloud semantic segmentation. Through comprehensive evaluations on the
SemanticKITTI, SemanticPOSS, and S3DIS datasets, the paper demonstrates
substantial superiority of the proposed method over the considered baselines.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03784" title="Abstract">arXiv:2312.03784</a> [<a href="/pdf/2312.03784" title="Download PDF">pdf</a>, <a href="/format/2312.03784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computation of the optimal error exponent function for fixed-length  lossy source coding in discrete memoryless sources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jitsumatsu%2C+Y">Yutaka Jitsumatsu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages in single column double space format, 8 figures. arXiv admin note: substantial text overlap with <a href="/abs/2304.11558">arXiv:2304.11558</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The error exponent of fixed-length lossy source coding was established by
Marton. Ahlswede showed that this exponent can be discontinuous at a rate $R$,
depending on the source distribution $P$ and the distortion measure $d(x,y)$.
The reason for the discontinuity in the error exponent is that there exists a
distortion measure $d(x,y)$ and a distortion level $\Delta$ such that the
rate-distortion function $R(\Delta|P)$ is neither concave nor quasi-concave
with respect to $P$. Arimoto's algorithm for computing the error exponent in
lossy source coding is based on Blahut's parametric representation of the error
exponent. However, Blahut's parametric representation is a lower convex
envelope of Marton's exponent, and the two do not generally agree. A major
contribution of this paper is to provide a parametric representation that
perfectly matches the inverse function of Marton's exponent, thereby preventing
the problems arising from the above-mentioned non-concavity of $R(\Delta|P)$.
For fixed parameters, an optimal distribution can be obtained using Arimoto's
algorithm. By performing a nonconvex optimization over the parameters, the
inverse function of Marton's exponent is obtained.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03785" title="Abstract">arXiv:2312.03785</a> [<a href="/pdf/2312.03785" title="Download PDF">pdf</a>, <a href="/ps/2312.03785" title="Download PostScript">ps</a>, <a href="/format/2312.03785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sports Recommender Systems: Overview and Research Issues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Felfernig%2C+A">Alexander Felfernig</a>, 
<a href="/search/cs?searchtype=author&query=Wundara%2C+M">Manfred Wundara</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+T+N+T">Thi Ngoc Trang Tran</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+V">Viet-Man Le</a>, 
<a href="/search/cs?searchtype=author&query=Lubos%2C+S">Sebastian Lubos</a>, 
<a href="/search/cs?searchtype=author&query=Polat-Erdeniz%2C+S">Seda Polat-Erdeniz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Article under review in the Journal of Intelligent Information Systems (Springer JIIS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Sports recommender systems receive an increasing attention due to their
potential of fostering healthy living, improving personal well-being, and
increasing performances in sport. These systems support people in sports, for
example, by the recommendation of healthy and performance boosting food items,
the recommendation of training practices, talent and team recommendation, and
the recommendation of specific tactics in competitions. With applications in
the virtual world, for example, the recommendation of maps or opponents in
e-sports, these systems already transcend conventional sports scenarios where
physical presence is needed. On the basis of different working examples, we
present an overview of sports recommender systems applications and techniques.
Overall, we analyze the related state-of-the-art and discuss open research
issues.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03787" title="Abstract">arXiv:2312.03787</a> [<a href="/pdf/2312.03787" title="Download PDF">pdf</a>, <a href="/format/2312.03787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detection and Mitigation of Position Spoofing Attacks on Cooperative UAV  Swarm Formations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bi%2C+S">Siguo Bi</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+K">Kai Li</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+S">Shuyan Hu</a>, 
<a href="/search/eess?searchtype=author&query=Ni%2C+W">Wei Ni</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Cong Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by IEEE TIFS in Dec. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Detecting spoofing attacks on the positions of unmanned aerial vehicles
(UAVs) within a swarm is challenging. Traditional methods relying solely on
individually reported positions and pairwise distance measurements are
ineffective in identifying the misbehavior of malicious UAVs. This paper
presents a novel systematic structure designed to detect and mitigate spoofing
attacks in UAV swarms. We formulate the problem of detecting malicious UAVs as
a localization feasibility problem, leveraging the reported positions and
distance measurements. To address this problem, we develop a semidefinite
relaxation (SDR) approach, which reformulates the non-convex localization
problem into a convex and tractable semidefinite program (SDP). Additionally,
we propose two innovative algorithms that leverage the proximity of neighboring
UAVs to identify malicious UAVs effectively. Simulations demonstrate the
superior performance of our proposed approaches compared to existing
benchmarks. Our methods exhibit robustness across various swarm networks,
showcasing their effectiveness in detecting and mitigating spoofing attacks.
{\blue Specifically, the detection success rate is improved by up to 65\%,
55\%, and 51\% against distributed, collusion, and mixed attacks, respectively,
compared to the benchmarks.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03788" title="Abstract">arXiv:2312.03788</a> [<a href="/pdf/2312.03788" title="Download PDF">pdf</a>, <a href="/format/2312.03788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SmoothQuant+: Accurate and Efficient 4-bit Post-Training  WeightQuantization for LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jiayi Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengcan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+K">Kaifu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yangguang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhenyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+B">Bin Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models (LLMs) have shown remarkable capabilities in various
tasks. However their huge model size and the consequent demand for
computational and memory resources also pose challenges to model deployment.
Currently, 4-bit post-training quantization (PTQ) has achieved some success in
LLMs, reducing the memory footprint by approximately 75% compared to FP16
models, albeit with some accuracy loss. In this paper, we propose SmoothQuant+,
an accurate and efficient 4-bit weight-only PTQ that requires no additional
training, which enables lossless in accuracy for LLMs for the first time. Based
on the fact that the loss of weight quantization is amplified by the activation
outliers, SmoothQuant+ smoothes the activation outliers by channel before
quantization, while adjusting the corresponding weights for mathematical
equivalence, and then performs group-wise 4-bit weight quantization for linear
layers. We have integrated SmoothQuant+ into the vLLM framework, an advanced
high-throughput inference engine specially developed for LLMs, and equipped it
with an efficient W4A16 CUDA kernels, so that vLLM can seamlessly support
SmoothQuant+ 4-bit weight quantization. Our results show that, with
SmoothQuant+, the Code Llama-34B model can be quantized and deployed on a A100
40GB GPU, achieving lossless accuracy and a throughput increase of 1.9 to 4.0
times compared to the FP16 model deployed on two A100 40GB GPUs. Moreover, the
latency per token is only 68% of the FP16 model deployed on two A100 40GB GPUs.
This is the state-of-the-art 4-bit weight quantization for LLMs as we know.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03789" title="Abstract">arXiv:2312.03789</a> [<a href="/pdf/2312.03789" title="Download PDF">pdf</a>, <a href="/ps/2312.03789" title="Download PostScript">ps</a>, <a href="/format/2312.03789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Analysis of Multilingual Text Classification &amp;  Identification through Deep Learning and Embedding Visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wyawhare%2C+A">Arinjay Wyawhare</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 Pages, 10 Figures, 1 Table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This research conducts a comparative study on multilingual text
classification methods, utilizing deep learning and embedding visualization.
The study employs LangDetect, LangId, FastText, and Sentence Transformer on a
dataset encompassing 17 languages. It explores dimensionality's impact on
clustering, revealing FastText's clearer clustering in 2D visualization due to
its extensive multilingual corpus training. Notably, the FastText multi-layer
perceptron model achieved remarkable accuracy, precision, recall, and F1 score,
outperforming the Sentence Transformer model. The study underscores the
effectiveness of these techniques in multilingual text classification,
emphasizing the importance of large multilingual corpora for training
embeddings. It lays the groundwork for future research and assists
practitioners in developing language detection and classification systems.
Additionally, it includes the comparison of multi-layer perceptron, LSTM, and
Convolution models for classification.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03790" title="Abstract">arXiv:2312.03790</a> [<a href="/pdf/2312.03790" title="Download PDF">pdf</a>, <a href="/format/2312.03790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory-Efficient Optical Flow via Radius-Distribution Orthogonal Cost  Volume
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Gangwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shujun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+H">Hao Jia</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+M">Miaojie Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xin Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The full 4D cost volume in Recurrent All-Pairs Field Transforms (RAFT) or
global matching by Transformer achieves impressive performance for optical flow
estimation. However, their memory consumption increases quadratically with
input resolution, rendering them impractical for high-resolution images. In
this paper, we present MeFlow, a novel memory-efficient method for
high-resolution optical flow estimation. The key of MeFlow is a recurrent local
orthogonal cost volume representation, which decomposes the 2D search space
dynamically into two 1D orthogonal spaces, enabling our method to scale
effectively to very high-resolution inputs. To preserve essential information
in the orthogonal space, we utilize self attention to propagate feature
information from the 2D space to the orthogonal space. We further propose a
radius-distribution multi-scale lookup strategy to model the correspondences of
large displacements at a negligible cost. We verify the efficiency and
effectiveness of our method on the challenging Sintel and KITTI benchmarks, and
real-world 4K ($2160\!\times\!3840$) images. Our method achieves competitive
performance on both Sintel and KITTI benchmarks, while maintaining the highest
memory efficiency on high-resolution inputs.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03792" title="Abstract">arXiv:2312.03792</a> [<a href="/pdf/2312.03792" title="Download PDF">pdf</a>, <a href="/format/2312.03792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PCDP-SGD: Improving the Convergence of Differentially Private SGD via  Projection in Advance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sha%2C+H">Haichao Sha</a> (1), 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruixuan Liu</a> (1), 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yixuan Liu</a> (1), 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hong Chen</a> (1) ((1) Renmin University of China)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The paradigm of Differentially Private SGD~(DP-SGD) can provide a theoretical
guarantee for training data in both centralized and federated settings.
However, the utility degradation caused by DP-SGD limits its wide application
in high-stakes tasks, such as medical image diagnosis. In addition to the
necessary perturbation, the convergence issue is attributed to the information
loss on the gradient clipping. In this work, we propose a general framework
PCDP-SGD, which aims to compress redundant gradient norms and preserve more
crucial top gradient components via projection operation before gradient
clipping. Additionally, we extend PCDP-SGD as a fundamental component in
differential privacy federated learning~(DPFL) for mitigating the data
heterogeneous challenge and achieving efficient communication. We prove that
pre-projection enhances the convergence of DP-SGD by reducing the dependence of
clipping error and bias to a fraction of the top gradient eigenspace, and in
theory, limits cross-client variance to improve the convergence under
heterogeneous federation. Experimental results demonstrate that PCDP-SGD
achieves higher accuracy compared with state-of-the-art DP-SGD variants in
computer vision tasks. Moreover, PCDP-SGD outperforms current federated
learning frameworks when DP is guaranteed on local training sets.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03793" title="Abstract">arXiv:2312.03793</a> [<a href="/pdf/2312.03793" title="Download PDF">pdf</a>, <a href="/format/2312.03793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnimateZero: Video Diffusion Models are Zero-Shot Image Animators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiwen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Cun%2C+X">Xiaodong Cun</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+C">Chenyang Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xintao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://vvictoryuki.github.io/animatezero.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large-scale text-to-video (T2V) diffusion models have great progress in
recent years in terms of visual quality, motion and temporal consistency.
However, the generation process is still a black box, where all attributes
(e.g., appearance, motion) are learned and generated jointly without precise
control ability other than rough text descriptions. Inspired by image animation
which decouples the video as one specific appearance with the corresponding
motion, we propose AnimateZero to unveil the pre-trained text-to-video
diffusion model, i.e., AnimateDiff, and provide more precise appearance and
motion control abilities for it. For appearance control, we borrow intermediate
latents and their features from the text-to-image (T2I) generation for ensuring
the generated first frame is equal to the given generated image. For temporal
control, we replace the global temporal attention of the original T2V model
with our proposed positional-corrected window attention to ensure other frames
align with the first frame well. Empowered by the proposed methods, AnimateZero
can successfully control the generating progress without further training. As a
zero-shot image animator for given images, AnimateZero also enables multiple
new applications, including interactive video generation and real image
animation. The detailed experiments demonstrate the effectiveness of the
proposed method in both T2V and related applications.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03795" title="Abstract">arXiv:2312.03795</a> [<a href="/pdf/2312.03795" title="Download PDF">pdf</a>, <a href="/format/2312.03795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnimatableDreamer: Text-Guided Non-rigid 3D Model Generation and  Reconstruction with Canonical Score Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinzhou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yikai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Junliang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhengyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Fuchun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Pengkun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Ling Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+K">Kai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xintong Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bin He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://animatabledreamer.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-to-3D model adaptations have advanced static 3D model quality, but
sequential 3D model generation, particularly for animatable objects with large
motions, is still scarce. Our work proposes AnimatableDreamer, a text-to-4D
generation framework capable of generating diverse categories of non-rigid
objects while adhering to the object motions extracted from a monocular video.
At its core, AnimatableDreamer is equipped with our novel optimization design
dubbed Canonical Score Distillation (CSD), which simplifies the generation
dimension from 4D to 3D by denoising over different frames in the time-varying
camera spaces while conducting the distillation process in a unique canonical
space shared per video. Concretely, CSD ensures that score gradients
back-propagate to the canonical space through differentiable warping, hence
guaranteeing the time-consistent generation and maintaining morphological
plausibility across different poses. By lifting the 3D generator to 4D with
warping functions, AnimatableDreamer offers a novel perspective on non-rigid 3D
model generation and reconstruction. Besides, with inductive knowledge from a
multi-view consistent diffusion model, CSD regularizes reconstruction from
novel views, thus cyclically enhancing the generation process. Extensive
experiments demonstrate the capability of our method in generating
high-flexibility text-guided 3D models from the monocular video, while also
showing improved reconstruction performance over typical non-rigid
reconstruction methods. Project page https://AnimatableDreamer.github.io.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03796" title="Abstract">arXiv:2312.03796</a> [<a href="/pdf/2312.03796" title="Download PDF">pdf</a>, <a href="/format/2312.03796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Scale and Multi-Modal Contrastive Learning Network for Biomedical  Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hongbo Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xinzi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoxing Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 figures, submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multi-modal biomedical time series (MBTS) data offers a holistic view of the
physiological state, holding significant importance in various bio-medical
applications. Owing to inherent noise and distribution gaps across different
modalities, MBTS can be complex to model. Various deep learning models have
been developed to learn representations of MBTS but still fall short in
robustness due to the ignorance of modal-to-modal variations. This paper
presents a multi-scale and multi-modal biomedical time series representation
learning (MBSL) network with contrastive learning to migrate these variations.
Firstly, MBTS is grouped based on inter-modal distances, then each group with
minimum intra-modal variations can be effectively modeled by individual
encoders. Besides, to enhance the multi-scale feature extraction (encoder),
various patch lengths and mask ratios are designed to generate tokens with
semantic information at different scales and diverse contextual perspectives
respectively. Finally, cross-modal contrastive learning is proposed to maximize
consistency among inter-modal groups, maintaining useful information and
eliminating noises. Experiments against four bio-medical applications show that
MBSL outperforms state-of-the-art models by 33.9% mean average errors (MAE) in
respiration rate, by 13.8% MAE in exercise heart rate, by 1.41% accuracy in
human activity recognition, and by 1.14% F1-score in obstructive sleep
apnea-hypopnea syndrome.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03798" title="Abstract">arXiv:2312.03798</a> [<a href="/pdf/2312.03798" title="Download PDF">pdf</a>, <a href="/format/2312.03798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single Image Reflection Removal with Reflection Intensity Prior  Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+D">Dongshen Han</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seungkyu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaoning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+H">Heechan Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+H">Hyukmin Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">HyunCheol Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choo%2C+H">HyonGon Choo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Single Image Reflection Removal (SIRR) in real-world images is a challenging
task due to diverse image degradations occurring on the glass surface during
light transmission and reflection. Many existing methods rely on specific prior
assumptions to resolve the problem. In this paper, we propose a general
reflection intensity prior that captures the intensity of the reflection
phenomenon and demonstrate its effectiveness. To learn the reflection intensity
prior, we introduce the Reflection Prior Extraction Network (RPEN). By
segmenting images into regional patches, RPEN learns non-uniform reflection
prior in an image. We propose Prior-based Reflection Removal Network (PRRN)
using a simple transformer U-Net architecture that adapts reflection prior fed
from RPEN. Experimental results on real-world benchmarks demonstrate the
effectiveness of our approach achieving state-of-the-art accuracy in SIRR.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03799" title="Abstract">arXiv:2312.03799</a> [<a href="/pdf/2312.03799" title="Download PDF">pdf</a>, <a href="/format/2312.03799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-power, Continuous Remote Behavioral Localization with Event Cameras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamann%2C+F">Friedhelm Hamann</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Suman Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Martinez%2C+I+J">Ignacio Juarez Martinez</a>, 
<a href="/search/cs?searchtype=author&query=Hart%2C+T">Tom Hart</a>, 
<a href="/search/cs?searchtype=author&query=Kacelnik%2C+A">Alex Kacelnik</a>, 
<a href="/search/cs?searchtype=author&query=Gallego%2C+G">Guillermo Gallego</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures, 11 tables, Project page: <a href="https://tub-rip.github.io/eventpenguins/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Researchers in natural science need reliable methods for quantifying animal
behavior. Recently, numerous computer vision methods emerged to automate the
process. However, observing wild species at remote locations remains a
challenging task due to difficult lighting conditions and constraints on power
supply and data storage. Event cameras offer unique advantages for
battery-dependent remote monitoring due to their low power consumption and high
dynamic range capabilities. We use this novel sensor to quantify a behavior in
Chinstrap penguins called ecstatic display. We formulate the problem as a
temporal action detection task, determining the start and end times of the
behavior. For this purpose, we recorded a colony of breeding penguins in
Antarctica during several weeks and labeled event data on 16 nests. The
developed method consists of a generator of candidate time intervals
(proposals) and a classifier of the actions within them. The experiments show
that the event cameras' natural response to motion is effective for continuous
behavior monitoring and detection, reaching a mean average precision (mAP) of
58% (which increases to 63% in good weather conditions). The results also
demonstrate the robustness against various lighting conditions contained in the
challenging dataset. The low-power capabilities of the event camera allows to
record three times longer than with a conventional camera. This work pioneers
the use of event cameras for remote wildlife observation, opening new
interdisciplinary opportunities. https://tub-rip.github.io/eventpenguins/
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03801" title="Abstract">arXiv:2312.03801</a> [<a href="/pdf/2312.03801" title="Download PDF">pdf</a>, <a href="/format/2312.03801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalization to New Sequential Decision Making Tasks with In-Context  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raparthy%2C+S+C">Sharath Chandra Raparthy</a>, 
<a href="/search/cs?searchtype=author&query=Hambro%2C+E">Eric Hambro</a>, 
<a href="/search/cs?searchtype=author&query=Kirk%2C+R">Robert Kirk</a>, 
<a href="/search/cs?searchtype=author&query=Henaff%2C+M">Mikael Henaff</a>, 
<a href="/search/cs?searchtype=author&query=Raileanu%2C+R">Roberta Raileanu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Training autonomous agents that can learn new tasks from only a handful of
demonstrations is a long-standing problem in machine learning. Recently,
transformers have been shown to learn new language or vision tasks without any
weight updates from only a few examples, also referred to as in-context
learning. However, the sequential decision making setting poses additional
challenges having a lower tolerance for errors since the environment's
stochasticity or the agent's actions can lead to unseen, and sometimes
unrecoverable, states. In this paper, we use an illustrative example to show
that naively applying transformers to sequential decision making problems does
not enable in-context learning of new tasks. We then demonstrate how training
on sequences of trajectories with certain distributional properties leads to
in-context learning of new sequential decision making tasks. We investigate
different design choices and find that larger model and dataset sizes, as well
as more task diversity, environment stochasticity, and trajectory burstiness,
all result in better in-context learning of new out-of-distribution tasks. By
training on large diverse offline datasets, our model is able to learn new
MiniHack and Procgen tasks without any weight updates from just a handful of
demonstrations.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03804" title="Abstract">arXiv:2312.03804</a> [<a href="/pdf/2312.03804" title="Download PDF">pdf</a>, <a href="/format/2312.03804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Low Can You Go? Surfacing Prototypical In-Distribution Samples for  Unsupervised Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meissen%2C+F">Felix Meissen</a>, 
<a href="/search/cs?searchtype=author&query=Getzner%2C+J">Johannes Getzner</a>, 
<a href="/search/cs?searchtype=author&query=Ziller%2C+A">Alexander Ziller</a>, 
<a href="/search/cs?searchtype=author&query=Kaissis%2C+G">Georgios Kaissis</a>, 
<a href="/search/cs?searchtype=author&query=Rueckert%2C+D">Daniel Rueckert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unsupervised anomaly detection (UAD) alleviates large labeling efforts by
training exclusively on unlabeled in-distribution data and detecting outliers
as anomalies. Generally, the assumption prevails that large training datasets
allow the training of higher-performing UAD models. However, in this work, we
show that using only very few training samples can already match - and in some
cases even improve - anomaly detection compared to training with the whole
training dataset. We propose three methods to identify prototypical samples
from a large dataset of in-distribution samples. We demonstrate that by
training with a subset of just ten such samples, we achieve an area under the
receiver operating characteristics curve (AUROC) of $96.37 \%$ on CIFAR10,
$92.59 \%$ on CIFAR100, $95.37 \%$ on MNIST, $95.38 \%$ on Fashion-MNIST,
$96.37 \%$ on MVTec-AD, $98.81 \%$ on BraTS, and $81.95 \%$ on RSNA pneumonia
detection, even exceeding the performance of full training in $25/67$ classes
we tested. Additionally, we show that the prototypical in-distribution samples
identified by our proposed methods translate well to different models and other
datasets and that using their characteristics as guidance allows for successful
manual selection of small subsets of high-performing samples. Our code is
available at https://anonymous.4open.science/r/uad_prototypical_samples/
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03805" title="Abstract">arXiv:2312.03805</a> [<a href="/pdf/2312.03805" title="Download PDF">pdf</a>, <a href="/format/2312.03805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SYNC-CLIP: Synthetic Data Make CLIP Generalize Better in Data-Limited  Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mushui Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+W">Weijie He</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Ziqian Lu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yunlong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Prompt learning is a powerful technique for transferring Vision-Language
Models (VLMs) such as CLIP to downstream tasks. However, the prompt-based
methods that are fine-tuned solely with base classes may struggle to generalize
to novel classes in open-vocabulary scenarios, especially when data are
limited. To address this issue, we propose an innovative approach called
SYNC-CLIP that leverages SYNthetiC data for enhancing the generalization
capability of CLIP. Based on the observation of the distribution shift between
the real and synthetic samples, we treat real and synthetic samples as distinct
domains and propose to optimize separate domain prompts to capture
domain-specific information, along with the shared visual prompts to preserve
the semantic consistency between two domains. By aligning the cross-domain
features, the synthetic data from novel classes can provide implicit guidance
to rebalance the decision boundaries. Experimental results on three model
generalization tasks demonstrate that our method performs very competitively
across various benchmarks. Notably, SYNC-CLIP outperforms the state-of-the-art
competitor PromptSRC by an average improvement of 3.0% on novel classes across
11 datasets in open-vocabulary scenarios.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03806" title="Abstract">arXiv:2312.03806</a> [<a href="/pdf/2312.03806" title="Download PDF">pdf</a>, <a href="/format/2312.03806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XCube ($\mathcal{X}^3$): Large-Scale 3D Generative Modeling using Sparse  Voxel Hierarchies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xuanchi Ren</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiahui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xiaohui Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Museth%2C+K">Ken Museth</a>, 
<a href="/search/cs?searchtype=author&query=Fidler%2C+S">Sanja Fidler</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+F">Francis Williams</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present $\mathcal{X}^3$ (pronounced XCube), a novel generative model for
high-resolution sparse 3D voxel grids with arbitrary attributes. Our model can
generate millions of voxels with a finest effective resolution of up to
$1024^3$ in a feed-forward fashion without time-consuming test-time
optimization. To achieve this, we employ a hierarchical voxel latent diffusion
model which generates progressively higher resolution grids in a coarse-to-fine
manner using a custom framework built on the highly efficient VDB data
structure. Apart from generating high-resolution objects, we demonstrate the
effectiveness of XCube on large outdoor scenes at scales of 100m$\times$100m
with a voxel size as small as 10cm. We observe clear qualitative and
quantitative improvements over past approaches. In addition to unconditional
generation, we show that our model can be used to solve a variety of tasks such
as user-guided editing, scene completion from a single scan, and text-to-3D.
More results and details can be found at
https://research.nvidia.com/labs/toronto-ai/xcube/.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03808" title="Abstract">arXiv:2312.03808</a> [<a href="/pdf/2312.03808" title="Download PDF">pdf</a>, <a href="/format/2312.03808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SurfaceAug: Closing the Gap in Multimodal Ground Truth Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rubel%2C+R">Ryan Rubel</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+N">Nathan Clark</a>, 
<a href="/search/cs?searchtype=author&query=Dudash%2C+A">Andrew Dudash</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Contains eight pages and three figures. A version of this document was submitted to CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite recent advances in both model architectures and data augmentation,
multimodal object detectors still barely outperform their LiDAR-only
counterparts. This shortcoming has been attributed to a lack of sufficiently
powerful multimodal data augmentation. To address this, we present SurfaceAug,
a novel ground truth sampling algorithm. SurfaceAug pastes objects by
resampling both images and point clouds, enabling object-level transformations
in both modalities. We evaluate our algorithm by training a multimodal detector
on KITTI and compare its performance to previous works. We show experimentally
that SurfaceAug outperforms existing methods on car detection tasks and
establishes a new state of the art for multimodal ground truth sampling.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03812" title="Abstract">arXiv:2312.03812</a> [<a href="/pdf/2312.03812" title="Download PDF">pdf</a>, <a href="/ps/2312.03812" title="Download PostScript">ps</a>, <a href="/format/2312.03812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seeing the random forest through the decision trees. Supporting learning  health systems from histopathology with machine learning models: Challenges  and opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+R">Ricardo Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+A">Ashirbani Saha</a>, 
<a href="/search/cs?searchtype=author&query=Campbell%2C+C+J+V">Clinton J.V. Campbell</a>, 
<a href="/search/cs?searchtype=author&query=Nejat%2C+P">Peyman Nejat</a>, 
<a href="/search/cs?searchtype=author&query=Lokker%2C+C">Cynthia Lokker</a>, 
<a href="/search/cs?searchtype=author&query=Norgan%2C+A+P">Andrew P. Norgan</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Pathology Informatics 15 (2024) 100347
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper discusses some overlooked challenges faced when working with
machine learning models for histopathology and presents a novel opportunity to
support "Learning Health Systems" with them. Initially, the authors elaborate
on these challenges after separating them according to their mitigation
strategies: those that need innovative approaches, time, or future
technological capabilities and those that require a conceptual reappraisal from
a critical perspective. Then, a novel opportunity to support "Learning Health
Systems" by integrating hidden information extracted by ML models from
digitalized histopathology slides with other healthcare big data is presented.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03813" title="Abstract">arXiv:2312.03813</a> [<a href="/pdf/2312.03813" title="Download PDF">pdf</a>, <a href="/format/2312.03813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Activation Steering in Language Models with Mean-Centring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jorgensen%2C+O">Ole Jorgensen</a>, 
<a href="/search/cs?searchtype=author&query=Cope%2C+D">Dylan Cope</a>, 
<a href="/search/cs?searchtype=author&query=Schoots%2C+N">Nandi Schoots</a>, 
<a href="/search/cs?searchtype=author&query=Shanahan%2C+M">Murray Shanahan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent work in activation steering has demonstrated the potential to better
control the outputs of Large Language Models (LLMs), but it involves finding
steering vectors. This is difficult because engineers do not typically know how
features are represented in these models. We seek to address this issue by
applying the idea of mean-centring to steering vectors. We find that taking the
average of activations associated with a target dataset, and then subtracting
the mean of all training activations, results in effective steering vectors. We
test this method on a variety of models on natural language tasks by steering
away from generating toxic text, and steering the completion of a story towards
a target genre. We also apply mean-centring to extract function vectors, more
effectively triggering the execution of a range of natural language tasks by a
significant margin (compared to previous baselines). This suggests that
mean-centring can be used to easily improve the effectiveness of activation
steering in a wide range of contexts.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03814" title="Abstract">arXiv:2312.03814</a> [<a href="/pdf/2312.03814" title="Download PDF">pdf</a>, <a href="/format/2312.03814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pearl: A Production-ready Reinforcement Learning Agent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zheqing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=de+Salvo+Braz%2C+R">Rodrigo de Salvo Braz</a>, 
<a href="/search/cs?searchtype=author&query=Bhandari%2C+J">Jalaj Bhandari</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Daniel Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yi Wan</a>, 
<a href="/search/cs?searchtype=author&query=Efroni%2C+Y">Yonathan Efroni</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ruiyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hongbo Guo</a>, 
<a href="/search/cs?searchtype=author&query=Nikulkov%2C+A">Alex Nikulkov</a>, 
<a href="/search/cs?searchtype=author&query=Korenkevych%2C+D">Dmytro Korenkevych</a>, 
<a href="/search/cs?searchtype=author&query=Dogan%2C+U">Urun Dogan</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+F">Frank Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wanqiao Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Reinforcement Learning (RL) offers a versatile framework for achieving
long-term goals. Its generality allows us to formalize a wide range of problems
that real-world intelligent systems encounter, such as dealing with delayed
rewards, handling partial observability, addressing the exploration and
exploitation dilemma, utilizing offline data to improve online performance, and
ensuring safety constraints are met. Despite considerable progress made by the
RL research community in addressing these issues, existing open-source RL
libraries tend to focus on a narrow portion of the RL solution pipeline,
leaving other aspects largely unattended. This paper introduces Pearl, a
Production-ready RL agent software package explicitly designed to embrace these
challenges in a modular fashion. In addition to presenting preliminary
benchmark results, this paper highlights Pearl's industry adoptions to
demonstrate its readiness for production usage. Pearl is open sourced on Github
at github.com/facebookresearch/pearl and its official website is located at
pearlagent.github.io.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03815" title="Abstract">arXiv:2312.03815</a> [<a href="/pdf/2312.03815" title="Download PDF">pdf</a>, <a href="/format/2312.03815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM as OS (llmao), Agents as Apps: Envisioning AIOS, Agents and the  AIOS-Agent Ecosystem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yingqiang Ge</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yujie Ren</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+W">Wenyue Hua</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shuyuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+J">Juntao Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongfeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Operating Systems (cs.OS)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper envisions a revolutionary AIOS-Agent ecosystem, where Large
Language Model (LLM) serves as the (Artificial) Intelligent Operating System
(IOS, or AIOS)--an operating system ``with soul''. Upon this foundation, a
diverse range of LLM-based AI Agent Applications (Agents, or AAPs) are
developed, enriching the AIOS-Agent ecosystem and signaling a paradigm shift
from the traditional OS-APP ecosystem. We envision that LLM's impact will not
be limited to the AI application level, instead, it will in turn revolutionize
the design and implementation of computer system, architecture, software, and
programming language, featured by several main concepts: LLM as OS
(system-level), Agents as Applications (application-level), Natural Language as
Programming Interface (user-level), and Tools as Devices/Libraries
(hardware/middleware-level).
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03816" title="Abstract">arXiv:2312.03816</a> [<a href="/pdf/2312.03816" title="Download PDF">pdf</a>, <a href="/format/2312.03816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AVID: Any-Length Video Inpainting with Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhixing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bichen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoyan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yaqiao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Luxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yinan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Vajda%2C+P">Peter Vajda</a>, 
<a href="/search/cs?searchtype=author&query=Metaxas%2C+D">Dimitris Metaxas</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Licheng Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="https://zhang-zx.github.io/AVID/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advances in diffusion models have successfully enabled text-guided
image inpainting. While it seems straightforward to extend such editing
capability into video domain, there has been fewer works regarding text-guided
video inpainting. Given a video, a masked region at its initial frame, and an
editing prompt, it requires a model to do infilling at each frame following the
editing guidance while keeping the out-of-mask region intact. There are three
main challenges in text-guided video inpainting: ($i$) temporal consistency of
the edited video, ($ii$) supporting different inpainting types at different
structural fidelity level, and ($iii$) dealing with variable video length. To
address these challenges, we introduce Any-Length Video Inpainting with
Diffusion Model, dubbed as AVID. At its core, our model is equipped with
effective motion modules and adjustable structure guidance, for fixed-length
video inpainting. Building on top of that, we propose a novel Temporal
MultiDiffusion sampling pipeline with an middle-frame attention guidance
mechanism, facilitating the generation of videos with any desired duration. Our
comprehensive experiments show our model can robustly deal with various
inpainting types at different video duration range, with high quality. More
visualization results is made publicly available at
https://zhang-zx.github.io/AVID/ .
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03817" title="Abstract">arXiv:2312.03817</a> [<a href="/pdf/2312.03817" title="Download PDF">pdf</a>, <a href="/format/2312.03817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Illusions: Hiding Images in Plain Sight
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Burgert%2C+R">Ryan Burgert</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Leite%2C+A">Abe Leite</a>, 
<a href="/search/cs?searchtype=author&query=Ranasinghe%2C+K">Kanchana Ranasinghe</a>, 
<a href="/search/cs?searchtype=author&query=Ryoo%2C+M+S">Michael S. Ryoo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We explore the problem of computationally generating special `prime' images
that produce optical illusions when physically arranged and viewed in a certain
way. First, we propose a formal definition for this problem. Next, we introduce
Diffusion Illusions, the first comprehensive pipeline designed to automatically
generate a wide range of these illusions. Specifically, we both adapt the
existing `score distillation loss' and propose a new `dream target loss' to
optimize a group of differentially parametrized prime images, using a frozen
text-to-image diffusion model. We study three types of illusions, each where
the prime images are arranged in different ways and optimized using the
aforementioned losses such that images derived from them align with user-chosen
text prompts or images. We conduct comprehensive experiments on these illusions
and verify the effectiveness of our proposed method qualitatively and
quantitatively. Additionally, we showcase the successful physical fabrication
of our illusions -- as they are all designed to work in the real world. Our
code and examples are publicly available at our interactive project website:
https://diffusionillusions.com
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03818" title="Abstract">arXiv:2312.03818</a> [<a href="/pdf/2312.03818" title="Download PDF">pdf</a>, <a href="/format/2312.03818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alpha-CLIP: A CLIP Model Focusing on Wherever You Want
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zeyi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Ye Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zang%2C+Y">Yuhang Zang</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+S">Shu Kong</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yuanjun Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project page: <a href="https://aleafy.github.io/alpha-clip">this https URL</a>; code: <a href="https://github.com/SunzeY/AlphaCLIP">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Contrastive Language-Image Pre-training (CLIP) plays an essential role in
extracting valuable content information from images across diverse tasks. It
aligns textual and visual modalities to comprehend the entire image, including
all the details, even those irrelevant to specific tasks. However, for a finer
understanding and controlled editing of images, it becomes crucial to focus on
specific regions of interest, which can be indicated as points, masks, or boxes
by humans or perception models. To fulfill the requirements, we introduce
Alpha-CLIP, an enhanced version of CLIP with an auxiliary alpha channel to
suggest attentive regions and fine-tuned with constructed millions of RGBA
region-text pairs. Alpha-CLIP not only preserves the visual recognition ability
of CLIP but also enables precise control over the emphasis of image contents.
It demonstrates effectiveness in various tasks, including but not limited to
open-world recognition, multimodal large language models, and conditional 2D /
3D generation. It has a strong potential to serve as a versatile tool for
image-related tasks.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03849" title="Abstract">arXiv:2312.03849</a> [<a href="/pdf/2312.03849" title="Download PDF">pdf</a>, <a href="/format/2312.03849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LEGO: Learning EGOcentric Action Frame Generation via Visual Instruction  Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+B">Bolin Lai</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xiaoliang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lawrence Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+G">Guan Pang</a>, 
<a href="/search/cs?searchtype=author&query=Rehg%2C+J+M">James M. Rehg</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Miao Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generating instructional images of human daily actions from an egocentric
viewpoint serves a key step towards efficient skill transfer. In this paper, we
introduce a novel problem -- egocentric action frame generation. The goal is to
synthesize the action frame conditioning on the user prompt question and an
input egocentric image that captures user's environment. Notably, existing
egocentric datasets lack the detailed annotations that describe the execution
of actions. Additionally, the diffusion-based image manipulation models fail to
control the state change of an action within the corresponding egocentric image
pixel space. To this end, we finetune a visual large language model (VLLM) via
visual instruction tuning for curating the enriched action descriptions to
address our proposed problem. Moreover, we propose to Learn EGOcentric (LEGO)
action frame generation using image and text embeddings from VLLM as additional
conditioning. We validate our proposed model on two egocentric datasets --
Ego4D and Epic-Kitchens. Our experiments show prominent improvement over prior
image manipulation models in both quantitative and qualitative evaluation. We
also conduct detailed ablation studies and analysis to provide insights on our
method.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03850" title="Abstract">arXiv:2312.03850</a> [<a href="/pdf/2312.03850" title="Download PDF">pdf</a>, <a href="/format/2312.03850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning the Dynamics of Future Marine Microgrids Using Temporal  Convolutional Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ge%2C+X">Xiaoyu Ge</a>, 
<a href="/search/eess?searchtype=author&query=Hosseinipour%2C+A">Ali Hosseinipour</a>, 
<a href="/search/eess?searchtype=author&query=Putri%2C+S">Saskia Putri</a>, 
<a href="/search/eess?searchtype=author&query=Moazeni%2C+F">Faegheh Moazeni</a>, 
<a href="/search/eess?searchtype=author&query=Khazaei%2C+J">Javad Khazaei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Medium-voltage direct-current (MVDC) ship-board microgrids (SMGs) are the
state-of-the-art architecture for onboard power distribution in navy. These
systems are considered to be highly dynamic due to high penetration of power
electronic converters and volatile load patterns such as pulsed-power load
(PPL) and propulsion motors demand variation. Obtaining the dynamic model of an
MVDC SMG is a challenging task due to the confidentiality of system components
models and uncertainty in the dynamic models through time. In this paper, a
dynamic identification framework based on a temporal convolutional neural
network (TCN) is developed to learn the system dynamics from measurement data.
Different kinds of testing scenarios are implemented, and the testing results
show that this approach achieves an exceptional performance and high
generalization ability, thus holding substantial promise for development of
advanced data-driven control strategies and stability prediction of the system.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03853" title="Abstract">arXiv:2312.03853</a> [<a href="/pdf/2312.03853" title="Download PDF">pdf</a>, <a href="/format/2312.03853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dr. Jekyll and Mr. Hyde: Two Faces of LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Collu%2C+M+G">Matteo Gioele Collu</a>, 
<a href="/search/cs?searchtype=author&query=Janssen-Groesbeek%2C+T">Tom Janssen-Groesbeek</a>, 
<a href="/search/cs?searchtype=author&query=Koffas%2C+S">Stefanos Koffas</a>, 
<a href="/search/cs?searchtype=author&query=Conti%2C+M">Mauro Conti</a>, 
<a href="/search/cs?searchtype=author&query=Picek%2C+S">Stjepan Picek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This year, we witnessed a rise in the use of Large Language Models,
especially when combined with applications like chatbot assistants. Safety
mechanisms and specialized training procedures are put in place to prevent
improper responses from these assistants. In this work, we bypass these
measures for ChatGPT and Bard (and, to some extent, Bing chat) by making them
impersonate complex personas with opposite characteristics as those of the
truthful assistants they are supposed to be. We start by creating elaborate
biographies of these personas, which we then use in a new session with the same
chatbots. Our conversation followed a role-play style to get the response the
assistant was not allowed to provide. By making use of personas, we show that
the response that is prohibited is actually provided, making it possible to
obtain unauthorized, illegal, or harmful information. This work shows that by
using adversarial personas, one can overcome safety mechanisms set out by
ChatGPT and Bard. It also introduces several ways of activating such
adversarial personas, altogether showing that both chatbots are vulnerable to
this kind of attack.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03858" title="Abstract">arXiv:2312.03858</a> [<a href="/pdf/2312.03858" title="Download PDF">pdf</a>, <a href="/format/2312.03858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stop Hiding The Sharp Knives: The WebAssembly Linux Interface
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramesh%2C+A">Arjun Ramesh</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tianshu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Titzer%2C+B+L">Ben L. Titzer</a>, 
<a href="/search/cs?searchtype=author&query=Rowe%2C+A">Anthony Rowe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Operating Systems (cs.OS)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">WebAssembly is gaining popularity as a portable binary format targetable from
many programming languages. With a well-specified low-level virtual instruction
set, minimal memory footprint and many high-performance implementations, it has
been successfully adopted for lightweight in-process memory sandboxing in many
contexts. Despite these advantages, WebAssembly lacks many standard system
interfaces, making it difficult to reuse existing applications.
<br />This paper proposes WALI: The WebAssembly Linux Interface, a thin layer over
Linux's userspace system calls, creating a new class of virtualization where
WebAssembly seamlessly interacts with native processes and the underlying
operating system. By virtualizing the lowest level of userspace, WALI offers
application portability with little effort and reuses existing compiler
backends. With WebAssembly's control flow integrity guarantees, these modules
gain an additional level of protection against remote code injection attacks.
Furthermore, capability-based APIs can themselves be virtualized and
implemented in terms of WALI, improving reuse and robustness through better
layering. We present an implementation of WALI in a modern WebAssembly engine
and evaluate its performance on a number of applications which we can now
compile with mostly trivial effort.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03859" title="Abstract">arXiv:2312.03859</a> [<a href="/pdf/2312.03859" title="Download PDF">pdf</a>, <a href="/ps/2312.03859" title="Download PostScript">ps</a>, <a href="/format/2312.03859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Tight Bounds for the Graph Homomorphism Problem Parameterized by  Cutwidth via Asymptotic Rank Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Groenland%2C+C">Carla Groenland</a>, 
<a href="/search/cs?searchtype=author&query=Mannens%2C+I">Isja Mannens</a>, 
<a href="/search/cs?searchtype=author&query=Nederlof%2C+J">Jesper Nederlof</a>, 
<a href="/search/cs?searchtype=author&query=Piecyk%2C+M">Marta Piecyk</a>, 
<a href="/search/cs?searchtype=author&query=Rz%C4%85%C5%BCewski%2C+P">Pawe&#x142; Rz&#x105;&#x17c;ewski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">A homomorphism from a graph $G$ to a graph $H$ is an edge-preserving mapping
from $V(G)$ to $V(H)$. In the graph homomorphism problem, denoted by $Hom(H)$,
the graph $H$ is fixed and we need to determine if there exists a homomorphism
from an instance graph $G$ to $H$. We study the complexity of the problem
parameterized by the cutwidth of $G$.
<br />We aim, for each $H$, for algorithms for $Hom(H)$ running in time $c_H^k
n^{\mathcal{O}(1)}$ and matching lower bounds that exclude $c_H^{k \cdot
o(1)}n^{\mathcal{O}(1)}$ or $c_H^{k(1-\Omega(1))}n^{\mathcal{O}(1)}$ time
algorithms under the (Strong) Exponential Time Hypothesis.
<br />In the paper we introduce a new parameter that we call $\mathrm{mimsup}(H)$.
Our main contribution is strong evidence of a close connection between $c_H$
and $\mathrm{mimsup}(H)$:
<br />* an information-theoretic argument that the number of states needed in a
natural dynamic programming algorithm is at most $\mathrm{mimsup}(H)^k$,
<br />* lower bounds that show that for almost all graphs $H$ indeed we have $c_H
\geq \mathrm{mimsup}(H)$, assuming the (Strong) Exponential-Time Hypothesis,
and
<br />* an algorithm with running time $\exp ( {\mathcal{O}( \mathrm{mimsup}(H)
\cdot k \log k)}) n^{\mathcal{O}(1)}$.
<br />The parameter $\mathrm{mimsup}(H)$ can be thought of as the $p$-th root of
the maximum induced matching number in the graph obtained by multiplying $p$
copies of $H$ via certain graph product, where $p$ tends to infinity. It can
also be defined as an asymptotic rank parameter of the adjacency matrix of $H$.
Our results tightly link the parameterized complexity of a problem to such an
asymptotic rank parameter for the first time.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03863" title="Abstract">arXiv:2312.03863</a> [<a href="/pdf/2312.03863" title="Download PDF">pdf</a>, <a href="/format/2312.03863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Large Language Models: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Zhongwei Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Che Liu</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+S">Samiul Alam</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Z">Zhongnan Qu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shen Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Quanlu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+M">Mosharaf Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) have demonstrated remarkable capabilities in
important tasks such as natural language understanding, language generation,
and complex reasoning and have the potential to make a substantial impact on
our society. Such capabilities, however, come with the considerable resources
they demand, highlighting the strong need to develop effective techniques for
addressing their efficiency challenges. In this survey, we provide a systematic
and comprehensive review of efficient LLMs research. We organize the literature
in a taxonomy consisting of three main categories, covering distinct yet
interconnected efficient LLMs topics from model-centric, data-centric, and
framework-centric perspective, respectively. We have also created a GitHub
repository where we compile the papers featured in this survey at
https://github.com/AIoT-MLSys-Lab/EfficientLLMs,
https://github.com/AIoT-MLSys-Lab/Efficient-LLMs-Survey, and will actively
maintain this repository and incorporate new research as it emerges. We hope
our survey can serve as a valuable resource to help researchers and
practitioners gain a systematic understanding of the research developments in
efficient LLMs and inspire them to contribute to this important and exciting
field.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03864" title="Abstract">arXiv:2312.03864</a> [<a href="/pdf/2312.03864" title="Download PDF">pdf</a>, <a href="/format/2312.03864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometry Matching for Multi-Embodiment Grasping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Attarian%2C+M">Maria Attarian</a>, 
<a href="/search/cs?searchtype=author&query=Asif%2C+M+A">Muhammad Adil Asif</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingzhou Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hari%2C+R">Ruthrash Hari</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+A">Animesh Garg</a>, 
<a href="/search/cs?searchtype=author&query=Gilitschenski%2C+I">Igor Gilitschenski</a>, 
<a href="/search/cs?searchtype=author&query=Tompson%2C+J">Jonathan Tompson</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 7th Annual Conference on Robot Learning, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Many existing learning-based grasping approaches concentrate on a single
embodiment, provide limited generalization to higher DoF end-effectors and
cannot capture a diverse set of grasp modes. We tackle the problem of grasping
using multiple embodiments by learning rich geometric representations for both
objects and end-effectors using Graph Neural Networks. Our novel method -
GeoMatch - applies supervised learning on grasping data from multiple
embodiments, learning end-to-end contact point likelihood maps as well as
conditional autoregressive predictions of grasps keypoint-by-keypoint. We
compare our method against baselines that support multiple embodiments. Our
approach performs better across three end-effectors, while also producing
diverse grasps. Examples, including real robot demos, can be found at
geo-match.github.io.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03865" title="Abstract">arXiv:2312.03865</a> [<a href="/pdf/2312.03865" title="Download PDF">pdf</a>, <a href="/format/2312.03865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Genomic Sequence Representations using Graph Neural Networks  over De Bruijn Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kapu%C5%9Bniak%2C+K">Kacper Kapu&#x15b;niak</a>, 
<a href="/search/cs?searchtype=author&query=Burger%2C+M">Manuel Burger</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%A4tsch%2C+G">Gunnar R&#xe4;tsch</a>, 
<a href="/search/cs?searchtype=author&query=Joudaki%2C+A">Amir Joudaki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Poster at "NeurIPS 2023 New Frontiers in Graph Learning Workshop (NeurIPS GLFrontiers 2023)"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Genomics (q-bio.GN)

</div>
<p class="mathjax">The rapid expansion of genomic sequence data calls for new methods to achieve
robust sequence representations. Existing techniques often neglect intricate
structural details, emphasizing mainly contextual information. To address this,
we developed k-mer embeddings that merge contextual and structural string
information by enhancing De Bruijn graphs with structural similarity
connections. Subsequently, we crafted a self-supervised method based on
Contrastive Learning that employs a heterogeneous Graph Convolutional Network
encoder and constructs positive pairs based on node similarities. Our
embeddings consistently outperform prior techniques for Edit Distance
Approximation and Closest String Retrieval tasks.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03867" title="Abstract">arXiv:2312.03867</a> [<a href="/pdf/2312.03867" title="Download PDF">pdf</a>, <a href="/ps/2312.03867" title="Download PostScript">ps</a>, <a href="/format/2312.03867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Group Fairness Evaluation via Conditional Value-at-Risk Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paes%2C+L+M">Lucas Monteiro Paes</a>, 
<a href="/search/cs?searchtype=author&query=Suresh%2C+A+T">Ananda Theertha Suresh</a>, 
<a href="/search/cs?searchtype=author&query=Beutel%2C+A">Alex Beutel</a>, 
<a href="/search/cs?searchtype=author&query=Calmon%2C+F+P">Flavio P. Calmon</a>, 
<a href="/search/cs?searchtype=author&query=Beirami%2C+A">Ahmad Beirami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Information Theory (cs.IT); Machine Learning (stat.ML)

</div>
<p class="mathjax">Machine learning (ML) models used in prediction and classification tasks may
display performance disparities across population groups determined by
sensitive attributes (e.g., race, sex, age). We consider the problem of
evaluating the performance of a fixed ML model across population groups defined
by multiple sensitive attributes (e.g., race and sex and age). Here, the sample
complexity for estimating the worst-case performance gap across groups (e.g.,
the largest difference in error rates) increases exponentially with the number
of group-denoting sensitive attributes. To address this issue, we propose an
approach to test for performance disparities based on Conditional Value-at-Risk
(CVaR). By allowing a small probabilistic slack on the groups over which a
model has approximately equal performance, we show that the sample complexity
required for discovering performance violations is reduced exponentially to be
at most upper bounded by the square root of the number of groups. As a
byproduct of our analysis, when the groups are weighted by a specific prior
distribution, we show that R\'enyi entropy of order $2/3$ of the prior
distribution captures the sample complexity of the proposed CVaR test
algorithm. Finally, we also show that there exists a non-i.i.d. data collection
strategy that results in a sample complexity independent of the number of
groups.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03868" title="Abstract">arXiv:2312.03868</a> [<a href="/pdf/2312.03868" title="Download PDF">pdf</a>, <a href="/format/2312.03868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-Informed Renewable Energy Scheduling: A Scalable Bilevel  Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhao%2C+D">Dongwei Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Dvorkin%2C+V">Vladimir Dvorkin</a>, 
<a href="/search/eess?searchtype=author&query=Delikaraoglou%2C+S">Stefanos Delikaraoglou</a>, 
<a href="/search/eess?searchtype=author&query=L.%2C+A+J+L">Alberto J. Lamadrid L.</a>, 
<a href="/search/eess?searchtype=author&query=Botterud%2C+A">Audun Botterud</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Transactions on Energy Markets, Policy, and Regulation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; General Economics (econ.GN); Optimization and Control (math.OC)

</div>
<p class="mathjax">This work proposes an uncertainty-informed bid adjustment framework for
integrating variable renewable energy sources (VRES) into electricity markets.
This framework adopts a bilevel model to compute the optimal VRES day-ahead
bids. It aims to minimize the expected system cost across day-ahead and
real-time stages and approximate the cost efficiency of the stochastic market
design. However, solving the bilevel optimization problem is computationally
challenging for large-scale systems. To overcome this challenge, we introduce a
novel technique based on strong duality and McCormick envelopes, which relaxes
the problem to a linear program, enabling large-scale applications. The
proposed bilevel framework is applied to the 1576-bus NYISO system and
benchmarked against a myopic strategy, where the VRES bid is the mean value of
the probabilistic power forecast. Results demonstrate that, under high VRES
penetration levels (e.g., 40%), our framework can significantly reduce system
costs and market-price volatility, by optimizing VRES quantities efficiently in
the day-ahead market. Furthermore, we find that when transmission capacity
increases, the proposed bilevel model will still reduce the system cost,
whereas the myopic strategy may incur a much higher cost due to over-scheduling
of VRES in the day-ahead market and the lack of flexible conventional
generators in real time.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03869" title="Abstract">arXiv:2312.03869</a> [<a href="/pdf/2312.03869" title="Download PDF">pdf</a>, <a href="/format/2312.03869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inpaint3D: 3D Scene Content Generation using 2D Inpainting Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prabhu%2C+K">Kira Prabhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jane Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+L">Lynn Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Hedman%2C+P">Peter Hedman</a>, 
<a href="/search/cs?searchtype=author&query=Goldman%2C+D+B">Dan B Goldman</a>, 
<a href="/search/cs?searchtype=author&query=Poole%2C+B">Ben Poole</a>, 
<a href="/search/cs?searchtype=author&query=Broxton%2C+M">Michael Broxton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents a novel approach to inpainting 3D regions of a scene,
given masked multi-view images, by distilling a 2D diffusion model into a
learned 3D scene representation (e.g. a NeRF). Unlike 3D generative methods
that explicitly condition the diffusion model on camera pose or multi-view
information, our diffusion model is conditioned only on a single masked 2D
image. Nevertheless, we show that this 2D diffusion model can still serve as a
generative prior in a 3D multi-view reconstruction problem where we optimize a
NeRF using a combination of score distillation sampling and NeRF reconstruction
losses. Predicted depth is used as additional supervision to encourage accurate
geometry. We compare our approach to 3D inpainting methods that focus on object
removal. Because our method can generate content to fill any 3D masked region,
we additionally demonstrate 3D object completion, 3D object replacement, and 3D
scene completion.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03872" title="Abstract">arXiv:2312.03872</a> [<a href="/pdf/2312.03872" title="Download PDF">pdf</a>, <a href="/format/2312.03872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The BigCode Project Governance Card
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=BigCode+collaboration">BigCode collaboration</a>: 
<a href="/search/cs?searchtype=author&query=Hughes%2C+S">Sean Hughes</a>, 
<a href="/search/cs?searchtype=author&query=de+Vries%2C+H">Harm de Vries</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+J">Jennifer Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Ferrandis%2C+C+M">Carlos Mu&#xf1;oz Ferrandis</a>, 
<a href="/search/cs?searchtype=author&query=Allal%2C+L+B">Loubna Ben Allal</a>, 
<a href="/search/cs?searchtype=author&query=von+Werra%2C+L">Leandro von Werra</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jennifer Ding</a>, 
<a href="/search/cs?searchtype=author&query=Paquet%2C+S">Sebastien Paquet</a>, 
<a href="/search/cs?searchtype=author&query=Jernite%2C+Y">Yacine Jernite</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, related papers <a href="/abs/2305.06161">arXiv:2305.06161</a> and <a href="/abs/2301.03988">arXiv:2301.03988</a> and <a href="/abs/2211.15533">arXiv:2211.15533v1</a>, learn more at <a href="https://www.bigcode-project.org/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Programming Languages (cs.PL)

</div>
<p class="mathjax">This document serves as an overview of the different mechanisms and areas of
governance in the BigCode project. It aims to support transparency by providing
relevant information about choices that were made during the project to the
broader public, and to serve as an example of intentional governance of an open
research project that future endeavors can leverage to shape their own
approach. The first section, Project Structure, covers the project
organization, its stated goals and values, its internal decision processes, and
its funding and resources. The second section, Data and Model Governance,
covers decisions relating to the questions of data subject consent, privacy,
and model release.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03878" title="Abstract">arXiv:2312.03878</a> [<a href="/pdf/2312.03878" title="Download PDF">pdf</a>, <a href="/format/2312.03878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain constraints improve risk prediction when outcome data is missing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balachandar%2C+S">Sidhika Balachandar</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+N">Nikhil Garg</a>, 
<a href="/search/cs?searchtype=author&query=Pierson%2C+E">Emma Pierson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Machine learning models are often trained to predict the outcome resulting
from a human decision. For example, if a doctor decides to test a patient for
disease, will the patient test positive? A challenge is that the human decision
censors the outcome data: we only observe test outcomes for patients doctors
historically tested. Untested patients, for whom outcomes are unobserved, may
differ from tested patients along observed and unobserved dimensions. We
propose a Bayesian model class which captures this setting. The purpose of the
model is to accurately estimate risk for both tested and untested patients.
Estimating this model is challenging due to the wide range of possibilities for
untested patients. To address this, we propose two domain constraints which are
plausible in health settings: a prevalence constraint, where the overall
disease prevalence is known, and an expertise constraint, where the human
decision-maker deviates from purely risk-based decision-making only along a
constrained feature set. We show theoretically and on synthetic data that
domain constraints improve parameter inference. We apply our model to a case
study of cancer risk prediction, showing that the model's inferred risk
predicts cancer diagnoses, its inferred testing policy captures known public
health policies, and it can identify suboptimalities in test allocation. Though
our case study is in healthcare, our analysis reveals a general class of domain
constraints which can improve model estimation in many settings.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03881" title="Abstract">arXiv:2312.03881</a> [<a href="/pdf/2312.03881" title="Download PDF">pdf</a>, <a href="/format/2312.03881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FoMo Rewards: Can we cast foundation models as reward functions?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lubana%2C+E+S">Ekdeep Singh Lubana</a>, 
<a href="/search/cs?searchtype=author&query=Brehmer%2C+J">Johann Brehmer</a>, 
<a href="/search/cs?searchtype=author&query=de+Haan%2C+P">Pim de Haan</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+T">Taco Cohen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS FMDM workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We explore the viability of casting foundation models as generic reward
functions for reinforcement learning. To this end, we propose a simple pipeline
that interfaces an off-the-shelf vision model with a large language model.
Specifically, given a trajectory of observations, we infer the likelihood of an
instruction describing the task that the user wants an agent to perform. We
show that this generic likelihood function exhibits the characteristics ideally
expected from a reward function: it associates high values with the desired
behaviour and lower values for several similar, but incorrect policies.
Overall, our work opens the possibility of designing open-ended agents for
interactive tasks via foundation models.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03882" title="Abstract">arXiv:2312.03882</a> [<a href="/pdf/2312.03882" title="Download PDF">pdf</a>, <a href="/format/2312.03882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Signal Detection in Ambient Backscatter Systems: Fundamentals, Methods,  and Trends
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zargari%2C+S">Shayan Zargari</a>, 
<a href="/search/cs?searchtype=author&query=Hakimi%2C+A">Azar Hakimi</a>, 
<a href="/search/cs?searchtype=author&query=Rezaei%2C+F">Fatemeh Rezaei</a>, 
<a href="/search/cs?searchtype=author&query=Tellambura%2C+C">Chintha Tellambura</a>, 
<a href="/search/cs?searchtype=author&query=Maaref%2C+A">Amine Maaref</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the IEEE Access
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Internet-of-Things (IoT) is rapidly growing in wireless technology, aiming to
connect vast numbers of devices to gather and distribute vital information.
Despite individual devices having low energy consumption, the cumulative demand
results in significant energy usage. Consequently, the concept of
ultra-low-power tags gains appeal. Such tags communicate by reflecting rather
than generating the radio frequency (RF) signals by themselves. Thus, these
backscatter tags can be low-cost and battery-free. The RF signals can be
ambient sources such as wireless-fidelity (Wi-Fi), cellular, or television (TV)
signals, or the system can generate them externally. Backscatter channel
characteristics are different from conventional point-to-point or cooperative
relay channels. These systems are also affected by a strong interference link
between the RF source and the tag besides the direct and backscattering links,
making signal detection challenging. This paper provides an overview of the
fundamentals, challenges, and ongoing research in signal detection for AmBC
networks. It delves into various detection methods, discussing their advantages
and drawbacks. The paper's emphasis on signal detection sets it apart and
positions it as a valuable resource for IoT and wireless communication
professionals and researchers.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03884" title="Abstract">arXiv:2312.03884</a> [<a href="/pdf/2312.03884" title="Download PDF">pdf</a>, <a href="/format/2312.03884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WonderJourney: Going from Anywhere to Everywhere
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hong-Xing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+H">Haoyi Duan</a>, 
<a href="/search/cs?searchtype=author&query=Hur%2C+J">Junhwa Hur</a>, 
<a href="/search/cs?searchtype=author&query=Sargent%2C+K">Kyle Sargent</a>, 
<a href="/search/cs?searchtype=author&query=Rubinstein%2C+M">Michael Rubinstein</a>, 
<a href="/search/cs?searchtype=author&query=Freeman%2C+W+T">William T. Freeman</a>, 
<a href="/search/cs?searchtype=author&query=Cole%2C+F">Forrester Cole</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Deqing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Snavely%2C+N">Noah Snavely</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Herrmann%2C+C">Charles Herrmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website with video results: <a href="https://kovenyu.com/WonderJourney/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We introduce WonderJourney, a modularized framework for perpetual 3D scene
generation. Unlike prior work on view generation that focuses on a single type
of scenes, we start at any user-provided location (by a text description or an
image) and generate a journey through a long sequence of diverse yet coherently
connected 3D scenes. We leverage an LLM to generate textual descriptions of the
scenes in this journey, a text-driven point cloud generation pipeline to make a
compelling and coherent sequence of 3D scenes, and a large VLM to verify the
generated scenes. We show compelling, diverse visual results across various
scene types and styles, forming imaginary "wonderjourneys". Project website:
https://kovenyu.com/WonderJourney/
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03885" title="Abstract">arXiv:2312.03885</a> [<a href="/pdf/2312.03885" title="Download PDF">pdf</a>, <a href="/format/2312.03885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapting Newton&#x27;s Method to Neural Networks through a Summary of  Higher-Order Derivatives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wolinski%2C+P">Pierre Wolinski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We consider a gradient-based optimization method applied to a function
$\mathcal{L}$ of a vector of variables $\boldsymbol{\theta}$, in the case where
$\boldsymbol{\theta}$ is represented as a tuple of tensors $(\mathbf{T}_1,
\cdots, \mathbf{T}_S)$. This framework encompasses many common use-cases, such
as training neural networks by gradient descent. First, we propose a
computationally inexpensive technique providing higher-order information on
$\mathcal{L}$, especially about the interactions between the tensors
$\mathbf{T}_s$, based on automatic differentiation and computational tricks.
Second, we use this technique at order 2 to build a second-order optimization
method which is suitable, among other things, for training deep neural networks
of various architectures. This second-order method leverages the partition
structure of $\boldsymbol{\theta}$ into tensors $(\mathbf{T}_1, \cdots,
\mathbf{T}_S)$, in such a way that it requires neither the computation of the
Hessian of $\mathcal{L}$ according to $\boldsymbol{\theta}$, nor any
approximation of it. The key part consists in computing a smaller matrix
interpretable as a "Hessian according to the partition", which can be computed
exactly and efficiently. In contrast to many existing practical second-order
methods used in neural networks, which perform a diagonal or block-diagonal
approximation of the Hessian or its inverse, the method we propose does not
neglect interactions between layers. Finally, we can tune the coarseness of the
partition to recover well-known optimization methods: the coarsest case
corresponds to Cauchy's steepest descent method, the finest case corresponds to
the usual Newton's method.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03886" title="Abstract">arXiv:2312.03886</a> [<a href="/pdf/2312.03886" title="Download PDF">pdf</a>, <a href="/format/2312.03886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On The Fairness Impacts of Hardware Selection in Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nelaturu%2C+S+H">Sree Harsha Nelaturu</a>, 
<a href="/search/cs?searchtype=author&query=Ravichandran%2C+N+K">Nishaanth Kanna Ravichandran</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+C">Cuong Tran</a>, 
<a href="/search/cs?searchtype=author&query=Hooker%2C+S">Sara Hooker</a>, 
<a href="/search/cs?searchtype=author&query=Fioretto%2C+F">Ferdinando Fioretto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">In the machine learning ecosystem, hardware selection is often regarded as a
mere utility, overshadowed by the spotlight on algorithms and data. This
oversight is particularly problematic in contexts like ML-as-a-service
platforms, where users often lack control over the hardware used for model
deployment. How does the choice of hardware impact generalization properties?
This paper investigates the influence of hardware on the delicate balance
between model performance and fairness. We demonstrate that hardware choices
can exacerbate existing disparities, attributing these discrepancies to
variations in gradient flows and loss surfaces across different demographic
groups. Through both theoretical and empirical analysis, the paper not only
identifies the underlying factors but also proposes an effective strategy for
mitigating hardware-induced performance imbalances.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03889" title="Abstract">arXiv:2312.03889</a> [<a href="/pdf/2312.03889" title="Download PDF">pdf</a>, <a href="/format/2312.03889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Masked Pruning Approach for Dimensionality Reduction in  Communication-Efficient Federated Learning Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gez%2C+T+L+S">Tamir L.S. Gez</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+K">Kobi Cohen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated Learning (FL) represents a growing machine learning (ML) paradigm
designed for training models across numerous nodes that retain local datasets,
all without directly exchanging the underlying private data with the parameter
server (PS). Its increasing popularity is attributed to notable advantages in
terms of training deep neural network (DNN) models under privacy aspects and
efficient utilization of communication resources. Unfortunately, DNNs suffer
from high computational and communication costs, as well as memory consumption
in intricate tasks. These factors restrict the applicability of FL algorithms
in communication-constrained systems with limited hardware resources.
<br />In this paper, we develop a novel algorithm that overcomes these limitations
by synergistically combining a pruning-based method with the FL process,
resulting in low-dimensional representations of the model with minimal
communication cost, dubbed Masked Pruning over FL (MPFL). The algorithm
operates by initially distributing weights to the nodes through the PS.
Subsequently, each node locally trains its model and computes pruning masks.
These low-dimensional masks are then transmitted back to the PS, which
generates a consensus pruning mask, broadcasted back to the nodes. This
iterative process enhances the robustness and stability of the masked pruning
model. The generated mask is used to train the FL model, achieving significant
bandwidth savings. We present an extensive experimental study demonstrating the
superior performance of MPFL compared to existing methods. Additionally, we
have developed an open-source software package for the benefit of researchers
and developers in related fields.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03891" title="Abstract">arXiv:2312.03891</a> [<a href="/pdf/2312.03891" title="Download PDF">pdf</a>, <a href="/ps/2312.03891" title="Download PostScript">ps</a>, <a href="/format/2312.03891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of Infrastructure-based Warning System on Driving Behaviors-A  Roundabout Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+C">Chi Tian</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+T">Tianfang Han</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hang Li</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yiheng Feng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yunfeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Proctor%2C+R+W">Robert W. Proctor</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiansong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Smart intersections have the potential to improve road safety with sensing,
communication, and edge computing technologies. Perception sensors installed at
a smart intersection can monitor the traffic environment in real time and send
infrastructure-based warnings to nearby travelers through V2X communication.
This paper investigated how infrastructure-based warnings can influence driving
behaviors and improve roundabout safety through a driving-simulator study - a
challenging driving scenario for human drivers. A co-simulation platform
integrating Simulation of Urban Mobility (SUMO) and Webots was developed to
serve as the driving simulator. A real-world roundabout in Ann Arbor, Michigan
was built in the co-simulation platform as the study area, and the merging
scenarios were investigated. 36 participants were recruited and asked to
navigate the roundabout under three danger levels (e.g., low, medium, high) and
three collision warning designs (e.g., no warning, warning issued 1 second in
advance, warning issued 2 seconds in advance). Results indicated that advanced
warnings can significantly enhance safety by minimizing potential risks
compared to scenarios without warnings. Earlier warnings enabled smoother
driver responses and reduced abrupt decelerations. In addition, a personalized
intention prediction model was developed to predict drivers' stop-or-go
decisions when the warning is displayed. Among all tested machine learning
models, the XGBoost model achieved the highest prediction accuracy with a
precision rate of 95.56% and a recall rate of 97.73%.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03893" title="Abstract">arXiv:2312.03893</a> [<a href="/pdf/2312.03893" title="Download PDF">pdf</a>, <a href="/format/2312.03893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deliberative Technology for Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Konya%2C+A">Andrew Konya</a>, 
<a href="/search/cs?searchtype=author&query=Turan%2C+D">Deger Turan</a>, 
<a href="/search/cs?searchtype=author&query=Ovadya%2C+A">Aviv Ovadya</a>, 
<a href="/search/cs?searchtype=author&query=Qui%2C+L">Lina Qui</a>, 
<a href="/search/cs?searchtype=author&query=Masood%2C+D">Daanish Masood</a>, 
<a href="/search/cs?searchtype=author&query=Devine%2C+F">Flynn Devine</a>, 
<a href="/search/cs?searchtype=author&query=Schirch%2C+L">Lisa Schirch</a>, 
<a href="/search/cs?searchtype=author&query=Roberts%2C+I">Isabella Roberts</a>, 
<a href="/search/cs?searchtype=author&query=Forum%2C+D+A">Deliberative Alignment Forum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">For humanity to maintain and expand its agency into the future, the most
powerful systems we create must be those which act to align the future with the
will of humanity. The most powerful systems today are massive institutions like
governments, firms, and NGOs. Deliberative technology is already being used
across these institutions to help align governance and diplomacy with human
will, and modern AI is poised to make this technology significantly better. At
the same time, the race to superhuman AGI is already underway, and the AI
systems it gives rise to may become the most powerful systems of the future.
Failure to align the impact of such powerful AI with the will of humanity may
lead to catastrophic consequences, while success may unleash abundance. Right
now, there is a window of opportunity to use deliberative technology to align
the impact of powerful AI with the will of humanity. Moreover, it may be
possible to engineer a symbiotic coupling between powerful AI and deliberative
alignment systems such that the quality of alignment improves as AI
capabilities increase.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03896" title="Abstract">arXiv:2312.03896</a> [<a href="/pdf/2312.03896" title="Download PDF">pdf</a>, <a href="/format/2312.03896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Tight Threshold Bound for Search Trees with 2-way Comparisons
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atalig%2C+S">Sunny Atalig</a>, 
<a href="/search/cs?searchtype=author&query=Chrobak%2C+M">Marek Chrobak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study search trees with 2-way comparisons (2WCST's), which involve
separate less-than and equal-to tests in their nodes, each test having two
possible outcomes, yes and no. These trees have a much subtler structure than
standard search trees with 3-way comparisons (3WCST's) and are still not well
understood, hampering progress towards designing an efficient algorithm for
computing minimum-cost trees. One question that attracted attention in the past
is whether there is an easy way to determine which type of comparison should be
applied at any step of the search. Anderson, Kannan, Karloff and Ladner studied
this in terms of the ratio between the maximum and total key weight, and
defined two threshold values: $\lambda^-$ is the largest ratio that forces the
less-than test, and $\lambda^+$ is the smallest ratio that forces the equal-to
test. They determined that $\lambda^- = 1/4$, but for the higher threshold they
only showed that $\lambda^+\in [3/7,4/9]$. We give the tight bound for the
higher threshold, by proving that in fact $\lambda^+ = 3/7$.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03897" title="Abstract">arXiv:2312.03897</a> [<a href="/pdf/2312.03897" title="Download PDF">pdf</a>, <a href="/format/2312.03897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting the Optimality of Word Lengths
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pimentel%2C+T">Tiago Pimentel</a>, 
<a href="/search/cs?searchtype=author&query=Meister%2C+C">Clara Meister</a>, 
<a href="/search/cs?searchtype=author&query=Wilcox%2C+E+G">Ethan Gotlieb Wilcox</a>, 
<a href="/search/cs?searchtype=author&query=Mahowald%2C+K">Kyle Mahowald</a>, 
<a href="/search/cs?searchtype=author&query=Cotterell%2C+R">Ryan Cotterell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Zipf (1935) posited that wordforms are optimized to minimize utterances'
communicative costs. Under the assumption that cost is given by an utterance's
length, he supported this claim by showing that words' lengths are inversely
correlated with their frequencies. Communicative cost, however, can be
operationalized in different ways. Piantadosi et al. (2011) claim that cost
should be measured as the distance between an utterance's information rate and
channel capacity, which we dub the channel capacity hypothesis (CCH) here.
Following this logic, they then proposed that a word's length should be
proportional to the expected value of its surprisal (negative log-probability
in context). In this work, we show that Piantadosi et al.'s derivation does not
minimize CCH's cost, but rather a lower bound, which we term CCH-lower. We
propose a novel derivation, suggesting an improved way to minimize CCH's cost.
Under this method, we find that a language's word lengths should instead be
proportional to the surprisal's expectation plus its variance-to-mean ratio.
Experimentally, we compare these three communicative cost functions: Zipf's,
CCH-lower , and CCH. Across 13 languages and several experimental settings, we
find that length is better predicted by frequency than either of the other
hypotheses. In fact, when surprisal's expectation, or expectation plus
variance-to-mean ratio, is estimated using better language models, it leads to
worse word length predictions. We take these results as evidence that Zipf's
longstanding hypothesis holds.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03901" title="Abstract">arXiv:2312.03901</a> [<a href="/pdf/2312.03901" title="Download PDF">pdf</a>, <a href="/format/2312.03901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Redrawing the 2012 map of the Maryland congressional districts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+N">Noah Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Hyunwoo Park</a>, 
<a href="/search/cs?searchtype=author&query=Shim%2C+S">Sangho Shim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, to be submitted to IISE 2024 Annual Conference Proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Gerrymandering is the practice of drawing biased electoral maps that
manipulate the voter population to gain an advantage. The most recent time
gerrymandering became an issue was 2019 when the U.S. Federal Supreme Court
decided that the court does not have the authority to dictate how to draw the
district map and state legislators are the ones who should come up with an
electoral district plan. We solve the political districting problem and redraw
the 2012 map of Maryland congressional districts which raised the issue in
2019.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03903" title="Abstract">arXiv:2312.03903</a> [<a href="/pdf/2312.03903" title="Download PDF">pdf</a>, <a href="/format/2312.03903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Dependency Learning Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sriramulu%2C+A">Abishek Sriramulu</a>, 
<a href="/search/cs?searchtype=author&query=Fourrier%2C+N">Nicolas Fourrier</a>, 
<a href="/search/cs?searchtype=author&query=Bergmeir%2C+C">Christoph Bergmeir</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Information Sciences, 625, 700-714 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph Neural Networks (GNN) have recently gained popularity in the
forecasting domain due to their ability to model complex spatial and temporal
patterns in tasks such as traffic forecasting and region-based demand
forecasting. Most of these methods require a predefined graph as input, whereas
in real-life multivariate time series problems, a well-predefined dependency
graph rarely exists. This requirement makes it harder for GNNs to be utilised
widely for multivariate forecasting problems in other domains such as retail or
energy. In this paper, we propose a hybrid approach combining neural networks
and statistical structure learning models to self-learn the dependencies and
construct a dynamically changing dependency graph from multivariate data aiming
to enable the use of GNNs for multivariate forecasting even when a well-defined
graph does not exist. The statistical structure modeling in conjunction with
neural networks provides a well-principled and efficient approach by bringing
in causal semantics to determine dependencies among the series. Finally, we
demonstrate significantly improved performance using our proposed approach on
real-world benchmark datasets without a pre-defined dependency graph.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03905" title="Abstract">arXiv:2312.03905</a> [<a href="/pdf/2312.03905" title="Download PDF">pdf</a>, <a href="/format/2312.03905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Pseudo-Semantic Loss for Autoregressive Models with Logical  Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+K">Kareem Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kai-Wei Chang</a>, 
<a href="/search/cs?searchtype=author&query=Van+den+Broeck%2C+G">Guy Van den Broeck</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Neuro-symbolic AI bridges the gap between purely symbolic and neural
approaches to learning. This often requires maximizing the likelihood of a
symbolic constraint w.r.t the neural network's output distribution. Such output
distributions are typically assumed to be fully-factorized. This limits the
applicability of neuro-symbolic learning to the more expressive autoregressive
distributions, e.g., transformers. Under such distributions, computing the
likelihood of even simple constraints is #P-hard. Instead of attempting to
enforce the constraint on the entire output distribution, we propose to do so
on a random, local approximation thereof. More precisely, we optimize the
likelihood of the constraint under a pseudolikelihood-based approximation
centered around a model sample. Our approximation is factorized, allowing the
reuse of solutions to sub-problems, a main tenet for efficiently computing
neuro-symbolic losses. Moreover, it is a local, high-fidelity approximation of
the likelihood, exhibiting low entropy and KL-divergence around the model
sample. We evaluate our approach on Sudoku and shortest-path prediction cast as
autoregressive generation, and observe that we greatly improve upon the base
model's ability to predict logically-consistent outputs. We also evaluate on
the task of detoxifying large language models. Using a simple constraint
disallowing a list of toxic words, we are able to steer the model's outputs
away from toxic generations, achieving SoTA detoxification compared to previous
approaches.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03906" title="Abstract">arXiv:2312.03906</a> [<a href="/pdf/2312.03906" title="Download PDF">pdf</a>, <a href="/ps/2312.03906" title="Download PostScript">ps</a>, <a href="/format/2312.03906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing the Volume of a Restricted Independent Set Polytope  Deterministically
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gamarnik%2C+D">David Gamarnik</a>, 
<a href="/search/cs?searchtype=author&query=Smedira%2C+D">Devin Smedira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO); Probability (math.PR)

</div>
<p class="mathjax">We construct a quasi-polynomial time deterministic approximation algorithm
for computing the volume of an independent set polytope with restrictions.
Randomized polynomial time approximation algorithms for computing the volume of
a convex body have been known now for several decades, but the corresponding
deterministic counterparts are not available, and our algorithm is the first of
this kind. The class of polytopes for which our algorithm applies arises as
linear programming relaxation of the independent set problem with the
additional restriction that each variable takes value in the interval
$[0,1-\alpha]$ for some $\alpha&lt;1/2$. (We note that the $\alpha\ge 1/2$ case is
trivial).
<br />We use the correlation decay method for this problem applied to its
appropriate and natural discretization. The method works provided $\alpha&gt;
1/2-O(1/\Delta^2)$, where $\Delta$ is the maximum degree of the graph. When
$\Delta=3$ (the sparsest non-trivial case), our method works provided
$0.488&lt;\alpha&lt;0.5$. Interestingly, the interpolation method, which is based on
analyzing complex roots of the associated partition functions, fails even in
the trivial case when the underlying graph is a singleton.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03908" title="Abstract">arXiv:2312.03908</a> [<a href="/pdf/2312.03908" title="Download PDF">pdf</a>, <a href="/format/2312.03908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Theory of Irrotational Contact Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castro%2C+A">Alejandro Castro</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xuchen Han</a>, 
<a href="/search/cs?searchtype=author&query=Masterjohn%2C+J">Joseph Masterjohn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computational Engineering, Finance, and Science (cs.CE); Mathematical Physics (math-ph)

</div>
<p class="mathjax">We present a framework that enables to write a family of convex
approximations of complex contact models. Within this framework, we show that
we can incorporate well established and experimentally validated contact models
such as the Hunt &amp; Crossley model. Moreover, we show how to incorporate
Coulomb's law and the principle of maximum dissipation using a regularized
model of friction. Contrary to common wisdom that favors the use of rigid
contact models, our convex formulation is robust and performant even at high
stiffness values far beyond that of materials such as steel. Therefore, the
same formulation enables the modeling of compliant surfaces such as rubber
gripper pads or robot feet as well as hard objects. We characterize and
evaluate our approximations in a number of tests cases. We report their
properties and highlight limitations.
<br />Finally, we demonstrate robust simulation of robotic tasks at interactive
rates, with accurately resolved stiction and contact transitions, as required
for meaningful sim-to-real transfer. Our method is implemented in the open
source robotics toolkit Drake.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03911" title="Abstract">arXiv:2312.03911</a> [<a href="/pdf/2312.03911" title="Download PDF">pdf</a>, <a href="/format/2312.03911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Gradient-guided Nested Sampling for Posterior Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lemos%2C+P">Pablo Lemos</a>, 
<a href="/search/cs?searchtype=author&query=Malkin%2C+N">Nikolay Malkin</a>, 
<a href="/search/cs?searchtype=author&query=Handley%2C+W">Will Handley</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>, 
<a href="/search/cs?searchtype=author&query=Hezaveh%2C+Y">Yashar Hezaveh</a>, 
<a href="/search/cs?searchtype=author&query=Perreault-Levasseur%2C+L">Laurence Perreault-Levasseur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures. Code available at <a href="https://github.com/Pablo-Lemos/GGNS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation (stat.CO); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">We present a performant, general-purpose gradient-guided nested sampling
algorithm, ${\tt GGNS}$, combining the state of the art in differentiable
programming, Hamiltonian slice sampling, clustering, mode separation, dynamic
nested sampling, and parallelization. This unique combination allows ${\tt
GGNS}$ to scale well with dimensionality and perform competitively on a variety
of synthetic and real-world problems. We also show the potential of combining
nested sampling with generative flow networks to obtain large amounts of
high-quality samples from the posterior distribution. This combination leads to
faster mode discovery and more accurate estimates of the partition function.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03912" title="Abstract">arXiv:2312.03912</a> [<a href="/pdf/2312.03912" title="Download PDF">pdf</a>, <a href="/format/2312.03912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaboration or Corporate Capture? Quantifying NLP&#x27;s Reliance on  Industry Artifacts and Contributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aitken%2C+W">Will Aitken</a>, 
<a href="/search/cs?searchtype=author&query=Abdalla%2C+M">Mohamed Abdalla</a>, 
<a href="/search/cs?searchtype=author&query=Rudie%2C+K">Karen Rudie</a>, 
<a href="/search/cs?searchtype=author&query=Stinson%2C+C">Catherine Stinson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The advent of transformers, higher computational budgets, and big data has
engendered remarkable progress in Natural Language Processing (NLP). Impressive
performance of industry pre-trained models has garnered public attention in
recent years and made news headlines. That these are industry models is
noteworthy. Rarely, if ever, are academic institutes producing exciting new NLP
models. Using these models is critical for competing on NLP benchmarks and
correspondingly to stay relevant in NLP research. We surveyed 100 papers
published at EMNLP 2022 to determine whether this phenomenon constitutes a
reliance on industry for NLP publications.
<br />We find that there is indeed a substantial reliance. Citations of industry
artifacts and contributions across categories is at least three times greater
than industry publication rates per year. Quantifying this reliance does not
settle how we ought to interpret the results. We discuss two possible
perspectives in our discussion: 1) Is collaboration with industry still
collaboration in the absence of an alternative? Or 2) has free NLP inquiry been
captured by the motivations and research direction of private corporations?
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03913" title="Abstract">arXiv:2312.03913</a> [<a href="/pdf/2312.03913" title="Download PDF">pdf</a>, <a href="/format/2312.03913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controllable Human-Object Interaction Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaman Li</a>, 
<a href="/search/cs?searchtype=author&query=Clegg%2C+A">Alexander Clegg</a>, 
<a href="/search/cs?searchtype=author&query=Mottaghi%2C+R">Roozbeh Mottaghi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Puig%2C+X">Xavier Puig</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C+K">C. Karen Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project webpage: <a href="https://lijiaman.github.io/projects/chois/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Synthesizing semantic-aware, long-horizon, human-object interaction is
critical to simulate realistic human behaviors. In this work, we address the
challenging problem of generating synchronized object motion and human motion
guided by language descriptions in 3D scenes. We propose Controllable
Human-Object Interaction Synthesis (CHOIS), an approach that generates object
motion and human motion simultaneously using a conditional diffusion model
given a language description, initial object and human states, and sparse
object waypoints. While language descriptions inform style and intent,
waypoints ground the motion in the scene and can be effectively extracted using
high-level planning methods. Naively applying a diffusion model fails to
predict object motion aligned with the input waypoints and cannot ensure the
realism of interactions that require precise hand-object contact and
appropriate contact grounded by the floor. To overcome these problems, we
introduce an object geometry loss as additional supervision to improve the
matching between generated object motion and input object waypoints. In
addition, we design guidance terms to enforce contact constraints during the
sampling process of the trained diffusion model.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03918" title="Abstract">arXiv:2312.03918</a> [<a href="/pdf/2312.03918" title="Download PDF">pdf</a>, <a href="/format/2312.03918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Safety vs. App Privacy: Comparing the Usability of Android and iOS  Privacy Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yanzi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Juneja%2C+J">Jaideep Juneja</a>, 
<a href="/search/cs?searchtype=author&query=Birrell%2C+E">Eleanor Birrell</a>, 
<a href="/search/cs?searchtype=author&query=Cranor%2C+L">Lorrie Cranor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Privacy labels -- standardized, compact representations of data collection
and data use practices -- have frequently been recommended as a solution to the
shortcomings of privacy policies. Apple introduced mandatory privacy labels for
apps in its App Store in December 2020; Google introduced data safety labels
for Android apps in July 2022. iOS app privacy labels have been evaluated and
critiqued in prior work. In this work, we evaluated Android data safety labels
and explored how differences between the two label designs impact user
comprehension and label utility. We conducted a between-subjects,
semi-structured interview study with 12 Android users and 12 iOS users. While
some users found Android Data Safety Labels informative and helpful, other
users found them too vague. Compared to iOS App Privacy Labels, Android users
found the distinction between data collection groups more intuitive and found
explicit inclusion of omitted data collection groups more salient. However,
some users expressed skepticism regarding elided information about collected
data type categories. Most users missed critical information due to not
expanding the accordion interface, and they were surprised by collection
practices excluded from Android's definitions. Our findings also revealed that
Android users generally appreciated information about security practices
included in the labels and iOS users wanted that information added.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03920" title="Abstract">arXiv:2312.03920</a> [<a href="/pdf/2312.03920" title="Download PDF">pdf</a>, <a href="/format/2312.03920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Closed Payment Networks on the Lightning Network: Dual  Central Node Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jeffy Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 8 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">The Lightning Network, known for its millisecond settlement speeds and low
transaction fees, offers a compelling alternative to traditional payment
processors, which often have higher fees and longer processing times. This is
particularly significant for the unbanked population, which lacks access to
standard financial services. Our research targets businesses looking to shift
their client to client payment processes, such as B2B invoicing, remittances,
and cross-border transactions, to the Lightning Network. We compare the
efficiency of interconnected mesh nodes (complete graph topology) with central
routing nodes (star graph topology), with a specific focus on the dual central
node approach. This approach introduces features like circular rebalancing,
redundancy, and a closed network system. Through a basic SimPy model, we assess
the network's throughput in a 100 node scenario. While this approach
centralizes a technology initially designed for decentralization, it fosters
broader enterprise adoption of Bitcoin-based payment networks and encourages
participation in the decentralized financial ecosystem. Our study also
considers the regulatory implications of using central routing nodes, possibly
classified as payment processors under Money Transmission Laws (MTL). These
findings aim to contribute to the discourse on the Lightning Network's
application in business, highlighting its potential to drive shifts in
financial technology towards more decentralized systems.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03924" title="Abstract">arXiv:2312.03924</a> [<a href="/pdf/2312.03924" title="Download PDF">pdf</a>, <a href="/ps/2312.03924" title="Download PostScript">ps</a>, <a href="/format/2312.03924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating Traditional CS Class Activities with Computing for Social  Good, Ethics, and Communication and Leadership Skills
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cortinovis%2C+R">Renato Cortinovis</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+D">Devender Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Capretz%2C+L+F">Luiz Fernando Capretz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34th Annual Workshop of the Psychology of Programming Interest Group (PPIG 2023), pp. 169-177, Lund, Sweden, August 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Software and information technologies are becoming increasingly integrated
and pervasive in human society and range from automated decision making and
social media and entertainment, to running critical social and physical
infrastructures like government programs, utilities, and financial
institutions. As a result, there is a growing awareness of the need to develop
professionals who will harness these technologies in fair and inclusive ways
and use them to address global issues like health, water management, poverty,
and human rights. In this regard, many academic researchers have expressed the
need to complement traditional teaching of CS technical skills with computer
and information ethics (computing for social good), as well as communication
and leadership skills. In this paper, we describe our goals and some possible
class activities we have developed and refined over the past few years with
encouraging results, to help CS students understand the potential uses of
computing for social good. In these carefully planned project assignments, we
seamlessly integrate traditional approaches to develop technical skills with
broader professional responsibility and soft skills. We then discuss the
lessons learned from these activities and briefly outline future plans.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03927" title="Abstract">arXiv:2312.03927</a> [<a href="/pdf/2312.03927" title="Download PDF">pdf</a>, <a href="/format/2312.03927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A fast numerical algorithm for finding all real solutions to a system of  N nonlinear equations in a finite domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chueca-Diez%2C+F">Fernando Chueca-Diez</a>, 
<a href="/search/eess?searchtype=author&query=Ganan-Calvo%2C+A+M">Alfonso M. Ganan-Calvo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">A highly recurrent traditional bottleneck in applied mathematics, for which
the most popular codes (Mathematica and Matlab) do not offer a solution, is to
find all the real solutions of a system of N nonlinear equations in a certain
finite domain of the N-dimensional space of variables. We present an algorithm
of minimum length and computational weight to solve this problem, resembling a
graphical tool of edge detection in an image extended to N dimensions. Once the
hypersurfaces (edges) defined by each nonlinear equation have been identified
in a single, simultaneous step, the coincidence of the hypersurfaces in the
vicinity of all the hyperpoints that constitute the solutions makes the final
Newton-Raphson step rapidly convergent to all the solutions with the desired
degree of accuracy. As long as N remains smaller than about five, which is
often the case for physical systems that depend on fewer than five parameters,
this approach demonstrates excellent effectiveness.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03928" title="Abstract">arXiv:2312.03928</a> [<a href="/pdf/2312.03928" title="Download PDF">pdf</a>, <a href="/format/2312.03928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Weighted Co-Learning for Cross-Domain Few-Shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alchihabi%2C+A">Abdullah Alchihabi</a>, 
<a href="/search/cs?searchtype=author&query=Heidari%2C+M">Marzi Heidari</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuhong Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Due to the availability of only a few labeled instances for the novel target
prediction task and the significant domain shift between the well annotated
source domain and the target domain, cross-domain few-shot learning (CDFSL)
induces a very challenging adaptation problem. In this paper, we propose a
simple Adaptive Weighted Co-Learning (AWCoL) method to address the CDFSL
challenge by adapting two independently trained source prototypical
classification models to the target task in a weighted co-learning manner. The
proposed method deploys a weighted moving average prediction strategy to
generate probabilistic predictions from each model, and then conducts adaptive
co-learning by jointly fine-tuning the two models in an alternating manner
based on the pseudo-labels and instance weights produced from the predictions.
Moreover, a negative pseudo-labeling regularizer is further deployed to improve
the fine-tuning process by penalizing false predictions. Comprehensive
experiments are conducted on multiple benchmark datasets and the empirical
results demonstrate that the proposed method produces state-of-the-art CDFSL
performance.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03930" title="Abstract">arXiv:2312.03930</a> [<a href="/pdf/2312.03930" title="Download PDF">pdf</a>, <a href="/ps/2312.03930" title="Download PostScript">ps</a>, <a href="/format/2312.03930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis and preconditioning of a probabilistic domain decomposition  algorithm for elliptic boundary value problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bernal%2C+F">Francisco Bernal</a>, 
<a href="/search/math?searchtype=author&query=Mor%C3%B3n-Vidal%2C+J">Jorge Mor&#xf3;n-Vidal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">PDDSparse is a new hybrid parallelisation scheme for solving large-scale
elliptic boundary value problems on supercomputers, which can be described as a
Feynman-Kac formula for domain decomposition. At its core lies a stochastic
linear, sparse system for the solutions on the interfaces, whose entries are
generated via Monte Carlo simulations. Assuming small statistical errors, we
show that the random system matrix ${\tilde G}(\omega)$ is near a nonsingular
M-matrix $G$, i.e. ${\tilde G}(\omega)+E=G$ where $||E||/||G||$ is small. Using
nonstandard arguments, we bound $||G^{-1}||$ and the condition number of $G$,
showing that both of them grow moderately with the degrees of freedom of the
discretisation. Moreover, the truncated Neumann series of $G^{-1}$ -- which is
straightforward to calculate -- is the basis for an excellent preconditioner
for ${\tilde G}(\omega)$. These findings are supported by numerical evidence.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03936" title="Abstract">arXiv:2312.03936</a> [<a href="/pdf/2312.03936" title="Download PDF">pdf</a>, <a href="/format/2312.03936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Potential of Vision-Language Models for Content Moderation of  Children&#x27;s Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S+H">Syed Hammad Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shengnan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Sukthankar%2C+G">Gita Sukthankar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure. Accepted at IEEE ICMLA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Natural language supervision has been shown to be effective for zero-shot
learning in many computer vision tasks, such as object detection and activity
recognition. However, generating informative prompts can be challenging for
more subtle tasks, such as video content moderation. This can be difficult, as
there are many reasons why a video might be inappropriate, beyond violence and
obscenity. For example, scammers may attempt to create junk content that is
similar to popular educational videos but with no meaningful information. This
paper evaluates the performance of several CLIP variations for content
moderation of children's cartoons in both the supervised and zero-shot setting.
We show that our proposed model (Vanilla CLIP with Projection Layer)
outperforms previous work conducted on the Malicious or Benign (MOB) benchmark
for video content moderation. This paper presents an in depth analysis of how
context-specific language prompts affect content moderation performance. Our
results indicate that it is important to include more context in content
moderation prompts, particularly for cartoon videos as they are not well
represented in the CLIP training data.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03938" title="Abstract">arXiv:2312.03938</a> [<a href="/pdf/2312.03938" title="Download PDF">pdf</a>, <a href="/format/2312.03938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapting HouseDiffusion for conditional Floor Plan generation on  Modified Swiss Dwellings dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuhn%2C+E">Emanuel Kuhn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Automated floor plan generation has recently gained momentum with several
methods that have been proposed. The CVAAD Floor Plan Auto-Completion workshop
challenge introduced MSD, a new dataset that includes existing structural walls
of the building as an additional input constraint. This technical report
presents an approach for extending a recent work, HouseDiffusion
(<a href="/abs/2211.13287">arXiv:2211.13287</a> [cs.CV]), to the MSD dataset. The adaption involves modifying
the model's transformer layers to condition on a set of wall lines. The report
introduces a pre-processing pipeline to extract wall lines from the binary mask
of the building structure provided as input. Additionally, it was found that a
data processing procedure that simplifies all room polygons to rectangles leads
to better performance. This indicates that future work should explore better
representations of variable-length polygons in diffusion models. The code will
be made available at a later date.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03940" title="Abstract">arXiv:2312.03940</a> [<a href="/pdf/2312.03940" title="Download PDF">pdf</a>, <a href="/format/2312.03940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PECANN: Parallel Efficient Clustering with Graph-Based Approximate  Nearest Neighbor Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shangdi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Engels%2C+J">Joshua Engels</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yihao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shun%2C+J">Julian Shun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper studies density-based clustering of point sets. These methods use
dense regions of points to detect clusters of arbitrary shapes. In particular,
we study variants of density peaks clustering, a popular type of algorithm that
has been shown to work well in practice. Our goal is to cluster large
high-dimensional datasets, which are prevalent in practice. Prior solutions are
either sequential, and cannot scale to large data, or are specialized for
low-dimensional data.
<br />This paper unifies the different variants of density peaks clustering into a
single framework, PECANN, by abstracting out several key steps common to this
class of algorithms. One such key step is to find nearest neighbors that
satisfy a predicate function, and one of the main contributions of this paper
is an efficient way to do this predicate search using graph-based approximate
nearest neighbor search (ANNS). To provide ample parallelism, we propose a
doubling search technique that enables points to find an approximate nearest
neighbor satisfying the predicate in a small number of rounds. Our technique
can be applied to many existing graph-based ANNS algorithms, which can all be
plugged into PECANN.
<br />We implement five clustering algorithms with PECANN and evaluate them on
synthetic and real-world datasets with up to 1.28 million points and up to 1024
dimensions on a 30-core machine with two-way hyper-threading. Compared to the
state-of-the-art FASTDP algorithm for high-dimensional density peaks
clustering, which is sequential, our best algorithm is 45x-734x faster while
achieving competitive ARI scores. Compared to the state-of-the-art parallel
DPC-based algorithm, which is optimized for low dimensions, we show that PECANN
is two orders of magnitude faster. As far as we know, our work is the first to
evaluate DPC variants on large high-dimensional real-world image and text
embedding datasets.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03946" title="Abstract">arXiv:2312.03946</a> [<a href="/pdf/2312.03946" title="Download PDF">pdf</a>, <a href="/format/2312.03946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Layer-Wise Tokens-to-Token Transformer Network for Improved Historical  Document Image Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biswas%2C+R">Risab Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+S+K">Swalpa Kumar Roy</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+U">Umapada Pal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2312.03568">arXiv:2312.03568</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Document image enhancement is a fundamental and important stage for attaining
the best performance in any document analysis assignment because there are many
degradation situations that could harm document images, making it more
difficult to recognize and analyze them. In this paper, we propose
\textbf{T2T-BinFormer} which is a novel document binarization encoder-decoder
architecture based on a Tokens-to-token vision transformer. Each image is
divided into a set of tokens with a defined length using the ViT model, which
is then applied several times to model the global relationship between the
tokens. However, the conventional tokenization of input data does not
adequately reflect the crucial local structure between adjacent pixels of the
input image, which results in low efficiency. Instead of using a simple ViT and
hard splitting of images for the document image enhancement task, we employed a
progressive tokenization technique to capture this local information from an
image to achieve more effective results. Experiments on various DIBCO and
H-DIBCO benchmarks demonstrate that the proposed model outperforms the existing
CNN and ViT-based state-of-the-art methods. In this research, the primary area
of examination is the application of the proposed architecture to the task of
document binarization. The source code will be made available at
https://github.com/RisabBiswas/T2T-BinFormer.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03950" title="Abstract">arXiv:2312.03950</a> [<a href="/pdf/2312.03950" title="Download PDF">pdf</a>, <a href="/format/2312.03950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Scalable and Generalizable Pathloss Map Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Ju-Hyung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Molisch%2C+A+F">Andreas F. Molisch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Large-scale channel prediction, i.e., estimation of the pathloss from
geographical/morphological/building maps, is an essential component of wireless
network planning. Ray tracing (RT)-based methods have been widely used for many
years, but they require significant computational effort that may become
prohibitive with the increased network densification and/or use of higher
frequencies in B5G/6G systems. In this paper, we propose a data-driven,
model-free pathloss map prediction (PMP) method, called PMNet. PMNet uses a
supervised learning approach: it is trained on a limited amount of RT (or
channel measurement) data and map data. Once trained, PMNet can predict
pathloss over location with high accuracy (an RMSE level of $10^{-2}$) in a few
milliseconds. We further extend PMNet by employing transfer learning (TL). TL
allows PMNet to learn a new network scenario quickly (x5.6 faster training) and
efficiently (using x4.5 less data) by transferring knowledge from a pre-trained
model, while retaining accuracy. Our results demonstrate that PMNet is a
scalable and generalizable ML-based PMP method, showing its potential to be
used in several network optimization applications.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03951" title="Abstract">arXiv:2312.03951</a> [<a href="/pdf/2312.03951" title="Download PDF">pdf</a>, <a href="/format/2312.03951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Role of Optimization in Double Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C+Y">Chris Yuhao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Flanigan%2C+J">Jeffrey Flanigan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS Workshop 2023 Optimization for Machine Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">The phenomenon of model-wise double descent, where the test error peaks and
then reduces as the model size increases, is an interesting topic that has
attracted the attention of researchers due to the striking observed gap between
theory and practice \citep{Belkin2018ReconcilingMM}. Additionally, while double
descent has been observed in various tasks and architectures, the peak of
double descent can sometimes be noticeably absent or diminished, even without
explicit regularization, such as weight decay and early stopping. In this
paper, we investigate this intriguing phenomenon from the optimization
perspective and propose a simple optimization-based explanation for why double
descent sometimes occurs weakly or not at all. To the best of our knowledge, we
are the first to demonstrate that many disparate factors contributing to
model-wise double descent (initialization, normalization, batch size, learning
rate, optimization algorithm) are unified from the viewpoint of optimization:
model-wise double descent is observed if and only if the optimizer can find a
sufficiently low-loss minimum. These factors directly affect the condition
number of the optimization problem or the optimizer and thus affect the final
minimum found by the optimizer, reducing or increasing the height of the double
descent peak. We conduct a series of controlled experiments on random feature
models and two-layer neural networks under various optimization settings,
demonstrating this optimization-based unified view. Our results suggest the
following implication: Double descent is unlikely to be a problem for
real-world machine learning setups. Additionally, our results help explain the
gap between weak double descent peaks in practice and strong peaks observable
in carefully designed setups.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03964" title="Abstract">arXiv:2312.03964</a> [<a href="/pdf/2312.03964" title="Download PDF">pdf</a>, <a href="/ps/2312.03964" title="Download PostScript">ps</a>, <a href="/format/2312.03964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Ranging with IEEE 802.15.4z HRP UWB
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiliang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Kalkanli%2C+C">Cem Kalkanli</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+P">Pengcheng Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+M">Moche Cohen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the 45th IEEE Symposium on Security and Privacy, MAY 20-23, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Secure ranging refers to the capability of upper-bounding the actual physical
distance between two devices with reliability. This is essential in a variety
of applications, including to unlock physical systems. In this work, we will
look at secure ranging in the context of ultra-wideband impulse radio (UWB-IR)
as specified in IEEE 802.15.4z (a.k.a. 4z). In particular, an encrypted
waveform, i.e. the scrambled timestamp sequence (STS), is defined in the high
rate pulse repetition frequency (HRP) mode of operation in 4z for secure
ranging. This work demonstrates the security analysis of 4z HRP when
implemented with an adequate receiver design and shows the STS waveform can
enable secure ranging. We first review the STS receivers adopted in previous
studies and analyze their security vulnerabilities. Then we present a reference
STS receiver and prove that secure ranging can be achieved by employing the STS
waveform in 4z HRP. The performance bounds of the reference secure STS receiver
are also characterized. Numerical experiments corroborate the analyses and
demonstrate the security of the reference STS receiver.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03966" title="Abstract">arXiv:2312.03966</a> [<a href="/pdf/2312.03966" title="Download PDF">pdf</a>, <a href="/ps/2312.03966" title="Download PostScript">ps</a>, <a href="/format/2312.03966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impostor Phenomenon in Software Engineers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guenes%2C+P">Paloma Guenes</a>, 
<a href="/search/cs?searchtype=author&query=Tomaz%2C+R">Rafael Tomaz</a>, 
<a href="/search/cs?searchtype=author&query=Kalinowski%2C+M">Marcos Kalinowski</a>, 
<a href="/search/cs?searchtype=author&query=Baldassarre%2C+M+T">Maria Teresa Baldassarre</a>, 
<a href="/search/cs?searchtype=author&query=Storey%2C+M">Margaret-Anne Storey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint with the original submission accepted for publication at ICSE-SEIS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The Impostor Phenomenon (IP) is widely discussed in Science, Technology,
Engineering, and Mathematics (STEM) and has been evaluated in Computer Science
students. However, formal research on IP in software engineers has yet to be
conducted, although its impacts may lead to mental disorders such as depression
and burnout. This study describes a survey that investigates the extent of
impostor feelings in software engineers, considering aspects such as gender,
race/ethnicity, and roles. Furthermore, we investigate the influence of IP on
their perceived productivity. The survey instrument was designed using a
theory-driven approach and included demographic questions, an internationally
validated IP scale, and questions for measuring perceived productivity based on
the SPACE framework constructs. The survey was sent to companies operating in
various business sectors. Data analysis used bootstrapping with resampling to
calculate confidence intervals and Mann-Whitney statistical significance
testing for assessing the hypotheses. We received responses from 624 software
engineers from 26 countries. The bootstrapping results reveal that a proportion
of 52.7% of software engineers experience frequent to intense levels of IP and
that women suffer at a significantly higher proportion (60.6%) than men
(48.8%). Regarding race/ethnicity, we observed more frequent impostor feelings
in Asian (67.9%) and Black (65.1%) than in White (50.0%) software engineers. We
also observed that the presence of IP is less common among individuals who are
married and have children. Moreover, the prevalence of IP showed a
statistically significant negative effect on the perceived productivity for all
SPACE framework constructs. The evidence relating IP to software engineers
provides a starting point to help organizations find ways to raise awareness of
the problem and improve the emotional skills of software professionals.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03970" title="Abstract">arXiv:2312.03970</a> [<a href="/pdf/2312.03970" title="Download PDF">pdf</a>, <a href="/format/2312.03970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Medical Report Generation with Adapter Tuning and Knowledge  Enhancement in Vision-Language Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shibin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zhiyu Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoqian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hairong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Medical report generation demands automatic creation of coherent and precise
descriptions for medical images. However, the scarcity of labelled medical
image-report pairs poses formidable challenges in developing large-scale neural
networks capable of harnessing the potential of artificial intelligence,
exemplified by large language models. This study builds upon the
state-of-the-art vision-language pre-training and fine-tuning approach, BLIP-2,
to customize general large-scale foundation models. Integrating adapter tuning
and a medical knowledge enhancement loss, our model significantly improves
accuracy and coherence. Validation on the dataset of ImageCLEFmedical 2023
demonstrates our model's prowess, achieving the best-averaged results against
several state-of-the-art methods. Significant improvements in ROUGE and CIDEr
underscore our method's efficacy, highlighting promising outcomes for the rapid
medical-domain adaptation of the vision-language foundation models in
addressing challenges posed by data scarcity.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03979" title="Abstract">arXiv:2312.03979</a> [<a href="/pdf/2312.03979" title="Download PDF">pdf</a>, <a href="/format/2312.03979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Node-aware Bi-smoothing: Certified Robustness against Graph Injection  Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">Yuni Lai</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yulin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+B">Bailin Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kai Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Deep Graph Learning (DGL) has emerged as a crucial technique across various
domains. However, recent studies have exposed vulnerabilities in DGL models,
such as susceptibility to evasion and poisoning attacks. While empirical and
provable robustness techniques have been developed to defend against graph
modification attacks (GMAs), the problem of certified robustness against graph
injection attacks (GIAs) remains largely unexplored. To bridge this gap, we
introduce the node-aware bi-smoothing framework, which is the first certifiably
robust approach for general node classification tasks against GIAs. Notably,
the proposed node-aware bi-smoothing scheme is model-agnostic and is applicable
for both evasion and poisoning attacks. Through rigorous theoretical analysis,
we establish the certifiable conditions of our smoothing scheme. We also
explore the practical implications of our node-aware bi-smoothing schemes in
two contexts: as an empirical defense approach against real-world GIAs and in
the context of recommendation systems. Furthermore, we extend two
state-of-the-art certified robustness frameworks to address node injection
attacks and compare our approach against them. Extensive evaluations
demonstrate the effectiveness of our proposed certificates.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03987" title="Abstract">arXiv:2312.03987</a> [<a href="/pdf/2312.03987" title="Download PDF">pdf</a>, <a href="/format/2312.03987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cost-Effective In-Context Learning for Entity Resolution: A Design Space  Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+M">Meihao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaoyue Han</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Ju Fan</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+C">Chengliang Chai</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+N">Nan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guoliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xiaoyong Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Entity resolution (ER) is an important data integration task with a wide
spectrum of applications. The state-of-the-art solutions on ER rely on
pre-trained language models (PLMs), which require fine-tuning on a lot of
labeled matching/non-matching entity pairs. Recently, large languages models
(LLMs), such as GPT-4, have shown the ability to perform many tasks without
tuning model parameters, which is known as in-context learning (ICL) that
facilitates effective learning from a few labeled input context demonstrations.
However, existing ICL approaches to ER typically necessitate providing a task
description and a set of demonstrations for each entity pair and thus have
limitations on the monetary cost of interfacing LLMs. To address the problem,
in this paper, we provide a comprehensive study to investigate how to develop a
cost-effective batch prompting approach to ER. We introduce a framework BATCHER
consisting of demonstration selection and question batching and explore
different design choices that support batch prompting for ER. We also devise a
covering-based demonstration selection strategy that achieves an effective
balance between matching accuracy and monetary cost. We conduct a thorough
evaluation to explore the design space and evaluate our proposed strategies.
Through extensive experiments, we find that batch prompting is very
cost-effective for ER, compared with not only PLM-based methods fine-tuned with
extensive labeled data but also LLM-based methods with manually designed
prompting. We also provide guidance for selecting appropriate design choices
for batch prompting.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03989" title="Abstract">arXiv:2312.03989</a> [<a href="/pdf/2312.03989" title="Download PDF">pdf</a>, <a href="/format/2312.03989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rapid detection of rare events from in situ X-ray diffraction data using  machine learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Weijian Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jun-Sang Park</a>, 
<a href="/search/cs?searchtype=author&query=Kenesei%2C+P">Peter Kenesei</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+A">Ahsan Ali</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengchun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Foster%2C+I+T">Ian T. Foster</a>, 
<a href="/search/cs?searchtype=author&query=Schwarz%2C+N">Nicholas Schwarz</a>, 
<a href="/search/cs?searchtype=author&query=Kettimuthu%2C+R">Rajkumar Kettimuthu</a>, 
<a href="/search/cs?searchtype=author&query=Miceli%2C+A">Antonino Miceli</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+H">Hemant Sharma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Materials Science (cond-mat.mtrl-sci); Image and Video Processing (eess.IV); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">High-energy X-ray diffraction methods can non-destructively map the 3D
microstructure and associated attributes of metallic polycrystalline
engineering materials in their bulk form. These methods are often combined with
external stimuli such as thermo-mechanical loading to take snapshots over time
of the evolving microstructure and attributes. However, the extreme data
volumes and the high costs of traditional data acquisition and reduction
approaches pose a barrier to quickly extracting actionable insights and
improving the temporal resolution of these snapshots. Here we present a fully
automated technique capable of rapidly detecting the onset of plasticity in
high-energy X-ray microscopy data. Our technique is computationally faster by
at least 50 times than the traditional approaches and works for data sets that
are up to 9 times sparser than a full data set. This new technique leverages
self-supervised image representation learning and clustering to transform
massive data into compact, semantic-rich representations of visually salient
characteristics (e.g., peak shapes). These characteristics can be a rapid
indicator of anomalous events such as changes in diffraction peak shapes. We
anticipate that this technique will provide just-in-time actionable information
to drive smarter experiments that effectively deploy multi-modal X-ray
diffraction methods that span many decades of length scales.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03991" title="Abstract">arXiv:2312.03991</a> [<a href="/pdf/2312.03991" title="Download PDF">pdf</a>, <a href="/format/2312.03991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MICRO: Model-Based Offline Reinforcement Learning with a Conservative  Bellman Operator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao-Yin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiao-Hu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guo-Tao Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+M">Mei-Jiang Gui</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+T">Tian-Yu Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">De-Xing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Z">Zeng-Guang Hou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Offline reinforcement learning (RL) faces a significant challenge of
distribution shift. Model-free offline RL penalizes the Q value for
out-of-distribution (OOD) data or constrains the policy closed to the behavior
policy to tackle this problem, but this inhibits the exploration of the OOD
region. Model-based offline RL, which uses the trained environment model to
generate more OOD data and performs conservative policy optimization within
that model, has become an effective method for this problem. However, the
current model-based algorithms rarely consider agent robustness when
incorporating conservatism into policy. Therefore, the new model-based offline
algorithm with a conservative Bellman operator (MICRO) is proposed. This method
trades off performance and robustness via introducing the robust Bellman
operator into the algorithm. Compared with previous model-based algorithms with
robust adversarial models, MICRO can significantly reduce the computation cost
by only choosing the minimal Q value in the state uncertainty set. Extensive
experiments demonstrate that MICRO outperforms prior RL algorithms in offline
RL benchmark and is considerably robust to adversarial perturbations.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03993" title="Abstract">arXiv:2312.03993</a> [<a href="/pdf/2312.03993" title="Download PDF">pdf</a>, <a href="/format/2312.03993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Style Transfer to Calvin and Hobbes comics using Stable Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shrestha%2C+S">Sloke Shrestha</a>, 
<a href="/search/cs?searchtype=author&query=S.%2C+S+S+V">Sundar Sripada V. S.</a>, 
<a href="/search/cs?searchtype=author&query=Venkataramanan%2C+A">Asvin Venkataramanan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project report for ECE 371Q Digital Image Processing at UT Austin
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This project report summarizes our journey to perform stable diffusion
fine-tuning on a dataset containing Calvin and Hobbes comics. The purpose is to
convert any given input image into the comic style of Calvin and Hobbes,
essentially performing style transfer. We train stable-diffusion-v1.5 using Low
Rank Adaptation (LoRA) to efficiently speed up the fine-tuning process. The
diffusion itself is handled by a Variational Autoencoder (VAE), which is a
U-net. Our results were visually appealing for the amount of training time and
the quality of input data that went into training.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03996" title="Abstract">arXiv:2312.03996</a> [<a href="/pdf/2312.03996" title="Download PDF">pdf</a>, <a href="/ps/2312.03996" title="Download PostScript">ps</a>, <a href="/format/2312.03996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable diffusion for Data Augmentation in COCO and Weed Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+B">Boyang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yuzhen Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generative models have increasingly impacted relative tasks ranging from
image revision and object detection in computer vision to interior design and
idea illustration in more general fields. Stable diffusion is an outstanding
model series that paves the way for producing high-resolution images with
thorough details from text prompts or reference images. It will be an
interesting topic about how to leverage the capability of stable diffusion to
elevate the image variations of certain categories (e.g., vehicles, humans, and
daily objects); particularly, it has the potential to gain improvements for
small datasets with image-sparse categories. This study utilized seven
categories in the popular COCO dataset and three widespread weed species in
Michigan to evaluate the efficiency of a recent version of stable diffusion. In
detail, Stable diffusion was used to generate synthetic images belonging to
these classes; then, YOLOv8 models were trained based on these synthetic
images, whose performance was compared to the models trained on original
images. In addition, several techniques (e.g., Image-to-image translation,
Dreambooth, ControlNet) of Stable diffusion were leveraged for image generation
with different focuses. In spite of the overall results being disappointing,
promising results have been achieved in some classes, illustrating the
potential of stable diffusion models to improve the performance of detection
models, which represent more helpful information being conveyed into the models
by the generated images. This seminal study may expedite the adaption of stable
diffusion models to classification and detection tasks in different fields.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03998" title="Abstract">arXiv:2312.03998</a> [<a href="/pdf/2312.03998" title="Download PDF">pdf</a>, <a href="/format/2312.03998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Series2Vec: Similarity-based Self-supervised Representation Learning for  Time Series Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Foumani%2C+N+M">Navid Mohammadi Foumani</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C+W">Chang Wei Tan</a>, 
<a href="/search/cs?searchtype=author&query=Webb%2C+G+I">Geoffrey I. Webb</a>, 
<a href="/search/cs?searchtype=author&query=Salehi%2C+M">Mahsa Salehi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We argue that time series analysis is fundamentally different in nature to
either vision or natural language processing with respect to the forms of
meaningful self-supervised learning tasks that can be defined. Motivated by
this insight, we introduce a novel approach called \textit{Series2Vec} for
self-supervised representation learning. Unlike other self-supervised methods
in time series, which carry the risk of positive sample variants being less
similar to the anchor sample than series in the negative set, Series2Vec is
trained to predict the similarity between two series in both temporal and
spectral domains through a self-supervised task. Series2Vec relies primarily on
the consistency of the unsupervised similarity step, rather than the intrinsic
quality of the similarity measurement, without the need for hand-crafted data
augmentation. To further enforce the network to learn similar representations
for similar time series, we propose a novel approach that applies
order-invariant attention to each representation within the batch during
training. Our evaluation of Series2Vec on nine large real-world datasets, along
with the UCR/UEA archive, shows enhanced performance compared to current
state-of-the-art self-supervised techniques for time series. Additionally, our
extensive experiments show that Series2Vec performs comparably with fully
supervised training and offers high efficiency in datasets with limited-labeled
data. Finally, we show that the fusion of Series2Vec with other representation
learning models leads to enhanced performance for time series classification.
Code and models are open-source at
\url{https://github.com/Navidfoumani/Series2Vec.}
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04000" title="Abstract">arXiv:2312.04000</a> [<a href="/pdf/2312.04000" title="Download PDF">pdf</a>, <a href="/format/2312.04000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiDAR: Sensing Linear Probing Performance in Joint Embedding SSL  Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thilak%2C+V">Vimal Thilak</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Saremi%2C+O">Omid Saremi</a>, 
<a href="/search/cs?searchtype=author&query=Dinh%2C+L">Laurent Dinh</a>, 
<a href="/search/cs?searchtype=author&query=Goh%2C+H">Hanlin Goh</a>, 
<a href="/search/cs?searchtype=author&query=Nakkiran%2C+P">Preetum Nakkiran</a>, 
<a href="/search/cs?searchtype=author&query=Susskind%2C+J+M">Joshua M. Susskind</a>, 
<a href="/search/cs?searchtype=author&query=Littwin%2C+E">Etai Littwin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Joint embedding (JE) architectures have emerged as a promising avenue for
acquiring transferable data representations. A key obstacle to using JE
methods, however, is the inherent challenge of evaluating learned
representations without access to a downstream task, and an annotated dataset.
Without efficient and reliable evaluation, it is difficult to iterate on
architectural and training choices for JE methods. In this paper, we introduce
LiDAR (Linear Discriminant Analysis Rank), a metric designed to measure the
quality of representations within JE architectures. Our metric addresses
several shortcomings of recent approaches based on feature covariance rank by
discriminating between informative and uninformative features. In essence,
LiDAR quantifies the rank of the Linear Discriminant Analysis (LDA) matrix
associated with the surrogate SSL task -- a measure that intuitively captures
the information content as it pertains to solving the SSL task. We empirically
demonstrate that LiDAR significantly surpasses naive rank based approaches in
its predictive power of optimal hyperparameters. Our proposed criterion
presents a more robust and intuitive means of assessing the quality of
representations within JE architectures, which we hope facilitates broader
adoption of these powerful techniques in various domains.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04004" title="Abstract">arXiv:2312.04004</a> [<a href="/pdf/2312.04004" title="Download PDF">pdf</a>, <a href="/format/2312.04004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Occlusion-based Detection of Trojan-triggering Inputs in Large Language  Models of Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hussain%2C+A">Aftab Hussain</a>, 
<a href="/search/cs?searchtype=author&query=Rabin%2C+M+R+I">Md Rafiqul Islam Rabin</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+T">Toufique Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Alipour%2C+M+A">Mohammad Amin Alipour</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bowen Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Large language models (LLMs) are becoming an integrated part of software
development. These models are trained on large datasets for code, where it is
hard to verify each data point. Therefore, a potential attack surface can be to
inject poisonous data into the training data to make models vulnerable, aka
trojaned. It can pose a significant threat by hiding manipulative behaviors
inside models, leading to compromising the integrity of the models in
downstream tasks.
<br />In this paper, we propose an occlusion-based human-in-the-loop technique,
OSeql, to distinguish trojan-triggering inputs of code. The technique is based
on the observation that trojaned neural models of code rely heavily on the
triggering part of input; hence, its removal would change the confidence of the
models in their prediction substantially. Our results suggest that OSeql can
detect the triggering inputs with almost 100% recall. We discuss the problem of
false positives and how to address them. These results provide a baseline for
future studies in this field.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04005" title="Abstract">arXiv:2312.04005</a> [<a href="/pdf/2312.04005" title="Download PDF">pdf</a>, <a href="/format/2312.04005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KOALA: Self-Attention Matters in Knowledge Distillation of Latent  Diffusion Models for Memory-Efficient and Fast Image Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Youngwan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+K">Kwanyong Park</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+Y">Yoorhim Cho</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yong-Ju Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+S+J">Sung Ju Hwang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://youngwanlee.github.io/KOALA/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Stable diffusion is the mainstay of the text-to-image (T2I) synthesis in the
community due to its generation performance and open-source nature. Recently,
Stable Diffusion XL (SDXL), the successor of stable diffusion, has received a
lot of attention due to its significant performance improvements with a higher
resolution of 1024x1024 and a larger model. However, its increased computation
cost and model size require higher-end hardware(e.g., bigger VRAM GPU) for
end-users, incurring higher costs of operation. To address this problem, in
this work, we propose an efficient latent diffusion model for text-to-image
synthesis obtained by distilling the knowledge of SDXL. To this end, we first
perform an in-depth analysis of the denoising U-Net in SDXL, which is the main
bottleneck of the model, and then design a more efficient U-Net based on the
analysis. Secondly, we explore how to effectively distill the generation
capability of SDXL into an efficient U-Net and eventually identify four
essential factors, the core of which is that self-attention is the most
important part. With our efficient U-Net and self-attention-based knowledge
distillation strategy, we build our efficient T2I models, called KOALA-1B &amp;
-700M, while reducing the model size up to 54% and 69% of the original SDXL
model. In particular, the KOALA-700M is more than twice as fast as SDXL while
still retaining a decent generation quality. We hope that due to its balanced
speed-performance tradeoff, our KOALA models can serve as a cost-effective
alternative to SDXL in resource-constrained environments.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04008" title="Abstract">arXiv:2312.04008</a> [<a href="/pdf/2312.04008" title="Download PDF">pdf</a>, <a href="/format/2312.04008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Natural-language-driven Simulation Benchmark and Copilot for Efficient  Production of Object Interactions in Virtual Road Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kairui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zihao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Gengjie Lin</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Haotian Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+D">Die Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Jibin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhecheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fupeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Z">Ziyun Bai</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Di Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We advocate the idea of the natural-language-driven(NLD) simulation to
efficiently produce the object interactions between multiple objects in the
virtual road scenes, for teaching and testing the autonomous driving systems
that should take quick action to avoid collision with obstacles with
unpredictable motions. The NLD simulation allows the brief natural-language
description to control the object interactions, significantly reducing the
human efforts for creating a large amount of interaction data. To facilitate
the research of NLD simulation, we collect the Language-to-Interaction(L2I)
benchmark dataset with 120,000 natural-language descriptions of object
interactions in 6 common types of road topologies. Each description is
associated with the programming code, which the graphic render can use to
visually reconstruct the object interactions in the virtual scenes. As a
methodology contribution, we design SimCopilot to translate the interaction
descriptions to the renderable code. We use the L2I dataset to evaluate
SimCopilot's abilities to control the object motions, generate complex
interactions, and generalize interactions across road topologies. The L2I
dataset and the evaluation results motivate the relevant research of the NLD
simulation.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04009" title="Abstract">arXiv:2312.04009</a> [<a href="/pdf/2312.04009" title="Download PDF">pdf</a>, <a href="/ps/2312.04009" title="Download PostScript">ps</a>, <a href="/format/2312.04009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Programmable Turbine Failsafe System for Pico-Hydroelectric Power in the  Nepal Himalayas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yeh%2C+H+J">Hsi-Jen James Yeh</a>, 
<a href="/search/eess?searchtype=author&query=Sturdivant%2C+R">Rick Sturdivant</a>, 
<a href="/search/eess?searchtype=author&query=Stambaugh%2C+M">Mark Stambaugh</a>, 
<a href="/search/eess?searchtype=author&query=Zahnd%2C+A">Alex Zahnd</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, we describe a novel turbine failsafe system designed for a
pico-hydroelectric power generation. We designed and built a pico-hydroelectric
system in a remote rural Himalayan village. We developed a Prioritized Load
Control System (PLCS) that diverts excess electrical power to useful purposes
such as heating up bath water and the air in the community center when the
electrical demand from the village is low; instead of dumping the excess
electricity back into the river in the form of heat. A critical part of the
PLCS system is the failsafe mechanism where the turbines and electrical
components on the grid are protected in case any part of the PLCS system stops
functioning, possibly intermittently. Our novel failsafe system contains the
following enhancements compared to previous systems: (1) adjustable threshold
voltage, (2) controllable fractional power diversion with adjustable
parameters, (3) automatic reset with adjustable parameters. In addition, the
failsafe subsystem uses the widely available Arduino platform and programming
environment, and JSON for human readable and writable communications,
demonstrating their suitability for critical applications.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04014" title="Abstract">arXiv:2312.04014</a> [<a href="/pdf/2312.04014" title="Download PDF">pdf</a>, <a href="/format/2312.04014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resilience-Assuring Hydrogen-Powered Microgrids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lin%2C+C">Chaofan Lin</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+X">Xiaonan Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Green hydrogen has shown great potential to power microgrids as a primary
source, yet the operation methodology under extreme events is still an open
area. To fill this gap, this letter establishes an operational optimization
strategy towards resilient hydrogen-powered microgrids, where the frequency and
voltage regulation characteristics of hydrogen sources under advanced controls
are accurately represented by piecewise linear constraints. The results show
that the new operation approach can output a safety-assured operation plan with
rational power change distribution and reduced frequency and voltage variation.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04016" title="Abstract">arXiv:2312.04016</a> [<a href="/pdf/2312.04016" title="Download PDF">pdf</a>, <a href="/ps/2312.04016" title="Download PostScript">ps</a>, <a href="/format/2312.04016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PartDistill: 3D Shape Part Segmentation by Vision-Language Model  Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Umam%2C+A">Ardian Umam</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cheng-Kun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Min-Hung Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chuang%2C+J">Jen-Hui Chuang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yen-Yu Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper proposes a cross-modal distillation framework, PartDistill, which
transfers 2D knowledge from vision-language models (VLMs) to facilitate 3D
shape part segmentation. PartDistill addresses three major challenges in this
task: the lack of 3D segmentation in invisible or undetected regions in the 2D
projections, inaccurate and inconsistent 2D predictions by VLMs, and the lack
of knowledge accumulation across different 3D shapes. PartDistill consists of a
teacher network that uses a VLM to make 2D predictions and a student network
that learns from the 2D predictions while extracting geometrical features from
multiple 3D shapes to carry out 3D part segmentation. A bi-directional
distillation, including forward and backward distillations, is carried out
within the framework, where the former forward distills the 2D predictions to
the student network, and the latter improves the quality of the 2D predictions,
which subsequently enhances the final 3D part segmentation. Moreover,
PartDistill can exploit generative models that facilitate effortless 3D shape
creation for generating knowledge sources to be distilled. Through extensive
experiments, PartDistill boosts the existing methods with substantial margins
on widely used ShapeNetPart and PartE datasets, by more than 15% and 12% higher
mIoU scores, respectively.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04018" title="Abstract">arXiv:2312.04018</a> [<a href="/pdf/2312.04018" title="Download PDF">pdf</a>, <a href="/format/2312.04018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ricci-Notation Tensor Framework for Model-Based Approaches to Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joseph%2C+D">Dileepan Joseph</a> (Electrical and Computer Engineering, University of Alberta)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 5 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Software (cs.MS)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Model-based approaches to imaging, like specialized image enhancements in
astronomy, favour physics-based models which facilitate explanations of
relationships between observed inputs and computed outputs. While this paper
features a tutorial example, inspired by exoplanet imaging, that reveals
embedded 2D fast Fourier transforms in an image enhancement model, the work is
actually about the tensor algebra and software, or tensor frameworks, available
for model-based imaging. The paper proposes a Ricci-notation tensor (RT)
framework, comprising an extended Ricci notation, which aligns well with the
symbolic dual-index algebra of non-Euclidean geometry, and codesigned
object-oriented software, called the RTToolbox for MATLAB. Extensions offer
novel representations for entrywise, pagewise, and broadcasting operations
popular in extended matrix-vector (EMV) frameworks for imaging. Complementing
the EMV algebra computable with MATLAB, the RTToolbox demonstrates programmatic
and computational efficiency thanks to careful design of tensor and dual-index
classes. Compared to a numeric tensor predecessor, the RT framework enables
superior ways to model imaging problems and, thereby, to develop solutions.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04021" title="Abstract">arXiv:2312.04021</a> [<a href="/pdf/2312.04021" title="Download PDF">pdf</a>, <a href="/format/2312.04021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study on the Calibration of In-context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanlin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi-Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yaodong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Madeka%2C+D">Dhruv Madeka</a>, 
<a href="/search/cs?searchtype=author&query=Foster%2C+D">Dean Foster</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+E">Eric Xing</a>, 
<a href="/search/cs?searchtype=author&query=Lakkaraju%2C+H">Hima Lakkaraju</a>, 
<a href="/search/cs?searchtype=author&query=Kakade%2C+S">Sham Kakade</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Spotlight Talk at NeurIPS 2023 Workshop on Failure Modes in the Age of Foundation Models
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Modern auto-regressive language models are trained to minimize log loss on
broad data by predicting the next token so they are expected to get calibrated
answers when framing a problem as a next-token prediction task. We study this
for in-context learning (ICL), a widely used way to adapt frozen large language
models (LLMs) via crafting prompts, and investigate the trade-offs between
performance and calibration on a wide range of natural language understanding
and reasoning tasks. We conduct extensive experiments to show that such
trade-offs may get worse as we increase model size, incorporate more ICL
examples, and fine-tune models using instruction, dialog, or reinforcement
learning from human feedback (RLHF) on carefully curated datasets. Furthermore,
we find that common recalibration techniques that are widely effective such as
temperature scaling provide limited gains in calibration errors, suggesting
that new methods may be required for settings where models are expected to be
reliable.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04024" title="Abstract">arXiv:2312.04024</a> [<a href="/pdf/2312.04024" title="Download PDF">pdf</a>, <a href="/format/2312.04024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> k* Distribution: Evaluating the Latent Space of Deep Neural Networks  using Local Neighborhood Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kotyan%2C+S">Shashank Kotyan</a>, 
<a href="/search/cs?searchtype=author&query=Tatsuya%2C+U">Ueda Tatsuya</a>, 
<a href="/search/cs?searchtype=author&query=Vargas%2C+D+V">Danilo Vasconcellos Vargas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Most examinations of neural networks' learned latent spaces typically employ
dimensionality reduction techniques such as t-SNE or UMAP. While these methods
effectively capture the overall sample distribution in the entire learned
latent space, they tend to distort the structure of sample distributions within
specific classes in the subset of the latent space. This distortion complicates
the task of easily distinguishing classes identifiable by neural networks. In
response to this challenge, we introduce the k* Distribution methodology. This
approach focuses on capturing the characteristics and structure of sample
distributions for individual classes within the subset of the learned latent
space using local neighborhood analysis. The key concept is to facilitate easy
comparison of different k* distributions, enabling analysis of how various
classes are processed by the same neural network. This provides a more profound
understanding of existing contemporary visualizations. Our study reveals three
distinct distributions of samples within the learned latent space subset: a)
Fractured, b) Overlapped, and c) Clustered. We note and demonstrate that the
distribution of samples within the network's learned latent space significantly
varies depending on the class. Furthermore, we illustrate that our analysis can
be applied to explore the latent space of diverse neural network architectures,
various layers within neural networks, transformations applied to input
samples, and the distribution of training and testing data for neural networks.
We anticipate that our approach will facilitate more targeted investigations
into neural networks by collectively examining the distribution of different
samples within the learned latent space.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04025" title="Abstract">arXiv:2312.04025</a> [<a href="/pdf/2312.04025" title="Download PDF">pdf</a>, <a href="/format/2312.04025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Moirai: Towards Optimal Placement for Distributed Inference on  Heterogeneous Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Beibei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hongwei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+F">Feng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhihui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S+X">Sean Xiaoyang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The escalating size of Deep Neural Networks (DNNs) has spurred a growing
research interest in hosting and serving DNN models across multiple devices. A
number of studies have been reported to partition a DNN model across devices,
providing device placement solutions. The methods appeared in the literature,
however, either suffer from poor placement performance due to the exponential
search space or miss an optimal placement as a consequence of the reduced
search space with limited heuristics. Moreover, these methods have ignored the
runtime inter-operator optimization of a computation graph when coarsening the
graph, which degrades the end-to-end inference performance. This paper presents
Moirai that better exploits runtime inter-operator fusion in a model to render
a coarsened computation graph, reducing the search space while maintaining the
inter-operator optimization provided by inference backends. Moirai also
generalizes the device placement algorithm from multiple perspectives by
considering inference constraints and device heterogeneity.Extensive
experimental evaluation with 11 large DNNs demonstrates that Moirai outperforms
the state-of-the-art counterparts, i.e., Placeto, m-SCT, and GETF, up to
4.28$\times$ in reduction of the end-to-end inference latency. Moirai code is
anonymously released at \url{https://github.com/moirai-placement/moirai}.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04027" title="Abstract">arXiv:2312.04027</a> [<a href="/pdf/2312.04027" title="Download PDF">pdf</a>, <a href="/ps/2312.04027" title="Download PostScript">ps</a>, <a href="/format/2312.04027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The sample complexity of multi-distribution learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Binghui Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS); Machine Learning (stat.ML)

</div>
<p class="mathjax">Multi-distribution learning generalizes the classic PAC learning to handle
data coming from multiple distributions. Given a set of $k$ data distributions
and a hypothesis class of VC dimension $d$, the goal is to learn a hypothesis
that minimizes the maximum population loss over $k$ distributions, up to
$\epsilon$ additive error. In this paper, we settle the sample complexity of
multi-distribution learning by giving an algorithm of sample complexity
$\widetilde{O}((d+k)\epsilon^{-2}) \cdot (k/\epsilon)^{o(1)}$. This matches the
lower bound up to sub-polynomial factor and resolves the COLT 2023 open problem
of Awasthi, Haghtalab and Zhao [AHZ23].
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04028" title="Abstract">arXiv:2312.04028</a> [<a href="/pdf/2312.04028" title="Download PDF">pdf</a>, <a href="/format/2312.04028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ImFace++: A Sophisticated Nonlinear 3D Morphable Face Model with  Implicit Neural Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+M">Mingwu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haiyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Di Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 14 figures. arXiv admin note: text overlap with <a href="/abs/2203.14510">arXiv:2203.14510</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Accurate representations of 3D faces are of paramount importance in various
computer vision and graphics applications. However, the challenges persist due
to the limitations imposed by data discretization and model linearity, which
hinder the precise capture of identity and expression clues in current studies.
This paper presents a novel 3D morphable face model, named ImFace++, to learn a
sophisticated and continuous space with implicit neural representations.
ImFace++ first constructs two explicitly disentangled deformation fields to
model complex shapes associated with identities and expressions, respectively,
which simultaneously facilitate the automatic learning of correspondences
across diverse facial shapes. To capture more sophisticated facial details, a
refinement displacement field within the template space is further
incorporated, enabling a fine-grained learning of individual-specific facial
details. Furthermore, a Neural Blend-Field is designed to reinforce the
representation capabilities through adaptive blending of an array of local
fields. In addition to ImFace++, we have devised an improved learning strategy
to extend expression embeddings, allowing for a broader range of expression
variations. Comprehensive qualitative and quantitative evaluations demonstrate
that ImFace++ significantly advances the state-of-the-art in terms of both face
reconstruction fidelity and correspondence accuracy.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04029" title="Abstract">arXiv:2312.04029</a> [<a href="/pdf/2312.04029" title="Download PDF">pdf</a>, <a href="/format/2312.04029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Face Representation via Joint Label Classification and  Supervised Contrastive Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenduo Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Face clustering tasks can learn hierarchical semantic information from
large-scale data, which has the potential to help facilitate face recognition.
However, there are few works on this problem. This paper explores it by
proposing a joint optimization task of label classification and supervised
contrastive clustering to introduce the cluster knowledge to the traditional
face recognition task in two ways. We first extend ArcFace with a
cluster-guided angular margin to adjust the within-class feature distribution
according to the hard level of face clustering. Secondly, we propose a
supervised contrastive clustering approach to pull the features to the cluster
center and propose the cluster-aligning procedure to align the cluster center
and the learnable class center in the classifier for joint training. Finally,
extensive qualitative and quantitative experiments on popular facial benchmarks
demonstrate the effectiveness of our paradigm and its superiority over the
existing approaches to face recognition.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04030" title="Abstract">arXiv:2312.04030</a> [<a href="/pdf/2312.04030" title="Download PDF">pdf</a>, <a href="/format/2312.04030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Boundedly Rational Agents with Latent Inference Budgets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jacob%2C+A+P">Athul Paul Jacob</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhishek Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Andreas%2C+J">Jacob Andreas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We study the problem of modeling a population of agents pursuing unknown
goals subject to unknown computational constraints. In standard models of
bounded rationality, sub-optimal decision-making is simulated by adding
homoscedastic noise to optimal decisions rather than explicitly simulating
constrained inference. In this work, we introduce a latent inference budget
model (L-IBM) that models agents' computational constraints explicitly, via a
latent variable (inferred jointly with a model of agents' goals) that controls
the runtime of an iterative inference algorithm. L-IBMs make it possible to
learn agent models using data from diverse populations of suboptimal actors. In
three modeling tasks -- inferring navigation goals from routes, inferring
communicative intents from human utterances, and predicting next moves in human
chess games -- we show that L-IBMs match or outperform Boltzmann models of
decision-making under uncertainty. Inferred inference budgets are themselves
meaningful, efficient to compute, and correlated with measures of player skill,
partner skill and task difficulty.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04031" title="Abstract">arXiv:2312.04031</a> [<a href="/pdf/2312.04031" title="Download PDF">pdf</a>, <a href="/format/2312.04031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Importance of Coordinate Frames in Dynamic SLAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morris%2C+J">Jesse Morris</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiduo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ila%2C+V">Viorela Ila</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Most Simultaneous localisation and mapping (SLAM) systems have traditionally
assumed a static world, which does not align with real-world scenarios. To
enable robots to safely navigate and plan in dynamic environments, it is
essential to employ representations capable of handling moving objects. Dynamic
SLAM is an emerging field in SLAM research as it improves the overall system
accuracy while providing additional estimation of object motions.
State-of-the-art literature informs two main formulations for Dynamic SLAM,
representing dynamic object points in either the world or object coordinate
frame. While expressing object points in a local reference frame may seem
intuitive, it may not necessarily lead to the most accurate and robust
solutions. This paper conducts and presents a thorough analysis of various
Dynamic SLAM formulations, identifying the best approach to address the
problem. To this end, we introduce a front-end agnostic framework using GTSAM
that can be used to evaluate various Dynamic SLAM formulations.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04032" title="Abstract">arXiv:2312.04032</a> [<a href="/pdf/2312.04032" title="Download PDF">pdf</a>, <a href="/format/2312.04032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoAST: Robustifying Language Models via Adversarial Perturbation with  Selective Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jaehyung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yuning Mao</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+R">Rui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hanchao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+D">Davis Liang</a>, 
<a href="/search/cs?searchtype=author&query=Fung%2C+P">Pascale Fung</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fuli Feng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lifu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Khabsa%2C+M">Madian Khabsa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, accepted at EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Fine-tuning pre-trained language models (LMs) has become the de facto
standard in many NLP tasks. Nevertheless, fine-tuned LMs are still prone to
robustness issues, such as adversarial robustness and model calibration.
Several perspectives of robustness for LMs have been studied independently, but
lacking a unified consideration in multiple perspectives. In this paper, we
propose Robustifying LMs via Adversarial perturbation with Selective Training
(RoAST), a simple yet effective fine-tuning technique to enhance the
multi-perspective robustness of LMs in a unified way. RoAST effectively
incorporates two important sources for the model robustness, robustness on the
perturbed inputs and generalizable knowledge in pre-trained LMs. To be
specific, RoAST introduces adversarial perturbation during fine-tuning while
the model parameters are selectively updated upon their relative importance to
minimize unnecessary deviation. Under a unified evaluation of fine-tuned LMs by
incorporating four representative perspectives of model robustness, we
demonstrate the effectiveness of RoAST compared to state-of-the-art fine-tuning
methods on six different types of LMs, which indicates its usefulness in
practice.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04035" title="Abstract">arXiv:2312.04035</a> [<a href="/pdf/2312.04035" title="Download PDF">pdf</a>, <a href="/format/2312.04035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defense against ML-based Power Side-channel Attacks on DNN Accelerators  with Adversarial Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xiaobei Yan</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+C+H">Chip Hong Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Artificial Intelligence (AI) hardware accelerators have been widely adopted
to enhance the efficiency of deep learning applications. However, they also
raise security concerns regarding their vulnerability to power side-channel
attacks (SCA). In these attacks, the adversary exploits unintended
communication channels to infer sensitive information processed by the
accelerator, posing significant privacy and copyright risks to the models.
Advanced machine learning algorithms are further employed to facilitate the
side-channel analysis and exacerbate the privacy issue of AI accelerators.
Traditional defense strategies naively inject execution noise to the runtime of
AI models, which inevitably introduce large overheads.
<br />In this paper, we present AIAShield, a novel defense methodology to safeguard
FPGA-based AI accelerators and mitigate model extraction threats via
power-based SCAs. The key insight of AIAShield is to leverage the prominent
adversarial attack technique from the machine learning community to craft
delicate noise, which can significantly obfuscate the adversary's side-channel
observation while incurring minimal overhead to the execution of the protected
model. At the hardware level, we design a new module based on ring oscillators
to achieve fine-grained noise generation. At the algorithm level, we repurpose
Neural Architecture Search to worsen the adversary's extraction results.
Extensive experiments on the Nvidia Deep Learning Accelerator (NVDLA)
demonstrate that AIAShield outperforms existing solutions with excellent
transferability.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04036" title="Abstract">arXiv:2312.04036</a> [<a href="/pdf/2312.04036" title="Download PDF">pdf</a>, <a href="/format/2312.04036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffusionPhase: Motion Diffusion in Frequency Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+W">Weilin Wan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yiming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shutong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Komura%2C+T">Taku Komura</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jayaraman%2C+D">Dinesh Jayaraman</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingjie Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this study, we introduce a learning-based method for generating
high-quality human motion sequences from text descriptions (e.g., ``A person
walks forward"). Existing techniques struggle with motion diversity and smooth
transitions in generating arbitrary-length motion sequences, due to limited
text-to-motion datasets and the pose representations used that often lack
expressiveness or compactness. To address these issues, we propose the first
method for text-conditioned human motion generation in the frequency domain of
motions. We develop a network encoder that converts the motion space into a
compact yet expressive parameterized phase space with high-frequency details
encoded, capturing the local periodicity of motions in time and space with high
accuracy. We also introduce a conditional diffusion model for predicting
periodic motion parameters based on text descriptions and a start pose,
efficiently achieving smooth transitions between motion sequences associated
with different text descriptions. Experiments demonstrate that our approach
outperforms current methods in generating a broader variety of high-quality
motions, and synthesizing long sequences with natural transitions.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04037" title="Abstract">arXiv:2312.04037</a> [<a href="/pdf/2312.04037" title="Download PDF">pdf</a>, <a href="/format/2312.04037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Radar-Based Fall Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shuting Hu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Siyang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Toosizadeh%2C+N">Nima Toosizadeh</a>, 
<a href="/search/cs?searchtype=author&query=Barton%2C+J">Jennifer Barton</a>, 
<a href="/search/cs?searchtype=author&query=Hector%2C+M+G">Melvin G. Hector</a>, 
<a href="/search/cs?searchtype=author&query=Fain%2C+M+J">Mindy J. Fain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Fall detection, particularly critical for high-risk demographics like the
elderly, is a key public health concern where timely detection can greatly
minimize harm. With the advancements in radio frequency technology, radar has
emerged as a powerful tool for human detection and tracking. Traditional
machine learning algorithms, such as Support Vector Machines (SVM) and
k-Nearest Neighbors (kNN), have shown promising outcomes. However, deep
learning approaches, notably Convolutional Neural Networks (CNN) and Recurrent
Neural Networks (RNN), have outperformed in learning intricate features and
managing large, unstructured datasets. This survey offers an in-depth analysis
of radar-based fall detection, with emphasis on Micro-Doppler, Range-Doppler,
and Range-Doppler-Angles techniques. We discuss the intricacies and challenges
in fall detection and emphasize the necessity for a clear definition of falls
and appropriate detection criteria, informed by diverse influencing factors. We
present an overview of radar signal processing principles and the underlying
technology of radar-based fall detection, providing an accessible insight into
machine learning and deep learning algorithms. After examining 74 research
articles on radar-based fall detection published since 2000, we aim to bridge
current research gaps and underscore the potential future research strategies,
emphasizing the real-world applications possibility and the unexplored
potential of deep learning in improving radar-based fall detection.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04038" title="Abstract">arXiv:2312.04038</a> [<a href="/pdf/2312.04038" title="Download PDF">pdf</a>, <a href="/format/2312.04038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstruction of dynamical systems from data without time labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhijun Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+P">Pipi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+C">Chenglong Bao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zuoqiang Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Dynamical Systems (math.DS); Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this paper, we study the method to reconstruct dynamical systems from data
without time labels. Data without time labels appear in many applications, such
as molecular dynamics, single-cell RNA sequencing etc. Reconstruction of
dynamical system from time sequence data has been studied extensively. However,
these methods do not apply if time labels are unknown. Without time labels,
sequence data becomes distribution data. Based on this observation, we propose
to treat the data as samples from a probability distribution and try to
reconstruct the underlying dynamical system by minimizing the distribution
loss, sliced Wasserstein distance more specifically. Extensive experiment
results demonstrate the effectiveness of the proposed method.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04043" title="Abstract">arXiv:2312.04043</a> [<a href="/pdf/2312.04043" title="Download PDF">pdf</a>, <a href="/format/2312.04043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Doodle Your 3D: From Abstract Freehand Sketches to Precise 3D Shapes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bandyopadhyay%2C+H">Hmrishav Bandyopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Koley%2C+S">Subhadeep Koley</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Ayan Das</a>, 
<a href="/search/cs?searchtype=author&query=Sain%2C+A">Aneeshan Sain</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+P+N">Pinaki Nath Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+T">Tao Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Bhunia%2C+A+K">Ayan Kumar Bhunia</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yi-Zhe Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://hmrishavbandy.github.io/doodle23d/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we democratise 3D content creation, enabling precise
generation of 3D shapes from abstract sketches while overcoming limitations
tied to drawing skills. We introduce a novel part-level modelling and alignment
framework that facilitates abstraction modelling and cross-modal
correspondence. Leveraging the same part-level decoder, our approach seamlessly
extends to sketch modelling by establishing correspondence between CLIPasso
edgemaps and projected 3D part regions, eliminating the need for a dataset
pairing human sketches and 3D shapes. Additionally, our method introduces a
seamless in-position editing process as a byproduct of cross-modal part-aligned
modelling. Operating in a low-dimensional implicit space, our approach
significantly reduces computational demands and processing time.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04044" title="Abstract">arXiv:2312.04044</a> [<a href="/pdf/2312.04044" title="Download PDF">pdf</a>, <a href="/format/2312.04044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Residual Graph Convolutional Network for Bird&#x27;s-Eye-View Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qiuxiao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xiaojun Qi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, this paper has been accepted by and will be presented at the WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Retrieving spatial information and understanding the semantic information of
the surroundings are important for Bird's-Eye-View (BEV) semantic segmentation.
In the application of autonomous driving, autonomous vehicles need to be aware
of their surroundings to drive safely. However, current BEV semantic
segmentation techniques, deep Convolutional Neural Networks (CNNs) and
transformers, have difficulties in obtaining the global semantic relationships
of the surroundings at the early layers of the network. In this paper, we
propose to incorporate a novel Residual Graph Convolutional (RGC) module in
deep CNNs to acquire both the global information and the region-level semantic
relationship in the multi-view image domain. Specifically, the RGC module
employs a non-overlapping graph space projection to efficiently project the
complete BEV information into graph space. It then builds interconnected
spatial and channel graphs to extract spatial information between each node and
channel information within each node (i.e., extract contextual relationships of
the global features). Furthermore, it uses a downsample residual process to
enhance the coordinate feature reuse to maintain the global information. The
segmentation data augmentation and alignment module helps to simultaneously
augment and align BEV features and ground truth to geometrically preserve their
alignment to achieve better segmentation results. Our experimental results on
the nuScenes benchmark dataset demonstrate that the RGC network outperforms
four state-of-the-art networks and its four variants in terms of IoU and mIoU.
The proposed RGC network achieves a higher mIoU of 3.1% than the best
state-of-the-art network, BEVFusion. Code and models will be released.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04046" title="Abstract">arXiv:2312.04046</a> [<a href="/pdf/2312.04046" title="Download PDF">pdf</a>, <a href="/ps/2312.04046" title="Download PostScript">ps</a>, <a href="/format/2312.04046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Actuator with Magnetic Restoration, Part I: An Electromechanical  Model Including Eddy Currents, Identification, and Drive Circuit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mohammadi%2C+S">Sajjad Mohammadi</a>, 
<a href="/search/eess?searchtype=author&query=Benner%2C+W+R">William R. Benner</a>, 
<a href="/search/eess?searchtype=author&query=Kirtley%2C+J+L">James L. Kirtley</a>, 
<a href="/search/eess?searchtype=author&query=Lang%2C+J+H">Jeffrey H. Lang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Modeling, identification, drive, and current control loop of a
limited-rotation actuator with magnetic restoration is studied. Nonlinear and
linearized electromechanical models are developed for the design of the drive
as well as small and large signal controls of the actuator. To get higher
accuracy and an efficient design, the eddy-currents in the laminations and the
magnet are modeled by analytically solving the diffusion equation from which a
lumped-element circuit is derived for system-level analyses like control system
design. The impact of the pre-sliding friction is studied as well. Finite
element analysis is also employed. The actuator is prototyped and the
identification of the model is carried out. A close agreement is observed
between the results obtained from the model, FEM and experiment. Its
superiority over previous approaches are shown. Then, an op-amp-based drive is
proposed and designed. Afterward, a very accurate model for the drive and the
current loop is developed to be used as a simulation platform, while its
simplified version is obtained for design purposes. Part II of the paper is on
the evaluations and trade-offs of the current control as well as linear and
nonlinear position control.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04049" title="Abstract">arXiv:2312.04049</a> [<a href="/pdf/2312.04049" title="Download PDF">pdf</a>, <a href="/ps/2312.04049" title="Download PostScript">ps</a>, <a href="/format/2312.04049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Actuator with Magnetic Restoration, Part II: Model Evaluation and  Control Loops
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mohammadi%2C+S">Sajjad Mohammadi</a>, 
<a href="/search/eess?searchtype=author&query=Benner%2C+W+R">William R. Benner</a>, 
<a href="/search/eess?searchtype=author&query=Kirtley%2C+J+L">James L. Kirtley</a>, 
<a href="/search/eess?searchtype=author&query=Lang%2C+J+H">Jeffrey H. Lang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This is part II of a paper on modeling, design, drive, and control of an
actuator with magnetic restoration. In part I, nonlinear and linearized models
incorporating eddy currents and friction impacts were developed and employed in
the identification and were verified by FEM and an experimental prototype. A
drive circuit was also proposed, designed, and modeled to be employed in the
control loops. In part II, the accuracy of the modeling of the actuator and the
drive circuit is evaluated in control designs. The importance of eddy current
modeling is shown as well. Also, the effectiveness of the designed current loop
and its practical trade-offs are investigated. Then, three DSP-based position
control techniques are implemented and compared: pole placement with voltage
drive, placement with current drive, and nonlinear control with feed
linearization. Full-order and reduced-order observers are also employed to
estimate the unmeasured states. The control system designs are evaluated for
different applications through indices like rise time, overshoot and
steady-state error, and large-signal tracking in the step response as well as
bandwidth, robustness, phase margin, sensitivity, disturbance rejection, and
noise rejection in the frequency domain.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04051" title="Abstract">arXiv:2312.04051</a> [<a href="/pdf/2312.04051" title="Download PDF">pdf</a>, <a href="/ps/2312.04051" title="Download PostScript">ps</a>, <a href="/format/2312.04051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PLS is contained in PLC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ishizuka%2C+T">Takashi Ishizuka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">Recently, Pasarkar, Papadimitriou, and Yannakakis (ITCS 2023) have introduced
the new TFNP subclass called PLC that contains the class PPP; they also have
proven that several search problems related to extremal combinatorial
principles (e.g., Ramsey's theorem and the Sunflower lemma) belong to PLC. This
short paper shows that the class PLC also contains PLS, a complexity class for
TFNP problems that can be solved by a local search method. However, it is still
open whether PLC contains the class PPA.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04052" title="Abstract">arXiv:2312.04052</a> [<a href="/pdf/2312.04052" title="Download PDF">pdf</a>, <a href="/format/2312.04052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Misinformation Detection in a South African Social Media  Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Jager%2C+A">Amica De Jager</a>, 
<a href="/search/cs?searchtype=author&query=Marivate%2C+V">Vukosi Marivate</a>, 
<a href="/search/cs?searchtype=author&query=Modupe%2C+A">Abioudun Modupe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Artificial Intelligence Research. SACAIR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With the constant spread of misinformation on social media networks, a need
has arisen to continuously assess the veracity of digital content. This need
has inspired numerous research efforts on the development of misinformation
detection (MD) models. However, many models do not use all information
available to them and existing research contains a lack of relevant datasets to
train the models, specifically within the South African social media
environment. The aim of this paper is to investigate the transferability of
knowledge of a MD model between different contextual environments. This
research contributes a multimodal MD model capable of functioning in the South
African social media environment, as well as introduces a South African
misinformation dataset. The model makes use of multiple sources of information
for misinformation detection, namely: textual and visual elements. It uses
bidirectional encoder representations from transformers (BERT) as the textual
encoder and a residual network (ResNet) as the visual encoder. The model is
trained and evaluated on the Fakeddit dataset and a South African
misinformation dataset. Results show that using South African samples in the
training of the model increases model performance, in a South African
contextual environment, and that a multimodal model retains significantly more
knowledge than both the textual and visual unimodal models. Our study suggests
that the performance of a misinformation detection model is influenced by the
cultural nuances of its operating environment and multimodal models assist in
the transferability of knowledge between different contextual environments.
Therefore, local data should be incorporated into the training process of a
misinformation detection model in order to optimize model performance.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04053" title="Abstract">arXiv:2312.04053</a> [<a href="/pdf/2312.04053" title="Download PDF">pdf</a>, <a href="/ps/2312.04053" title="Download PostScript">ps</a>, <a href="/format/2312.04053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling and Design of a Double-Sided Linear Motor with Halbach Array  for Low-Vibration and High-Acceleration Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mohammadi%2C+S">Sajjad Mohammadi</a>, 
<a href="/search/eess?searchtype=author&query=Lang%2C+J+H">Jeffrey H. Lang</a>, 
<a href="/search/eess?searchtype=author&query=Kirtley%2C+J+L">James L. Kirtley</a>, 
<a href="/search/eess?searchtype=author&query=Trumper%2C+D+L">David L. Trumper</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, Amperian current and magnetic charge models of permanent
magnets are integrated into a hybrid approach to develop a comprehensive
analytical modeling for designing a slotless double-sided linear motor with an
arbitrary Halbach array. Unlike the conventional methods that treat magnets as
sources for Poisson's equations, the solution is reduced to Laplace's
equations, with magnets being represented as boundary conditions. The proposed
hybrid approach reduces the complexity of of the problem, requiring the
solution for only two or three regions compared to a large number of regions if
either Amperian currents or magnetic charges were utilized. The magnetic fields
and potentials within distinct regions, along with machine quantities such as
shear stress, force-angle characteristics, torque profile, attraction force,
misalignment force, and back-EMF, are derived, comprehensively analyzed, and
compared to FEM results for accuracy validation. Finally, a thorough
sensitivity analysis and design consideration of a linear stage for high
acceleration and low vibration applications is discussed.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04054" title="Abstract">arXiv:2312.04054</a> [<a href="/pdf/2312.04054" title="Download PDF">pdf</a>, <a href="/format/2312.04054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Queueing Delay Minimization in Overloaded Networks via Rate Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xinyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Dan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Modiano%2C+E">Eytan Modiano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">We develop link rate control policies to minimize the queueing delay of
packets in overloaded networks. We show that increasing link rates does not
guarantee delay reduction during overload. We consider a fluid queueing model
that facilitates explicit characterization of the queueing delay of packets,
and establish explicit conditions on link rates that can minimize the average
and maximum queueing delay in both single-hop and multi-stage (switching)
networks. These min-delay conditions require maintaining an identical ratio
between the ingress and egress rates of different nodes at the same layer of
the network. We term the policies that follow these conditions
rate-proportional policies. We further generalize the rate-proportional
policies to queue-proportional policies, which minimize the queueing delay
asymptotically based on the time-varying queue length while remaining agnostic
of packet arrival rates. We validate that the proposed policies lead to minimum
queueing delay under various network topologies and settings, compared with
benchmarks including the backpressure policy that maximizes network throughput
and the max-link-rate policy that fully utilizes bandwidth. We further remark
that the explicit min-delay policy design in multi-stage networks facilitates
co-optimization with other metrics, such as minimizing total bandwidth,
balancing link utilization and node buffer usage. This demonstrates the wider
utility of our main results in data center network optimization in practice.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04055" title="Abstract">arXiv:2312.04055</a> [<a href="/pdf/2312.04055" title="Download PDF">pdf</a>, <a href="/ps/2312.04055" title="Download PostScript">ps</a>, <a href="/format/2312.04055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jointly spatial-temporal representation learning for individual  trajectories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+J">Jianrong Lv</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yang Yue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 3 tables, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Individual trajectories, containing substantial information on
human-environment interactions across space and time, is a crucial input for
geospatial foundation models (GeoFMs). However, existing attempts, leveraging
trajectory data for various applications have overlooked the implicit
spatial-temporal dependency within trajectories and failed to encode and
represent it in a format friendly to deep learning, posing a challenge in
obtaining general-purpose trajectory representations. Therefore, this paper
proposes a spatial-temporal joint representation learning method (ST-GraphRL)
to formalize learnable spatial-temporal dependencies into trajectory
representations. The proposed ST-GraphRL consists of three compositions: (i) a
weighted directed spatial-temporal graph to explicitly construct mobility
interactions over both space and time dimensions; (ii) a two-stage jointly
encoder (i.e., decoupling and fusion) to learn entangled spatial-temporal
dependencies by independently decomposing and jointly aggregating space and
time information; (iii) a decoder guides ST-GraphRL to learn explicit mobility
regularities by simulating the spatial-temporal distributions of trajectories.
Tested on three real-world human mobility datasets, the proposed ST-GraphRL
outperformed all the baseline models in predicting movement spatial-temporal
distributions and preserving trajectory similarity with high spatial-temporal
correlations. We also explore how spatial-temporal features presented in latent
space, validating that ST-GraphRL understands spatial-temporal patterns. This
method is also transferable for general-purpose geospatial data representations
for broad downstream tasks, as well advancing GeoFMs developing.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04056" title="Abstract">arXiv:2312.04056</a> [<a href="/pdf/2312.04056" title="Download PDF">pdf</a>, <a href="/ps/2312.04056" title="Download PostScript">ps</a>, <a href="/format/2312.04056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Cost-Effective Test Bench for Evaluating Safe Human-Robot Interaction  in Mobile Robotics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fereydooni%2C+A">Atefeh Fereydooni</a>, 
<a href="/search/cs?searchtype=author&query=Azarakhsh%2C+A">Armin Azarakhsh</a>, 
<a href="/search/cs?searchtype=author&query=Shafiei%2C+A">Ayda Shafiei</a>, 
<a href="/search/cs?searchtype=author&query=Zandi%2C+H">Hesam Zandi</a>, 
<a href="/search/cs?searchtype=author&query=Delrobaei%2C+M">Mehdi Delrobaei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at the 11th RSI International Conference on Robotics and Mechatronics (ICRoM), Tehran, Iran, Dec. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Safety concerns have risen as robots become more integrated into our daily
lives and continue to interact closely with humans. One of the most crucial
safety priorities is preventing collisions between robots and people walking
nearby. Despite developing various algorithms to address this issue, evaluating
their effectiveness on a cost-effective test bench remains a significant
challenge. In this work, we propose a solution by introducing a simple yet
functional platform that enables researchers and developers to assess how
humans interact with mobile robots. This platform is designed to provide a
quick yet accurate evaluation of the performance of safe interaction algorithms
and make informed decisions for future development. The platform's features and
structure are detailed, along with the initial testing results using two
preliminary algorithms. The results obtained from the evaluation were
consistent with theoretical calculations, demonstrating its effectiveness in
assessing human-robot interaction. Our solution provides a preliminary yet
reliable approach to ensure the safety of both robots and humans in their daily
interactions.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04059" title="Abstract">arXiv:2312.04059</a> [<a href="/pdf/2312.04059" title="Download PDF">pdf</a>, <a href="/ps/2312.04059" title="Download PostScript">ps</a>, <a href="/format/2312.04059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing Large Language Model AI and Human-Generated Coaching Messages  for Behavioral Weight Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhuoran Huang</a>, 
<a href="/search/cs?searchtype=author&query=Berry%2C+M+P">Michael P. Berry</a>, 
<a href="/search/cs?searchtype=author&query=Chwyl%2C+C">Christina Chwyl</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+G">Gary Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jing Wei</a>, 
<a href="/search/cs?searchtype=author&query=Forman%2C+E+M">Evan M. Forman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Automated coaching messages for weight control can save time and costs, but
their repetitive, generic nature may limit their effectiveness compared to
human coaching. Large language model (LLM) based artificial intelligence (AI)
chatbots, like ChatGPT, could offer more personalized and novel messages to
address repetition with their data-processing abilities. While LLM AI
demonstrates promise to encourage healthier lifestyles, studies have yet to
examine the feasibility and acceptability of LLM-based BWL coaching. 87 adults
in a weight-loss trial rated ten coaching messages' helpfulness (five
human-written, five ChatGPT-generated) using a 5-point Likert scale, providing
additional open-ended feedback to justify their ratings. Participants also
identified which messages they believed were AI-generated. The evaluation
occurred in two phases: messages in Phase 1 were perceived as impersonal and
negative, prompting revisions for Phase 2 messages. In Phase 1, AI-generated
messages were rated less helpful than human-written ones, with 66 percent
receiving a helpfulness rating of 3 or higher. However, in Phase 2, the AI
messages matched the human-written ones regarding helpfulness, with 82% scoring
three or above. Additionally, 50% were misidentified as human-written,
suggesting AI's sophistication in mimicking human-generated content. A thematic
analysis of open-ended feedback revealed that participants appreciated AI's
empathy and personalized suggestions but found them more formulaic, less
authentic, and too data-focused. This study reveals the preliminary feasibility
and acceptability of LLM AIs, like ChatGPT, in crafting potentially effective
weight control coaching messages. Our findings also underscore areas for future
enhancement.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04060" title="Abstract">arXiv:2312.04060</a> [<a href="/pdf/2312.04060" title="Download PDF">pdf</a>, <a href="/format/2312.04060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Registration of Images and LiDAR Point Clouds with  VoxelPoint-to-Pixel Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Junsheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+B">Baorui Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yi Fang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu-Shen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhizhong Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at NeurIPS2023 (Spotlight). Code is available at <a href="https://github.com/junshengzhou/VP2P-Match">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Cross-modality registration between 2D images from cameras and 3D point
clouds from LiDARs is a crucial task in computer vision and robotic. Previous
methods estimate 2D-3D correspondences by matching point and pixel patterns
learned by neural networks, and use Perspective-n-Points (PnP) to estimate
rigid transformation during post-processing. However, these methods struggle to
map points and pixels to a shared latent space robustly since points and pixels
have very different characteristics with patterns learned in different manners
(MLP and CNN), and they also fail to construct supervision directly on the
transformation since the PnP is non-differentiable, which leads to unstable
registration results. To address these problems, we propose to learn a
structured cross-modality latent space to represent pixel features and 3D
features via a differentiable probabilistic PnP solver. Specifically, we design
a triplet network to learn VoxelPoint-to-Pixel matching, where we represent 3D
elements using both voxels and points to learn the cross-modality latent space
with pixels. We design both the voxel and pixel branch based on CNNs to operate
convolutions on voxels/pixels represented in grids, and integrate an additional
point branch to regain the information lost during voxelization. We train our
framework end-to-end by imposing supervisions directly on the predicted pose
distribution with a probabilistic PnP solver. To explore distinctive patterns
of cross-modality features, we design a novel loss with adaptive-weighted
optimization for cross-modality feature description. The experimental results
on KITTI and nuScenes datasets show significant improvements over the
state-of-the-art methods. The code and models are available at
https://github.com/junshengzhou/VP2P-Match.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04062" title="Abstract">arXiv:2312.04062</a> [<a href="/pdf/2312.04062" title="Download PDF">pdf</a>, <a href="/format/2312.04062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Low-Overhead Incorporation-Extrapolation based Few-Shot CSI Feedback  Framework for Massive MIMO Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Binggui Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jintao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shaodan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+F">Feifei Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guanghua Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 10 figures, 4 tables. This paper has been submitted to IEEE journal for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Accurate channel state information (CSI) is essential for downlink precoding
at the base station (BS), especially for frequency FDD wideband massive MIMO
systems with OFDM. In FDD systems, CSI is attained through CSI feedback from
the user equipment (UE). However, large-scale antennas and large number of
subcarriers significantly increase CSI feedback overhead. Deep learning-based
CSI feedback methods have received tremendous attention in recent years due to
their great capability of compressing CSI. Nonetheless, large amounts of
collected samples are required to train deep learning models, which is severely
challenging in practice. Besides, with the rapidly increasing number of
antennas and subcarriers, most of these deep learning methods' CSI feedback
overhead also grow dramatically, owing to their focus on full-dimensional CSI
feedback. To address this issue, in this paper, we propose a low-overhead
Incorporation-Extrapolation based Few-Shot CSI feedback Framework (IEFSF) for
massive MIMO systems. To further reduce the feedback overhead, a
low-dimensional eigenvector-based CSI matrix is first formed with the
incorporation process at the UE, and then recovered to the full-dimensional
eigenvector-based CSI matrix at the BS via the extrapolation process. After
that, to alleviate the necessity of the extensive collected samples and enable
few-shot CSI feedback, we further propose a knowledge-driven data augmentation
method and an artificial intelligence-generated content (AIGC) -based data
augmentation method by exploiting the domain knowledge of wireless channels and
by exploiting a novel generative model, respectively. Numerical results
demonstrate that the proposed IEFSF can significantly reduce CSI feedback
overhead by 16 times compared with existing CSI feedback methods while
maintaining higher feedback accuracy using only several hundreds of collected
samples.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04063" title="Abstract">arXiv:2312.04063</a> [<a href="/pdf/2312.04063" title="Download PDF">pdf</a>, <a href="/format/2312.04063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An unsupervised approach towards promptable defect segmentation in  laser-based additive manufacturing by Segment Anything
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Era%2C+I+Z">Israt Zarin Era</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+I">Imtiaz Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhichao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Srinjoy Das</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Foundation models are currently driving a paradigm shift in computer vision
tasks for various fields including biology, astronomy, and robotics among
others, leveraging user-generated prompts to enhance their performance. In the
manufacturing domain, accurate image-based defect segmentation is imperative to
ensure product quality and facilitate real-time process control. However, such
tasks are often characterized by multiple challenges including the absence of
labels and the requirement for low latency inference among others. To address
these issues, we construct a framework for image segmentation using a
state-of-the-art Vision Transformer (ViT) based Foundation model (Segment
Anything Model) with a novel multi-point prompt generation scheme using
unsupervised clustering. We apply our framework to perform real-time porosity
segmentation in a case study of laser base powder bed fusion (L-PBF) and obtain
high Dice Similarity Coefficients (DSC) without the necessity for any
supervised fine-tuning in the model. Using such lightweight foundation model
inference in conjunction with unsupervised prompt generation, we envision the
construction of a real-time anomaly detection pipeline that has the potential
to revolutionize the current laser-based additive manufacturing processes,
thereby facilitating the shift towards Industry 4.0 and promoting defect-free
production along with operational efficiency.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04065" title="Abstract">arXiv:2312.04065</a> [<a href="/pdf/2312.04065" title="Download PDF">pdf</a>, <a href="/ps/2312.04065" title="Download PostScript">ps</a>, <a href="/format/2312.04065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Robust and Efficient Boundary Point Detection Method by Measuring  Local Direction Dispersion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+D">Dehua Peng</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+Z">Zhipeng Gui</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Huayi Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Boundary points pose a significant challenge for machine learning tasks,
including classification, clustering, and dimensionality reduction. Due to the
similarity of features, boundary areas can result in mixed-up classes or
clusters, leading to a crowding problem in dimensionality reduction. To address
this challenge, numerous boundary point detection methods have been developed,
but they are insufficiently to accurately and efficiently identify the boundary
points in non-convex structures and high-dimensional manifolds. In this work,
we propose a robust and efficient method for detecting boundary points using
Local Direction Dispersion (LoDD). LoDD considers that internal points are
surrounded by neighboring points in all directions, while neighboring points of
a boundary point tend to be distributed only in a certain directional range.
LoDD adopts a density-independent K-Nearest Neighbors (KNN) method to determine
neighboring points, and defines a statistic-based metric using the eigenvalues
of the covariance matrix of KNN coordinates to measure the centrality of a
query point. We demonstrated the validity of LoDD on five synthetic datasets
(2-D and 3-D) and ten real-world benchmarks, and tested its clustering
performance by equipping with two typical clustering methods, K-means and Ncut.
Our results show that LoDD achieves promising and robust detection accuracy in
a time-efficient manner.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04066" title="Abstract">arXiv:2312.04066</a> [<a href="/pdf/2312.04066" title="Download PDF">pdf</a>, <a href="/format/2312.04066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combining inherent knowledge of vision-language models with unsupervised  domain adaptation through self-knowledge distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Westfechtel%2C+T">Thomas Westfechtel</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dexuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Harada%2C+T">Tatsuya Harada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unsupervised domain adaptation (UDA) tries to overcome the tedious work of
labeling data by leveraging a labeled source dataset and transferring its
knowledge to a similar but different target dataset. On the other hand, current
vision-language models exhibit astonishing zero-shot prediction capabilities.
In this work, we combine knowledge gained through UDA with the inherent
knowledge of vision-language models. In a first step, we generate the zero-shot
predictions of the source and target dataset using the vision-language model.
Since zero-shot predictions usually exhibit a large entropy, meaning that the
class probabilities are rather evenly distributed, we first adjust the
distribution to accentuate the winning probabilities. This is done using both
source and target data to keep the relative confidence between source and
target data. We then employ a conventional DA method, to gain the knowledge
from the source dataset, in combination with self-knowledge distillation, to
maintain the inherent knowledge of the vision-language model. We further
combine our method with a gradual source domain expansion strategy (GSDE) and
show that this strategy can also benefit by including zero-shot predictions. We
conduct experiments and ablation studies on three benchmarks (OfficeHome,
VisDA, and DomainNet) and outperform state-of-the-art methods. We further show
in ablation studies the contributions of different parts of our algorithm.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04067" title="Abstract">arXiv:2312.04067</a> [<a href="/pdf/2312.04067" title="Download PDF">pdf</a>, <a href="/ps/2312.04067" title="Download PostScript">ps</a>, <a href="/format/2312.04067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MeanCut: A Greedy-Optimized Graph Clustering via Path-based Similarity  and Degree Descent Criterion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+D">Dehua Peng</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+Z">Zhipeng Gui</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Huayi Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 8 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">As the most typical graph clustering method, spectral clustering is popular
and attractive due to the remarkable performance, easy implementation, and
strong adaptability. Classical spectral clustering measures the edge weights of
graph using pairwise Euclidean-based metric, and solves the optimal graph
partition by relaxing the constraints of indicator matrix and performing
Laplacian decomposition. However, Euclidean-based similarity might cause skew
graph cuts when handling non-spherical data distributions, and the relaxation
strategy introduces information loss. Meanwhile, spectral clustering requires
specifying the number of clusters, which is hard to determine without enough
prior knowledge. In this work, we leverage the path-based similarity to enhance
intra-cluster associations, and propose MeanCut as the objective function and
greedily optimize it in degree descending order for a nondestructive graph
partition. This algorithm enables the identification of arbitrary shaped
clusters and is robust to noise. To reduce the computational complexity of
similarity calculation, we transform optimal path search into generating the
maximum spanning tree (MST), and develop a fast MST (FastMST) algorithm to
further improve its time-efficiency. Moreover, we define a density gradient
factor (DGF) for separating the weakly connected clusters. The validity of our
algorithm is demonstrated by testifying on real-world benchmarks and
application of face recognition. The source code of MeanCut is available at
https://github.com/ZPGuiGroupWhu/MeanCut-Clustering.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04068" title="Abstract">arXiv:2312.04068</a> [<a href="/pdf/2312.04068" title="Download PDF">pdf</a>, <a href="/format/2312.04068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making Translators Privacy-aware on the User&#x27;s Side
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sato%2C+R">Ryoma Sato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose PRISM to enable users of machine translation systems to preserve
the privacy of data on their own initiative. There is a growing demand to apply
machine translation systems to data that require privacy protection. While
several machine translation engines claim to prioritize privacy, the extent and
specifics of such protection are largely ambiguous. First, there is often a
lack of clarity on how and to what degree the data is protected. Even if
service providers believe they have sufficient safeguards in place,
sophisticated adversaries might still extract sensitive information. Second,
vulnerabilities may exist outside of these protective measures, such as within
communication channels, potentially leading to data leakage. As a result, users
are hesitant to utilize machine translation engines for data demanding high
levels of privacy protection, thereby missing out on their benefits. PRISM
resolves this problem. Instead of relying on the translation service to keep
data safe, PRISM provides the means to protect data on the user's side. This
approach ensures that even machine translation engines with inadequate privacy
measures can be used securely. For platforms already equipped with privacy
safeguards, PRISM acts as an additional protection layer, reinforcing their
security furthermore. PRISM adds these privacy features without significantly
compromising translation accuracy. Our experiments demonstrate the
effectiveness of PRISM using real-world translators, T5 and ChatGPT
(GPT-3.5-turbo), and the datasets with two languages. PRISM effectively
balances privacy protection with translation accuracy.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04070" title="Abstract">arXiv:2312.04070</a> [<a href="/pdf/2312.04070" title="Download PDF">pdf</a>, <a href="/format/2312.04070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Transformer Model for Symbolic Regression towards Scientific Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lalande%2C+F">Florian Lalande</a>, 
<a href="/search/cs?searchtype=author&query=Matsubara%2C+Y">Yoshitomo Matsubara</a>, 
<a href="/search/cs?searchtype=author&query=Chiba%2C+N">Naoya Chiba</a>, 
<a href="/search/cs?searchtype=author&query=Taniai%2C+T">Tatsunori Taniai</a>, 
<a href="/search/cs?searchtype=author&query=Igarashi%2C+R">Ryo Igarashi</a>, 
<a href="/search/cs?searchtype=author&query=Ushiku%2C+Y">Yoshitala Ushiku</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for oral presentation at NeurIPS2023 AI4Science Workshop. OpenReview: <a href="https://openreview.net/forum?id=AIfqWNHKjo">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Symbolic Regression (SR) searches for mathematical expressions which best
describe numerical datasets. This allows to circumvent interpretation issues
inherent to artificial neural networks, but SR algorithms are often
computationally expensive. This work proposes a new Transformer model aiming at
Symbolic Regression particularly focused on its application for Scientific
Discovery. We propose three encoder architectures with increasing flexibility
but at the cost of column-permutation equivariance violation. Training results
indicate that the most flexible architecture is required to prevent from
overfitting. Once trained, we apply our best model to the SRSD datasets
(Symbolic Regression for Scientific Discovery datasets) which yields
state-of-the-art results using the normalized tree-based edit distance, at no
extra computational cost.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04071" title="Abstract">arXiv:2312.04071</a> [<a href="/pdf/2312.04071" title="Download PDF">pdf</a>, <a href="/format/2312.04071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synergistic Signals: Exploiting Co-Engagement and Semantic Links via  Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zijie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Baolin Li</a>, 
<a href="/search/cs?searchtype=author&query=Asgharzadeh%2C+H">Hafez Asgharzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Cocos%2C+A">Anne Cocos</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cox%2C+E">Evan Cox</a>, 
<a href="/search/cs?searchtype=author&query=Wise%2C+C">Colby Wise</a>, 
<a href="/search/cs?searchtype=author&query=Lamkhede%2C+S">Sudarshan Lamkhede</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Given a set of candidate entities (e.g. movie titles), the ability to
identify similar entities is a core capability of many recommender systems.
Most often this is achieved by collaborative filtering approaches, i.e. if
users co-engage with a pair of entities frequently enough, the embeddings
should be similar. However, relying on co-engagement data alone can result in
lower-quality embeddings for new and unpopular entities. We study this problem
in the context recommender systems at Netflix. We observe that there is
abundant semantic information such as genre, content maturity level, themes,
etc. that complements co-engagement signals and provides interpretability in
similarity models. To learn entity similarities from both data sources
holistically, we propose a novel graph-based approach called SemanticGNN.
SemanticGNN models entities, semantic concepts, collaborative edges, and
semantic edges within a large-scale knowledge graph and conducts representation
learning over it. Our key technical contributions are twofold: (1) we develop a
novel relation-aware attention graph neural network (GNN) to handle the
imbalanced distribution of relation types in our graph; (2) to handle web-scale
graph data that has millions of nodes and billions of edges, we develop a novel
distributed graph training paradigm. The proposed model is successfully
deployed within Netflix and empirical experiments indicate it yields up to 35%
improvement in performance on similarity judgment tasks.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04072" title="Abstract">arXiv:2312.04072</a> [<a href="/pdf/2312.04072" title="Download PDF">pdf</a>, <a href="/format/2312.04072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Voice Recognition Robot with Real-Time Surveillance and Automation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Basyal%2C+L">Lochan Basyal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 16 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Creative Research Thoughts (2018)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Voice recognition technology enables the execution of real-world operations
through a single voice command. This paper introduces a voice recognition
system that involves converting input voice signals into corresponding text
using an Android application. The text messages are then transmitted through
Bluetooth connectivity, serving as a communication platform. Simultaneously, a
controller circuit, equipped with a Bluetooth module, receives the text signal
and, following a coding mechanism, executes real-world operations. The paper
extends the application of voice recognition to real-time surveillance and
automation, incorporating obstacle detection and avoidance mechanisms, as well
as control over lighting and horn functions through predefined voice commands.
The proposed technique not only serves as an assistive tool for individuals
with disabilities but also finds utility in industrial automation, enabling
robots to perform specific tasks with precision.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04073" title="Abstract">arXiv:2312.04073</a> [<a href="/pdf/2312.04073" title="Download PDF">pdf</a>, <a href="/format/2312.04073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information Design for Hybrid Work under Infectious Disease Transmission  Risk
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+S">Sohil Shah</a>, 
<a href="/search/cs?searchtype=author&query=Amin%2C+S">Saurabh Amin</a>, 
<a href="/search/cs?searchtype=author&query=Jaillet%2C+P">Patrick Jaillet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">We study a planner's provision of information to manage workplace occupancy
when strategic workers (agents) face risk of infectious disease transmission.
The planner implements an information mechanism to signal information about the
underlying risk of infection at the workplace. Agents update their belief over
the risk parameter using this information and choose to work in-person or
remotely. We address the design of the optimal signaling mechanism that best
aligns the workplace occupancy with the planner's preference (i.e., maintaining
safe capacity limits and operational efficiency at workplace). For various
forms of planner preferences, we show numerical and analytical proof that
interval-based information mechanisms are optimal. These mechanisms partition
the continuous domain of the risk parameter into disjoint intervals and
provision information based on interval-specific probability distributions over
a finite set of signals. When the planner seeks to achieve an occupancy that
lies in one of finitely many pre-specified ranges independent of the underlying
risk, we provide an optimal mechanism that uses at most two intervals. On the
other hand, when the preference on the occupancy is risk-dependent, we show
that an approximately optimal interval-based mechanism can be computed
efficiently. We bound the approximation loss for preferences that are expressed
through a Lipschitz continuous function of both occupancy and risk parameter.
We provide examples that demonstrate the improvement of proposed signaling
mechanisms relative to the common benchmarks in information provision. Our
findings suggest that information provision over the risk of disease
transmission is an effective intervention for maintaining desirable occupancy
levels at the workplace.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04076" title="Abstract">arXiv:2312.04076</a> [<a href="/pdf/2312.04076" title="Download PDF">pdf</a>, <a href="/format/2312.04076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models are Good Prompt Learners for Low-Shot Image  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhaoheng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jingmin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xuefeng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Haidong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Nevatia%2C+R">Ram Nevatia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Low-shot image classification, where training images are limited or
inaccessible, has benefited from recent progress on pre-trained vision-language
(VL) models with strong generalizability, e.g. CLIP. Prompt learning methods
built with VL models generate text features from the class names that only have
confined class-specific information. Large Language Models (LLMs), with their
vast encyclopedic knowledge, emerge as the complement. Thus, in this paper, we
discuss the integration of LLMs to enhance pre-trained VL models, specifically
on low-shot classification. However, the domain gap between language and vision
blocks the direct application of LLMs. Thus, we propose LLaMP, Large Language
Models as Prompt learners, that produces adaptive prompts for the CLIP text
encoder, establishing it as the connecting bridge. Experiments show that,
compared with other state-of-the-art prompt learning methods, LLaMP yields
better performance on both zero-shot generalization and few-shot image
classification, over a spectrum of 11 datasets.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04081" title="Abstract">arXiv:2312.04081</a> [<a href="/pdf/2312.04081" title="Download PDF">pdf</a>, <a href="/ps/2312.04081" title="Download PostScript">ps</a>, <a href="/format/2312.04081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rate-splitting Multiple Access for Hierarchical HAP-LAP Networks under  Limited Fronthaul
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kim%2C+J">Jeongbin Kim</a>, 
<a href="/search/eess?searchtype=author&query=Jeong%2C+S">Seongah Jeong</a>, 
<a href="/search/eess?searchtype=author&query=Yoo%2C+S">Seonghoon Yoo</a>, 
<a href="/search/eess?searchtype=author&query=Son%2C+W">Woong Son</a>, 
<a href="/search/eess?searchtype=author&query=Kang%2C+J">Joonhyuk Kang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this correspondence, we propose hierarchical high-altitude platform
(HAP)-low-altitude platform (LAP) networks with the aim of maximizing the
sum-rate of ground user equipments (UEs). The multiple aerial radio units (RUs)
mounted on HAPs and LAPs are managed by the central unit (CU) via constrained
fronthaul links. The limitation of fronthaul capacity can be addressed through
quantization, employing the cloud radio access network (C-RAN) architecture.
For spectral efficiency, we adopt the rate-splitting multiple access (RSMA),
leveraging the advantages of both space-division multiple access (SDMA) and
non-orthogonal multiple access (NOMA). To achieve this, we jointly optimize
rate splitting, transmit power allocation, quantization noise variance, and UAV
placement using an alternating optimization (AO) approach coupled with
successive convex approximation (SCA) and the weighted minimum mean square
error (WMMSE) method. Numerical results validate the superior performance of
the proposed method compared to benchmark schemes, including partial
optimizations or those without the assistance of LAPs.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04083" title="Abstract">arXiv:2312.04083</a> [<a href="/pdf/2312.04083" title="Download PDF">pdf</a>, <a href="/format/2312.04083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the adaptation of in-context learners for system identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Piga%2C+D">Dario Piga</a>, 
<a href="/search/cs?searchtype=author&query=Pura%2C+F">Filippo Pura</a>, 
<a href="/search/cs?searchtype=author&query=Forgione%2C+M">Marco Forgione</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In-context system identification aims at constructing meta-models to describe
classes of systems, differently from traditional approaches that model single
systems. This paradigm facilitates the leveraging of knowledge acquired from
observing the behaviour of different, yet related dynamics. This paper
discusses the role of meta-model adaptation. Through numerical examples, we
demonstrate how meta-model adaptation can enhance predictive performance in
three realistic scenarios: tailoring the meta-model to describe a specific
system rather than a class; extending the meta-model to capture the behaviour
of systems beyond the initial training class; and recalibrating the model for
new prediction tasks. Results highlight the effectiveness of meta-model
adaptation to achieve a more robust and versatile meta-learning framework for
system identification.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04086" title="Abstract">arXiv:2312.04086</a> [<a href="/pdf/2312.04086" title="Download PDF">pdf</a>, <a href="/format/2312.04086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MTVG : Multi-text Video Generation with Text-to-Video Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oh%2C+G">Gyeongrok Oh</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+J">Jaehwan Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sieun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Byeon%2C+W">Wonmin Byeon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jinkyu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sungwoong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+H">Hyeokmin Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sangpil Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, video generation has attracted massive attention and yielded
noticeable outcomes. Concerning the characteristics of video, multi-text
conditioning incorporating sequential events is necessary for next-step video
generation. In this work, we propose a novel multi-text video generation~(MTVG)
by directly utilizing a pre-trained diffusion-based text-to-video~(T2V)
generation model without additional fine-tuning. To generate consecutive video
segments, visual consistency generated by distinct prompts is necessary with
diverse variations, such as motion and content-related transitions. Our
proposed MTVG includes Dynamic Noise and Last Frame Aware Inversion which
reinitialize the noise latent to preserve visual coherence between videos of
different prompts and prevent repetitive motion or contents. Furthermore, we
present Structure Guiding Sampling to maintain the global appearance across the
frames in a single video clip, where we leverage iterative latent updates
across the preceding frame. Additionally, our Prompt Generator allows for
arbitrary format of text conditions consisting of diverse events. As a result,
our extensive experiments, including diverse transitions of descriptions,
demonstrate that our proposed methods show superior generated outputs in terms
of semantically coherent and temporally seamless video.Video examples are
available in our project page: https://kuai-lab.github.io/mtvg-page.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04087" title="Abstract">arXiv:2312.04087</a> [<a href="/pdf/2312.04087" title="Download PDF">pdf</a>, <a href="/format/2312.04087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VRPTEST: Evaluating Visual Referring Prompting in Large Multimodal  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chaozheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chaowei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+P">Pingchuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Daoyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Cuiyun Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With recent advancements in Large Multimodal Models (LMMs) across various
domains, a novel prompting method called visual referring prompting has
emerged, showing significant potential in enhancing human-computer interaction
within multimodal systems. This method offers a more natural and flexible
approach to human interaction with these systems compared to traditional text
descriptions or coordinates. However, the categorization of visual referring
prompting remains undefined, and its impact on the performance of LMMs has yet
to be formally examined. In this study, we conduct the first comprehensive
analysis of LMMs using a variety of visual referring prompting strategies. We
introduce a benchmark dataset called VRPTEST, comprising 3 different visual
tasks and 2,275 images, spanning diverse combinations of prompt strategies.
Using VRPTEST, we conduct a comprehensive evaluation of eight versions of
prominent open-source and proprietary foundation models, including two early
versions of GPT-4V. We develop an automated assessment framework based on
software metamorphic testing techniques to evaluate the accuracy of LMMs
without the need for human intervention or manual labeling. We find that the
current proprietary models generally outperform the open-source ones, showing
an average accuracy improvement of 22.70%; however, there is still potential
for improvement. Moreover, our quantitative analysis shows that the choice of
prompt strategy significantly affects the accuracy of LMMs, with variations
ranging from -17.5% to +7.3%. Further case studies indicate that an appropriate
visual referring prompting strategy can improve LMMs' understanding of context
and location information, while an unsuitable one might lead to answer
rejection. We also provide insights on minimizing the negative impact of visual
referring prompting on LMMs.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04088" title="Abstract">arXiv:2312.04088</a> [<a href="/pdf/2312.04088" title="Download PDF">pdf</a>, <a href="/format/2312.04088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Maximum Fair Clique Search over Large Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rong-Hua Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zifan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Hongchao Qin</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Ye Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoren Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Mining cohesive subgraphs in attributed graphs is an essential problem in the
domain of graph data analysis. The integration of fairness considerations
significantly fuels interest in models and algorithms for mining fairness-aware
cohesive subgraphs. Notably, the relative fair clique emerges as a robust
model, ensuring not only comprehensive attribute coverage but also greater
flexibility in distributing attribute vertices. Motivated by the strength of
this model, we for the first time pioneer an investigation into the
identification of the maximum relative fair clique in large-scale graphs. We
introduce a novel concept of colorful support, which serves as the foundation
for two innovative graph reduction techniques. These techniques effectively
narrow the graph's size by iteratively removing edges that do not belong to
relative fair cliques. Furthermore, a series of upper bounds of the maximum
relative fair clique size is proposed by incorporating consideration of vertex
attributes and colors. The pruning techniques derived from these upper bounds
can significantly trim unnecessary search space during the branch-and-bound
procedure. Adding to this, we present a heuristic algorithm with a linear time
complexity, employing both a degree-based greedy strategy and a colored
degree-based greedy strategy to identify a larger relative fair clique. This
heuristic algorithm can serve a dual purpose by aiding in branch pruning,
thereby enhancing overall search efficiency. Extensive experiments conducted on
six real-life datasets demonstrate the efficiency, scalability, and
effectiveness of our algorithms.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04089" title="Abstract">arXiv:2312.04089</a> [<a href="/pdf/2312.04089" title="Download PDF">pdf</a>, <a href="/format/2312.04089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open-Vocabulary Segmentation with Semantic-Assisted Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+S">Sule Bai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yitong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yansong Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper studies open-vocabulary segmentation (OVS) through calibrating
in-vocabulary and domain-biased embedding space with generalized contextual
prior of CLIP. As the core of open-vocabulary understanding, alignment of
visual content with the semantics of unbounded text has become the bottleneck
of this field. To address this challenge, recent works propose to utilize CLIP
as an additional classifier and aggregate model predictions with CLIP
classification results. Despite their remarkable progress, performance of OVS
methods in relevant scenarios is still unsatisfactory compared with supervised
counterparts. We attribute this to the in-vocabulary embedding and
domain-biased CLIP prediction. To this end, we present a Semantic-assisted
CAlibration Network (SCAN). In SCAN, we incorporate generalized semantic prior
of CLIP into proposal embedding to avoid collapsing on known categories.
Besides, a contextual shift strategy is applied to mitigate the lack of global
context and unnatural background noise. With above designs, SCAN achieves
state-of-the-art performance on all popular open-vocabulary segmentation
benchmarks. Furthermore, we also focus on the problem of existing evaluation
system that ignores semantic duplication across categories, and propose a new
metric called Semantic-Guided IoU (SG-IoU).
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04092" title="Abstract">arXiv:2312.04092</a> [<a href="/pdf/2312.04092" title="Download PDF">pdf</a>, <a href="/ps/2312.04092" title="Download PostScript">ps</a>, <a href="/format/2312.04092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data stewardship: case studies from North-American, Dutch, and Finnish  universities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rousi%2C+A+M">Antti M. Rousi</a>, 
<a href="/search/cs?searchtype=author&query=Boehm%2C+R+I">Reid I. Boehm</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">Purpose - As national legislation, federated national services, institutional
policies and institutional research service organizations may differ, data
stewardship transpires differently in higher education institutions across the
world. This work seeks to elaborate the picture of different data stewardship
programs running in different institutional arrangements and research
environments. Design/methodology/approach - Drawing from autoethnography and
case study methods, this study described three distinct data stewardship
programs from Purdue University (United States), Delft Technical University
(Netherlands) and Aalto University (Finland). In addition, this work
investigated the institutional arrangements and national research environments
of the programs. The focus was on initiatives led by academic libraries or
similar services. Findings - This work demonstrates that data stewardship may
be understood differently within different national and institutional contexts.
The data stewardship programs differed in terms of roles, organization and
funding structures. Moreover, the mesh of policies and legislation,
organizational structures, and national infrastructures differed. Originality -
This work broadens the current literature on data stewardship by not only
providing detailed descriptions of three distinct data stewardship programs,
but also highlighting how research environments may affect their organization.
We argue that the knowledge of institutional and national arrangements is a
transversal requirement of data stewardship. Research limitations/implications
- The data stewardship programs and their contexts develop, and the
descriptions presented in this work should be considered as snapshots. Although
individual researchers and research groups may undertake data stewardship
activities, this study only investigated formalized services.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04095" title="Abstract">arXiv:2312.04095</a> [<a href="/pdf/2312.04095" title="Download PDF">pdf</a>, <a href="/format/2312.04095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learn to Unlearn for Deep Neural Networks: Minimizing Unlearning  Interference with Gradient Projection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoang%2C+T">Tuan Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Rana%2C+S">Santu Rana</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Sunil Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Venkatesh%2C+S">Svetha Venkatesh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recent data-privacy laws have sparked interest in machine unlearning, which
involves removing the effect of specific training samples from a learnt model
as if they were never present in the original training dataset. The challenge
of machine unlearning is to discard information about the ``forget'' data in
the learnt model without altering the knowledge about the remaining dataset and
to do so more efficiently than the naive retraining approach. To achieve this,
we adopt a projected-gradient based learning method, named as
Projected-Gradient Unlearning (PGU), in which the model takes steps in the
orthogonal direction to the gradient subspaces deemed unimportant for the
retaining dataset, so as to its knowledge is preserved. By utilizing Stochastic
Gradient Descent (SGD) to update the model weights, our method can efficiently
scale to any model and dataset size. We provide empirically evidence to
demonstrate that our unlearning method can produce models that behave similar
to models retrained from scratch across various metrics even when the training
dataset is no longer accessible. Our code is available at
https://github.com/hnanhtuan/projected_gradient_unlearning.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04096" title="Abstract">arXiv:2312.04096</a> [<a href="/pdf/2312.04096" title="Download PDF">pdf</a>, <a href="/format/2312.04096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MediHunt: A Network Forensics Framework for Medical IoT Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+A">Ayushi Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Boppana%2C+T+K">Tej Kiran Boppana</a>, 
<a href="/search/cs?searchtype=author&query=Bagade%2C+P">Priyanka Bagade</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The Medical Internet of Things (MIoT) has enabled small, ubiquitous medical
devices to communicate with each other to facilitate interconnected healthcare
delivery. These devices interact using communication protocols like MQTT,
Bluetooth, and Wi-Fi. However, as MIoT devices proliferate, these networked
devices are vulnerable to cyber-attacks. This paper focuses on the
vulnerabilities present in the Message Queuing Telemetry and Transport (MQTT)
protocol. The MQTT protocol is prone to cyber-attacks that can harm the
system's functionality. The memory-constrained MIoT devices enforce a
limitation on storing all data logs that are required for comprehensive network
forensics. This paper solves the data log availability challenge by detecting
the attack in real-time and storing the corresponding logs for further analysis
with the proposed network forensics framework: MediHunt. Machine learning (ML)
techniques are the most real safeguard against cyber-attacks. However, these
models require a specific dataset that covers diverse attacks on the MQTT-based
IoT system for training. The currently available datasets do not encompass a
variety of applications and TCP layer attacks. To address this issue, we
leveraged the usage of a flow-based dataset containing flow data for TCP/IP
layer and application layer attacks. Six different ML models are trained with
the generated dataset to evaluate the effectiveness of the MediHunt framework
in detecting real-time attacks. F1 scores and detection accuracy exceeded 0.99
for the proposed MediHunt framework with our custom dataset.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04100" title="Abstract">arXiv:2312.04100</a> [<a href="/pdf/2312.04100" title="Download PDF">pdf</a>, <a href="/ps/2312.04100" title="Download PostScript">ps</a>, <a href="/format/2312.04100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A framework for securing email entrances and mitigating phishing  impersonation attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wosah%2C+P+N">Peace Nmachi Wosah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Emails are used every day for communication, and many countries and
organisations mostly use email for official communications. It is highly valued
and recognised for confidential conversations and transactions in day-to-day
business. The Often use of this channel and the quality of information it
carries attracted cyber attackers to it. There are many existing techniques to
mitigate attacks on email, however, the systems are more focused on email
content and behaviour and not securing entrances to email boxes, composition,
and settings. This work intends to protect users' email composition and
settings to prevent attackers from using an account when it gets hacked or
hijacked and stop them from setting forwarding on the victim's email account to
a different account which automatically stops the user from receiving emails. A
secure code is applied to the composition send button to curtail insider
impersonation attack. Also, to secure open applications on public and private
devices.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04101" title="Abstract">arXiv:2312.04101</a> [<a href="/pdf/2312.04101" title="Download PDF">pdf</a>, <a href="/ps/2312.04101" title="Download PostScript">ps</a>, <a href="/format/2312.04101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge computing service deployment and task offloading based on  multi-task high-dimensional multi-objective optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yanheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Linjie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengxia Li</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xingjuan Cai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinjun Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">The Mobile Edge Computing (MEC) system located close to the client allows
mobile smart devices to offload their computations onto edge servers, enabling
them to benefit from low-latency computing services. Both cloud service
providers and users seek more comprehensive solutions, necessitating judicious
decisions in service deployment and task offloading while balancing multiple
objectives. This study investigates service deployment and task offloading
challenges in a multi-user environment, framing them as a multi-task
high-dimensional multi-objective optimization (MT-HD-MOO) problem within an
edge environment. To ensure stable service provisioning, beyond considering
latency, energy consumption, and cost as deployment objectives, network
reliability is also incorporated. Furthermore, to promote equitable usage of
edge servers, load balancing is introduced as a fourth task offloading
objective, in addition to latency, energy consumption, and cost. Additionally,
this paper designs a MT-HD-MOO algorithm based on a multi-selection strategy to
address this model and its solution. By employing diverse selection strategies,
an environment selection strategy pool is established to enhance population
diversity within the high-dimensional objective space. Ultimately, the
algorithm's effectiveness is verified through simulation experiments.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04102" title="Abstract">arXiv:2312.04102</a> [<a href="/pdf/2312.04102" title="Download PDF">pdf</a>, <a href="/format/2312.04102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the Load Flexibility of Stratified Electric Water Heaters:  Design and Experimental Validation of MPC Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Buechler%2C+E">Elizabeth Buechler</a>, 
<a href="/search/eess?searchtype=author&query=Goldin%2C+A">Aaron Goldin</a>, 
<a href="/search/eess?searchtype=author&query=Rajagopal%2C+R">Ram Rajagopal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Residential electric water heaters have significant load shifting
capabilities due to their thermal heat capacity and large energy consumption.
Model predictive control (MPC) has been shown to be an effective control
strategy to enable water heater load shifting in home energy management
systems. In this work, we analyze how modeling tank stratification in an MPC
formulation impacts control performance for stratified electric water heaters
under time-of-use (TOU) rates. Specifically, we propose an MPC formulation
based on a three-node thermal model that captures tank stratification, and
compare it to a one-node formulation that does not capture stratification and a
standard thermostatic controller. These strategies are compared through both
real-time laboratory testing and simulation-based evaluation for different
water use patterns. Laboratory experiments show cost reductions of 12.3-23.2%
for the one-node MPC and 31.2-42.5% for the three-node MPC relative to the
thermostatic controller. The performance of the one-node MPC is limited by
significant plant-model mismatch, while the three-node formulation better
approximates real-world dynamics and results in much more effective cost
reduction and load shifting. A simple analysis of how each strategy performs
under water use forecast errors is also provided.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04103" title="Abstract">arXiv:2312.04103</a> [<a href="/pdf/2312.04103" title="Download PDF">pdf</a>, <a href="/format/2312.04103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing the Rationale-Input Alignment for Self-explaining  Rationalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haozhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhiying Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">YuanKai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruixuan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accept at ICDE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Rationalization empowers deep learning models with self-explaining
capabilities through a cooperative game, where a generator selects a
semantically consistent subset of the input as a rationale, and a subsequent
predictor makes predictions based on the selected rationale. In this paper, we
discover that rationalization is prone to a problem named \emph{rationale
shift}, which arises from the algorithmic bias of the cooperative game.
Rationale shift refers to a situation where the semantics of the selected
rationale may deviate from the original input, but the predictor still produces
accurate predictions based on the deviation, resulting in a compromised
generator with misleading feedback.
<br />To address this issue, we first demonstrate the importance of the alignment
between the rationale and the full input through both empirical observations
and theoretical analysis. Subsequently, we introduce a novel approach called
DAR (\textbf{D}iscriminatively \textbf{A}ligned \textbf{R}ationalization),
which utilizes an auxiliary module pretrained on the full input to
discriminatively align the selected rationale and the original input. We
theoretically illustrate how DAR accomplishes the desired alignment, thereby
overcoming the rationale shift problem. The experiments on two widely used
real-world benchmarks show that the proposed method significantly improves the
explanation quality (measured by the overlap between the model-selected
explanation and the human-annotated rationale) as compared to state-of-the-art
techniques. Additionally, results on two synthetic settings further validate
the effectiveness of DAR in addressing the rationale shift problem.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04106" title="Abstract">arXiv:2312.04106</a> [<a href="/pdf/2312.04106" title="Download PDF">pdf</a>, <a href="/format/2312.04106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identity-Obscured Neural Radiance Fields: Privacy-Preserving 3D Facial  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+J">Jiayi Kong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Baixin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xurui Song</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chen Qian</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jun Luo</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Ying He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural radiance fields (NeRF) typically require a complete set of images
taken from multiple camera perspectives to accurately reconstruct geometric
details. However, this approach raise significant privacy concerns in the
context of facial reconstruction. The critical need for privacy protection
often leads invidividuals to be reluctant in sharing their facial images, due
to fears of potential misuse or security risks. Addressing these concerns, we
propose a method that leverages privacy-preserving images for reconstructing 3D
head geometry within the NeRF framework. Our method stands apart from
traditional facial reconstruction techniques as it does not depend on RGB
information from images containing sensitive facial data. Instead, it
effectively generates plausible facial geometry using a series of
identity-obscured inputs, thereby protecting facial privacy.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04109" title="Abstract">arXiv:2312.04109</a> [<a href="/pdf/2312.04109" title="Download PDF">pdf</a>, <a href="/format/2312.04109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridge the Present and Future: A Cross-Layer Matching Game in Dynamic  Cloud-Aided Mobile Edge Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+H">Houyi Qi</a>, 
<a href="/search/cs?searchtype=author&query=Liwang%2C+M">Minghui Liwang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xianbin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+W">Wei Gong</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jian Jin</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+Z">Zhenzhen Jiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Cloud-aided mobile edge networks (CAMENs) allow edge servers (ESs) to
purchase resources from remote cloud servers (CSs), while overcoming resource
shortage when handling computation-intensive tasks of mobile users (MUs).
Conventional trading mechanisms (e.g., onsite trading) confront many
challenges, including decision-making overhead (e.g., latency) and potential
trading failures. This paper investigates a series of cross-layer matching
mechanisms to achieve stable and cost-effective resource provisioning across
different layers (i.e., MUs, ESs, CSs), seamlessly integrated into a novel
hybrid paradigm that incorporates futures and spot trading. In futures trading,
we explore an overbooking-driven aforehand cross-layer matching (OA-CLM)
mechanism, facilitating two future contract types: contract between MUs and
ESs, and contract between ESs and CSs, while assessing potential risks under
historical statistical analysis. In spot trading, we design two backup plans
respond to current network/market conditions: determination on contractual MUs
that should switch to local processing from edge/cloud services; and an onsite
cross-layer matching (OS-CLM) mechanism that engages participants in real-time
practical transactions. We next show that our matching mechanisms theoretically
satisfy stability, individual rationality, competitive equilibrium, and weak
Pareto optimality. Comprehensive simulations in real-world and numerical
network settings confirm the corresponding efficacy, while revealing remarkable
improvements in time/energy efficiency and social welfare.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04111" title="Abstract">arXiv:2312.04111</a> [<a href="/pdf/2312.04111" title="Download PDF">pdf</a>, <a href="/format/2312.04111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breaking the Entanglement of Homophily and Heterophily in  Semi-supervised Node Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Henan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xunkai Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhengyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+D">Daohan Su</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rong-Hua Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoren Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Recently, graph neural networks (GNNs) have shown prominent performance in
semi-supervised node classification by leveraging knowledge from the graph
database. However, most existing GNNs follow the homophily assumption, where
connected nodes are more likely to exhibit similar feature distributions and
the same labels, and such an assumption has proven to be vulnerable in a
growing number of practical applications. As a supplement, heterophily reflects
dissimilarity in connected nodes, which has gained significant attention in
graph learning. To this end, data engineers aim to develop a powerful GNN model
that can ensure performance under both homophily and heterophily. Despite
numerous attempts, most existing GNNs struggle to achieve optimal node
representations due to the constraints of undirected graphs. The neglect of
directed edges results in sub-optimal graph representations, thereby hindering
the capacity of GNNs. To address this issue, we introduce AMUD, which
quantifies the relationship between node profiles and topology from a
statistical perspective, offering valuable insights for \underline{A}daptively
\underline{M}odeling the natural directed graphs as the \underline{U}ndirected
or \underline{D}irected graph to maximize the benefits from subsequent graph
learning. Furthermore, we propose \underline{A}daptive \underline{D}irected
\underline{P}attern \underline{A}ggregation (ADPA) as a new directed graph
learning paradigm for AMUD. Empirical studies have demonstrated that AMUD
guides efficient graph learning. Meanwhile, extensive experiments on 14
benchmark datasets substantiate the impressive performance of ADPA,
outperforming baselines by significant margins of 3.96\%.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04113" title="Abstract">arXiv:2312.04113</a> [<a href="/pdf/2312.04113" title="Download PDF">pdf</a>, <a href="/ps/2312.04113" title="Download PostScript">ps</a>, <a href="/format/2312.04113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-strategy Collaborative Optimized YOLOv5s and its Application in  Distance Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zijian Shen</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+Z">Zhenping Mu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangxiang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper contains 5 pages, 10 figures, and was accepted at 4th International Conference on Advances in Electrical Engineering and Computer Applications (AEECA2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The increasing accident rate brought about by the explosive growth of
automobiles has made the research on active safety systems of automobiles
increasingly important. The importance of improving the accuracy of vehicle
target detection is self-evident. To achieve the goals of vehicle detection and
distance estimation and provide safety warnings, a Distance Estimation Safety
Warning System (DESWS) based on a new neural network model (YOLOv5s-SE) by
replacing the IoU with DIoU, embedding SE attention module, and a distance
estimation method through using the principle of similar triangles was
proposed. In addition, a method that can give safety suggestions based on the
estimated distance using nonparametric testing was presented in this work.
Through the simulation experiment, it was verified that the mAP was improved by
5.5% and the purpose of giving safety suggestions based on the estimated
distance information can be achieved.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04114" title="Abstract">arXiv:2312.04114</a> [<a href="/pdf/2312.04114" title="Download PDF">pdf</a>, <a href="/format/2312.04114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TI-DNS: A Trusted and Incentive DNS Resolution Architecture based on  Blockchain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yufan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jiuqi Wei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Ying Li</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Botao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaodong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Domain Name System (DNS) is a critical component of the Internet
infrastructure, responsible for translating domain names into IP addresses.
However, DNS is vulnerable to some malicious attacks, including DNS cache
poisoning, which redirects users to malicious websites displaying offensive or
illegal content. Existing countermeasures often suffer from at least one of the
following weakness: weak attack resistance, high overhead, or complex
implementation. To address these challenges, this paper presents TI-DNS, a
blockchain-based DNS resolution architecture designed to detect and correct the
forged DNS records caused by the cache poisoning attacks in the DNS resolution
process. TI-DNS leverages a multi-resolver Query Vote mechanism to ensure the
credibility of verified records on the blockchain ledger and a stake-based
incentive mechanism to promote well-behaved participation. Importantly, TI-DNS
is easy to be adopted as it only requires modifications to the resolver side of
current DNS infrastructure. Finally, we develop a prototype and evaluate it
against alternative solutions. The result demonstrates that TI-DNS effectively
and efficiently solves DNS cache poisoning.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04117" title="Abstract">arXiv:2312.04117</a> [<a href="/pdf/2312.04117" title="Download PDF">pdf</a>, <a href="/format/2312.04117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instance Tracking in 3D Scenes from Egocentric Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yunhan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Haoyu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+S">Shu Kong</a>, 
<a href="/search/cs?searchtype=author&query=Fowlkes%2C+C">Charless Fowlkes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Egocentric sensors such as AR/VR devices capture human-object interactions
and offer the potential to provide task-assistance by recalling 3D locations of
objects of interest in the surrounding environment. This capability requires
instance tracking in real-world 3D scenes from egocentric videos (IT3DEgo). We
explore this problem by first introducing a new benchmark dataset, consisting
of RGB and depth videos, per-frame camera pose, and instance-level annotations
in both 2D camera and 3D world coordinates. We present an evaluation protocol
which evaluates tracking performance in 3D coordinates with two settings for
enrolling instances to track: (1) single-view online enrollment where an
instance is specified on-the-fly based on the human wearer's interactions. and
(2) multi-view pre-enrollment where images of an instance to be tracked are
stored in memory ahead of time. To address IT3DEgo, we first re-purpose methods
from relevant areas, e.g., single object tracking (SOT) -- running SOT methods
to track instances in 2D frames and lifting them to 3D using camera pose and
depth. We also present a simple method that leverages pretrained segmentation
and detection models to generate proposals from RGB frames and match proposals
with enrolled instance images. Perhaps surprisingly, our extensive experiments
show that our method (with no finetuning) significantly outperforms SOT-based
approaches. We conclude by arguing that the problem of egocentric instance
tracking is made easier by leveraging camera pose and using a 3D allocentric
(world) coordinate representation.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04118" title="Abstract">arXiv:2312.04118</a> [<a href="/pdf/2312.04118" title="Download PDF">pdf</a>, <a href="/format/2312.04118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Caregiver Talk Shapes Toddler Vision: A Computational Study of Dyadic  Play
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schauml%C3%B6ffel%2C+T">Timothy Schauml&#xf6;ffel</a>, 
<a href="/search/cs?searchtype=author&query=Aubret%2C+A">Arthur Aubret</a>, 
<a href="/search/cs?searchtype=author&query=Roig%2C+G">Gemma Roig</a>, 
<a href="/search/cs?searchtype=author&query=Triesch%2C+J">Jochen Triesch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 2023 IEEE International Conference on Development and Learning (ICDL)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Infants' ability to recognize and categorize objects develops gradually. The
second year of life is marked by both the emergence of more semantic visual
representations and a better understanding of word meaning. This suggests that
language input may play an important role in shaping visual representations.
However, even in suitable contexts for word learning like dyadic play sessions,
caregivers utterances are sparse and ambiguous, often referring to objects that
are different from the one to which the child attends. Here, we systematically
investigate to what extent caregivers' utterances can nevertheless enhance
visual representations. For this we propose a computational model of visual
representation learning during dyadic play. We introduce a synthetic dataset of
ego-centric images perceived by a toddler-agent that moves and rotates toy
objects in different parts of its home environment while hearing caregivers'
utterances, modeled as captions. We propose to model toddlers' learning as
simultaneously aligning representations for 1) close-in-time images and 2)
co-occurring images and utterances. We show that utterances with statistics
matching those of real caregivers give rise to representations supporting
improved category recognition. Our analysis reveals that a small
decrease/increase in object-relevant naming frequencies can drastically impact
the learned representations. This affects the attention on object names within
an utterance, which is required for efficient visuo-linguistic alignment.
Overall, our results support the hypothesis that caregivers' naming utterances
can improve toddlers' visual representations.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04119" title="Abstract">arXiv:2312.04119</a> [<a href="/pdf/2312.04119" title="Download PDF">pdf</a>, <a href="/format/2312.04119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multilevel Guidance-Exploration Network and Behavior-Scene Matching  Method for Human Behavior Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guoqing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhiming Luo</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianzhe Gao</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">Yingxin Lai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kun Yang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yifan He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shaozi Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages,7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human behavior anomaly detection aims to identify unusual human actions,
playing a crucial role in intelligent surveillance and other areas. The current
mainstream methods still adopt reconstruction or future frame prediction
techniques. However, reconstructing or predicting low-level pixel features
easily enables the network to achieve overly strong generalization ability,
allowing anomalies to be reconstructed or predicted as effectively as normal
data. Different from their methods, inspired by the Student-Teacher Network, we
propose a novel framework called the Multilevel Guidance-Exploration
Network(MGENet), which detects anomalies through the difference in high-level
representation between the Guidance and Exploration network. Specifically, we
first utilize the pre-trained Normalizing Flow that takes skeletal keypoints as
input to guide an RGB encoder, which takes unmasked RGB frames as input, to
explore motion latent features. Then, the RGB encoder guides the mask encoder,
which takes masked RGB frames as input, to explore the latent appearance
feature. Additionally, we design a Behavior-Scene Matching Module(BSMM) to
detect scene-related behavioral anomalies. Extensive experiments demonstrate
that our proposed method achieves state-of-the-art performance on ShanghaiTech
and UBnormal datasets, with AUC of 86.9 % and 73.5 %, respectively. The code
will be available on https://github.com/molu-ggg/GENet.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04123" title="Abstract">arXiv:2312.04123</a> [<a href="/pdf/2312.04123" title="Download PDF">pdf</a>, <a href="/format/2312.04123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximating the Graph Edit Distance with Compact Neighborhood  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bause%2C+F">Franka Bause</a>, 
<a href="/search/cs?searchtype=author&query=Permann%2C+C">Christian Permann</a>, 
<a href="/search/cs?searchtype=author&query=Kriege%2C+N+M">Nils M. Kriege</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">The graph edit distance is used for comparing graphs in various domains. Due
to its high computational complexity it is primarily approximated. Widely-used
heuristics search for an optimal assignment of vertices based on the distance
between local substructures. While faster ones only consider vertices and their
incident edges, leading to poor accuracy, other approaches require
computationally intense exact distance computations between subgraphs. Our new
method abstracts local substructures to neighborhood trees and compares them
using efficient tree matching techniques. This results in a ground distance for
mapping vertices that yields high quality approximations of the graph edit
distance. By limiting the maximum tree height, our method supports steering
between more accurate results and faster execution. We thoroughly analyze the
running time of the tree matching method and propose several techniques to
accelerate computation in practice. We use compressed tree representations,
recognize redundancies by tree canonization and exploit them via caching.
Experimentally we show that our method provides a significantly improved
trade-off between running time and approximation quality compared to existing
state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04125" title="Abstract">arXiv:2312.04125</a> [<a href="/pdf/2312.04125" title="Download PDF">pdf</a>, <a href="/format/2312.04125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forensic Iris Image Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhuiyan%2C+R+A">Rasel Ahmed Bhuiyan</a>, 
<a href="/search/cs?searchtype=author&query=Czajka%2C+A">Adam Czajka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Post-mortem iris recognition is an emerging application of iris-based human
identification in a forensic setup, able to correctly identify deceased
subjects even three weeks post-mortem. This technique thus is considered as an
important component of future forensic toolkits. The current advancements in
this field are seriously slowed down by exceptionally difficult data
collection, which can happen in mortuary conditions, at crime scenes, or in
``body farm'' facilities. This paper makes a novel contribution to facilitate
progress in post-mortem iris recognition by offering a conditional
StyleGAN-based iris synthesis model, trained on the largest-available dataset
of post-mortem iris samples acquired from more than 350 subjects, generating --
through appropriate exploration of StyleGAN latent space -- multiple
within-class (same identity) and between-class (different new identities)
post-mortem iris images, compliant with ISO/IEC 29794-6, and with decomposition
deformations controlled by the requested PMI (post mortem interval). Besides an
obvious application to enhance the existing, very sparse, post-mortem iris
datasets to advance -- among others -- iris presentation attack endeavors, we
anticipate it may be useful to generate samples that would expose professional
forensic human examiners to never-seen-before deformations for various PMIs,
increasing their training effectiveness. The source codes and model weights are
made available with the paper.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04126" title="Abstract">arXiv:2312.04126</a> [<a href="/pdf/2312.04126" title="Download PDF">pdf</a>, <a href="/format/2312.04126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Improved Scheduling with Advantage Actor-Critic for Storm Workloads
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+G">Gaoqiang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mingjing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+T">Tingting Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Various resources as the essential elements of data centers, and the
completion time is vital to users. In terms of the persistence, the periodicity
and the spatial-temporal dependence of stream workload, a new Storm scheduler
with Advantage Actor-Critic is proposed to improve resource utilization for
minimizing the completion time. A new weighted embedding with a Graph Neural
Network is designed to depend on the features of a job comprehensively, which
includes the dependence, the types and the positions of tasks in a job. An
improved Advantage Actor-Critic integrating task chosen and executor assignment
is proposed to schedule tasks to executors in order to better resource
utilization. Then the status of tasks and executors are updated for the next
scheduling. Compared to existing methods, experimental results show that the
proposed Storm scheduler improves resource utilization. The completion time is
reduced by almost 17\% on the TPC-H data set and reduced by almost 25\% on the
Alibaba data set.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04127" title="Abstract">arXiv:2312.04127</a> [<a href="/pdf/2312.04127" title="Download PDF">pdf</a>, <a href="/format/2312.04127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing the Inherent Response Tendency of LLMs: Real-World  Instructions-Driven Jailbreak
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yanrui Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sendong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+M">Ming Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+B">Bing Qin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Extensive work has been devoted to improving the safety mechanism of Large
Language Models (LLMs). However, in specific scenarios, LLMs still generate
harmful responses when faced with malicious instructions, a phenomenon referred
to as "Jailbreak Attack". In our research, we introduce a novel jailbreak
attack method (\textbf{RADIAL}), which consists of two steps: 1) Inherent
Response Tendency Analysis: we analyze the inherent affirmation and rejection
tendency of LLMs to react to real-world instructions. 2) Real-World
Instructions-Driven Jailbreak: based on our analysis, we strategically choose
several real-world instructions and embed malicious instructions into them to
amplify the LLM's potential to generate harmful responses. On three open-source
human-aligned LLMs, our method achieves excellent jailbreak attack performance
for both Chinese and English malicious instructions. Besides, we guided
detailed ablation experiments and verified the effectiveness of our core idea
"Inherent Response Tendency Analysis". Our exploration also exposes the
vulnerability of LLMs to being induced into generating more detailed harmful
responses in subsequent rounds of dialogue.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04134" title="Abstract">arXiv:2312.04134</a> [<a href="/pdf/2312.04134" title="Download PDF">pdf</a>, <a href="/ps/2312.04134" title="Download PostScript">ps</a>, <a href="/format/2312.04134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using a Large Language Model to generate a Design Structure Matrix
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koh%2C+E+C+Y">Edwin C. Y. Koh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 7 Figures, 6 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The Design Structure Matrix (DSM) is an established method used in dependency
modelling, especially in the design of complex engineering systems. The
generation of DSM is traditionally carried out through manual means and can
involve interviewing experts to elicit critical system elements and the
relationships between them. Such manual approaches can be time-consuming and
costly. This paper presents a workflow that uses a Large Language Model (LLM)
to support the generation of DSM and improve productivity. A prototype of the
workflow was developed in this work and applied on a diesel engine DSM
published previously. It was found that the prototype could reproduce 357 out
of 462 DSM entries published (i.e. 77.3%), suggesting that the work can aid DSM
generation. A no-code version of the prototype is made available online to
support future research.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04135" title="Abstract">arXiv:2312.04135</a> [<a href="/pdf/2312.04135" title="Download PDF">pdf</a>, <a href="/format/2312.04135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Federated Learning-based Intrusion Detection System for Flying  Ad Hoc Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ceviz%2C+O">Ozlem Ceviz</a> (1), 
<a href="/search/cs?searchtype=author&query=Sadioglu%2C+P">Pinar Sadioglu</a> (1), 
<a href="/search/cs?searchtype=author&query=Sen%2C+S">Sevil Sen</a> (1), 
<a href="/search/cs?searchtype=author&query=Vassilakis%2C+V+G">Vassilios G. Vassilakis</a> (2) ((1) WISE Lab., Deparment of Computer Engineering, Hacettepe University, Ankara, Turkey (2) Department of Computer Science, University of York, York, United Kingdom)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Unmanned aerial vehicles (UAVs) in flying ad-hoc networks (FANETs) face
security challenges due to the dynamic and distributed nature of these
networks. This paper presents the Federated Learning-based Intrusion Detection
System (FL-IDS), an innovative approach designed to improve FANET security.
FL-IDS leverages federated learning to address privacy concerns of centralized
intrusion detection systems. FL-IDS operates in a decentralized manner,
enabling UAVs to collaboratively train a global intrusion detection model
without sharing raw data. Local models are assigned to each UAV, using
client-specific data, and only updated model weights are shared with a central
server. This preserves privacy while utilizing collective intelligence for
effective intrusion detection. Experimental results show FL-IDS's competitive
performance with Central IDS (C-IDS) while mitigating privacy concerns. The
Bias Towards Specific Clients (BTSC) method further enhances FL-IDS
performance, surpassing C-IDS even at lower attacker ratios. A comparative
analysis with traditional intrusion detection methods, including Local IDS
(L-IDS), provides insights into FL-IDS's strengths. This study significantly
contributes to FANET security by introducing a privacy-aware, decentralized
intrusion detection approach tailored to the unique challenges of UAV networks.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04140" title="Abstract">arXiv:2312.04140</a> [<a href="/pdf/2312.04140" title="Download PDF">pdf</a>, <a href="/format/2312.04140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polarimetric Light Transport Analysis for Specular Inter-reflection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maeda%2C+R">Ryota Maeda</a>, 
<a href="/search/cs?searchtype=author&query=Hiura%2C+S">Shinsaku Hiura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Polarization is well known for its ability to decompose diffuse and specular
reflections. However, the existing decomposition methods only focus on direct
reflection and overlook multiple reflections, especially specular
inter-reflection. In this paper, we propose a novel decomposition method for
handling specular inter-reflection of metal objects by using a unique
polarimetric feature: the rotation direction of linear polarization. This
rotation direction serves as a discriminative factor between direct and
inter-reflection on specular surfaces. To decompose the reflectance components,
we actively rotate the linear polarization of incident light and analyze the
rotation direction of the reflected light. We evaluate our method using both
synthetic and real data, demonstrating its effectiveness in decomposing
specular inter-reflections of metal objects. Furthermore, we demonstrate that
our method can be combined with other decomposition methods for a detailed
analysis of light transport. As a practical application, we show its
effectiveness in improving the accuracy of 3D measurement against strong
specular inter-reflection.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04141" title="Abstract">arXiv:2312.04141</a> [<a href="/pdf/2312.04141" title="Download PDF">pdf</a>, <a href="/ps/2312.04141" title="Download PostScript">ps</a>, <a href="/format/2312.04141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Approximate Computing with Constant Locality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+D">Deheng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Tao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhongyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shi Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">We consider a distributed coding for computing problem with constant decoding
locality, i.e. with a vanishing error probability, any single sample of the
function can be approximately recovered by probing only constant number of
compressed bits. We establish an achievable rate region by designing an
efficient coding scheme. The scheme reduces the required rate by introducing
auxiliary random variables and supports local decoding at the same time. Then
we show the rate region is optimal under mild regularity conditions on source
distributions. A coding for computing problem with side information is
analogously studied. These results indicate that more rate has to be taken in
order to achieve lower coding complexity in distributed computing settings.
Moreover, useful graph characterizations are developed to simplify the
computation of the achievable rate region.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04142" title="Abstract">arXiv:2312.04142</a> [<a href="/pdf/2312.04142" title="Download PDF">pdf</a>, <a href="/format/2312.04142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TimeDRL: Disentangled Representation Learning for Multivariate  Time-Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Ching Chang</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+C">Chiao-Tung Chan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei-Yao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wen-Chih Peng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tien-Fu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is currently under review. The code will be made available upon acceptance
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multivariate time-series data in numerous real-world applications (e.g.,
healthcare and industry) are informative but challenging due to the lack of
labels and high dimensionality. Recent studies in self-supervised learning have
shown their potential in learning rich representations without relying on
labels, yet they fall short in learning disentangled embeddings and addressing
issues of inductive bias (e.g., transformation-invariance). To tackle these
challenges, we propose TimeDRL, a generic multivariate time-series
representation learning framework with disentangled dual-level embeddings.
TimeDRL is characterized by three novel features: (i) disentangled derivation
of timestamp-level and instance-level embeddings from patched time-series data
using a [CLS] token strategy; (ii) utilization of timestamp-predictive and
instance-contrastive tasks for disentangled representation learning, with the
former optimizing timestamp-level embeddings with predictive loss, and the
latter optimizing instance-level embeddings with contrastive loss; and (iii)
avoidance of augmentation methods to eliminate inductive biases, such as
transformation-invariance from cropping and masking. Comprehensive experiments
on 6 time-series forecasting datasets and 5 time-series classification datasets
have shown that TimeDRL consistently surpasses existing representation learning
approaches, achieving an average improvement of forecasting by 57.98% in MSE
and classification by 1.25% in accuracy. Furthermore, extensive ablation
studies confirmed the relative contribution of each component in TimeDRL's
architecture, and semi-supervised learning evaluations demonstrated its
effectiveness in real-world scenarios, even with limited labeled data.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04143" title="Abstract">arXiv:2312.04143</a> [<a href="/pdf/2312.04143" title="Download PDF">pdf</a>, <a href="/format/2312.04143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards 4D Human Video Stylization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tiantian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+X">Xinxin Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+F">Fangzhou Mu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a first step towards 4D (3D and time) human video stylization,
which addresses style transfer, novel view synthesis and human animation within
a unified framework. While numerous video stylization methods have been
developed, they are often restricted to rendering images in specific viewpoints
of the input video, lacking the capability to generalize to novel views and
novel poses in dynamic scenes. To overcome these limitations, we leverage
Neural Radiance Fields (NeRFs) to represent videos, conducting stylization in
the rendered feature space. Our innovative approach involves the simultaneous
representation of both the human subject and the surrounding scene using two
NeRFs. This dual representation facilitates the animation of human subjects
across various poses and novel viewpoints. Specifically, we introduce a novel
geometry-guided tri-plane representation, significantly enhancing feature
representation robustness compared to direct tri-plane optimization. Following
the video reconstruction, stylization is performed within the NeRFs' rendered
feature space. Extensive experiments demonstrate that the proposed method
strikes a superior balance between stylized textures and temporal coherence,
surpassing existing approaches. Furthermore, our framework uniquely extends its
capabilities to accommodate novel poses and viewpoints, making it a versatile
tool for creative human video stylization.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04145" title="Abstract">arXiv:2312.04145</a> [<a href="/pdf/2312.04145" title="Download PDF">pdf</a>, <a href="/format/2312.04145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusing Colors: Image Colorization with Text Guided Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zabari%2C+N">Nir Zabari</a>, 
<a href="/search/cs?searchtype=author&query=Azulay%2C+A">Aharon Azulay</a>, 
<a href="/search/cs?searchtype=author&query=Gorkor%2C+A">Alexey Gorkor</a>, 
<a href="/search/cs?searchtype=author&query=Halperin%2C+T">Tavi Halperin</a>, 
<a href="/search/cs?searchtype=author&query=Fried%2C+O">Ohad Fried</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGGRAPH Asia 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">The colorization of grayscale images is a complex and subjective task with
significant challenges. Despite recent progress in employing large-scale
datasets with deep neural networks, difficulties with controllability and
visual quality persist. To tackle these issues, we present a novel image
colorization framework that utilizes image diffusion techniques with granular
text prompts. This integration not only produces colorization outputs that are
semantically appropriate but also greatly improves the level of control users
have over the colorization process. Our method provides a balance between
automation and control, outperforming existing techniques in terms of visual
quality and semantic coherence. We leverage a pretrained generative Diffusion
Model, and show that we can finetune it for the colorization task without
losing its generative power or attention to text prompts. Moreover, we present
a novel CLIP-based ranking model that evaluates color vividness, enabling
automatic selection of the most suitable level of vividness based on the
specific scene semantics. Our approach holds potential particularly for color
enhancement and historical image colorization.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04147" title="Abstract">arXiv:2312.04147</a> [<a href="/pdf/2312.04147" title="Download PDF">pdf</a>, <a href="/ps/2312.04147" title="Download PostScript">ps</a>, <a href="/format/2312.04147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Improved Masking Strategy for Self-supervised Masked Reconstruction  in Human Activity Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Tao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+H">Huansheng Ning</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Masked reconstruction serves as a fundamental pretext task for
self-supervised learning, enabling the model to enhance its feature extraction
capabilities by reconstructing the masked segments from extensive unlabeled
data. In human activity recognition, this pretext task employed a masking
strategy centered on the time dimension. However, this masking strategy fails
to fully exploit the inherent characteristics of wearable sensor data and
overlooks the inter-channel information coupling, thereby limiting its
potential as a powerful pretext task. To address these limitations, we propose
a novel masking strategy called Channel Masking. It involves masking the sensor
data along the channel dimension, thereby compelling the encoder to extract
channel-related features while performing the masked reconstruction task.
Moreover, Channel Masking can be seamlessly integrated with masking strategies
along the time dimension, thereby motivating the self-supervised model to
undertake the masked reconstruction task in both the time and channel
dimensions. Integrated masking strategies are named Time-Channel Masking and
Span-Channel Masking. Finally, we optimize the reconstruction loss function to
incorporate the reconstruction loss in both the time and channel dimensions. We
evaluate proposed masking strategies on three public datasets, and experimental
results show that the proposed strategies outperform prior strategies in both
self-supervised and semi-supervised scenarios.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04148" title="Abstract">arXiv:2312.04148</a> [<a href="/pdf/2312.04148" title="Download PDF">pdf</a>, <a href="/ps/2312.04148" title="Download PostScript">ps</a>, <a href="/format/2312.04148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Damping Torque Analysis of Ultra-Low Frequency Oscillation  in the Jerk Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Yichen Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+T">Tao Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yonggang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Ultra low frequency oscillation (ULFO) is significantly threatening the power
system stability. Its unstable mechanism is mostly studied via generalized
damping torque analysis method (GDTA). However, the analysis still adopts the
framework established for low frequency oscillation. Hence, this letter
proposes a GDTA approach in the jerk space for ULFO. A multi-information
variable is constructed to transform the system into a new state space, where
it is found that the jerk dynamics of the turbine-generator cascaded system is
a second-order differential equation. Benefiting from this characteristic, we
propose a new form for GDTA using jerk dynamics, which is established in the
frequency-frequency acceleration phase space. Then, analytical expressions of
all damping torque are provided. Finally, test results verified the proposed
theoretical results. The negative damping mechanism is revealed, and parameter
adjustment measures are concluded.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04152" title="Abstract">arXiv:2312.04152</a> [<a href="/pdf/2312.04152" title="Download PDF">pdf</a>, <a href="/format/2312.04152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EulerMormer: Robust Eulerian Motion Magnification via Dynamic Filtering  within Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Dan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kun Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Meng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video Motion Magnification (VMM) aims to break the resolution limit of human
visual perception capability and reveal the imperceptible minor motion that
contains valuable information in the macroscopic domain. However, challenges
arise in this task due to photon noise inevitably introduced by photographic
devices and spatial inconsistency in amplification, leading to flickering
artifacts in static fields and motion blur and distortion in dynamic fields in
the video. Existing methods focus on explicit motion modeling without
emphasizing prioritized denoising during the motion magnification process. This
paper proposes a novel dynamic filtering strategy to achieve static-dynamic
field adaptive denoising. Specifically, based on Eulerian theory, we separate
texture and shape to extract motion representation through inter-frame shape
differences, expecting to leverage these subdivided features to solve this task
finely. Then, we introduce a novel dynamic filter that eliminates noise cues
and preserves critical features in the motion magnification and amplification
generation phases. Overall, our unified framework, EulerMormer, is a pioneering
effort to first equip with Transformer in learning-based VMM. The core of the
dynamic filter lies in a global dynamic sparse cross-covariance attention
mechanism that explicitly removes noise while preserving vital information,
coupled with a multi-scale dual-path gating mechanism that selectively
regulates the dependence on different frequency features to reduce spatial
attenuation and complement motion boundaries. We demonstrate extensive
experiments that EulerMormer achieves more robust video motion magnification
from the Eulerian perspective, significantly outperforming state-of-the-art
methods. The source code is available at
https://github.com/VUT-HFUT/EulerMormer.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04158" title="Abstract">arXiv:2312.04158</a> [<a href="/pdf/2312.04158" title="Download PDF">pdf</a>, <a href="/format/2312.04158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safety-Enhanced Self-Learning for Optimal Power Converter Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wan%2C+Y">Yihao Wan</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Q">Qianwen Xu</a>, 
<a href="/search/eess?searchtype=author&query=Dragi%C4%8Devi%C4%87%2C+T">Tomislav Dragi&#x10d;evi&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Data-driven learning-based control methods such as reinforcement learning
(RL) have become increasingly popular with recent proliferation of the machine
learning paradigm. These methods address the parameter sensitiveness and
unmodeled dynamics in model-based controllers, such as finite control-set model
predictive control. RL agents are typically utilized in simulation
environments, where they are allowed to explore multiple "unsafe" actions
during the learning process. However, this type of learning is not applicable
to online self-learning of controllers in physical power converters, because
unsafe actions would damage them. To address this, this letter proposes a safe
online RL-based control framework to autonomously find the optimal switching
strategy for the power converters, while ensuring system safety during the
entire self-learning process. The proposed safe online RL-based control is
validated in a practical testbed on a two-level voltage source converter
system, and the results confirm the effectiveness of the proposed method.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04159" title="Abstract">arXiv:2312.04159</a> [<a href="/pdf/2312.04159" title="Download PDF">pdf</a>, <a href="/ps/2312.04159" title="Download PostScript">ps</a>, <a href="/format/2312.04159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Touch Networks: Towards Next-Generation Network Automation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajab%2C+M+E">Mirna El Rajab</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Li Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shami%2C+A">Abdallah Shami</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 115 pages, 12 figures, 15 tables, submitted to Computer Networks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The Zero-touch network and Service Management (ZSM) framework represents an
emerging paradigm in the management of the fifth-generation (5G) and Beyond
(5G+) networks, offering automated self-management and self-healing
capabilities to address the escalating complexity and the growing data volume
of modern networks. ZSM frameworks leverage advanced technologies such as
Machine Learning (ML) to enable intelligent decision-making and reduce human
intervention. This paper presents a comprehensive survey of Zero-Touch Networks
(ZTNs) within the ZSM framework, covering network optimization, traffic
monitoring, energy efficiency, and security aspects of next-generational
networks. The paper explores the challenges associated with ZSM, particularly
those related to ML, which necessitate the need to explore diverse network
automation solutions. In this context, the study investigates the application
of Automated ML (AutoML) in ZTNs, to reduce network management costs and
enhance performance. AutoML automates the selection and tuning process of a ML
model for a given task. Specifically, the focus is on AutoML's ability to
predict application throughput and autonomously adapt to data drift.
Experimental results demonstrate the superiority of the proposed AutoML
pipeline over traditional ML in terms of prediction accuracy. Integrating
AutoML and ZSM concepts significantly reduces network configuration and
management efforts, allowing operators to allocate more time and resources to
other important tasks. The paper also provides a high-level 5G system
architecture incorporating AutoML and ZSM concepts. This research highlights
the potential of ZTNs and AutoML to revolutionize the management of 5G+
networks, enabling automated decision-making and empowering network operators
to achieve higher efficiency, improved performance, and enhanced user
experience.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04160" title="Abstract">arXiv:2312.04160</a> [<a href="/pdf/2312.04160" title="Download PDF">pdf</a>, <a href="/format/2312.04160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text as Image: Learning Transferable Adapter for Multi-Label  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xuelin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiuxin Cao</a>, 
<a href="/search/cs?searchtype=author&query=liu%2C+J">Jian liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+D">Dongqi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Furong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weijia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+J">Jiawei Ge</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qingpei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Pre-trained vision-language models have notably accelerated progress of
open-world concept recognition. Their impressive zero-shot ability has recently
been transferred to multi-label image classification via prompt tuning,
enabling to discover novel labels in an open-vocabulary manner. However, this
paradigm suffers from non-trivial training costs, and becomes computationally
prohibitive for a large number of candidate labels. To address this issue, we
note that vision-language pre-training aligns images and texts in a unified
embedding space, making it potential for an adapter network to identify labels
in visual modality while be trained in text modality. To enhance such
cross-modal transfer ability, a simple yet effective method termed random
perturbation is proposed, which enables the adapter to search for potential
visual embeddings by perturbing text embeddings with noise during training,
resulting in better performance in visual modality. Furthermore, we introduce
an effective approach to employ large language models for multi-label
instruction-following text generation. In this way, a fully automated pipeline
for visual label recognition is developed without relying on any manual data.
Extensive experiments on public benchmarks show the superiority of our method
in various multi-label classification tasks.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04161" title="Abstract">arXiv:2312.04161</a> [<a href="/pdf/2312.04161" title="Download PDF">pdf</a>, <a href="/format/2312.04161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling and Numerical Analysis of Kangaroo Lower Body based on  Constrained Dynamics of Hybrid Serial-Parallel Floating-Base Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoffman%2C+E+M">Enrico Mingo Hoffman</a>, 
<a href="/search/cs?searchtype=author&query=Curti%2C+A">Andrea Curti</a>, 
<a href="/search/cs?searchtype=author&query=Miguel%2C+N">Narcis Miguel</a>, 
<a href="/search/cs?searchtype=author&query=Kothakota%2C+S+K">Sai Kishor Kothakota</a>, 
<a href="/search/cs?searchtype=author&query=Molina%2C+A">Alberto Molina</a>, 
<a href="/search/cs?searchtype=author&query=Roig%2C+A">Adria Roig</a>, 
<a href="/search/cs?searchtype=author&query=Marchionni%2C+L">Luca Marchionni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents the modeling and numerical analysis of the Kangaroo lower
body prototype, a novel bipedal humanoid robot developed and manufactured by
PAL Robotics. Kangaroo features high-power linear electric actuators combined
with unique serial-parallel hybrid chains, which allow for the positioning of
all the leg actuators near the base of the robot in order to improve the
overall mass distribution. To model and analyze such complex nonlinear
mechanisms, we employ a constrained formulation that is extended to account for
floating-base systems in contact with the environment. A comparison is made to
demonstrate the significant improvements achieved with TALOS, another humanoid
bipedal robot designed by PAL Robotics, in terms of equivalent Cartesian
inertia at the feet and centroidal angular momentum. Finally, the paper
includes numerical experiments conducted through simulation and preliminary
tests performed on the actual Kangaroo platform.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04166" title="Abstract">arXiv:2312.04166</a> [<a href="/pdf/2312.04166" title="Download PDF">pdf</a>, <a href="/format/2312.04166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Communication Efficiency of Federated Distillation via  Accumulating Local Updates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Sheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Min Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+T">Tian Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wen Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">As an emerging federated learning paradigm, federated distillation enables
communication-efficient model training by transmitting only small-scale
knowledge during the learning process. To further improve the communication
efficiency of federated distillation, we propose a novel technique, ALU, which
accumulates multiple rounds of local updates before transferring the knowledge
to the central server. ALU drastically decreases the frequency of communication
in federated distillation, thereby significantly reducing the communication
overhead during the training process. Empirical experiments demonstrate the
substantial effect of ALU in improving the communication efficiency of
federated distillation.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04167" title="Abstract">arXiv:2312.04167</a> [<a href="/pdf/2312.04167" title="Download PDF">pdf</a>, <a href="/format/2312.04167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixture of Dynamical Variational Autoencoders for Multi-Source  Trajectory Modeling and Separation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiaoyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Girin%2C+L">Laurent Girin</a>, 
<a href="/search/cs?searchtype=author&query=Alameda-Pineda%2C+X">Xavier Alameda-Pineda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2202.09315">arXiv:2202.09315</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper, we propose a latent-variable generative model called mixture
of dynamical variational autoencoders (MixDVAE) to model the dynamics of a
system composed of multiple moving sources. A DVAE model is pre-trained on a
single-source dataset to capture the source dynamics. Then, multiple instances
of the pre-trained DVAE model are integrated into a multi-source mixture model
with a discrete observation-to-source assignment latent variable. The posterior
distributions of both the discrete observation-to-source assignment variable
and the continuous DVAE variables representing the sources content/position are
estimated using a variational expectation-maximization algorithm, leading to
multi-source trajectories estimation. We illustrate the versatility of the
proposed MixDVAE model on two tasks: a computer vision task, namely
multi-object tracking, and an audio processing task, namely single-channel
audio source separation. Experimental results show that the proposed method
works well on these two tasks, and outperforms several baseline methods.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04168" title="Abstract">arXiv:2312.04168</a> [<a href="/pdf/2312.04168" title="Download PDF">pdf</a>, <a href="/format/2312.04168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmentation-Free Dense Contrastive Knowledge Distillation for Efficient  Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jiawei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chao Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaolong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Meina Song</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+A">Anbang Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper of Af-DCD is accepted to NeurIPS 2023. Code and models are available at <a href="https://github.com/OSVAI/Af-DCD">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, knowledge distillation methods based on contrastive learning
have achieved promising results on image classification and object detection
tasks. However, in this line of research, we note that less attention is paid
to semantic segmentation. Existing methods heavily rely on data augmentation
and memory buffer, which entail high computational resource demands when
applying them to handle semantic segmentation that requires to preserve
high-resolution feature maps for making dense pixel-wise predictions. In order
to address this problem, we present Augmentation-free Dense Contrastive
Knowledge Distillation (Af-DCD), a new contrastive distillation learning
paradigm to train compact and accurate deep neural networks for semantic
segmentation applications. Af-DCD leverages a masked feature mimicking
strategy, and formulates a novel contrastive learning loss via taking advantage
of tactful feature partitions across both channel and spatial dimensions,
allowing to effectively transfer dense and structured local knowledge learnt by
the teacher model to a target student model while maintaining training
efficiency. Extensive experiments on five mainstream benchmarks with various
teacher-student network pairs demonstrate the effectiveness of our approach.
For instance, the DeepLabV3-Res18|DeepLabV3-MBV2 model trained by Af-DCD
reaches 77.03%|76.38% mIOU on Cityscapes dataset when choosing DeepLabV3-Res101
as the teacher, setting new performance records. Besides that, Af-DCD achieves
an absolute mIOU improvement of 3.26%|3.04%|2.75%|2.30%|1.42% compared with
individually trained counterpart on Cityscapes|Pascal
VOC|Camvid|ADE20K|COCO-Stuff-164K. Code is available at
https://github.com/OSVAI/Af-DCD
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04171" title="Abstract">arXiv:2312.04171</a> [<a href="/pdf/2312.04171" title="Download PDF">pdf</a>, <a href="/format/2312.04171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A novel feature selection framework for incomplete data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Cong Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Feature selection on incomplete datasets is an exceptionally challenging
task. Existing methods address this challenge by first employing imputation
methods to complete the incomplete data and then conducting feature selection
based on the imputed data. Since imputation and feature selection are entirely
independent steps, the importance of features cannot be considered during
imputation. However, in real-world scenarios or datasets, different features
have varying degrees of importance. To address this, we propose a novel
incomplete data feature selection framework that considers feature importance.
The framework mainly consists of two alternating iterative stages: the M-stage
and the W-stage. In the M-stage, missing values are imputed based on a given
feature importance vector and multiple initial imputation results. In the
W-stage, an improved reliefF algorithm is employed to learn the feature
importance vector based on the imputed data. Specifically, the feature
importance vector obtained in the current iteration of the W-stage serves as
input for the next iteration of the M-stage. Experimental results on both
artificially generated and real incomplete datasets demonstrate that the
proposed method outperforms other approaches significantly.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04173" title="Abstract">arXiv:2312.04173</a> [<a href="/pdf/2312.04173" title="Download PDF">pdf</a>, <a href="/format/2312.04173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contract Wallet Using Emails
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suegami%2C+S">Sora Suegami</a>, 
<a href="/search/cs?searchtype=author&query=Shibano%2C+K">Kyohei Shibano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE International Conference on Blockchain and
  Cryptocurrency (ICBC), Dubai, United Arab Emirates, 2023, pp. 1-2.
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">We proposed a new construction for contract wallets, smart contract
applications that allow users to control their crypto assets. Users can
manipulate their crypto assets by simply sending emails with no need to manage
keys. These emails are verified using zero-knowledge proof (ZKP) along with
their attached digital signatures that the sender domain server (SDS) generates
according to DomainKeys Identified Mail. Unless the SDS forges the emails, the
crypto assets remain secure in the proposed system. Moreover, the existing SDSs
can be used as is by outsourcing additional work to a third party that is not
necessarily trusted. The system supports various functions to manipulate crypto
assets. We produced a tool for variable-regex mapping (VRM) that enables
developers to build a new function without ZKP skills. For example, using the
tool, we built a demo application where users can exchange crypto assets via
Uniswap only with emails. The published version of this paper is available at
https://doi.org/10.1109/ICBC5<a href="/abs/6567.2023">6567.2023</a>.10174932.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04180" title="Abstract">arXiv:2312.04180</a> [<a href="/pdf/2312.04180" title="Download PDF">pdf</a>, <a href="/format/2312.04180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI and Jobs: Has the Inflection Point Arrived? Evidence from an Online  Labor Platform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiao%2C+D">Dandan Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Rui%2C+H">Huaxia Rui</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Q">Qian Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 6 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); General Economics (econ.GN)

</div>
<p class="mathjax">Artificial intelligence (AI) refers to the ability of machines or software to
mimic or even surpass human intelligence in a given cognitive task. While
humans learn by both induction and deduction, the success of current AI is
rooted in induction, relying on its ability to detect statistical regularities
in task input -- an ability learnt from a vast amount of training data using
enormous computation resources. We examine the performance of such a
statistical AI in a human task through the lens of four factors, including task
learnability, statistical resource, computation resource, and learning
techniques, and then propose a three-phase visual framework to understand the
evolving relation between AI and jobs. Based on this conceptual framework, we
develop a simple economic model of competition to show the existence of an
inflection point for each occupation. Before AI performance crosses the
inflection point, human workers always benefit from an improvement in AI
performance, but after the inflection point, human workers become worse off
whenever such an improvement occurs. To offer empirical evidence, we first
argue that AI performance has passed the inflection point for the occupation of
translation but not for the occupation of web development. We then study how
the launch of ChatGPT, which led to significant improvement of AI performance
on many tasks, has affected workers in these two occupations on a large online
labor platform. Consistent with the inflection point conjecture, we find that
translators are negatively affected by the shock both in terms of the number of
accepted jobs and the earnings from those jobs, while web developers are
positively affected by the very same shock. Given the potentially large
disruption of AI on employment, more studies on more occupations using data
from different platforms are urgently needed.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04181" title="Abstract">arXiv:2312.04181</a> [<a href="/pdf/2312.04181" title="Download PDF">pdf</a>, <a href="/format/2312.04181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cell segmentation of in situ transcriptomics data using signed graph  partitioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Andersson%2C+A">Axel Andersson</a>, 
<a href="/search/cs?searchtype=author&query=Behanova%2C+A">Andrea Behanova</a>, 
<a href="/search/cs?searchtype=author&query=W%C3%A4hlby%2C+C">Carolina W&#xe4;hlby</a>, 
<a href="/search/cs?searchtype=author&query=Malmberg%2C+F">Filip Malmberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at GbRPR 2023: Graph-Based Representations in Pattern Recognition
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> GbRPR 2023. Lecture Notes in Computer Science, vol 14121.
  Springer, Cham
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">The locations of different mRNA molecules can be revealed by multiplexed in
situ RNA detection. By assigning detected mRNA molecules to individual cells,
it is possible to identify many different cell types in parallel. This in turn
enables investigation of the spatial cellular architecture in tissue, which is
crucial for furthering our understanding of biological processes and diseases.
However, cell typing typically depends on the segmentation of cell nuclei,
which is often done based on images of a DNA stain, such as DAPI. Limiting cell
definition to a nuclear stain makes it fundamentally difficult to determine
accurate cell borders, and thereby also difficult to assign mRNA molecules to
the correct cell. As such, we have developed a computational tool that segments
cells solely based on the local composition of mRNA molecules. First, a small
neural network is trained to compute attractive and repulsive edges between
pairs of mRNA molecules. The signed graph is then partitioned by a mutex
watershed into components corresponding to different cells. We evaluated our
method on two publicly available datasets and compared it against the current
state-of-the-art and older baselines. We conclude that combining neural
networks with combinatorial optimization is a promising approach for cell
segmentation of in situ transcriptomics data.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04182" title="Abstract">arXiv:2312.04182</a> [<a href="/pdf/2312.04182" title="Download PDF">pdf</a>, <a href="/format/2312.04182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Persuasion for Containing SIS Epidemic with Asymptomatic  Infection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hota%2C+A+R">Ashish R. Hota</a>, 
<a href="/search/eess?searchtype=author&query=Satapathi%2C+A">Abhisek Satapathi</a>, 
<a href="/search/eess?searchtype=author&query=Maitra%2C+U">Urmee Maitra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">We investigate the strategic behavior of a large population of agents who
decide whether to adopt a costly partially effective protection or remain
unprotected against the susceptible-infected-susceptible epidemic. In contrast
with most prior works on epidemic games, we assume that the agents are not
aware of their true infection status while making decisions. We adopt the
Bayesian persuasion framework where the agents receive a noisy signal regarding
their true infection status, and maximize their expected utility computed using
the posterior probability of being infected conditioned on the received signal.
We completely characterize the stationary Nash equilibrium of this setting, and
identify conditions under which partial information disclosure leads to a
smaller proportion of infected individuals at the equilibrium compared to full
information disclosure, and vice versa.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04183" title="Abstract">arXiv:2312.04183</a> [<a href="/pdf/2312.04183" title="Download PDF">pdf</a>, <a href="/ps/2312.04183" title="Download PostScript">ps</a>, <a href="/format/2312.04183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced data Detection for Massive MIMO with 1-Bit ADCs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Radbord%2C+A">Amin Radbord</a>, 
<a href="/search/cs?searchtype=author&query=Atzeni%2C+I">Italo Atzeni</a>, 
<a href="/search/cs?searchtype=author&query=Tolli%2C+A">Antti Tolli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the IEEE Asilomar Conference on Signals, Systems, and Computers 2023. arXiv admin note: text overlap with <a href="/abs/2303.18061">arXiv:2303.18061</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">We present new insightful results on the uplink data detection for massive
multiple-input multiple-output systems with 1-bit analog-to-digital converters.
The expected values of the soft-estimated symbols (i.e., after the linear
combining and prior to the data detection) have been recently characterized for
multiple user equipments (UEs) and maximum ratio combining (MRC) receiver at
the base station. In this paper, we first provide a numerical evaluation of the
expected value of the soft-estimated symbols with zero-forcing (ZF) and minimum
mean squared error (MMSE) receivers for a multi-UE setting with correlated
Rayleigh fading. Then, we propose a joint data detection (JD) strategy, which
exploits the interdependence among the soft-estimated symbols of the
interfering UEs, along with its low-complexity variant. These strategies are
compared with a naive approach that adapts the maximum-likelihood data
detection to the 1-bit quantization. Numerical results show that ZF and MMSE
provide considerable gains over MRC in terms of symbol error rate. Moreover,
the proposed JD and its low-complexity variant provide a significant boost in
comparison with the single-UE data detection.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04187" title="Abstract">arXiv:2312.04187</a> [<a href="/pdf/2312.04187" title="Download PDF">pdf</a>, <a href="/ps/2312.04187" title="Download PostScript">ps</a>, <a href="/format/2312.04187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enumerating Complexity Revisited
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shekhovtsov%2C+A">Alexander Shekhovtsov</a>, 
<a href="/search/cs?searchtype=author&query=Zakharov%2C+G">Georgii Zakharov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">We reduce the best-known upper bound on the length of a program that
enumerates a set in terms of the probability of it being enumerated by a random
program. We prove a general result that any linear upper bound for finite sets
implies the same linear bound for infinite sets.
<br />So far, the best-known upper bound was given by Solovay. He showed that the
minimum length of a program enumerating a subset $S$ of natural numbers is
bounded by minus three binary logarithms of the probability that a random
program will enumerate $S$. Later, Vereshchagin showed that the constant can be
improved from three to two for finite sets. In this work, using an improvement
of the method proposed by Solovay, we demonstrate that any bound for finite
sets implies the same for infinite sets, modulo logarithmic factors. Using
Vereshchagin's result, we improve the current best-known upper bound from three
to two.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04189" title="Abstract">arXiv:2312.04189</a> [<a href="/pdf/2312.04189" title="Download PDF">pdf</a>, <a href="/format/2312.04189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint-Individual Fusion Structure with Fusion Attention Module for  Multi-Modal Skin Cancer Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+P">Peng Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xintong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Nan%2C+Y">Yang Nan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaobin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaobin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Krammer%2C+B+H+M+S">Bjoern H Menzee.Sebastian Krammer</a>, 
<a href="/search/cs?searchtype=author&query=Lasser%2C+T">Tobias Lasser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to Pattern Recognition journal before 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Most convolutional neural network (CNN) based methods for skin cancer
classification obtain their results using only dermatological images. Although
good classification results have been shown, more accurate results can be
achieved by considering the patient's metadata, which is valuable clinical
information for dermatologists. Current methods only use the simple joint
fusion structure (FS) and fusion modules (FMs) for the multi-modal
classification methods, there still is room to increase the accuracy by
exploring more advanced FS and FM. Therefore, in this paper, we design a new
fusion method that combines dermatological images (dermoscopy images or
clinical images) and patient metadata for skin cancer classification from the
perspectives of FS and FM. First, we propose a joint-individual fusion (JIF)
structure that learns the shared features of multi-modality data and preserves
specific features simultaneously. Second, we introduce a fusion attention (FA)
module that enhances the most relevant image and metadata features based on
both the self and mutual attention mechanism to support the decision-making
pipeline. We compare the proposed JIF-MMFA method with other state-of-the-art
fusion methods on three different public datasets. The results show that our
JIF-MMFA method improves the classification results for all tested CNN
backbones and performs better than the other fusion methods on the three public
datasets, demonstrating our method's effectiveness and robustness
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04190" title="Abstract">arXiv:2312.04190</a> [<a href="/pdf/2312.04190" title="Download PDF">pdf</a>, <a href="/format/2312.04190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Receding Horizon Re-ordering of Multi-Agent Execution Schedules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berndt%2C+A">Alexander Berndt</a>, 
<a href="/search/cs?searchtype=author&query=van+Duijkeren%2C+N">Niels van Duijkeren</a>, 
<a href="/search/cs?searchtype=author&query=Palmieri%2C+L">Luigi Palmieri</a>, 
<a href="/search/cs?searchtype=author&query=Kleiner%2C+A">Alexander Kleiner</a>, 
<a href="/search/cs?searchtype=author&query=Keviczky%2C+T">Tam&#xe1;s Keviczky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Transactions on Robotics (T-Ro) preprint, 17 pages, 32 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The trajectory planning for a fleet of Automated Guided Vehicles (AGVs) on a
roadmap is commonly referred to as the Multi-Agent Path Finding (MAPF) problem,
the solution to which dictates each AGV's spatial and temporal location until
it reaches it's goal without collision. When executing MAPF plans in dynamic
workspaces, AGVs can be frequently delayed, e.g., due to encounters with humans
or third-party vehicles. If the remainder of the AGVs keeps following their
individual plans, synchrony of the fleet is lost and some AGVs may pass through
roadmap intersections in a different order than originally planned. Although
this could reduce the cumulative route completion time of the AGVs, generally,
a change in the original ordering can cause conflicts such as deadlocks. In
practice, synchrony is therefore often enforced by using a MAPF execution
policy employing, e.g., an Action Dependency Graph (ADG) to maintain ordering.
To safely re-order without introducing deadlocks, we present the concept of the
Switchable Action Dependency Graph (SADG). Using the SADG, we formulate a
comparatively low-dimensional Mixed-Integer Linear Program (MILP) that
repeatedly re-orders AGVs in a recursively feasible manner, thus maintaining
deadlock-free guarantees, while dynamically minimizing the cumulative route
completion time of all AGVs. Various simulations validate the efficiency of our
approach when compared to the original ADG method as well as robust MAPF
solution approaches.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04193" title="Abstract">arXiv:2312.04193</a> [<a href="/pdf/2312.04193" title="Download PDF">pdf</a>, <a href="/ps/2312.04193" title="Download PostScript">ps</a>, <a href="/format/2312.04193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Model Knowledge Distillation for Efficient Question Answering  in Spanish
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bazaga%2C+A">Adri&#xe1;n Bazaga</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>, 
<a href="/search/cs?searchtype=author&query=Micklem%2C+G">Gos Micklem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Recent advances in the development of pre-trained Spanish language models has
led to significant progress in many Natural Language Processing (NLP) tasks,
such as question answering. However, the lack of efficient models imposes a
barrier for the adoption of such models in resource-constrained environments.
Therefore, smaller distilled models for the Spanish language could be proven to
be highly scalable and facilitate their further adoption on a variety of tasks
and scenarios. In this work, we take one step in this direction by developing
SpanishTinyRoBERTa, a compressed language model based on RoBERTa for efficient
question answering in Spanish. To achieve this, we employ knowledge
distillation from a large model onto a lighter model that allows for a wider
implementation, even in areas with limited computational resources, whilst
attaining negligible performance sacrifice. Our experiments show that the dense
distilled model can still preserve the performance of its larger counterpart,
while significantly increasing inference speedup. This work serves as a
starting point for further research and investigation of model compression
efforts for Spanish language models across various NLP tasks.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04197" title="Abstract">arXiv:2312.04197</a> [<a href="/pdf/2312.04197" title="Download PDF">pdf</a>, <a href="/format/2312.04197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAMBA: A Trainable Segmentation Web-App with Smart Labelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Docherty%2C+R">Ronan Docherty</a>, 
<a href="/search/cs?searchtype=author&query=Squires%2C+I">Isaac Squires</a>, 
<a href="/search/cs?searchtype=author&query=Vamvakeros%2C+A">Antonis Vamvakeros</a>, 
<a href="/search/cs?searchtype=author&query=Cooper%2C+S+J">Samuel J. Cooper</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Segmentation is the assigning of a semantic class to every pixel in an image
and is a prerequisite for various statistical analysis tasks in materials
science, like phase quantification, physics simulations or morphological
characterization. The wide range of length scales, imaging techniques and
materials studied in materials science means any segmentation algorithm must
generalise to unseen data and support abstract, user-defined semantic classes.
Trainable segmentation is a popular interactive segmentation paradigm where a
classifier is trained to map from image features to user drawn labels. SAMBA is
a trainable segmentation tool that uses Meta's Segment Anything Model (SAM) for
fast, high-quality label suggestions and a random forest classifier for robust,
generalizable segmentations. It is accessible in the browser
(https://www.sambasegment.com/) without the need to download any external
dependencies. The segmentation backend is run in the cloud, so does not require
the user to have powerful hardware.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04198" title="Abstract">arXiv:2312.04198</a> [<a href="/pdf/2312.04198" title="Download PDF">pdf</a>, <a href="/format/2312.04198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Formation Maneuver Control Using Complex Laplacian
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fang%2C+X">Xu Fang</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+L">Lihua Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper studies the problem of distributed formation maneuver control of
multi-agent systems via complex Laplacian. We will show how to change the
translation, scaling, rotation, and also the shape of formation continuously by
only tuning the positions of the leaders in both 2-D and 3-D spaces, where the
rotation of formation in 3-D space is realized by changing the yaw angle, pitch
angle, and roll angle of formation sequentially. Compared with
real-Laplacian-based methods, the first advantage of the proposed
complex-Laplacian-based approach is that each follower requires fewer neighbors
and lesser communication. The second advantage is that non-convex and
non-generic nominal configurations are allowed and the uniqueness of the
complex-constraint-based target formation can be guaranteed by the
non-collocated nominal agents. The third advantage is that more formation
shapes can be realized by only tuning the positions of the leaders. Two
simulation examples are given to illustrate the theoretical results.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04204" title="Abstract">arXiv:2312.04204</a> [<a href="/pdf/2312.04204" title="Download PDF">pdf</a>, <a href="/ps/2312.04204" title="Download PostScript">ps</a>, <a href="/format/2312.04204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wavelength-multiplexed Delayed Inputs for Memory Enhancement of  Microring-based Reservoir Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castro%2C+B+J+G">Bernard J. Giron Castro</a>, 
<a href="/search/cs?searchtype=author&query=Peucheret%2C+C">Christophe Peucheret</a>, 
<a href="/search/cs?searchtype=author&query=Da+Ros%2C+F">Francesco Da Ros</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages, 2 figures. Submitted to Conference on Lasers and Electro-Optics (CLEO) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Emerging Technologies (cs.ET); Machine Learning (cs.LG)

</div>
<p class="mathjax">We numerically demonstrate a silicon add-drop microring-based reservoir
computing scheme that combines parallel delayed inputs and wavelength division
multiplexing. The scheme solves memory-demanding tasks like time-series
prediction with good performance without requiring external optical feedback.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04209" title="Abstract">arXiv:2312.04209</a> [<a href="/pdf/2312.04209" title="Download PDF">pdf</a>, <a href="/format/2312.04209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained Hierarchical Clustering via Graph Coarsening and Optimal  Cuts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mauduit%2C+E">Eliabelle Mauduit</a>, 
<a href="/search/cs?searchtype=author&query=Simonetto%2C+A">Andrea Simonetto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, appeared at the Asilomar Conference on Signals, Systems, and Computer, 11/2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Motivated by extracting and summarizing relevant information in short
sentence settings, such as satisfaction questionnaires, hotel reviews, and
X/Twitter, we study the problem of clustering words in a hierarchical fashion.
In particular, we focus on the problem of clustering with horizontal and
vertical structural constraints. Horizontal constraints are typically
cannot-link and must-link among words, while vertical constraints are
precedence constraints among cluster levels. We overcome state-of-the-art
bottlenecks by formulating the problem in two steps: first, as a
soft-constrained regularized least-squares which guides the result of a
sequential graph coarsening algorithm towards the horizontal feasible set.
Then, flat clusters are extracted from the resulting hierarchical tree by
computing optimal cut heights based on the available constraints. We show that
the resulting approach compares very well with respect to existing algorithms
and is computationally light.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04210" title="Abstract">arXiv:2312.04210</a> [<a href="/pdf/2312.04210" title="Download PDF">pdf</a>, <a href="/format/2312.04210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constraint Model for the Satellite Image Mosaic Selection Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sim%C3%B3n%2C+M+C">Manuel Combarro Sim&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Talbot%2C+P">Pierre Talbot</a>, 
<a href="/search/cs?searchtype=author&query=Danoy%2C+G">Gr&#xe9;goire Danoy</a>, 
<a href="/search/cs?searchtype=author&query=Musial%2C+J">Jedrzej Musial</a>, 
<a href="/search/cs?searchtype=author&query=Alswaitti%2C+M">Mohammed Alswaitti</a>, 
<a href="/search/cs?searchtype=author&query=Bouvry%2C+P">Pascal Bouvry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper contains minor corrections from the original document presented at the 29th International Conference on Principles and Practice of Constraint Programming (CP 2023). Minor corrections in Figures 5a and 5b that do not affect the analysis result. Minor typo corrections in Appendix A
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In 29th International Conference on Principles and Practice of
  Constraint Programming. Leibniz International Proceedings in Informatics
  (LIPIcs), Volume 280, pp. 44:1-44:15, Schloss Dagstuhl - Leibniz-Zentrum
  f\"ur Informatik (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computational Geometry (cs.CG); Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Satellite imagery solutions are widely used to study and monitor different
regions of the Earth. However, a single satellite image can cover only a
limited area. In cases where a larger area of interest is studied, several
images must be stitched together to create a single larger image, called a
mosaic, that can cover the area. Today, with the increasing number of satellite
images available for commercial use, selecting the images to build the mosaic
is challenging, especially when the user wants to optimize one or more
parameters, such as the total cost and the cloud coverage percentage in the
mosaic. More precisely, for this problem the input is an area of interest,
several satellite images intersecting the area, a list of requirements relative
to the image and the mosaic, such as cloud coverage percentage, image
resolution, and a list of objectives to optimize. We contribute to the
constraint and mixed integer lineal programming formulation of this new
problem, which we call the \textit{satellite image mosaic selection problem},
which is a multi-objective extension of the polygon cover problem. We propose a
dataset of realistic and challenging instances, where the images were captured
by the satellite constellations SPOT, Pl\'eiades and Pl\'eiades Neo. We
evaluate and compare the two proposed models and show their efficiency for
large instances, up to 200 images.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04216" title="Abstract">arXiv:2312.04216</a> [<a href="/pdf/2312.04216" title="Download PDF">pdf</a>, <a href="/format/2312.04216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CODEX: A Cluster-Based Method for Explainable Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mathes%2C+T+K">Timothy K. Mathes</a>, 
<a href="/search/cs?searchtype=author&query=Inman%2C+J">Jessica Inman</a>, 
<a href="/search/cs?searchtype=author&query=Col%C3%B3n%2C+A">Andr&#xe9;s Col&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Simon Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the International Joint Conference on Artificial Intelligence (IJCAI) 2023 Workshop on Explainable Artificial Intelligence (XAI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Despite the impressive feats demonstrated by Reinforcement Learning (RL),
these algorithms have seen little adoption in high-risk, real-world
applications due to current difficulties in explaining RL agent actions and
building user trust. We present Counterfactual Demonstrations for Explanation
(CODEX), a method that incorporates semantic clustering, which can effectively
summarize RL agent behavior in the state-action space. Experimentation on the
MiniGrid and StarCraft II gaming environments reveals the semantic clusters
retain temporal as well as entity information, which is reflected in the
constructed summary of agent behavior. Furthermore, clustering the
discrete+continuous game-state latent representations identifies the most
crucial episodic events, demonstrating a relationship between the latent and
semantic spaces. This work contributes to the growing body of work that strives
to unlock the power of RL for widespread use by leveraging and extending
techniques from Natural Language Processing.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04217" title="Abstract">arXiv:2312.04217</a> [<a href="/pdf/2312.04217" title="Download PDF">pdf</a>, <a href="/ps/2312.04217" title="Download PostScript">ps</a>, <a href="/format/2312.04217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hybrid Monte Carlo, Discontinuous Galerkin method for linear kinetic  transport equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Krotz%2C+J">Johannes Krotz</a>, 
<a href="/search/math?searchtype=author&query=Hauck%2C+C+D">Cory D. Hauck</a>, 
<a href="/search/math?searchtype=author&query=McClarren%2C+R+G">Ryan G. McClarren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present a hybrid method for time-dependent particle transport problems
that combines Monte Carlo (MC) estimation with deterministic solutions based on
discrete ordinates. For spatial discretizations, the MC algorithm computes a
piecewise constant solution and the discrete ordinates uses bilinear
discontinuous finite elements. From the hybridization of the problem, the
resulting problem solved by Monte Carlo is scattering free, resulting in a
simple, efficient solution procedure. Between time steps, we use a projection
approach to ``relabel'' collided particles as uncollided particles. From a
series of standard 2-D Cartesian test problems we observe that our hybrid
method has improved accuracy and reduction in computational complexity of
approximately an order of magnitude relative to standard discrete ordinates
solutions.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04219" title="Abstract">arXiv:2312.04219</a> [<a href="/pdf/2312.04219" title="Download PDF">pdf</a>, <a href="/format/2312.04219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Swap distance minimization in SOV languages. Cognitive and mathematical  foundations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferrer-i-Cancho%2C+R">Ramon Ferrer-i-Cancho</a>, 
<a href="/search/cs?searchtype=author&query=Namboodiripad%2C+S">Savithry Namboodiripad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Distance minimization is a general principle of language. A special case of
this principle in the domain of word order is swap distance minimization. This
principle predicts that variations from a canonical order that are reached by
fewer swaps of adjacent constituents are lest costly and thus more likely. Here
we investigate the principle in the context of the triple formed by subject
(S), object (O) and verb (V). We introduce the concept of word order rotation
as a cognitive underpinning of that prediction. When the canonical order of a
language is SOV, the principle predicts SOV &lt; SVO, OSV &lt; VSO, OVS &lt; VOS, in
order of increasing cognitive cost. We test the prediction in three flexible
order SOV languages: Korean (Koreanic), Malayalam (Dravidian), and Sinhalese
(Indo-European). Evidence of swap distance minimization is found in all three
languages, but it is weaker in Sinhalese. Swap distance minimization is
stronger than a preference for the canonical order in Korean and especially
Malayalam.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04223" title="Abstract">arXiv:2312.04223</a> [<a href="/pdf/2312.04223" title="Download PDF">pdf</a>, <a href="/format/2312.04223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sensing the Body: Towards Best Practices for Integrating Physiological  Signals in HCI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chiossi%2C+F">Francesco Chiossi</a>, 
<a href="/search/cs?searchtype=author&query=Stepanova%2C+E+R">Ekaterina R. Stepanova</a>, 
<a href="/search/cs?searchtype=author&query=Tag%2C+B">Benjamin Tag</a>, 
<a href="/search/cs?searchtype=author&query=Perusquia-Hernandez%2C+M">Monica Perusquia-Hernandez</a>, 
<a href="/search/cs?searchtype=author&query=Kitson%2C+A">Alexandra Kitson</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+A">Arindam Dey</a>, 
<a href="/search/cs?searchtype=author&query=Mayer%2C+S">Sven Mayer</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+A+E">Abdallah El Ali</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Recently, we saw a trend toward using physiological signals in interactive
systems. These signals, offering deep insights into users' internal states and
health, herald a new era for HCI. However, as this is an interdisciplinary
approach, many challenges arise for HCI researchers, such as merging diverse
disciplines, from understanding physiological functions to design expertise.
Also, isolated research endeavors limit the scope and reach of findings. This
workshop aims to bridge these gaps, fostering cross-disciplinary discussions on
usability, open science, and ethics tied to physiological data in HCI. In this
workshop, we will discuss best practices for embedding physiological signals in
interactive systems. Through collective efforts, we seek to craft a guiding
document for best practices in physiological HCI research, ensuring that it
remains grounded in shared principles and methodologies as the field advances.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04224" title="Abstract">arXiv:2312.04224</a> [<a href="/pdf/2312.04224" title="Download PDF">pdf</a>, <a href="/format/2312.04224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameter fine-tuning method for MMG model using real-scale ship data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Suyama%2C+R">Rin Suyama</a>, 
<a href="/search/eess?searchtype=author&query=Matsushita%2C+R">Rintaro Matsushita</a>, 
<a href="/search/eess?searchtype=author&query=Kakuta%2C+R">Ryo Kakuta</a>, 
<a href="/search/eess?searchtype=author&query=Wakita%2C+K">Kouki Wakita</a>, 
<a href="/search/eess?searchtype=author&query=Maki%2C+A">Atsuo Maki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 11 figures, a preprint submitted to Ocean Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">In this paper, a fine-tuning method of the parameters in the MMG model for
the real-scale ship is proposed. In the proposed method, all of the arbitrarily
indicated target parameters of the MMG model are tuned simultaneously in the
framework of SI using time series data of real-sale ship maneuvering motion
data to steadily improve the accuracy of the MMG model. Parameter tuning is
formulated as a minimization problem of the deviation of the maneuvering motion
simulated with given parameters and the real-scale ship trials, and the global
solution is explored using CMA-ES. By constraining the exploration ranges to
the neighborhood of the previously determined parameter values, the proposed
method limits the output in a realistic range. The proposed method is applied
to the tuning of 12 parameters for a container ship with five different widths
of the exploration range. The results show that, in all cases, the accuracy of
the maneuvering simulation is improved by applying the tuned parameters to the
MMG model, and the validity of the proposed parameter fine-tuning method is
confirmed.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04225" title="Abstract">arXiv:2312.04225</a> [<a href="/pdf/2312.04225" title="Download PDF">pdf</a>, <a href="/format/2312.04225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TLCE: Transfer-Learning Based Classifier Ensembles for Few-Shot  Class-Incremental Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuangmei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tieru Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Few-shot class-incremental learning (FSCIL) struggles to incrementally
recognize novel classes from few examples without catastrophic forgetting of
old classes or overfitting to new classes. We propose TLCE, which ensembles
multiple pre-trained models to improve separation of novel and old classes.
TLCE minimizes interference between old and new classes by mapping old class
images to quasi-orthogonal prototypes using episodic training. It then
ensembles diverse pre-trained models to better adapt to novel classes despite
data imbalance. Extensive experiments on various datasets demonstrate that our
transfer learning ensemble approach outperforms state-of-the-art FSCIL methods.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04226" title="Abstract">arXiv:2312.04226</a> [<a href="/pdf/2312.04226" title="Download PDF">pdf</a>, <a href="/format/2312.04226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Data-Driven Digital Twins for Blockchain Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diamantopoulos%2C+G">Georgios Diamantopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Tziritas%2C+N">Nikos Tziritas</a>, 
<a href="/search/cs?searchtype=author&query=Bahsoon%2C+R">Rami Bahsoon</a>, 
<a href="/search/cs?searchtype=author&query=Theodoropoulos%2C+G">Georgios Theodoropoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 Pages, 5 Figures accepted for publication in InfoSymbiotics/Dynamic Data Driven Applications Systems (DDDAS2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Performance (cs.PF)

</div>
<p class="mathjax">In recent years, we have seen an increase in the adoption of blockchain-based
systems in non-financial applications, looking to benefit from what the
technology has to offer. Although many fields have managed to include
blockchain in their core functionalities, the adoption of blockchain, in
general, is constrained by the so-called trilemma trade-off between
decentralization, scalability, and security. In our previous work, we have
shown that using a digital twin for dynamically managing blockchain systems
during runtime can be effective in managing the trilemma trade-off. Our Digital
Twin leverages DDDAS feedback loop, which is responsible for getting the data
from the system to the digital twin, conducting optimisation, and updating the
physical system. This paper examines how leveraging DDDAS feedback loop can
support the optimisation component of the trilemma benefiting from
Reinforcement Learning agents and a simulation component to augment the quality
of the learned model while reducing the computational overhead required for
decision-making.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04227" title="Abstract">arXiv:2312.04227</a> [<a href="/pdf/2312.04227" title="Download PDF">pdf</a>, <a href="/format/2312.04227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Mentor-Student Communication with Symbolic Design for Message  States
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yuanzhe Jin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiali Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In the mentor-student communication process, students often struggle to
receive prompt and clear guidance from their mentors, making it challenging to
determine their next steps. When mentors don't respond promptly, it can lead to
student confusion, as they may be uncertain whether their message has been
acknowledged without resulting action. Instead of the binary options of "read"
and "unread," there's a pressing need for more nuanced descriptions of message
states. To tackle this ambiguity, we've developed a set of symbols to precisely
represent the cognitive states associated with messages in transit. Through
experimentation, this design not only assists mentors and students in
effectively labeling their responses but also mitigates unnecessary
misunderstandings. By utilizing symbols for accurate information and
understanding state marking, we've enhanced communication efficiency between
mentors and students, thereby improving the quality and efficacy of
communication in mentor-student relationships.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04231" title="Abstract">arXiv:2312.04231</a> [<a href="/pdf/2312.04231" title="Download PDF">pdf</a>, <a href="/format/2312.04231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adventures of Trustworthy Vision-Language Models: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vatsa%2C+M">Mayank Vatsa</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Anubhooti Jain</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+R">Richa Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, transformers have become incredibly popular in computer vision and
vision-language tasks. This notable rise in their usage can be primarily
attributed to the capabilities offered by attention mechanisms and the
outstanding ability of transformers to adapt and apply themselves to a variety
of tasks and domains. Their versatility and state-of-the-art performance have
established them as indispensable tools for a wide array of applications.
However, in the constantly changing landscape of machine learning, the
assurance of the trustworthiness of transformers holds utmost importance. This
paper conducts a thorough examination of vision-language transformers,
employing three fundamental principles of responsible AI: Bias, Robustness, and
Interpretability. The primary objective of this paper is to delve into the
intricacies and complexities associated with the practical use of transformers,
with the overarching goal of advancing our comprehension of how to enhance
their reliability and accountability.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04233" title="Abstract">arXiv:2312.04233</a> [<a href="/pdf/2312.04233" title="Download PDF">pdf</a>, <a href="/ps/2312.04233" title="Download PostScript">ps</a>, <a href="/format/2312.04233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-tune vision foundation model for crack segmentation in civil  infrastructures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+K">Kang Ge</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yutao Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large-scale foundation models have become the mainstream method in the field
of deep learning, while in civil engineering, the scale of AI models is
strictly limited. In this work, vision foundation model is introduced for crack
segmentation. Two Parameter-efficient fine-tuning methods, adapter and low-rank
adaptation, are adopted to fine-tune the foundation model in the field of
semantic segmentation: Segment Anything Model (SAM). The fine-tuned model
CrackSAM is much larger than all the existing crack segmentation models, but
shows excellent performance. To test the zero-shot performance of the proposed
method, two unique datasets related to road and exterior wall cracks are
collected, annotated and open-sourced, in total 810 images. Comparative
experiments are conducted with twelve mature semantic segmentation models. On
datasets with artificial noise and previously unseen datasets, the performance
of CrackSAM far exceeds that of all state-of-the-art models. CrackSAM exhibits
remarkable superiority, particularly in challenging conditions such as dim
lighting, shadows, road markings, construction joints, and other interference
factors. Such cross-scenario results demonstrate the outstanding zero-shot
capability of foundation models, and provide new ideas for the development of
vision models in civil engineering.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04234" title="Abstract">arXiv:2312.04234</a> [<a href="/pdf/2312.04234" title="Download PDF">pdf</a>, <a href="/format/2312.04234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Convolutions Enrich the Self-Attention in Transformers!
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jeongwhan Choi</a>, 
<a href="/search/cs?searchtype=author&query=Wi%2C+H">Hyowon Wi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jayoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+Y">Yehjin Shin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kookjin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Trask%2C+N">Nathaniel Trask</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+N">Noseong Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Transformers, renowned for their self-attention mechanism, have achieved
state-of-the-art performance across various tasks in natural language
processing, computer vision, time-series modeling, etc. However, one of the
challenges with deep Transformer models is the oversmoothing problem, where
representations across layers converge to indistinguishable values, leading to
significant performance degradation. We interpret the original self-attention
as a simple graph filter and redesign it from a graph signal processing (GSP)
perspective. We propose graph-filter-based self-attention (GFSA) to learn a
general yet effective one, whose complexity, however, is slightly larger than
that of the original self-attention mechanism. We demonstrate that GFSA
improves the performance of Transformers in various fields, including computer
vision, natural language processing, graph pattern classification, speech
recognition, and code classification.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04235" title="Abstract">arXiv:2312.04235</a> [<a href="/pdf/2312.04235" title="Download PDF">pdf</a>, <a href="/format/2312.04235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distances and shortest paths on graphs of bounded highway dimension:  simple, fast, dynamic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Collette%2C+S">S&#xe9;bastien Collette</a>, 
<a href="/search/cs?searchtype=author&query=Iacono%2C+J">John Iacono</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Dijkstra's algorithm is the standard method for computing shortest paths on
arbitrary graphs. However, it is slow for large graphs, taking at least linear
time. It has been long known that for real world road networks, creating a
hierarchy of well-chosen shortcuts allows fast distance and path computation,
with exact distance queries seemingly being answered in logarithmic time.
However, these methods were but heuristics until the work of Abraham et
al.~[JACM 2016], where they defined a graph parameter called highway dimension
which is constant for real-world road networks, and showed that in graphs of
constant highway dimension, a shortcut hierarchy exists that guarantees
shortest distance computation takes $O(\log (U+V))$ time and $O(V \log (U+V))$
space, where $U$ is the ratio of the smallest to largest edge, and $V$ is the
number of vertices. The problem is that they were unable to efficiently compute
the hierarchy of shortcuts. Here we present a simple and efficient algorithm to
compute the needed hierarchy of shortcuts in time and space $O(V \log (U+V))$,
as well as supporting updates in time $O( \log (U+V))$.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04236" title="Abstract">arXiv:2312.04236</a> [<a href="/pdf/2312.04236" title="Download PDF">pdf</a>, <a href="/format/2312.04236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting and Restoring Non-Standard Hands in Stable Diffusion Generated  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiqun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhenyue Qin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Campbell%2C+D">Dylan Campbell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We introduce a pipeline to address anatomical inaccuracies in Stable
Diffusion generated hand images. The initial step involves constructing a
specialized dataset, focusing on hand anomalies, to train our models
effectively. A finetuned detection model is pivotal for precise identification
of these anomalies, ensuring targeted correction. Body pose estimation aids in
understanding hand orientation and positioning, crucial for accurate anomaly
correction. The integration of ControlNet and InstructPix2Pix facilitates
sophisticated inpainting and pixel-level transformation, respectively. This
dual approach allows for high-fidelity image adjustments. This comprehensive
approach ensures the generation of images with anatomically accurate hands,
closely resembling real-world appearances. Our experimental results demonstrate
the pipeline's efficacy in enhancing hand image realism in Stable Diffusion
outputs. We provide an online demo at https://fixhand.yiqun.io
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04241" title="Abstract">arXiv:2312.04241</a> [<a href="/pdf/2312.04241" title="Download PDF">pdf</a>, <a href="/format/2312.04241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A novel time-domain direct sampling approach for inverse scattering  problems in acoustics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Guo%2C+Y">Yukun Guo</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+H">Hongjie Li</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+X">Xianchao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This work is concerned with an inverse scattering problem of determining
unknown scatterers from time-dependent acoustic measurements. A novel
time-domain direct sampling method is developed to efficiently determine both
the locations and shapes of inhomogeneous media. In particular, our approach is
very easy to implement since only cheap space-time integrations are involved in
the evaluation of the imaging functionals. Based on the Fourier-Laplace
transform, we establish an inherent connection between the time-domain and
frequency-domain direct sampling method. Moreover, rigorous theoretical
justifications and numerical experiments are provided to verify the validity
and feasibility of the proposed method.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04242" title="Abstract">arXiv:2312.04242</a> [<a href="/pdf/2312.04242" title="Download PDF">pdf</a>, <a href="/format/2312.04242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Signal Temporal Logic Control Synthesis among Uncontrollable Dynamic  Agents with Conformal Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yu%2C+X">Xinyi Yu</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Y">Yiqi Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Yin%2C+X">Xiang Yin</a>, 
<a href="/search/eess?searchtype=author&query=Lindemann%2C+L">Lars Lindemann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The control of dynamical systems under temporal logic specifications among
uncontrollable dynamic agents is challenging due to the agents' a-priori
unknown behavior. Existing works have considered the problem where either all
agents are controllable, the agent models are deterministic and known, or no
safety guarantees are provided. We propose a predictive control synthesis
framework that guarantees, with high probability, the satisfaction of signal
temporal logic (STL) tasks that are defined over the system and uncontrollable
stochastic agents. We use trajectory predictors and conformal prediction to
construct probabilistic prediction regions for each uncontrollable agent that
are valid over multiple future time steps. Specifically, we reduce conservatism
and increase data efficiency compared to existing works by constructing a
normalized prediction region over all agents and time steps. We then formulate
a worst-case mixed integer program (MIP) that accounts for all agent
realizations within the prediction region to obtain control inputs that
provably guarantee task satisfaction with high probability. To efficiently
solve this MIP, we propose an equivalent MIP program based on KKT conditions of
the original one. We illustrate our control synthesis framework on two case
studies.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04245" title="Abstract">arXiv:2312.04245</a> [<a href="/pdf/2312.04245" title="Download PDF">pdf</a>, <a href="/format/2312.04245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mastering Complex Coordination through Attention-based Dynamic Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Guangchong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeren Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+G">Guoliang Fan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The coordination between agents in multi-agent systems has become a popular
topic in many fields. To catch the inner relationship between agents, the graph
structure is combined with existing methods and improves the results. But in
large-scale tasks with numerous agents, an overly complex graph would lead to a
boost in computational cost and a decline in performance. Here we present
DAGMIX, a novel graph-based value factorization method. Instead of a complete
graph, DAGMIX generates a dynamic graph at each time step during training, on
which it realizes a more interpretable and effective combining process through
the attention mechanism. Experiments show that DAGMIX significantly outperforms
previous SOTA methods in large-scale scenarios, as well as achieving promising
results on other tasks.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04248" title="Abstract">arXiv:2312.04248</a> [<a href="/pdf/2312.04248" title="Download PDF">pdf</a>, <a href="/format/2312.04248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TeMO: Towards Text-Driven 3D Stylization for Multi-Object Meshes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuying Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+B">Bo-Wen Yin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Q">Qibin Hou</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Ming-Ming Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent progress in the text-driven 3D stylization of a single object has been
considerably promoted by CLIP-based methods. However, the stylization of
multi-object 3D scenes is still impeded in that the image-text pairs used for
pre-training CLIP mostly consist of an object. Meanwhile, the local details of
multiple objects may be susceptible to omission due to the existing supervision
manner primarily relying on coarse-grained contrast of image-text pairs. To
overcome these challenges, we present a novel framework, dubbed TeMO, to parse
multi-object 3D scenes and edit their styles under the contrast supervision at
multiple levels. We first propose a Decoupled Graph Attention (DGA) module to
distinguishably reinforce the features of 3D surface points. Particularly, a
cross-modal graph is constructed to align the object points accurately and noun
phrases decoupled from the 3D mesh and textual description. Then, we develop a
Cross-Grained Contrast (CGC) supervision system, where a fine-grained loss
between the words in the textual description and the randomly rendered images
are constructed to complement the coarse-grained loss. Extensive experiments
show that our method can synthesize high-quality stylized content and
outperform the existing methods over a wide range of multi-object 3D meshes.
Our code and results will be made publicly available
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04249" title="Abstract">arXiv:2312.04249</a> [<a href="/pdf/2312.04249" title="Download PDF">pdf</a>, <a href="/ps/2312.04249" title="Download PostScript">ps</a>, <a href="/format/2312.04249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extending Answer Set Programming with Rational Numbers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pacenza%2C+F">Francesco Pacenza</a>, 
<a href="/search/cs?searchtype=author&query=Zangari%2C+J">Jessica Zangari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO); Programming Languages (cs.PL); Software Engineering (cs.SE)

</div>
<p class="mathjax">Answer Set Programming (ASP) is a widely used declarative programming
paradigm that has shown great potential in solving complex computational
problems. However, the inability to natively support non-integer arithmetic has
been highlighted as a major drawback in real-world applications. This feature
is crucial to accurately model and manage real-world data and information as
emerged in various contexts, such as the smooth movement of video game
characters, the 3D movement of mechanical arms, and data streamed by sensors.
Nevertheless, extending ASP in this direction, without affecting its
declarative nature and its well-defined semantics, poses non-trivial
challenges; thus, no ASP system is able to reason natively with non-integer
domains. Indeed, the widespread floating-point arithmetic is not applicable to
the ASP case, as the reproducibility of results cannot be guaranteed and the
semantics of an ASP program would not be uniquely and declaratively determined,
regardless of the employed machine or solver. To overcome such limitations and
in the realm of pure ASP, this paper proposes an extension of ASP in which
non-integers are approximated to rational numbers, fully granting
reproducibility and declarativity. We provide a well-defined semantics for the
ASP-Core-2 standard extended with rational numbers and an implementation
thereof. We hope this work could serve as a stepping stone towards a more
expressive and versatile ASP language that can handle a broader range of
real-world problems.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04257" title="Abstract">arXiv:2312.04257</a> [<a href="/pdf/2312.04257" title="Download PDF">pdf</a>, <a href="/format/2312.04257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proxima: Near-storage Acceleration for Graph-based Approximate Nearest  Neighbor Search in 3D NAND
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weihong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+P">Po-Kai Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jaeyoung Kang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Minxuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Pinge%2C+S">Sumukh Pinge</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shimeng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Rosing%2C+T">Tajana Rosing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Approximate nearest neighbor search (ANNS) plays an indispensable role in a
wide variety of applications, including recommendation systems, information
retrieval, and semantic search. Among the cutting-edge ANNS algorithms,
graph-based approaches provide superior accuracy and scalability on massive
datasets. However, the best-performing graph-based ANN search solutions incur
tens of hundreds of memory footprints as well as costly distance computation,
thus hindering their efficient deployment at scale. The 3D NAND flash is
emerging as a promising device for data-intensive applications due to its high
density and nonvolatility. In this work, we present the near-storage processing
(NSP)-based ANNS solution Proxima, to accelerate graph-based ANNS with
algorithm-hardware co-design in 3D NAND flash. Proxima significantly reduces
the complexity of graph search by leveraging the distance approximation and
early termination. On top of the algorithmic enhancement, we implement Proxima
search algorithm in 3D NAND flash using the heterogeneous integration
technique. To maximize 3D NAND's bandwidth utilization, we present customized
dataflow and optimized data allocation scheme. Our evaluation results show
that: compared to graph ANNS on CPU and GPU, Proxima achieves a magnitude
improvement in throughput or energy efficiency. Proxima yields 7x to 13x
speedup over existing ASIC designs. Furthermore, Proxima achieves a good
balance between accuracy, efficiency and storage density compared to previous
NSP-based accelerators.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04261" title="Abstract">arXiv:2312.04261</a> [<a href="/pdf/2312.04261" title="Download PDF">pdf</a>, <a href="/ps/2312.04261" title="Download PostScript">ps</a>, <a href="/format/2312.04261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New ternary self-orthogonal codes and related LCD codes from weakly  regular plateaued functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+D">Dengcheng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shixin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">A linear code is said to be self-orthogonal if it is contained in its dual.
Self-orthogonal codes are of interest because of their important applications,
such as for constructing linear complementary dual (LCD) codes and quantum
codes. In this paper, we construct several new families of ternary
self-orthogonal codes by employing weakly regular plateaued functions. Their
parameters and weight distributions are completely determined. Then we apply
these self-orthogonal codes to construct several new families of ternary LCD
codes. As a consequence, we obtain many (almost) optimal ternary
self-orthogonal codes and LCD codes.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04262" title="Abstract">arXiv:2312.04262</a> [<a href="/pdf/2312.04262" title="Download PDF">pdf</a>, <a href="/format/2312.04262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PsyChat: A Client-Centric Dialogue System for Mental Health Support
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+H">Huachuan Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Anqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lizhi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Z">Zhenzhong Lan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Dialogue systems are increasingly integrated into mental health support to
help clients facilitate exploration, gain insight, take action, and ultimately
heal themselves. For a dialogue system to be practical and user-friendly, it
should be client-centric, focusing on the client's behaviors. However, existing
dialogue systems publicly available for mental health support often concentrate
solely on the counselor's strategies rather than the behaviors expressed by
clients. This can lead to the implementation of unreasonable or inappropriate
counseling strategies and corresponding responses from the dialogue system. To
address this issue, we propose PsyChat, a client-centric dialogue system that
provides psychological support through online chat. The client-centric dialogue
system comprises five modules: client behavior recognition, counselor strategy
selection, input packer, response generator intentionally fine-tuned to produce
responses, and response selection. Both automatic and human evaluations
demonstrate the effectiveness and practicality of our proposed dialogue system
for real-life mental health support. Furthermore, we employ our proposed
dialogue system to simulate a real-world client-virtual-counselor interaction
scenario. The system is capable of predicting the client's behaviors, selecting
appropriate counselor strategies, and generating accurate and suitable
responses, as demonstrated in the scenario.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04264" title="Abstract">arXiv:2312.04264</a> [<a href="/pdf/2312.04264" title="Download PDF">pdf</a>, <a href="/ps/2312.04264" title="Download PostScript">ps</a>, <a href="/format/2312.04264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-agricultural Machinery Collaborative Task Assignment Based on  Improved Genetic Hybrid Optimization Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Haohao Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">To address the challenges of delayed scheduling information, heavy reliance
on manual labour, and low operational efficiency in traditional large-scale
agricultural machinery operations, this study proposes a method for
multi-agricultural machinery collaborative task assignment based on an improved
genetic hybrid optimisation algorithm. The proposed method establishes a
multi-agricultural machinery task allocation model by combining the path
pre-planning of a simulated annealing algorithm and the static task allocation
of a genetic algorithm. By sequentially fusing these two algorithms, their
respective shortcomings can be overcome, and their advantages in global and
local search can be utilised. Consequently, the search capability of the
population is enhanced, leading to the discovery of more optimal solutions.
Then, an adaptive crossover operator is constructed according to the task
assignment model, considering the capacity, path cost, and time of agricultural
machinery; two-segment coding and multi-population adaptive mutation are used
to assign tasks to improve the diversity of the population and enhance the
exploration ability of the population; and to improve the global optimisation
ability of the hybrid algorithm, a 2-Opt local optimisation operator and an
Circle modification algorithm are introduced. Finally, simulation experiments
were conducted in MATLAB to evaluate the performance of the multi-agricultural
machinery collaborative task assignment based on the improved genetic hybrid
algorithm. The algorithm's capabilities were assessed through comparative
analysis in the simulation trials. The results demonstrate that the developed
hybrid algorithm can effectively reduce path costs, and the efficiency of the
assignment outcomes surpasses that of the classical genetic algorithm. This
approach proves particularly suitable for addressing large-scale task
allocation problems.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04265" title="Abstract">arXiv:2312.04265</a> [<a href="/pdf/2312.04265" title="Download PDF">pdf</a>, <a href="/format/2312.04265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stronger, Fewer, &amp; Superior: Harnessing Vision Foundation Models for  Domain Generalized Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhixiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaoxiao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianle Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+P">Pengyang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Ben Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huaian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jinjin Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we first assess and harness various Vision Foundation Models
(VFMs) in the context of Domain Generalized Semantic Segmentation (DGSS).
Driven by the motivation that Leveraging Stronger pre-trained models and Fewer
trainable parameters for Superior generalizability, we introduce a robust
fine-tuning approach, namely Rein, to parameter-efficiently harness VFMs for
DGSS. Built upon a set of trainable tokens, each linked to distinct instances,
Rein precisely refines and forwards the feature maps from each layer to the
next layer within the backbone. This process produces diverse refinements for
different categories within a single image. With fewer trainable parameters,
Rein efficiently fine-tunes VFMs for DGSS tasks, surprisingly surpassing full
parameter fine-tuning. Extensive experiments across various settings
demonstrate that Rein significantly outperforms state-of-the-art methods.
Remarkably, with just an extra 1% of trainable parameters within the frozen
backbone, Rein achieves a mIoU of 68.1% on the Cityscapes, without accessing
any real urban-scene datasets.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04266" title="Abstract">arXiv:2312.04266</a> [<a href="/pdf/2312.04266" title="Download PDF">pdf</a>, <a href="/format/2312.04266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Activity Grammars for Temporal Action Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+D">Dayoung Gong</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Joonseok Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+D">Deunsol Jung</a>, 
<a href="/search/cs?searchtype=author&query=Kwak%2C+S">Suha Kwak</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+M">Minsu Cho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Sequence prediction on temporal data requires the ability to understand
compositional structures of multi-level semantics beyond individual and
contextual properties. The task of temporal action segmentation, which aims at
translating an untrimmed activity video into a sequence of action segments,
remains challenging for this reason. This paper addresses the problem by
introducing an effective activity grammar to guide neural predictions for
temporal action segmentation. We propose a novel grammar induction algorithm
that extracts a powerful context-free grammar from action sequence data. We
also develop an efficient generalized parser that transforms frame-level
probability distributions into a reliable sequence of actions according to the
induced grammar with recursive rules. Our approach can be combined with any
neural network for temporal action segmentation to enhance the sequence
prediction and discover its compositional structure. Experimental results
demonstrate that our method significantly improves temporal action segmentation
in terms of both performance and interpretability on two standard benchmarks,
Breakfast and 50 Salads.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04273" title="Abstract">arXiv:2312.04273</a> [<a href="/pdf/2312.04273" title="Download PDF">pdf</a>, <a href="/format/2312.04273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invariant Random Forest: Tree-Based Model Solution for OOD  Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yufan Liao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xing Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Out-Of-Distribution (OOD) generalization is an essential topic in machine
learning. However, recent research is only focusing on the corresponding
methods for neural networks. This paper introduces a novel and effective
solution for OOD generalization of decision tree models, named Invariant
Decision Tree (IDT). IDT enforces a penalty term with regard to the
unstable/varying behavior of a split across different environments during the
growth of the tree. Its ensemble version, the Invariant Random Forest (IRF), is
constructed. Our proposed method is motivated by a theoretical result under
mild conditions, and validated by numerical tests with both synthetic and real
datasets. The superior performance compared to non-OOD tree models implies that
considering OOD generalization for tree models is absolutely necessary and
should be given more attention.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04275" title="Abstract">arXiv:2312.04275</a> [<a href="/pdf/2312.04275" title="Download PDF">pdf</a>, <a href="/ps/2312.04275" title="Download PostScript">ps</a>, <a href="/format/2312.04275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating Countries with Similar Maternal Mortality Rate using Cluster  Analysis and Pairing Countries with Identical MMR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nandini%2C+S">S. Nandini</a>, 
<a href="/search/cs?searchtype=author&query=R%2C+S+V">Sanjjushri Varshini R</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">In the evolving world, we require more additionally the young era to flourish
and evolve into developed land. Most of the population all around the world are
unaware of the complications involved in the routine they follow while they are
pregnant and how hospital facilities affect maternal health. Maternal Mortality
is the death of a pregnant woman due to intricacies correlated to pregnancy,
underlying circumstances exacerbated by the pregnancy or management of these
situations. It is crucial to consider the Maternal Mortality Rate (MMR) in
diverse locations and determine which human routines and hospital facilities
diminish the Maternal Mortality Rate (MMR). This research aims to examine and
discover the countries which are keeping more lavish threats of MMR and
countries alike in MMR encountered. Data is examined and collected for various
countries, data consists of the earlier years' observation. From the
perspective of Machine Learning, Unsupervised Machine Learning is implemented
to perform Cluster Analysis. Therefore the pairs of countries with similar MMR
as well as the extreme opposite pair concerning the MMR are found.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04279" title="Abstract">arXiv:2312.04279</a> [<a href="/pdf/2312.04279" title="Download PDF">pdf</a>, <a href="/format/2312.04279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MSEVA : A System for Multimodal Short Videos Emotion Visual Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Q">Qinglan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yaqi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">YouTube Shorts, a new section launched by YouTube in 2021, is a direct
competitor to short video platforms like TikTok. It reflects the rising demand
for short video content among online users. Social media platforms are often
flooded with short videos that capture different perspectives and emotions on
hot events. These videos can go viral and have a significant impact on the
public's mood and views. However, short videos' affective computing was a
neglected area of research in the past. Monitoring the public's emotions
through these videos requires a lot of time and effort, which may not be enough
to prevent undesirable outcomes. In this paper, we create the first multimodal
dataset of short video news covering hot events. We also propose an automatic
technique for audio segmenting and transcribing. In addition, we improve the
accuracy of the multimodal affective computing model by about 4.17% by
optimizing it. Moreover, a novel system MSEVA for emotion analysis of short
videos is proposed. Achieving good results on the bili-news dataset, the MSEVA
system applies the multimodal emotion analysis method in the real world. It is
helpful to conduct timely public opinion guidance and stop the spread of
negative emotions. Data and code from our investigations can be accessed at:
<a href="http://xxx.github.com.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04282" title="Abstract">arXiv:2312.04282</a> [<a href="/pdf/2312.04282" title="Download PDF">pdf</a>, <a href="/format/2312.04282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Recursive Query Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herlihy%2C+A">Anna Herlihy</a>, 
<a href="/search/cs?searchtype=author&query=Martres%2C+G">Guillaume Martres</a>, 
<a href="/search/cs?searchtype=author&query=Ailamaki%2C+A">Anastasia Ailamaki</a>, 
<a href="/search/cs?searchtype=author&query=Odersky%2C+M">Martin Odersky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Performance-critical industrial applications, including large-scale program,
network, and distributed system analyses, are increasingly reliant on recursive
queries for data analysis. Yet traditional relational algebra-based query
optimization techniques do not scale well to recursive query processing due to
the iterative nature of query evaluation, where relation cardinalities can
change unpredictably during the course of a single query execution. To avoid
error-prone cardinality estimation, adaptive query processing techniques use
runtime information to inform query optimization, but these systems are not
optimized for the specific needs of recursive query processing. In this paper,
we introduce Adaptive Metaprogramming, an innovative technique that shifts
recursive query optimization and code generation from compile-time to runtime
using principled metaprogramming, enabling dynamic optimization and
re-optimization before and after query execution has begun. We present a custom
join-ordering optimization applicable at multiple stages during query
compilation and execution. Through Carac, we evaluate the optimization
potential of Adaptive Metaprogramming and show unoptimized recursive query
execution time can be improved by three orders of magnitude and hand-optimized
queries by 4x.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04293" title="Abstract">arXiv:2312.04293</a> [<a href="/pdf/2312.04293" title="Download PDF">pdf</a>, <a href="/ps/2312.04293" title="Download PostScript">ps</a>, <a href="/format/2312.04293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT-4V with Emotion: A Zero-shot Benchmark for Multimodal Emotion  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lian%2C+Z">Zheng Lian</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Licai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haiyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Z">Zhuofan Wen</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+J">Jianhua Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Recently, GPT-4 with Vision (GPT-4V) has shown remarkable performance across
various multimodal tasks. However, its efficacy in emotion recognition remains
a question. This paper quantitatively evaluates GPT-4V's capabilities in
multimodal emotion understanding, encompassing tasks such as facial emotion
recognition, visual sentiment analysis, micro-expression recognition, dynamic
facial emotion recognition, and multimodal emotion recognition. Our experiments
show that GPT-4V exhibits impressive multimodal and temporal understanding
capabilities, even surpassing supervised systems in some tasks. Despite these
achievements, GPT-4V is currently tailored for general domains. It performs
poorly in micro-expression recognition that requires specialized expertise. The
main purpose of this paper is to present quantitative results of GPT-4V on
emotion understanding and establish a zero-shot benchmark for future research.
Code and evaluation results are available at:
https://github.com/zeroQiaoba/gpt4v-emotion.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04294" title="Abstract">arXiv:2312.04294</a> [<a href="/pdf/2312.04294" title="Download PDF">pdf</a>, <a href="/ps/2312.04294" title="Download PostScript">ps</a>, <a href="/format/2312.04294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-Efficient Internet of Things Monitoring with Content-Based  Wake-Up Radio
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+A+A">Anay Ajit Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Chiariotti%2C+F">Federico Chiariotti</a>, 
<a href="/search/cs?searchtype=author&query=Zanella%2C+A">Andrea Zanella</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The use of Wake-Up Radio (WUR) in Internet of Things (IoT) networks can
significantly improve their energy efficiency: battery-powered sensors can
remain in a low-power (sleep) mode while listening for wake-up messages using
their WUR and reactivate only when polled. However, polling-based WUR may still
lead to wasted energy if values sensed by the polled sensors provide no new
information to the receiver, or in general have a low Value of Information
(VoI). In this paper, we design a content-based WUR that tracks the process
observed by the sensors and only wakes up the sensor if its estimated update's
VoI is higher than a threshold communicated through the poll. If the sensor
does not reply to the polling request, the Gateway (GW) can make a Bayesian
update, knowing that either the sensor value substantially confirms its current
estimate or the transmission failed due to the wireless channel. We analyze the
trade-off between the tracking error and the battery lifetime of the sensors,
showing that content-based WUR can provide fine-grained control of this
trade-off and significantly increase the battery lifetime of the node with a
minimal Mean Squared Error (MSE) increase.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04296" title="Abstract">arXiv:2312.04296</a> [<a href="/pdf/2312.04296" title="Download PDF">pdf</a>, <a href="/format/2312.04296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-codex Learning for Reliable Scribe Identification in Medieval  Manuscripts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%C3%9Fmann%2C+J">Julius Wei&#xdf;mann</a>, 
<a href="/search/cs?searchtype=author&query=Seidl%2C+M">Markus Seidl</a>, 
<a href="/search/cs?searchtype=author&query=Dietrich%2C+A">Anya Dietrich</a>, 
<a href="/search/cs?searchtype=author&query=Haltrich%2C+M">Martin Haltrich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Historic scribe identification is a substantial task for obtaining
information about the past. Uniform script styles, such as the Carolingian
minuscule, make it a difficult task for classification to focus on meaningful
features. Therefore, we demonstrate in this paper the importance of cross-codex
training data for CNN based text-independent off-line scribe identification, to
overcome codex dependent overfitting. We report three main findings: First, we
found that preprocessing with masked grayscale images instead of RGB images
clearly increased the F1-score of the classification results. Second, we
trained different neural networks on our complex data, validating time and
accuracy differences in order to define the most reliable network architecture.
With AlexNet, the network with the best trade-off between F1-score and time, we
achieved for individual classes F1-scores of up to 0,96 on line level and up to
1.0 on page level in classification. Third, we could replicate the finding that
the CNN output can be further improved by implementing a reject option, giving
more stable results. We present the results on our large scale open source
dataset -- the Codex Claustroneoburgensis database (CCl-DB) -- containing a
significant number of writings from different scribes in several codices. We
demonstrate for the first time on a dataset with such a variety of codices that
paleographic decisions can be reproduced automatically and precisely with CNNs.
This gives manifold new and fast possibilities for paleographers to gain
insights into unlabeled material, but also to develop further hypotheses.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04302" title="Abstract">arXiv:2312.04302</a> [<a href="/pdf/2312.04302" title="Download PDF">pdf</a>, <a href="/format/2312.04302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Highlighter: Interactive Control for Multi-Modal LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuechen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+S">Shengju Qian</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Bohao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jiaya Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages. Project Page: <a href="https://julianjuaner.github.io/projects/PromptHighlighter">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">This study targets a critical aspect of multi-modal LLMs' (LLMs&amp;VLMs)
inference: explicit controllable text generation. Multi-modal LLMs empower
multi-modality understanding with the capability of semantic generation yet
bring less explainability and heavier reliance on prompt contents due to their
autoregressive generative nature. While manipulating prompt formats could
improve outputs, designing specific and precise prompts per task can be
challenging and ineffective. To tackle this issue, we introduce a novel
inference method, Prompt Highlighter, which enables users to highlight specific
prompt spans to interactively control the focus during generation. Motivated by
the classifier-free diffusion guidance, we form regular and unconditional
context pairs based on highlighted tokens, demonstrating that the
autoregressive generation in models can be guided in a classifier-free way.
Notably, we find that, during inference, guiding the models with highlighted
tokens through the attention weights leads to more desired outputs. Our
approach is compatible with current LLMs and VLMs, achieving impressive
customized generation results without training. Experiments confirm its
effectiveness in focusing on input contexts and generating reliable content.
Without tuning on LLaVA-v1.5, our method secured 69.5 in the MMBench test and
1552.5 in MME-perception. The code is available at:
https://github.com/dvlab-research/Prompt-Highlighter/
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04306" title="Abstract">arXiv:2312.04306</a> [<a href="/pdf/2312.04306" title="Download PDF">pdf</a>, <a href="/format/2312.04306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> nerblackbox: A High-level Library for Named Entity Recognition in Python
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stollenwerk%2C+F">Felix Stollenwerk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Proceedings of the 3rd Workshop for Natural Language Processing Open Source Software (NLP-OSS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present nerblackbox, a python library to facilitate the use of
state-of-the-art transformer-based models for named entity recognition. It
provides simple-to-use yet powerful methods to access data and models from a
wide range of sources, for fully automated model training and evaluation as
well as versatile model inference. While many technical challenges are solved
and hidden from the user by default, nerblackbox also offers fine-grained
control and a rich set of customizable features. It is thus targeted both at
application-oriented developers as well as machine learning experts and
researchers.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04307" title="Abstract">arXiv:2312.04307</a> [<a href="/pdf/2312.04307" title="Download PDF">pdf</a>, <a href="/format/2312.04307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Structural-Clustering Based Active Learning for Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fajri%2C+R+M">Ricky Maulana Fajri</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+Y">Yulong Pei</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+L">Lu Yin</a>, 
<a href="/search/cs?searchtype=author&query=Pechenizkiy%2C+M">Mykola Pechenizkiy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In active learning for graph-structured data, Graph Neural Networks (GNNs)
have shown effectiveness. However, a common challenge in these applications is
the underutilization of crucial structural information. To address this
problem, we propose the Structural-Clustering PageRank method for improved
Active learning (SPA) specifically designed for graph-structured data. SPA
integrates community detection using the SCAN algorithm with the PageRank
scoring method for efficient and informative sample selection. SPA prioritizes
nodes that are not only informative but also central in structure. Through
extensive experiments, SPA demonstrates higher accuracy and macro-F1 score over
existing methods across different annotation budgets and achieves significant
reductions in query time. In addition, the proposed method only adds two
hyperparameters, $\epsilon$ and $\mu$ in the algorithm to finely tune the
balance between structural learning and node selection. This simplicity is a
key advantage in active learning scenarios, where extensive hyperparameter
tuning is often impractical.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04308" title="Abstract">arXiv:2312.04308</a> [<a href="/pdf/2312.04308" title="Download PDF">pdf</a>, <a href="/format/2312.04308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi Actor-Critic DDPG for Robot Action Space Decomposition: A  Framework to Control Large 3D Deformation of Soft Linear Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daniel%2C+M">M&#xe9;lodie Daniel</a>, 
<a href="/search/cs?searchtype=author&query=Magassouba%2C+A">Aly Magassouba</a>, 
<a href="/search/cs?searchtype=author&query=Aranda%2C+M">Miguel Aranda</a>, 
<a href="/search/cs?searchtype=author&query=Lequi%C3%A8vre%2C+L">Laurent Lequi&#xe8;vre</a>, 
<a href="/search/cs?searchtype=author&query=Ramon%2C+J+A+C">Juan Antonio Corrales Ramon</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+R+I">Roberto Iglesias Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Mezouar%2C+Y">Youcef Mezouar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robotic manipulation of deformable linear objects (DLOs) has great potential
for applications in diverse fields such as agriculture or industry. However, a
major challenge lies in acquiring accurate deformation models that describe the
relationship between robot motion and DLO deformations. Such models are
difficult to calculate analytically and vary among DLOs. Consequently,
manipulating DLOs poses significant challenges, particularly in achieving large
deformations that require highly accurate global models. To address these
challenges, this paper presents MultiAC6: a new multi Actor-Critic framework
for robot action space decomposition to control large 3D deformations of DLOs.
In our approach, two deep reinforcement learning (DRL) agents orient and
position a robot gripper to deform a DLO into the desired shape. Unlike
previous DRL-based studies, MultiAC6 is able to solve the sim-to-real gap,
achieving large 3D deformations up to 40 cm in real-world settings.
Experimental results also show that MultiAC6 has a 66\% higher success rate
than a single-agent approach. Further experimental studies demonstrate that
MultiAC6 generalizes well, without retraining, to DLOs with different lengths
or materials.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04311" title="Abstract">arXiv:2312.04311</a> [<a href="/pdf/2312.04311" title="Download PDF">pdf</a>, <a href="/format/2312.04311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Interpretable Class-Specific Patterns through Efficient Neural  Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Walter%2C+N+P">Nils Philipp Walter</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+J">Jonas Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Vreeken%2C+J">Jilles Vreeken</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Discovering patterns in data that best describe the differences between
classes allows to hypothesize and reason about class-specific mechanisms. In
molecular biology, for example, this bears promise of advancing the
understanding of cellular processes differing between tissues or diseases,
which could lead to novel treatments. To be useful in practice, methods that
tackle the problem of finding such differential patterns have to be readily
interpretable by domain experts, and scalable to the extremely high-dimensional
data.
<br />In this work, we propose a novel, inherently interpretable binary neural
network architecture DIFFNAPS that extracts differential patterns from data.
DiffNaps is scalable to hundreds of thousands of features and robust to noise,
thus overcoming the limitations of current state-of-the-art methods in
large-scale applications such as in biology. We show on synthetic and real
world data, including three biological applications, that, unlike its
competitors, DiffNaps consistently yields accurate, succinct, and interpretable
class descriptions
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04314" title="Abstract">arXiv:2312.04314</a> [<a href="/pdf/2312.04314" title="Download PDF">pdf</a>, <a href="/format/2312.04314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT4SGG: Synthesizing Scene Graphs from Holistic and Region-specific  Narratives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zuyao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jinlin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Z">Zhen Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoxiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Changwen Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learning scene graphs from natural language descriptions has proven to be a
cheap and promising scheme for Scene Graph Generation (SGG). However, such
unstructured caption data and its processing are troubling the learning an
acurrate and complete scene graph. This dilema can be summarized as three
points. First, traditional language parsers often fail to extract meaningful
relationship triplets from caption data. Second, grounding unlocalized objects
in parsed triplets will meet ambiguity in visual-language alignment. Last,
caption data typically are sparse and exhibit bias to partial observations of
image content. These three issues make it hard for the model to generate
comprehensive and accurate scene graphs. To fill this gap, we propose a simple
yet effective framework, GPT4SGG, to synthesize scene graphs from holistic and
region-specific narratives. The framework discards traditional language parser,
and localize objects before obtaining relationship triplets. To obtain
relationship triplets, holistic and dense region-specific narratives are
generated from the image. With such textual representation of image data and a
task-specific prompt, an LLM, particularly GPT-4, directly synthesizes a scene
graph as "pseudo labels". Experimental results showcase GPT4SGG significantly
improves the performance of SGG models trained on image-caption data. We
believe this pioneering work can motivate further research into mining the
visual reasoning capabilities of LLMs.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04316" title="Abstract">arXiv:2312.04316</a> [<a href="/pdf/2312.04316" title="Download PDF">pdf</a>, <a href="/format/2312.04316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Knowledge-driven Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yeqi Bai</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+P">Pinlong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+L">Licheng Wen</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+D">Daocheng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xuemeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xinyu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Tao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jianfei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xing Gao</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+M">Min Dou</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Botian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Liang He</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper explores the emerging knowledge-driven autonomous driving
technologies. Our investigation highlights the limitations of current
autonomous driving systems, in particular their sensitivity to data bias,
difficulty in handling long-tail scenarios, and lack of interpretability.
Conversely, knowledge-driven methods with the abilities of cognition,
generalization and life-long learning emerge as a promising way to overcome
these challenges. This paper delves into the essence of knowledge-driven
autonomous driving and examines its core components: dataset \&amp; benchmark,
environment, and driver agent. By leveraging large language models, world
models, neural rendering, and other advanced artificial intelligence
techniques, these components collectively contribute to a more holistic,
adaptive, and intelligent autonomous driving system. The paper systematically
organizes and reviews previous research efforts in this area, and provides
insights and guidance for future research and practical applications of
autonomous driving. We will continually share the latest updates on
cutting-edge developments in knowledge-driven autonomous driving along with the
relevant valuable open-source resources at:
\url{https://github.com/PJLab-ADG/awesome-knowledge-driven-AD}.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04318" title="Abstract">arXiv:2312.04318</a> [<a href="/pdf/2312.04318" title="Download PDF">pdf</a>, <a href="/format/2312.04318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MIMo: A Multi-Modal Infant Model for Studying Cognitive Development
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mattern%2C+D">Dominik Mattern</a>, 
<a href="/search/cs?searchtype=author&query=Schumacher%2C+P">Pierre Schumacher</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+F+M">Francisco M. L&#xf3;pez</a>, 
<a href="/search/cs?searchtype=author&query=Raabe%2C+M+C">Marcel C. Raabe</a>, 
<a href="/search/cs?searchtype=author&query=Ernst%2C+M+R">Markus R. Ernst</a>, 
<a href="/search/cs?searchtype=author&query=Aubret%2C+A">Arthur Aubret</a>, 
<a href="/search/cs?searchtype=author&query=Triesch%2C+J">Jochen Triesch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures. Submitted to IEEE Transactions on Congnitive and Developmental Systems (TCDS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Human intelligence and human consciousness emerge gradually during the
process of cognitive development. Understanding this development is an
essential aspect of understanding the human mind and may facilitate the
construction of artificial minds with similar properties. Importantly, human
cognitive development relies on embodied interactions with the physical and
social environment, which is perceived via complementary sensory modalities.
These interactions allow the developing mind to probe the causal structure of
the world. This is in stark contrast to common machine learning approaches,
e.g., for large language models, which are merely passively ``digesting'' large
amounts of training data, but are not in control of their sensory inputs.
However, computational modeling of the kind of self-determined embodied
interactions that lead to human intelligence and consciousness is a formidable
challenge. Here we present MIMo, an open-source multi-modal infant model for
studying early cognitive development through computer simulations. MIMo's body
is modeled after an 18-month-old child with detailed five-fingered hands. MIMo
perceives its surroundings via binocular vision, a vestibular system,
proprioception, and touch perception through a full-body virtual skin, while
two different actuation models allow control of his body. We describe the
design and interfaces of MIMo and provide examples illustrating its use. All
code is available at https://github.com/trieschlab/MIMo .
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04326" title="Abstract">arXiv:2312.04326</a> [<a href="/pdf/2312.04326" title="Download PDF">pdf</a>, <a href="/format/2312.04326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> iDesigner: A High-Resolution and Complex-Prompt Following Text-to-Image  Diffusion Model for Interior Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gan%2C+R">Ruyi Gan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaojun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Junyu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuanhe Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dixiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Ziwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+R">Renliang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaxing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pingjian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yan Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the open-sourcing of text-to-image models (T2I) such as stable diffusion
(SD) and stable diffusion XL (SD-XL), there is an influx of models fine-tuned
in specific domains based on the open-source SD model, such as in anime,
character portraits, etc. However, there are few specialized models in certain
domains, such as interior design, which is attributed to the complex textual
descriptions and detailed visual elements inherent in design, alongside the
necessity for adaptable resolution. Therefore, text-to-image models for
interior design are required to have outstanding prompt-following capabilities,
as well as iterative collaboration with design professionals to achieve the
desired outcome. In this paper, we collect and optimize text-image data in the
design field and continue training in both English and Chinese on the basis of
the open-source CLIP model. We also proposed a fine-tuning strategy with
curriculum learning and reinforcement learning from CLIP feedback to enhance
the prompt-following capabilities of our approach so as to improve the quality
of image generation. The experimental results on the collected dataset
demonstrate the effectiveness of the proposed approach, which achieves
impressive results and outperforms strong baselines.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04327" title="Abstract">arXiv:2312.04327</a> [<a href="/pdf/2312.04327" title="Download PDF">pdf</a>, <a href="/format/2312.04327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to sample in Cartesian MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanchez%2C+T">Thomas Sanchez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD Thesis; 198 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Despite its exceptional soft tissue contrast, Magnetic Resonance Imaging
(MRI) faces the challenge of long scanning times compared to other modalities
like X-ray radiography. Shortening scanning times is crucial in clinical
settings, as it increases patient comfort, decreases examination costs and
improves throughput. Recent advances in compressed sensing (CS) and deep
learning allow accelerated MRI acquisition by reconstructing high-quality
images from undersampled data. While reconstruction algorithms have received
most of the focus, designing acquisition trajectories to optimize
reconstruction quality remains an open question. This thesis explores two
approaches to address this gap in the context of Cartesian MRI. First, we
propose two algorithms, lazy LBCS and stochastic LBCS, that significantly
improve upon G\"ozc\"u et al.'s greedy learning-based CS (LBCS) approach. These
algorithms scale to large, clinically relevant scenarios like multi-coil 3D MR
and dynamic MRI, previously inaccessible to LBCS. Additionally, we demonstrate
that generative adversarial networks (GANs) can serve as a natural criterion
for adaptive sampling by leveraging variance in the measurement domain to guide
acquisition. Second, we delve into the underlying structures or assumptions
that enable mask design algorithms to perform well in practice. Our experiments
reveal that state-of-the-art deep reinforcement learning (RL) approaches, while
capable of adaptation and long-horizon planning, offer only marginal
improvements over stochastic LBCS, which is neither adaptive nor does long-term
planning. Altogether, our findings suggest that stochastic LBCS and similar
methods represent promising alternatives to deep RL. They shine in particular
by their scalability and computational efficiency and could be key in the
deployment of optimized acquisition trajectories in Cartesian MRI.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04328" title="Abstract">arXiv:2312.04328</a> [<a href="/pdf/2312.04328" title="Download PDF">pdf</a>, <a href="/format/2312.04328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-scale Information Integration Framework for Infrared and Visible  Image Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jie Li</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+H">Hanxiao Lei</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinbo Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Infrared and visible image fusion aims at generating a fused image containing
the intensity and detail information of source images, and the key issue is
effectively measuring and integrating the complementary information of
multi-modality images from the same scene. Existing methods mostly adopt a
simple weight in the loss function to decide the information retention of each
modality rather than adaptively measuring complementary information for
different image pairs. In this study, we propose a multi-scale dual attention
(MDA) framework for infrared and visible image fusion, which is designed to
measure and integrate complementary information in both structure and loss
function at the image and patch level. In our method, the residual downsample
block decomposes source images into three scales first. Then, dual attention
fusion block integrates complementary information and generates a spatial and
channel attention map at each scale for feature fusion. Finally, the output
image is reconstructed by the residual reconstruction block. Loss function
consists of image-level, feature-level and patch-level three parts, of which
the calculation of the image-level and patch-level two parts are based on the
weights generated by the complementary information measurement. Indeed, to
constrain the pixel intensity distribution between the output and infrared
image, a style loss is added. Our fusion results perform robust and informative
across different scenarios. Qualitative and quantitative results on two
datasets illustrate that our method is able to preserve both thermal radiation
and detailed information from two modalities and achieve comparable results
compared with the other state-of-the-art methods. Ablation experiments show the
effectiveness of our information integration architecture and adaptively
measure complementary information retention in the loss function.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04329" title="Abstract">arXiv:2312.04329</a> [<a href="/pdf/2312.04329" title="Download PDF">pdf</a>, <a href="/format/2312.04329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reed-Muller codes have vanishing bit-error probability below capacity: a  simple tighter proof via camellia boosting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abbe%2C+E">Emmanuel Abbe</a>, 
<a href="/search/cs?searchtype=author&query=Sandon%2C+C">Colin Sandon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">This paper shows that a class of codes such as Reed-Muller (RM) codes have
vanishing bit-error probability below capacity on symmetric channels. The proof
relies on the notion of `camellia codes': a class of symmetric codes
decomposable into `camellias', i.e., set systems that differ from sunflowers by
allowing for scattered petal overlaps. The proof then follows from a boosting
argument on the camellia petals with second moment Fourier analysis. For
erasure channels, this gives a self-contained proof of the bit-error result in
Kudekar et al.'17, without relying on sharp thresholds for monotone properties
Friedgut-Kalai'96. For error channels, this gives a shortened proof of
Reeves-Pfister'23 with an exponentially tighter bound, and a proof variant of
the bit-error result in Abbe-Sandon'23. The control of the full (block) error
probability still requires Abbe-Sandon'23 for RM codes.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04330" title="Abstract">arXiv:2312.04330</a> [<a href="/pdf/2312.04330" title="Download PDF">pdf</a>, <a href="/format/2312.04330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Surrogate Modelling for Sea Ice Concentration using Lightweight Neural  Ensemble
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borisova%2C+J">Julia Borisova</a>, 
<a href="/search/cs?searchtype=author&query=Nikitin%2C+N+O">Nikolay O. Nikitin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">The modeling and forecasting of sea ice conditions in the Arctic region are
important tasks for ship routing, offshore oil production, and environmental
monitoring. We propose the adaptive surrogate modeling approach named LANE-SI
(Lightweight Automated Neural Ensembling for Sea Ice) that uses ensemble of
relatively simple deep learning models with different loss functions for
forecasting of spatial distribution for sea ice concentration in the specified
water area. Experimental studies confirm the quality of a long-term forecast
based on a deep learning model fitted to the specific water area is comparable
to resource-intensive physical modeling, and for some periods of the year, it
is superior. We achieved a 20% improvement against the state-of-the-art
physics-based forecast system SEAS5 for the Kara Sea.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04333" title="Abstract">arXiv:2312.04333</a> [<a href="/pdf/2312.04333" title="Download PDF">pdf</a>, <a href="/format/2312.04333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Surface: Probing LLaMA Across Scales and Layers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Nuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+N">Ning Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Shining Liang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+M">Ming Gong</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+L">Linjun Shou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper presents an in-depth analysis of Large Language Models (LLMs),
focusing on LLaMA, a prominent open-source foundational model in natural
language processing. Instead of assessing LLaMA through its generative output,
we design multiple-choice tasks to probe its intrinsic understanding in
high-order tasks such as reasoning and computation. We examine the model
horizontally, comparing different sizes, and vertically, assessing different
layers. We unveil several key and uncommon findings based on the designed
probing tasks: (1) Horizontally, enlarging model sizes almost could not
automatically impart additional knowledge or computational prowess. Instead, it
can enhance reasoning abilities, especially in math problem solving, and helps
reduce hallucinations, but only beyond certain size thresholds; (2) In vertical
analysis, the lower layers of LLaMA lack substantial arithmetic and factual
knowledge, showcasing logical thinking, multilingual and recognitive abilities,
with top layers housing most computational power and real-world knowledge.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04334" title="Abstract">arXiv:2312.04334</a> [<a href="/pdf/2312.04334" title="Download PDF">pdf</a>, <a href="/format/2312.04334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Perceptual Evaluation Framework for Lighting Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Giroux%2C+J">Justine Giroux</a>, 
<a href="/search/cs?searchtype=author&query=Dastjerdi%2C+M+R+K">Mohammad Reza Karimi Dastjerdi</a>, 
<a href="/search/cs?searchtype=author&query=Hold-Geoffroy%2C+Y">Yannick Hold-Geoffroy</a>, 
<a href="/search/cs?searchtype=author&query=Vazquez-Corral%2C+J">Javier Vazquez-Corral</a>, 
<a href="/search/cs?searchtype=author&query=Lalonde%2C+J">Jean-Fran&#xe7;ois Lalonde</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Progress in lighting estimation is tracked by computing existing image
quality assessment (IQA) metrics on images from standard datasets. While this
may appear to be a reasonable approach, we demonstrate that doing so does not
correlate to human preference when the estimated lighting is used to relight a
virtual scene into a real photograph. To study this, we design a controlled
psychophysical experiment where human observers must choose their preference
amongst rendered scenes lit using a set of lighting estimation algorithms
selected from the recent literature, and use it to analyse how these algorithms
perform according to human perception. Then, we demonstrate that none of the
most popular IQA metrics from the literature, taken individually, correctly
represent human perception. Finally, we show that by learning a combination of
existing IQA metrics, we can more accurately represent human preference. This
provides a new perceptual framework to help evaluate future lighting estimation
algorithms.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04337" title="Abstract">arXiv:2312.04337</a> [<a href="/pdf/2312.04337" title="Download PDF">pdf</a>, <a href="/format/2312.04337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-View Unsupervised Image Generation with Cross Attention Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cerkezi%2C+L">Llukman Cerkezi</a>, 
<a href="/search/cs?searchtype=author&query=Davtyan%2C+A">Aram Davtyan</a>, 
<a href="/search/cs?searchtype=author&query=Sameni%2C+S">Sepehr Sameni</a>, 
<a href="/search/cs?searchtype=author&query=Favaro%2C+P">Paolo Favaro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The growing interest in novel view synthesis, driven by Neural Radiance Field
(NeRF) models, is hindered by scalability issues due to their reliance on
precisely annotated multi-view images. Recent models address this by
fine-tuning large text2image diffusion models on synthetic multi-view data.
Despite robust zero-shot generalization, they may need post-processing and can
face quality issues due to the synthetic-real domain gap. This paper introduces
a novel pipeline for unsupervised training of a pose-conditioned diffusion
model on single-category datasets. With the help of pretrained self-supervised
Vision Transformers (DINOv2), we identify object poses by clustering the
dataset through comparing visibility and locations of specific object parts.
The pose-conditioned diffusion model, trained on pose labels, and equipped with
cross-frame attention at inference time ensures cross-view consistency, that is
further aided by our novel hard-attention guidance. Our model, MIRAGE,
surpasses prior work in novel view synthesis on real images. Furthermore,
MIRAGE is robust to diverse textures and geometries, as demonstrated with our
experiments on synthetic images generated with pretrained Stable Diffusion.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04339" title="Abstract">arXiv:2312.04339</a> [<a href="/pdf/2312.04339" title="Download PDF">pdf</a>, <a href="/format/2312.04339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Merging by Matching Models in Task Subspaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tam%2C+D">Derek Tam</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+M">Mohit Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Raffel%2C+C">Colin Raffel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Model merging aims to cheaply combine individual task-specific models into a
single multitask model. In this work, we view past merging methods as
leveraging different notions of a ''task subspace'' in which models are matched
before being merged. We connect the task subspace of a given model to its loss
landscape and formalize how this approach to model merging can be seen as
solving a linear system of equations. While past work has generally been
limited to linear systems that have a closed-form solution, we consider using
the conjugate gradient method to find a solution. We show that using the
conjugate gradient method can outperform closed-form solutions, enables merging
via linear systems that are otherwise intractable to solve, and flexibly allows
choosing from a wide variety of initializations and estimates for the ''task
subspace''. We ultimately demonstrate that our merging framework called
''Matching Models in their Task Subspace'' (MaTS) achieves state-of-the-art
results in multitask and intermediate-task model merging. We release all of the
code and checkpoints used in our work at https://github.com/r-three/mats.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04343" title="Abstract">arXiv:2312.04343</a> [<a href="/pdf/2312.04343" title="Download PDF">pdf</a>, <a href="/format/2312.04343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causality and Explainability for Trustworthy Integrated Pest Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsoumas%2C+I">Ilias Tsoumas</a>, 
<a href="/search/cs?searchtype=author&query=Sitokonstantinou%2C+V">Vasileios Sitokonstantinou</a>, 
<a href="/search/cs?searchtype=author&query=Giannarakis%2C+G">Georgios Giannarakis</a>, 
<a href="/search/cs?searchtype=author&query=Lampiri%2C+E">Evagelia Lampiri</a>, 
<a href="/search/cs?searchtype=author&query=Athanassiou%2C+C">Christos Athanassiou</a>, 
<a href="/search/cs?searchtype=author&query=Camps-Valls%2C+G">Gustau Camps-Valls</a>, 
<a href="/search/cs?searchtype=author&query=Kontoes%2C+C">Charalampos Kontoes</a>, 
<a href="/search/cs?searchtype=author&query=Athanasiadis%2C+I">Ioannis Athanasiadis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023 Workshop on Tackling Climate Change with Machine Learning: Blending New and Existing Knowledge Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Pesticides serve as a common tool in agricultural pest control but
significantly contribute to the climate crisis. To combat this, Integrated Pest
Management (IPM) stands as a climate-smart alternative. Despite its potential,
IPM faces low adoption rates due to farmers' skepticism about its
effectiveness. To address this challenge, we introduce an advanced data
analysis framework tailored to enhance IPM adoption. Our framework provides i)
robust pest population predictions across diverse environments with invariant
and causal learning, ii) interpretable pest presence predictions using
transparent models, iii) actionable advice through counterfactual explanations
for in-season IPM interventions, iv) field-specific treatment effect
estimations, and v) assessments of the effectiveness of our advice using causal
inference. By incorporating these features, our framework aims to alleviate
skepticism and encourage wider adoption of IPM practices among farmers.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04344" title="Abstract">arXiv:2312.04344</a> [<a href="/pdf/2312.04344" title="Download PDF">pdf</a>, <a href="/format/2312.04344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Medical Task Performance in GPT-4V: A Comprehensive Study on  Prompt Engineering Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pengcheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Ziyan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhongying Deng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yanzhou Su</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jin Ye</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junjun He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">OpenAI's latest large vision-language model (LVLM), GPT-4V(ision), has piqued
considerable interest for its potential in medical applications. Despite its
promise, recent studies and internal reviews highlight its underperformance in
specialized medical tasks. This paper explores the boundary of GPT-4V's
capabilities in medicine, particularly in processing complex imaging data from
endoscopies, CT scans, and MRIs etc. Leveraging open-source datasets, we
assessed its foundational competencies, identifying substantial areas for
enhancement. Our research emphasizes prompt engineering, an often-underutilized
strategy for improving AI responsiveness. Through iterative testing, we refined
the model's prompts, significantly improving its interpretative accuracy and
relevance in medical imaging. From our comprehensive evaluations, we distilled
10 effective prompt engineering techniques, each fortifying GPT-4V's medical
acumen. These methodical enhancements facilitate more reliable, precise, and
clinically valuable insights from GPT-4V, advancing its operability in critical
healthcare environments. Our findings are pivotal for those employing AI in
medicine, providing clear, actionable guidance on harnessing GPT-4V's full
diagnostic potential.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04346" title="Abstract">arXiv:2312.04346</a> [<a href="/pdf/2312.04346" title="Download PDF">pdf</a>, <a href="/format/2312.04346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Efficient Two-Stage Denoising Diffusion Power System  Measurement Recovery Against False Data Injection Attacks and Data Losses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pei%2C+J">Jianhua Pei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+D">Dongyuan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Ping Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Measurement uncertainties, represented by cyber-attacks and data losses,
seriously degrade the quality of power system measurements. Fortunately, the
powerful generation ability of the denoising diffusion models can enable more
precise measurement generation for power system data recovery. However, the
controllable data generation and efficient computing methods of denoising
diffusion models for deterministic trajectory still need further investigation.
To this end, this paper proposes an improved two-stage denoising diffusion
model (TSDM) to identify and reconstruct the measurements with various
measurement uncertainties. The first stage of the model comprises a
classifier-guided conditional anomaly detection component, while the second
stage involves diffusion-based measurement imputation component. Moreover, the
proposed TSDM adopts precise means and optimal variances to accelerate the
diffusion generation process with subsequence sampling. Extensive numerical
case studies demonstrate that the proposed TSDM can accurately recover power
system measurements despite strong randomness under renewable energy
integration and highly nonlinear dynamics under complex cyber-physical
contingencies. Additionally, the proposed TSDM has stronger robustness compared
to existing reconstruction networks and exhibits lower computational complexity
than general denoising diffusion models.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04348" title="Abstract">arXiv:2312.04348</a> [<a href="/pdf/2312.04348" title="Download PDF">pdf</a>, <a href="/format/2312.04348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Input Integers are Given in the Unary Numeral Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yamakami%2C+T">Tomoyuki Yamakami</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> (A4, 10pt, 12 pages, 1 figure) This is a preliminary report of the current work, which has appeared in the Proceedings of the 24th Italian Conference on Theoretical Computer Science (ICTCS 2023), Palermo, Italy, September 13--15, 2023, CEUR Workshop Proceedings (CEUR-WS.org)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Computation and Language (cs.CL); Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">Many NP-complete problems take integers as part of their input instances.
These input integers are generally binarized, that is, provided in the form of
the "binary" numeral representation, and the lengths of such binary forms are
used as a basis unit to measure the computational complexity of the problems.
In sharp contrast, the "unarization" (or the "unary" numeral representation) of
numbers has been known to bring a remarkably different effect onto the
computational complexity of the problems. When no computational-complexity
difference is observed between binarization and unarization of instances, on
the contrary, the problems are said to be strong NP-complete. This work
attempts to spotlight an issue of how the unarization of instances affects the
computational complexity of various combinatorial problems. We present numerous
NP-complete (or even NP-hard) problems, which turn out to be easily solvable
when input integers are represented in unary. We then discuss the computational
complexities of such problems when taking unary-form integer inputs. We hope
that a list of such problems signifies the structural differences between
strong NP-completeness and non-strong NP-completeness.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04350" title="Abstract">arXiv:2312.04350</a> [<a href="/pdf/2312.04350" title="Download PDF">pdf</a>, <a href="/format/2312.04350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLadder: A Benchmark to Assess Causal Reasoning Capabilities of Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhijing Jin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Leeb%2C+F">Felix Leeb</a>, 
<a href="/search/cs?searchtype=author&query=Gresele%2C+L">Luigi Gresele</a>, 
<a href="/search/cs?searchtype=author&query=Kamal%2C+O">Ojasv Kamal</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Z">Zhiheng Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Blin%2C+K">Kevin Blin</a>, 
<a href="/search/cs?searchtype=author&query=Adauto%2C+F+G">Fernando Gonzalez Adauto</a>, 
<a href="/search/cs?searchtype=author&query=Kleiman-Weiner%2C+M">Max Kleiman-Weiner</a>, 
<a href="/search/cs?searchtype=author&query=Sachan%2C+M">Mrinmaya Sachan</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The ability to perform causal reasoning is widely considered a core feature
of intelligence. In this work, we investigate whether large language models
(LLMs) can coherently reason about causality. Much of the existing work in
natural language processing (NLP) focuses on evaluating commonsense causal
reasoning in LLMs, thus failing to assess whether a model can perform causal
inference in accordance with a set of well-defined formal rules. To address
this, we propose a new NLP task, causal inference in natural language, inspired
by the "causal inference engine" postulated by Judea Pearl et al. We compose a
large dataset, CLadder, with 10K samples: based on a collection of causal
graphs and queries (associational, interventional, and counterfactual), we
obtain symbolic questions and ground-truth answers, through an oracle causal
inference engine. These are then translated into natural language. We evaluate
multiple LLMs on our dataset, and we introduce and evaluate a bespoke
chain-of-thought prompting strategy, CausalCoT. We show that our task is highly
challenging for LLMs, and we conduct an in-depth analysis to gain deeper
insight into the causal reasoning abilities of LLMs. Our data is open-sourced
at https://huggingface.co/datasets/causalNLP/cladder, and our code can be found
at https://github.com/causalNLP/cladder.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04351" title="Abstract">arXiv:2312.04351</a> [<a href="/pdf/2312.04351" title="Download PDF">pdf</a>, <a href="/format/2312.04351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nash Equilibria of Two-round Auctions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+C">Chulong Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xiang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shuangping Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+J">Jin Zhong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">In a two-round auction, a subset of bidders is selected (probabilistically),
according to their bids in the first round, for the second round, where they
can increase their bids. We formalize the two-round auction model, restricting
the second round to a dominant strategy incentive compatible (DSIC) auction for
the selected bidders. It turns out that, however, such two-round auctions are
not directly DSIC, even if the probability of each bidder being selected for
the second round is monotonic to its first bid, which is surprisingly
counter-intuitive. We also illustrate the necessary and sufficient conditions
of two-round auctions being DSIC. Besides, we characterize the Nash equilibria
for untruthful two-round auctions. One can achieve better revenue performance
by setting proper probability for selecting bidders for the second round
compared with truthful two-round auctions.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04355" title="Abstract">arXiv:2312.04355</a> [<a href="/pdf/2312.04355" title="Download PDF">pdf</a>, <a href="/format/2312.04355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Cell-Free Integrated Sensing and Communication in the Presence of  Information and Sensing Eavesdroppers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zixiang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Ling Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+D+W+K">Derrick Wing Kwan Ng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper studies a secure cell-free integrated sensing and communication
(ISAC) system, in which multiple ISAC transmitters collaboratively send
confidential information to multiple communication users (CUs) and concurrently
conduct target detection. Different from prior works investigating
communication security against potential information eavesdropping, we consider
the security of both communication and sensing in the presence of both
information and sensing eavesdroppers that aim to intercept confidential
communication information and extract target information, respectively. Towards
this end, we optimize the joint information and sensing transmit beamforming at
these ISAC transmitters for secure cell-free ISAC. Our objective is to maximize
the detection probability over a designated sensing area while ensuring the
minimum signal-to-interference-plus-noise-ratio (SINR) requirements at CUs. Our
formulation also takes into account the maximum tolerable signal-to-noise ratio
(SNR) at information eavesdroppers for ensuring the confidentiality of
information transmission, and the maximum detection probability constraints at
sensing eavesdroppers for preserving sensing privacy. The formulated secure
joint transmit beamforming problem is highly non-convex due to the intricate
interplay between the detection probabilities, beamforming vectors, and SINR
constraints. Fortunately, through strategic manipulation and via applying the
semidefinite relaxation (SDR) technique, we successfully obtain the globally
optimal solution to the design problem by rigorously verifying the tightness of
SDR. Furthermore, we present two alternative joint beamforming designs based on
the sensing SNR maximization over the specific sensing area and the coordinated
beamforming, respectively. Numerical results reveal the benefits of our
proposed design over these alternative benchmarks.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04356" title="Abstract">arXiv:2312.04356</a> [<a href="/pdf/2312.04356" title="Download PDF">pdf</a>, <a href="/format/2312.04356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuJeans: Private Neural Network Inference with Joint Optimization of  Convolution and Bootstrapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ju%2C+J+H">Jae Hyung Ju</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jaiyoung Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jongmin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Donghwan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+J+H">Jung Ho Ahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Fully homomorphic encryption (FHE) is a promising cryptographic primitive for
realizing private neural network inference (PI) services by allowing a client
to fully offload the inference task to a cloud server while keeping the client
data oblivious to the server. This work proposes NeuJeans, an FHE-based
solution for the PI of deep convolutional neural networks (CNNs). NeuJeans
tackles the critical problem of the enormous computational cost for the FHE
evaluation of convolutional layers (conv2d), mainly due to the high cost of
data reordering and bootstrapping. We first propose an encoding method
introducing nested structures inside encoded vectors for FHE, which enables us
to develop efficient conv2d algorithms with reduced data reordering costs.
However, the new encoding method also introduces additional computations for
conversion between encoding methods, which could negate its advantages. We
discover that fusing conv2d with bootstrapping eliminates such computations
while reducing the cost of bootstrapping. Then, we devise optimized execution
flows for various types of conv2d and apply them to end-to-end implementation
of CNNs. NeuJeans accelerates the performance of conv2d by up to 5.68 times
compared to state-of-the-art FHE-based PI work and performs the PI of a CNN at
the scale of ImageNet (ResNet18) within a mere few seconds
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04362" title="Abstract">arXiv:2312.04362</a> [<a href="/pdf/2312.04362" title="Download PDF">pdf</a>, <a href="/format/2312.04362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PCoQA: Persian Conversational Question Answering Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hemati%2C+H+H">Hamed Hematian Hemati</a>, 
<a href="/search/cs?searchtype=author&query=Toghyani%2C+A">Atousa Toghyani</a>, 
<a href="/search/cs?searchtype=author&query=Souri%2C+A">Atena Souri</a>, 
<a href="/search/cs?searchtype=author&query=Alavian%2C+S+H">Sayed Hesam Alavian</a>, 
<a href="/search/cs?searchtype=author&query=Sameti%2C+H">Hossein Sameti</a>, 
<a href="/search/cs?searchtype=author&query=Beigy%2C+H">Hamid Beigy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Humans seek information regarding a specific topic through performing a
conversation containing a series of questions and answers. In the pursuit of
conversational question answering research, we introduce the PCoQA, the first
\textbf{P}ersian \textbf{Co}nversational \textbf{Q}uestion \textbf{A}nswering
dataset, a resource comprising information-seeking dialogs encompassing a total
of 9,026 contextually-driven questions. Each dialog involves a questioner, a
responder, and a document from the Wikipedia; The questioner asks several
inter-connected questions from the text and the responder provides a span of
the document as the answer for each question. PCoQA is designed to present
novel challenges compared to previous question answering datasets including
having more open-ended non-factual answers, longer answers, and fewer lexical
overlaps. This paper not only presents the comprehensive PCoQA dataset but also
reports the performance of various benchmark models. Our models include
baseline models and pre-trained models, which are leveraged to boost the
performance of the model. The dataset and benchmarks are available at our
Github page.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04364" title="Abstract">arXiv:2312.04364</a> [<a href="/pdf/2312.04364" title="Download PDF">pdf</a>, <a href="/format/2312.04364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DemoCaricature: Democratising Caricature Generation with a Rough Sketch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dar-Yen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Koley%2C+S">Subhadeep Koley</a>, 
<a href="/search/cs?searchtype=author&query=Sain%2C+A">Aneeshan Sain</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+P+N">Pinaki Nath Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+T">Tao Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Bhunia%2C+A+K">Ayan Kumar Bhunia</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yi-Zhe Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we democratise caricature generation, empowering individuals
to effortlessly craft personalised caricatures with just a photo and a
conceptual sketch. Our objective is to strike a delicate balance between
abstraction and identity, while preserving the creativity and subjectivity
inherent in a sketch. To achieve this, we present Explicit Rank-1 Model Editing
alongside single-image personalisation, selectively applying nuanced edits to
cross-attention layers for a seamless merge of identity and style.
Additionally, we propose Random Mask Reconstruction to enhance robustness,
directing the model to focus on distinctive identity and style features.
Crucially, our aim is not to replace artists but to eliminate accessibility
barriers, allowing enthusiasts to engage in the artistry.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04369" title="Abstract">arXiv:2312.04369</a> [<a href="/pdf/2312.04369" title="Download PDF">pdf</a>, <a href="/format/2312.04369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SingingHead: A Large-scale 4D Dataset for Singing Head Animation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Sijing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weitian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jun Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yucheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yichao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+G">Guangtao Zhai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Singing, as a common facial movement second only to talking, can be regarded
as a universal language across ethnicities and cultures, plays an important
role in emotional communication, art, and entertainment. However, it is often
overlooked in the field of audio-driven facial animation due to the lack of
singing head datasets and the domain gap between singing and talking in rhythm
and amplitude. To this end, we collect a high-quality large-scale singing head
dataset, SingingHead, which consists of more than 27 hours of synchronized
singing video, 3D facial motion, singing audio, and background music from 76
individuals and 8 types of music. Along with the SingingHead dataset, we argue
that 3D and 2D facial animation tasks can be solved together, and propose a
unified singing facial animation framework named UniSinger to achieve both
singing audio-driven 3D singing head animation and 2D singing portrait video
synthesis. Extensive comparative experiments with both SOTA 3D facial animation
and 2D portrait animation methods demonstrate the necessity of singing-specific
datasets in singing head animation tasks and the promising performance of our
unified facial animation framework.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04372" title="Abstract">arXiv:2312.04372</a> [<a href="/pdf/2312.04372" title="Download PDF">pdf</a>, <a href="/format/2312.04372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LaMPilot: An Open Benchmark Dataset for Autonomous Driving with Language  Model Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yunsheng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+C">Can Cui</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+W">Wenqian Ye</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Peiran Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Juanwu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Abdelraouf%2C+A">Amr Abdelraouf</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+R">Rohit Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kyungtae Han</a>, 
<a href="/search/cs?searchtype=author&query=Bera%2C+A">Aniket Bera</a>, 
<a href="/search/cs?searchtype=author&query=Rehg%2C+J+M">James M. Rehg</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziran Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present LaMPilot, a novel framework for planning in the field of
autonomous driving, rethinking the task as a code-generation process that
leverages established behavioral primitives. This approach aims to address the
challenge of interpreting and executing spontaneous user instructions such as
"overtake the car ahead," which have typically posed difficulties for existing
frameworks. We introduce the LaMPilot benchmark specifically designed to
quantitatively evaluate the efficacy of Large Language Models (LLMs) in
translating human directives into actionable driving policies. We then evaluate
a wide range of state-of-the-art code generation language models on tasks from
the LaMPilot Benchmark. The results of the experiments showed that GPT-4, with
human feedback, achieved an impressive task completion rate of 92.7% and a
minimal collision rate of 0.9%. To encourage further investigation in this
area, our code and dataset will be made available.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04374" title="Abstract">arXiv:2312.04374</a> [<a href="/pdf/2312.04374" title="Download PDF">pdf</a>, <a href="/format/2312.04374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Dynamics: Vehicle Dynamics Modeling with a Physics-Informed Neural  Network for Autonomous Racing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chrosniak%2C+J">John Chrosniak</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+J">Jingyun Ning</a>, 
<a href="/search/cs?searchtype=author&query=Behl%2C+M">Madhur Behl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE RA-L for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Autonomous racing is a critical research area for autonomous driving,
presenting significant challenges in vehicle dynamics modeling, such as
balancing model precision and computational efficiency at high speeds
(&gt;280kmph), where minor errors in modeling have severe consequences. Existing
physics-based models for vehicle dynamics require elaborate testing setups and
tuning, which are hard to implement, time-intensive, and cost-prohibitive.
Conversely, purely data-driven approaches do not generalize well and cannot
adequately ensure physical constraints on predictions. This paper introduces
Deep Dynamics, a physics-informed neural network (PINN) for vehicle dynamics
modeling of an autonomous racecar. It combines physics coefficient estimation
and dynamical equations to accurately predict vehicle states at high speeds and
includes a unique Physics Guard layer to ensure internal coefficient estimates
remain within their nominal physical ranges. Open-loop and closed-loop
performance assessments, using a physics-based simulator and full-scale
autonomous Indy racecar data, highlight Deep Dynamics as a promising approach
for modeling racecar vehicle dynamics.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04377" title="Abstract">arXiv:2312.04377</a> [<a href="/pdf/2312.04377" title="Download PDF">pdf</a>, <a href="/format/2312.04377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HARQ-IR Aided Short Packet Communications: BLER Analysis and Throughput  Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+F">Fuchao He</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zheng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guanghua Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaofan Li</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xinrong Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shaodan Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper introduces hybrid automatic repeat request with incremental
redundancy (HARQ-IR) to boost the reliability of short packet communications.
The finite blocklength information theory and correlated decoding events
tremendously preclude the analysis of average block error rate (BLER).
Fortunately, the recursive form of average BLER motivates us to calculate its
value through the trapezoidal approximation and Gauss-Laguerre quadrature.
Moreover, the asymptotic analysis is performed to derive a simple expression
for the average BLER at high signal-to-noise ratio (SNR). Then, we study the
maximization of long term average throughput (LTAT) via power allocation
meanwhile ensuring the power and the BLER constraints. For tractability, the
asymptotic BLER is employed to solve the problem through geometric programming
(GP). However, the GP-based solution underestimates the LTAT at low SNR due to
a large approximation error in this case. Alternatively, we also develop a deep
reinforcement learning (DRL)-based framework to learn power allocation policy.
In particular, the optimization problem is transformed into a constrained
Markov decision process, which is solved by integrating deep deterministic
policy gradient (DDPG) with subgradient method. The numerical results finally
demonstrate that the DRL-based method outperforms the GP-based one at low SNR,
albeit at the cost of increasing computational burden.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04379" title="Abstract">arXiv:2312.04379</a> [<a href="/pdf/2312.04379" title="Download PDF">pdf</a>, <a href="/format/2312.04379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How much informative is your XAI? A decision-making assessment task to  objectively measure the goodness of explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Matarese%2C+M">Marco Matarese</a>, 
<a href="/search/cs?searchtype=author&query=Rea%2C+F">Francesco Rea</a>, 
<a href="/search/cs?searchtype=author&query=Sciutti%2C+A">Alessandra Sciutti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC); Robotics (cs.RO)

</div>
<p class="mathjax">There is an increasing consensus about the effectiveness of user-centred
approaches in the explainable artificial intelligence (XAI) field. Indeed, the
number and complexity of personalised and user-centred approaches to XAI have
rapidly grown in recent years. Often, these works have a two-fold objective:
(1) proposing novel XAI techniques able to consider the users and (2) assessing
the \textit{goodness} of such techniques with respect to others. From these new
works, it emerged that user-centred approaches to XAI positively affect the
interaction between users and systems. However, so far, the goodness of XAI
systems has been measured through indirect measures, such as performance. In
this paper, we propose an assessment task to objectively and quantitatively
measure the goodness of XAI systems in terms of their \textit{information
power}, which we intended as the amount of information the system provides to
the users during the interaction. Moreover, we plan to use our task to
objectively compare two XAI techniques in a human-robot decision-making task to
understand deeper whether user-centred approaches are more informative than
classical ones.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04386" title="Abstract">arXiv:2312.04386</a> [<a href="/pdf/2312.04386" title="Download PDF">pdf</a>, <a href="/format/2312.04386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-Based Epistemic Variance of Values for Risk-Aware Policy  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luis%2C+C+E">Carlos E. Luis</a>, 
<a href="/search/cs?searchtype=author&query=Bottero%2C+A+G">Alessandro G. Bottero</a>, 
<a href="/search/cs?searchtype=author&query=Vinogradska%2C+J">Julia Vinogradska</a>, 
<a href="/search/cs?searchtype=author&query=Berkenkamp%2C+F">Felix Berkenkamp</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Jan Peters</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2302.12526">arXiv:2302.12526</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We consider the problem of quantifying uncertainty over expected cumulative
rewards in model-based reinforcement learning. In particular, we focus on
characterizing the variance over values induced by a distribution over MDPs.
Previous work upper bounds the posterior variance over values by solving a
so-called uncertainty Bellman equation (UBE), but the over-approximation may
result in inefficient exploration. We propose a new UBE whose solution
converges to the true posterior variance over values and leads to lower regret
in tabular exploration problems. We identify challenges to apply the UBE theory
beyond tabular problems and propose a suitable approximation. Based on this
approximation, we introduce a general-purpose policy optimization algorithm,
Q-Uncertainty Soft Actor-Critic (QU-SAC), that can be applied for either
risk-seeking or risk-averse policy optimization with minimal changes.
Experiments in both online and offline RL demonstrate improved performance
compared to other uncertainty estimation methods.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04393" title="Abstract">arXiv:2312.04393</a> [<a href="/pdf/2312.04393" title="Download PDF">pdf</a>, <a href="/format/2312.04393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PhysHOI: Physics-Based Imitation of Dynamic Human-Object Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yinhuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jing Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+A">Ailing Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhengyi Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Robotics (cs.RO)

</div>
<p class="mathjax">Humans interact with objects all the time. Enabling a humanoid to learn
human-object interaction (HOI) is a key step for future smart animation and
intelligent robotics systems. However, recent progress in physics-based HOI
requires carefully designed task-specific rewards, making the system unscalable
and labor-intensive. This work focuses on dynamic HOI imitation: teaching
humanoid dynamic interaction skills through imitating kinematic HOI
demonstrations. It is quite challenging because of the complexity of the
interaction between body parts and objects and the lack of dynamic HOI data. To
handle the above issues, we present PhysHOI, the first physics-based whole-body
HOI imitation approach without task-specific reward designs. Except for the
kinematic HOI representations of humans and objects, we introduce the contact
graph to model the contact relations between body parts and objects explicitly.
A contact graph reward is also designed, which proved to be critical for
precise HOI imitation. Based on the key designs, PhysHOI can imitate diverse
HOI tasks simply yet effectively without prior knowledge. To make up for the
lack of dynamic HOI scenarios in this area, we introduce the BallPlay dataset
that contains eight whole-body basketball skills. We validate PhysHOI on
diverse HOI tasks, including whole-body grasping and basketball skills.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04395" title="Abstract">arXiv:2312.04395</a> [<a href="/pdf/2312.04395" title="Download PDF">pdf</a>, <a href="/ps/2312.04395" title="Download PostScript">ps</a>, <a href="/format/2312.04395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Czerwinski&#x27;s &quot;${\rm P} \neq {\rm NP}$ relative to a ${\rm  P}$-complete oracle&quot;
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chavrimootoo%2C+M+C">Michael C. Chavrimootoo</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T+D+A">Tran Duy Anh Le</a>, 
<a href="/search/cs?searchtype=author&query=Reidy%2C+M+P">Michael P. Reidy</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+E+J">Eliot J. Smith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">In this paper, we take a closer look at Czerwinski's "${\rm P}\neq{\rm NP}$
relative to a ${\rm P}$-complete oracle" [Cze23]. There are (uncountably)
infinitely-many relativized worlds where ${\rm P}$ and ${\rm NP}$ differ, and
it is well-known that for any ${\rm P}$-complete problem $A$, ${\rm P}^A \neq
{\rm NP}^A \iff {\rm P}\neq {\rm NP}$. The paper defines two sets ${\rm D}_{\rm
P}$ and ${\rm D}_{\rm NP}$ and builds the purported proof of their main theorem
on the claim that an oracle Turing machine with ${\rm D}_{\rm NP}$ as its
oracle and that accepts ${\rm D}_{\rm P}$ must make $\Theta(2^n)$ queries to
the oracle. We invalidate the latter by proving that there is an oracle Turing
machine with ${\rm D}_{\rm NP}$ as its oracle that accepts ${\rm D}_{\rm P}$
and yet only makes one query to the oracle. We thus conclude that Czerwinski's
paper [Cze23] fails to establish that ${\rm P} \neq {\rm NP}$.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04398" title="Abstract">arXiv:2312.04398</a> [<a href="/pdf/2312.04398" title="Download PDF">pdf</a>, <a href="/ps/2312.04398" title="Download PostScript">ps</a>, <a href="/format/2312.04398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligent Anomaly Detection for Lane Rendering Using Transformer with  Self-Supervised Pre-Training and Customized Fine-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yongqi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xingmin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruohan Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+W">Wei Song</a>, 
<a href="/search/cs?searchtype=author&query=van+Arem%2C+B">Bart van Arem</a>, 
<a href="/search/cs?searchtype=author&query=Farah%2C+H">Haneen Farah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 6 figures, accepted by the 103rd Transportation Research Board (TRB) Annual Meeting, under review by Transportation Research Record: Journal of the Transportation Research Board
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Image and Video Processing (eess.IV); Machine Learning (stat.ML)

</div>
<p class="mathjax">The burgeoning navigation services using digital maps provide great
convenience to drivers. Nevertheless, the presence of anomalies in lane
rendering map images occasionally introduces potential hazards, as such
anomalies can be misleading to human drivers and consequently contribute to
unsafe driving conditions. In response to this concern and to accurately and
effectively detect the anomalies, this paper transforms lane rendering image
anomaly detection into a classification problem and proposes a four-phase
pipeline consisting of data pre-processing, self-supervised pre-training with
the masked image modeling (MiM) method, customized fine-tuning using
cross-entropy based loss with label smoothing, and post-processing to tackle it
leveraging state-of-the-art deep learning techniques, especially those
involving Transformer models. Various experiments verify the effectiveness of
the proposed pipeline. Results indicate that the proposed pipeline exhibits
superior performance in lane rendering image anomaly detection, and notably,
the self-supervised pre-training with MiM can greatly enhance the detection
accuracy while significantly reducing the total training time. For instance,
employing the Swin Transformer with Uniform Masking as self-supervised
pretraining (Swin-Trans-UM) yielded a heightened accuracy at 94.77% and an
improved Area Under The Curve (AUC) score of 0.9743 compared with the pure Swin
Transformer without pre-training (Swin-Trans) with an accuracy of 94.01% and an
AUC of 0.9498. The fine-tuning epochs were dramatically reduced to 41 from the
original 280. In conclusion, the proposed pipeline, with its incorporation of
self-supervised pre-training using MiM and other advanced deep learning
techniques, emerges as a robust solution for enhancing the accuracy and
efficiency of lane rendering image anomaly detection in digital navigation
systems.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04402" title="Abstract">arXiv:2312.04402</a> [<a href="/pdf/2312.04402" title="Download PDF">pdf</a>, <a href="/format/2312.04402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Supervised Active Learning for Semantic Segmentation in Unknown  Environments Using Informative Path Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=R%C3%BCckin%2C+J">Julius R&#xfc;ckin</a>, 
<a href="/search/cs?searchtype=author&query=Magistri%2C+F">Federico Magistri</a>, 
<a href="/search/cs?searchtype=author&query=Stachniss%2C+C">Cyrill Stachniss</a>, 
<a href="/search/cs?searchtype=author&query=Popovi%C4%87%2C+M">Marija Popovi&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Semantic segmentation enables robots to perceive and reason about their
environments beyond geometry. Most of such systems build upon deep learning
approaches. As autonomous robots are commonly deployed in initially unknown
environments, pre-training on static datasets cannot always capture the variety
of domains and limits the robot's perception performance during missions.
Recently, self-supervised and fully supervised active learning methods emerged
to improve a robot's vision. These approaches rely on large in-domain
pre-training datasets or require substantial human labelling effort. We propose
a planning method for semi-supervised active learning of semantic segmentation
that substantially reduces human labelling requirements compared to fully
supervised approaches. We leverage an adaptive map-based planner guided towards
the frontiers of unexplored space with high model uncertainty collecting
training data for human labelling. A key aspect of our approach is to combine
the sparse high-quality human labels with pseudo labels automatically extracted
from highly certain environment map areas. Experimental results show that our
method reaches segmentation performance close to fully supervised approaches
with drastically reduced human labelling effort while outperforming
self-supervised approaches.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04403" title="Abstract">arXiv:2312.04403</a> [<a href="/pdf/2312.04403" title="Download PDF">pdf</a>, <a href="/format/2312.04403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OT-Attack: Enhancing Adversarial Transferability of Vision-Language  Models via Optimal Transport Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+D">Dongchen Han</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiaojun Jia</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yang Bai</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jindong Gu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xiaochun Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision-language pre-training (VLP) models demonstrate impressive abilities in
processing both images and text. However, they are vulnerable to multi-modal
adversarial examples (AEs). Investigating the generation of
high-transferability adversarial examples is crucial for uncovering VLP models'
vulnerabilities in practical scenarios. Recent works have indicated that
leveraging data augmentation and image-text modal interactions can enhance the
transferability of adversarial examples for VLP models significantly. However,
they do not consider the optimal alignment problem between dataaugmented
image-text pairs. This oversight leads to adversarial examples that are overly
tailored to the source model, thus limiting improvements in transferability. In
our research, we first explore the interplay between image sets produced
through data augmentation and their corresponding text sets. We find that
augmented image samples can align optimally with certain texts while exhibiting
less relevance to others. Motivated by this, we propose an Optimal
Transport-based Adversarial Attack, dubbed OT-Attack. The proposed method
formulates the features of image and text sets as two distinct distributions
and employs optimal transport theory to determine the most efficient mapping
between them. This optimal mapping informs our generation of adversarial
examples to effectively counteract the overfitting issues. Extensive
experiments across various network architectures and datasets in image-text
matching tasks reveal that our OT-Attack outperforms existing state-of-the-art
methods in terms of adversarial transferability.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04404" title="Abstract">arXiv:2312.04404</a> [<a href="/pdf/2312.04404" title="Download PDF">pdf</a>, <a href="/format/2312.04404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Impact of Multi-dimensional Local Differential Privacy on  Fairness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Makhlouf%2C+k">karima Makhlouf</a>, 
<a href="/search/cs?searchtype=author&query=Arcolezi%2C+H+H">Heber H. Arcolezi</a>, 
<a href="/search/cs?searchtype=author&query=Zhioua%2C+S">Sami Zhioua</a>, 
<a href="/search/cs?searchtype=author&query=Brahim%2C+G+B">Ghassen Ben Brahim</a>, 
<a href="/search/cs?searchtype=author&query=Palamidessi%2C+C">Catuscia Palamidessi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computers and Society (cs.CY)

</div>
<p class="mathjax">Automated decision systems are increasingly used to make consequential
decisions in people's lives. Due to the sensitivity of the manipulated data as
well as the resulting decisions, several ethical concerns need to be addressed
for the appropriate use of such technologies, in particular, fairness and
privacy. Unlike previous work, which focused on centralized differential
privacy (DP) or local DP (LDP) for a single sensitive attribute, in this paper,
we examine the impact of LDP in the presence of several sensitive attributes
(i.e., multi-dimensional data) on fairness. Detailed empirical analysis on
synthetic and benchmark datasets revealed very relevant observations. In
particular, (1) multi-dimensional LDP is an efficient approach to reduce
disparity, (2) the multi-dimensional approach of LDP (independent vs. combined)
matters only at low privacy guarantees, and (3) the outcome Y distribution has
an important effect on which group is more sensitive to the obfuscation. Last,
we summarize our findings in the form of recommendations to guide practitioners
in adopting effective privacy-preserving practices while maintaining fairness
and utility in ML applications.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04410" title="Abstract">arXiv:2312.04410</a> [<a href="/pdf/2312.04410" title="Download PDF">pdf</a>, <a href="/format/2312.04410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smooth Diffusion: Crafting Smooth Latent Spaces in Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiayi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xingqian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+Y">Yifan Pu</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+Z">Zanlin Ni</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chaofei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Vasu%2C+M">Manushree Vasu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shiji Song</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Humphrey Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> GitHub: <a href="https://github.com/SHI-Labs/Smooth-Diffusion">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, diffusion models have made remarkable progress in text-to-image
(T2I) generation, synthesizing images with high fidelity and diverse contents.
Despite this advancement, latent space smoothness within diffusion models
remains largely unexplored. Smooth latent spaces ensure that a perturbation on
an input latent corresponds to a steady change in the output image. This
property proves beneficial in downstream tasks, including image interpolation,
inversion, and editing. In this work, we expose the non-smoothness of diffusion
latent spaces by observing noticeable visual fluctuations resulting from minor
latent variations. To tackle this issue, we propose Smooth Diffusion, a new
category of diffusion models that can be simultaneously high-performing and
smooth. Specifically, we introduce Step-wise Variation Regularization to
enforce the proportion between the variations of an arbitrary input latent and
that of the output image is a constant at any diffusion training step. In
addition, we devise an interpolation standard deviation (ISTD) metric to
effectively assess the latent space smoothness of a diffusion model. Extensive
quantitative and qualitative experiments demonstrate that Smooth Diffusion
stands out as a more desirable solution not only in T2I generation but also
across various downstream tasks. Smooth Diffusion is implemented as a
plug-and-play Smooth-LoRA to work with various community models. Code is
available at https://github.com/SHI-Labs/Smooth-Diffusion.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04412" title="Abstract">arXiv:2312.04412</a> [<a href="/pdf/2312.04412" title="Download PDF">pdf</a>, <a href="/ps/2312.04412" title="Download PostScript">ps</a>, <a href="/format/2312.04412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Developing Elementary Federated Learning Algorithms Leveraging the  ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Popovic%2C+M">Miroslav Popovic</a>, 
<a href="/search/cs?searchtype=author&query=Popovic%2C+M">Marko Popovic</a>, 
<a href="/search/cs?searchtype=author&query=Kastelan%2C+I">Ivan Kastelan</a>, 
<a href="/search/cs?searchtype=author&query=Djukic%2C+M">Miodrag Djukic</a>, 
<a href="/search/cs?searchtype=author&query=Basicevic%2C+I">Ilija Basicevic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 6 tables, submitted to Telfor 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The Python Testbed for Federated Learning Algorithms is a simple Python FL
framework easy to use by ML&amp;AI developers who do not need to be professional
programmers, and this paper shows that it is also amenable to emerging AI
tools. In this paper, we successfully developed three elementary FL algorithms
using the following three steps process: (i) specify context, (ii) ask ChatGPT
to complete server and clients' callback functions, and (iii) verify the
generated code.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04416" title="Abstract">arXiv:2312.04416</a> [<a href="/pdf/2312.04416" title="Download PDF">pdf</a>, <a href="/format/2312.04416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monitoring Sustainable Global Development Along Shared Socioeconomic  Pathways
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+M+W+L">Michelle W.L. Wan</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+J+N">Jeffrey N. Clark</a>, 
<a href="/search/cs?searchtype=author&query=Small%2C+E+A">Edward A. Small</a>, 
<a href="/search/cs?searchtype=author&query=Mayoral%2C+E+F">Elena Fillola Mayoral</a>, 
<a href="/search/cs?searchtype=author&query=Santos-Rodr%C3%ADguez%2C+R">Ra&#xfa;l Santos-Rodr&#xed;guez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure. Presented at NeurIPS 2023 Workshop: Tackling Climate Change with Machine Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Sustainable global development is one of the most prevalent challenges facing
the world today, hinging on the equilibrium between socioeconomic growth and
environmental sustainability. We propose approaches to monitor and quantify
sustainable development along the Shared Socioeconomic Pathways (SSPs),
including mathematically derived scoring algorithms, and machine learning
methods. These integrate socioeconomic and environmental datasets, to produce
an interpretable metric for SSP alignment. An initial study demonstrates
promising results, laying the groundwork for the application of different
methods to the monitoring of sustainable global development.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04417" title="Abstract">arXiv:2312.04417</a> [<a href="/pdf/2312.04417" title="Download PDF">pdf</a>, <a href="/ps/2312.04417" title="Download PostScript">ps</a>, <a href="/format/2312.04417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Fairness in Multiwinner Voting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elkind%2C+E">Edith Elkind</a>, 
<a href="/search/cs?searchtype=author&query=Obratzsova%2C+S">Svetlana Obratzsova</a>, 
<a href="/search/cs?searchtype=author&query=Teh%2C+N">Nicholas Teh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the 38th AAAI Conference on Artificial Intelligence (AAAI), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Theoretical Economics (econ.TH)

</div>
<p class="mathjax">Multiwinner voting captures a wide variety of settings, from parliamentary
elections in democratic systems to product placement in online shopping
platforms. There is a large body of work dealing with axiomatic
characterizations, computational complexity, and algorithmic analysis of
multiwinner voting rules. Although many challenges remain, significant progress
has been made in showing existence of fair and representative outcomes as well
as efficient algorithmic solutions for many commonly studied settings. However,
much of this work focuses on single-shot elections, even though in numerous
real-world settings elections are held periodically and repeatedly. Hence, it
is imperative to extend the study of multiwinner voting to temporal settings.
Recently, there have been several efforts to address this challenge. However,
these works are difficult to compare, as they model multi-period voting in very
different ways. We propose a unified framework for studying temporal fairness
in this domain, drawing connections with various existing bodies of work, and
consolidating them within a general framework. We also identify gaps in
existing literature, outline multiple opportunities for future work, and put
forward a vision for the future of multiwinner voting in temporal settings.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04418" title="Abstract">arXiv:2312.04418</a> [<a href="/pdf/2312.04418" title="Download PDF">pdf</a>, <a href="/format/2312.04418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MIST: An Efficient Approach for Software-Defined Multicast in Wireless  Mesh Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Rupei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuming Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Jue%2C+J+P">Jason P. Jue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Multicasting is a vital information dissemination technique in
Software-Defined Networking (SDN). With SDN, a multicast service can
incorporate network functions implemented at different nodes, which is referred
to as software-defined multicast. Emerging ubiquitous wireless networks for 5G
and Beyond (B5G) inherently support multicast. However, the broadcast nature of
wireless channels, especially in dense deployments, leads to neighborhood
interference as a primary system degradation factor, which introduces a new
challenge for software-defined multicast in wireless mesh networks. To tackle
this, this paper introduces a novel approach, based on the idea of minimizing
both the total length cost of the multicast tree and the interference at the
same time. Accordingly, a bicriteria optimization problem is formulated, which
is called \emph{Minimum Interference Steiner Tree (MIST)}. To solve the
bicriteria problem, instead of resorting to heuristics, this paper employs an
innovative approach that is an approximate algorithm for MIST but with
guaranteed performance. Specifically, the approach is a two-stage relaxation
algorithm by exploiting the monotone submodularity property of the interference
metric and identifying Pareto optimal solutions for MIST. Simulation results
demonstrate and validate the performance of the proposed algorithm.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04423" title="Abstract">arXiv:2312.04423</a> [<a href="/pdf/2312.04423" title="Download PDF">pdf</a>, <a href="/format/2312.04423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Knowledge Graph Construction and Inference on Human Genome  Variants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prasanna%2C+S">Shivika Prasanna</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+D">Deepthi Rao</a>, 
<a href="/search/cs?searchtype=author&query=Simoes%2C+E">Eduardo Simoes</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+P">Praveen Rao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Databases (cs.DB); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Real-world knowledge can be represented as a graph consisting of entities and
relationships between the entities. The need for efficient and scalable
solutions arises when dealing with vast genomic data, like RNA-sequencing.
Knowledge graphs offer a powerful approach for various tasks in such
large-scale genomic data, such as analysis and inference. In this work,
variant-level information extracted from the RNA-sequences of vaccine-na\"ive
COVID-19 patients have been represented as a unified, large knowledge graph.
Variant call format (VCF) files containing the variant-level information were
annotated to include further information for each variant. The data records in
the annotated files were then converted to Resource Description Framework (RDF)
triples. Each VCF file obtained had an associated CADD scores file that
contained the raw and Phred-scaled scores for each variant. An ontology was
defined for the VCF and CADD scores files. Using this ontology and the
extracted information, a large, scalable knowledge graph was created. Available
graph storage was then leveraged to query and create datasets for further
downstream tasks. We also present a case study using the knowledge graph and
perform a classification task using graph machine learning. We also draw
comparisons between different Graph Neural Networks (GNNs) for the case study.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04424" title="Abstract">arXiv:2312.04424</a> [<a href="/pdf/2312.04424" title="Download PDF">pdf</a>, <a href="/format/2312.04424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cascade-Zero123: One Image to Highly Consistent 3D with Self-Prompted  Nearby Views
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yabo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Jiemin Fang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuyang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+T">Taoran Yi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaopeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lingxi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinggang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+W">Wenrui Dai</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hongkai Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qi Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://cascadezero123.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Synthesizing multi-view 3D from one single image is a significant and
challenging task. For this goal, Zero-1-to-3 methods aim to extend a 2D latent
diffusion model to the 3D scope. These approaches generate the target-view
image with a single-view source image and the camera pose as condition
information. However, the one-to-one manner adopted in Zero-1-to-3 incurs
challenges for building geometric and visual consistency across views,
especially for complex objects. We propose a cascade generation framework
constructed with two Zero-1-to-3 models, named Cascade-Zero123, to tackle this
issue, which progressively extracts 3D information from the source image.
Specifically, a self-prompting mechanism is designed to generate several nearby
views at first. These views are then fed into the second-stage model along with
the source image as generation conditions. With self-prompted multiple views as
the supplementary information, our Cascade-Zero123 generates more highly
consistent novel-view images than Zero-1-to-3. The promotion is significant for
various complex and challenging scenes, involving insects, humans, transparent
objects, and stacked multiple objects etc. The project page is at
https://cascadezero123.github.io/.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04427" title="Abstract">arXiv:2312.04427</a> [<a href="/pdf/2312.04427" title="Download PDF">pdf</a>, <a href="/format/2312.04427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spheroidal Molecular Communication via Diffusion: Signaling Between  Homogeneous Cell Aggregates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rezaei%2C+M">Mitra Rezaei</a>, 
<a href="/search/cs?searchtype=author&query=Arjmandi%2C+H">Hamidreza Arjmandi</a>, 
<a href="/search/cs?searchtype=author&query=Zoofaghari%2C+M">Mohammad Zoofaghari</a>, 
<a href="/search/cs?searchtype=author&query=Kanebratt%2C+K">Kajsa Kanebratt</a>, 
<a href="/search/cs?searchtype=author&query=Vilen%2C+L">Liisa Vilen</a>, 
<a href="/search/cs?searchtype=author&query=Janzen%2C+D">David Janzen</a>, 
<a href="/search/cs?searchtype=author&query=Gennemark%2C+P">Peter Gennemark</a>, 
<a href="/search/cs?searchtype=author&query=Noel%2C+A">Adam Noel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 10 figures; submission for journal publication. arXiv admin note: text overlap with <a href="/abs/2302.09265">arXiv:2302.09265</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cell Behavior (q-bio.CB)

</div>
<p class="mathjax">Recent molecular communication (MC) research has integrated more detailed
computational models to capture the dynamics of practical biophysical systems.
This research focuses on developing realistic models for MC transceivers
inspired by spheroids - three-dimensional cell aggregates commonly used in
organ-on-chip experimental systems. Potential applications that can be used or
modeled with spheroids include nutrient transport in an organ-on-chip system,
the release of biomarkers or reception of drug molecules by a cancerous tumor
site, or transceiver nanomachines participating in information exchange. In
this paper, a simple diffusive MC system is considered where a spheroidal
transmitter and receiver are in an unbounded fluid environment. These
spheroidal antennas are modeled as porous media for diffusive signaling
molecules, then their boundary conditions and effective diffusion coefficients
are characterized. Further, for either a point source or spheroidal
transmitter, Green's function for concentration (GFC) outside and inside the
receiving spheroid is analytically derived and formulated in terms of an
infinite series and confirmed by a particle-based simulator (PBS). The provided
GFCs enable computation of the transmitted and received signals in the
spheroidal communication system. This study shows that the porous structure of
the receiving spheroid amplifies diffusion signals but also disperses them,
thus there is a trade-off between porosity and information transmission rate.
Also, the results reveal that the porous arrangement of the transmitting
spheroid not only disperses the received signal but also attenuates it. System
performance is also evaluated in terms of bit error rate (BER). Decreasing the
porosity of the receiving spheroid is shown to enhance system performance.
Conversely, reducing the porosity of the transmitting spheroid can adversely
affect system performance.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04429" title="Abstract">arXiv:2312.04429</a> [<a href="/pdf/2312.04429" title="Download PDF">pdf</a>, <a href="/format/2312.04429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximate Caching for Efficiently Serving Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+S">Shubham Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+S">Subrata Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+S">Sarthak Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Karanam%2C+S">Srikrishna Karanam</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+K">Koyel Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Saini%2C+S">Shiv Saini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NSDI'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-to-image generation using diffusion models has seen explosive popularity
owing to their ability in producing high quality images adhering to text
prompts. However, production-grade diffusion model serving is a resource
intensive task that not only require high-end GPUs which are expensive but also
incurs considerable latency. In this paper, we introduce a technique called
approximate-caching that can reduce such iterative denoising steps for an image
generation based on a prompt by reusing intermediate noise states created
during a prior image generation for similar prompts. Based on this idea, we
present an end to end text-to-image system, Nirvana, that uses the
approximate-caching with a novel cache management-policy Least Computationally
Beneficial and Frequently Used (LCBFU) to provide % GPU compute savings, 19.8%
end-to-end latency reduction and 19% dollar savings, on average, on two real
production workloads. We further present an extensive characterization of real
production text-to-image prompts from the perspective of caching, popularity
and reuse of intermediate states in a large production environment.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04431" title="Abstract">arXiv:2312.04431</a> [<a href="/pdf/2312.04431" title="Download PDF">pdf</a>, <a href="/format/2312.04431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Content Moderation on Social Media in the EU: Insights From the DSA  Transparency Database
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Drolsbach%2C+C">Chiara Drolsbach</a>, 
<a href="/search/cs?searchtype=author&query=Pr%C3%B6llochs%2C+N">Nicolas Pr&#xf6;llochs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">The Digital Services Act (DSA) requires large social media platforms in the
EU to provide clear and specific information whenever they remove or restrict
access to certain content. These "Statements of Reasons" (SoRs) are collected
in the DSA Transparency Database to ensure transparency and scrutiny of content
moderation decisions of the providers of online platforms. In this work, we
empirically analyze 156 million SoRs within an observation period of two months
to provide an early look at content moderation decisions of social media
platforms in the EU. Our empirical analysis yields the following main findings:
(i) There are vast differences in the frequency of content moderation across
platforms. For instance, TikTok performs more than 350 times more content
moderation decisions per user than X/Twitter. (ii) Content moderation is most
commonly applied for text and videos, whereas images and other content formats
undergo moderation less frequently. (ii) The primary reasons for moderation
include content falling outside the platform's scope of service,
illegal/harmful speech, and pornography/sexualized content, with moderation of
misinformation being relatively uncommon. (iii) The majority of rule-breaking
content is detected and decided upon via automated means rather than manual
intervention. However, X/Twitter reports that it relies solely on non-automated
methods. (iv) There is significant variation in the content moderation actions
taken across platforms. Altogether, our study implies inconsistencies in how
social media platforms implement their obligations under the DSA -- resulting
in a fragmented outcome that the DSA is meant to avoid. Our findings have
important implications for regulators to clarify existing guidelines or lay out
more specific rules that ensure common standards on how social media providers
handle rule-breaking content on their platforms.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04432" title="Abstract">arXiv:2312.04432</a> [<a href="/pdf/2312.04432" title="Download PDF">pdf</a>, <a href="/format/2312.04432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FreqFed: A Frequency Analysis-Based Approach for Mitigating Poisoning  Attacks in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fereidooni%2C+H">Hossein Fereidooni</a>, 
<a href="/search/cs?searchtype=author&query=Pegoraro%2C+A">Alessandro Pegoraro</a>, 
<a href="/search/cs?searchtype=author&query=Rieger%2C+P">Phillip Rieger</a>, 
<a href="/search/cs?searchtype=author&query=Dmitrienko%2C+A">Alexandra Dmitrienko</a>, 
<a href="/search/cs?searchtype=author&query=Sadeghi%2C+A">Ahmad-Reza Sadeghi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the Network and Distributed System Security (NDSS) Symposium 2024. 16 pages, 8 figures, 12 tables, 1 algorithm, 3 equations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated learning (FL) is a collaborative learning paradigm allowing
multiple clients to jointly train a model without sharing their training data.
However, FL is susceptible to poisoning attacks, in which the adversary injects
manipulated model updates into the federated model aggregation process to
corrupt or destroy predictions (untargeted poisoning) or implant hidden
functionalities (targeted poisoning or backdoors). Existing defenses against
poisoning attacks in FL have several limitations, such as relying on specific
assumptions about attack types and strategies or data distributions or not
sufficiently robust against advanced injection techniques and strategies and
simultaneously maintaining the utility of the aggregated model. To address the
deficiencies of existing defenses, we take a generic and completely different
approach to detect poisoning (targeted and untargeted) attacks. We present
FreqFed, a novel aggregation mechanism that transforms the model updates (i.e.,
weights) into the frequency domain, where we can identify the core frequency
components that inherit sufficient information about weights. This allows us to
effectively filter out malicious updates during local training on the clients,
regardless of attack types, strategies, and clients' data distributions. We
extensively evaluate the efficiency and effectiveness of FreqFed in different
application domains, including image classification, word prediction, IoT
intrusion detection, and speech recognition. We demonstrate that FreqFed can
mitigate poisoning attacks effectively with a negligible impact on the utility
of the aggregated model.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04433" title="Abstract">arXiv:2312.04433</a> [<a href="/pdf/2312.04433" title="Download PDF">pdf</a>, <a href="/format/2312.04433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreamVideo: Composing Your Dream Videos with Customized Subject and  Motion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yujie Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qing%2C+Z">Zhiwu Qing</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Hangjie Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+H">Hongming Shan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Customized generation using diffusion models has made impressive progress in
image generation, but remains unsatisfactory in the challenging video
generation task, as it requires the controllability of both subjects and
motions. To that end, we present DreamVideo, a novel approach to generating
personalized videos from a few static images of the desired subject and a few
videos of target motion. DreamVideo decouples this task into two stages,
subject learning and motion learning, by leveraging a pre-trained video
diffusion model. The subject learning aims to accurately capture the fine
appearance of the subject from provided images, which is achieved by combining
textual inversion and fine-tuning of our carefully designed identity adapter.
In motion learning, we architect a motion adapter and fine-tune it on the given
videos to effectively model the target motion pattern. Combining these two
lightweight and efficient adapters allows for flexible customization of any
subject with any motion. Extensive experimental results demonstrate the
superior performance of our DreamVideo over the state-of-the-art methods for
customized video generation. Our project page is at
https://dreamvideo-t2v.github.io.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04435" title="Abstract">arXiv:2312.04435</a> [<a href="/pdf/2312.04435" title="Download PDF">pdf</a>, <a href="/format/2312.04435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep3DSketch: 3D modeling from Free-hand Sketches with View- and  Structural-Aware Adversarial Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianrun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Chenglong Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lanyun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+P">Papa Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zang%2C+Y">Ying Zang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lingyun Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2023. arXiv admin note: substantial text overlap with <a href="/abs/2310.18148">arXiv:2310.18148</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">This work aims to investigate the problem of 3D modeling using single
free-hand sketches, which is one of the most natural ways we humans express
ideas. Although sketch-based 3D modeling can drastically make the 3D modeling
process more accessible, the sparsity and ambiguity of sketches bring
significant challenges for creating high-fidelity 3D models that reflect the
creators' ideas. In this work, we propose a view- and structural-aware deep
learning approach, \textit{Deep3DSketch}, which tackles the ambiguity and fully
uses sparse information of sketches, emphasizing the structural information.
Specifically, we introduced random pose sampling on both 3D shapes and 2D
silhouettes, and an adversarial training scheme with an effective progressive
discriminator to facilitate learning of the shape structures. Extensive
experiments demonstrated the effectiveness of our approach, which outperforms
existing methods -- with state-of-the-art (SOTA) performance on both synthetic
and real datasets.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04440" title="Abstract">arXiv:2312.04440</a> [<a href="/pdf/2312.04440" title="Download PDF">pdf</a>, <a href="/format/2312.04440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenAsp: A Benchmark for Multi-document Open Aspect-based Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amar%2C+S">Shmuel Amar</a>, 
<a href="/search/cs?searchtype=author&query=Schiff%2C+L">Liat Schiff</a>, 
<a href="/search/cs?searchtype=author&query=Ernst%2C+O">Ori Ernst</a>, 
<a href="/search/cs?searchtype=author&query=Shefer%2C+A">Asi Shefer</a>, 
<a href="/search/cs?searchtype=author&query=Shapira%2C+O">Ori Shapira</a>, 
<a href="/search/cs?searchtype=author&query=Dagan%2C+I">Ido Dagan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The performance of automatic summarization models has improved dramatically
in recent years. Yet, there is still a gap in meeting specific information
needs of users in real-world scenarios, particularly when a targeted summary is
sought, such as in the useful aspect-based summarization setting targeted in
this paper. Previous datasets and studies for this setting have predominantly
concentrated on a limited set of pre-defined aspects, focused solely on single
document inputs, or relied on synthetic data. To advance research on more
realistic scenarios, we introduce OpenAsp, a benchmark for multi-document
\textit{open} aspect-based summarization. This benchmark is created using a
novel and cost-effective annotation protocol, by which an open aspect dataset
is derived from existing generic multi-document summarization datasets. We
analyze the properties of OpenAsp showcasing its high-quality content. Further,
we show that the realistic open-aspect setting realized in OpenAsp poses a
challenge for current state-of-the-art summarization models, as well as for
large language models.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04449" title="Abstract">arXiv:2312.04449</a> [<a href="/pdf/2312.04449" title="Download PDF">pdf</a>, <a href="/ps/2312.04449" title="Download PostScript">ps</a>, <a href="/format/2312.04449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Climb Against Time -- Self-perspective through a psychological game
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cliff%2C+S">Stefan Cliff</a>, 
<a href="/search/cs?searchtype=author&query=Jovanovi%C4%87%2C+M">Mla&#x111;an Jovanovi&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">With the rapid development of technology and its place in our lives, so too
has the idea of needing to grow up faster, do more, be more and more as we are
exposed to so many of our betters billboarding their successes and achievements
that very often we can experience burnout, depression, feeling of inadequacy
and worse. All because we cannot keep up with their tempos in life, and in this
chaos, we often lose the very important fact and truth, our life should be
lived at the tempo that fits our actual wants, our capabilities and
opportunities. In recent years, since the mid 2010s, video games have entered
the mainstream even more than before as a media platform that provides a more
interactive experience than others like it. Where the players actions have
consequences, outcomes both good and bad, and the experience of the player is
highly linked to their capabilities. Based on the type of video game, be it
single player or multiplayer, often the solution to the problem the player is
facing will vary. With the increase popularity of both buying and creating
games, more and more personal stories, talented teams and individuals, unique
takes and ideas are being tried and often for the games that do succeed, there
is financial gain but more impactful is communities built around the message
and/or its execution. These communities usually reside on social media, such as
Reddit, X, Tumblr, or on their own community pages made by the developers to
directly interact with their players. But this is true often even for games
that do not gain much financial success, they gain a certain cult following,
especially if the topics of the game are either obscure or whose workings
revolve around mental health issues, trauma survival, loss, or just in general
very human and emotional topics.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04455" title="Abstract">arXiv:2312.04455</a> [<a href="/pdf/2312.04455" title="Download PDF">pdf</a>, <a href="/format/2312.04455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fortify the Shortest Stave in Attention: Enhancing Context Awareness of  Large Language Models for Effective Tool Use
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+A">Ang Lv</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+T">Ting-En Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Changyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuchuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rui Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advancements in large language models (LLMs) have significantly
expanded their functionality and skills as tool agents. In this paper, we argue
that a waveform pattern in the model's attention allocation has an impact on
the tool use performance, which degrades when the position of essential
information hits the trough zone. To address this issue, we propose a novel
inference method named Attention Buckets. This approach enables LLMs to handle
context by conducting parallel processes, each featuring a unique RoPE angle
base that shapes the attention waveform. Attention Buckets ensures that an
attention trough of a particular process can be compensated with an attention
peak of another run, reducing the risk of the LLM missing essential information
residing within the attention trough. Our extensive experiments on the widely
recognized tool use benchmark demonstrate the efficacy of our approach, where a
7B-parameter open-source model enhanced by Attention Buckets achieves SOTA
performance on par with GPT-4.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04461" title="Abstract">arXiv:2312.04461</a> [<a href="/pdf/2312.04461" title="Download PDF">pdf</a>, <a href="/format/2312.04461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PhotoMaker: Customizing Realistic Human Photos via Stacked ID Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhen Li</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+M">Mingdeng Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xintao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zhongang Qi</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Ming-Ming Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tech report; Project page: <a href="https://photo-maker.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">Recent advances in text-to-image generation have made remarkable progress in
synthesizing realistic human photos conditioned on given text prompts. However,
existing personalized generation methods cannot simultaneously satisfy the
requirements of high efficiency, promising identity (ID) fidelity, and flexible
text controllability. In this work, we introduce PhotoMaker, an efficient
personalized text-to-image generation method, which mainly encodes an arbitrary
number of input ID images into a stack ID embedding for preserving ID
information. Such an embedding, serving as a unified ID representation, can not
only encapsulate the characteristics of the same input ID comprehensively, but
also accommodate the characteristics of different IDs for subsequent
integration. This paves the way for more intriguing and practically valuable
applications. Besides, to drive the training of our PhotoMaker, we propose an
ID-oriented data construction pipeline to assemble the training data. Under the
nourishment of the dataset constructed through the proposed pipeline, our
PhotoMaker demonstrates better ID preservation ability than test-time
fine-tuning based methods, yet provides significant speed improvements,
high-quality generation results, strong generalization capabilities, and a wide
range of applications. Our project page is available at
https://photo-maker.github.io/
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04463" title="Abstract">arXiv:2312.04463</a> [<a href="/pdf/2312.04463" title="Download PDF">pdf</a>, <a href="/format/2312.04463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Transformer-based Language Models to Automate Requirements  Satisfaction Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poudel%2C+A">Amrit Poudel</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jinfeng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cleland-Huang%2C+J">Jane Cleland-Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Requirements Satisfaction Assessment (RSA) evaluates whether the set of
design elements linked to a single requirement provide sufficient coverage of
that requirement -- typically meaning that all concepts in the requirement are
addressed by at least one of the design elements. RSA is an important software
engineering activity for systems with any form of hierarchical decomposition --
especially safety or mission critical ones. In previous studies, researchers
used basic Information Retrieval (IR) models to decompose requirements and
design elements into chunks, and then evaluated the extent to which chunks of
design elements covered all chunks in the requirement. However, results had low
accuracy because many critical concepts that extend across the entirety of the
sentence were not well represented when the sentence was parsed into
independent chunks. In this paper we leverage recent advances in natural
language processing to deliver significantly more accurate results. We propose
two major architectures: Satisfaction BERT (Sat-BERT), and Dual-Satisfaction
BERT (DSat-BERT), along with their multitask learning variants to improve
satisfaction assessments. We perform RSA on five different datasets and compare
results from our variants against the chunk-based legacy approach. All
BERT-based models significantly outperformed the legacy baseline, and Sat-BERT
delivered the best results returning an average improvement of 124.75% in Mean
Average Precision.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04464" title="Abstract">arXiv:2312.04464</a> [<a href="/pdf/2312.04464" title="Download PDF">pdf</a>, <a href="/format/2312.04464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement  Learning with General Function Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiayi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+H">Han Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L+F">Lin F. Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">To tackle long planning horizon problems in reinforcement learning with
general function approximation, we propose the first algorithm, termed as
UCRL-WVTR, that achieves both \emph{horizon-free} and
\emph{instance-dependent}, since it eliminates the polynomial dependency on the
planning horizon. The derived regret bound is deemed \emph{sharp}, as it
matches the minimax lower bound when specialized to linear mixture MDPs up to
logarithmic factors. Furthermore, UCRL-WVTR is \emph{computationally efficient}
with access to a regression oracle. The achievement of such a horizon-free,
instance-dependent, and sharp regret bound hinges upon (i) novel algorithm
designs: weighted value-targeted regression and a high-order moment estimator
in the context of general function approximation; and (ii) fine-grained
analyses: a novel concentration bound of weighted non-linear least squares and
a refined analysis which leads to the tight instance-dependent bound. We also
conduct comprehensive experiments to corroborate our theoretical findings.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04465" title="Abstract">arXiv:2312.04465</a> [<a href="/pdf/2312.04465" title="Download PDF">pdf</a>, <a href="/format/2312.04465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FitDiff: Robust monocular 3D facial shape and reflectance estimation  using Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Galanakis%2C+S">Stathis Galanakis</a>, 
<a href="/search/cs?searchtype=author&query=Lattas%2C+A">Alexandros Lattas</a>, 
<a href="/search/cs?searchtype=author&query=Moschoglou%2C+S">Stylianos Moschoglou</a>, 
<a href="/search/cs?searchtype=author&query=Zafeiriou%2C+S">Stefanos Zafeiriou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The remarkable progress in 3D face reconstruction has resulted in high-detail
and photorealistic facial representations. Recently, Diffusion Models have
revolutionized the capabilities of generative methods by achieving far better
performance than GANs. In this work, we present FitDiff, a diffusion-based 3D
facial avatar generative model. This model accurately generates relightable
facial avatars, utilizing an identity embedding extracted from an "in-the-wild"
2D facial image. Our multi-modal diffusion model concurrently outputs facial
reflectance maps (diffuse and specular albedo and normals) and shapes,
showcasing great generalization capabilities. It is solely trained on an
annotated subset of a public facial dataset, paired with 3D reconstructions. We
revisit the typical 3D facial fitting approach by guiding a reverse diffusion
process using perceptual and face recognition losses. Being the first LDM
conditioned on face recognition embeddings, FitDiff reconstructs relightable
human avatars, that can be used as-is in common rendering engines, starting
only from an unconstrained facial image, and achieving state-of-the-art
performance.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04466" title="Abstract">arXiv:2312.04466</a> [<a href="/pdf/2312.04466" title="Download PDF">pdf</a>, <a href="/format/2312.04466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emotional Speech-driven 3D Body Animation via Disentangled Latent  Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chhatre%2C+K">Kiran Chhatre</a>, 
<a href="/search/cs?searchtype=author&query=Dan%C4%9B%C4%8Dek%2C+R">Radek Dan&#x11b;&#x10d;ek</a>, 
<a href="/search/cs?searchtype=author&query=Athanasiou%2C+N">Nikos Athanasiou</a>, 
<a href="/search/cs?searchtype=author&query=Becherini%2C+G">Giorgio Becherini</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+C">Christopher Peters</a>, 
<a href="/search/cs?searchtype=author&query=Black%2C+M+J">Michael J. Black</a>, 
<a href="/search/cs?searchtype=author&query=Bolkart%2C+T">Timo Bolkart</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing methods for synthesizing 3D human gestures from speech have shown
promising results, but they do not explicitly model the impact of emotions on
the generated gestures. Instead, these methods directly output animations from
speech without control over the expressed emotion. To address this limitation,
we present AMUSE, an emotional speech-driven body animation model based on
latent diffusion. Our observation is that content (i.e., gestures related to
speech rhythm and word utterances), emotion, and personal style are separable.
To account for this, AMUSE maps the driving audio to three disentangled latent
vectors: one for content, one for emotion, and one for personal style. A latent
diffusion model, trained to generate gesture motion sequences, is then
conditioned on these latent vectors. Once trained, AMUSE synthesizes 3D human
gestures directly from speech with control over the expressed emotions and
style by combining the content from the driving speech with the emotion and
style of another speech sequence. Randomly sampling the noise of the diffusion
model further generates variations of the gesture with the same emotional
expressivity. Qualitative, quantitative, and perceptual evaluations demonstrate
that AMUSE outputs realistic gesture sequences. Compared to the state of the
art, the generated gestures are better synchronized with the speech content and
better represent the emotion expressed by the input speech. Our project website
is amuse.is.tue.mpg.de.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04469" title="Abstract">arXiv:2312.04469</a> [<a href="/pdf/2312.04469" title="Download PDF">pdf</a>, <a href="/format/2312.04469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Learnability of Watermarks for Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+C">Chenchen Gu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X+L">Xiang Lisa Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Percy Liang</a>, 
<a href="/search/cs?searchtype=author&query=Hashimoto%2C+T">Tatsunori Hashimoto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Watermarking of language model outputs enables statistical detection of
model-generated text, which has many applications in the responsible deployment
of language models. Existing watermarking strategies operate by altering the
decoder of an existing language model, and the ability for a language model to
directly learn to generate the watermark would have significant implications
for the real-world deployment of watermarks. First, learned watermarks could be
used to build open models that naturally generate watermarked text, allowing
for open models to benefit from watermarking. Second, if watermarking is used
to determine the provenance of generated text, an adversary can hurt the
reputation of a victim model by spoofing its watermark and generating damaging
watermarked text. To investigate the learnability of watermarks, we propose
watermark distillation, which trains a student model to behave like a teacher
model that uses decoding-based watermarking. We test our approach on three
distinct decoding-based watermarking strategies and various hyperparameter
settings, finding that models can learn to generate watermarked text with high
detectability. We also find limitations to learnability, including the loss of
watermarking capabilities under fine-tuning on normal text and high sample
complexity when learning low-distortion watermarks.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04470" title="Abstract">arXiv:2312.04470</a> [<a href="/pdf/2312.04470" title="Download PDF">pdf</a>, <a href="/format/2312.04470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GaitGuard: Towards Private Gait in Mixed Reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Romero%2C+D">Diana Romero</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+R+J">Ruchi Jagdish Patel</a>, 
<a href="/search/cs?searchtype=author&query=Markopolou%2C+A">Athina Markopolou</a>, 
<a href="/search/cs?searchtype=author&query=Elmalaki%2C+S">Salma Elmalaki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Augmented/Mixed Reality (AR/MR) devices are unique from other mobile systems
because of their capability to offer an immersive multi-user collaborative
experience. While previous studies have explored privacy and security aspects
of multiple user interactions in AR/MR, a less-explored area is the
vulnerability of gait privacy. Gait is considered a private state because it is
a highly individualistic and a distinctive biometric trait. Thus, preserving
gait privacy in emerging AR/MR systems is crucial to safeguard individuals from
potential identity tracking and unauthorized profiling.
<br />This paper first introduces GaitExtract, a framework designed to
automatically detect gait information in humans, shedding light on the nuances
of gait privacy in AR/MR. In this paper, we designed GaitExtract, a framework
that can automatically detect the outside gait information of a human and
investigate the vulnerability of gait privacy in AR. In a user study with $20$
participants, our findings reveal that participants were uniquely identifiable
with an accuracy of up to $78\%$ using GaitExtract. Consequently, we propose
GaitGuard, a system that safeguards gait information of people appearing in the
camera view of the AR/MR device.
<br />Furthermore, we tested GaitGuard in an MR collaborative application,
achieving $22$ fps while streaming mitigated frames to the collaborative
server. Our user-study survey indicated that users are more comfortable with
releasing videos of them walking when GaitGuard is applied to the frames. These
results underscore the efficacy and practicality of GaitGuard in mitigating
gait privacy concerns in MR contexts.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04474" title="Abstract">arXiv:2312.04474</a> [<a href="/pdf/2312.04474" title="Download PDF">pdf</a>, <a href="/format/2312.04474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chain of Code: Reasoning with a Language Model-Augmented Code Emulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengshu Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jacky Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+A">Andy Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hausman%2C+K">Karol Hausman</a>, 
<a href="/search/cs?searchtype=author&query=Sadigh%2C+D">Dorsa Sadigh</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>, 
<a href="/search/cs?searchtype=author&query=Fei-Fei%2C+L">Li Fei-Fei</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+F">Fei Xia</a>, 
<a href="/search/cs?searchtype=author&query=Ichter%2C+B">Brian Ichter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Code provides a general syntactic structure to build complex programs and
perform precise computations when paired with a code interpreter -- we
hypothesize that language models (LMs) can leverage code-writing to improve
Chain of Thought reasoning not only for logic and arithmetic tasks, but also
for linguistic ones (and in particular, those that are a mix of both). For
example, consider prompting an LM to write code that counts the number of times
it detects sarcasm in an essay: the LM may struggle to write an implementation
for "detect_sarcasm(string)" that can be executed by the interpreter (handling
the edge cases would be insurmountable). However, LMs may still produce a valid
solution if they are used not only to write the code, but also to selectively
"emulate" the interpreter by generating the expected output of
"detect_sarcasm(string)" and other lines of code (e.g., that the interpreter
could not compile). In this work, we propose Chain of Code (CoT), a simple yet
surprisingly effective extension that improves LM code-driven reasoning. The
key idea is to encourage LMs to format linguistic sub-tasks in a program as
flexible pseudocode that the compiler can explicitly catch undefined behaviors
and hand off to simulate with an LM (as an "LMulator"). Experiments demonstrate
that Chain of Code outperforms Chain of Thought and other baselines across a
variety of benchmarks; on BIG-Bench Hard, Chain of Code achieves 84%, a gain of
12% over Chain of Thought. CoT scales well with large and small models alike,
and broadens the scope of reasoning questions that LMs can correctly answer by
"thinking in code". Project webpage: https://chain-of-code.github.io/.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04479" title="Abstract">arXiv:2312.04479</a> [<a href="/pdf/2312.04479" title="Download PDF">pdf</a>, <a href="/format/2312.04479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GSGFormer: Generative Social Graph Transformer for Multimodal Pedestrian  Trajectory Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhongchang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Robin%2C+M">Marion Robin</a>, 
<a href="/search/cs?searchtype=author&query=Vasishta%2C+P">Pavan Vasishta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Pedestrian trajectory prediction, vital for selfdriving cars and
socially-aware robots, is complicated due to intricate interactions between
pedestrians, their environment, and other Vulnerable Road Users. This paper
presents GSGFormer, an innovative generative model adept at predicting
pedestrian trajectories by considering these complex interactions and offering
a plethora of potential modal behaviors. We incorporate a heterogeneous graph
neural network to capture interactions between pedestrians, semantic maps, and
potential destinations. The Transformer module extracts temporal features,
while our novel CVAE-Residual-GMM module promotes diverse behavioral modality
generation. Through evaluations on multiple public datasets, GSGFormer not only
outperforms leading methods with ample data but also remains competitive when
data is limited.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04483" title="Abstract">arXiv:2312.04483</a> [<a href="/pdf/2312.04483" title="Download PDF">pdf</a>, <a href="/format/2312.04483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Spatio-temporal Decoupling for Text-to-Video Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qing%2C+Z">Zhiwu Qing</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiayu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yujie Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Changxin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+N">Nong Sang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://higen-t2v.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite diffusion models having shown powerful abilities to generate
photorealistic images, generating videos that are realistic and diverse still
remains in its infancy. One of the key reasons is that current methods
intertwine spatial content and temporal dynamics together, leading to a notably
increased complexity of text-to-video generation (T2V). In this work, we
propose HiGen, a diffusion model-based method that improves performance by
decoupling the spatial and temporal factors of videos from two perspectives,
i.e., structure level and content level. At the structure level, we decompose
the T2V task into two steps, including spatial reasoning and temporal
reasoning, using a unified denoiser. Specifically, we generate spatially
coherent priors using text during spatial reasoning and then generate
temporally coherent motions from these priors during temporal reasoning. At the
content level, we extract two subtle cues from the content of the input video
that can express motion and appearance changes, respectively. These two cues
then guide the model's training for generating videos, enabling flexible
content variations and enhancing temporal stability. Through the decoupled
paradigm, HiGen can effectively reduce the complexity of this task and generate
realistic videos with semantics accuracy and motion stability. Extensive
experiments demonstrate the superior performance of HiGen over the
state-of-the-art T2V methods.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04484" title="Abstract">arXiv:2312.04484</a> [<a href="/pdf/2312.04484" title="Download PDF">pdf</a>, <a href="/format/2312.04484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FRNet: Frustum-Range Networks for Scalable LiDAR Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lingdong Kong</a>, 
<a href="/search/cs?searchtype=author&query=Shuai%2C+H">Hui Shuai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qingshan Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint; 20 pages, 9 figures, 9 tables; Code at <a href="https://github.com/Xiangxu-0103/FRNet">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">LiDAR segmentation is crucial for autonomous driving systems. The recent
range-view approaches are promising for real-time processing. However, they
suffer inevitably from corrupted contextual information and rely heavily on
post-processing techniques for prediction refinement. In this work, we propose
a simple yet powerful FRNet that restores the contextual information of the
range image pixels with corresponding frustum LiDAR points. Firstly, a frustum
feature encoder module is used to extract per-point features within the frustum
region, which preserves scene consistency and is crucial for point-level
predictions. Next, a frustum-point fusion module is introduced to update
per-point features hierarchically, which enables each point to extract more
surrounding information via the frustum features. Finally, a head fusion module
is used to fuse features at different levels for final semantic prediction.
Extensive experiments on four popular LiDAR segmentation benchmarks under
various task setups demonstrate our superiority. FRNet achieves competitive
performance while maintaining high efficiency. The code is publicly available.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04487" title="Abstract">arXiv:2312.04487</a> [<a href="/pdf/2312.04487" title="Download PDF">pdf</a>, <a href="/format/2312.04487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On The Maximum Linear Arrangement Problem for Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alemany-Puig%2C+L">Llu&#xed;s Alemany-Puig</a>, 
<a href="/search/cs?searchtype=author&query=Esteban%2C+J+L">Juan Luis Esteban</a>, 
<a href="/search/cs?searchtype=author&query=Ferrer-i-Cancho%2C+R">Ramon Ferrer-i-Cancho</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">Linear arrangements of graphs are a well-known type of graph labeling and are
found at the heart of many important computational problems, such as the
Minimum Linear Arrangement Problem (minLA). A linear arrangement is usually
defined as a permutation of the $n$ vertices of a graph. An intuitive geometric
setting is that of vertices lying on consecutive integer positions in the real
line, starting at 1; edges are typically drawn as semicircles above the real
line. In this paper we study the Maximum Linear Arrangement problem (MaxLA),
the maximization variant of minLA and a less studied problem than minLA. We a
devise new characterization of maximum arrangements of general graphs, and
prove that MaxLA can be solved for cycle graphs in constant time, and for
$k$-linear trees ($k\le2$) in time $O(n)$. We present a simple algorithm that
solves a constrained variant of MaxLA, which we call bipartite MaxLA, in time
$O(n)$. This algorithm has two promising characteristics. First, it solves
MaxLA for most trees consisting of a few tenths of nodes. Second, it produces a
high quality approximation to MaxLA for trees where the algorithm fails to
solve MaxLA. Furthermore, we conjecture this algorithm solves MaxLA for at
least $50\%$ of all free trees.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04494" title="Abstract">arXiv:2312.04494</a> [<a href="/pdf/2312.04494" title="Download PDF">pdf</a>, <a href="/format/2312.04494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AVA: Towards Autonomous Visualization Agents through Visual  Perception-Driven Decision-Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shusen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+H">Haichao Miao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhimin Li</a>, 
<a href="/search/cs?searchtype=author&query=Olson%2C+M">Matthew Olson</a>, 
<a href="/search/cs?searchtype=author&query=Pascucci%2C+V">Valerio Pascucci</a>, 
<a href="/search/cs?searchtype=author&query=Bremer%2C+P">Peer-Timo Bremer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)

</div>
<p class="mathjax">With recent advances in multi-modal foundation models, the previously
text-only large language models (LLM) have evolved to incorporate visual input,
opening up unprecedented opportunities for various applications in
visualization. Our work explores the utilization of the visual perception
ability of multi-modal LLMs to develop Autonomous Visualization Agents (AVAs)
that can interpret and accomplish user-defined visualization objectives through
natural language. We propose the first framework for the design of AVAs and
present several usage scenarios intended to demonstrate the general
applicability of the proposed paradigm. The addition of visual perception
allows AVAs to act as the virtual visualization assistant for domain experts
who may lack the knowledge or expertise in fine-tuning visualization outputs.
Our preliminary exploration and proof-of-concept agents suggest that this
approach can be widely applicable whenever the choices of appropriate
visualization parameters require the interpretation of previous visual output.
Feedback from unstructured interviews with experts in AI research, medical
visualization, and radiology has been incorporated, highlighting the
practicality and potential of AVAs. Our study indicates that AVAs represent a
general paradigm for designing intelligent visualization systems that can
achieve high-level visualization goals, which pave the way for developing
expert-level visualization agents in the future.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04501" title="Abstract">arXiv:2312.04501</a> [<a href="/pdf/2312.04501" title="Download PDF">pdf</a>, <a href="/format/2312.04501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Metanetworks for Processing Diverse Neural Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lim%2C+D">Derek Lim</a>, 
<a href="/search/cs?searchtype=author&query=Maron%2C+H">Haggai Maron</a>, 
<a href="/search/cs?searchtype=author&query=Law%2C+M+T">Marc T. Law</a>, 
<a href="/search/cs?searchtype=author&query=Lorraine%2C+J">Jonathan Lorraine</a>, 
<a href="/search/cs?searchtype=author&query=Lucas%2C+J">James Lucas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Neural networks efficiently encode learned information within their
parameters. Consequently, many tasks can be unified by treating neural networks
themselves as input data. When doing so, recent studies demonstrated the
importance of accounting for the symmetries and geometry of parameter spaces.
However, those works developed architectures tailored to specific networks such
as MLPs and CNNs without normalization layers, and generalizing such
architectures to other types of networks can be challenging. In this work, we
overcome these challenges by building new metanetworks - neural networks that
take weights from other neural networks as input. Put simply, we carefully
build graphs representing the input neural networks and process the graphs
using graph neural networks. Our approach, Graph Metanetworks (GMNs),
generalizes to neural architectures where competing methods struggle, such as
multi-head attention layers, normalization layers, convolutional layers, ResNet
blocks, and group-equivariant linear layers. We prove that GMNs are expressive
and equivariant to parameter permutation symmetries that leave the input neural
network functions unchanged. We validate the effectiveness of our method on
several metanetwork tasks over diverse neural network architectures.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04503" title="Abstract">arXiv:2312.04503</a> [<a href="/pdf/2312.04503" title="Download PDF">pdf</a>, <a href="/format/2312.04503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Robust Reinforcement Learning Control of Uncertain Nonlinear  Systems: Towards a Fully-Automated, Insulin-Based Artificial Pancreas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tanzanakis%2C+A">Alexandros Tanzanakis</a>, 
<a href="/search/eess?searchtype=author&query=Lygeros%2C+J">John Lygeros</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, a novel robust tracking control scheme for a general class of
discrete-time nonlinear systems affected by unknown bounded uncertainty is
presented. By solving a parameterized optimal tracking control problem subject
to the unknown nominal system and a suitable cost function, the resulting
optimal tracking control policy can ensure closed-loop stability by achieving a
sufficiently small tracking error for the original uncertain nonlinear system.
The computation of the optimal tracking controller is accomplished through the
derivation of a novel Q-function-based $\lambda$-Policy Iteration algorithm.
The proposed algorithm not only enjoys rigorous theoretical guarantees, but
also avoids technical weaknesses of conventional reinforcement learning
methods. By employing a data-driven, critic-only least squares implementation,
the performance of the proposed algorithm is evaluated to the problem of
fully-automated, insulin-based, closed-loop glucose control for patients
diagnosed with Type 1 and Type 2 Diabetes Mellitus. The U.S. FDA-accepted
DMMS.R simulator from the Epsilon Group is used to conduct a comprehensive in
silico clinical campaign on a rich set of virtual subjects under completely
unannounced meal and exercise settings. Simulation results underline the
superior glycaemic behavior achieved by the derived approach, as well as its
overall maturity for the design of highly-effective, closed-loop drug delivery
systems for personalized medicine.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04504" title="Abstract">arXiv:2312.04504</a> [<a href="/pdf/2312.04504" title="Download PDF">pdf</a>, <a href="/format/2312.04504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coordination-free Decentralised Federated Learning on Complex Networks:  Overcoming Heterogeneity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valerio%2C+L">Lorenzo Valerio</a>, 
<a href="/search/cs?searchtype=author&query=Boldrini%2C+C">Chiara Boldrini</a>, 
<a href="/search/cs?searchtype=author&query=Passarella%2C+A">Andrea Passarella</a>, 
<a href="/search/cs?searchtype=author&query=Kert%C3%A9sz%2C+J">J&#xe1;nos Kert&#xe9;sz</a>, 
<a href="/search/cs?searchtype=author&query=Karsai%2C+M">M&#xe1;rton Karsai</a>, 
<a href="/search/cs?searchtype=author&query=I%C3%B1iguez%2C+G">Gerardo I&#xf1;iguez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Supported by the H2020 HumaneAI Net (#952026), H2020 INFRAIA-01-2018-2019 SoBigData++ (#871042), and by the CHIST-ERA-19-XAI010 SAI projects, FWF (grant No. I 5205). Also funded by PNRR MUR Partenariato Esteso PE00000013 FAIR, PNRR MUR Partenariato Esteso PE00000001 - "RESTART"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Multiagent Systems (cs.MA); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Federated Learning (FL) is a well-known framework for successfully performing
a learning task in an edge computing scenario where the devices involved have
limited resources and incomplete data representation. The basic assumption of
FL is that the devices communicate directly or indirectly with a parameter
server that centrally coordinates the whole process, overcoming several
challenges associated with it. However, in highly pervasive edge scenarios, the
presence of a central controller that oversees the process cannot always be
guaranteed, and the interactions (i.e., the connectivity graph) between devices
might not be predetermined, resulting in a complex network structure. Moreover,
the heterogeneity of data and devices further complicates the learning process.
This poses new challenges from a learning standpoint that we address by
proposing a communication-efficient Decentralised Federated Learning (DFL)
algorithm able to cope with them. Our solution allows devices communicating
only with their direct neighbours to train an accurate model, overcoming the
heterogeneity induced by data and different training histories. Our results
show that the resulting local models generalise better than those trained with
competing approaches, and do so in a more communication-efficient way.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04509" title="Abstract">arXiv:2312.04509</a> [<a href="/pdf/2312.04509" title="Download PDF">pdf</a>, <a href="/format/2312.04509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-context learning of state estimators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Busetto%2C+R">Riccardo Busetto</a>, 
<a href="/search/eess?searchtype=author&query=Breschi%2C+V">Valentina Breschi</a>, 
<a href="/search/eess?searchtype=author&query=Forgione%2C+M">Marco Forgione</a>, 
<a href="/search/eess?searchtype=author&query=Piga%2C+D">Dario Piga</a>, 
<a href="/search/eess?searchtype=author&query=Formentin%2C+S">Simone Formentin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">State estimation has a pivotal role in several applications, including but
not limited to advanced control design. Especially when dealing with nonlinear
systems state estimation is a nontrivial task, often entailing approximations
and challenging fine-tuning phases. In this work, we propose to overcome these
challenges by formulating an in-context state-estimation problem, enabling us
to learn a state estimator for a class of (nonlinear) systems abstracting from
particular instances of the state seen during training. To this end, we extend
an in-context learning framework recently proposed for system identification,
showing via a benchmark numerical example that this approach allows us to (i)
use training data directly for the design of the state estimator, (ii) not
requiring extensive fine-tuning procedures, while (iii) achieving superior
performance compared to state-of-the-art benchmarks.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04510" title="Abstract">arXiv:2312.04510</a> [<a href="/pdf/2312.04510" title="Download PDF">pdf</a>, <a href="/format/2312.04510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Block Metropolis-Hastings Sampler for Controllable Energy-based Text  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Forristal%2C+J">Jarad Forristal</a>, 
<a href="/search/cs?searchtype=author&query=Mireshghallah%2C+N">Niloofar Mireshghallah</a>, 
<a href="/search/cs?searchtype=author&query=Durrett%2C+G">Greg Durrett</a>, 
<a href="/search/cs?searchtype=author&query=Berg-Kirkpatrick%2C+T">Taylor Berg-Kirkpatrick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent work has shown that energy-based language modeling is an effective
framework for controllable text generation because it enables flexible
integration of arbitrary discriminators. However, because energy-based LMs are
globally normalized, approximate techniques like Metropolis-Hastings (MH) are
required for inference. Past work has largely explored simple proposal
distributions that modify a single token at a time, like in Gibbs sampling. In
this paper, we develop a novel MH sampler that, in contrast, proposes re-writes
of the entire sequence in each step via iterative prompting of a large language
model. Our new sampler (a) allows for more efficient and accurate sampling from
a target distribution and (b) allows generation length to be determined through
the sampling procedure rather than fixed in advance, as past work has required.
We perform experiments on two controlled generation tasks, showing both
downstream performance gains and more accurate target distribution sampling in
comparison with single-token proposal techniques.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04511" title="Abstract">arXiv:2312.04511</a> [<a href="/pdf/2312.04511" title="Download PDF">pdf</a>, <a href="/format/2312.04511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An LLM Compiler for Parallel Function Calling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sehoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+S">Suhong Moon</a>, 
<a href="/search/cs?searchtype=author&query=Tabrizi%2C+R">Ryan Tabrizi</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+N">Nicholas Lee</a>, 
<a href="/search/cs?searchtype=author&query=Mahoney%2C+M+W">Michael W. Mahoney</a>, 
<a href="/search/cs?searchtype=author&query=Keutzer%2C+K">Kurt Keutzer</a>, 
<a href="/search/cs?searchtype=author&query=Gholami%2C+A">Amir Gholami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have shown remarkable results on various complex
reasoning benchmarks. The reasoning capabilities of LLMs enable them to execute
function calls, using user-provided functions to overcome their inherent
limitations, such as knowledge cutoffs, poor arithmetic skills, or lack of
access to private data. This development has expanded LLMs' scope to include
multi-function calling, where LLMs are equipped with a variety of functions and
select the proper functions based on the context. Multi-function calling
abilities of LLMs have catalyzed LLM-based software development, allowing them
to tackle more complex problems. However, current methods for multi-function
calling often require sequential reasoning and acting for each function which
can result in high latency, cost, and sometimes inaccurate behavior. To address
this, we introduce LLMCompiler, which executes functions in parallel to
efficiently orchestrate multi-function calling. Drawing from the principles of
classical compilers, LLMCompiler streamlines parallel function calling with
three components: (i) an LLM Planner, formulating execution strategies and
dependencies; (ii) a Task Fetching Unit, dispatching function calling tasks;
and (iii) an Executor, executing these tasks in parallel. LLMCompiler
automatically computes an optimized orchestration for the function calls and
can be used with open-source models such as LLaMA-2. We have benchmarked
LLMCompiler on a range of tasks including cases with non-trivial
inter-dependency between function calls, as well as cases that require dynamic
replanning based on intermediate results. We observe consistent latency speedup
of up to 3.7x, cost savings of up to 6.7x, and accuracy improvement of up to
~9% as compared to ReAct. Additionally, LLMCompiler achieves up to 1.35x
latency gain over OpenAI's recent parallel function calling, while achieving
similar accuracy.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04512" title="Abstract">arXiv:2312.04512</a> [<a href="/pdf/2312.04512" title="Download PDF">pdf</a>, <a href="/format/2312.04512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MuFuzz: Sequence-Aware Mutation and Seed Mask Guidance for Blockchain  Smart Contract Fuzzing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+P">Peng Qian</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hanjie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zeren Du</a>, 
<a href="/search/cs?searchtype=author&query=Vural%2C+T">Turan Vural</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+D">Dazhong Rong</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zheng Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanbin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianhai Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qinming He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by ICDE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">As blockchain smart contracts become more widespread and carry more valuable
digital assets, they become an increasingly attractive target for attackers.
Over the past few years, smart contracts have been subject to a plethora of
devastating attacks, resulting in billions of dollars in financial losses.
There has been a notable surge of research interest in identifying defects in
smart contracts. However, existing smart contract fuzzing tools are still
unsatisfactory. They struggle to screen out meaningful transaction sequences
and specify critical inputs for each transaction. As a result, they can only
trigger a limited range of contract states, making it difficult to unveil
complicated vulnerabilities hidden in the deep state space.
<br />In this paper, we shed light on smart contract fuzzing by employing a
sequence-aware mutation and seed mask guidance strategy. In particular, we
first utilize data-flow-based feedback to determine transaction orders in a
meaningful way and further introduce a sequence-aware mutation technique to
explore deeper states. Thereafter, we design a mask-guided seed mutation
strategy that biases the generated transaction inputs to hit target branches.
In addition, we develop a dynamic-adaptive energy adjustment paradigm that
balances the fuzzing resource allocation during a fuzzing campaign. We
implement our designs into a new smart contract fuzzer named MuFuzz, and
extensively evaluate it on three benchmarks. Empirical results demonstrate that
MuFuzz outperforms existing tools in terms of both branch coverage and bug
finding. Overall, MuFuzz achieves higher branch coverage than state-of-the-art
fuzzers (up to 25%) and detects 30% more bugs than existing bug detectors.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04514" title="Abstract">arXiv:2312.04514</a> [<a href="/pdf/2312.04514" title="Download PDF">pdf</a>, <a href="/format/2312.04514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Channel Charting for Streaming CSI Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taner%2C+S">Sueda Taner</a>, 
<a href="/search/cs?searchtype=author&query=Guillaud%2C+M">Maxime Guillaud</a>, 
<a href="/search/cs?searchtype=author&query=Tirkkonen%2C+O">Olav Tirkkonen</a>, 
<a href="/search/cs?searchtype=author&query=Studer%2C+C">Christoph Studer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the 2023 Asilomar Conference on Signals, Systems, and Computers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Channel charting (CC) applies dimensionality reduction to channel state
information (CSI) data at the infrastructure basestation side with the goal of
extracting pseudo-position information for each user. The self-supervised
nature of CC enables predictive tasks that depend on user position without
requiring any ground-truth position information. In this work, we focus on the
practically relevant streaming CSI data scenario, in which CSI is constantly
estimated. To deal with storage limitations, we develop a novel streaming CC
architecture that maintains a small core CSI dataset from which the channel
charts are learned. Curation of the core CSI dataset is achieved using a
min-max-similarity criterion. Numerical validation with measured CSI data
demonstrates that our method approaches the accuracy obtained from the complete
CSI dataset while using only a fraction of CSI storage and avoiding
catastrophic forgetting of old CSI data.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04515" title="Abstract">arXiv:2312.04515</a> [<a href="/pdf/2312.04515" title="Download PDF">pdf</a>, <a href="/format/2312.04515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Monotonic Multihead Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xutai Ma</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+A">Anna Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+S">Siqi Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Inaguma%2C+H">Hirofumi Inaguma</a>, 
<a href="/search/cs?searchtype=author&query=Tomasello%2C+P">Paden Tomasello</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We introduce the Efficient Monotonic Multihead Attention (EMMA), a
state-of-the-art simultaneous translation model with numerically-stable and
unbiased monotonic alignment estimation. In addition, we present improved
training and inference strategies, including simultaneous fine-tuning from an
offline translation model and reduction of monotonic alignment variance. The
experimental results demonstrate that the proposed model attains
state-of-the-art performance in simultaneous speech-to-text translation on the
Spanish and English translation task.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04516" title="Abstract">arXiv:2312.04516</a> [<a href="/pdf/2312.04516" title="Download PDF">pdf</a>, <a href="/format/2312.04516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing Perfect Bayesian Equilibria in Sequential Auctions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thoma%2C+V">Vinzenz Thoma</a>, 
<a href="/search/cs?searchtype=author&query=Bosshard%2C+V">Vitor Bosshard</a>, 
<a href="/search/cs?searchtype=author&query=Seuken%2C+S">Sven Seuken</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We present a best-response based algorithm for computing verifiable
$\varepsilon$-perfect Bayesian equilibria for sequential auctions with
combinatorial bidding spaces and incomplete information. Previous work has
focused only on computing Bayes-Nash equilibria for static single-round
auctions, which our work captures as a special case. Additionally, we prove an
upper bound $\varepsilon$ on the utility loss of our approximate equilibria and
present an algorithm to efficiently compute $\varepsilon$ based on the
immediate loss at each subgame. We evaluate the performance of our algorithm by
reproducing known results from several auctions previously introduced in the
literature, including a model of combinatorial split-award auctions used in
procurement.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04519" title="Abstract">arXiv:2312.04519</a> [<a href="/pdf/2312.04519" title="Download PDF">pdf</a>, <a href="/format/2312.04519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bootstrapping Autonomous Radars with Self-Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yiduo Hao</a>, 
<a href="/search/cs?searchtype=author&query=Madani%2C+S">Sohrab Madani</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+J">Junfeng Guan</a>, 
<a href="/search/cs?searchtype=author&query=Alloulah%2C+M">Mohammed Alloulah</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Saurabh Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Hassanieh%2C+H">Haitham Hassanieh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The perception of autonomous vehicles using radars has attracted increased
research interest due its ability to operate in fog and bad weather. However,
training radar models is hindered by the cost and difficulty of annotating
large-scale radar data. To overcome this bottleneck, we propose a
self-supervised learning framework to leverage the large amount of unlabeled
radar data to pre-train radar-only embeddings for self-driving perception
tasks. The proposed method combines radar-to-radar and radar-to-vision
contrastive losses to learn a general representation from unlabeled radar
heatmaps paired with their corresponding camera images. When used for
downstream object detection, we demonstrate that the proposed self-supervision
framework can improve the accuracy of state-of-the-art supervised baselines by
5.8% in mAP.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04521" title="Abstract">arXiv:2312.04521</a> [<a href="/pdf/2312.04521" title="Download PDF">pdf</a>, <a href="/format/2312.04521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Industrial Anomaly Detection by Crossmodal Feature Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Costanzino%2C+A">Alex Costanzino</a>, 
<a href="/search/cs?searchtype=author&query=Ramirez%2C+P+Z">Pierluigi Zama Ramirez</a>, 
<a href="/search/cs?searchtype=author&query=Lisanti%2C+G">Giuseppe Lisanti</a>, 
<a href="/search/cs?searchtype=author&query=Di+Stefano%2C+L">Luigi Di Stefano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The paper explores the industrial multimodal Anomaly Detection (AD) task,
which exploits point clouds and RGB images to localize anomalies. We introduce
a novel light and fast framework that learns to map features from one modality
to the other on nominal samples. At test time, anomalies are detected by
pinpointing inconsistencies between observed and mapped features. Extensive
experiments show that our approach achieves state-of-the-art detection and
segmentation performance in both the standard and few-shot settings on the
MVTec 3D-AD dataset while achieving faster inference and occupying less memory
than previous multimodal AD methods. Moreover, we propose a layer-pruning
technique to improve memory and time efficiency with a marginal sacrifice in
performance.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04524" title="Abstract">arXiv:2312.04524</a> [<a href="/pdf/2312.04524" title="Download PDF">pdf</a>, <a href="/format/2312.04524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RAVE: Randomized Noise Shuffling for Fast and Consistent Video Editing  with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kara%2C+O">Ozgur Kara</a>, 
<a href="/search/cs?searchtype=author&query=Kurtkaya%2C+B">Bariscan Kurtkaya</a>, 
<a href="/search/cs?searchtype=author&query=Yesiltepe%2C+H">Hidir Yesiltepe</a>, 
<a href="/search/cs?searchtype=author&query=Rehg%2C+J+M">James M. Rehg</a>, 
<a href="/search/cs?searchtype=author&query=Yanardag%2C+P">Pinar Yanardag</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project webpage: <a href="https://rave-video.github.io">this https URL</a> , Github: <a href="http://github.com/rehg-lab/RAVE">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advancements in diffusion-based models have demonstrated significant
success in generating images from text. However, video editing models have not
yet reached the same level of visual quality and user control. To address this,
we introduce RAVE, a zero-shot video editing method that leverages pre-trained
text-to-image diffusion models without additional training. RAVE takes an input
video and a text prompt to produce high-quality videos while preserving the
original motion and semantic structure. It employs a novel noise shuffling
strategy, leveraging spatio-temporal interactions between frames, to produce
temporally consistent videos faster than existing methods. It is also efficient
in terms of memory requirements, allowing it to handle longer videos. RAVE is
capable of a wide range of edits, from local attribute modifications to shape
transformations. In order to demonstrate the versatility of RAVE, we create a
comprehensive video evaluation dataset ranging from object-focused scenes to
complex human activities like dancing and typing, and dynamic scenes featuring
swimming fish and boats. Our qualitative and quantitative experiments highlight
the effectiveness of RAVE in diverse video editing scenarios compared to
existing methods. Our code, dataset and videos can be found in
https://rave-video.github.io.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04526" title="Abstract">arXiv:2312.04526</a> [<a href="/pdf/2312.04526" title="Download PDF">pdf</a>, <a href="/format/2312.04526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithms for the Global Domination Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Inza%2C+E+P">Ernesto Parra Inza</a>, 
<a href="/search/cs?searchtype=author&query=Vakhania%2C+N">Nodari Vakhania</a>, 
<a href="/search/cs?searchtype=author&query=Almira%2C+J+M+S">Jose M. Sigarreta Almira</a>, 
<a href="/search/cs?searchtype=author&query=Mira%2C+F+A+H">Frank A. Hern&#xe1;ndez Mira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">A dominating set D in a graph G is a subset of its vertices such that every
vertex of the graph which does not belong to set D is adjacent to at least one
vertex from set D. A set of vertices of graph G is a global dominating set if
it is a dominating set for both, graph G and its complement. The objective is
to find a global dominating set with the minimum cardinality. The problem is
known to be NP-hard. Neither exact nor approximation algorithm existed . We
propose two exact solution methods, one of them being based on an integer
linear program (ILP) formulation, three heuristic algorithms and a special
purification procedure that further reduces the size of a global dominated set
delivered by any of our heuristic algorithms. We show that the problem remains
NP-hard for restricted types of graphs and specify some families of graphs for
which the heuristics guarantee the optimality. The second exact algorithm
turned out to be about twice faster than ILP for graphs with more than 230
vertices and up to 1080 vertices, which were the largest benchmark instances
that were solved optimally. The heuristics were tested for the existing 2284
benchmark problem instances with up to 14000 vertices and delivered solutions
for the largest instances in less than one minute. Remarkably, for about 52% of
the 1000 instances with the obtained optimal solutions, at least one of the
heuristics generated an optimal solution, where the average approximation error
for the remaining instances was 1.07%.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04527" title="Abstract">arXiv:2312.04527</a> [<a href="/pdf/2312.04527" title="Download PDF">pdf</a>, <a href="/format/2312.04527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correspondences of the Third Kind: Camera Pose Estimation from Object  Reflection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yamashita%2C+K">Kohei Yamashita</a>, 
<a href="/search/cs?searchtype=author&query=Lepetit%2C+V">Vincent Lepetit</a>, 
<a href="/search/cs?searchtype=author&query=Nishino%2C+K">Ko Nishino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Computer vision has long relied on two kinds of correspondences: pixel
correspondences in images and 3D correspondences on object surfaces. Is there
another kind, and if there is, what can they do for us? In this paper, we
introduce correspondences of the third kind we call reflection correspondences
and show that they can help estimate camera pose by just looking at objects
without relying on the background. Reflection correspondences are point
correspondences in the reflected world, i.e., the scene reflected by the object
surface. The object geometry and reflectance alters the scene geometrically and
radiometrically, respectively, causing incorrect pixel correspondences.
Geometry recovered from each image is also hampered by distortions, namely
generalized bas-relief ambiguity, leading to erroneous 3D correspondences. We
show that reflection correspondences can resolve the ambiguities arising from
these distortions. We introduce a neural correspondence estimator and a RANSAC
algorithm that fully leverages all three kinds of correspondences for robust
and accurate joint camera pose and object shape estimation just from the object
appearance. The method expands the horizon of numerous downstream tasks,
including camera pose estimation for appearance modeling (e.g., NeRF) and
motion estimation of reflective objects (e.g., cars on the road), to name a
few, as it relieves the requirement of overlapping background.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04528" title="Abstract">arXiv:2312.04528</a> [<a href="/pdf/2312.04528" title="Download PDF">pdf</a>, <a href="/format/2312.04528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Large Language Models for Hyperparameter Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M+R">Michael R. Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Desai%2C+N">Nishkrit Desai</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+J">Juhan Bae</a>, 
<a href="/search/cs?searchtype=author&query=Lorraine%2C+J">Jonathan Lorraine</a>, 
<a href="/search/cs?searchtype=author&query=Ba%2C+J">Jimmy Ba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper studies using foundational large language models (LLMs) to make
decisions during hyperparameter optimization (HPO). Empirical evaluations
demonstrate that in settings with constrained search budgets, LLMs can perform
comparably or better than traditional HPO methods like random search and
Bayesian optimization on standard benchmarks. Furthermore, we propose to treat
the code specifying our model as a hyperparameter, which the LLM outputs, going
beyond the capabilities of existing HPO approaches. Our findings suggest that
LLMs are a promising tool for improving efficiency in the traditional
decision-making problem of hyperparameter optimization.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04529" title="Abstract">arXiv:2312.04529</a> [<a href="/pdf/2312.04529" title="Download PDF">pdf</a>, <a href="/format/2312.04529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Reflectance Map: Single-Image Stochastic Inverse Rendering of  Illumination and Reflectance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Enyo%2C+Y">Yuto Enyo</a>, 
<a href="/search/cs?searchtype=author&query=Nishino%2C+K">Ko Nishino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Reflectance bounds the frequency spectrum of illumination in the object
appearance. In this paper, we introduce the first stochastic inverse rendering
method, which recovers the full frequency spectrum of an illumination jointly
with the object reflectance from a single image. Our key idea is to solve this
blind inverse problem in the reflectance map, an appearance representation
invariant to the underlying geometry, by learning to reverse the image
formation with a novel diffusion model which we refer to as the Diffusion
Reflectance Map Network (DRMNet). Given an observed reflectance map converted
and completed from the single input image, DRMNet generates a reflectance map
corresponding to a perfect mirror sphere while jointly estimating the
reflectance. The forward process can be understood as gradually filtering a
natural illumination with lower and lower frequency reflectance and additive
Gaussian noise. DRMNet learns to invert this process with two subnetworks,
IllNet and RefNet, which work in concert towards this joint estimation. The
network is trained on an extensive synthetic dataset and is demonstrated to
generalize to real images, showing state-of-the-art accuracy on established
datasets.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04530" title="Abstract">arXiv:2312.04530</a> [<a href="/pdf/2312.04530" title="Download PDF">pdf</a>, <a href="/format/2312.04530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Camera Height Doesn&#x27;t Change: Unsupervised Monocular Scale-Aware  Road-Scene Depth Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kinoshita%2C+G">Genki Kinoshita</a>, 
<a href="/search/cs?searchtype=author&query=Nishino%2C+K">Ko Nishino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Monocular depth estimators either require explicit scale supervision through
auxiliary sensors or suffer from scale ambiguity, which renders them difficult
to deploy in downstream applications. A possible source of scale is the sizes
of objects found in the scene, but inaccurate localization makes them difficult
to exploit. In this paper, we introduce a novel scale-aware monocular depth
estimation method called StableCamH that does not require any auxiliary sensor
or supervision. The key idea is to exploit prior knowledge of object heights in
the scene but aggregate the height cues into a single invariant measure common
to all frames in a road video sequence, namely the camera height. By
formulating monocular depth estimation as camera height optimization, we
achieve robust and accurate unsupervised end-to-end training. To realize
StableCamH, we devise a novel learning-based size prior that can directly
convert car appearance into its dimensions. Extensive experiments on KITTI and
Cityscapes show the effectiveness of StableCamH, its state-of-the-art accuracy
compared with related methods, and its generalizability. The training framework
of StableCamH can be used for any monocular depth estimation method and will
hopefully become a fundamental building block for further work.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04533" title="Abstract">arXiv:2312.04533</a> [<a href="/pdf/2312.04533" title="Download PDF">pdf</a>, <a href="/format/2312.04533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dream2Real: Zero-Shot 3D Object Rearrangement with Vision-Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kapelyukh%2C+I">Ivan Kapelyukh</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yifei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Alzugaray%2C+I">Ignacio Alzugaray</a>, 
<a href="/search/cs?searchtype=author&query=Johns%2C+E">Edward Johns</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project webpage with videos: <a href="https://www.robot-learning.uk/dream2real">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce Dream2Real, a robotics framework which integrates
vision-language models (VLMs) trained on 2D data into a 3D object rearrangement
pipeline. This is achieved by the robot autonomously constructing a 3D
representation of the scene, where objects can be rearranged virtually and an
image of the resulting arrangement rendered. These renders are evaluated by a
VLM, so that the arrangement which best satisfies the user instruction is
selected and recreated in the real world with pick-and-place. This enables
language-conditioned rearrangement to be performed zero-shot, without needing
to collect a training dataset of example arrangements. Results on a series of
real-world tasks show that this framework is robust to distractors,
controllable by language, capable of understanding complex multi-object
relations, and readily applicable to both tabletop and 6-DoF rearrangement
tasks.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04534" title="Abstract">arXiv:2312.04534</a> [<a href="/pdf/2312.04534" title="Download PDF">pdf</a>, <a href="/format/2312.04534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PICTURE: PhotorealistIC virtual Try-on from UnconstRained dEsigns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ning%2C+S">Shuliang Ning</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Duomin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yipeng Qin</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zirong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Baoyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaoguang Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://ningshuliang.github.io/2023/Arxiv/index.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we propose a novel virtual try-on from unconstrained designs
(ucVTON) task to enable photorealistic synthesis of personalized composite
clothing on input human images. Unlike prior arts constrained by specific input
types, our method allows flexible specification of style (text or image) and
texture (full garment, cropped sections, or texture patches) conditions. To
address the entanglement challenge when using full garment images as
conditions, we develop a two-stage pipeline with explicit disentanglement of
style and texture. In the first stage, we generate a human parsing map
reflecting the desired style conditioned on the input. In the second stage, we
composite textures onto the parsing map areas based on the texture input. To
represent complex and non-stationary textures that have never been achieved in
previous fashion editing works, we first propose extracting hierarchical and
balanced CLIP features and applying position encoding in VTON. Experiments
demonstrate superior synthesis quality and personalization enabled by our
method. The flexible control over style and texture mixing brings virtual
try-on to a new level of user experience for online shopping and fashion
design.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04535" title="Abstract">arXiv:2312.04535</a> [<a href="/pdf/2312.04535" title="Download PDF">pdf</a>, <a href="/format/2312.04535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trajeglish: Learning the Language of Driving Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Philion%2C+J">Jonah Philion</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X+B">Xue Bin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Fidler%2C+S">Sanja Fidler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">A longstanding challenge for self-driving development is simulating dynamic
driving scenarios seeded from recorded driving logs. In pursuit of this
functionality, we apply tools from discrete sequence modeling to model how
vehicles, pedestrians and cyclists interact in driving scenarios. Using a
simple data-driven tokenization scheme, we discretize trajectories to
centimeter-level resolution using a small vocabulary. We then model the
multi-agent sequence of motion tokens with a GPT-like encoder-decoder that is
autoregressive in time and takes into account intra-timestep interaction
between agents. Scenarios sampled from our model exhibit state-of-the-art
realism; our model tops the Waymo Sim Agents Benchmark, surpassing prior work
along the realism meta metric by 3.3% and along the interaction metric by 9.9%.
We ablate our modeling choices in full autonomy and partial autonomy settings,
and show that the representations learned by our model can quickly be adapted
to improve performance on nuScenes. We additionally evaluate the scalability of
our model with respect to parameter count and dataset size, and use density
estimates from our model to quantify the saliency of context length and
intra-timestep interaction for the traffic modeling task.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04539" title="Abstract">arXiv:2312.04539</a> [<a href="/pdf/2312.04539" title="Download PDF">pdf</a>, <a href="/format/2312.04539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Guided Open-Vocabulary Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%9Clger%2C+O">Osman &#xdc;lger</a>, 
<a href="/search/cs?searchtype=author&query=Kulicki%2C+M">Maksymilian Kulicki</a>, 
<a href="/search/cs?searchtype=author&query=Asano%2C+Y">Yuki Asano</a>, 
<a href="/search/cs?searchtype=author&query=Oswald%2C+M+R">Martin R. Oswald</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision-Language Models (VLMs) have emerged as promising tools for open-ended
image understanding tasks, including open vocabulary segmentation. Yet, direct
application of such VLMs to segmentation is non-trivial, since VLMs are trained
with image-text pairs and naturally lack pixel-level granularity. Recent works
have made advancements in bridging this gap, often by leveraging the shared
image-text space in which the image and a provided text prompt are represented.
In this paper, we challenge the capabilities of VLMs further and tackle
open-vocabulary segmentation without the need for any textual input. To this
end, we propose a novel Self-Guided Semantic Segmentation (Self-Seg) framework.
Self-Seg is capable of automatically detecting relevant class names from
clustered BLIP embeddings and using these for accurate semantic segmentation.
In addition, we propose an LLM-based Open-Vocabulary Evaluator (LOVE) to
effectively assess predicted open-vocabulary class names. We achieve
state-of-the-art results on Pascal VOC, ADE20K and CityScapes for
open-vocabulary segmentation without given class names, as well as competitive
performance with methods where class names are given. All code and data will be
released.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04540" title="Abstract">arXiv:2312.04540</a> [<a href="/pdf/2312.04540" title="Download PDF">pdf</a>, <a href="/format/2312.04540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sim-to-Real Causal Transfer: A Metric Learning Approach to  Causally-Aware Interaction Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuejiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Rahimi%2C+A">Ahmad Rahimi</a>, 
<a href="/search/cs?searchtype=author&query=Luan%2C+P">Po-Chien Luan</a>, 
<a href="/search/cs?searchtype=author&query=Raji%C4%8D%2C+F">Frano Raji&#x10d;</a>, 
<a href="/search/cs?searchtype=author&query=Alahi%2C+A">Alexandre Alahi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Multiagent Systems (cs.MA); Robotics (cs.RO)

</div>
<p class="mathjax">Modeling spatial-temporal interactions among neighboring agents is at the
heart of multi-agent problems such as motion forecasting and crowd navigation.
Despite notable progress, it remains unclear to which extent modern
representations can capture the causal relationships behind agent interactions.
In this work, we take an in-depth look at the causal awareness of these
representations, from computational formalism to real-world practice. First, we
cast doubt on the notion of non-causal robustness studied in the recent
CausalAgents benchmark. We show that recent representations are already
partially resilient to perturbations of non-causal agents, and yet modeling
indirect causal effects involving mediator agents remains challenging. To
address this challenge, we introduce a metric learning approach that
regularizes latent representations with causal annotations. Our controlled
experiments show that this approach not only leads to higher degrees of causal
awareness but also yields stronger out-of-distribution robustness. To further
operationalize it in practice, we propose a sim-to-real causal transfer method
via cross-domain multi-task learning. Experiments on pedestrian datasets show
that our method can substantially boost generalization, even in the absence of
real-world causal annotations. We hope our work provides a new perspective on
the challenges and potential pathways towards causally-aware representations of
multi-agent interactions. Our code is available at
https://github.com/socialcausality.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04542" title="Abstract">arXiv:2312.04542</a> [<a href="/pdf/2312.04542" title="Download PDF">pdf</a>, <a href="/format/2312.04542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoK: Unintended Interactions among Machine Learning Defenses and Risks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duddu%2C+V">Vasisht Duddu</a>, 
<a href="/search/cs?searchtype=author&query=Szyller%2C+S">Sebastian Szyller</a>, 
<a href="/search/cs?searchtype=author&query=Asokan%2C+N">N. Asokan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine learning (ML) models cannot neglect risks to security, privacy, and
fairness. Several defenses have been proposed to mitigate such risks. When a
defense is effective in mitigating one risk, it may correspond to increased or
decreased susceptibility to other risks. Existing research lacks an effective
framework to recognize and explain these unintended interactions. We present
such a framework, based on the conjecture that overfitting and memorization
underlie unintended interactions. We survey existing literature on unintended
interactions, accommodating them within our framework. We use our framework to
conjecture on two previously unexplored interactions, and empirically validate
our conjectures.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04543" title="Abstract">arXiv:2312.04543</a> [<a href="/pdf/2312.04543" title="Download PDF">pdf</a>, <a href="/format/2312.04543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperDreamer: Hyper-Realistic 3D Content Generation and Editing from a  Single Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhibing Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xinggang Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGGRAPH Asia 2023 (conference track). Project page: <a href="https://ys-imtech.github.io/HyperDreamer/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D content creation from a single image is a long-standing yet highly
desirable task. Recent advances introduce 2D diffusion priors, yielding
reasonable results. However, existing methods are not hyper-realistic enough
for post-generation usage, as users cannot view, render and edit the resulting
3D content from a full range. To address these challenges, we introduce
HyperDreamer with several key designs and appealing properties: 1) Viewable:
360 degree mesh modeling with high-resolution textures enables the creation of
visually compelling 3D models from a full range of observation points. 2)
Renderable: Fine-grained semantic segmentation and data-driven priors are
incorporated as guidance to learn reasonable albedo, roughness, and specular
properties of the materials, enabling semantic-aware arbitrary material
estimation. 3) Editable: For a generated model or their own data, users can
interactively select any region via a few clicks and efficiently edit the
texture with text-based guidance. Extensive experiments demonstrate the
effectiveness of HyperDreamer in modeling region-aware materials with
high-resolution textures and enabling user-friendly editing. We believe that
HyperDreamer holds promise for advancing 3D content creation and finding
applications in various domains.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04546" title="Abstract">arXiv:2312.04546</a> [<a href="/pdf/2312.04546" title="Download PDF">pdf</a>, <a href="/format/2312.04546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Learning for Feature Shift Detection and Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barrabes%2C+M">Miriam Barrabes</a>, 
<a href="/search/cs?searchtype=author&query=Montserrat%2C+D+M">Daniel Mas Montserrat</a>, 
<a href="/search/cs?searchtype=author&query=Geleta%2C+M">Margarita Geleta</a>, 
<a href="/search/cs?searchtype=author&query=Giro-i-Nieto%2C+X">Xavier Giro-i-Nieto</a>, 
<a href="/search/cs?searchtype=author&query=Ioannidis%2C+A+G">Alexander G. Ioannidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Applications (stat.AP); Machine Learning (stat.ML)

</div>
<p class="mathjax">Data shift is a phenomenon present in many real-world applications, and while
there are multiple methods attempting to detect shifts, the task of localizing
and correcting the features originating such shifts has not been studied in
depth. Feature shifts can occur in many datasets, including in multi-sensor
data, where some sensors are malfunctioning, or in tabular and structured data,
including biomedical, financial, and survey data, where faulty standardization
and data processing pipelines can lead to erroneous features. In this work, we
explore using the principles of adversarial learning, where the information
from several discriminators trained to distinguish between two distributions is
used to both detect the corrupted features and fix them in order to remove the
distribution shift between datasets. We show that mainstream supervised
classifiers, such as random forest or gradient boosting trees, combined with
simple iterative heuristics, can localize and correct feature shifts,
outperforming current statistical and neural network-based techniques. The code
is available at https://github.com/AI-sandbox/DataFix.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04547" title="Abstract">arXiv:2312.04547</a> [<a href="/pdf/2312.04547" title="Download PDF">pdf</a>, <a href="/format/2312.04547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital Life Project: Autonomous 3D Characters with Social Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhongang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jianping Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Qing%2C+Z">Zhongfei Qing</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xinying Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhengyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+H">Haiyi Mei</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+C">Chen Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruisi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+W">Wanqi Yin</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiangyu Fan</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Han Du</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Liang Pan</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Peng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhitao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+T">Tianxiang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yukun Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaogang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Loy%2C+C+C">Chen Change Loy</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Homepage: <a href="https://digital-life-project.com/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this work, we present Digital Life Project, a framework utilizing language
as the universal medium to build autonomous 3D characters, who are capable of
engaging in social interactions and expressing with articulated body motions,
thereby simulating life in a digital environment. Our framework comprises two
primary components: 1) SocioMind: a meticulously crafted digital brain that
models personalities with systematic few-shot exemplars, incorporates a
reflection process based on psychology principles, and emulates autonomy by
initiating dialogue topics; 2) MoMat-MoGen: a text-driven motion synthesis
paradigm for controlling the character's digital body. It integrates motion
matching, a proven industry technique to ensure motion quality, with
cutting-edge advancements in motion generation for diversity. Extensive
experiments demonstrate that each module achieves state-of-the-art performance
in its respective domain. Collectively, they enable virtual characters to
initiate and sustain dialogues autonomously, while evolving their
socio-psychological states. Concurrently, these characters can perform
contextually relevant bodily movements. Additionally, a motion captioning
module further allows the virtual character to recognize and appropriately
respond to human players' actions. Homepage: https://digital-life-project.com/
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04548" title="Abstract">arXiv:2312.04548</a> [<a href="/pdf/2312.04548" title="Download PDF">pdf</a>, <a href="/format/2312.04548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiview Aerial Visual Recognition (MAVREC): Can Multi-view Improve  Aerial Visual Perception?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dutta%2C+A">Aritra Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Srijan Das</a>, 
<a href="/search/cs?searchtype=author&query=Nielsen%2C+J">Jacob Nielsen</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+R">Rajatsubhra Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+M">Mubarak Shah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite the commercial abundance of UAVs, aerial data acquisition remains
challenging, and the existing Asia and North America-centric open-source UAV
datasets are small-scale or low-resolution and lack diversity in scene
contextuality. Additionally, the color content of the scenes, solar-zenith
angle, and population density of different geographies influence the data
diversity. These two factors conjointly render suboptimal aerial-visual
perception of the deep neural network (DNN) models trained primarily on the
ground-view data, including the open-world foundational models.
<br />To pave the way for a transformative era of aerial detection, we present
Multiview Aerial Visual RECognition or MAVREC, a video dataset where we record
synchronized scenes from different perspectives -- ground camera and
drone-mounted camera. MAVREC consists of around 2.5 hours of industry-standard
2.7K resolution video sequences, more than 0.5 million frames, and 1.1 million
annotated bounding boxes. This makes MAVREC the largest ground and aerial-view
dataset, and the fourth largest among all drone-based datasets across all
modalities and tasks. Through our extensive benchmarking on MAVREC, we
recognize that augmenting object detectors with ground-view images from the
corresponding geographical location is a superior pre-training strategy for
aerial detection. Building on this strategy, we benchmark MAVREC with a
curriculum-based semi-supervised object detection approach that leverages
labeled (ground and aerial) and unlabeled (only aerial) images to enhance the
aerial detection. We publicly release the MAVREC dataset:
https://mavrec.github.io.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04549" title="Abstract">arXiv:2312.04549</a> [<a href="/pdf/2312.04549" title="Download PDF">pdf</a>, <a href="/format/2312.04549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PlayFusion: Skill Acquisition via Diffusion from Language-Annotated Play
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lili Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bahl%2C+S">Shikhar Bahl</a>, 
<a href="/search/cs?searchtype=author&query=Pathak%2C+D">Deepak Pathak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In CoRL 2023. Website at <a href="https://play-fusion.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Learning from unstructured and uncurated data has become the dominant
paradigm for generative approaches in language and vision. Such unstructured
and unguided behavior data, commonly known as play, is also easier to collect
in robotics but much more difficult to learn from due to its inherently
multimodal, noisy, and suboptimal nature. In this paper, we study this problem
of learning goal-directed skill policies from unstructured play data which is
labeled with language in hindsight. Specifically, we leverage advances in
diffusion models to learn a multi-task diffusion model to extract robotic
skills from play data. Using a conditional denoising diffusion process in the
space of states and actions, we can gracefully handle the complexity and
multimodality of play data and generate diverse and interesting robot
behaviors. To make diffusion models more useful for skill learning, we
encourage robotic agents to acquire a vocabulary of skills by introducing
discrete bottlenecks into the conditional behavior generation process. In our
experiments, we demonstrate the effectiveness of our approach across a wide
variety of environments in both simulation and the real world. Results
visualizations and videos at https://play-fusion.github.io
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04551" title="Abstract">arXiv:2312.04551</a> [<a href="/pdf/2312.04551" title="Download PDF">pdf</a>, <a href="/format/2312.04551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Free3D: Consistent Novel View Synthesis without 3D Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chuanxia Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Vedaldi%2C+A">Andrea Vedaldi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> webpage: <a href="https://chuanxiaz.com/free3d/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce Free3D, a simple approach designed for open-set novel view
synthesis (NVS) from a single image. Similar to Zero-1-to-3, we start from a
pre-trained 2D image generator for generalization, and fine-tune it for NVS.
Compared to recent and concurrent works, we obtain significant improvements
without resorting to an explicit 3D representation, which is slow and
memory-consuming or training an additional 3D network. We do so by encoding
better the target camera pose via a new per-pixel ray conditioning
normalization (RCN) layer. The latter injects pose information in the
underlying 2D image generator by telling each pixel its specific viewing
direction. We also improve multi-view consistency via a light-weight multi-view
attention layer and multi-view noise sharing. We train Free3D on the Objaverse
dataset and demonstrate excellent generalization to various new categories in
several new datasets, including OminiObject3D and GSO. We hope our simple and
effective approach will serve as a solid baseline and help future research in
NVS with more accuracy pose. The project page is available at
https://chuanxiaz.com/free3d/.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04552" title="Abstract">arXiv:2312.04552</a> [<a href="/pdf/2312.04552" title="Download PDF">pdf</a>, <a href="/format/2312.04552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Illustrated Instructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Menon%2C+S">Sachit Menon</a>, 
<a href="/search/cs?searchtype=author&query=Misra%2C+I">Ishan Misra</a>, 
<a href="/search/cs?searchtype=author&query=Girdhar%2C+R">Rohit Girdhar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="http://facebookresearch.github.io/IllustratedInstructions">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">We introduce the new task of generating Illustrated Instructions, i.e.,
visual instructions customized to a user's needs. We identify desiderata unique
to this task, and formalize it through a suite of automatic and human
evaluation metrics, designed to measure the validity, consistency, and efficacy
of the generations. We combine the power of large language models (LLMs)
together with strong text-to-image generation diffusion models to propose a
simple approach called StackedDiffusion, which generates such illustrated
instructions given text as input. The resulting model strongly outperforms
baseline approaches and state-of-the-art multimodal LLMs; and in 30% of cases,
users even prefer it to human-generated articles. Most notably, it enables
various new and exciting applications far beyond what static articles on the
web can provide, such as personalized instructions complete with intermediate
steps and pictures in response to a user's individual situation.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04553" title="Abstract">arXiv:2312.04553</a> [<a href="/pdf/2312.04553" title="Download PDF">pdf</a>, <a href="/format/2312.04553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPIDeRS: Structured Polarization for Invisible Depth and Reflectance  Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ichikawa%2C+T">Tomoki Ichikawa</a>, 
<a href="/search/cs?searchtype=author&query=Nobuhara%2C+S">Shohei Nobuhara</a>, 
<a href="/search/cs?searchtype=author&query=Nishino%2C+K">Ko Nishino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Can we capture shape and reflectance in stealth? Such capability would be
valuable for many application domains in vision, xR, robotics, and HCI. We
introduce Structured Polarization, the first depth and reflectance sensing
method using patterns of polarized light (SPIDeRS). The key idea is to modulate
the angle of linear polarization (AoLP) of projected light at each pixel. The
use of polarization makes it invisible and lets us recover not only depth but
also directly surface normals and even reflectance. We implement SPIDeRS with a
liquid crystal spatial light modulator (SLM) and a polarimetric camera. We
derive a novel method for robustly extracting the projected structured
polarization pattern from the polarimetric object appearance. We evaluate the
effectiveness of SPIDeRS by applying it to a number of real-world objects. The
results show that our method successfully reconstructs object shapes of various
materials and is robust to diffuse reflection and ambient light. We also
demonstrate relighting using recovered surface normals and reflectance. We
believe SPIDeRS opens a new avenue of polarization use in visual sensing.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04554" title="Abstract">arXiv:2312.04554</a> [<a href="/pdf/2312.04554" title="Download PDF">pdf</a>, <a href="/format/2312.04554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Visual Grounding through Self-Consistent Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ruozhen He</a>, 
<a href="/search/cs?searchtype=author&query=Cascante-Bonilla%2C+P">Paola Cascante-Bonilla</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ziyan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Berg%2C+A+C">Alexander C. Berg</a>, 
<a href="/search/cs?searchtype=author&query=Ordonez%2C+V">Vicente Ordonez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://catherine-r-he.github.io/SelfEQ/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Vision-and-language models trained to match images with text can be combined
with visual explanation methods to point to the locations of specific objects
in an image. Our work shows that the localization --"grounding"-- abilities of
these models can be further improved by finetuning for self-consistent visual
explanations. We propose a strategy for augmenting existing text-image datasets
with paraphrases using a large language model, and SelfEQ, a weakly-supervised
strategy on visual explanation maps for paraphrases that encourages
self-consistency. Specifically, for an input textual phrase, we attempt to
generate a paraphrase and finetune the model so that the phrase and paraphrase
map to the same region in the image. We posit that this both expands the
vocabulary that the model is able to handle, and improves the quality of the
object locations highlighted by gradient-based visual explanation methods (e.g.
GradCAM). We demonstrate that SelfEQ improves performance on Flickr30k,
ReferIt, and RefCOCO+ over a strong baseline method and several prior works.
Particularly, comparing to other methods that do not use any type of box
annotations, we obtain 84.07% on Flickr30k (an absolute improvement of 4.69%),
67.40% on ReferIt (an absolute improvement of 7.68%), and 75.10%, 55.49% on
RefCOCO+ test sets A and B respectively (an absolute improvement of 3.74% on
average).
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04556" title="Abstract">arXiv:2312.04556</a> [<a href="/pdf/2312.04556" title="Download PDF">pdf</a>, <a href="/format/2312.04556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Mathematicians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frieder%2C+S">Simon Frieder</a>, 
<a href="/search/cs?searchtype=author&query=Berner%2C+J">Julius Berner</a>, 
<a href="/search/cs?searchtype=author&query=Petersen%2C+P">Philipp Petersen</a>, 
<a href="/search/cs?searchtype=author&query=Lukasiewicz%2C+T">Thomas Lukasiewicz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); History and Overview (math.HO)

</div>
<p class="mathjax">Large language models (LLMs) such as ChatGPT have received immense interest
for their general-purpose language understanding and, in particular, their
ability to generate high-quality text or computer code. For many professions,
LLMs represent an invaluable tool that can speed up and improve the quality of
work. In this note, we discuss to what extent they can aid professional
mathematicians. We first provide a mathematical description of the transformer
model used in all modern language models. Based on recent studies, we then
outline best practices and potential issues and report on the mathematical
abilities of language models. Finally, we shed light on the potential of LMMs
to change how mathematicians work.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04557" title="Abstract">arXiv:2312.04557</a> [<a href="/pdf/2312.04557" title="Download PDF">pdf</a>, <a href="/format/2312.04557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GenTron: Delving Deep into Diffusion Transformers for Image and Video  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shoufa Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mengmeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jiawei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Cong%2C+Y">Yuren Cong</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Sen He</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yanping Xie</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+A">Animesh Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+T">Tao Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Perez-Rua%2C+J">Juan-Manuel Perez-Rua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report. Website: <a href="https://www.shoufachen.com/gentron_website/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this study, we explore Transformer-based diffusion models for image and
video generation. Despite the dominance of Transformer architectures in various
fields due to their flexibility and scalability, the visual generative domain
primarily utilizes CNN-based U-Net architectures, particularly in
diffusion-based models. We introduce GenTron, a family of Generative models
employing Transformer-based diffusion, to address this gap. Our initial step
was to adapt Diffusion Transformers (DiTs) from class to text conditioning, a
process involving thorough empirical exploration of the conditioning mechanism.
We then scale GenTron from approximately 900M to over 3B parameters, observing
significant improvements in visual quality. Furthermore, we extend GenTron to
text-to-video generation, incorporating novel motion-free guidance to enhance
video quality. In human evaluations against SDXL, GenTron achieves a 51.1% win
rate in visual quality (with a 19.8% draw rate), and a 42.3% win rate in text
alignment (with a 42.9% draw rate). GenTron also excels in the T2I-CompBench,
underscoring its strengths in compositional generation. We believe this work
will provide meaningful insights and serve as a valuable reference for future
research.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04558" title="Abstract">arXiv:2312.04558</a> [<a href="/pdf/2312.04558" title="Download PDF">pdf</a>, <a href="/format/2312.04558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MonoGaussianAvatar: Monocular Gaussian Point-based Head Avatar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yufan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lizhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qijing Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+H">Hongjiang Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shengping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Hongxun Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yebin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The link to our projectpage is <a href="https://yufan1012.github.io/MonoGaussianAvatar">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The ability to animate photo-realistic head avatars reconstructed from
monocular portrait video sequences represents a crucial step in bridging the
gap between the virtual and real worlds. Recent advancements in head avatar
techniques, including explicit 3D morphable meshes (3DMM), point clouds, and
neural implicit representation have been exploited for this ongoing research.
However, 3DMM-based methods are constrained by their fixed topologies,
point-based approaches suffer from a heavy training burden due to the extensive
quantity of points involved, and the last ones suffer from limitations in
deformation flexibility and rendering efficiency. In response to these
challenges, we propose MonoGaussianAvatar (Monocular Gaussian Point-based Head
Avatar), a novel approach that harnesses 3D Gaussian point representation
coupled with a Gaussian deformation field to learn explicit head avatars from
monocular portrait videos. We define our head avatars with Gaussian points
characterized by adaptable shapes, enabling flexible topology. These points
exhibit movement with a Gaussian deformation field in alignment with the target
pose and expression of a person, facilitating efficient deformation.
Additionally, the Gaussian points have controllable shape, size, color, and
opacity combined with Gaussian splatting, allowing for efficient training and
rendering. Experiments demonstrate the superior performance of our method,
which achieves state-of-the-art results among previous methods.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04559" title="Abstract">arXiv:2312.04559</a> [<a href="/pdf/2312.04559" title="Download PDF">pdf</a>, <a href="/format/2312.04559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PrimDiffusion: Volumetric Primitives Diffusion for 3D Human Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhaoxi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+F">Fangzhou Hong</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+H">Haiyi Mei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guangcong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023; Project page <a href="https://frozenburning.github.io/projects/primdiffusion/">this https URL</a> Code available at <a href="https://github.com/FrozenBurning/PrimDiffusion">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We present PrimDiffusion, the first diffusion-based framework for 3D human
generation. Devising diffusion models for 3D human generation is difficult due
to the intensive computational cost of 3D representations and the articulated
topology of 3D humans. To tackle these challenges, our key insight is operating
the denoising diffusion process directly on a set of volumetric primitives,
which models the human body as a number of small volumes with radiance and
kinematic information. This volumetric primitives representation marries the
capacity of volumetric representations with the efficiency of primitive-based
rendering. Our PrimDiffusion framework has three appealing properties: 1)
compact and expressive parameter space for the diffusion model, 2) flexible 3D
representation that incorporates human prior, and 3) decoder-free rendering for
efficient novel-view and novel-pose synthesis. Extensive experiments validate
that PrimDiffusion outperforms state-of-the-art methods in 3D human generation.
Notably, compared to GAN-based methods, our PrimDiffusion supports real-time
rendering of high-quality 3D humans at a resolution of $512\times512$ once the
denoising process is done. We also demonstrate the flexibility of our framework
on training-free conditional generation such as texture transfer and 3D
inpainting.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04560" title="Abstract">arXiv:2312.04560</a> [<a href="/pdf/2312.04560" title="Download PDF">pdf</a>, <a href="/format/2312.04560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeRFiller: Completing Scenes via Generative 3D Inpainting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weber%2C+E">Ethan Weber</a>, 
<a href="/search/cs?searchtype=author&query=Ho%C5%82y%C5%84ski%2C+A">Aleksander Ho&#x142;y&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Jampani%2C+V">Varun Jampani</a>, 
<a href="/search/cs?searchtype=author&query=Saxena%2C+S">Saurabh Saxena</a>, 
<a href="/search/cs?searchtype=author&query=Snavely%2C+N">Noah Snavely</a>, 
<a href="/search/cs?searchtype=author&query=Kar%2C+A">Abhishek Kar</a>, 
<a href="/search/cs?searchtype=author&query=Kanazawa%2C+A">Angjoo Kanazawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://ethanweber.me/nerfiller">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">We propose NeRFiller, an approach that completes missing portions of a 3D
capture via generative 3D inpainting using off-the-shelf 2D visual generative
models. Often parts of a captured 3D scene or object are missing due to mesh
reconstruction failures or a lack of observations (e.g., contact regions, such
as the bottom of objects, or hard-to-reach areas). We approach this challenging
3D inpainting problem by leveraging a 2D inpainting diffusion model. We
identify a surprising behavior of these models, where they generate more 3D
consistent inpaints when images form a 2$\times$2 grid, and show how to
generalize this behavior to more than four images. We then present an iterative
framework to distill these inpainted regions into a single consistent 3D scene.
In contrast to related works, we focus on completing scenes rather than
deleting foreground objects, and our approach does not require tight 2D object
masks or text. We compare our approach to relevant baselines adapted to our
setting on a variety of scenes, where NeRFiller creates the most 3D consistent
and plausible scene completions. Our project page is at
https://ethanweber.me/nerfiller.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04561" title="Abstract">arXiv:2312.04561</a> [<a href="/pdf/2312.04561" title="Download PDF">pdf</a>, <a href="/format/2312.04561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GenDeF: Learning Generative Deformation Field for Video Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+K">Kecheng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiuyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zifan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Ceyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yujun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chunhua Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://aim-uofa.github.io/GenDeF/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We offer a new perspective on approaching the task of video generation.
Instead of directly synthesizing a sequence of frames, we propose to render a
video by warping one static image with a generative deformation field (GenDeF).
Such a pipeline enjoys three appealing advantages. First, we can sufficiently
reuse a well-trained image generator to synthesize the static image (also
called canonical image), alleviating the difficulty in producing a video and
thereby resulting in better visual quality. Second, we can easily convert a
deformation field to optical flows, making it possible to apply explicit
structural regularizations for motion modeling, leading to temporally
consistent results. Third, the disentanglement between content and motion
allows users to process a synthesized video through processing its
corresponding static image without any tuning, facilitating many applications
like video editing, keypoint tracking, and video segmentation. Both qualitative
and quantitative results on three common video generation benchmarks
demonstrate the superiority of our GenDeF method.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04563" title="Abstract">arXiv:2312.04563</a> [<a href="/pdf/2312.04563" title="Download PDF">pdf</a>, <a href="/format/2312.04563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Geometry Grounded Deep Structure From Motion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Karaev%2C+N">Nikita Karaev</a>, 
<a href="/search/cs?searchtype=author&query=Rupprecht%2C+C">Christian Rupprecht</a>, 
<a href="/search/cs?searchtype=author&query=Novotny%2C+D">David Novotny</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 figures. Project page: <a href="https://vggsfm.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Structure-from-motion (SfM) is a long-standing problem in the computer vision
community, which aims to reconstruct the camera poses and 3D structure of a
scene from a set of unconstrained 2D images. Classical frameworks solve this
problem in an incremental manner by detecting and matching keypoints,
registering images, triangulating 3D points, and conducting bundle adjustment.
Recent research efforts have predominantly revolved around harnessing the power
of deep learning techniques to enhance specific elements (e.g., keypoint
matching), but are still based on the original, non-differentiable pipeline.
Instead, we propose a new deep pipeline VGGSfM, where each component is fully
differentiable and thus can be trained in an end-to-end manner. To this end, we
introduce new mechanisms and simplifications. First, we build on recent
advances in deep 2D point tracking to extract reliable pixel-accurate tracks,
which eliminates the need for chaining pairwise matches. Furthermore, we
recover all cameras simultaneously based on the image and track features
instead of gradually registering cameras. Finally, we optimise the cameras and
triangulate 3D points via a differentiable bundle adjustment layer. We attain
state-of-the-art performance on three popular datasets, CO3D, IMC Phototourism,
and ETH3D.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04564" title="Abstract">arXiv:2312.04564</a> [<a href="/pdf/2312.04564" title="Download PDF">pdf</a>, <a href="/format/2312.04564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EAGLES: Efficient Accelerated 3D Gaussians with Lightweight EncodingS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Girish%2C+S">Sharath Girish</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+K">Kamal Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+A">Abhinav Shrivastava</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Website: <a href="https://efficientgaussian.github.io">this https URL</a> Code: <a href="https://github.com/Sharath-girish/efficientgaussian">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Recently, 3D Gaussian splatting (3D-GS) has gained popularity in novel-view
scene synthesis. It addresses the challenges of lengthy training times and slow
rendering speeds associated with Neural Radiance Fields (NeRFs). Through rapid,
differentiable rasterization of 3D Gaussians, 3D-GS achieves real-time
rendering and accelerated training. They, however, demand substantial memory
resources for both training and storage, as they require millions of Gaussians
in their point cloud representation for each scene. We present a technique
utilizing quantized embeddings to significantly reduce memory storage
requirements and a coarse-to-fine training strategy for a faster and more
stable optimization of the Gaussian point clouds. Our approach results in scene
representations with fewer Gaussians and quantized representations, leading to
faster training times and rendering speeds for real-time rendering of high
resolution scenes. We reduce memory by more than an order of magnitude all
while maintaining the reconstruction quality. We validate the effectiveness of
our approach on a variety of datasets and scenes preserving the visual quality
while consuming 10-20x less memory and faster training/inference speed. Project
page and code is available https://efficientgaussian.github.io
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04565" title="Abstract">arXiv:2312.04565</a> [<a href="/pdf/2312.04565" title="Download PDF">pdf</a>, <a href="/format/2312.04565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MuRF: Multi-Baseline Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haofei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Anpei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuedong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sakaridis%2C+C">Christos Sakaridis</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yulun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pollefeys%2C+M">Marc Pollefeys</a>, 
<a href="/search/cs?searchtype=author&query=Geiger%2C+A">Andreas Geiger</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Fisher Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://haofeixu.github.io/murf/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present Multi-Baseline Radiance Fields (MuRF), a general feed-forward
approach to solving sparse view synthesis under multiple different baseline
settings (small and large baselines, and different number of input views). To
render a target novel view, we discretize the 3D space into planes parallel to
the target image plane, and accordingly construct a target view frustum volume.
Such a target volume representation is spatially aligned with the target view,
which effectively aggregates relevant information from the input views for
high-quality rendering. It also facilitates subsequent radiance field
regression with a convolutional network thanks to its axis-aligned nature. The
3D context modeled by the convolutional network enables our method to synthesis
sharper scene structures than prior works. Our MuRF achieves state-of-the-art
performance across multiple different baseline settings and diverse scenarios
ranging from simple objects (DTU) to complex indoor and outdoor scenes
(RealEstate10K and LLFF). We also show promising zero-shot generalization
abilities on the Mip-NeRF 360 dataset, demonstrating the general applicability
of MuRF.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04566" title="Abstract">arXiv:2312.04566</a> [<a href="/pdf/2312.04566" title="Download PDF">pdf</a>, <a href="/format/2312.04566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gen2Det: Generate to Detect
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suri%2C+S">Saksham Suri</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+F">Fanyi Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+A">Animesh Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Culatana%2C+S+C">Sean Chang Culatana</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamoorthi%2C+R">Raghuraman Krishnamoorthi</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chenchen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+A">Abhinav Shrivastava</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently diffusion models have shown improvement in synthetic image quality
as well as better control in generation. We motivate and present Gen2Det, a
simple modular pipeline to create synthetic training data for object detection
for free by leveraging state-of-the-art grounded image generation methods.
Unlike existing works which generate individual object instances, require
identifying foreground followed by pasting on other images, we simplify to
directly generating scene-centric images. In addition to the synthetic data,
Gen2Det also proposes a suite of techniques to best utilize the generated data,
including image-level filtering, instance-level filtering, and better training
recipe to account for imperfections in the generation. Using Gen2Det, we show
healthy improvements on object detection and segmentation tasks under various
settings and agnostic to detection methods. In the long-tailed detection
setting on LVIS, Gen2Det improves the performance on rare categories by a large
margin while also significantly improving the performance on other categories,
e.g. we see an improvement of 2.13 Box AP and 1.84 Mask AP over just training
on real data on LVIS with Mask R-CNN. In the low-data regime setting on COCO,
Gen2Det consistently improves both Box and Mask AP by 2.27 and 1.85 points. In
the most general detection setting, Gen2Det still demonstrates robust
performance gains, e.g. it improves the Box and Mask AP on COCO by 0.45 and
0.32 points.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04567" title="Abstract">arXiv:2312.04567</a> [<a href="/pdf/2312.04567" title="Download PDF">pdf</a>, <a href="/format/2312.04567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Laws of Synthetic Images for Model Training ... for Now
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lijie Fan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kaifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+D">Dilip Krishnan</a>, 
<a href="/search/cs?searchtype=author&query=Katabi%2C+D">Dina Katabi</a>, 
<a href="/search/cs?searchtype=author&query=Isola%2C+P">Phillip Isola</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yonglong Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent significant advances in text-to-image models unlock the possibility of
training vision systems using synthetic images, potentially overcoming the
difficulty of collecting curated data at scale. It is unclear, however, how
these models behave at scale, as more synthetic data is added to the training
set. In this paper we study the scaling laws of synthetic images generated by
state of the art text-to-image models, for the training of supervised models:
image classifiers with label supervision, and CLIP with language supervision.
We identify several factors, including text prompts, classifier-free guidance
scale, and types of text-to-image models, that significantly affect scaling
behavior. After tuning these factors, we observe that synthetic images
demonstrate a scaling trend similar to, but slightly less effective than, real
images in CLIP training, while they significantly underperform in scaling when
training supervised image classifiers. Our analysis indicates that the main
reason for this underperformance is the inability of off-the-shelf
text-to-image models to generate certain concepts, a limitation that
significantly impairs the training of image classifiers. Our findings also
suggest that scaling synthetic data can be particularly effective in scenarios
such as: (1) when there is a limited supply of real images for a supervised
problem (e.g., fewer than 0.5 million images in ImageNet), (2) when the
evaluation dataset diverges significantly from the training data, indicating
the out-of-distribution scenario, or (3) when synthetic data is used in
conjunction with real images, as demonstrated in the training of CLIP models.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Fri,  8 Dec 23</h3>
<dl>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03761" title="Abstract">arXiv:2312.03761</a> (cross-list from stat.ML) [<a href="/pdf/2312.03761" title="Download PDF">pdf</a>, <a href="/format/2312.03761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning High-Dimensional Differential Graphs From Multi-Attribute Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Tugnait%2C+J+K">Jitendra K Tugnait</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures and 1 table. To be published in the IEEE Transactions on Signal Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">We consider the problem of estimating differences in two Gaussian graphical
models (GGMs) which are known to have similar structure. The GGM structure is
encoded in its precision (inverse covariance) matrix. In many applications one
is interested in estimating the difference in two precision matrices to
characterize underlying changes in conditional dependencies of two sets of
data. Existing methods for differential graph estimation are based on
single-attribute (SA) models where one associates a scalar random variable with
each node. In multi-attribute (MA) graphical models, each node represents a
random vector. In this paper, we analyze a group lasso penalized D-trace loss
function approach for differential graph learning from multi-attribute data. An
alternating direction method of multipliers (ADMM) algorithm is presented to
optimize the objective function. Theoretical analysis establishing consistency
in support recovery and estimation in high-dimensional settings is provided.
Numerical results based on synthetic as well as real data are presented.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03773" title="Abstract">arXiv:2312.03773</a> (cross-list from q-bio.MN) [<a href="/pdf/2312.03773" title="Download PDF">pdf</a>, <a href="/ps/2312.03773" title="Download PostScript">ps</a>, <a href="/format/2312.03773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A multi-layer refined network model for the identification of essential  proteins
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+H">Haoyue Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Pan%2C+L">Li Pan</a>, 
<a href="/search/q-bio?searchtype=author&query=Yang%2C+B">Bo Yang</a>, 
<a href="/search/q-bio?searchtype=author&query=Jiang%2C+J">Junqiang Jiang</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+W">Wenbin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Molecular Networks (q-bio.MN)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">The identification of essential proteins in protein-protein interaction
networks (PINs) can help to discover drug targets and prevent disease. In order
to improve the accuracy of the identification of essential proteins,
researchers attempted to obtain a refined PIN by combining multiple biological
information to filter out some unreliable interactions in the PIN.
Unfortunately, such approaches drastically reduce the number of nodes in the
PIN after multiple refinements and result in a sparser PIN. It makes a
considerable portion of essential proteins unidentifiable. In this paper, we
propose a multi-layer refined network (MR-PIN) that addresses this problem.
Firstly, four refined networks are constructed by respectively integrating
different biological information into the static PIN to form a multi-layer
heterogeneous network. Then scores of proteins in each network layer are
calculated by the existing node ranking method, and the importance score of a
protein in the MR-PIN is evaluated in terms of the geometric mean of its scores
in all layers. Finally, all nodes are sorted by their importance scores to
determine their essentiality. To evaluate the effectiveness of the multi-layer
refined network model, we apply 16 node ranking methods on the MR-PIN, and
compare the results with those on the SPIN, DPIN and RDPIN. Then the predictive
performances of these ranking methods are validated in terms of the
identification number of essential protein at top100 - top600, sensitivity,
specificity, positive predictive value, negative predictive value, F-measure,
accuracy, Jackknife, ROCAUC and PRAUC. The experimental results show that the
MR-PIN is superior to the existing refined PINs in the identification accuracy
of essential proteins.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03807" title="Abstract">arXiv:2312.03807</a> (cross-list from math.OC) [<a href="/pdf/2312.03807" title="Download PDF">pdf</a>, <a href="/format/2312.03807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Achieving ${O}(&#x3b5;^{-1.5})$ Complexity in Hessian/Jacobian-free  Stochastic Bilevel Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yang%2C+Y">Yifan Yang</a>, 
<a href="/search/math?searchtype=author&query=Xiao%2C+P">Peiyao Xiao</a>, 
<a href="/search/math?searchtype=author&query=Ji%2C+K">Kaiyi Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we revisit the bilevel optimization problem, in which the
upper-level objective function is generally nonconvex and the lower-level
objective function is strongly convex. Although this type of problem has been
studied extensively, it still remains an open question how to achieve an
${O}(\epsilon^{-1.5})$ sample complexity of ${O}(\epsilon^{-1.5})$ in
Hessian/Jacobian-free stochastic bilevel optimization without any second-order
derivative computation. To fill this gap, we propose a novel
Hessian/Jacobian-free bilevel optimizer named FdeHBO, which features a simple
fully single-loop structure, a projection-aided finite-difference
Hessian/Jacobian-vector approximation, and momentum-based updates.
Theoretically, we show that FdeHBO requires ${O}(\epsilon^{-1.5})$ iterations
(each using ${O}(1)$ samples and only first-order gradient information) to find
an $\epsilon$-accurate stationary point. As far as we know, this is the first
Hessian/Jacobian-free method with an ${O}(\epsilon^{-1.5})$ sample complexity
for nonconvex-strongly-convex stochastic bilevel optimization.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03823" title="Abstract">arXiv:2312.03823</a> (cross-list from physics.data-an) [<a href="/pdf/2312.03823" title="Download PDF">pdf</a>, <a href="/format/2312.03823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High Pileup Particle Tracking with Object Condensation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Lieret%2C+K">Kilian Lieret</a>, 
<a href="/search/physics?searchtype=author&query=DeZoort%2C+G">Gage DeZoort</a>, 
<a href="/search/physics?searchtype=author&query=Chatterjee%2C+D">Devdoot Chatterjee</a>, 
<a href="/search/physics?searchtype=author&query=Park%2C+J">Jian Park</a>, 
<a href="/search/physics?searchtype=author&query=Miao%2C+S">Siqi Miao</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+P">Pan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, 8th International Connecting The Dots Workshop (Toulouse 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Analysis, Statistics and Probability (physics.data-an)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex)

</div>
<p class="mathjax">Recent work has demonstrated that graph neural networks (GNNs) can match the
performance of traditional algorithms for charged particle tracking while
improving scalability to meet the computing challenges posed by the HL-LHC.
Most GNN tracking algorithms are based on edge classification and identify
tracks as connected components from an initial graph containing spurious
connections. In this talk, we consider an alternative based on object
condensation (OC), a multi-objective learning framework designed to cluster
points (hits) belonging to an arbitrary number of objects (tracks) and regress
the properties of each object. Building on our previous results, we present a
streamlined model and show progress toward a one-shot OC tracking algorithm in
a high-pileup environment.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03824" title="Abstract">arXiv:2312.03824</a> (cross-list from astro-ph.IM) [<a href="/pdf/2312.03824" title="Download PDF">pdf</a>, <a href="/ps/2312.03824" title="Download PostScript">ps</a>, <a href="/format/2312.03824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> nbi: the Astronomer&#x27;s Package for Neural Posterior Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Zhang%2C+K">Keming Zhang</a>, 
<a href="/search/astro-ph?searchtype=author&query=Bloom%2C+J">Joshua Bloom</a>, 
<a href="/search/astro-ph?searchtype=author&query=van+der+Walt%2C+S">St&#xe9;fan van der Walt</a>, 
<a href="/search/astro-ph?searchtype=author&query=Hernitschek%2C+N">Nina Hernitschek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023 Workshop on Deep Learning and Inverse Problems. Initially appeared at ICML 2023 Workshop on Machine Learning for Astrophysics. Code at <a href="https://github.com/kmzzhang/nbi">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">Despite the promise of Neural Posterior Estimation (NPE) methods in
astronomy, the adaptation of NPE into the routine inference workflow has been
slow. We identify three critical issues: the need for custom featurizer
networks tailored to the observed data, the inference inexactness, and the
under-specification of physical forward models. To address the first two
issues, we introduce a new framework and open-source software nbi (Neural
Bayesian Inference), which supports both amortized and sequential NPE. First,
nbi provides built-in "featurizer" networks with demonstrated efficacy on
sequential data, such as light curve and spectra, thus obviating the need for
this customization on the user end. Second, we introduce a modified algorithm
SNPE-IS, which facilities asymptotically exact inference by using the surrogate
posterior under NPE only as a proposal distribution for importance sampling.
These features allow nbi to be applied off-the-shelf to astronomical inference
problems involving light curves and spectra. We discuss how nbi may serve as an
effective alternative to existing methods such as Nested Sampling. Our package
is at https://github.com/kmzzhang/nbi.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03843" title="Abstract">arXiv:2312.03843</a> (cross-list from econ.GN) [<a href="/pdf/2312.03843" title="Download PDF">pdf</a>, <a href="/format/2312.03843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exposing Disparities in Flood Adaptation for Equitable Future  Interventions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Pecharroman%2C+L+C">Lidia Cano Pecharroman</a>, 
<a href="/search/econ?searchtype=author&query=Hahn%2C+C">ChangHoon Hahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">As governments race to implement new climate adaptation policies that prepare
for more frequent flooding, they must seek policies that are effective for all
communities and uphold climate justice. This requires evaluating policies not
only on their overall effectiveness but also on whether their benefits are felt
across all communities. We illustrate the importance of considering such
disparities for flood adaptation using the FEMA National Flood Insurance
Program Community Rating System and its dataset of $\sim$2.5 million flood
insurance claims. We use ${\rm C{\scriptsize AUSAL}F{\scriptsize LOW}}$, a
causal inference method based on deep generative models, to estimate the
treatment effect of flood adaptation interventions based on a community's
income, diversity, population, flood risk, educational attainment, and
precipitation. We find that the program saves communities \$5,000--15,000 per
household. However, these savings are not evenly spread across communities. For
example, for low-income communities savings sharply decline as flood-risk
increases in contrast to their high-income counterparts with all else equal.
Even among low-income communities, there is a gap in savings between
predominantly white and non-white communities: savings of predominantly white
communities can be higher by more than \$6000 per household. As communities
worldwide ramp up efforts to reduce losses inflicted by floods, simply
prescribing a series flood adaptation measures is not enough. Programs must
provide communities with the necessary technical and economic support to
compensate for historical patterns of disenfranchisement, racism, and
inequality. Future flood adaptation efforts should go beyond reducing losses
overall and aim to close existing gaps to equitably support communities in the
race for climate adaptation.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03870" title="Abstract">arXiv:2312.03870</a> (cross-list from math.PR) [<a href="/pdf/2312.03870" title="Download PDF">pdf</a>, <a href="/ps/2312.03870" title="Download PostScript">ps</a>, <a href="/format/2312.03870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A M|M|m|m Queue System Transient Behavior Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ferreira%2C+M+A+M">Manuel Alberto M. Ferreira</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages and no figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">It is a very hard task to compute an exact solution for the differential
equations, with differences, system that allows the determination of the
M|M|m|m system transient probabilities. The respective complexity grows with m.
The computations are extremely fastidious and the length and the fact that the
expressions obtained are often approximate, and not exact, will not allow the
transient probabilities behavior as time functions characterization. To
overcome these problems, in this work it is analyzed how that system can supply
approximate values to the M|M|m|m queue system. It is also presented an
asymptotic method to solve the system that becomes possible in many cases to
obtain simple approximated expressions for those probabilities using the
M|M|Inf transient probabilities, very well-known and very much easier to study.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03871" title="Abstract">arXiv:2312.03871</a> (cross-list from stat.ML) [<a href="/pdf/2312.03871" title="Download PDF">pdf</a>, <a href="/format/2312.03871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hidden yet quantifiable: A lower bound for confounding strength using  randomized trials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=De+Bartolomeis%2C+P">Piersilvio De Bartolomeis</a>, 
<a href="/search/stat?searchtype=author&query=Abad%2C+J">Javier Abad</a>, 
<a href="/search/stat?searchtype=author&query=Donhauser%2C+K">Konstantin Donhauser</a>, 
<a href="/search/stat?searchtype=author&query=Yang%2C+F">Fanny Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the era of fast-paced precision medicine, observational studies play a
major role in properly evaluating new treatments in clinical practice. Yet,
unobserved confounding can significantly compromise causal conclusions drawn
from non-randomized data. We propose a novel strategy that leverages randomized
trials to quantify unobserved confounding. First, we design a statistical test
to detect unobserved confounding with strength above a given threshold. Then,
we use the test to estimate an asymptotically valid lower bound on the
unobserved confounding strength. We evaluate the power and validity of our
statistical test on several synthetic and semi-synthetic datasets. Further, we
show how our lower bound can correctly identify the absence and presence of
unobserved confounding in a real-world setting.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03873" title="Abstract">arXiv:2312.03873</a> (cross-list from physics.chem-ph) [<a href="/pdf/2312.03873" title="Download PDF">pdf</a>, <a href="/format/2312.03873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing $CO_{2}$ Capture in Pressure Swing Adsorption Units: A Deep  Neural Network Approach with Optimality Evaluation and Operating Maps for  Decision-Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Rebello%2C+C+M">Carine Menezes Rebello</a>, 
<a href="/search/physics?searchtype=author&query=Nogueira%2C+I+B+R">Idelfonso B. R. Nogueira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This study presents a methodology for surrogate optimization of cyclic
adsorption processes, focusing on enhancing Pressure Swing Adsorption units for
carbon dioxide ($CO_{2}$) capture. We developed and implemented a
multiple-input, single-output (MISO) framework comprising two deep neural
network (DNN) models, predicting key process performance indicators. These
models were then integrated into an optimization framework, leveraging particle
swarm optimization (PSO) and statistical analysis to generate a comprehensive
Pareto front representation. This approach delineated feasible operational
regions (FORs) and highlighted the spectrum of optimal decision-making
scenarios. A key aspect of our methodology was the evaluation of optimization
effectiveness. This was accomplished by testing decision variables derived from
the Pareto front against a phenomenological model, affirming the surrogate
models reliability. Subsequently, the study delved into analyzing the feasible
operational domains of these decision variables. A detailed correlation map was
constructed to elucidate the interplay between these variables, thereby
uncovering the most impactful factors influencing process behavior. The study
offers a practical, insightful operational map that aids operators in
pinpointing the optimal process location and prioritizing specific operational
goals.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03876" title="Abstract">arXiv:2312.03876</a> (cross-list from physics.ao-ph) [<a href="/pdf/2312.03876" title="Download PDF">pdf</a>, <a href="/format/2312.03876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling transformer neural networks for skillful and reliable  medium-range weather forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Nguyen%2C+T">Tung Nguyen</a>, 
<a href="/search/physics?searchtype=author&query=Shah%2C+R">Rohan Shah</a>, 
<a href="/search/physics?searchtype=author&query=Bansal%2C+H">Hritik Bansal</a>, 
<a href="/search/physics?searchtype=author&query=Arcomano%2C+T">Troy Arcomano</a>, 
<a href="/search/physics?searchtype=author&query=Madireddy%2C+S">Sandeep Madireddy</a>, 
<a href="/search/physics?searchtype=author&query=Maulik%2C+R">Romit Maulik</a>, 
<a href="/search/physics?searchtype=author&query=Kotamarthi%2C+V">Veerabhadra Kotamarthi</a>, 
<a href="/search/physics?searchtype=author&query=Foster%2C+I">Ian Foster</a>, 
<a href="/search/physics?searchtype=author&query=Grover%2C+A">Aditya Grover</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Weather forecasting is a fundamental problem for anticipating and mitigating
the impacts of climate change. Recently, data-driven approaches for weather
forecasting based on deep learning have shown great promise, achieving
accuracies that are competitive with operational systems. However, those
methods often employ complex, customized architectures without sufficient
ablation analysis, making it difficult to understand what truly contributes to
their success. Here we introduce Stormer, a simple transformer model that
achieves state-of-the-art performance on weather forecasting with minimal
changes to the standard transformer backbone. We identify the key components of
Stormer through careful empirical analyses, including weather-specific
embedding, randomized dynamics forecast, and pressure-weighted loss. At the
core of Stormer is a randomized forecasting objective that trains the model to
forecast the weather dynamics over varying time intervals. During inference,
this allows us to produce multiple forecasts for a target lead time and combine
them to obtain better forecast accuracy. On WeatherBench 2, Stormer performs
competitively at short to medium-range forecasts and outperforms current
methods beyond 7 days, while requiring orders-of-magnitude less training data
and compute. Additionally, we demonstrate Stormer's favorable scaling
properties, showing consistent improvements in forecast accuracy with increases
in model size and training tokens. Code and checkpoints will be made publicly
available.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03895" title="Abstract">arXiv:2312.03895</a> (cross-list from stat.ML) [<a href="/pdf/2312.03895" title="Download PDF">pdf</a>, <a href="/format/2312.03895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HLoOP -- Hyperbolic 2-space Local Outlier Probabilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Allietta%2C+C">Cl&#xe9;mence Allietta</a>, 
<a href="/search/stat?searchtype=author&query=Condomines%2C+J">Jean-Philippe Condomines</a>, 
<a href="/search/stat?searchtype=author&query=Tourneret%2C+J">Jean-Yves Tourneret</a>, 
<a href="/search/stat?searchtype=author&query=Lochin%2C+E">Emmanuel Lochin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Hyperbolic geometry has recently garnered considerable attention in machine
learning due to its capacity to embed hierarchical graph structures with low
distortions for further downstream processing. This paper introduces a simple
framework to detect local outliers for datasets grounded in hyperbolic 2-space
referred to as HLoOP (Hyperbolic Local Outlier Probability). Within a Euclidean
space, well-known techniques for local outlier detection are based on the Local
Outlier Factor (LOF) and its variant, the LoOP (Local Outlier Probability),
which incorporates probabilistic concepts to model the outlier level of a data
vector. The developed HLoOP combines the idea of finding nearest neighbors,
density-based outlier scoring with a probabilistic, statistically oriented
approach. Therefore, the method consists in computing the Riemmanian distance
of a data point to its nearest neighbors following a Gaussian probability
density function expressed in a hyperbolic space. This is achieved by defining
a Gaussian cumulative distribution in this space. The HLoOP algorithm is tested
on the WordNet dataset yielding promising results. Code and data will be made
available on request for reproductibility.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03916" title="Abstract">arXiv:2312.03916</a> (cross-list from quant-ph) [<a href="/pdf/2312.03916" title="Download PDF">pdf</a>, <a href="/format/2312.03916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum algorithm for linear non-unitary dynamics with near-optimal  dependence on all parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=An%2C+D">Dong An</a>, 
<a href="/search/quant-ph?searchtype=author&query=Childs%2C+A+M">Andrew M. Childs</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lin%2C+L">Lin Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We introduce a family of identities that express general linear non-unitary
evolution operators as a linear combination of unitary evolution operators,
each solving a Hamiltonian simulation problem. This formulation can
exponentially enhance the accuracy of the recently introduced linear
combination of Hamiltonian simulation (LCHS) method [An, Liu, and Lin, Physical
Review Letters, 2023]. For the first time, this approach enables quantum
algorithms to solve linear differential equations with both optimal state
preparation cost and near-optimal scaling in matrix queries on all parameters.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03919" title="Abstract">arXiv:2312.03919</a> (cross-list from math.LO) [<a href="/pdf/2312.03919" title="Download PDF">pdf</a>, <a href="/ps/2312.03919" title="Download PostScript">ps</a>, <a href="/format/2312.03919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Indivisibility and uniform computational strength
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gill%2C+K">Kenneth Gill</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 4 figures. This work extends the results of Sections 1.2 and 1.3 of the author's Ph.D. thesis at Penn State University
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO); Combinatorics (math.CO)

</div>
<p class="mathjax">A countable structure is indivisible if for every coloring with finite range
there is a monochromatic isomorphic subcopy of the structure. Each indivisible
structure $\mathcal{S}$ naturally corresponds to an indivisibility problem
$\mathsf{Ind}\ \mathcal{S}$, which outputs such a subcopy given a presentation
and coloring. We investigate the Weihrauch complexity of the indivisibility
problems for two structures: the rational numbers $\mathbb{Q}$ as a linear
order, and the equivalence relation $\mathscr{E}$ with countably many
equivalence classes each having countably many members. We separate the
Weihrauch degrees of both $\mathsf{Ind}\ \mathbb{Q}$ and $\mathsf{Ind}\
\mathscr{E}$ from several benchmark problems, showing in particular that
$\mathsf{C}_\mathbb{N} \vert_\mathrm{W} \mathsf{Ind}\ \mathbb{Q}$ and hence
$\mathsf{Ind}\ \mathbb{Q}$ is strictly weaker than the problem of finding an
interval in which some color is dense for a given coloring of $\mathbb{Q}$; and
that the Weihrauch degree of $\mathsf{Ind}\ \mathscr{E}_k$ is strictly between
those of $\mathsf{SRT}^2_k$ and $\mathsf{RT}^2_k$, where $\mathsf{Ind}\
\mathcal{S}_k$ is the restriction of $\mathsf{Ind}\ \mathcal{S}$ to
$k$-colorings.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03957" title="Abstract">arXiv:2312.03957</a> (cross-list from q-bio.TO) [<a href="/pdf/2312.03957" title="Download PDF">pdf</a>, <a href="/format/2312.03957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PerSival: Neural-network-based visualisation for pervasive  continuum-mechanical simulations in musculoskeletal biomechanics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Rosin%2C+D">David Rosin</a>, 
<a href="/search/q-bio?searchtype=author&query=K%C3%A4ssinger%2C+J">Johannes K&#xe4;ssinger</a>, 
<a href="/search/q-bio?searchtype=author&query=Yu%2C+X">Xingyao Yu</a>, 
<a href="/search/q-bio?searchtype=author&query=Avci%2C+O">Okan Avci</a>, 
<a href="/search/q-bio?searchtype=author&query=Bleiler%2C+C">Christian Bleiler</a>, 
<a href="/search/q-bio?searchtype=author&query=R%C3%B6hrle%2C+O">Oliver R&#xf6;hrle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures, 5 tables, to be submitted to Medical Image Analysis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Tissues and Organs (q-bio.TO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper presents a novel neural network architecture for the purpose of
pervasive visualisation of a 3D human upper limb musculoskeletal system model.
Bringing simulation capabilities to resource-poor systems like mobile devices
is of growing interest across many research fields, to widen applicability of
methods and results. Until recently, this goal was thought to be out of reach
for realistic continuum-mechanical simulations of musculoskeletal systems, due
to prohibitive computational cost. Within this work we use a sparse grid
surrogate to capture the surface deformation of the m.~biceps brachii in order
to train a deep learning model, used for real-time visualisation of the same
muscle. Both these surrogate models take 5 muscle activation levels as input
and output Cartesian coordinate vectors for each mesh node on the muscle's
surface. Thus, the neural network architecture features a significantly lower
input than output dimension. 5 muscle activation levels were sufficient to
achieve an average error of 0.97 +/- 0.16 mm, or 0.57 +/- 0.10 % for the 2809
mesh node positions of the biceps. The model achieved evaluation times of 9.88
ms per predicted deformation state on CPU only and 3.48 ms with GPU-support,
leading to theoretical frame rates of 101 fps and 287 fps respectively. Deep
learning surrogates thus provide a way to make continuum-mechanical simulations
accessible for visual real-time applications.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03975" title="Abstract">arXiv:2312.03975</a> (cross-list from math.CO) [<a href="/pdf/2312.03975" title="Download PDF">pdf</a>, <a href="/ps/2312.03975" title="Download PostScript">ps</a>, <a href="/format/2312.03975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The classification of Boolean degree $1$ functions in high-dimensional  finite vector spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ihringer%2C+F">Ferdinand Ihringer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We classify the {\it Boolean degree $1$ functions} of $k$-spaces in a vector
space of dimension $n$ (also known as {\it Cameron-Liebler classes}) over the
field with $q$ elements for $n \geq n_0(k, q)$, a problem going back to a work
by Cameron and Liebler from 1982. This also implies that two-intersecting sets
with respect to $k$-spaces do not exist for $n \geq n_0(k, q)$. Our main
ingredient is the Ramsey theory for geometric lattices.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04019" title="Abstract">arXiv:2312.04019</a> (cross-list from q-bio.BM) [<a href="/pdf/2312.04019" title="Download PDF">pdf</a>, <a href="/format/2312.04019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficiently Predicting Protein Stability Changes Upon Single-point  Mutation with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+Y">Yijie Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Gao%2C+Z">Zhangyang Gao</a>, 
<a href="/search/q-bio?searchtype=author&query=Tan%2C+C">Cheng Tan</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+S+Z">Stan Z.Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Predicting protein stability changes induced by single-point mutations has
been a persistent challenge over the years, attracting immense interest from
numerous researchers. The ability to precisely predict protein thermostability
is pivotal for various subfields and applications in biochemistry, including
drug development, protein evolution analysis, and enzyme synthesis. Despite the
proposition of multiple methodologies aimed at addressing this issue, few
approaches have successfully achieved optimal performance coupled with high
computational efficiency. Two principal hurdles contribute to the existing
challenges in this domain. The first is the complexity of extracting and
aggregating sufficiently representative features from proteins. The second
refers to the limited availability of experimental data for protein mutation
analysis, further complicating the comprehensive evaluation of model
performance on unseen data samples. With the advent of Large Language
Models(LLM), such as the ESM models in protein research, profound
interpretation of protein features is now accessibly aided by enormous training
data. Therefore, LLMs are indeed to facilitate a wide range of protein
research. In our study, we introduce an ESM-assisted efficient approach that
integrates protein sequence and structural features to predict the
thermostability changes in protein upon single-point mutations. Furthermore, we
have curated a dataset meticulously designed to preclude data leakage,
corresponding to two extensively employed test datasets, to facilitate a more
equitable model comparison.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04022" title="Abstract">arXiv:2312.04022</a> (cross-list from eess.IV) [<a href="/pdf/2312.04022" title="Download PDF">pdf</a>, <a href="/format/2312.04022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of Coding Gain Due to In-Loop Reshaping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wong%2C+C">Chau-Wai Wong</a>, 
<a href="/search/eess?searchtype=author&query=Fu%2C+C">Chang-Hong Fu</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+M">Mengting Xu</a>, 
<a href="/search/eess?searchtype=author&query=Su%2C+G">Guan-Ming Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transactions on Image Processing, under revision
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Reshaping, a point operation that alters the characteristics of signals, has
been shown capable of improving the compression ratio in video coding
practices. Out-of-loop reshaping that directly modifies the input video signal
was first adopted as the supplemental enhancement information~(SEI) for the
HEVC/H.265 without the need of altering the core design of the video codec.
VVC/H.266 further improves the coding efficiency by adopting in-loop reshaping
that modifies the residual signal being processed in the hybrid coding loop. In
this paper, we theoretically analyze the rate-distortion performance of the
in-loop reshaping and use experiments to verify the theoretical result. We
prove that the in-loop reshaping can improve coding efficiency when the entropy
coder adopted in the coding pipeline is suboptimal, which is in line with the
practical scenarios that video codecs operate in. We derive the PSNR gain in a
closed form and show that the theoretically predicted gain is consistent with
that measured from experiments using standard testing video sequences.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04064" title="Abstract">arXiv:2312.04064</a> (cross-list from q-bio.QM) [<a href="/pdf/2312.04064" title="Download PDF">pdf</a>, <a href="/format/2312.04064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiscoBAX: Discovery of Optimal Intervention Sets in Genomic Experiment  Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Lyle%2C+C">Clare Lyle</a>, 
<a href="/search/q-bio?searchtype=author&query=Mehrjou%2C+A">Arash Mehrjou</a>, 
<a href="/search/q-bio?searchtype=author&query=Notin%2C+P">Pascal Notin</a>, 
<a href="/search/q-bio?searchtype=author&query=Jesson%2C+A">Andrew Jesson</a>, 
<a href="/search/q-bio?searchtype=author&query=Bauer%2C+S">Stefan Bauer</a>, 
<a href="/search/q-bio?searchtype=author&query=Gal%2C+Y">Yarin Gal</a>, 
<a href="/search/q-bio?searchtype=author&query=Schwab%2C+P">Patrick Schwab</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Conference on Machine Learning, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">The discovery of therapeutics to treat genetically-driven pathologies relies
on identifying genes involved in the underlying disease mechanisms. Existing
approaches search over the billions of potential interventions to maximize the
expected influence on the target phenotype. However, to reduce the risk of
failure in future stages of trials, practical experiment design aims to find a
set of interventions that maximally change a target phenotype via diverse
mechanisms. We propose DiscoBAX, a sample-efficient method for maximizing the
rate of significant discoveries per experiment while simultaneously probing for
a wide range of diverse mechanisms during a genomic experiment campaign. We
provide theoretical guarantees of approximate optimality under standard
assumptions, and conduct a comprehensive experimental evaluation covering both
synthetic as well as real-world experimental design tasks. DiscoBAX outperforms
existing state-of-the-art methods for experimental design, selecting effective
and diverse perturbations in biological systems.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04091" title="Abstract">arXiv:2312.04091</a> (cross-list from math.LO) [<a href="/pdf/2312.04091" title="Download PDF">pdf</a>, <a href="/ps/2312.04091" title="Download PostScript">ps</a>, <a href="/format/2312.04091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyperarithmetical Complexity of Infinitary Action Logic with  Multiplexing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pshenitsyn%2C+T">Tikhon Pshenitsyn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">In 2023, Kuznetsov and Speranski introduced infinitary action logic with
multiplexing $!^m\nabla \mathrm{ACT}_\omega$ and proved that the derivability
problem for it lies between the $\omega$ and $\omega^\omega$ levels of the
hyperarithmetical hierarchy. We prove that this problem is
$\Delta^0_{\omega^\omega}$-complete under Turing reductions. Namely, we prove
that it is recursively isomorphic to the satisfaction predicate for computable
infinitary formulas of rank less than $\omega^\omega$ in the language of
arithmetic. We also prove this result for the fragment of $!^m\nabla
\mathrm{ACT}_\omega$ where Kleene star is not allowed to be in the scope of the
subexponential. Finally, we present a family of logics, which are fragments of
$!^m\nabla \mathrm{ACT}_\omega$, such that the complexity of the $k$-th logic
is between $\Delta^0_{\omega^k}$ and $\Delta^0_{\omega^{k+1}}$.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04110" title="Abstract">arXiv:2312.04110</a> (cross-list from stat.ML) [<a href="/pdf/2312.04110" title="Download PDF">pdf</a>, <a href="/format/2312.04110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Small Area Estimation of Case Growths for Timely COVID-19 Outbreak  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=She%2C+Z">Zhaowei She</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+Z">Zilong Wang</a>, 
<a href="/search/stat?searchtype=author&query=Chhatwal%2C+J">Jagpreet Chhatwal</a>, 
<a href="/search/stat?searchtype=author&query=Ayer%2C+T">Turgay Ayer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Equal contributions by co-first authors Zhaowei She, Zilong Wang (in alphabetical order)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">The COVID-19 pandemic has exerted a profound impact on the global economy and
continues to exact a significant toll on human lives. The COVID-19 case growth
rate stands as a key epidemiological parameter to estimate and monitor for
effective detection and containment of the resurgence of outbreaks. A
fundamental challenge in growth rate estimation and hence outbreak detection is
balancing the accuracy-speed tradeoff, where accuracy typically degrades with
shorter fitting windows. In this paper, we develop a machine learning (ML)
algorithm, which we call Transfer Learning Generalized Random Forest (TLGRF),
that balances this accuracy-speed tradeoff. Specifically, we estimate the
instantaneous COVID-19 exponential growth rate for each U.S. county by using
TLGRF that chooses an adaptive fitting window size based on relevant day-level
and county-level features affecting the disease spread. Through transfer
learning, TLGRF can accurately estimate case growth rates for counties with
small sample sizes. Out-of-sample prediction analysis shows that TLGRF
outperforms established growth rate estimation methods. Furthermore, we
conducted a case study based on outbreak case data from the state of Colorado
and showed that the timely detection of outbreaks could have been improved by
up to 224% using TLGRF when compared to the decisions made by Colorado's
Department of Health and Environment (CDPHE). To facilitate implementation, we
have developed a publicly available outbreak detection tool for timely
detection of COVID-19 outbreaks in each U.S. county, which received substantial
attention from policymakers.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04131" title="Abstract">arXiv:2312.04131</a> (cross-list from eess.AS) [<a href="/pdf/2312.04131" title="Download PDF">pdf</a>, <a href="/format/2312.04131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Training or Not: An Exploration of Pre-trained Speech Models in  Audio-Visual Speaker Diarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhao%2C+H">Huan Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yue Li</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yannan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Hongji Wang</a>, 
<a href="/search/eess?searchtype=author&query=Rao%2C+W">Wei Rao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Q">Qing Wang</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+L">Lei Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">The scarcity of labeled audio-visual datasets is a constraint for training
superior audio-visual speaker diarization systems. To improve the performance
of audio-visual speaker diarization, we leverage pre-trained supervised and
self-supervised speech models for audio-visual speaker diarization.
Specifically, we adopt supervised~(ResNet and ECAPA-TDNN) and self-supervised
pre-trained models~(WavLM and HuBERT) as the speaker and audio embedding
extractors in an end-to-end audio-visual speaker diarization~(AVSD) system.
Then we explore the effectiveness of different frameworks, including
Transformer, Conformer, and cross-attention mechanism, in the audio-visual
decoder. To mitigate the degradation of performance caused by separate
training, we jointly train the audio encoder, speaker encoder, and audio-visual
decoder in the AVSD system. Experiments on the MISP dataset demonstrate that
the proposed method achieves superior performance and obtained third place in
MISP Challenge 2022.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04155" title="Abstract">arXiv:2312.04155</a> (cross-list from eess.SP) [<a href="/pdf/2312.04155" title="Download PDF">pdf</a>, <a href="/format/2312.04155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource Allocation for Semantic Communication under Physical-layer  Security
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+X">Xinyu Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper appears in IEEE Global Communications Conference (GLOBECOM) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Semantic communication is deemed as a revolution of Shannon's paradigm in the
six-generation (6G) wireless networks. It aims at transmitting the extracted
information rather than the original data, which receivers will try to recover.
Intuitively, the larger extracted information, the longer latency of semantic
communication will be. Besides, larger extracted information will result in
more accurate reconstructed information, thereby causing a higher utility of
the semantic communication system. Shorter latency and higher utility are
desirable objectives for the system, so there will be a trade-off between
utility and latency. This paper proposes a joint optimization algorithm for
total latency and utility. Moreover, security is essential for the semantic
communication system. We incorporate the secrecy rate, a physical-layer
security method, into the optimization problem. The secrecy rate is the
communication rate at which no information is disclosed to an eavesdropper.
Experimental results demonstrate that the proposed algorithm obtains the best
joint optimization performance compared to the baselines.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04163" title="Abstract">arXiv:2312.04163</a> (cross-list from stat.ML) [<a href="/pdf/2312.04163" title="Download PDF">pdf</a>, <a href="/format/2312.04163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-scale Residual Transformer for VLF Lightning Transients  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sun%2C+J">Jinghao Sun</a>, 
<a href="/search/stat?searchtype=author&query=Ji%2C+T">Tingting Ji</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+G">Guoyu Wang</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+R">Rui Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The utilization of Very Low Frequency (VLF) electromagnetic signals in
navigation systems is widespread. However, the non-stationary behavior of
lightning signals can affect VLF electromagnetic signal transmission.
Accurately classifying lightning signals is important for reducing interference
and noise in VLF, thereby improving the reliability and overall performance of
navigation systems. In recent years, the evolution of deep learning,
specifically Convolutional Neural Network (CNNs), has sparked a transformation
in lightning classification, surpassing traditional statistical methodologies.
Existing CNN models have limitations as they overlook the diverse attributes of
lightning signals across different scales and neglect the significance of
temporal sequencing in sequential signals. This study introduces an innovative
multi-scale residual transform (MRTransformer) that not only has the ability to
discern intricate fine-grained patterns while also weighing the significance of
different aspects within the input lightning signal sequence. This model
performs the attributes of the lightning signal across different scales and the
level of accuracy reached 90% in the classification. In future work, this model
has the potential applied to a comprehensive understanding of the localization
and waveform characteristics of lightning signals.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04174" title="Abstract">arXiv:2312.04174</a> (cross-list from stat.ML) [<a href="/pdf/2312.04174" title="Download PDF">pdf</a>, <a href="/format/2312.04174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coherent energy and force uncertainty in deep learning force fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=J%C3%B8rgensen%2C+P+B">Peter Bj&#xf8;rn J&#xf8;rgensen</a>, 
<a href="/search/stat?searchtype=author&query=Busk%2C+J">Jonas Busk</a>, 
<a href="/search/stat?searchtype=author&query=Winther%2C+O">Ole Winther</a>, 
<a href="/search/stat?searchtype=author&query=Schmidt%2C+M+N">Mikkel N. Schmidt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at Advancing Molecular Machine Learning - Overcoming Limitations [ML4Molecules], ELLIS workshop, VIRTUAL, December 8, 2023, unofficial NeurIPS 2023 side-event
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">In machine learning energy potentials for atomic systems, forces are commonly
obtained as the negative derivative of the energy function with respect to
atomic positions. To quantify aleatoric uncertainty in the predicted energies,
a widely used modeling approach involves predicting both a mean and variance
for each energy value. However, this model is not differentiable under the
usual white noise assumption, so energy uncertainty does not naturally
translate to force uncertainty. In this work we propose a machine learning
potential energy model in which energy and force aleatoric uncertainty are
linked through a spatially correlated noise process. We demonstrate our
approach on an equivariant messages passing neural network potential trained on
energies and forces on two out-of-equilibrium molecular datasets. Furthermore,
we also show how to obtain epistemic uncertainties in this setting based on a
Bayesian interpretation of deep ensemble models.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04191" title="Abstract">arXiv:2312.04191</a> (cross-list from math.GR) [<a href="/pdf/2312.04191" title="Download PDF">pdf</a>, <a href="/ps/2312.04191" title="Download PostScript">ps</a>, <a href="/format/2312.04191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subsets of groups with context-free preimages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Levine%2C+A">Alex Levine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Group Theory (math.GR)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">We study subsets $E$ of finitely generated groups where the set of all words
over a given finite generating set that lie in $E$ forms a context-free
language. We call these sets recognisably context-free. They are invariant of
the choice of generating set and a theorem of Muller and Schupp fully
classifies when the set $\{1\}$ can be recognisably context-free. We extend
Muller and Schupp's result to show that a group $G$ admits a finite
recognisably context-free subset if and only if $G$ is virtually free. We show
that every conjugacy class of a group $G$ is recognisably context-free if and
only if $G$ is virtually free. We conclude by showing that a coset is
recognisably context-free if and only if the Schreier coset graph of the
corresponding subgroup is quasi-isometric to a tree.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04215" title="Abstract">arXiv:2312.04215</a> (cross-list from eess.IV) [<a href="/pdf/2312.04215" title="Download PDF">pdf</a>, <a href="/format/2312.04215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guided Reconstruction with Conditioned Diffusion Models for Unsupervised  Anomaly Detection in Brain MRIs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Behrendt%2C+F">Finn Behrendt</a>, 
<a href="/search/eess?searchtype=author&query=Bhattacharya%2C+D">Debayan Bhattacharya</a>, 
<a href="/search/eess?searchtype=author&query=Mieling%2C+R">Robin Mieling</a>, 
<a href="/search/eess?searchtype=author&query=Maack%2C+L">Lennart Maack</a>, 
<a href="/search/eess?searchtype=author&query=Kr%C3%BCger%2C+J">Julia Kr&#xfc;ger</a>, 
<a href="/search/eess?searchtype=author&query=Opfer%2C+R">Roland Opfer</a>, 
<a href="/search/eess?searchtype=author&query=Schlaefer%2C+A">Alexander Schlaefer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Unsupervised anomaly detection in Brain MRIs aims to identify abnormalities
as outliers from a healthy training distribution. Reconstruction-based
approaches that use generative models to learn to reconstruct healthy brain
anatomy are commonly used for this task. Diffusion models are an emerging class
of deep generative models that show great potential regarding reconstruction
fidelity. However, they face challenges in preserving intensity characteristics
in the reconstructed images, limiting their performance in anomaly detection.
To address this challenge, we propose to condition the denoising mechanism of
diffusion models with additional information about the image to reconstruct
coming from a latent representation of the noise-free input image. This
conditioning enables high-fidelity reconstruction of healthy brain structures
while aligning local intensity characteristics of input-reconstruction pairs.
We evaluate our method's reconstruction quality, domain adaptation features and
finally segmentation performance on publicly available data sets with various
pathologies. Using our proposed conditioning mechanism we can reduce the
false-positive predictions and enable a more precise delineation of anomalies
which significantly enhances the anomaly detection performance compared to
established state-of-the-art approaches to unsupervised anomaly detection in
brain MRI. Furthermore, our approach shows promise in domain adaptation across
different MRI acquisitions and simulated contrasts, a crucial property of
general anomaly detection methods.
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04229" title="Abstract">arXiv:2312.04229</a> (cross-list from eess.SP) [<a href="/pdf/2312.04229" title="Download PDF">pdf</a>, <a href="/ps/2312.04229" title="Download PostScript">ps</a>, <a href="/format/2312.04229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerated Real-Life (ARL) Testing and Characterization of Automotive  LiDAR Sensors to facilitate the Development and Validation of Enhanced Sensor  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kettelgerdes%2C+M">Marcel Kettelgerdes</a>, 
<a href="/search/eess?searchtype=author&query=Hillmann%2C+T">Tjorven Hillmann</a>, 
<a href="/search/eess?searchtype=author&query=Hirmer%2C+T">Thomas Hirmer</a>, 
<a href="/search/eess?searchtype=author&query=Erdogan%2C+H">H&#xfc;seyin Erdogan</a>, 
<a href="/search/eess?searchtype=author&query=Wunderle%2C+B">Bernhard Wunderle</a>, 
<a href="/search/eess?searchtype=author&query=Elger%2C+G">Gordon Elger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9th Symposium Driving Simulation 2023, Brunswick, Germany
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In the realm of automated driving simulation and sensor modeling, the need
for highly accurate sensor models is paramount for ensuring the reliability and
safety of advanced driving assistance systems (ADAS). Hence, numerous works
focus on the development of high-fidelity models of ADAS sensors, such as
camera, Radar as well as modern LiDAR systems to simulate the sensor behavior
in different driving scenarios, even under varying environmental conditions,
considering for example adverse weather effects. However, aging effects of
sensors, leading to suboptimal system performance, are mostly overlooked by
current simulation techniques. This paper introduces a cutting-edge
Hardware-in-the-Loop (HiL) test bench designed for the automated, accelerated
aging and characterization of Automotive LiDAR sensors. The primary objective
of this research is to address the aging effects of LiDAR sensors over the
product life cycle, specifically focusing on aspects such as laser beam profile
deterioration, output power reduction and intrinsic parameter drift, which are
mostly neglected in current sensor models. By that, this proceeding research is
intended to path the way, not only towards identifying and modeling respective
degradation effects, but also to suggest quantitative model validation metrics.
</p>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04281" title="Abstract">arXiv:2312.04281</a> (cross-list from stat.ML) [<a href="/pdf/2312.04281" title="Download PDF">pdf</a>, <a href="/format/2312.04281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Factor-Assisted Federated Learning for Personalized Optimization with  Heterogeneous Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wang%2C+F">Feifei Wang</a>, 
<a href="/search/stat?searchtype=author&query=Tang%2C+H">Huiyun Tang</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+Y">Yang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated learning is an emerging distributed machine learning framework
aiming at protecting data privacy. Data heterogeneity is one of the core
challenges in federated learning, which could severely degrade the convergence
rate and prediction performance of deep neural networks. To address this issue,
we develop a novel personalized federated learning framework for heterogeneous
data, which we refer to as FedSplit. This modeling framework is motivated by
the finding that, data in different clients contain both common knowledge and
personalized knowledge. Then the hidden elements in each neural layer can be
split into the shared and personalized groups. With this decomposition, a novel
objective function is established and optimized. We demonstrate FedSplit
enjoyers a faster convergence speed than the standard federated learning method
both theoretically and empirically. The generalization bound of the FedSplit
method is also studied. To practically implement the proposed method on real
datasets, factor analysis is introduced to facilitate the decoupling of hidden
elements. This leads to a practically implemented model for FedSplit and we
further refer to as FedFac. We demonstrated by simulation studies that, using
factor analysis can well recover the underlying shared/personalized
decomposition. The superior prediction performance of FedFac is further
verified empirically by comparison with various state-of-the-art federated
learning methods on several real datasets.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04291" title="Abstract">arXiv:2312.04291</a> (cross-list from physics.ao-ph) [<a href="/pdf/2312.04291" title="Download PDF">pdf</a>, <a href="/format/2312.04291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulating the Air Quality Impact of Prescribed Fires Using a Graph  Neural Network-Based PM$_{2.5}$ Emissions Forecasting System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Liao%2C+K">Kyleen Liao</a>, 
<a href="/search/physics?searchtype=author&query=Buch%2C+J">Jatan Buch</a>, 
<a href="/search/physics?searchtype=author&query=Lamb%2C+K">Kara Lamb</a>, 
<a href="/search/physics?searchtype=author&query=Gentine%2C+P">Pierre Gentine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 + 3 pages; accepted to the Tackling Climate Change with Machine Learning Workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The increasing size and severity of wildfires across western North America
have generated dangerous levels of PM$_{2.5}$ pollution in recent years. In a
warming climate, expanding the use of prescribed fires is widely considered to
be the most robust fire mitigation strategy. However, reliably forecasting the
potential air quality impact from these prescribed fires, a critical ingredient
in determining the fires' location and time, at hourly to daily time scales
remains a challenging problem. This paper proposes a novel integration of
prescribed fire simulation with a spatio-temporal graph neural network-based
PM$_{2.5}$ forecasting model. The experiments in this work focus on determining
the optimal time for implementing prescribed fires in California as well as
quantifying the potential air quality trade-offs involved in conducting more
prescribed fires outside the fire season.
</p>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04312" title="Abstract">arXiv:2312.04312</a> (cross-list from math.OC) [<a href="/pdf/2312.04312" title="Download PDF">pdf</a>, <a href="/format/2312.04312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic-Constrained Stochastic Optimization with Markovian Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kim%2C+Y">Yeongjong Kim</a>, 
<a href="/search/math?searchtype=author&query=Lee%2C+D">Dabeen Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper considers stochastic-constrained stochastic optimization where the
stochastic constraint is to satisfy that the expectation of a random function
is below a certain threshold. In particular, we study the setting where data
samples are drawn from a Markov chain and thus are not independent and
identically distributed. We generalize the drift-plus-penalty framework, a
primal-dual stochastic gradient method developed for the i.i.d. case, to the
Markov chain sampling setting. We propose two variants of drift-plus-penalty;
one is for the case when the mixing time of the underlying Markov chain is
known while the other is for the case of unknown mixing time. In fact, our
algorithms apply to a more general setting of constrained online convex
optimization where the sequence of constraint functions follows a Markov chain.
Both algorithms are adaptive in that the first works without knowledge of the
time horizon while the second uses AdaGrad-style algorithm parameters, which is
of independent interest. We demonstrate the effectiveness of our proposed
methods through numerical experiments on classification with fairness
constraints.
</p>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04323" title="Abstract">arXiv:2312.04323</a> (cross-list from q-bio.BM) [<a href="/pdf/2312.04323" title="Download PDF">pdf</a>, <a href="/format/2312.04323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equivariant Scalar Fields for Molecular Docking with Fast Fourier  Transforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Jing%2C+B">Bowen Jing</a>, 
<a href="/search/q-bio?searchtype=author&query=Jaakkola%2C+T">Tommi Jaakkola</a>, 
<a href="/search/q-bio?searchtype=author&query=Berger%2C+B">Bonnie Berger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Molecular docking is critical to structure-based virtual screening, yet the
throughput of such workflows is limited by the expensive optimization of
scoring functions involved in most docking algorithms. We explore how machine
learning can accelerate this process by learning a scoring function with a
functional form that allows for more rapid optimization. Specifically, we
define the scoring function to be the cross-correlation of multi-channel ligand
and protein scalar fields parameterized by equivariant graph neural networks,
enabling rapid optimization over rigid-body degrees of freedom with fast
Fourier transforms. The runtime of our approach can be amortized at several
levels of abstraction, and is particularly favorable for virtual screening
settings with a common binding pocket. We benchmark our scoring functions on
two simplified docking-related tasks: decoy pose scoring and rigid conformer
docking. Our method attains similar but faster performance on crystal
structures compared to the widely-used Vina and Gnina scoring functions, and is
more robust on computationally predicted structures. Code is available at
https://github.com/bjing2016/scalar-fields.
</p>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04324" title="Abstract">arXiv:2312.04324</a> (cross-list from eess.AS) [<a href="/pdf/2312.04324" title="Download PDF">pdf</a>, <a href="/format/2312.04324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiaPer: End-to-End Neural Diarization with Perceiver-Based Attractors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Landini%2C+F">Federico Landini</a>, 
<a href="/search/eess?searchtype=author&query=Diez%2C+M">Mireia Diez</a>, 
<a href="/search/eess?searchtype=author&query=Stafylakis%2C+T">Themos Stafylakis</a>, 
<a href="/search/eess?searchtype=author&query=Burget%2C+L">Luk&#xe1;&#x161; Burget</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Until recently, the field of speaker diarization was dominated by cascaded
systems. Due to their limitations, mainly regarding overlapped speech and
cumbersome pipelines, end-to-end models have gained great popularity lately.
One of the most successful models is end-to-end neural diarization with
encoder-decoder based attractors (EEND-EDA). In this work, we replace the EDA
module with a Perceiver-based one and show its advantages over EEND-EDA; namely
obtaining better performance on the largely studied Callhome dataset, finding
the quantity of speakers in a conversation more accurately, and running
inference on almost half of the time on long recordings. Furthermore, when
exhaustively compared with other methods, our model, DiaPer, reaches remarkable
performance with a very lightweight design. Besides, we perform comparisons
with other works and a cascaded baseline across more than ten public wide-band
datasets. Together with this publication, we release the code of DiaPer as well
as models trained on public and free data.
</p>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04360" title="Abstract">arXiv:2312.04360</a> (cross-list from quant-ph) [<a href="/pdf/2312.04360" title="Download PDF">pdf</a>, <a href="/format/2312.04360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Computational Advantage of MIP* Vanishes in the Presence of Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Dong%2C+Y">Yangjing Dong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Fu%2C+H">Honghao Fu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Natarajan%2C+A">Anand Natarajan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Qin%2C+M">Minglong Qin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Xu%2C+H">Haochen Xu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yao%2C+P">Penghui Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Comments are welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">Quantum multiprover interactive proof systems with entanglement MIP* are much
more powerful than their classical counterpart MIP (Babai et al. '91, Ji et al.
'20): while MIP = NEXP, the quantum class MIP* is equal to RE, a class
including the halting problem. This is because the provers in MIP* can share
unbounded quantum entanglement. However, recent works of Qin and Yao '21 and
'23 have shown that this advantage is significantly reduced if the provers'
shared state contains noise. This paper attempts to exactly characterize the
effect of noise on the computational power of quantum multiprover interactive
proof systems. We investigate the quantum two-prover one-round interactive
system MIP*[poly, O(1)], where the verifier sends polynomially many bits to the
provers and the provers send back constantly many bits. We show noise
completely destroys the computational advantage given by shared entanglement in
this model. Specifically, we show that if the provers are allowed to share
arbitrarily many EPR states, where each EPR state is affected by an arbitrarily
small constant amount of noise, the resulting complexity class is contained in
NEXP = MIP. This improves significantly on the previous best-known bound of
NEEEXP (nondeterministic triply exponential time) by Qin and Yao '21. We also
show that this collapse in power is due to the noise, rather than the O(1)
answer size, by showing that allowing for noiseless EPR states gives the class
the full power of RE = MIP*[poly, poly]. Along the way, we develop two
technical tools of independent interest. First, we give a new, deterministic
tester for the positivity of an exponentially large matrix, provided it has a
low-degree Fourier decomposition in terms of Pauli matrices. Secondly, we
develop a new invariance principle for smooth matrix functions having bounded
third-order Fr\'echet derivatives or which are Lipschitz continous.
</p>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04367" title="Abstract">arXiv:2312.04367</a> (cross-list from math.LO) [<a href="/pdf/2312.04367" title="Download PDF">pdf</a>, <a href="/ps/2312.04367" title="Download PostScript">ps</a>, <a href="/format/2312.04367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Paraconsistent Existential Graphs Gamma Peirce System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sierra-Aristizabal%2C+M">Manuel Sierra-Aristizabal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">In this paper, the paraconsistent propositional logic LG is presented, along
with its semantic characterization. It is shown that LG's set of theorems
corresponds to the set of valid existential graphs, GET, which turns out to be
an extension of Peirce's Gamma system, without becoming Zeman's gamma-4 system.
All evidence is presented in a complete, rigorous, and detailed manner. This
result is generalized by constructing the paraconsistent system of existential
graphs GET4, and its semantic-deductive characterization. Finally, Zeman's
Gamma-4, Gamma-4.2, and Gamma-5 existential graph systems are proven to be
paraconsistent.
</p>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04370" title="Abstract">arXiv:2312.04370</a> (cross-list from eess.AS) [<a href="/pdf/2312.04370" title="Download PDF">pdf</a>, <a href="/format/2312.04370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating the Design Space of Diffusion Models for Speech  Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gonzalez%2C+P">Philippe Gonzalez</a>, 
<a href="/search/eess?searchtype=author&query=Tan%2C+Z">Zheng-Hua Tan</a>, 
<a href="/search/eess?searchtype=author&query=%C3%98stergaard%2C+J">Jan &#xd8;stergaard</a>, 
<a href="/search/eess?searchtype=author&query=Jensen%2C+J">Jesper Jensen</a>, 
<a href="/search/eess?searchtype=author&query=Alstr%C3%B8m%2C+T+S">Tommy Sonne Alstr&#xf8;m</a>, 
<a href="/search/eess?searchtype=author&query=May%2C+T">Tobias May</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">Diffusion models are a new class of generative models that have shown
outstanding performance in image generation literature. As a consequence,
studies have attempted to apply diffusion models to other tasks, such as speech
enhancement. A popular approach in adapting diffusion models to speech
enhancement consists in modelling a progressive transformation between the
clean and noisy speech signals. However, one popular diffusion model framework
previously laid in image generation literature did not account for such a
transformation towards the system input, which prevents from relating the
existing diffusion-based speech enhancement systems with the aforementioned
diffusion model framework. To address this, we extend this framework to account
for the progressive transformation between the clean and noisy speech signals.
This allows us to apply recent developments from image generation literature,
and to systematically investigate design aspects of diffusion models that
remain largely unexplored for speech enhancement, such as the neural network
preconditioning, the training loss weighting, the stochastic differential
equation (SDE), or the amount of stochasticity injected in the reverse process.
We show that the performance of previous diffusion-based speech enhancement
systems cannot be attributed to the progressive transformation between the
clean and noisy speech signals. Moreover, we show that a proper choice of
preconditioning, training loss weighting, SDE and sampler allows to outperform
a popular diffusion-based speech enhancement system in terms of perceptual
metrics while using fewer sampling steps, thus reducing the computational cost
by a factor of four.
</p>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04371" title="Abstract">arXiv:2312.04371</a> (cross-list from math.OC) [<a href="/pdf/2312.04371" title="Download PDF">pdf</a>, <a href="/format/2312.04371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Scalable Network-Aware Multi-Agent Reinforcement Learning Framework  for Decentralized Inverter-based Voltage Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Xu%2C+H">Han Xu</a>, 
<a href="/search/math?searchtype=author&query=Zheng%2C+J">Jialin Zheng</a>, 
<a href="/search/math?searchtype=author&query=Qu%2C+G">Guannan Qu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA); Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper addresses the challenges associated with decentralized voltage
control in power grids due to an increase in distributed generations (DGs).
Traditional model-based voltage control methods struggle with the rapid energy
fluctuations and uncertainties of these DGs. While multi-agent reinforcement
learning (MARL) has shown potential for decentralized secondary control,
scalability issues arise when dealing with a large number of DGs. This problem
lies in the dominant centralized training and decentralized execution (CTDE)
framework, where the critics take global observations and actions. To overcome
these challenges, we propose a scalable network-aware (SNA) framework that
leverages network structure to truncate the input to the critic's Q-function,
thereby improving scalability and reducing communication costs during training.
Further, the SNA framework is theoretically grounded with provable
approximation guarantee, and it can seamlessly integrate with multiple
multi-agent actor-critic algorithms. The proposed SNA framework is successfully
demonstrated in a system with 114 DGs, providing a promising solution for
decentralized voltage control in increasingly complex power grid systems.
</p>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04382" title="Abstract">arXiv:2312.04382</a> (cross-list from eess.IV) [<a href="/pdf/2312.04382" title="Download PDF">pdf</a>, <a href="/format/2312.04382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Denoising Diffusion Model for Unsupervised Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yu%2C+J">Jongmin Yu</a>, 
<a href="/search/eess?searchtype=author&query=Oh%2C+H">Hyeontaek Oh</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+J">Jinhong Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for the poster session of DGM4H worshop on NeuralPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we propose the Adversarial Denoising Diffusion Model (ADDM).
The ADDM is based on the Denoising Diffusion Probabilistic Model (DDPM) but
complementarily trained by adversarial learning. The proposed adversarial
learning is achieved by classifying model-based denoised samples and samples to
which random Gaussian noise is added to a specific sampling step. With the
addition of explicit adversarial learning on data samples, ADDM can learn the
semantic characteristics of the data more robustly during training, which
achieves a similar data sampling performance with much fewer sampling steps
than DDPM. We apply ADDM to anomaly detection in unsupervised MRI images.
Experimental results show that the proposed ADDM outperformed existing
generative model-based unsupervised anomaly detection methods. In particular,
compared to other DDPM-based anomaly detection methods, the proposed ADDM shows
better performance with the same number of sampling steps and similar
performance with 50% fewer sampling steps.
</p>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04385" title="Abstract">arXiv:2312.04385</a> (cross-list from eess.IV) [<a href="/pdf/2312.04385" title="Download PDF">pdf</a>, <a href="/format/2312.04385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AniRes2D: Anisotropic Residual-enhanced Diffusion for 2D MR  Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wu%2C+Z">Zejun Wu</a>, 
<a href="/search/eess?searchtype=author&query=Remedios%2C+S+W">Samuel W. Remedios</a>, 
<a href="/search/eess?searchtype=author&query=Dewey%2C+B+E">Blake E. Dewey</a>, 
<a href="/search/eess?searchtype=author&query=Carass%2C+A">Aaron Carass</a>, 
<a href="/search/eess?searchtype=author&query=Prince%2C+J+L">Jerry L. Prince</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at SPIE Medical Imaging 2024, Clinical and Biomedical Imaging
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Anisotropic low-resolution (LR) magnetic resonance (MR) images are fast to
obtain but hinder automated processing. We propose to use denoising diffusion
probabilistic models (DDPMs) to super-resolve these 2D-acquired LR MR slices.
This paper introduces AniRes2D, a novel approach combining DDPM with a residual
prediction for 2D super-resolution (SR). Results demonstrate that AniRes2D
outperforms several other DDPM-based models in quantitative metrics, visual
quality, and out-of-domain evaluation. We use a trained AniRes2D to
super-resolve 3D volumes slice by slice, where comparative quantitative results
and reduced skull aliasing are achieved compared to a recent state-of-the-art
self-supervised 3D super-resolution method. Furthermore, we explored the use of
noise conditioning augmentation (NCA) as an alternative augmentation technique
for DDPM-based SR models, but it was found to reduce performance. Our findings
contribute valuable insights to the application of DDPMs for SR of anisotropic
MR images.
</p>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04447" title="Abstract">arXiv:2312.04447</a> (cross-list from quant-ph) [<a href="/pdf/2312.04447" title="Download PDF">pdf</a>, <a href="/format/2312.04447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-preserving quantum federated learning via gradient hiding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+C">Changhao Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kumar%2C+N">Niraj Kumar</a>, 
<a href="/search/quant-ph?searchtype=author&query=Song%2C+Z">Zhixin Song</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chakrabarti%2C+S">Shouvanik Chakrabarti</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pistoia%2C+M">Marco Pistoia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 2 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Distributed quantum computing, particularly distributed quantum machine
learning, has gained substantial prominence for its capacity to harness the
collective power of distributed quantum resources, transcending the limitations
of individual quantum nodes. Meanwhile, the critical concern of privacy within
distributed computing protocols remains a significant challenge, particularly
in standard classical federated learning (FL) scenarios where data of
participating clients is susceptible to leakage via gradient inversion attacks
by the server. This paper presents innovative quantum protocols with quantum
communication designed to address the FL problem, strengthen privacy measures,
and optimize communication efficiency. In contrast to previous works that
leverage expressive variational quantum circuits or differential privacy
techniques, we consider gradient information concealment using quantum states
and propose two distinct FL protocols, one based on private inner-product
estimation and the other on incremental learning. These protocols offer
substantial advancements in privacy preservation with low communication
resources, forging a path toward efficient quantum communication-assisted FL
protocols and contributing to the development of secure distributed quantum
machine learning, thus addressing critical privacy concerns in the quantum
computing era.
</p>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04456" title="Abstract">arXiv:2312.04456</a> (cross-list from quant-ph) [<a href="/pdf/2312.04456" title="Download PDF">pdf</a>, <a href="/format/2312.04456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reversible Entanglement Beyond Quantum Operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+Y">Yu-Ao Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhu%2C+C">Chenghong Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages including appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Strongly Correlated Electrons (cond-mat.str-el); Information Theory (cs.IT); High Energy Physics - Theory (hep-th); Mathematical Physics (math-ph)

</div>
<p class="mathjax">We introduce a reversible theory of exact entanglement manipulation by
establishing a necessary and sufficient condition for state transfer under
trace-preserving transformations that completely preserve the positivity of
partial transpose (PPT). Under these free transformations, we show that
logarithmic negativity emerges as the pivotal entanglement measure for
determining entangled states' transformations, analogous to the role of entropy
in the second law of thermodynamics. Previous results have proven that
entanglement is irreversible under quantum operations that completely preserve
PPT and leave open the question of reversibility for quantum operations that do
not generate entanglement asymptotically. However, we find that going beyond
the complete positivity constraint imposed by standard quantum mechanics
enables a reversible theory of exact entanglement manipulation, which may
suggest a potential incompatibility between the reversibility of entanglement
and the fundamental principles of quantum mechanics.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Fri,  8 Dec 23</h3>
<dl>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.12928" title="Abstract">arXiv:2104.12928</a> (replaced) [<a href="/pdf/2104.12928" title="Download PDF">pdf</a>, <a href="/format/2104.12928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> If your data distribution shifts, use self-learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rusak%2C+E">Evgenia Rusak</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+S">Steffen Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Pachitariu%2C+G">George Pachitariu</a>, 
<a href="/search/cs?searchtype=author&query=Eck%2C+L">Luisa Eck</a>, 
<a href="/search/cs?searchtype=author&query=Gehler%2C+P">Peter Gehler</a>, 
<a href="/search/cs?searchtype=author&query=Bringmann%2C+O">Oliver Bringmann</a>, 
<a href="/search/cs?searchtype=author&query=Brendel%2C+W">Wieland Brendel</a>, 
<a href="/search/cs?searchtype=author&query=Bethge%2C+M">Matthias Bethge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Web: <a href="https://domainadaptation.org/selflearning">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.09199" title="Abstract">arXiv:2105.09199</a> (replaced) [<a href="/pdf/2105.09199" title="Download PDF">pdf</a>, <a href="/format/2105.09199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Piecewise orthogonal collocation for computing periodic solutions of  renewal equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ando%27%2C+A">Alessia Ando&#x27;</a>, 
<a href="/search/math?searchtype=author&query=Breda%2C+D">Dimitri Breda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> And\`o, A., Breda, D. Piecewise orthogonal collocation for
  computing periodic solutions of renewal equations. Adv Comput Math 49, 93
  (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.00198" title="Abstract">arXiv:2106.00198</a> (replaced) [<a href="/pdf/2106.00198" title="Download PDF">pdf</a>, <a href="/format/2106.00198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient play in stochastic games: stationary points, convergence, and  sample complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Runyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhaolin Ren</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Na Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.08712" title="Abstract">arXiv:2106.08712</a> (replaced) [<a href="/pdf/2106.08712" title="Download PDF">pdf</a>, <a href="/format/2106.08712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Rank Parity-Check Codes Over Finite Commutative Rings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kamche%2C+H+T">Hermann Tchatchiem Kamche</a>, 
<a href="/search/cs?searchtype=author&query=Kalachi%2C+H+T">Herv&#xe9; Tal&#xe9; Kalachi</a>, 
<a href="/search/cs?searchtype=author&query=Djomou%2C+F+R+K">Franck Rivel Kamwa Djomou</a>, 
<a href="/search/cs?searchtype=author&query=Fouotsa%2C+E">Emmanuel Fouotsa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.03501" title="Abstract">arXiv:2111.03501</a> (replaced) [<a href="/pdf/2111.03501" title="Download PDF">pdf</a>, <a href="/format/2111.03501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Checking Temporal Properties of Recursive Probabilistic Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Winkler%2C+T">Tobias Winkler</a>, 
<a href="/search/cs?searchtype=author&query=Gehnen%2C+C">Christina Gehnen</a>, 
<a href="/search/cs?searchtype=author&query=Katoen%2C+J">Joost-Pieter Katoen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Journal version of FoSSaCS '22 paper with same title, submitted to LMCS, 30 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.10303" title="Abstract">arXiv:2111.10303</a> (replaced) [<a href="/pdf/2111.10303" title="Download PDF">pdf</a>, <a href="/ps/2111.10303" title="Download PostScript">ps</a>, <a href="/format/2111.10303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymptotic Improvements on the Exact Matching Distance for 2-parameter  Persistence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bjerkevik%2C+H+B">H&#xe5;vard Bakke Bjerkevik</a>, 
<a href="/search/math?searchtype=author&query=Kerber%2C+M">Michael Kerber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Topology (math.AT)</span>; Computational Geometry (cs.CG)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.00428" title="Abstract">arXiv:2112.00428</a> (replaced) [<a href="/pdf/2112.00428" title="Download PDF">pdf</a>, <a href="/format/2112.00428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adv-4-Adv: Thwarting Changing Adversarial Perturbations via Adversarial  Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tianyue Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+S">Shuya Ding</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+C">Chao Cai</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jun Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.07921" title="Abstract">arXiv:2112.07921</a> (replaced) [<a href="/pdf/2112.07921" title="Download PDF">pdf</a>, <a href="/format/2112.07921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Shuffling for Defending Deep Action Recognition Models against  Adversarial Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jaehui Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jun-Ho Choi</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+C">Cho-Jui Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jong-Seok Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, accepted to Neural Networks
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neural Networks, vol. 169, pp. 388-397, Jan. 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.12681" title="Abstract">arXiv:2112.12681</a> (replaced) [<a href="/pdf/2112.12681" title="Download PDF">pdf</a>, <a href="/ps/2112.12681" title="Download PostScript">ps</a>, <a href="/format/2112.12681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Point-free Perspective on Lax extensions and Predicate liftings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Goncharov%2C+S">Sergey Goncharov</a>, 
<a href="/search/math?searchtype=author&query=Hofmann%2C+D">Dirk Hofmann</a>, 
<a href="/search/math?searchtype=author&query=Nora%2C+P">Pedro Nora</a>, 
<a href="/search/math?searchtype=author&query=Schr%C3%B6der%2C+L">Lutz Schr&#xf6;der</a>, 
<a href="/search/math?searchtype=author&query=Wild%2C+P">Paul Wild</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Mathematical Structures in Computer Science. 2023:1-30
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.02351" title="Abstract">arXiv:2201.02351</a> (replaced) [<a href="/pdf/2201.02351" title="Download PDF">pdf</a>, <a href="/format/2201.02351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymptotic Security using Bayesian Defense Mechanism with Application to  Cyber Deception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sasahara%2C+H">Hampei Sasahara</a>, 
<a href="/search/cs?searchtype=author&query=Sandberg%2C+H">Henrik Sandberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, accepted at IEEE Transactions on Automatic Control
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Science and Game Theory (cs.GT); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.09517" title="Abstract">arXiv:2202.09517</a> (replaced) [<a href="/pdf/2202.09517" title="Download PDF">pdf</a>, <a href="/format/2202.09517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning for Hate Speech Detection: A Comparative Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malik%2C+J+S">Jitendra Singh Malik</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+H">Hezhe Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+G">Guansong Pang</a>, 
<a href="/search/cs?searchtype=author&query=van+den+Hengel%2C+A">Anton van den Hengel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 4 figures, and 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.04969" title="Abstract">arXiv:2204.04969</a> (replaced) [<a href="/pdf/2204.04969" title="Download PDF">pdf</a>, <a href="/format/2204.04969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing hierarchies by their consistent segmentations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gutman%2C+Z">Zeev Gutman</a>, 
<a href="/search/cs?searchtype=author&query=Vij%2C+R">Ritvik Vij</a> (IIT Delhi), 
<a href="/search/cs?searchtype=author&query=Najman%2C+L">Laurent Najman</a> (LIGM), 
<a href="/search/cs?searchtype=author&query=Lindenbaum%2C+M">Michael Lindenbaum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.06857" title="Abstract">arXiv:2205.06857</a> (replaced) [<a href="/pdf/2205.06857" title="Download PDF">pdf</a>, <a href="/ps/2205.06857" title="Download PostScript">ps</a>, <a href="/format/2205.06857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameterized Complexity of Gerrymandering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fraser%2C+A">Andrew Fraser</a>, 
<a href="/search/cs?searchtype=author&query=Lavallee%2C+B">Brian Lavallee</a>, 
<a href="/search/cs?searchtype=author&query=Sullivan%2C+B+D">Blair D. Sullivan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.08324" title="Abstract">arXiv:2205.08324</a> (replaced) [<a href="/pdf/2205.08324" title="Download PDF">pdf</a>, <a href="/format/2205.08324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Interactive Guidance for Unified and Effective Image  Matting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Dinghao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weijia Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yiqi Lin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Conghui He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.09944" title="Abstract">arXiv:2205.09944</a> (replaced) [<a href="/e-print/2205.09944" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 6G Network AI Architecture for Everyone-Centric Customized Services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+M">Mulei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hequan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Quan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Ping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+X">Xiaohu You</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jianjun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Chenghui Peng</a>, 
<a href="/search/cs?searchtype=author&query=Yum%2C+T+P">Tak-Shing Peter Yum</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Sherman Shen</a>, 
<a href="/search/cs?searchtype=author&query=Aghvami%2C+H">Hamid Aghvami</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G+Y">Geoffrey Y Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiangzhou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guangyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Peng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiongyan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+C">Chang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Thompson%2C+J">John Thompson</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kat-Kit Wong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shanzhi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Debbah%2C+M">Merouane Debbah</a>, 
<a href="/search/cs?searchtype=author&query=Dustdar%2C+S">Schahram Dustdar</a>, 
<a href="/search/cs?searchtype=author&query=Eliassen%2C+F">Frank Eliassen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+X">Xiangyang Duan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shaohui Sun</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+X">Xiaofeng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jianwei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shuguang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jie Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yue Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Honggang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+X">Xiaohu Ge</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yong Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cheng-Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zaichen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ci%2C+S">Song Ci</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+G">Guoqiang Mao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changle Li</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Ziyu Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Junrui Liang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kai Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Liantao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Fanglei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kunlun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zening Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+T">Teng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+H">Hongfeng Shu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The current version has partial Insufficient completion, so we would like to withdraw it. We hope you agree, thank you
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.14608" title="Abstract">arXiv:2205.14608</a> (replaced) [<a href="/pdf/2205.14608" title="Download PDF">pdf</a>, <a href="/format/2205.14608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flat singularities of chained systems, illustrated with an aircraft  model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kaminski%2C+Y+J">Yirmeyahu J. Kaminski</a>, 
<a href="/search/math?searchtype=author&query=Ollivier%2C+F">Fran&#xe7;ois Ollivier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Symbolic Computation (cs.SC); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.04770" title="Abstract">arXiv:2206.04770</a> (replaced) [<a href="/pdf/2206.04770" title="Download PDF">pdf</a>, <a href="/ps/2206.04770" title="Download PostScript">ps</a>, <a href="/format/2206.04770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Continuous-Time Perspective on Global Acceleration for Monotone  Equation Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lin%2C+T">Tianyi Lin</a>, 
<a href="/search/math?searchtype=author&query=Jordan%2C+M+I">Michael. I. Jordan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 Pages; Adding new results and rewritting the paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.04979" title="Abstract">arXiv:2206.04979</a> (replaced) [<a href="/pdf/2206.04979" title="Download PDF">pdf</a>, <a href="/ps/2206.04979" title="Download PostScript">ps</a>, <a href="/format/2206.04979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convolutional layers are equivariant to discrete shifts but not  continuous translations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McGreivy%2C+N">Nick McGreivy</a>, 
<a href="/search/cs?searchtype=author&query=Hakim%2C+A">Ammar Hakim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.14738" title="Abstract">arXiv:2206.14738</a> (replaced) [<a href="/pdf/2206.14738" title="Download PDF">pdf</a>, <a href="/format/2206.14738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding $k$-community structures in special graph classes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Baghirova%2C+N">Narmina Baghirova</a>, 
<a href="/search/math?searchtype=author&query=Dallard%2C+C">Cl&#xe9;ment Dallard</a>, 
<a href="/search/math?searchtype=author&query=Ries%2C+B">Bernard Ries</a>, 
<a href="/search/math?searchtype=author&query=Schindl%2C+D">David Schindl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.03186" title="Abstract">arXiv:2207.03186</a> (replaced) [<a href="/pdf/2207.03186" title="Download PDF">pdf</a>, <a href="/format/2207.03186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kronecker Product Approximation of Operators in Spectral Norm via  Alternating SDP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dressler%2C+M">Mareike Dressler</a>, 
<a href="/search/math?searchtype=author&query=Uschmajew%2C+A">Andr&#xe9; Uschmajew</a>, 
<a href="/search/math?searchtype=author&query=Chandrasekaran%2C+V">Venkat Chandrasekaran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> final version; 17 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Algebraic Geometry (math.AG); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.13276" title="Abstract">arXiv:2207.13276</a> (replaced) [<a href="/pdf/2207.13276" title="Download PDF">pdf</a>, <a href="/format/2207.13276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Some New Methods to Generate Short Addition Chains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yuanchao Ding</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hua Guo</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Y">Yewei Guan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hutao Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiyong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.13326" title="Abstract">arXiv:2207.13326</a> (replaced) [<a href="/pdf/2207.13326" title="Download PDF">pdf</a>, <a href="/format/2207.13326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point Cloud Attacks in Graph Spectral Domain: When 3D Geometry Meets  Graph Signal Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Daizong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI). arXiv admin note: substantial text overlap with <a href="/abs/2202.07261">arXiv:2202.07261</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.08089" title="Abstract">arXiv:2208.08089</a> (replaced) [<a href="/pdf/2208.08089" title="Download PDF">pdf</a>, <a href="/format/2208.08089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained Few-Shot Learning: Human-Like Low Sample Complexity Learning  and Non-Episodic Text Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mar%2C+J">Jaron Mar</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiamou Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Add additional references Update various sections for clarity
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.13428" title="Abstract">arXiv:2208.13428</a> (replaced) [<a href="/pdf/2208.13428" title="Download PDF">pdf</a>, <a href="/format/2208.13428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constructive Many-one Reduction from the Halting Problem to  Semi-unification (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dudenhefner%2C+A">Andrej Dudenhefner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.01878" title="Abstract">arXiv:2209.01878</a> (replaced) [<a href="/pdf/2209.01878" title="Download PDF">pdf</a>, <a href="/ps/2209.01878" title="Download PostScript">ps</a>, <a href="/format/2209.01878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new T-compatibility condition and its application to the  discretization of the damped time-harmonic Galbrun&#x27;s equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Halla%2C+M">Martin Halla</a>, 
<a href="/search/math?searchtype=author&query=Lehrenfeld%2C+C">Christoph Lehrenfeld</a>, 
<a href="/search/math?searchtype=author&query=Stocker%2C+P">Paul Stocker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.13862" title="Abstract">arXiv:2209.13862</a> (replaced) [<a href="/pdf/2209.13862" title="Download PDF">pdf</a>, <a href="/format/2209.13862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Operational Approach to Information Leakage via Generalized Gain  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kurri%2C+G+R">Gowtham R. Kurri</a>, 
<a href="/search/cs?searchtype=author&query=Sankar%2C+L">Lalitha Sankar</a>, 
<a href="/search/cs?searchtype=author&query=Kosut%2C+O">Oliver Kosut</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 1 Figure. New results are added. Some results of this paper were presented at ISIT 2021 and ISIT 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.04099" title="Abstract">arXiv:2210.04099</a> (replaced) [<a href="/pdf/2210.04099" title="Download PDF">pdf</a>, <a href="/format/2210.04099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Developable Quad Meshes and Contact Element Nets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Inza%2C+V+C">Victor Ceballos Inza</a>, 
<a href="/search/cs?searchtype=author&query=Rist%2C+F">Florian Rist</a>, 
<a href="/search/cs?searchtype=author&query=Wallner%2C+J">Johannes Wallner</a>, 
<a href="/search/cs?searchtype=author&query=Pottmann%2C+H">Helmut Pottmann</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM Transactions on Graphics, Volume 42, Issue 6, Article 183
  (December 2023), 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.08620" title="Abstract">arXiv:2210.08620</a> (replaced) [<a href="/pdf/2210.08620" title="Download PDF">pdf</a>, <a href="/format/2210.08620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Twin-width of Planar Graphs is at most 8, and some Related Bounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hlin%C4%9Bn%C3%BD%2C+P">Petr Hlin&#x11b;n&#xfd;</a>, 
<a href="/search/math?searchtype=author&query=Jedelsk%C3%BD%2C+J">Jan Jedelsk&#xfd;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.09943" title="Abstract">arXiv:2210.09943</a> (replaced) [<a href="/pdf/2210.09943" title="Download PDF">pdf</a>, <a href="/format/2210.09943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Bias Mitigation: Fairer Architectures Make for Fairer Face  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dooley%2C+S">Samuel Dooley</a>, 
<a href="/search/cs?searchtype=author&query=Sukthanker%2C+R+S">Rhea Sanjay Sukthanker</a>, 
<a href="/search/cs?searchtype=author&query=Dickerson%2C+J+P">John P. Dickerson</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+C">Colin White</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+F">Frank Hutter</a>, 
<a href="/search/cs?searchtype=author&query=Goldblum%2C+M">Micah Goldblum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.11407" title="Abstract">arXiv:2210.11407</a> (replaced) [<a href="/pdf/2210.11407" title="Download PDF">pdf</a>, <a href="/format/2210.11407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Similarity of Neural Architectures using Adversarial Attack  Transferability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jaehui Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+D">Dongyoon Han</a>, 
<a href="/search/cs?searchtype=author&query=Heo%2C+B">Byeongho Heo</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Song Park</a>, 
<a href="/search/cs?searchtype=author&query=Chun%2C+S">Sanghyuk Chun</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jong-Seok Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20pages, 13 figures, 2.3MB
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.12583" title="Abstract">arXiv:2210.12583</a> (replaced) [<a href="/pdf/2210.12583" title="Download PDF">pdf</a>, <a href="/format/2210.12583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Learning of Discrete-Time Dynamics for Uncertainty-Aware Model  Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saviolo%2C+A">Alessandro Saviolo</a>, 
<a href="/search/cs?searchtype=author&query=Frey%2C+J">Jonathan Frey</a>, 
<a href="/search/cs?searchtype=author&query=Rathod%2C+A">Abhishek Rathod</a>, 
<a href="/search/cs?searchtype=author&query=Diehl%2C+M">Moritz Diehl</a>, 
<a href="/search/cs?searchtype=author&query=Loianno%2C+G">Giuseppe Loianno</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03894" title="Abstract">arXiv:2211.03894</a> (replaced) [<a href="/pdf/2211.03894" title="Download PDF">pdf</a>, <a href="/format/2211.03894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> visClust: A visual clustering algorithm based on orthogonal projections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Breger%2C+A">Anna Breger</a>, 
<a href="/search/cs?searchtype=author&query=Karner%2C+C">Clemens Karner</a>, 
<a href="/search/cs?searchtype=author&query=Ehler%2C+M">Martin Ehler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.05588" title="Abstract">arXiv:2211.05588</a> (replaced) [<a href="/pdf/2211.05588" title="Download PDF">pdf</a>, <a href="/format/2211.05588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Watching the News: Towards VideoQA Models that can Read
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jahagirdar%2C+S">Soumya Jahagirdar</a>, 
<a href="/search/cs?searchtype=author&query=Mathew%2C+M">Minesh Mathew</a>, 
<a href="/search/cs?searchtype=author&query=Karatzas%2C+D">Dimosthenis Karatzas</a>, 
<a href="/search/cs?searchtype=author&query=Jawahar%2C+C+V">C. V. Jawahar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08586" title="Abstract">arXiv:2211.08586</a> (replaced) [<a href="/pdf/2211.08586" title="Download PDF">pdf</a>, <a href="/ps/2211.08586" title="Download PostScript">ps</a>, <a href="/format/2211.08586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bandit Algorithms for Prophet Inequality and Pandora&#x27;s Box
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gatmiry%2C+K">Khashayar Gatmiry</a>, 
<a href="/search/cs?searchtype=author&query=Kesselheim%2C+T">Thomas Kesselheim</a>, 
<a href="/search/cs?searchtype=author&query=Singla%2C+S">Sahil Singla</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08705" title="Abstract">arXiv:2211.08705</a> (replaced) [<a href="/pdf/2211.08705" title="Download PDF">pdf</a>, <a href="/format/2211.08705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource Allocation of Federated Learning for the Metaverse with Mobile  Augmented Reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xinyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper appears in IEEE Transactions on Wireless Communications. DOI: <a href="https://doi.org/10.1109/TWC.2023.3326884">this https URL</a> It is the journal version of 2022 IEEE 42nd International Conference on Distributed Computing Systems (ICDCS) paper: <a href="/abs/2209.14900">arXiv:2209.14900</a>; i.e., <a href="https://doi.org/10.1109/ICDCS54860.2022.00101">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08774" title="Abstract">arXiv:2211.08774</a> (replaced) [<a href="/pdf/2211.08774" title="Download PDF">pdf</a>, <a href="/format/2211.08774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speaker Adaptation for End-To-End Speech Recognition Systems in Noisy  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wagner%2C+D">Dominik Wagner</a>, 
<a href="/search/cs?searchtype=author&query=Baumann%2C+I">Ilja Baumann</a>, 
<a href="/search/cs?searchtype=author&query=Bayerl%2C+S+P">Sebastian P. Bayerl</a>, 
<a href="/search/cs?searchtype=author&query=Riedhammer%2C+K">Korbinian Riedhammer</a>, 
<a href="/search/cs?searchtype=author&query=Bocklet%2C+T">Tobias Bocklet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ASRU 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.10558" title="Abstract">arXiv:2211.10558</a> (replaced) [<a href="/pdf/2211.10558" title="Download PDF">pdf</a>, <a href="/format/2211.10558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Internal Representations of Vision Models Through the Lens of Frames on  Data Manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kvinge%2C+H">Henry Kvinge</a>, 
<a href="/search/cs?searchtype=author&query=Jorgenson%2C+G">Grayson Jorgenson</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+D">Davis Brown</a>, 
<a href="/search/cs?searchtype=author&query=Godfrey%2C+C">Charles Godfrey</a>, 
<a href="/search/cs?searchtype=author&query=Emerson%2C+T">Tegan Emerson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, accepted as an oral presentation at the Workshop on Symmetry and Geometry in Neural Representations at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14284" title="Abstract">arXiv:2211.14284</a> (replaced) [<a href="/pdf/2211.14284" title="Download PDF">pdf</a>, <a href="/format/2211.14284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multigrid solvers for the de Rham complex with optimal complexity in  polynomial degree
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Brubeck%2C+P+D">Pablo D. Brubeck</a>, 
<a href="/search/math?searchtype=author&query=Farrell%2C+P+E">Patrick E. Farrell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01506" title="Abstract">arXiv:2212.01506</a> (replaced) [<a href="/pdf/2212.01506" title="Download PDF">pdf</a>, <a href="/format/2212.01506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Apple Fruitlet Sizing and Growth Rate Tracking using Computer  Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Freeman%2C+H">Harry Freeman</a>, 
<a href="/search/cs?searchtype=author&query=Qadri%2C+M">Mohamad Qadri</a>, 
<a href="/search/cs?searchtype=author&query=Silwal%2C+A">Abhisesh Silwal</a>, 
<a href="/search/cs?searchtype=author&query=O%27Connor%2C+P">Paul O&#x27;Connor</a>, 
<a href="/search/cs?searchtype=author&query=Rubinstein%2C+Z">Zachary Rubinstein</a>, 
<a href="/search/cs?searchtype=author&query=Cooley%2C+D">Daniel Cooley</a>, 
<a href="/search/cs?searchtype=author&query=Kantor%2C+G">George Kantor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.04821" title="Abstract">arXiv:2212.04821</a> (replaced) [<a href="/pdf/2212.04821" title="Download PDF">pdf</a>, <a href="/format/2212.04821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PromptonomyViT: Multi-Task Prompt Learning Improves Video Transformers  using Synthetic Scene Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herzig%2C+R">Roei Herzig</a>, 
<a href="/search/cs?searchtype=author&query=Abramovich%2C+O">Ofir Abramovich</a>, 
<a href="/search/cs?searchtype=author&query=Ben-Avraham%2C+E">Elad Ben-Avraham</a>, 
<a href="/search/cs?searchtype=author&query=Arbelle%2C+A">Assaf Arbelle</a>, 
<a href="/search/cs?searchtype=author&query=Karlinsky%2C+L">Leonid Karlinsky</a>, 
<a href="/search/cs?searchtype=author&query=Shamir%2C+A">Ariel Shamir</a>, 
<a href="/search/cs?searchtype=author&query=Darrell%2C+T">Trevor Darrell</a>, 
<a href="/search/cs?searchtype=author&query=Globerson%2C+A">Amir Globerson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07207" title="Abstract">arXiv:2212.07207</a> (replaced) [<a href="/pdf/2212.07207" title="Download PDF">pdf</a>, <a href="/format/2212.07207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAELi: Masked Autoencoder for Large-Scale LiDAR Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krispel%2C+G">Georg Krispel</a>, 
<a href="/search/cs?searchtype=author&query=Schinagl%2C+D">David Schinagl</a>, 
<a href="/search/cs?searchtype=author&query=Fruhwirth-Reisinger%2C+C">Christian Fruhwirth-Reisinger</a>, 
<a href="/search/cs?searchtype=author&query=Possegger%2C+H">Horst Possegger</a>, 
<a href="/search/cs?searchtype=author&query=Bischof%2C+H">Horst Bischof</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV 2024, 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.14578" title="Abstract">arXiv:2212.14578</a> (replaced) [<a href="/pdf/2212.14578" title="Download PDF">pdf</a>, <a href="/format/2212.14578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAUVE Scores for Generative Models: Theory and Practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pillutla%2C+K">Krishna Pillutla</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Thickstun%2C+J">John Thickstun</a>, 
<a href="/search/cs?searchtype=author&query=Welleck%2C+S">Sean Welleck</a>, 
<a href="/search/cs?searchtype=author&query=Swayamdipta%2C+S">Swabha Swayamdipta</a>, 
<a href="/search/cs?searchtype=author&query=Zellers%2C+R">Rowan Zellers</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+S">Sewoong Oh</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yejin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Harchaoui%2C+Z">Zaid Harchaoui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Journal of Machine Learning Research
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00752" title="Abstract">arXiv:2301.00752</a> (replaced) [<a href="/pdf/2301.00752" title="Download PDF">pdf</a>, <a href="/format/2301.00752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point Cloud-based Proactive Link Quality Prediction for Millimeter-wave  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ohta%2C+S">Shoki Ohta</a>, 
<a href="/search/cs?searchtype=author&query=Nishio%2C+T">Takayuki Nishio</a>, 
<a href="/search/cs?searchtype=author&query=Kudo%2C+R">Riichi Kudo</a>, 
<a href="/search/cs?searchtype=author&query=Takahashi%2C+K">Kahoko Takahashi</a>, 
<a href="/search/cs?searchtype=author&query=Nagata%2C+H">Hisashi Nagata</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Machine Learning in Communications and
  Networking, vol. 1, pp. 258-276, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.05601" title="Abstract">arXiv:2301.05601</a> (replaced) [<a href="/pdf/2301.05601" title="Download PDF">pdf</a>, <a href="/format/2301.05601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sem@$K$: Is my knowledge graph embedding model semantic-aware?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hubert%2C+N">Nicolas Hubert</a>, 
<a href="/search/cs?searchtype=author&query=Monnin%2C+P">Pierre Monnin</a>, 
<a href="/search/cs?searchtype=author&query=Brun%2C+A">Armelle Brun</a>, 
<a href="/search/cs?searchtype=author&query=Monticolo%2C+D">Davy Monticolo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09820" title="Abstract">arXiv:2301.09820</a> (replaced) [<a href="/pdf/2301.09820" title="Download PDF">pdf</a>, <a href="/format/2301.09820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Stability Analysis of Fine-Tuning a Pre-Trained Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+Z">Zihao Fu</a>, 
<a href="/search/cs?searchtype=author&query=So%2C+A+M">Anthony Man-Cho So</a>, 
<a href="/search/cs?searchtype=author&query=Collier%2C+N">Nigel Collier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11634" title="Abstract">arXiv:2301.11634</a> (replaced) [<a href="/pdf/2301.11634" title="Download PDF">pdf</a>, <a href="/format/2301.11634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Bisimilarity for Quasi-discrete Closure Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ciancia%2C+V">Vincenzo Ciancia</a> (1), 
<a href="/search/cs?searchtype=author&query=Latella%2C+D">Diego Latella</a> (1), 
<a href="/search/cs?searchtype=author&query=Massink%2C+M">Mieke Massink</a> (1), 
<a href="/search/cs?searchtype=author&query=de+Vink%2C+E+P">Erik P. de Vink</a> (2) ((1) Istituto di Scienza e Tecnologie dell&#x27;Informazione &quot;A. Faedo&#x27;&#x27;, Consiglio Nazionale delle Ricerche, Pisa, Italy, (2) Department of Mathematics and Computer Science, Eindhoven University of Technology, Eindhoven, The Netherlands)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12340" title="Abstract">arXiv:2301.12340</a> (replaced) [<a href="/pdf/2301.12340" title="Download PDF">pdf</a>, <a href="/ps/2301.12340" title="Download PostScript">ps</a>, <a href="/format/2301.12340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incremental Value and Interpretability of Radiomics Features of Both  Lung and Epicardial Adipose Tissue for Detecting the Severity of COVID-19  Infection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yao%2C+N">Ni Yao</a>, 
<a href="/search/eess?searchtype=author&query=Tian%2C+Y">Yanhui Tian</a>, 
<a href="/search/eess?searchtype=author&query=Neves%2C+D+G+d">Daniel Gama das Neves</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+C">Chen Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Mesquita%2C+C+T">Claudio Tinoco Mesquita</a>, 
<a href="/search/eess?searchtype=author&query=de+Andrade+Martins%2C+W">Wolney de Andrade Martins</a>, 
<a href="/search/eess?searchtype=author&query=Santos%2C+A+A+S+M+D+d">Alair Augusto Sarmet Moreira Damas dos Santos</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yanting Li</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+C">Chuang Han</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+F">Fubao Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Dai%2C+N">Neng Dai</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+W">Weihua Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01330" title="Abstract">arXiv:2302.01330</a> (replaced) [<a href="/pdf/2302.01330" title="Download PDF">pdf</a>, <a href="/format/2302.01330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SceneDreamer: Unbounded 3D Scene Generation from 2D Image Collections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhaoxi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guangcong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Transactions on Pattern Analysis &amp; Machine Intelligence (TPAMI) 2023; Project Page <a href="https://scene-dreamer.github.io/">this https URL</a> Code <a href="https://github.com/FrozenBurning/SceneDreamer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03684" title="Abstract">arXiv:2302.03684</a> (replaced) [<a href="/pdf/2302.03684" title="Download PDF">pdf</a>, <a href="/format/2302.03684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Robustness against Data Poisoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenxiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feizi%2C+S">Soheil Feizi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04871" title="Abstract">arXiv:2302.04871</a> (replaced) [<a href="/pdf/2302.04871" title="Download PDF">pdf</a>, <a href="/format/2302.04871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-N-Out: Faithful 3D GAN Inversion with Volumetric Decomposition for  Face Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yiran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+Z">Zhixin Shu</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+C">Cameron Smith</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+S+W">Seoung Wug Oh</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jia-Bin Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://in-n-out-3d.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05813" title="Abstract">arXiv:2302.05813</a> (replaced) [<a href="/pdf/2302.05813" title="Download PDF">pdf</a>, <a href="/format/2302.05813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lazard-style CAD and Equational Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Davenport%2C+J+H">James H. Davenport</a>, 
<a href="/search/cs?searchtype=author&query=Nair%2C+A+S">Akshar S. Nair</a>, 
<a href="/search/cs?searchtype=author&query=Sankaran%2C+G+K">Gregory K. Sankaran</a>, 
<a href="/search/cs?searchtype=author&query=Uncu%2C+A+K">Ali K.Uncu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of ISSAC'23, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06814" title="Abstract">arXiv:2302.06814</a> (replaced) [<a href="/pdf/2302.06814" title="Download PDF">pdf</a>, <a href="/format/2302.06814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Poly-algorithmic Approach to Quantifier Elimination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Davenport%2C+J+H">James H. Davenport</a>, 
<a href="/search/cs?searchtype=author&query=Tonks%2C+Z+P">Zak P. Tonks</a>, 
<a href="/search/cs?searchtype=author&query=Uncu%2C+A+K">Ali K. Uncu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in Proceedings SYNASC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10722" title="Abstract">arXiv:2302.10722</a> (replaced) [<a href="/pdf/2302.10722" title="Download PDF">pdf</a>, <a href="/format/2302.10722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing the Optimal 0-1 Loss for Multi-class Classification with  a Test-time Attacker
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+S">Sihui Dai</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Wenxin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Bhagoji%2C+A+N">Arjun Nitin Bhagoji</a>, 
<a href="/search/cs?searchtype=author&query=Cullina%2C+D">Daniel Cullina</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B+Y">Ben Y. Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Haitao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+P">Prateek Mittal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Spotlight
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10903" title="Abstract">arXiv:2302.10903</a> (replaced) [<a href="/pdf/2302.10903" title="Download PDF">pdf</a>, <a href="/format/2302.10903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trajectory-User Linking via Hierarchical Spatio-Temporal Attention  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yanwei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yongguo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Junyu Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 8 figures, accepted by ACM Trans. Knowl. Discov. Data Journal (TKDD)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11196" title="Abstract">arXiv:2302.11196</a> (replaced) [<a href="/e-print/2302.11196" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invariant Target Detection in Images through the Normalized 2-D  Correlation Technique
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Al-Obaidi%2C+F+E+M">Fatin E. M. Al-Obaidi</a>, 
<a href="/search/cs?searchtype=author&query=Al-Saleh%2C+A+H">Anwar H. Al-Saleh</a>, 
<a href="/search/cs?searchtype=author&query=Kafi%2C+S+H">Shaymaa H. Kafi</a>, 
<a href="/search/cs?searchtype=author&query=Karam%2C+A+J">Ali J.Karam</a>, 
<a href="/search/cs?searchtype=author&query=Al-Zuky%2C+A+A+D">Ali A. D. Al-Zuky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper in its uploaded format contained errors in analysis as in Abstract-4th and 5th line. In section 4 ; results and discussion and in conclusion section. So, in order not to adopt the research as a source by other researchers I wish to withdraw it completely
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11835" title="Abstract">arXiv:2302.11835</a> (replaced) [<a href="/pdf/2302.11835" title="Download PDF">pdf</a>, <a href="/format/2302.11835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning for Combining Search Methods in the Calibration  of Economic ABMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Glielmo%2C+A">Aldo Glielmo</a>, 
<a href="/search/cs?searchtype=author&query=Favorito%2C+M">Marco Favorito</a>, 
<a href="/search/cs?searchtype=author&query=Chanda%2C+D">Debmallya Chanda</a>, 
<a href="/search/cs?searchtype=author&query=Gatti%2C+D+D">Domenico Delli Gatti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages and 5 figures, presented at the AAAI bridge program 'AI for Financial Institutions' (<a href="https://aaai23.bankit.art/">this https URL</a>), at the ICLR bridge program 'AI4ABM' (<a href="https://ai4abm.org/workshop_iclr2023/">this https URL</a>) and at ICAIF '23 (<a href="https://ai-finance.org/">this https URL</a>). Proceedings of the Fourth ACM International Conference on AI in Finance, (ICAIF 23), Association for Computing Machinery, New York, NY, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); General Economics (econ.GN)

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13711" title="Abstract">arXiv:2302.13711</a> (replaced) [<a href="/pdf/2302.13711" title="Download PDF">pdf</a>, <a href="/format/2302.13711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Internal-Coordinate Density Modelling of Protein Structure: Covariance  Matters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arts%2C+M">Marloes Arts</a>, 
<a href="/search/cs?searchtype=author&query=Frellsen%2C+J">Jes Frellsen</a>, 
<a href="/search/cs?searchtype=author&query=Boomsma%2C+W">Wouter Boomsma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pages: 9 main, 3 references, 8 appendix. Figures: 5 main, 6 appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00491" title="Abstract">arXiv:2303.00491</a> (replaced) [<a href="/pdf/2303.00491" title="Download PDF">pdf</a>, <a href="/format/2303.00491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pose Impact Estimation on Face Recognition using 3D-Aware Synthetic Data  with Application to Quality Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grimmer%2C+M">Marcel Grimmer</a>, 
<a href="/search/cs?searchtype=author&query=Rathgeb%2C+C">Christian Rathgeb</a>, 
<a href="/search/cs?searchtype=author&query=Busch%2C+C">Christoph Busch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06458" title="Abstract">arXiv:2303.06458</a> (replaced) [<a href="/pdf/2303.06458" title="Download PDF">pdf</a>, <a href="/format/2303.06458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZeroNLG: Aligning and Autoencoding Domains for Zero-Shot Multimodal and  Multilingual Natural Language Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fenglin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Y">Yuexian Zou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaowei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Clifton%2C+D+A">David A. Clifton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our code and data are available at <a href="https://github.com/yangbang18/ZeroNLG">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13472" title="Abstract">arXiv:2303.13472</a> (replaced) [<a href="/pdf/2303.13472" title="Download PDF">pdf</a>, <a href="/format/2303.13472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Plotting Behind the Scenes: Towards Learnable Game Engines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Menapace%2C+W">Willi Menapace</a>, 
<a href="/search/cs?searchtype=author&query=Siarohin%2C+A">Aliaksandr Siarohin</a>, 
<a href="/search/cs?searchtype=author&query=Lathuili%C3%A8re%2C+S">St&#xe9;phane Lathuili&#xe8;re</a>, 
<a href="/search/cs?searchtype=author&query=Achlioptas%2C+P">Panos Achlioptas</a>, 
<a href="/search/cs?searchtype=author&query=Golyanik%2C+V">Vladislav Golyanik</a>, 
<a href="/search/cs?searchtype=author&query=Tulyakov%2C+S">Sergey Tulyakov</a>, 
<a href="/search/cs?searchtype=author&query=Ricci%2C+E">Elisa Ricci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM Transactions on Graphics \c{opyright} Copyright is held by the owner/author(s) 2023. This is the author's version of the work. It is posted here for your personal use. Not for redistribution. The definitive Version of Record was published in ACM Transactions on Graphics, <a href="http://dx.doi.org/10.1145/3635705">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16343" title="Abstract">arXiv:2303.16343</a> (replaced) [<a href="/pdf/2303.16343" title="Download PDF">pdf</a>, <a href="/ps/2303.16343" title="Download PostScript">ps</a>, <a href="/format/2303.16343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Facial recognition technology and human raters can predict political  orientation from images of expressionless faces even when controlling for  demographics and self-presentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kosinski%2C+M">Michal Kosinski</a>, 
<a href="/search/cs?searchtype=author&query=Khambatta%2C+P">Poruz Khambatta</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yilun Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Now published at American Psychologist (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17859" title="Abstract">arXiv:2303.17859</a> (replaced) [<a href="/pdf/2303.17859" title="Download PDF">pdf</a>, <a href="/format/2303.17859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MapFormer: Boosting Change Detection by Using Pre-change Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bernhard%2C+M">Maximilian Bernhard</a>, 
<a href="/search/cs?searchtype=author&query=Strau%C3%9F%2C+N">Niklas Strau&#xdf;</a>, 
<a href="/search/cs?searchtype=author&query=Schubert%2C+M">Matthias Schubert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.18187" title="Abstract">arXiv:2303.18187</a> (replaced) [<a href="/pdf/2303.18187" title="Download PDF">pdf</a>, <a href="/format/2303.18187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive-Signal-Dependent Plasticity: Forward-Forward Learning of  Spiking Neural Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ororbia%2C+A">Alexander Ororbia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01954" title="Abstract">arXiv:2304.01954</a> (replaced) [<a href="/pdf/2304.01954" title="Download PDF">pdf</a>, <a href="/ps/2304.01954" title="Download PostScript">ps</a>, <a href="/format/2304.01954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strong spatial mixing for colorings on trees and its algorithmic  applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zongchen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kuikui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mani%2C+N">Nitya Mani</a>, 
<a href="/search/cs?searchtype=author&query=Moitra%2C+A">Ankur Moitra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages, 6 page appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10306" title="Abstract">arXiv:2304.10306</a> (replaced) [<a href="/pdf/2304.10306" title="Download PDF">pdf</a>, <a href="/format/2304.10306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FIANCEE: Faster Inference of Adversarial Networks via Conditional Early  Exits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karpikova%2C+P">Polina Karpikova</a>, 
<a href="/search/cs?searchtype=author&query=Ekaterina%2C+R">Radionova Ekaterina</a>, 
<a href="/search/cs?searchtype=author&query=Yaschenko%2C+A">Anastasia Yaschenko</a>, 
<a href="/search/cs?searchtype=author&query=Spiridonov%2C+A">Andrei Spiridonov</a>, 
<a href="/search/cs?searchtype=author&query=Kostyushko%2C+L">Leonid Kostyushko</a>, 
<a href="/search/cs?searchtype=author&query=Fabbricatore%2C+R">Riccardo Fabbricatore</a>, 
<a href="/search/cs?searchtype=author&query=Ivakhnenko%2C+A">Aleksei Ivakhnenko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 22 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14484" title="Abstract">arXiv:2304.14484</a> (replaced) [<a href="/pdf/2304.14484" title="Download PDF">pdf</a>, <a href="/format/2304.14484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OriCon3D: Effective 3D Object Detection using Orientation and Confidence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajani%2C+D+M">Dhyey Manish Rajani</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S+P">Surya Pratap Singh</a>, 
<a href="/search/cs?searchtype=author&query=Swayampakula%2C+R+K">Rahul Kashyap Swayampakula</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00054" title="Abstract">arXiv:2305.00054</a> (replaced) [<a href="/pdf/2305.00054" title="Download PDF">pdf</a>, <a href="/format/2305.00054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LAVA: Data Valuation without Pre-Specified Learning Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Just%2C+H+A">Hoang Anh Just</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+F">Feiyang Kang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J+T">Jiachen T. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yi Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+M">Myeongseob Ko</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Ming Jin</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+R">Ruoxi Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2023 Spotlight
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02041" title="Abstract">arXiv:2305.02041</a> (replaced) [<a href="/pdf/2305.02041" title="Download PDF">pdf</a>, <a href="/format/2305.02041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-complexity subspace-descent over symmetric positive definite  manifold
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Darmwal%2C+Y">Yogesh Darmwal</a>, 
<a href="/search/stat?searchtype=author&query=Rajawat%2C+K">Ketan Rajawat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03514" title="Abstract">arXiv:2305.03514</a> (replaced) [<a href="/pdf/2305.03514" title="Download PDF">pdf</a>, <a href="/format/2305.03514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Large Language Models Transform Computational Social Science?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ziems%2C+C">Caleb Ziems</a>, 
<a href="/search/cs?searchtype=author&query=Held%2C+W">William Held</a>, 
<a href="/search/cs?searchtype=author&query=Shaikh%2C+O">Omar Shaikh</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhehao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Diyi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in "Computational Linguistics" (CL)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03907" title="Abstract">arXiv:2305.03907</a> (replaced) [<a href="/pdf/2305.03907" title="Download PDF">pdf</a>, <a href="/format/2305.03907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Listen to Look into the Future: Audio-Visual Egocentric Gaze  Anticipation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+B">Bolin Lai</a>, 
<a href="/search/cs?searchtype=author&query=Ryan%2C+F">Fiona Ryan</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+W">Wenqi Jia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Miao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Rehg%2C+J+M">James M. Rehg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04120" title="Abstract">arXiv:2305.04120</a> (replaced) [<a href="/pdf/2305.04120" title="Download PDF">pdf</a>, <a href="/format/2305.04120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Latent Diffusion Model for Protein Structure Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Fu%2C+C">Cong Fu</a>, 
<a href="/search/q-bio?searchtype=author&query=Yan%2C+K">Keqiang Yan</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+L">Limei Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Au%2C+W+Y">Wing Yee Au</a>, 
<a href="/search/q-bio?searchtype=author&query=McThrow%2C+M">Michael McThrow</a>, 
<a href="/search/q-bio?searchtype=author&query=Komikado%2C+T">Tao Komikado</a>, 
<a href="/search/q-bio?searchtype=author&query=Maruhashi%2C+K">Koji Maruhashi</a>, 
<a href="/search/q-bio?searchtype=author&query=Uchino%2C+K">Kanji Uchino</a>, 
<a href="/search/q-bio?searchtype=author&query=Qian%2C+X">Xiaoning Qian</a>, 
<a href="/search/q-bio?searchtype=author&query=Ji%2C+S">Shuiwang Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the Second Learning on Graphs Conference (LoG 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05894" title="Abstract">arXiv:2305.05894</a> (replaced) [<a href="/pdf/2305.05894" title="Download PDF">pdf</a>, <a href="/format/2305.05894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structured Kalman Filter for Time Scale Generation in Atomic Clock  Ensembles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yan%2C+Y">Yuyue Yan</a>, 
<a href="/search/eess?searchtype=author&query=Kawaguchi%2C+T">Takahiro Kawaguchi</a>, 
<a href="/search/eess?searchtype=author&query=Yano%2C+Y">Yuichiro Yano</a>, 
<a href="/search/eess?searchtype=author&query=Hanado%2C+Y">Yuko Hanado</a>, 
<a href="/search/eess?searchtype=author&query=Ishizaki%2C+T">Takayuki Ishizaki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06164" title="Abstract">arXiv:2305.06164</a> (replaced) [<a href="/pdf/2305.06164" title="Download PDF">pdf</a>, <a href="/format/2305.06164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conversational Semantic Parsing using Dynamic Context Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+P">Parag Jain</a>, 
<a href="/search/cs?searchtype=author&query=Lapata%2C+M">Mirella Lapata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> camera ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07372" title="Abstract">arXiv:2305.07372</a> (replaced) [<a href="/pdf/2305.07372" title="Download PDF">pdf</a>, <a href="/format/2305.07372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Text-to-SQL Generation via Editable Step-by-Step  Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+Z">Zheng Ning</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T+J">Toby Jia-Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Kummerfeld%2C+J+K">Jonathan K. Kummerfeld</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ARR AE score of 4
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09132" title="Abstract">arXiv:2305.09132</a> (replaced) [<a href="/pdf/2305.09132" title="Download PDF">pdf</a>, <a href="/format/2305.09132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DualGenerator: Information Interaction-based Generative Network for  Point Cloud Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+P">Pengcheng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Haozhe Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xu Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yiyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jihua Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11426" title="Abstract">arXiv:2305.11426</a> (replaced) [<a href="/pdf/2305.11426" title="Download PDF">pdf</a>, <a href="/format/2305.11426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Post Hoc Explanations of Language Models Can Improve Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krishna%2C+S">Satyapriya Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jiaqi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Slack%2C+D">Dylan Slack</a>, 
<a href="/search/cs?searchtype=author&query=Ghandeharioun%2C+A">Asma Ghandeharioun</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Sameer Singh</a>, 
<a href="/search/cs?searchtype=author&query=Lakkaraju%2C+H">Himabindu Lakkaraju</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13840" title="Abstract">arXiv:2305.13840</a> (replaced) [<a href="/pdf/2305.13840" title="Download PDF">pdf</a>, <a href="/format/2305.13840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control-A-Video: Controllable Text-to-Video Generation with Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Y">Yatai Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hefeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+P">Pan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiashi Li</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xuefeng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Liang Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16225" title="Abstract">arXiv:2305.16225</a> (replaced) [<a href="/pdf/2305.16225" title="Download PDF">pdf</a>, <a href="/format/2305.16225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProSpect: Prompt Spectrum for Attribute-Aware Personalization of  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+W">Weiming Dong</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+F">Fan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+N">Nisha Huang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haibin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chongyang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+T">Tong-Yee Lee</a>, 
<a href="/search/cs?searchtype=author&query=Deussen%2C+O">Oliver Deussen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Changsheng Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17178" title="Abstract">arXiv:2305.17178</a> (replaced) [<a href="/pdf/2305.17178" title="Download PDF">pdf</a>, <a href="/format/2305.17178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rate-Splitting Multiple Access: Finite Constellations, Receiver Design,  and SIC-free Implementation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sibo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Clerckx%2C+B">Bruno Clerckx</a>, 
<a href="/search/cs?searchtype=author&query=Vargas%2C+D">David Vargas</a>, 
<a href="/search/cs?searchtype=author&query=Haffenden%2C+O">Oliver Haffenden</a>, 
<a href="/search/cs?searchtype=author&query=Murphy%2C+A">Andrew Murphy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE for publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00245" title="Abstract">arXiv:2306.00245</a> (replaced) [<a href="/pdf/2306.00245" title="Download PDF">pdf</a>, <a href="/format/2306.00245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Pixels to UI Actions: Learning to Follow Instructions via Graphical  User Interfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaw%2C+P">Peter Shaw</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+M">Mandar Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Cohan%2C+J">James Cohan</a>, 
<a href="/search/cs?searchtype=author&query=Berant%2C+J">Jonathan Berant</a>, 
<a href="/search/cs?searchtype=author&query=Pasupat%2C+P">Panupong Pasupat</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hexiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Khandelwal%2C+U">Urvashi Khandelwal</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kenton Lee</a>, 
<a href="/search/cs?searchtype=author&query=Toutanova%2C+K">Kristina Toutanova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00857" title="Abstract">arXiv:2306.00857</a> (replaced) [<a href="/pdf/2306.00857" title="Download PDF">pdf</a>, <a href="/format/2306.00857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Loss-Optimal Classification Trees: A Generalized Framework and the  Logistic Case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Aldinucci%2C+T">Tommaso Aldinucci</a>, 
<a href="/search/stat?searchtype=author&query=Lapucci%2C+M">Matteo Lapucci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00971" title="Abstract">arXiv:2306.00971</a> (replaced) [<a href="/pdf/2306.00971" title="Download PDF">pdf</a>, <a href="/format/2306.00971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViCo: Plug-and-play Visual Condition for Personalized Text-to-image  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+S">Shaozhe Hao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kai Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shihao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K+K">Kwan-Yee K. Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03088" title="Abstract">arXiv:2306.03088</a> (replaced) [<a href="/pdf/2306.03088" title="Download PDF">pdf</a>, <a href="/format/2306.03088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepGraphDMD: Interpretable Spatio-Temporal Decomposition of Non-linear  Functional Brain Network Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Turja%2C+M+A">Md Asadullah Turja</a>, 
<a href="/search/cs?searchtype=author&query=Styner%2C+M">Martin Styner</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Guorong Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in MICCAI 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> LNCS14227(2023)358-368
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03881" title="Abstract">arXiv:2306.03881</a> (replaced) [<a href="/pdf/2306.03881" title="Download PDF">pdf</a>, <a href="/format/2306.03881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergent Correspondence from Image Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+L">Luming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+M">Menglin Jia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qianqian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Phoo%2C+C+P">Cheng Perng Phoo</a>, 
<a href="/search/cs?searchtype=author&query=Hariharan%2C+B">Bharath Hariharan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. Project page: <a href="https://diffusionfeatures.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03955" title="Abstract">arXiv:2306.03955</a> (replaced) [<a href="/pdf/2306.03955" title="Download PDF">pdf</a>, <a href="/format/2306.03955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kernel quadrature with randomly pivoted Cholesky
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Epperly%2C+E+N">Ethan N. Epperly</a>, 
<a href="/search/math?searchtype=author&query=Moreno%2C+E">Elvira Moreno</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 3 figures; NeurIPS 2023 (spotlight), camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04843" title="Abstract">arXiv:2306.04843</a> (replaced) [<a href="/pdf/2306.04843" title="Download PDF">pdf</a>, <a href="/format/2306.04843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classical Verification of Quantum Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Caro%2C+M+C">Matthias C. Caro</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hinsche%2C+M">Marcel Hinsche</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ioannou%2C+M">Marios Ioannou</a>, 
<a href="/search/quant-ph?searchtype=author&query=Nietner%2C+A">Alexander Nietner</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sweke%2C+R">Ryan Sweke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 + 46 + 23 pages, 1 table, 1 figure; V2 fixes some typos and includes new results in Section 6.3
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05566" title="Abstract">arXiv:2306.05566</a> (replaced) [<a href="/pdf/2306.05566" title="Download PDF">pdf</a>, <a href="/format/2306.05566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Adaptive Probabilistic Likelihood Approximation for Ordinary  Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wu%2C+M">Mohan Wu</a>, 
<a href="/search/stat?searchtype=author&query=Lysy%2C+M">Martin Lysy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06397" title="Abstract">arXiv:2306.06397</a> (replaced) [<a href="/pdf/2306.06397" title="Download PDF">pdf</a>, <a href="/format/2306.06397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lower-depth programmable linear optical processors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Tang%2C+R">Rui Tang</a>, 
<a href="/search/physics?searchtype=author&query=Tanomura%2C+R">Ryota Tanomura</a>, 
<a href="/search/physics?searchtype=author&query=Tanemura%2C+T">Takuo Tanemura</a>, 
<a href="/search/physics?searchtype=author&query=Nakano%2C+Y">Yoshiaki Nakano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06503" title="Abstract">arXiv:2306.06503</a> (replaced) [<a href="/pdf/2306.06503" title="Download PDF">pdf</a>, <a href="/ps/2306.06503" title="Download PostScript">ps</a>, <a href="/format/2306.06503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preserving privacy in domain transfer of medical AI models comes at no  performance costs: The integral role of differential privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arasteh%2C+S+T">Soroosh Tayebi Arasteh</a>, 
<a href="/search/cs?searchtype=author&query=Lotfinia%2C+M">Mahshad Lotfinia</a>, 
<a href="/search/cs?searchtype=author&query=Nolte%2C+T">Teresa Nolte</a>, 
<a href="/search/cs?searchtype=author&query=Saehn%2C+M">Marwin Saehn</a>, 
<a href="/search/cs?searchtype=author&query=Isfort%2C+P">Peter Isfort</a>, 
<a href="/search/cs?searchtype=author&query=Kuhl%2C+C">Christiane Kuhl</a>, 
<a href="/search/cs?searchtype=author&query=Nebelung%2C+S">Sven Nebelung</a>, 
<a href="/search/cs?searchtype=author&query=Kaissis%2C+G">Georgios Kaissis</a>, 
<a href="/search/cs?searchtype=author&query=Truhn%2C+D">Daniel Truhn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Radiology: Artificial Intelligence. RSNA
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Radiology: Artificial Intelligence, 2024, 6(1), e230212
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12816" title="Abstract">arXiv:2306.12816</a> (replaced) [<a href="/pdf/2306.12816" title="Download PDF">pdf</a>, <a href="/format/2306.12816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XAI-TRIS: Non-linear image benchmarks to quantify false positive  post-hoc attribution of feature importance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Clark%2C+B">Benedict Clark</a>, 
<a href="/search/cs?searchtype=author&query=Wilming%2C+R">Rick Wilming</a>, 
<a href="/search/cs?searchtype=author&query=Haufe%2C+S">Stefan Haufe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07569" title="Abstract">arXiv:2307.07569</a> (replaced) [<a href="/pdf/2307.07569" title="Download PDF">pdf</a>, <a href="/ps/2307.07569" title="Download PostScript">ps</a>, <a href="/format/2307.07569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orthologic with Axioms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guilloud%2C+S">Simon Guilloud</a>, 
<a href="/search/cs?searchtype=author&query=Kuncak%2C+V">Viktor Kuncak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08360" title="Abstract">arXiv:2307.08360</a> (replaced) [<a href="/pdf/2307.08360" title="Download PDF">pdf</a>, <a href="/format/2307.08360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Online Learning with Gradient Variations: A Multi-layer Online  Ensemble Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yu-Hu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Peng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhi-Hua Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08417" title="Abstract">arXiv:2307.08417</a> (replaced) [<a href="/pdf/2307.08417" title="Download PDF">pdf</a>, <a href="/format/2307.08417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Divide&amp;Classify: Fine-Grained Classification for City-Wide Visual Place  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Trivigno%2C+G">Gabriele Trivigno</a>, 
<a href="/search/cs?searchtype=author&query=Berton%2C+G">Gabriele Berton</a>, 
<a href="/search/cs?searchtype=author&query=Aragon%2C+J">Juan Aragon</a>, 
<a href="/search/cs?searchtype=author&query=Caputo%2C+B">Barbara Caputo</a>, 
<a href="/search/cs?searchtype=author&query=Masone%2C+C">Carlo Masone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08726" title="Abstract">arXiv:2307.08726</a> (replaced) [<a href="/pdf/2307.08726" title="Download PDF">pdf</a>, <a href="/ps/2307.08726" title="Download PostScript">ps</a>, <a href="/format/2307.08726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RYDE: A Digital Signature Scheme based on Rank-Syndrome-Decoding Problem  with MPCitH Paradigm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bidoux%2C+L">Lo&#xef;c Bidoux</a>, 
<a href="/search/cs?searchtype=author&query=Chi-Dom%C3%ADnguez%2C+J">Jes&#xfa;s-Javier Chi-Dom&#xed;nguez</a>, 
<a href="/search/cs?searchtype=author&query=Feneuil%2C+T">Thibauld Feneuil</a>, 
<a href="/search/cs?searchtype=author&query=Gaborit%2C+P">Philippe Gaborit</a>, 
<a href="/search/cs?searchtype=author&query=Joux%2C+A">Antoine Joux</a>, 
<a href="/search/cs?searchtype=author&query=Rivain%2C+M">Matthieu Rivain</a>, 
<a href="/search/cs?searchtype=author&query=Vin%C3%A7otte%2C+A">Adrien Vin&#xe7;otte</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2307.08575">arXiv:2307.08575</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11086" title="Abstract">arXiv:2307.11086</a> (replaced) [<a href="/pdf/2307.11086" title="Download PDF">pdf</a>, <a href="/format/2307.11086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PAPR: Proximity Attention Point Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanshu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Shichong Peng</a>, 
<a href="/search/cs?searchtype=author&query=Moazeni%2C+A">Alireza Moazeni</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Ke Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11601" title="Abstract">arXiv:2307.11601</a> (replaced) [<a href="/pdf/2307.11601" title="Download PDF">pdf</a>, <a href="/format/2307.11601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Averaged Nystr&#xf6;m interpolants for the solution of Fredholm integral  equations of the second kind
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fermo%2C+L">Luisa Fermo</a>, 
<a href="/search/math?searchtype=author&query=Reichel%2C+L">Lothar Reichel</a>, 
<a href="/search/math?searchtype=author&query=Rodriguez%2C+G">Giuseppe Rodriguez</a>, 
<a href="/search/math?searchtype=author&query=Spalevi%C4%87%2C+M+M">Miodrag M. Spalevi&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 2 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Appl. Math. Comput., 467:128482 (20 pages), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12409" title="Abstract">arXiv:2307.12409</a> (replaced) [<a href="/pdf/2307.12409" title="Download PDF">pdf</a>, <a href="/format/2307.12409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Machine Learning Approach to Two-Stage Adaptive Robust Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bertsimas%2C+D">Dimitris Bertsimas</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C+W">Cheol Woo Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13423" title="Abstract">arXiv:2307.13423</a> (replaced) [<a href="/pdf/2307.13423" title="Download PDF">pdf</a>, <a href="/format/2307.13423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non Intrusive Intelligibility Predictor for Hearing Impaired Individuals  using Self Supervised Speech Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Close%2C+G">George Close</a>, 
<a href="/search/cs?searchtype=author&query=Hain%2C+T">Thomas Hain</a>, 
<a href="/search/cs?searchtype=author&query=Goetze%2C+S">Stefan Goetze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted @ ASRU 2023 SPARKS workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14023" title="Abstract">arXiv:2307.14023</a> (replaced) [<a href="/pdf/2307.14023" title="Download PDF">pdf</a>, <a href="/format/2307.14023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Transformers with One Layer Self-Attention Using Low-Rank Weight  Matrices Universal Approximators?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kajitsuka%2C+T">Tokio Kajitsuka</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+I">Issei Sato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15250" title="Abstract">arXiv:2307.15250</a> (replaced) [<a href="/pdf/2307.15250" title="Download PDF">pdf</a>, <a href="/format/2307.15250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> D2S: Representing local descriptors and global scene coordinates for  camera relocalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bui%2C+B">Bach-Thuan Bui</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+D">Dinh-Tuan Tran</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Joo-Ho Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02205" title="Abstract">arXiv:2308.02205</a> (replaced) [<a href="/pdf/2308.02205" title="Download PDF">pdf</a>, <a href="/format/2308.02205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GEMRec: Towards Generative Model Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuanhe Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haoming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Hongyi Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WSDM 2024 (Demo Track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05335" title="Abstract">arXiv:2308.05335</a> (replaced) [<a href="/pdf/2308.05335" title="Download PDF">pdf</a>, <a href="/format/2308.05335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Match-based solution of general parametric eigenvalue problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pradovera%2C+D">Davide Pradovera</a>, 
<a href="/search/math?searchtype=author&query=Borghi%2C+A">Alessandro Borghi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06605" title="Abstract">arXiv:2308.06605</a> (replaced) [<a href="/pdf/2308.06605" title="Download PDF">pdf</a>, <a href="/format/2308.06605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Exascale Computation for Turbomachinery Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yuhang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Weiqi Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jiahuan Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guangwen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jifa Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+T">Tingwei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+F">Fangfang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+X">Xiaojing Lv</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hanyue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xiaoyu Song</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+G">Guocheng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Tucker%2C+P">Paul Tucker</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+S+A+E">Steven A.E. Miller</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Shirui Luo</a>, 
<a href="/search/cs?searchtype=author&query=Koric%2C+S">Seid Koric</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Weimin Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SC23, November, 2023, Denver, CO., USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09778" title="Abstract">arXiv:2308.09778</a> (replaced) [<a href="/pdf/2308.09778" title="Download PDF">pdf</a>, <a href="/format/2308.09778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Grounded Visual Spatial Reasoning in Multi-Modal Vision Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajabi%2C+N">Navid Rajabi</a>, 
<a href="/search/cs?searchtype=author&query=Kosecka%2C+J">Jana Kosecka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10158" title="Abstract">arXiv:2308.10158</a> (replaced) [<a href="/pdf/2308.10158" title="Download PDF">pdf</a>, <a href="/format/2308.10158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HODN: Disentangling Human-Object Feature for HOI Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+S">Shuman Fang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhiwen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+K">Ke Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jie Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xianming Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+R">Rongrong Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TMM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00269" title="Abstract">arXiv:2309.00269</a> (replaced) [<a href="/pdf/2309.00269" title="Download PDF">pdf</a>, <a href="/format/2309.00269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Co-Tuning of Cloud Infrastructure and Distributed Data Processing  Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dharmadasa%2C+I">Isuru Dharmadasa</a>, 
<a href="/search/cs?searchtype=author&query=Ullah%2C+F">Faheem Ullah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00605" title="Abstract">arXiv:2309.00605</a> (replaced) [<a href="/pdf/2309.00605" title="Download PDF">pdf</a>, <a href="/format/2309.00605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A decoupled, convergent and fully linear algorithm for the  Landau--Lifshitz--Gilbert equation with magnetoelastic effects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Normington%2C+H">Hywel Normington</a>, 
<a href="/search/math?searchtype=author&query=Ruggeri%2C+M">Michele Ruggeri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 7 figures Updated acknowledgements
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00931" title="Abstract">arXiv:2309.00931</a> (replaced) [<a href="/pdf/2309.00931" title="Download PDF">pdf</a>, <a href="/format/2309.00931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Parametric Finite-Element Discretization of the Surface Stokes  Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hardering%2C+H">Hanne Hardering</a>, 
<a href="/search/math?searchtype=author&query=Praetorius%2C+S">Simon Praetorius</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01860" title="Abstract">arXiv:2309.01860</a> (replaced) [<a href="/pdf/2309.01860" title="Download PDF">pdf</a>, <a href="/format/2309.01860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-Driven Multi-Modal Fusion: Enhancing Sign Language Recognition  and Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hakim%2C+Z+I+A">Zaber Ibn Abdul Hakim</a>, 
<a href="/search/cs?searchtype=author&query=Swargo%2C+R+M">Rasman Mubtasim Swargo</a>, 
<a href="/search/cs?searchtype=author&query=Adnan%2C+M+A">Muhammad Abdullah Adnan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03409" title="Abstract">arXiv:2309.03409</a> (replaced) [<a href="/pdf/2309.03409" title="Download PDF">pdf</a>, <a href="/format/2309.03409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models as Optimizers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chengrun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuezhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yifeng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hanxiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+Q+V">Quoc V. Le</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Denny Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 26 figures, 15 tables. Code at <a href="https://github.com/google-deepmind/opro">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03755" title="Abstract">arXiv:2309.03755</a> (replaced) [<a href="/pdf/2309.03755" title="Download PDF">pdf</a>, <a href="/format/2309.03755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TSGBench: Time Series Generation Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ang%2C+Y">Yihao Ang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+Y">Yifan Bao</a>, 
<a href="/search/cs?searchtype=author&query=Tung%2C+A+K+H">Anthony K. H. Tung</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhiyong Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted and to appear in VLDB 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04551" title="Abstract">arXiv:2309.04551</a> (replaced) [<a href="/pdf/2309.04551" title="Download PDF">pdf</a>, <a href="/ps/2309.04551" title="Download PostScript">ps</a>, <a href="/format/2309.04551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recursive Error Reduction for Regular Branching Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chattopadhyay%2C+E">Eshan Chattopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+J">Jyun-Jie Liao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06240" title="Abstract">arXiv:2309.06240</a> (replaced) [<a href="/pdf/2309.06240" title="Download PDF">pdf</a>, <a href="/ps/2309.06240" title="Download PostScript">ps</a>, <a href="/format/2309.06240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calibration in Machine Learning Uncertainty Quantification: beyond  consistency to target adaptivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Pernot%2C+P">Pascal Pernot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2303.07170">arXiv:2303.07170</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Chemical Physics (physics.chem-ph); Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07311" title="Abstract">arXiv:2309.07311</a> (replaced) [<a href="/pdf/2309.07311" title="Download PDF">pdf</a>, <a href="/format/2309.07311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and  Simplicity Bias in MLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Angelica Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shwartz-Ziv%2C+R">Ravid Shwartz-Ziv</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+K">Kyunghyun Cho</a>, 
<a href="/search/cs?searchtype=author&query=Leavitt%2C+M+L">Matthew L. Leavitt</a>, 
<a href="/search/cs?searchtype=author&query=Saphra%2C+N">Naomi Saphra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08967" title="Abstract">arXiv:2309.08967</a> (replaced) [<a href="/pdf/2309.08967" title="Download PDF">pdf</a>, <a href="/format/2309.08967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Recommendation Systems on Opinion Dynamics: Microscopic  versus Macroscopic Effects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lanzetti%2C+N">Nicolas Lanzetti</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%B6rfler%2C+F">Florian D&#xf6;rfler</a>, 
<a href="/search/cs?searchtype=author&query=Pagan%2C+N">Nicol&#xf2; Pagan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at, and publication in the proceedings of, the 62nd IEEE Conference on Decision and Control
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10286" title="Abstract">arXiv:2309.10286</a> (replaced) [<a href="/pdf/2309.10286" title="Download PDF">pdf</a>, <a href="/ps/2309.10286" title="Download PostScript">ps</a>, <a href="/format/2309.10286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A tight lower bound on non-adaptive group testing estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bshouty%2C+N+H">Nader H. Bshouty</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+T">Tsun-Ming Cheung</a>, 
<a href="/search/cs?searchtype=author&query=Harcos%2C+G">Gergely Harcos</a>, 
<a href="/search/cs?searchtype=author&query=Hatami%2C+H">Hamed Hatami</a>, 
<a href="/search/cs?searchtype=author&query=Ostuni%2C+A">Anthony Ostuni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is a merger of <a href="/abs/2309.09613">arXiv:2309.09613</a> and <a href="/abs/2309.10286">arXiv:2309.10286</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11783" title="Abstract">arXiv:2309.11783</a> (replaced) [<a href="/pdf/2309.11783" title="Download PDF">pdf</a>, <a href="/format/2309.11783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frame Pairwise Distance Loss for Weakly-supervised Sound Event Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+R">Rui Tao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuxing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiangdong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Long Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+L">Lufeng Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Ouchi%2C+K">Kazushige Ouchi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Taihao Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15311" title="Abstract">arXiv:2309.15311</a> (replaced) [<a href="/pdf/2309.15311" title="Download PDF">pdf</a>, <a href="/format/2309.15311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Importance of Multimodal Emotion Conditioning and Affect Consistency  for Embodied Conversational Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Che-Jui Chang</a>, 
<a href="/search/cs?searchtype=author&query=Sohn%2C+S+S">Samuel S. Sohn</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jayashankar%2C+R">Rajath Jayashankar</a>, 
<a href="/search/cs?searchtype=author&query=Usman%2C+M">Muhammad Usman</a>, 
<a href="/search/cs?searchtype=author&query=Kapadia%2C+M">Mubbasir Kapadia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01441" title="Abstract">arXiv:2310.01441</a> (replaced) [<a href="/pdf/2310.01441" title="Download PDF">pdf</a>, <a href="/format/2310.01441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UPAR: A Kantian-Inspired Prompting Framework for Enhancing Large  Language Model Capabilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geng%2C+H">Hejia Geng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Boxun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02074" title="Abstract">arXiv:2310.02074</a> (replaced) [<a href="/pdf/2310.02074" title="Download PDF">pdf</a>, <a href="/format/2310.02074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ACE: A fast, skillful learned global atmospheric model for climate  prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Watt-Meyer%2C+O">Oliver Watt-Meyer</a>, 
<a href="/search/physics?searchtype=author&query=Dresdner%2C+G">Gideon Dresdner</a>, 
<a href="/search/physics?searchtype=author&query=McGibbon%2C+J">Jeremy McGibbon</a>, 
<a href="/search/physics?searchtype=author&query=Clark%2C+S+K">Spencer K. Clark</a>, 
<a href="/search/physics?searchtype=author&query=Henn%2C+B">Brian Henn</a>, 
<a href="/search/physics?searchtype=author&query=Duncan%2C+J">James Duncan</a>, 
<a href="/search/physics?searchtype=author&query=Brenowitz%2C+N+D">Noah D. Brenowitz</a>, 
<a href="/search/physics?searchtype=author&query=Kashinath%2C+K">Karthik Kashinath</a>, 
<a href="/search/physics?searchtype=author&query=Pritchard%2C+M+S">Michael S. Pritchard</a>, 
<a href="/search/physics?searchtype=author&query=Bonev%2C+B">Boris Bonev</a>, 
<a href="/search/physics?searchtype=author&query=Peters%2C+M+E">Matthew E. Peters</a>, 
<a href="/search/physics?searchtype=author&query=Bretherton%2C+C+S">Christopher S. Bretherton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Tackling Climate Change with Machine Learning: workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02298" title="Abstract">arXiv:2310.02298</a> (replaced) [<a href="/pdf/2310.02298" title="Download PDF">pdf</a>, <a href="/format/2310.02298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompting Audios Using Acoustic Properties For Emotion Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhamyal%2C+H">Hira Dhamyal</a>, 
<a href="/search/cs?searchtype=author&query=Elizalde%2C+B">Benjamin Elizalde</a>, 
<a href="/search/cs?searchtype=author&query=Deshmukh%2C+S">Soham Deshmukh</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huaming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Raj%2C+B">Bhiksha Raj</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+R">Rita Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2211.07737">arXiv:2211.07737</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02437" title="Abstract">arXiv:2310.02437</a> (replaced) [<a href="/pdf/2310.02437" title="Download PDF">pdf</a>, <a href="/format/2310.02437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EvDNeRF: Reconstructing Event Data with Dynamic Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+A">Anish Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Madaan%2C+R">Ratnesh Madaan</a>, 
<a href="/search/cs?searchtype=author&query=Cladera%2C+F">Fernando Cladera</a>, 
<a href="/search/cs?searchtype=author&query=Vemprala%2C+S">Sai Vemprala</a>, 
<a href="/search/cs?searchtype=author&query=Bonatti%2C+R">Rogerio Bonatti</a>, 
<a href="/search/cs?searchtype=author&query=Daniilidis%2C+K">Kostas Daniilidis</a>, 
<a href="/search/cs?searchtype=author&query=Kapoor%2C+A">Ashish Kapoor</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vijay Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Matni%2C+N">Nikolai Matni</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+J+K">Jayesh K. Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 20 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02563" title="Abstract">arXiv:2310.02563</a> (replaced) [<a href="/pdf/2310.02563" title="Download PDF">pdf</a>, <a href="/format/2310.02563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Practical, Private Assurance of the Value of Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Asghar%2C+H+J">Hassan Jameel Asghar</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhigang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhongrui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Kaafar%2C+D">Dali Kaafar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04589" title="Abstract">arXiv:2310.04589</a> (replaced) [<a href="/pdf/2310.04589" title="Download PDF">pdf</a>, <a href="/format/2310.04589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shufflecake: Plausible Deniability for Multiple Hidden Filesystems on  Linux
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anzuoni%2C+E">Elia Anzuoni</a>, 
<a href="/search/cs?searchtype=author&query=Gagliardoni%2C+T">Tommaso Gagliardoni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A 15-page abstract of this work appears (with the same title) in the proceedings of the ACM Conference on Computer and Communications Security (CCS) 2023. This is the authors' full version. This revision date: 2023-12-07. This document supersedes any previous versions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04856" title="Abstract">arXiv:2310.04856</a> (replaced) [<a href="/pdf/2310.04856" title="Download PDF">pdf</a>, <a href="/format/2310.04856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LIPEx-Locally Interpretable Probabilistic Explanations-To Look Beyond  The True Class
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hongbo Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Cangelosi%2C+A">Angelo Cangelosi</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+P">Procheta Sen</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+A">Anirbit Mukherjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05140" title="Abstract">arXiv:2310.05140</a> (replaced) [<a href="/pdf/2310.05140" title="Download PDF">pdf</a>, <a href="/format/2310.05140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing the Power of Large Language Models for Empathetic Response  Generation: Empirical Investigations and Improvements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yushan Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei-Nan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> the Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05470" title="Abstract">arXiv:2310.05470</a> (replaced) [<a href="/pdf/2310.05470" title="Download PDF">pdf</a>, <a href="/format/2310.05470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Judge for Evaluating Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junlong Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Weizhe Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+R">Run-Ze Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Pengfei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fix typos in Table 1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06641" title="Abstract">arXiv:2310.06641</a> (replaced) [<a href="/pdf/2310.06641" title="Download PDF">pdf</a>, <a href="/format/2310.06641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How (not) to ensemble LVLMs for VQA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alazraki%2C+L">Lisa Alazraki</a>, 
<a href="/search/cs?searchtype=author&query=Castrejon%2C+L">Lluis Castrejon</a>, 
<a href="/search/cs?searchtype=author&query=Dehghani%2C+M">Mostafa Dehghani</a>, 
<a href="/search/cs?searchtype=author&query=Huot%2C+F">Fantine Huot</a>, 
<a href="/search/cs?searchtype=author&query=Uijlings%2C+J">Jasper Uijlings</a>, 
<a href="/search/cs?searchtype=author&query=Mensink%2C+T">Thomas Mensink</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4th I Can't Believe It's Not Better Workshop (co-located with NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06725" title="Abstract">arXiv:2310.06725</a> (replaced) [<a href="/pdf/2310.06725" title="Download PDF">pdf</a>, <a href="/format/2310.06725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Growing ecosystem of deep learning methods for modeling  protein$\unicode{x2013}$protein interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Rogers%2C+J+R">Julia R. Rogers</a>, 
<a href="/search/q-bio?searchtype=author&query=Nikol%C3%A9nyi%2C+G">Gerg&#x151; Nikol&#xe9;nyi</a>, 
<a href="/search/q-bio?searchtype=author&query=AlQuraishi%2C+M">Mohammed AlQuraishi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, added model names to discussion
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08224" title="Abstract">arXiv:2310.08224</a> (replaced) [<a href="/pdf/2310.08224" title="Download PDF">pdf</a>, <a href="/format/2310.08224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergence of Latent Binary Encoding in Deep Neural Network Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sbail%C3%B2%2C+L">Luigi Sbail&#xf2;</a>, 
<a href="/search/cs?searchtype=author&query=Ghiringhelli%2C+L">Luca Ghiringhelli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08412" title="Abstract">arXiv:2310.08412</a> (replaced) [<a href="/pdf/2310.08412" title="Download PDF">pdf</a>, <a href="/format/2310.08412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Sound and Complete Refinement Relation for Non-reducible Modal  Transition Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Basile%2C+D">Davide Basile</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08528" title="Abstract">arXiv:2310.08528</a> (replaced) [<a href="/pdf/2310.08528" title="Download PDF">pdf</a>, <a href="/format/2310.08528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 4D Gaussian Splatting for Real-Time Dynamic Scene Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Guanjun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+T">Taoran Yi</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Jiemin Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lingxi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaopeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qi Tian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinggang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://guanjunwu.github.io/4dgs/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09078" title="Abstract">arXiv:2310.09078</a> (replaced) [<a href="/pdf/2310.09078" title="Download PDF">pdf</a>, <a href="/format/2310.09078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DNFS-VNE: Deep Neuro Fuzzy System Driven Virtual Network Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+A">Ailing Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Ning Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Sheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peiying Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Suzhi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chunxiao Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09819" title="Abstract">arXiv:2310.09819</a> (replaced) [<a href="/pdf/2310.09819" title="Download PDF">pdf</a>, <a href="/format/2310.09819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing K-means for Big Data: A Comparative Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mussabayev%2C+R">Ravil Mussabayev</a>, 
<a href="/search/cs?searchtype=author&query=Mussabayev%2C+R">Rustam Mussabayev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11616" title="Abstract">arXiv:2310.11616</a> (replaced) [<a href="/pdf/2310.11616" title="Download PDF">pdf</a>, <a href="/format/2310.11616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling the General Intelligence Factor in Language Models: A  Psychometric Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ili%C4%87%2C+D">David Ili&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages (including appendix), 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13255" title="Abstract">arXiv:2310.13255</a> (replaced) [<a href="/pdf/2310.13255" title="Download PDF">pdf</a>, <a href="/format/2310.13255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Steve-Eye: Equipping LLM-based Embodied Agents with Visual Perception in  Open Worlds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Sipeng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiazheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yicheng Feng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zongqing Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13355" title="Abstract">arXiv:2310.13355</a> (replaced) [<a href="/pdf/2310.13355" title="Download PDF">pdf</a>, <a href="/format/2310.13355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SILC: Improving Vision Language Pretraining with Self-Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naeem%2C+M+F">Muhammad Ferjad Naeem</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+Y">Yongqin Xian</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaohua Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Hoyer%2C+L">Lukas Hoyer</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>, 
<a href="/search/cs?searchtype=author&query=Tombari%2C+F">Federico Tombari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14281" title="Abstract">arXiv:2310.14281</a> (replaced) [<a href="/pdf/2310.14281" title="Download PDF">pdf</a>, <a href="/ps/2310.14281" title="Download PostScript">ps</a>, <a href="/format/2310.14281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $t$-designs obtained from two shells and exceptional examples of them
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Awada%2C+M">Madoka Awada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages. arXiv admin note: text overlap with <a href="/abs/2309.03206">arXiv:2309.03206</a>; text overlap with <a href="/abs/2305.03285">arXiv:2305.03285</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Information Theory (cs.IT); Group Theory (math.GR); Number Theory (math.NT)

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14580" title="Abstract">arXiv:2310.14580</a> (replaced) [<a href="/pdf/2310.14580" title="Download PDF">pdf</a>, <a href="/format/2310.14580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Acoustic BPE for Speech Generation with Discrete Tokens
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+F">Feiyu Shen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yiwei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+C">Chenpeng Du</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kai Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures; submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14702" title="Abstract">arXiv:2310.14702</a> (replaced) [<a href="/pdf/2310.14702" title="Download PDF">pdf</a>, <a href="/format/2310.14702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BM2CP: Efficient Collaborative Perception with LiDAR-Camera Modalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Binyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Z">Zhaonian Zou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures. Accepted by CoRL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15911" title="Abstract">arXiv:2310.15911</a> (replaced) [<a href="/pdf/2310.15911" title="Download PDF">pdf</a>, <a href="/format/2310.15911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Beam Allocations through Reconfigurable Intelligent Surfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xiong%2C+R">Rujing Xiong</a>, 
<a href="/search/eess?searchtype=author&query=Yin%2C+K">Ke Yin</a>, 
<a href="/search/eess?searchtype=author&query=Mi%2C+T">Tiebin Mi</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+J">Jialong Lu</a>, 
<a href="/search/eess?searchtype=author&query=Wan%2C+K">Kai Wan</a>, 
<a href="/search/eess?searchtype=author&query=Qiu%2C+R+C">Robert Caiming Qiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16136" title="Abstract">arXiv:2310.16136</a> (replaced) [<a href="/pdf/2310.16136" title="Download PDF">pdf</a>, <a href="/format/2310.16136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Disparity and Temporal Progression of Internet Quality through  Crowdsourced Measurements with Bias-Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Lee%2C+H">Hyeongseong Lee</a>, 
<a href="/search/stat?searchtype=author&query=Paul%2C+U">Udit Paul</a>, 
<a href="/search/stat?searchtype=author&query=Gupta%2C+A">Arpit Gupta</a>, 
<a href="/search/stat?searchtype=author&query=Belding%2C+E">Elizabeth Belding</a>, 
<a href="/search/stat?searchtype=author&query=Gu%2C+M">Mengyang Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16427" title="Abstract">arXiv:2310.16427</a> (replaced) [<a href="/pdf/2310.16427" title="Download PDF">pdf</a>, <a href="/format/2310.16427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PromptAgent: Strategic Planning with Language Models Enables  Expert-level Prompt Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenxi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+F">Fan Bai</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haotian Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiayou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jojic%2C+N">Nebojsa Jojic</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+E+P">Eric P. Xing</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhiting Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18805" title="Abstract">arXiv:2310.18805</a> (replaced) [<a href="/pdf/2310.18805" title="Download PDF">pdf</a>, <a href="/format/2310.18805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inverse distance weighting attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McCarter%2C+C">Calvin McCarter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Associative Memory &amp; Hopfield Networks Workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19784" title="Abstract">arXiv:2310.19784</a> (replaced) [<a href="/pdf/2310.19784" title="Download PDF">pdf</a>, <a href="/format/2310.19784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CustomNet: Zero-shot Object Customization with Variable-Viewpoints in  Text-to-Image Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Ziyang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+M">Mingdeng Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xintao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zhongang Qi</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chun Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project webpage available at <a href="https://jiangyzy.github.io/CustomNet/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00502" title="Abstract">arXiv:2311.00502</a> (replaced) [<a href="/pdf/2311.00502" title="Download PDF">pdf</a>, <a href="/format/2311.00502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient LLM Inference on CPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Haihao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">Hanwen Chang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+B">Bo Dong</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+H">Hengyu Meng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS'2023 on Efficient Natural Language and Speech Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00519" title="Abstract">arXiv:2311.00519</a> (replaced) [<a href="/pdf/2311.00519" title="Download PDF">pdf</a>, <a href="/format/2311.00519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval-Based Reconstruction For Time-series Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+M+A">Maxwell A. Xu</a>, 
<a href="/search/cs?searchtype=author&query=Moreno%2C+A">Alexander Moreno</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Hui Wei</a>, 
<a href="/search/cs?searchtype=author&query=Marlin%2C+B+M">Benjamin M. Marlin</a>, 
<a href="/search/cs?searchtype=author&query=Rehg%2C+J+M">James M. Rehg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00979" title="Abstract">arXiv:2311.00979</a> (replaced) [<a href="/pdf/2311.00979" title="Download PDF">pdf</a>, <a href="/ps/2311.00979" title="Download PostScript">ps</a>, <a href="/format/2311.00979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overhead Line Defect Recognition Based on Unsupervised Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weixi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+X">Xichen Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sizhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xun Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02183" title="Abstract">arXiv:2311.02183</a> (replaced) [<a href="/pdf/2311.02183" title="Download PDF">pdf</a>, <a href="/format/2311.02183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Fine-grained Alignment Method for Image-text Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03518" title="Abstract">arXiv:2311.03518</a> (replaced) [<a href="/pdf/2311.03518" title="Download PDF">pdf</a>, <a href="/ps/2311.03518" title="Download PostScript">ps</a>, <a href="/format/2311.03518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-resolution power equipment recognition based on improved  self-attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Siyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xin Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhen Wei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sizhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xun Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04092" title="Abstract">arXiv:2311.04092</a> (replaced) [<a href="/pdf/2311.04092" title="Download PDF">pdf</a>, <a href="/format/2311.04092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solvable Polynomial Ideals: The Ideal Reflection for Program Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cyphert%2C+J">John Cyphert</a>, 
<a href="/search/cs?searchtype=author&query=Kincaid%2C+Z">Zachary Kincaid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Long version of an article to appear at the 51st ACM SIGPLAN Symposium on Principles of Programming Languages (POPL 2024). This version is a replacement of an earlier long version where typos have been fixed, DOI's have been added to references when able, and a data availability statement has been added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04464" title="Abstract">arXiv:2311.04464</a> (replaced) [<a href="/pdf/2311.04464" title="Download PDF">pdf</a>, <a href="/format/2311.04464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Few-shot CLIP with Semantic-Aware Fine-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuefeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+X">Xiaofeng Mao</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xiu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhigang Li</a>, 
<a href="/search/cs?searchtype=author&query=lu%2C+W">Wang lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jindong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xiangyang Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05587" title="Abstract">arXiv:2311.05587</a> (replaced) [<a href="/pdf/2311.05587" title="Download PDF">pdf</a>, <a href="/ps/2311.05587" title="Download PostScript">ps</a>, <a href="/format/2311.05587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Methods for Media Mix Modelling with shape and funnel effects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marin%2C+J">Javier Marin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Rev. 3, December 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05876" title="Abstract">arXiv:2311.05876</a> (replaced) [<a href="/pdf/2311.05876" title="Download PDF">pdf</a>, <a href="/format/2311.05876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trends in Integration of Knowledge and Large Language Models: A Survey  and Taxonomy of Methods, Benchmarks, and Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhangyin Feng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Weitao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Weijiang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haotian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qianglong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Weihua Peng</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xiaocheng Feng</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+B">Bing Qin</a>, 
<a href="/search/cs?searchtype=author&query=liu%2C+T">Ting liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress; 22 pages. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07625" title="Abstract">arXiv:2311.07625</a> (replaced) [<a href="/pdf/2311.07625" title="Download PDF">pdf</a>, <a href="/ps/2311.07625" title="Download PostScript">ps</a>, <a href="/format/2311.07625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Activity Sparsity Complements Weight Sparsity for Efficient RNN  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mukherji%2C+R">Rishav Mukherji</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6ne%2C+M">Mark Sch&#xf6;ne</a>, 
<a href="/search/cs?searchtype=author&query=Nazeer%2C+K+K">Khaleelulla Khan Nazeer</a>, 
<a href="/search/cs?searchtype=author&query=Mayr%2C+C">Christian Mayr</a>, 
<a href="/search/cs?searchtype=author&query=Subramoney%2C+A">Anand Subramoney</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the First MLNCP Workshop @ NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07956" title="Abstract">arXiv:2311.07956</a> (replaced) [<a href="/pdf/2311.07956" title="Download PDF">pdf</a>, <a href="/ps/2311.07956" title="Download PostScript">ps</a>, <a href="/format/2311.07956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Learning Based Condition Diagnosis Method for Distribution  Network Switchgear
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+W">Wenxi Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zhe Li</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+W">Weixi Li</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+W">Weisi Ma</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xinyi Chen</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Sizhe Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08684" title="Abstract">arXiv:2311.08684</a> (replaced) [<a href="/pdf/2311.08684" title="Download PDF">pdf</a>, <a href="/ps/2311.08684" title="Download PostScript">ps</a>, <a href="/format/2311.08684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Moonrise: Novel and Cartoon Writing System Built Upon Blockchain Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09200" title="Abstract">arXiv:2311.09200</a> (replaced) [<a href="/pdf/2311.09200" title="Download PDF">pdf</a>, <a href="/format/2311.09200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ExpM+NF Tractable Exponential Mechanism via Normalizing Flow, A Path  through the Accuracy-Privacy Ceiling Constraining Differentially Private ML
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bridges%2C+R+A">Robert A. Bridges</a>, 
<a href="/search/stat?searchtype=author&query=Tombs%2C+V+J">Vandy J. Tombs</a>, 
<a href="/search/stat?searchtype=author&query=Stanley%2C+C+B">Christopher B. Stanley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09257" title="Abstract">arXiv:2311.09257</a> (replaced) [<a href="/pdf/2311.09257" title="Download PDF">pdf</a>, <a href="/format/2311.09257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UFOGen: You Forward Once Large Scale Text-to-Image Generation via  Diffusion GANs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yanwu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zhisheng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+T">Tingbo Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11579" title="Abstract">arXiv:2311.11579</a> (replaced) [<a href="/pdf/2311.11579" title="Download PDF">pdf</a>, <a href="/ps/2311.11579" title="Download PostScript">ps</a>, <a href="/format/2311.11579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilevel Picard approximations overcome the curse of dimensionality in  the numerical approximation of general semilinear PDEs with  gradient-dependent nonlinearities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Neufeld%2C+A">Ariel Neufeld</a>, 
<a href="/search/math?searchtype=author&query=Nguyen%2C+T+A">Tuan Anh Nguyen</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+S">Sizhou Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11642" title="Abstract">arXiv:2311.11642</a> (replaced) [<a href="/pdf/2311.11642" title="Download PDF">pdf</a>, <a href="/format/2311.11642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video Face Re-Aging: Toward Temporally Consistent Face Re-Aging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muqeet%2C+A">Abdul Muqeet</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kyuchul Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Bumsoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yohan Hong</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hyungrae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+W">Woonggon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">KwangHee Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, 4 tables, Project page: <a href="https://video-reaging.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12961" title="Abstract">arXiv:2311.12961</a> (replaced) [<a href="/pdf/2311.12961" title="Download PDF">pdf</a>, <a href="/format/2311.12961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demystifying Digital Twin Buzzword: A Novel Generic Evaluation Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Araghi%2C+S+N">Sina Namaki Araghi</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+A">Arkopaul Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Karray%2C+M+H">Mohamed Hedi Karray</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a draft of the article that subject to future change and correction
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13060" title="Abstract">arXiv:2311.13060</a> (replaced) [<a href="/pdf/2311.13060" title="Download PDF">pdf</a>, <a href="/format/2311.13060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training Deep 3D Convolutional Neural Networks to Extract BSM Physics  Parameters Directly from HEP Data: a Proof-of-Concept Study Using Monte Carlo  Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ex?searchtype=author&query=Dubey%2C+S">S. Dubey</a>, 
<a href="/search/hep-ex?searchtype=author&query=Browder%2C+T+E">T.E. Browder</a>, 
<a href="/search/hep-ex?searchtype=author&query=Kohani%2C+S">S.Kohani</a>, 
<a href="/search/hep-ex?searchtype=author&query=Mandal%2C+R">R. Mandal</a>, 
<a href="/search/hep-ex?searchtype=author&query=Sibidanov%2C+A">A. Sibidanov</a>, 
<a href="/search/hep-ex?searchtype=author&query=Sinha%2C+R">R. Sinha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Experiment (hep-ex)</span>; Machine Learning (cs.LG); High Energy Physics - Phenomenology (hep-ph)

</div>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13434" title="Abstract">arXiv:2311.13434</a> (replaced) [<a href="/pdf/2311.13434" title="Download PDF">pdf</a>, <a href="/ps/2311.13434" title="Download PostScript">ps</a>, <a href="/format/2311.13434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recurrent neural networks and transfer learning for elasto-plasticity in  woven composites
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Ghane%2C+E">Ehsan Ghane</a>, 
<a href="/search/cond-mat?searchtype=author&query=Fagerstr%C3%B6m%2C+M">Martin Fagerstr&#xf6;m</a>, 
<a href="/search/cond-mat?searchtype=author&query=Mirkhalaf%2C+M">Mohsen Mirkhalaf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> There are 25 pages and 13 EPS images. The paper includes links to supporting materials
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13694" title="Abstract">arXiv:2311.13694</a> (replaced) [<a href="/pdf/2311.13694" title="Download PDF">pdf</a>, <a href="/ps/2311.13694" title="Download PostScript">ps</a>, <a href="/format/2311.13694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Limit Distribution Theory for Quantum Divergences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Sreekumar%2C+S">Sreejith Sreekumar</a>, 
<a href="/search/quant-ph?searchtype=author&query=Berta%2C+M">Mario Berta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13+28 pages. v2:tomography results only for multi-qubit states; added content on infinite-dimensional systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14388" title="Abstract">arXiv:2311.14388</a> (replaced) [<a href="/pdf/2311.14388" title="Download PDF">pdf</a>, <a href="/format/2311.14388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Parameterized Generative Adversarial Network Using Cyclic Projection  for Explainable Medical Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+X">Xiangyu Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yue Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaohong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+C">Chan-Tong Lam</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+T">Tong Tong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Q">Qinquan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+W">Wei Ke</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+T">Tao Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14540" title="Abstract">arXiv:2311.14540</a> (replaced) [<a href="/pdf/2311.14540" title="Download PDF">pdf</a>, <a href="/format/2311.14540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RDF Stream Taxonomy: Systematizing RDF Stream Types in Research and  Practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sowinski%2C+P">Piotr Sowinski</a>, 
<a href="/search/cs?searchtype=author&query=Szmeja%2C+P">Pawel Szmeja</a>, 
<a href="/search/cs?searchtype=author&query=Ganzha%2C+M">Maria Ganzha</a>, 
<a href="/search/cs?searchtype=author&query=Paprzycki%2C+M">Marcin Paprzycki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15095" title="Abstract">arXiv:2311.15095</a> (replaced) [<a href="/pdf/2311.15095" title="Download PDF">pdf</a>, <a href="/format/2311.15095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active disturbance rejection control for unmanned tracked vehicles in  leader-follower scenarios: discrete-time implementation and field test  validation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Amokrane%2C+S">Salem-Bilal Amokrane</a>, 
<a href="/search/eess?searchtype=author&query=Laidouni%2C+M+Z">Mohammed Zouaoui Laidouni</a>, 
<a href="/search/eess?searchtype=author&query=Adli%2C+T">Touati Adli</a>, 
<a href="/search/eess?searchtype=author&query=Madonski%2C+R">Rafal Madonski</a>, 
<a href="/search/eess?searchtype=author&query=Stankovi%C4%87%2C+M">Momir Stankovi&#x107;</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Mechatronics 97 (2024) 103114
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15327" title="Abstract">arXiv:2311.15327</a> (replaced) [<a href="/pdf/2311.15327" title="Download PDF">pdf</a>, <a href="/ps/2311.15327" title="Download PostScript">ps</a>, <a href="/format/2311.15327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FRAC-Q-Learning: A Reinforcement Learning with Boredom Avoidance  Processes for Social Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Onishi%2C+A">Akinari Onishi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15549" title="Abstract">arXiv:2311.15549</a> (replaced) [<a href="/pdf/2311.15549" title="Download PDF">pdf</a>, <a href="/ps/2311.15549" title="Download PostScript">ps</a>, <a href="/format/2311.15549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Prediction to Action: Critical Role of Performance Estimation for  Machine-Learning-Driven Materials Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Boley%2C+M">Mario Boley</a>, 
<a href="/search/cond-mat?searchtype=author&query=Luong%2C+F">Felix Luong</a>, 
<a href="/search/cond-mat?searchtype=author&query=Teshuva%2C+S">Simon Teshuva</a>, 
<a href="/search/cond-mat?searchtype=author&query=Schmidt%2C+D+F">Daniel F Schmidt</a>, 
<a href="/search/cond-mat?searchtype=author&query=Foppa%2C+L">Lucas Foppa</a>, 
<a href="/search/cond-mat?searchtype=author&query=Scheffler%2C+M">Matthias Scheffler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Simplified notation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15683" title="Abstract">arXiv:2311.15683</a> (replaced) [<a href="/pdf/2311.15683" title="Download PDF">pdf</a>, <a href="/ps/2311.15683" title="Download PostScript">ps</a>, <a href="/format/2311.15683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultrasensitive Textile Strain Sensors Redefine Wearable Silent Speech  Interfaces with High Machine Learning Efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tang%2C+C">Chenyu Tang</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+M">Muzi Xu</a>, 
<a href="/search/eess?searchtype=author&query=Yi%2C+W">Wentian Yi</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Zibo Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Occhipinti%2C+E">Edoardo Occhipinti</a>, 
<a href="/search/eess?searchtype=author&query=Dong%2C+C">Chaoqun Dong</a>, 
<a href="/search/eess?searchtype=author&query=Ravenscroft%2C+D">Dafydd Ravenscroft</a>, 
<a href="/search/eess?searchtype=author&query=Jung%2C+S">Sung-Min Jung</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+S">Sanghyo Lee</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+S">Shuo Gao</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+J+M">Jong Min Kim</a>, 
<a href="/search/eess?searchtype=author&query=Occhipinti%2C+L+G">Luigi G. Occhipinti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 figures in the article; 11 figures and 4 tables in supplementary information
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16057" title="Abstract">arXiv:2311.16057</a> (replaced) [<a href="/pdf/2311.16057" title="Download PDF">pdf</a>, <a href="/ps/2311.16057" title="Download PostScript">ps</a>, <a href="/format/2311.16057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Power of Adaptivity in Quantum Query Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Girish%2C+U">Uma Girish</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sinha%2C+M">Makrand Sinha</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tal%2C+A">Avishay Tal</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wu%2C+K">Kewen Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16447" title="Abstract">arXiv:2311.16447</a> (replaced) [<a href="/pdf/2311.16447" title="Download PDF">pdf</a>, <a href="/format/2311.16447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TopoSemiSeg: Enforcing Topological Consistency for Semi-Supervised  Segmentation of Histopathology Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+M">Meilong Xu</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+X">Xiaoling Hu</a>, 
<a href="/search/eess?searchtype=author&query=Gupta%2C+S">Saumya Gupta</a>, 
<a href="/search/eess?searchtype=author&query=Abousamra%2C+S">Shahira Abousamra</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+C">Chao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures, fix Eq. (8) and Eq. (9)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16733" title="Abstract">arXiv:2311.16733</a> (replaced) [<a href="/pdf/2311.16733" title="Download PDF">pdf</a>, <a href="/ps/2311.16733" title="Download PostScript">ps</a>, <a href="/format/2311.16733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMs for Science: Usage for Code Generation and Data Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nejjar%2C+M">Mohamed Nejjar</a>, 
<a href="/search/cs?searchtype=author&query=Zacharias%2C+L">Luca Zacharias</a>, 
<a href="/search/cs?searchtype=author&query=Stiehle%2C+F">Fabian Stiehle</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+I">Ingo Weber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint; In Submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17663" title="Abstract">arXiv:2311.17663</a> (replaced) [<a href="/pdf/2311.17663" title="Download PDF">pdf</a>, <a href="/format/2311.17663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cam4DOcc: Benchmark for Camera-Only 4D Occupancy Forecasting in  Autonomous Driving Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Junyi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xieyuanli Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiawei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jingyi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhen Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jintao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+W">Weihao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+R">Rui Ai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hesheng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00052" title="Abstract">arXiv:2312.00052</a> (replaced) [<a href="/pdf/2312.00052" title="Download PDF">pdf</a>, <a href="/ps/2312.00052" title="Download PostScript">ps</a>, <a href="/format/2312.00052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Case for Competent AI Systems $-$ A Concept Note
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karlapalem%2C+K">Kamalakar Karlapalem</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00065" title="Abstract">arXiv:2312.00065</a> (replaced) [<a href="/pdf/2312.00065" title="Download PDF">pdf</a>, <a href="/format/2312.00065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Keypoints from Pretrained Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hedlin%2C+E">Eric Hedlin</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+G">Gopal Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Mahajan%2C+S">Shweta Mahajan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xingzhe He</a>, 
<a href="/search/cs?searchtype=author&query=Isack%2C+H">Hossam Isack</a>, 
<a href="/search/cs?searchtype=author&query=Rhodin%2C+A+K+H">Abhishek Kar Helge Rhodin</a>, 
<a href="/search/cs?searchtype=author&query=Tagliasacchi%2C+A">Andrea Tagliasacchi</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+K+M">Kwang Moo Yi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00163" title="Abstract">arXiv:2312.00163</a> (replaced) [<a href="/pdf/2312.00163" title="Download PDF">pdf</a>, <a href="/format/2312.00163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Just add WATER: WebAssembly-based Circumvention Transports
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chi%2C+E">Erik Chi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gaukas Wang</a>, 
<a href="/search/cs?searchtype=author&query=Halderman%2C+J+A">J. Alex Halderman</a>, 
<a href="/search/cs?searchtype=author&query=Wustrow%2C+E">Eric Wustrow</a>, 
<a href="/search/cs?searchtype=author&query=Wampler%2C+J">Jack Wampler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00168" title="Abstract">arXiv:2312.00168</a> (replaced) [<a href="/pdf/2312.00168" title="Download PDF">pdf</a>, <a href="/ps/2312.00168" title="Download PostScript">ps</a>, <a href="/format/2312.00168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating News Narratives: A Media Bias Analysis Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raza%2C+S">Shaina Raza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00209" title="Abstract">arXiv:2312.00209</a> (replaced) [<a href="/pdf/2312.00209" title="Download PDF">pdf</a>, <a href="/format/2312.00209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Interplay Between Stepsize Tuning and Progressive Sharpening
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roulet%2C+V">Vincent Roulet</a>, 
<a href="/search/cs?searchtype=author&query=Agarwala%2C+A">Atish Agarwala</a>, 
<a href="/search/cs?searchtype=author&query=Pedregosa%2C+F">Fabian Pedregosa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the NeurIPS 2023 OPT Wokshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00271" title="Abstract">arXiv:2312.00271</a> (replaced) [<a href="/pdf/2312.00271" title="Download PDF">pdf</a>, <a href="/format/2312.00271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Clinical Prediction with Transparency: An Explainable AI  Approach to Survival Modelling in Residential Aged Care
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Susnjak%2C+T">Teo Susnjak</a>, 
<a href="/search/cs?searchtype=author&query=Griffin%2C+E">Elise Griffin</a>, 
<a href="/search/cs?searchtype=author&query=McCutcheon%2C+M">Mitchell McCutcheon</a>, 
<a href="/search/cs?searchtype=author&query=Potter%2C+K">Kathleen Potter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00273" title="Abstract">arXiv:2312.00273</a> (replaced) [<a href="/pdf/2312.00273" title="Download PDF">pdf</a>, <a href="/format/2312.00273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mark My Words: Analyzing and Evaluating Language Model Watermarks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Piet%2C+J">Julien Piet</a>, 
<a href="/search/cs?searchtype=author&query=Sitawarin%2C+C">Chawin Sitawarin</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+V">Vivian Fang</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+N">Norman Mu</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+D">David Wagner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00351" title="Abstract">arXiv:2312.00351</a> (replaced) [<a href="/pdf/2312.00351" title="Download PDF">pdf</a>, <a href="/format/2312.00351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Manipulating the Label Space for In-Context Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haokun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuhang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zihan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+X">Xin Geng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00690" title="Abstract">arXiv:2312.00690</a> (replaced) [<a href="/pdf/2312.00690" title="Download PDF">pdf</a>, <a href="/format/2312.00690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open-vocabulary object 6D pose estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Corsetti%2C+J">Jaime Corsetti</a>, 
<a href="/search/cs?searchtype=author&query=Boscaini%2C+D">Davide Boscaini</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+C">Changjae Oh</a>, 
<a href="/search/cs?searchtype=author&query=Cavallaro%2C+A">Andrea Cavallaro</a>, 
<a href="/search/cs?searchtype=author&query=Poiesi%2C+F">Fabio Poiesi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report. 21 pages, 15 figures, 6 tables. Updated website link
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00786" title="Abstract">arXiv:2312.00786</a> (replaced) [<a href="/pdf/2312.00786" title="Download PDF">pdf</a>, <a href="/format/2312.00786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dense Optical Tracking: Connecting the Dots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moing%2C+G+L">Guillaume Le Moing</a>, 
<a href="/search/cs?searchtype=author&query=Ponce%2C+J">Jean Ponce</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+C">Cordelia Schmid</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01227" title="Abstract">arXiv:2312.01227</a> (replaced) [<a href="/pdf/2312.01227" title="Download PDF">pdf</a>, <a href="/format/2312.01227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Bayesian Estimation in Sensor Networks: Consensus on  Marginal Densities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paritosh%2C+P">Parth Paritosh</a>, 
<a href="/search/cs?searchtype=author&query=Atanasov%2C+N">Nikolay Atanasov</a>, 
<a href="/search/cs?searchtype=author&query=Martinez%2C+S">Sonia Martinez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA); Robotics (cs.RO); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01235" title="Abstract">arXiv:2312.01235</a> (replaced) [<a href="/pdf/2312.01235" title="Download PDF">pdf</a>, <a href="/ps/2312.01235" title="Download PostScript">ps</a>, <a href="/format/2312.01235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strategic Data Revocation in Federated Unlearning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+N">Ningning Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+E">Ermin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Berry%2C+R">Randall Berry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE International Conference on Computer Communications (INFOCOM), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01530" title="Abstract">arXiv:2312.01530</a> (replaced) [<a href="/pdf/2312.01530" title="Download PDF">pdf</a>, <a href="/format/2312.01530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of Active Feature Acquisition Methods for Time-varying  Feature Settings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=von+Kleist%2C+H">Henrik von Kleist</a>, 
<a href="/search/stat?searchtype=author&query=Zamanian%2C+A">Alireza Zamanian</a>, 
<a href="/search/stat?searchtype=author&query=Shpitser%2C+I">Ilya Shpitser</a>, 
<a href="/search/stat?searchtype=author&query=Ahmidi%2C+N">Narges Ahmidi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages, 3 tables, 8 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01619" title="Abstract">arXiv:2312.01619</a> (replaced) [<a href="/pdf/2312.01619" title="Download PDF">pdf</a>, <a href="/format/2312.01619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Many Validation Labels Do You Need? Exploring the Design Space of  Label-Efficient Model Ranking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhengyu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jieyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yuchen Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Correction of a typographical error
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01623" title="Abstract">arXiv:2312.01623</a> (replaced) [<a href="/pdf/2312.01623" title="Download PDF">pdf</a>, <a href="/format/2312.01623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Segmentation at Arbitrary Granularity with Language  Instruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cairong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yitong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiahao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujiu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yansong Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01841" title="Abstract">arXiv:2312.01841</a> (replaced) [<a href="/pdf/2312.01841" title="Download PDF">pdf</a>, <a href="/format/2312.01841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VividTalk: One-Shot Audio-Driven Talking Head Generation Based on 3D  Hybrid Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xusen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Longhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xinya Ji</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kangneng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+D">Daiheng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Bo%2C+L">Liefeng Bo</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xun Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01860" title="Abstract">arXiv:2312.01860</a> (replaced) [<a href="/pdf/2312.01860" title="Download PDF">pdf</a>, <a href="/format/2312.01860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling Objects with SOLA: An Annotation-Free Image Search on the  Object Level for Automotive Data Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rigoll%2C+P">Philipp Rigoll</a>, 
<a href="/search/cs?searchtype=author&query=Langner%2C+J">Jacob Langner</a>, 
<a href="/search/cs?searchtype=author&query=Sax%2C+E">Eric Sax</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02080" title="Abstract">arXiv:2312.02080</a> (replaced) [<a href="/pdf/2312.02080" title="Download PDF">pdf</a>, <a href="/ps/2312.02080" title="Download PostScript">ps</a>, <a href="/format/2312.02080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fixed-point methods for long-term power control and beamforming design  in large-scale MIMO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miretti%2C+L">Lorenzo Miretti</a>, 
<a href="/search/cs?searchtype=author&query=Cavalcante%2C+R+L+G">Renato L. G. Cavalcante</a>, 
<a href="/search/cs?searchtype=author&query=Sta%C5%84czak%2C+S">S&#x142;awomir Sta&#x144;czak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02190" title="Abstract">arXiv:2312.02190</a> (replaced) [<a href="/pdf/2312.02190" title="Download PDF">pdf</a>, <a href="/format/2312.02190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Handles: Enabling 3D Edits for Diffusion Models by Lifting  Activations to 3D
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pandey%2C+K">Karran Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Guerrero%2C+P">Paul Guerrero</a>, 
<a href="/search/cs?searchtype=author&query=Gadelha%2C+M">Matheus Gadelha</a>, 
<a href="/search/cs?searchtype=author&query=Hold-Geoffroy%2C+Y">Yannick Hold-Geoffroy</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+K">Karan Singh</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+N">Niloy Mitra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Webpage: <a href="https://diffusionhandles.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02209" title="Abstract">arXiv:2312.02209</a> (replaced) [<a href="/pdf/2312.02209" title="Download PDF">pdf</a>, <a href="/format/2312.02209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AttriHuman-3D: Editable 3D Human Avatar Generation with Attribute  Decomposition and Indexing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaosheng He</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhongang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Si Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guosheng Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02238" title="Abstract">arXiv:2312.02238</a> (replaced) [<a href="/pdf/2312.02238" title="Download PDF">pdf</a>, <a href="/format/2312.02238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> X-Adapter: Adding Universal Compatibility of Plugins for Upgraded  Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ran%2C+L">Lingmin Ran</a>, 
<a href="/search/cs?searchtype=author&query=Cun%2C+X">Xiaodong Cun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jia-Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zijie%2C+S">Song Zijie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xintao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Keppo%2C+J">Jussi Keppo</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://showlab.github.io/X-Adapter/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02595" title="Abstract">arXiv:2312.02595</a> (replaced) [<a href="/pdf/2312.02595" title="Download PDF">pdf</a>, <a href="/format/2312.02595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Fairness Scheduling for Coded Caching in Multi-AP Multi-antenna  WLAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akcay%2C+K">Kagan Akcay</a>, 
<a href="/search/cs?searchtype=author&query=Salehi%2C+M">MohammadJavad Salehi</a>, 
<a href="/search/cs?searchtype=author&query=T%C3%B6lli%2C+A">Antti T&#xf6;lli</a>, 
<a href="/search/cs?searchtype=author&query=Caire%2C+G">Giuseppe Caire</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02914" title="Abstract">arXiv:2312.02914</a> (replaced) [<a href="/pdf/2312.02914" title="Download PDF">pdf</a>, <a href="/format/2312.02914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Video Domain Adaptation with Masked Pre-Training and  Collaborative Self-Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reddy%2C+A">Arun Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+W">William Paul</a>, 
<a href="/search/cs?searchtype=author&query=Rivera%2C+C">Corban Rivera</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+K">Ketul Shah</a>, 
<a href="/search/cs?searchtype=author&query=de+Melo%2C+C+M">Celso M. de Melo</a>, 
<a href="/search/cs?searchtype=author&query=Chellappa%2C+R">Rama Chellappa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02931" title="Abstract">arXiv:2312.02931</a> (replaced) [<a href="/pdf/2312.02931" title="Download PDF">pdf</a>, <a href="/format/2312.02931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WhisBERT: Multimodal Text-Audio Language Modeling on 100M Words
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wolf%2C+L">Lukas Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Tuckute%2C+G">Greta Tuckute</a>, 
<a href="/search/cs?searchtype=author&query=Kotar%2C+K">Klemen Kotar</a>, 
<a href="/search/cs?searchtype=author&query=Hosseini%2C+E">Eghbal Hosseini</a>, 
<a href="/search/cs?searchtype=author&query=Regev%2C+T">Tamar Regev</a>, 
<a href="/search/cs?searchtype=author&query=Wilcox%2C+E">Ethan Wilcox</a>, 
<a href="/search/cs?searchtype=author&query=Warstadt%2C+A">Alex Warstadt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at the BabyLM Challenge, a shared task co-sponsored by CMCL 2023 and CoNLL 2023, hosted by EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02959" title="Abstract">arXiv:2312.02959</a> (replaced) [<a href="/pdf/2312.02959" title="Download PDF">pdf</a>, <a href="/format/2312.02959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting algorithmic bias in medical AI-models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Smith%2C+J">Jeffrey Smith</a>, 
<a href="/search/stat?searchtype=author&query=Holder%2C+A">Andre Holder</a>, 
<a href="/search/stat?searchtype=author&query=Kamaleswaran%2C+R">Rishikesan Kamaleswaran</a>, 
<a href="/search/stat?searchtype=author&query=Xie%2C+Y">Yao Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03121" title="Abstract">arXiv:2312.03121</a> (replaced) [<a href="/pdf/2312.03121" title="Download PDF">pdf</a>, <a href="/format/2312.03121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Agents using Social Choice Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lanctot%2C+M">Marc Lanctot</a>, 
<a href="/search/cs?searchtype=author&query=Larson%2C+K">Kate Larson</a>, 
<a href="/search/cs?searchtype=author&query=Bachrach%2C+Y">Yoram Bachrach</a>, 
<a href="/search/cs?searchtype=author&query=Marris%2C+L">Luke Marris</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zun Li</a>, 
<a href="/search/cs?searchtype=author&query=Bhoopchand%2C+A">Avishkar Bhoopchand</a>, 
<a href="/search/cs?searchtype=author&query=Anthony%2C+T">Thomas Anthony</a>, 
<a href="/search/cs?searchtype=author&query=Tanner%2C+B">Brian Tanner</a>, 
<a href="/search/cs?searchtype=author&query=Koop%2C+A">Anna Koop</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03196" title="Abstract">arXiv:2312.03196</a> (replaced) [<a href="/pdf/2312.03196" title="Download PDF">pdf</a>, <a href="/format/2312.03196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Invariant Representation Learning and Sleep Dynamics Modeling for  Automatic Sleep Staging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seungyeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+T">Thai-Hoang Pham</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Ping Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03289" title="Abstract">arXiv:2312.03289</a> (replaced) [<a href="/pdf/2312.03289" title="Download PDF">pdf</a>, <a href="/format/2312.03289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Class Incremental Learning for Adversarial Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+S">Seungju Cho</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hongsin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Changick Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03406" title="Abstract">arXiv:2312.03406</a> (replaced) [<a href="/pdf/2312.03406" title="Download PDF">pdf</a>, <a href="/format/2312.03406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SVQ: Sparse Vector Quantization for Spatiotemporal Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yanjun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Liang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+R">Rong Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03461" title="Abstract">arXiv:2312.03461</a> (replaced) [<a href="/pdf/2312.03461" title="Download PDF">pdf</a>, <a href="/format/2312.03461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HiFi4G: High-Fidelity Human Performance Rendering via Compact Gaussian  Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuheng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhehao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Penghao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Z">Zhuo Su</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yu Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jingyi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03510" title="Abstract">arXiv:2312.03510</a> (replaced) [<a href="/pdf/2312.03510" title="Download PDF">pdf</a>, <a href="/format/2312.03510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Sobolev Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kichler%2C+N">Neil Kichler</a>, 
<a href="/search/cs?searchtype=author&query=Afghan%2C+S">Sher Afghan</a>, 
<a href="/search/cs?searchtype=author&query=Naumann%2C+U">Uwe Naumann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Finance (q-fin.CP)

</div>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03549" title="Abstract">arXiv:2312.03549</a> (replaced) [<a href="/pdf/2312.03549" title="Download PDF">pdf</a>, <a href="/format/2312.03549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Holmes: Towards Distributed Training Across Clusters with Heterogeneous  NIC Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Shuang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+N">Ning Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fangyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+K">Ke Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jiezhong Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+A">Aimin Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03594" title="Abstract">arXiv:2312.03594</a> (replaced) [<a href="/pdf/2312.03594" title="Download PDF">pdf</a>, <a href="/format/2312.03594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Task is Worth One Word: Learning with Task Prompts for High-Quality  Versatile Image Inpainting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+J">Junhao Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yanhong Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenran Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chun Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page with code: <a href="https://powerpaint.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03619" title="Abstract">arXiv:2312.03619</a> (replaced) [<a href="/pdf/2312.03619" title="Download PDF">pdf</a>, <a href="/format/2312.03619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of Active Feature Acquisition Methods for Static Feature  Settings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=von+Kleist%2C+H">Henrik von Kleist</a>, 
<a href="/search/stat?searchtype=author&query=Zamanian%2C+A">Alireza Zamanian</a>, 
<a href="/search/stat?searchtype=author&query=Shpitser%2C+I">Ilya Shpitser</a>, 
<a href="/search/stat?searchtype=author&query=Ahmidi%2C+N">Narges Ahmidi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 7 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03651" title="Abstract">arXiv:2312.03651</a> (replaced) [<a href="/pdf/2312.03651" title="Download PDF">pdf</a>, <a href="/format/2312.03651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MIRACLE: Inverse Reinforcement and Curriculum Learning Model for  Human-inspired Mobile Robot Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gunukula%2C+N">Nihal Gunukula</a>, 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+K">Kshitij Tiwari</a>, 
<a href="/search/cs?searchtype=author&query=Bera%2C+A">Aniket Bera</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03698" title="Abstract">arXiv:2312.03698</a> (replaced) [<a href="/pdf/2312.03698" title="Download PDF">pdf</a>, <a href="/format/2312.03698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intrinsic Harmonization for Illumination-Aware Compositing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Careaga%2C+C">Chris Careaga</a>, 
<a href="/search/cs?searchtype=author&query=Miangoleh%2C+S+M+H">S. Mahdi H. Miangoleh</a>, 
<a href="/search/cs?searchtype=author&query=Aksoy%2C+Y">Ya&#x11f;&#x131;z Aksoy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures. Accepted to SIGGRAPH Asia 2023 (Conference Track). Project page: <a href="https://yaksoy.github.io/intrinsicCompositing/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03699" title="Abstract">arXiv:2312.03699</a> (replaced) [<a href="/pdf/2312.03699" title="Download PDF">pdf</a>, <a href="/format/2312.03699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PROMISE: A Framework for Model-Driven Stateful Prompt Orchestration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Heierli%2C+J">Jasmin Heierli</a>, 
<a href="/search/cs?searchtype=author&query=Meisterhans%2C+M">Max Meisterhans</a>, 
<a href="/search/cs?searchtype=author&query=Moser%2C+A">Adrian Moser</a>, 
<a href="/search/cs?searchtype=author&query=F%C3%A4rber%2C+A">Andri F&#xe4;rber</a>, 
<a href="/search/cs?searchtype=author&query=Dolata%2C+M">Mateusz Dolata</a>, 
<a href="/search/cs?searchtype=author&query=Gavagnin%2C+E">Elena Gavagnin</a>, 
<a href="/search/cs?searchtype=author&query=de+Spindler%2C+A">Alexandre de Spindler</a>, 
<a href="/search/cs?searchtype=author&query=Schwabe%2C+G">Gerhard Schwabe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Minor revision regards wording
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item385">Cross-lists</a></li>
<li><a href="#item425">Replacements</a></li>
</ul>
<small>[ total of 636 entries:  <b>1-636</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2312">2312</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
