<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Thu 21 Dec 23  to  Fri 22 Dec 23, announced Mon, 25 Dec 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item310">Cross-lists</a></li>
<li><a href="#item350">Replacements</a></li>
</ul>
<small>[ total of 510 entries:  <b>1-510</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Mon, 25 Dec 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14158" title="Abstract">arXiv:2312.14158</a> [<a href="/pdf/2312.14158" title="Download PDF">pdf</a>, <a href="/format/2312.14158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Cooperatives for Identity Attestations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hardjono%2C+T">Thomas Hardjono</a>, 
<a href="/search/cs?searchtype=author&query=Pentland%2C+A">Alex Pentland</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Data cooperatives with fiduciary obligations to members provide a useful
source of truthful information regarding a given member whose personal data is
managed by the cooperative. Since one of the main propositions the cooperative
model is to protect the data privacy of members, we explore the notion of
blinded attestations in which the identity of the subject is removed from the
attestations issued by the cooperative regarding one of its members. This is
performed at the request of the individual member. We propose the use of a
legal entity to countersign the blinded attestation, one that has an
attorney-client relationship with the cooperative, and which can henceforth
become the legal point of contact for inquiries regarding the individual
related to the attribute being attested. There are several use-cases for this
feature, including the Funds Travel Rule in transactions in digital assets, and
the protection of privacy in decentralized social networks.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14159" title="Abstract">arXiv:2312.14159</a> [<a href="/pdf/2312.14159" title="Download PDF">pdf</a>, <a href="/format/2312.14159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Ethereum&#x27;s Security with LUMEN, a Novel Zero-Knowledge  Protocol Generating Transparent and Efficient zk-SNARKs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Quan%2C+Y">Yunjia Quan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Probability (math.PR)

</div>
<p class="mathjax">This paper proposes a novel recursive polynomial commitment scheme (PCS) and
a new polynomial interactive oracle proof (PIOP) protocol, which compile into
efficient and transparent zk-SNARKs (zero-knowledge succinct non-interactive
arguments of knowledge). The Ethereum blockchain utilizes zero-knowledge
Rollups (ZKR) to improve its scalability (the ability to handle a large number
of transactions), and ZKR uses zk-SNARKs to validate transactions. The
currently used zk-SNARKs rely on a trusted setup ceremony, where a group of
participants uses secret information about transactions to generate the public
parameters necessary to verify the zk-SNARKs. This introduces a security risk
into Ethereum's system. Thus, researchers have been developing transparent
zk-SNARKs (which do not require a trusted setup), but those are not as
efficient as non-transparent zk-SNARKs, so ZKRs do not use them. In this
research, I developed LUMEN, a set of novel algorithms that generate
transparent zk-SNARKs that improve Ethereum's security without sacrificing its
efficiency. Various techniques were creatively incorporated into LUMEN,
including groups with hidden orders, Lagrange basis polynomials, and an
amortization strategy. I wrote mathematical proofs for LUMEN that convey its
completeness, soundness and zero-knowledgeness, and implemented LUMEN by
writing around $8000$ lines of Rust and Python code, which conveyed the
practicality of LUMEN. Moreover, my implementation revealed the efficiency of
LUMEN (measured in proof size, proof computation time, and verification time),
which surpasses the efficiency of existing transparent zk-SNARKs and is on par
with that of non-transparent zk-SNARKs. Therefore, LUMEN is a promising
solution to improve Ethereum's security while maintaining its efficiency.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14171" title="Abstract">arXiv:2312.14171</a> [<a href="/pdf/2312.14171" title="Download PDF">pdf</a>, <a href="/ps/2312.14171" title="Download PostScript">ps</a>, <a href="/format/2312.14171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEOpinion: Summarization and Exploration Opinion of E-Commerce Websites
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mabrouk%2C+A">Alhassan Mabrouk</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz-Redondo%2C+R+P">Rebeca P. D&#xed;az-Redondo</a>, 
<a href="/search/cs?searchtype=author&query=Kayed%2C+M">Mohammed Kayed</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sensors, 2021, vol. 21, no 2, p. 636
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">E-Commerce (EC) websites provide a large amount of useful information that
exceed human cognitive processing ability. In order to help customers in
comparing alternatives when buying a product, previous studies designed opinion
summarization systems based on customer reviews. They ignored templates'
information provided by manufacturers, although these descriptive information
have much product aspects or characteristics. Therefore, this paper proposes a
methodology coined as SEOpinion (Summa-rization and Exploration of Opinions)
which provides a summary for the product aspects and spots opinion(s) regarding
them, using a combination of templates' information with the customer reviews
in two main phases. First, the Hierarchical Aspect Extraction (HAE) phase
creates a hierarchy of product aspects from the template. Subsequently, the
Hierarchical Aspect-based Opinion Summarization (HAOS) phase enriches this
hierarchy with customers' opinions; to be shown to other potential buyers. To
test the feasibility of using Deep Learning-based BERT techniques with our
approach, we have created a corpus by gathering information from the top five
EC websites for laptops. The experimental results show that Recurrent Neural
Network (RNN) achieves better results (77.4% and 82.6% in terms of F1-measure
for the first and second phase) than the Convolutional Neural Network (CNN) and
the Support Vector Machine (SVM) technique.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14180" title="Abstract">arXiv:2312.14180</a> [<a href="/pdf/2312.14180" title="Download PDF">pdf</a>, <a href="/format/2312.14180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Topic Language Model on Heterogeneous Children&#x27;s Mental Health  Clinical Notes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Hanwen Ye</a>, 
<a href="/search/cs?searchtype=author&query=Moreno%2C+T">Tatiana Moreno</a>, 
<a href="/search/cs?searchtype=author&query=Alpern%2C+A">Adrianne Alpern</a>, 
<a href="/search/cs?searchtype=author&query=Ehwerhemuepha%2C+L">Louis Ehwerhemuepha</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+A">Annie Qu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Applications (stat.AP); Machine Learning (stat.ML)

</div>
<p class="mathjax">Mental health diseases affect children's lives and well-beings which have
received increased attention since the COVID-19 pandemic. Analyzing psychiatric
clinical notes with topic models is critical to evaluate children's mental
status over time. However, few topic models are built for longitudinal
settings, and they fail to keep consistent topics and capture temporal
trajectories for each document. To address these challenges, we develop a
longitudinal topic model with time-invariant topics and individualized temporal
dependencies on the evolving document metadata. Our model preserves the
semantic meaning of discovered topics over time and incorporates heterogeneity
among documents. In particular, when documents can be categorized, we propose
an unsupervised topics learning approach to maximize topic heterogeneity across
different document groups. We also present an efficient variational
optimization procedure adapted for the multistage longitudinal setting. In this
case study, we apply our method to the psychiatric clinical notes from a large
tertiary pediatric hospital in Southern California and achieve a 38% increase
in the overall coherence of extracted topics. Our real data analysis reveals
that children tend to express more negative emotions during state shutdowns and
more positive when schools reopen. Furthermore, it suggests that sexual and
gender minority (SGM) children display more pronounced reactions to major
COVID-19 events and a greater sensitivity to vaccine-related news than non-SGM
children. This study examines the progression of children's mental health
during the pandemic and offers clinicians valuable insights to recognize the
disparities in children's mental health related to their sexual and gender
identities.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14182" title="Abstract">arXiv:2312.14182</a> [<a href="/pdf/2312.14182" title="Download PDF">pdf</a>, <a href="/format/2312.14182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Find the Lady: Permutation and Re-Synchronization of Deep Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Sousa+Trias%2C+C">Carl De Sousa Trias</a>, 
<a href="/search/cs?searchtype=author&query=Mitrea%2C+M+P">Mihai Petru Mitrea</a>, 
<a href="/search/cs?searchtype=author&query=Fiandrotti%2C+A">Attilio Fiandrotti</a>, 
<a href="/search/cs?searchtype=author&query=Cagnazzo%2C+M">Marco Cagnazzo</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhuri%2C+S">Sumanta Chaudhuri</a>, 
<a href="/search/cs?searchtype=author&query=Tartaglione%2C+E">Enzo Tartaglione</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Deep neural networks are characterized by multiple symmetrical, equi-loss
solutions that are redundant. Thus, the order of neurons in a layer and feature
maps can be given arbitrary permutations, without affecting (or minimally
affecting) their output. If we shuffle these neurons, or if we apply to them
some perturbations (like fine-tuning) can we put them back in the original
order i.e. re-synchronize? Is there a possible corruption threat? Answering
these questions is important for applications like neural network white-box
watermarking for ownership tracking and integrity verification. We advance a
method to re-synchronize the order of permuted neurons. Our method is also
effective if neurons are further altered by parameter pruning, quantization,
and fine-tuning, showing robustness to integrity attacks. Additionally, we
provide theoretical and practical evidence for the usual means to corrupt the
integrity of the model, resulting in a solution to counter it. We test our
approach on popular computer vision datasets and models, and we illustrate the
threat and our countermeasure on a popular white-box watermarking method.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14183" title="Abstract">arXiv:2312.14183</a> [<a href="/pdf/2312.14183" title="Download PDF">pdf</a>, <a href="/format/2312.14183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Early Detection of Hallucinations in Factual Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Snyder%2C+B">Ben Snyder</a>, 
<a href="/search/cs?searchtype=author&query=Moisescu%2C+M">Marius Moisescu</a>, 
<a href="/search/cs?searchtype=author&query=Zafar%2C+M+B">Muhammad Bilal Zafar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While large language models (LLMs) have taken great strides towards helping
humans with a plethora of tasks like search and summarization, hallucinations
remain a major impediment towards gaining user trust. The fluency and coherence
of model generations even when hallucinating makes it difficult to detect
whether or not a model is hallucinating. In this work, we explore if the
artifacts associated with the model generations can provide hints that the
generation will contain hallucinations. Specifically, we probe LLMs at 1) the
inputs via Integrated Gradients based token attribution, 2) the outputs via the
Softmax probabilities, and 3) the internal state via self-attention and
fully-connected layer activations for signs of hallucinations on open-ended
question answering tasks. Our results show that the distributions of these
artifacts differ between hallucinated and non-hallucinated generations.
Building on this insight, we train binary classifiers that use these artifacts
as input features to classify model generations into hallucinations and
non-hallucinations. These hallucination classifiers achieve up to 0.80 AUROC.
We further show that tokens preceding a hallucination can predict the
subsequent hallucination before it occurs.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14184" title="Abstract">arXiv:2312.14184</a> [<a href="/pdf/2312.14184" title="Download PDF">pdf</a>, <a href="/ps/2312.14184" title="Download PostScript">ps</a>, <a href="/format/2312.14184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models in Medical Term Classification and Unexpected  Misalignment Between Response and Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaodan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Vemulapalli%2C+S">Sandeep Vemulapalli</a>, 
<a href="/search/cs?searchtype=author&query=Talukdar%2C+N">Nabasmita Talukdar</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+S">Sumyeong Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiankun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+H">Han Meng</a>, 
<a href="/search/cs?searchtype=author&query=Murtaza%2C+S+M+B">Sardar Mehtab Bin Murtaza</a>, 
<a href="/search/cs?searchtype=author&query=Dave%2C+A+A">Aakash Ajay Dave</a>, 
<a href="/search/cs?searchtype=author&query=Leshchiner%2C+D">Dmitry Leshchiner</a>, 
<a href="/search/cs?searchtype=author&query=Joseph%2C+D+F">Dimitri F. Joseph</a>, 
<a href="/search/cs?searchtype=author&query=Witteveen-Lane%2C+M">Martin Witteveen-Lane</a>, 
<a href="/search/cs?searchtype=author&query=Chesla%2C+D">Dave Chesla</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiayu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bin Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This study assesses the ability of state-of-the-art large language models
(LLMs) including GPT-3.5, GPT-4, Falcon, and LLaMA 2 to identify patients with
mild cognitive impairment (MCI) from discharge summaries and examines instances
where the models' responses were misaligned with their reasoning. Utilizing the
MIMIC-IV v2.2 database, we focused on a cohort aged 65 and older, verifying MCI
diagnoses against ICD codes and expert evaluations. The data was partitioned
into training, validation, and testing sets in a 7:2:1 ratio for model
fine-tuning and evaluation, with an additional metastatic cancer dataset from
MIMIC III used to further assess reasoning consistency. GPT-4 demonstrated
superior interpretative capabilities, particularly in response to complex
prompts, yet displayed notable response-reasoning inconsistencies. In contrast,
open-source models like Falcon and LLaMA 2 achieved high accuracy but lacked
explanatory reasoning, underscoring the necessity for further research to
optimize both performance and interpretability. The study emphasizes the
significance of prompt engineering and the need for further exploration into
the unexpected reasoning-response misalignment observed in GPT-4. The results
underscore the promise of incorporating LLMs into healthcare diagnostics,
contingent upon methodological advancements to ensure accuracy and clinical
coherence of AI-generated outputs, thereby improving the trustworthiness of
LLMs for medical decision-making.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14185" title="Abstract">arXiv:2312.14185</a> [<a href="/pdf/2312.14185" title="Download PDF">pdf</a>, <a href="/format/2312.14185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auto311: A Confidence-guided Automated System for Non-emergency Call
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zirong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xutong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+M">Meiyi Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-2024, Sub-Track: Social Impacts
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Emergency and non-emergency response systems are essential services provided
by local governments and critical to protecting lives, the environment, and
property. The effective handling of (non-)emergency calls is critical for
public safety and well-being. By reducing the burden through non-emergency
callers, residents in critical need of assistance through 911 will receive a
fast and effective response. Collaborating with the Department of Emergency
Communications (DEC) in Nashville, we analyzed 11,796 non-emergency call
recordings and developed Auto311, the first automated system to handle 311
non-emergency calls, which (1) effectively and dynamically predicts ongoing
non-emergency incident types to generate tailored case reports during the call;
(2) itemizes essential information from dialogue contexts to complete the
generated reports; and (3) strategically structures system-caller dialogues
with optimized confidence. We used real-world data to evaluate the system's
effectiveness and deployability. The experimental results indicate that the
system effectively predicts incident type with an average F-1 score of 92.54%.
Moreover, the system successfully itemizes critical information from relevant
contexts to complete reports, evincing a 0.93 average consistency score
compared to the ground truth. Additionally, emulations demonstrate that the
system effectively decreases conversation turns as the utterance size gets more
extensive and categorizes the ongoing call with 94.49% mean accuracy.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14187" title="Abstract">arXiv:2312.14187</a> [<a href="/pdf/2312.14187" title="Download PDF">pdf</a>, <a href="/format/2312.14187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WaveCoder: Widespread And Versatile Enhanced Instruction Tuning with  Refined Data Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhaojian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+N">Ning Shang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yangyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Can Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yishujie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wenxiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Q">Qiufeng Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
<p class="mathjax">Recent work demonstrates that, after being fine-tuned on a high-quality
instruction dataset, the resulting model can obtain impressive capabilities to
address a wide range of tasks. However, existing methods for instruction data
generation often produce duplicate data and are not controllable enough on data
quality. In this paper, we extend the generalization of instruction tuning by
classifying the instruction data to 4 code-related tasks and propose a
LLM-based Generator-Discriminator data process framework to generate diverse,
high-quality instruction data from open source code. Hence, we introduce
CodeOcean, a dataset comprising 20,000 instruction instances across 4 universal
code-related tasks,which is aimed at augmenting the effectiveness of
instruction tuning and improving the generalization ability of fine-tuned
model. Subsequently, we present WaveCoder, a fine-tuned Code LLM with
Widespread And Versatile Enhanced instruction tuning. This model is
specifically designed for enhancing instruction tuning of Code Language Models
(LLMs). Our experiments demonstrate that Wavecoder models outperform other
open-source models in terms of generalization ability across different
code-related tasks at the same level of fine-tuning scale. Moreover, Wavecoder
exhibits high efficiency in previous code generation tasks. This paper thus
offers a significant contribution to the field of instruction data generation
and fine-tuning models, providing new insights and tools for enhancing
performance in code-related tasks.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14188" title="Abstract">arXiv:2312.14188</a> [<a href="/pdf/2312.14188" title="Download PDF">pdf</a>, <a href="/format/2312.14188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Neural Theorem Proving through Data Augmentation and Dynamic  Sampling Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vishwakarma%2C+R">Rahul Vishwakarma</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Subhankar Mishra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Theorem proving is a fundamental task in mathematics. With the advent of
large language models (LLMs) and interactive theorem provers (ITPs) like Lean,
there has been growing interest in integrating LLMs and ITPs to automate
theorem proving. In this approach, the LLM generates proof steps (tactics), and
the ITP checks the applicability of the tactics at the current goal. The two
systems work together to complete the proof. In this paper, we introduce
DS-Prover, a novel dynamic sampling method for theorem proving. This method
dynamically determines the number of tactics to apply to expand the current
goal, taking into account the remaining time compared to the total allocated
time for proving a theorem. This makes the proof search process more efficient
by adjusting the balance between exploration and exploitation as time passes.
We also augment the training dataset by decomposing simplification and rewrite
tactics with multiple premises into tactics with single premises. This gives
the model more examples to learn from and helps it to predict the tactics with
premises more accurately. We perform our experiments using the Mathlib dataset
of the Lean theorem prover and report the performance on two standard datasets,
MiniF2F and ProofNet. Our methods achieve significant performance gains on both
datasets. We achieved a state-of-the-art performance (Pass@1) of 14.2% on the
ProofNet dataset and a performance of 29.8% on MiniF2F, slightly surpassing the
best-reported Pass@1 of 29.6% using Lean.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14191" title="Abstract">arXiv:2312.14191</a> [<a href="/pdf/2312.14191" title="Download PDF">pdf</a>, <a href="/ps/2312.14191" title="Download PostScript">ps</a>, <a href="/format/2312.14191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noisy Measurements Are Important, the Design of Census Products Is Much  More Important
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abowd%2C+J+M">John M. Abowd</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Econometrics (econ.EM); Applications (stat.AP)

</div>
<p class="mathjax">McCartan et al. (2023) call for "making differential privacy work for census
data users." This commentary explains why the 2020 Census Noisy Measurement
Files (NMFs) are not the best focus for that plea. The August 2021 letter from
62 prominent researchers asking for production of the direct output of the
differential privacy system deployed for the 2020 Census signaled the
engagement of the scholarly community in the design of decennial census data
products. NMFs, the raw statistics produced by the 2020 Census Disclosure
Avoidance System before any post-processing, are one component of that
design--the query strategy output. The more important component is the query
workload output--the statistics released to the public. Optimizing the query
workload--the Redistricting Data (P.L. 94-171) Summary File,
specifically--could allow the privacy-loss budget to be more effectively
managed. There could be fewer noisy measurements, no post-processing bias, and
direct estimates of the uncertainty from disclosure avoidance for each
published statistic.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14193" title="Abstract">arXiv:2312.14193</a> [<a href="/pdf/2312.14193" title="Download PDF">pdf</a>, <a href="/format/2312.14193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clustering and Uncertainty Analysis to Improve the Machine  Learning-based Predictions of SAFARI-1 Control Follower Assembly Axial  Neutron Flux Profiles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moloko%2C+L">Lesego Moloko</a>, 
<a href="/search/cs?searchtype=author&query=Bokov%2C+P">Pavel Bokov</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ivanov%2C+K">Kostadin Ivanov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The goal of this work is to develop accurate Machine Learning (ML) models for
predicting the assembly axial neutron flux profiles in the SAFARI-1 research
reactor, trained by measurement data from historical cycles. The data-driven
nature of ML models makes them susceptible to uncertainties which are
introduced by sources such as noise in training data, incomplete coverage of
the domain, extrapolation and imperfect model architectures. To this end, we
also aim at quantifying the approximation uncertainties of the ML model
predictions. Previous work using Deep Neural Networks (DNNs) has been
successful for fuel assemblies in SAFARI-1, however, not as accurate for
control follower assemblies. The aim of this work is to improve the ML models
for the control assemblies by a combination of supervised and unsupervised ML
algorithms. The $k$-means and Affinity Propagation unsupervised ML algorithms
are employed to identify clusters in the set of the measured axial neutron flux
profiles. Then, regression-based supervised ML models using DNN (with
prediction uncertainties quantified with Monte Carlo dropout) and Gaussian
Process (GP) are trained for different clusters and the prediction uncertainty
is estimated. It was found that applying the proposed procedure improves the
prediction accuracy for the control assemblies and reduces the prediction
uncertainty. Flux shapes predicted by DNN and GP are very close, and the
overall accuracy became comparable to the fuel assemblies. The prediction
uncertainty is however smaller for GP models.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14194" title="Abstract">arXiv:2312.14194</a> [<a href="/pdf/2312.14194" title="Download PDF">pdf</a>, <a href="/ps/2312.14194" title="Download PostScript">ps</a>, <a href="/format/2312.14194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Problem of Computational Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zaidan%2C+R">Rami Zaidan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">This article presents a general solution to the problem of computational
complexity. First, it gives a historical introduction to the problem since the
revival of the foundational problems of mathematics at the end of the 19th
century. Second, building on the theory of functional relations in mathematics,
it provides a theoretical framework where we can rigorously distinguish two
pairs of concepts: Between solving a problem and verifying the solution to a
problem. Between a deterministic and a non-deterministic model of computation.
Third, it presents the theory of computational complexity and the difficulties
in solving the P versus NP problem. Finally, it gives a complete proof that a
certain decision problem in NP has an algorithmic exponential lower bound thus
establishing firmly that P is different from NP. The proof presents a new way
of approaching the subject: neither by entering into the unmanageable
difficulties of proving this type of lower bound for the known NP-complete
problems nor by entering into the difficulties regarding the properties of the
many complexity classes established since the mid-1970s.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14196" title="Abstract">arXiv:2312.14196</a> [<a href="/pdf/2312.14196" title="Download PDF">pdf</a>, <a href="/format/2312.14196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Heat Alert Issuance for Public Health in the United States  with Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Considine%2C+E+M">Ellen M. Considine</a>, 
<a href="/search/cs?searchtype=author&query=Nethery%2C+R+C">Rachel C. Nethery</a>, 
<a href="/search/cs?searchtype=author&query=Wellenius%2C+G+A">Gregory A. Wellenius</a>, 
<a href="/search/cs?searchtype=author&query=Dominici%2C+F">Francesca Dominici</a>, 
<a href="/search/cs?searchtype=author&query=Tec%2C+M">Mauricio Tec</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main text has 38 pages with 5 figures and 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP)

</div>
<p class="mathjax">Alerting the public when heat may harm their health is a crucial service,
especially considering that extreme heat events will be more frequent under
climate change. Current practice for issuing heat alerts in the US does not
take advantage of modern data science methods for optimizing local alert
criteria. Specifically, application of reinforcement learning (RL) has the
potential to inform more health-protective policies, accounting for regional
and sociodemographic heterogeneity as well as sequential dependence of alerts.
In this work, we formulate the issuance of heat alerts as a sequential decision
making problem and develop modifications to the RL workflow to address
challenges commonly encountered in environmental health settings. Key
modifications include creating a simulator that pairs hierarchical Bayesian
modeling of low-signal health effects with sampling of real weather
trajectories (exogenous features), constraining the total number of alerts
issued as well as preventing alerts on less-hot days, and optimizing
location-specific policies. Post-hoc contrastive analysis offers insights into
scenarios when using RL for heat alert issuance may protect public health
better than the current or alternative policies. This work contributes to a
broader movement of advancing data-driven policy optimization for public health
and climate change adaptation.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14197" title="Abstract">arXiv:2312.14197</a> [<a href="/pdf/2312.14197" title="Download PDF">pdf</a>, <a href="/format/2312.14197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking and Defending Against Indirect Prompt Injection Attacks on  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jingwei Yi</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yueqi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Bin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Hines%2C+K">Keegan Hines</a>, 
<a href="/search/cs?searchtype=author&query=Kiciman%2C+E">Emre Kiciman</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Guangzhong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fangzhao Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent remarkable advancements in large language models (LLMs) have led to
their widespread adoption in various applications. A key feature of these
applications is the combination of LLMs with external content, where user
instructions and third-party content are combined to create prompts for LLM
processing. These applications, however, are vulnerable to indirect prompt
injection attacks, where malicious instructions embedded within external
content compromise LLM's output, causing their responses to deviate from user
expectations. Despite the discovery of this security issue, no comprehensive
analysis of indirect prompt injection attacks on different LLMs is available
due to the lack of a benchmark. Furthermore, no effective defense has been
proposed.
<br />In this work, we introduce the first benchmark, BIPIA, to measure the
robustness of various LLMs and defenses against indirect prompt injection
attacks. Our experiments reveal that LLMs with greater capabilities exhibit
more vulnerable to indirect prompt injection attacks for text tasks, resulting
in a higher ASR. We hypothesize that indirect prompt injection attacks are
mainly due to the LLMs' inability to distinguish between instructions and
external content. Based on this conjecture, we propose four black-box methods
based on prompt learning and a white-box defense methods based on fine-tuning
with adversarial training to enable LLMs to distinguish between instructions
and external content and ignore instructions in the external content. Our
experimental results show that our black-box defense methods can effectively
reduce ASR but cannot completely thwart indirect prompt injection attacks,
while our white-box defense method can reduce ASR to nearly zero with little
adverse impact on the LLM's performance on general tasks. We hope that our
benchmark and defenses can inspire future work in this important area.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14198" title="Abstract">arXiv:2312.14198</a> [<a href="/pdf/2312.14198" title="Download PDF">pdf</a>, <a href="/format/2312.14198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZeroShape: Regression-based Zero-shot Shape Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zixuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Stojanov%2C+S">Stefan Stojanov</a>, 
<a href="/search/cs?searchtype=author&query=Thai%2C+A">Anh Thai</a>, 
<a href="/search/cs?searchtype=author&query=Jampani%2C+V">Varun Jampani</a>, 
<a href="/search/cs?searchtype=author&query=Rehg%2C+J+M">James M. Rehg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://zixuanh.com/projects/zeroshape.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We study the problem of single-image zero-shot 3D shape reconstruction.
Recent works learn zero-shot shape reconstruction through generative modeling
of 3D assets, but these models are computationally expensive at train and
inference time. In contrast, the traditional approach to this problem is
regression-based, where deterministic models are trained to directly regress
the object shape. Such regression methods possess much higher computational
efficiency than generative methods. This raises a natural question: is
generative modeling necessary for high performance, or conversely, are
regression-based approaches still competitive? To answer this, we design a
strong regression-based model, called ZeroShape, based on the converging
findings in this field and a novel insight. We also curate a large real-world
evaluation benchmark, with objects from three different real-world 3D datasets.
This evaluation benchmark is more diverse and an order of magnitude larger than
what prior works use to quantitatively evaluate their models, aiming at
reducing the evaluation variance in our field. We show that ZeroShape not only
achieves superior performance over state-of-the-art methods, but also
demonstrates significantly higher computational and data efficiency.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14199" title="Abstract">arXiv:2312.14199</a> [<a href="/pdf/2312.14199" title="Download PDF">pdf</a>, <a href="/format/2312.14199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Report on 2023 CyberTraining PI Meeting, 26-27 September 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fox%2C+G">Geoffrey Fox</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+M+P">Mary P Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Bhatia%2C+S">Sajal Bhatia</a>, 
<a href="/search/cs?searchtype=author&query=Brazil%2C+M">Marisa Brazil</a>, 
<a href="/search/cs?searchtype=author&query=Gasparini%2C+N+M">Nicole M Gasparini</a>, 
<a href="/search/cs?searchtype=author&query=Merwade%2C+V+M">Venkatesh Mohan Merwade</a>, 
<a href="/search/cs?searchtype=author&query=Neeman%2C+H+J">Henry J. Neeman</a>, 
<a href="/search/cs?searchtype=author&query=Carver%2C+J">Jeff Carver</a>, 
<a href="/search/cs?searchtype=author&query=Casanova%2C+H">Henri Casanova</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhary%2C+V">Vipin Chaudhary</a>, 
<a href="/search/cs?searchtype=author&query=Colbry%2C+D">Dirk Colbry</a>, 
<a href="/search/cs?searchtype=author&query=Crosby%2C+L">Lonnie Crosby</a>, 
<a href="/search/cs?searchtype=author&query=Dewan%2C+P">Prasun Dewan</a>, 
<a href="/search/cs?searchtype=author&query=Eisma%2C+J">Jessica Eisma</a>, 
<a href="/search/cs?searchtype=author&query=Gasparini%2C+N+M">Nicole M Gasparini</a>, 
<a href="/search/cs?searchtype=author&query=Irfan%2C+A">Ahmed Irfan</a>, 
<a href="/search/cs?searchtype=author&query=Kaehey%2C+K">Kate Kaehey</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qianqian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+Z">Zhen Ni</a>, 
<a href="/search/cs?searchtype=author&query=Prasad%2C+S">Sushil Prasad</a>, 
<a href="/search/cs?searchtype=author&query=Qasem%2C+A">Apan Qasem</a>, 
<a href="/search/cs?searchtype=author&query=Saule%2C+E">Erik Saule</a>, 
<a href="/search/cs?searchtype=author&query=Sundaravadivel%2C+P">Prabha Sundaravadivel</a>, 
<a href="/search/cs?searchtype=author&query=Tomko%2C+K">Karen Tomko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 3 main sections and 2 Appendix sections, 2 figures, 19 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">This document describes a two-day meeting held for the Principal
Investigators (PIs) of NSF CyberTraining grants. The report covers invited
talks, panels, and six breakout sessions. The meeting involved over 80 PIs and
NSF program managers (PMs). The lessons recorded in detail in the report are a
wealth of information that could help current and future PIs, as well as NSF
PMs, understand the future directions suggested by the PI community. The
meeting was held simultaneously with that of the PIs of the NSF
Cyberinfrastructure for Sustained Scientific Innovation (CSSI) program. This
co-location led to two joint sessions: one with NSF speakers and the other on
broader impact. Further, the joint poster and refreshment sessions benefited
from the interactions between CSSI and CyberTraining PIs.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14200" title="Abstract">arXiv:2312.14200</a> [<a href="/pdf/2312.14200" title="Download PDF">pdf</a>, <a href="/format/2312.14200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Architecture Search via Bi-level Data Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tu%2C+C">Chongjun Tu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+P">Peng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weihao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Hancheng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Baopu Li</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Improving the efficiency of Neural Architecture Search (NAS) is a challenging
but significant task that has received much attention. Previous works mainly
adopted the Differentiable Architecture Search (DARTS) and improved its search
strategies or modules to enhance search efficiency. Recently, some methods have
started considering data reduction for speedup, but they are not tightly
coupled with the architecture search process, resulting in sub-optimal
performance. To this end, this work pioneers an exploration into the critical
role of dataset characteristics for DARTS bi-level optimization, and then
proposes a novel Bi-level Data Pruning (BDP) paradigm that targets the weights
and architecture levels of DARTS to enhance efficiency from a data perspective.
Specifically, we introduce a new progressive data pruning strategy that
utilizes supernet prediction dynamics as the metric, to gradually prune
unsuitable samples for DARTS during the search. An effective automatic class
balance constraint is also integrated into BDP, to suppress potential class
imbalances resulting from data-efficient algorithms. Comprehensive evaluations
on the NAS-Bench-201 search space, DARTS search space, and MobileNet-like
search space validate that BDP reduces search costs by over 50% while achieving
superior performance when applied to baseline DARTS. Besides, we demonstrate
that BDP can harmoniously integrate with advanced DARTS variants, like PC-DARTS
and \b{eta}-DARTS, offering an approximately 2 times speedup with minimal
performance compromises.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14201" title="Abstract">arXiv:2312.14201</a> [<a href="/pdf/2312.14201" title="Download PDF">pdf</a>, <a href="/format/2312.14201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Better Visualizing the Decision Basis of Networks via Unfold and  Conquer Attribution Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Jung-Ho Hong</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+W">Woo-Jeoung Nam</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+K">Kyu-Sung Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seong-Whan Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures, Accepted paper in AAAI Conference on Artificial Intelligence (AAAI), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Revealing the transparency of Deep Neural Networks (DNNs) has been widely
studied to describe the decision mechanisms of network inner structures. In
this paper, we propose a novel post-hoc framework, Unfold and Conquer
Attribution Guidance (UCAG), which enhances the explainability of the network
decision by spatially scrutinizing the input features with respect to the model
confidence. Addressing the phenomenon of missing detailed descriptions, UCAG
sequentially complies with the confidence of slices of the image, leading to
providing an abundant and clear interpretation. Therefore, it is possible to
enhance the representation ability of explanation by preserving the detailed
descriptions of assistant input features, which are commonly overwhelmed by the
main meaningful regions. We conduct numerous evaluations to validate the
performance in several metrics: i) deletion and insertion, ii) (energy-based)
pointing games, and iii) positive and negative density maps. Experimental
results, including qualitative comparisons, demonstrate that our method
outperforms the existing methods with the nature of clear and detailed
explanations and applicability.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14202" title="Abstract">arXiv:2312.14202</a> [<a href="/pdf/2312.14202" title="Download PDF">pdf</a>, <a href="/format/2312.14202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Illuminating the Black Box: A Psychometric Investigation into the  Multifaceted Nature of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jordan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S+S">Shou-Hsuan Stephen Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study explores the idea of AI Personality or AInality suggesting that
Large Language Models (LLMs) exhibit patterns similar to human personalities.
Assuming that LLMs share these patterns with humans, we investigate using
human-centered psychometric tests such as the Myers-Briggs Type Indicator
(MBTI), Big Five Inventory (BFI), and Short Dark Triad (SD3) to identify and
confirm LLM personality types. By introducing role-play prompts, we demonstrate
the adaptability of LLMs, showing their ability to switch dynamically between
different personality types. Using projective tests, such as the Washington
University Sentence Completion Test (WUSCT), we uncover hidden aspects of LLM
personalities that are not easily accessible through direct questioning.
Projective tests allowed for a deep exploration of LLMs cognitive processes and
thought patterns and gave us a multidimensional view of AInality. Our machine
learning analysis revealed that LLMs exhibit distinct AInality traits and
manifest diverse personality types, demonstrating dynamic shifts in response to
external instructions. This study pioneers the application of projective tests
on LLMs, shedding light on their diverse and adaptable AInality traits.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14206" title="Abstract">arXiv:2312.14206</a> [<a href="/pdf/2312.14206" title="Download PDF">pdf</a>, <a href="/format/2312.14206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM4VG: Large Language Models Evaluation for Video Grounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+W">Wei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zihan Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuwei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenwu Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, researchers have attempted to investigate the capability of LLMs in
handling videos and proposed several video LLM models. However, the ability of
LLMs to handle video grounding (VG), which is an important time-related video
task requiring the model to precisely locate the start and end timestamps of
temporal moments in videos that match the given textual queries, still remains
unclear and unexplored in literature. To fill the gap, in this paper, we
propose the LLM4VG benchmark, which systematically evaluates the performance of
different LLMs on video grounding tasks. Based on our proposed LLM4VG, we
design extensive experiments to examine two groups of video LLM models on video
grounding: (i) the video LLMs trained on the text-video pairs (denoted as
VidLLM), and (ii) the LLMs combined with pretrained visual description models
such as the video/image captioning model. We propose prompt methods to
integrate the instruction of VG and description from different kinds of
generators, including caption-based generators for direct visual description
and VQA-based generators for information enhancement. We also provide
comprehensive comparisons of various VidLLMs and explore the influence of
different choices of visual models, LLMs, prompt designs, etc, as well. Our
experimental evaluations lead to two conclusions: (i) the existing VidLLMs are
still far away from achieving satisfactory video grounding performance, and
more time-related video tasks should be included to further fine-tune these
models, and (ii) the combination of LLMs and visual models shows preliminary
abilities for video grounding with considerable potential for improvement by
resorting to more reliable models and further guidance of prompt instructions.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14209" title="Abstract">arXiv:2312.14209</a> [<a href="/pdf/2312.14209" title="Download PDF">pdf</a>, <a href="/format/2312.14209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TextFusion: Unveiling the Power of Textual Semantics for Controllable  Image Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+C">Chunyang Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tianyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiao-Jun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hui Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xi Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zhangyong Tang</a>, 
<a href="/search/cs?searchtype=author&query=Kittler%2C+J">Josef Kittler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Advanced image fusion methods are devoted to generating the fusion results by
aggregating the complementary information conveyed by the source images.
However, the difference in the source-specific manifestation of the imaged
scene content makes it difficult to design a robust and controllable fusion
process. We argue that this issue can be alleviated with the help of
higher-level semantics, conveyed by the text modality, which should enable us
to generate fused images for different purposes, such as visualisation and
downstream tasks, in a controllable way. This is achieved by exploiting a
vision-and-language model to build a coarse-to-fine association mechanism
between the text and image signals. With the guidance of the association maps,
an affine fusion unit is embedded in the transformer network to fuse the text
and vision modalities at the feature level. As another ingredient of this work,
we propose the use of textual attention to adapt image quality assessment to
the fusion task. To facilitate the implementation of the proposed text-guided
fusion paradigm, and its adoption by the wider research community, we release a
text-annotated image fusion dataset IVT. Extensive experiments demonstrate that
our approach (TextFusion) consistently outperforms traditional appearance-based
fusion methods. Our code and dataset will be publicly available on the project
homepage.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14210" title="Abstract">arXiv:2312.14210</a> [<a href="/pdf/2312.14210" title="Download PDF">pdf</a>, <a href="/format/2312.14210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forecasting Fold Bifurcations through Physics-Informed Convolutional  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Habib%2C+G">Giuseppe Habib</a>, 
<a href="/search/cs?searchtype=author&query=Horv%C3%A1th%2C+%C3%81">&#xc1;d&#xe1;m Horv&#xe1;th</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Adaptation and Self-Organizing Systems (nlin.AO)

</div>
<p class="mathjax">This study proposes a physics-informed convolutional neural network (CNN) for
identifying dynamical systems' time series near a fold bifurcation. The
peculiarity of this work is that the CNN is trained with a relatively small
amount of data and on a single, very simple system. In contrast, the CNN is
validated on much more complicated systems. A similar task requires significant
extrapolation capabilities, which are obtained by exploiting physics-based
information. Physics-based information is provided through a specific
pre-processing of the input data, consisting mostly of a transformation into
polar coordinates, normalization, transformation into the logarithmic scale,
and filtering through a moving mean. The results illustrate that such data
pre-processing enables the CNN to grasp the important features related to
approaching a fold bifurcation, namely, the trend of the oscillation amplitude,
and neglect other characteristics that are not particularly relevant, such as
the vibration frequency. The developed CNN was able to correctly classify
trajectories near a fold for a mass-on-moving-belt system, a van der
Pol-Duffing oscillator with an attached tuned mass damper, and a
pitch-and-plunge wing profile. The results obtained pave the way for the
development of similar CNNs effective in real-life applications.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14211" title="Abstract">arXiv:2312.14211</a> [<a href="/pdf/2312.14211" title="Download PDF">pdf</a>, <a href="/ps/2312.14211" title="Download PostScript">ps</a>, <a href="/format/2312.14211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimenting with Large Language Models and vector embeddings in NASA  SciX
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blanco-Cuaresma%2C+S">Sergi Blanco-Cuaresma</a>, 
<a href="/search/cs?searchtype=author&query=Ciuc%C4%83%2C+I">Ioana Ciuc&#x103;</a>, 
<a href="/search/cs?searchtype=author&query=Accomazzi%2C+A">Alberto Accomazzi</a>, 
<a href="/search/cs?searchtype=author&query=Kurtz%2C+M+J">Michael J. Kurtz</a>, 
<a href="/search/cs?searchtype=author&query=Henneken%2C+E+A">Edwin A. Henneken</a>, 
<a href="/search/cs?searchtype=author&query=Lockhart%2C+K+E">Kelly E. Lockhart</a>, 
<a href="/search/cs?searchtype=author&query=Grezes%2C+F">Felix Grezes</a>, 
<a href="/search/cs?searchtype=author&query=Allen%2C+T">Thomas Allen</a>, 
<a href="/search/cs?searchtype=author&query=Shapurian%2C+G">Golnaz Shapurian</a>, 
<a href="/search/cs?searchtype=author&query=Grant%2C+C+S">Carolyn S. Grant</a>, 
<a href="/search/cs?searchtype=author&query=Thompson%2C+D+M">Donna M. Thompson</a>, 
<a href="/search/cs?searchtype=author&query=Hostetler%2C+T+W">Timothy W. Hostetler</a>, 
<a href="/search/cs?searchtype=author&query=Templeton%2C+M+R">Matthew R. Templeton</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shinyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Koch%2C+J">Jennifer Koch</a>, 
<a href="/search/cs?searchtype=author&query=Jacovich%2C+T">Taylor Jacovich</a>, 
<a href="/search/cs?searchtype=author&query=Chivvis%2C+D">Daniel Chivvis</a>, 
<a href="/search/cs?searchtype=author&query=de+Macedo+Alves%2C+F">Fernanda de Macedo Alves</a>, 
<a href="/search/cs?searchtype=author&query=Paquin%2C+J">Jean-Claude Paquin</a>, 
<a href="/search/cs?searchtype=author&query=Bartlett%2C+J">Jennifer Bartlett</a>, 
<a href="/search/cs?searchtype=author&query=Polimera%2C+M">Mugdha Polimera</a>, 
<a href="/search/cs?searchtype=author&query=Jarmak%2C+S">Stephanie Jarmak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the proceedings of the 33th annual international Astronomical Data Analysis Software &amp; Systems (ADASS XXXIII)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Open-source Large Language Models enable projects such as NASA SciX (i.e.,
NASA ADS) to think out of the box and try alternative approaches for
information retrieval and data augmentation, while respecting data copyright
and users' privacy. However, when large language models are directly prompted
with questions without any context, they are prone to hallucination. At NASA
SciX we have developed an experiment where we created semantic vectors for our
large collection of abstracts and full-text content, and we designed a prompt
system to ask questions using contextual chunks from our system. Based on a
non-systematic human evaluation, the experiment shows a lower degree of
hallucination and better responses when using Retrieval Augmented Generation.
Further exploration is required to design new features and data augmentation
processes at NASA SciX that leverages this technology while respecting the high
level of trust and quality that the project holds.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14215" title="Abstract">arXiv:2312.14215</a> [<a href="/pdf/2312.14215" title="Download PDF">pdf</a>, <a href="/format/2312.14215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SimLM: Can Language Models Infer Parameters of Physical Systems?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Memery%2C+S">Sean Memery</a>, 
<a href="/search/cs?searchtype=author&query=Lapata%2C+M">Mirella Lapata</a>, 
<a href="/search/cs?searchtype=author&query=Subr%2C+K">Kartic Subr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent developments in large-scale machine learning models for
general-purpose understanding, translation and generation of language are
driving impact across a variety of sectors including medicine, robotics, and
scientific discovery. The strength of such Large Language Models (LLMs) stems
from the large corpora that they are trained with. While this imbues them with
a breadth of capabilities, they have been found unsuitable for some specific
types of problems such as advanced mathematics. In this paper, we highlight the
inability of LLMs to reason about physics tasks. We demonstrate that their
ability to infer parameters of physical systems can be improved, without
retraining, by augmenting their context with feedback from physical simulation.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14216" title="Abstract">arXiv:2312.14216</a> [<a href="/pdf/2312.14216" title="Download PDF">pdf</a>, <a href="/format/2312.14216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreamDistribution: Prompt Distribution Learning for Text-to-Image  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B+N">Brian Nlong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yuhang Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiashu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xinyang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yifan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Itti%2C+L">Laurent Itti</a>, 
<a href="/search/cs?searchtype=author&query=Vineet%2C+V">Vibhav Vineet</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yunhao Ge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The popularization of Text-to-Image (T2I) diffusion models enables the
generation of high-quality images from text descriptions. However, generating
diverse customized images with reference visual attributes remains challenging.
This work focuses on personalizing T2I diffusion models at a more abstract
concept or category level, adapting commonalities from a set of reference
images while creating new instances with sufficient variations. We introduce a
solution that allows a pretrained T2I diffusion model to learn a set of soft
prompts, enabling the generation of novel images by sampling prompts from the
learned distribution. These prompts offer text-guided editing capabilities and
additional flexibility in controlling variation and mixing between multiple
distributions. We also show the adaptability of the learned prompt distribution
to other tasks, such as text-to-3D. Finally we demonstrate effectiveness of our
approach through quantitative analysis including automatic evaluation and human
assessment. Project website: https://briannlongzhao.github.io/DreamDistribution
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14217" title="Abstract">arXiv:2312.14217</a> [<a href="/pdf/2312.14217" title="Download PDF">pdf</a>, <a href="/format/2312.14217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Infrared Curves: An Attack on Infrared Pedestrian Detectors  in the Physical World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chengyin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Weiwen Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Deep neural network security is a persistent concern, with considerable
research on visible light physical attacks but limited exploration in the
infrared domain. Existing approaches, like white-box infrared attacks using
bulb boards and QR suits, lack realism and stealthiness. Meanwhile, black-box
methods with cold and hot patches often struggle to ensure robustness. To
bridge these gaps, we propose Adversarial Infrared Curves (AdvIC). Using
Particle Swarm Optimization, we optimize two Bezier curves and employ cold
patches in the physical realm to introduce perturbations, creating infrared
curve patterns for physical sample generation. Our extensive experiments
confirm AdvIC's effectiveness, achieving 94.8\% and 67.2\% attack success rates
for digital and physical attacks, respectively. Stealthiness is demonstrated
through a comparative analysis, and robustness assessments reveal AdvIC's
superiority over baseline methods. When deployed against diverse advanced
detectors, AdvIC achieves an average attack success rate of 76.8\%, emphasizing
its robust nature. we explore adversarial defense strategies against AdvIC and
examine its impact under various defense mechanisms. Given AdvIC's substantial
security implications for real-world vision-based applications, urgent
attention and mitigation efforts are warranted.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14218" title="Abstract">arXiv:2312.14218</a> [<a href="/pdf/2312.14218" title="Download PDF">pdf</a>, <a href="/format/2312.14218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoAugment Input Transformation for Highly Transferable Targeted  Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Haobo Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+K">Kun He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep Neural Networks (DNNs) are widely acknowledged to be susceptible to
adversarial examples, wherein imperceptible perturbations are added to clean
examples through diverse input transformation attacks. However, these methods
originally designed for non-targeted attacks exhibit low success rates in
targeted attacks. Recent targeted adversarial attacks mainly pay attention to
gradient optimization, attempting to find the suitable perturbation direction.
However, few of them are dedicated to input transformation.In this work, we
observe a positive correlation between the logit/probability of the target
class and diverse input transformation methods in targeted attacks. To this
end, we propose a novel targeted adversarial attack called AutoAugment Input
Transformation (AAIT). Instead of relying on hand-made strategies, AAIT
searches for the optimal transformation policy from a transformation space
comprising various operations. Then, AAIT crafts adversarial examples using the
found optimal transformation policy to boost the adversarial transferability in
targeted attacks. Extensive experiments conducted on CIFAR-10 and
ImageNet-Compatible datasets demonstrate that the proposed AAIT surpasses other
transfer-based targeted attacks significantly.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14219" title="Abstract">arXiv:2312.14219</a> [<a href="/pdf/2312.14219" title="Download PDF">pdf</a>, <a href="/format/2312.14219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DCFL: Non-IID awareness Data Condensation aided Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sha%2C+S">Shaohan Sha</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">YaFeng Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages,17 figures, haven't been published
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated learning is a decentralized learning paradigm wherein a central
server trains a global model iteratively by utilizing clients who possess a
certain amount of private datasets. The challenge lies in the fact that the
client side private data may not be identically and independently distributed,
significantly impacting the accuracy of the global model. Existing methods
commonly address the Non-IID challenge by focusing on optimization, client
selection and data complement. However, most approaches tend to overlook the
perspective of the private data itself due to privacy constraints.Intuitively,
statistical distinctions among private data on the client side can help
mitigate the Non-IID degree. Besides, the recent advancements in dataset
condensation technology have inspired us to investigate its potential
applicability in addressing Non-IID issues while maintaining privacy. Motivated
by this, we propose DCFL which divides clients into groups by using the
Centered Kernel Alignment (CKA) method, then uses dataset condensation methods
with non-IID awareness to complete clients. The private data from clients
within the same group is complementary and their condensed data is accessible
to all clients in the group. Additionally, CKA-guided client selection
strategy, filtering mechanisms, and data enhancement techniques are
incorporated to efficiently and precisely utilize the condensed data, enhance
model performance, and minimize communication time. Experimental results
demonstrate that DCFL achieves competitive performance on popular federated
learning benchmarks including MNIST, FashionMNIST, SVHN, and CIFAR-10 with
existing FL protocol.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14222" title="Abstract">arXiv:2312.14222</a> [<a href="/pdf/2312.14222" title="Download PDF">pdf</a>, <a href="/format/2312.14222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Topology Isomorphism Expertise Embedded Graph Contrastive  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiangmeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yifan Jin</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Hang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Qiang%2C+W">Wenwen Qiang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Changwen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Fuchun Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Graph contrastive learning (GCL) aims to align the positive features while
differentiating the negative features in the latent space by minimizing a
pair-wise contrastive loss. As the embodiment of an outstanding discriminative
unsupervised graph representation learning approach, GCL achieves impressive
successes in various graph benchmarks. However, such an approach falls short of
recognizing the topology isomorphism of graphs, resulting in that graphs with
relatively homogeneous node features cannot be sufficiently discriminated. By
revisiting classic graph topology recognition works, we disclose that the
corresponding expertise intuitively complements GCL methods. To this end, we
propose a novel hierarchical topology isomorphism expertise embedded graph
contrastive learning, which introduces knowledge distillations to empower GCL
models to learn the hierarchical topology isomorphism expertise, including the
graph-tier and subgraph-tier. On top of this, the proposed method holds the
feature of plug-and-play, and we empirically demonstrate that the proposed
method is universal to multiple state-of-the-art GCL models. The solid
theoretical analyses are further provided to prove that compared with
conventional GCL methods, our method acquires the tighter upper bound of Bayes
classification error. We conduct extensive experiments on real-world benchmarks
to exhibit the performance superiority of our method over candidate GCL
methods, e.g., for the real-world graph representation learning experiments,
the proposed method beats the state-of-the-art method by 0.23\% on unsupervised
representation learning setting, 0.43\% on transfer learning setting. Our code
is available at https://github.com/jyf123/HTML.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14223" title="Abstract">arXiv:2312.14223</a> [<a href="/pdf/2312.14223" title="Download PDF">pdf</a>, <a href="/format/2312.14223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Diffusion-Based Counterfactuals for Shortcut Removal and Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weng%2C+N">Nina Weng</a>, 
<a href="/search/cs?searchtype=author&query=Pegios%2C+P">Paraskevas Pegios</a>, 
<a href="/search/cs?searchtype=author&query=Feragen%2C+A">Aasa Feragen</a>, 
<a href="/search/cs?searchtype=author&query=Petersen%2C+E">Eike Petersen</a>, 
<a href="/search/cs?searchtype=author&query=Bigdeli%2C+S">Siavash Bigdeli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Shortcut learning is when a model -- e.g. a cardiac disease classifier --
exploits correlations between the target label and a spurious shortcut feature,
e.g. a pacemaker, to predict the target label based on the shortcut rather than
real discriminative features. This is common in medical imaging, where
treatment and clinical annotations correlate with disease labels, making them
easy shortcuts to predict disease. We propose a novel detection and
quantification of the impact of potential shortcut features via a fast
diffusion-based counterfactual image generation that can synthetically remove
or add shortcuts. Via a novel inpainting-based modification we spatially limit
the changes made with no extra inference step, encouraging the removal of
spatially constrained shortcut features while ensuring that the shortcut-free
counterfactuals preserve their remaining image features to a high degree. Using
these, we assess how shortcut features influence model predictions.
<br />This is enabled by our second contribution: An efficient diffusion-based
counterfactual explanation method with significant inference speed-up at
comparable image quality as state-of-the-art. We confirm this on two large
chest X-ray datasets, a skin lesion dataset, and CelebA.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14226" title="Abstract">arXiv:2312.14226</a> [<a href="/pdf/2312.14226" title="Download PDF">pdf</a>, <a href="/format/2312.14226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep de Finetti: Recovering Topic Distributions from Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=McCoy%2C+R+T">R. Thomas McCoy</a>, 
<a href="/search/cs?searchtype=author&query=Sumers%2C+T+R">Theodore R. Sumers</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jian-Qiao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Griffiths%2C+T+L">Thomas L. Griffiths</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Large language models (LLMs) can produce long, coherent passages of text,
suggesting that LLMs, although trained on next-word prediction, must represent
the latent structure that characterizes a document. Prior work has found that
internal representations of LLMs encode one aspect of latent structure, namely
syntax; here we investigate a complementary aspect, namely the document's topic
structure. We motivate the hypothesis that LLMs capture topic structure by
connecting LLM optimization to implicit Bayesian inference. De Finetti's
theorem shows that exchangeable probability distributions can be represented as
a mixture with respect to a latent generating distribution. Although text is
not exchangeable at the level of syntax, exchangeability is a reasonable
starting assumption for topic structure. We thus hypothesize that predicting
the next token in text will lead LLMs to recover latent topic distributions. We
examine this hypothesis using Latent Dirichlet Allocation (LDA), an
exchangeable probabilistic topic model, as a target, and we show that the
representations formed by LLMs encode both the topics used to generate
synthetic data and those used to explain natural corpus data.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14227" title="Abstract">arXiv:2312.14227</a> [<a href="/pdf/2312.14227" title="Download PDF">pdf</a>, <a href="/format/2312.14227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ElasticTrainer: Speeding Up On-Device Training with Runtime Elastic  Tensor Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Boyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Wei Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> published at ACM MobiSys 2023. 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">On-device training is essential for neural networks (NNs) to continuously
adapt to new online data, but can be time-consuming due to the device's limited
computing power. To speed up on-device training, existing schemes select
trainable NN portion offline or conduct unrecoverable selection at runtime, but
the evolution of trainable NN portion is constrained and cannot adapt to the
current need for training. Instead, runtime adaptation of on-device training
should be fully elastic, i.e., every NN substructure can be freely removed from
or added to the trainable NN portion at any time in training. In this paper, we
present ElasticTrainer, a new technique that enforces such elasticity to
achieve the required training speedup with the minimum NN accuracy loss.
Experiment results show that ElasticTrainer achieves up to 3.5x more training
speedup in wall-clock time and reduces energy consumption by 2x-3x more
compared to the existing schemes, without noticeable accuracy loss.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14229" title="Abstract">arXiv:2312.14229</a> [<a href="/pdf/2312.14229" title="Download PDF">pdf</a>, <a href="/format/2312.14229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time Neural Network Inference on Extremely Weak Devices: Agile  Offloading with Explainable AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Wei Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> published at ACM MobiCom 2022. 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the wide adoption of AI applications, there is a pressing need of
enabling real-time neural network (NN) inference on small embedded devices, but
deploying NNs and achieving high performance of NN inference on these small
devices is challenging due to their extremely weak capabilities. Although NN
partitioning and offloading can contribute to such deployment, they are
incapable of minimizing the local costs at embedded devices. Instead, we
suggest to address this challenge via agile NN offloading, which migrates the
required computations in NN offloading from online inference to offline
learning. In this paper, we present AgileNN, a new NN offloading technique that
achieves real-time NN inference on weak embedded devices by leveraging
eXplainable AI techniques, so as to explicitly enforce feature sparsity during
the training phase and minimize the online computation and communication costs.
Experiment results show that AgileNN's inference latency is &gt;6x lower than the
existing schemes, ensuring that sensory data on embedded devices can be timely
consumed. It also reduces the local device's resource consumption by &gt;8x,
without impairing the inference accuracy.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14230" title="Abstract">arXiv:2312.14230</a> [<a href="/pdf/2312.14230" title="Download PDF">pdf</a>, <a href="/format/2312.14230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Don&#x27;t slip into binary thinking about AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bristow%2C+T">Thorin Bristow</a>, 
<a href="/search/cs?searchtype=author&query=Thorburn%2C+L">Luke Thorburn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">In discussions about the development and governance of AI, a false binary is
often drawn between two groups: those most concerned about the existing, social
impacts of AI, and those most concerned about possible future risks of powerful
AI systems taking actions that don't align with human interests. In this piece,
we (i) describe the emergence of this false binary, (ii) explain why the
seemingly clean distinctions drawn between these two groups don't hold up under
scrutiny and (iii) highlight efforts to bridge this divide.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14231" title="Abstract">arXiv:2312.14231</a> [<a href="/pdf/2312.14231" title="Download PDF">pdf</a>, <a href="/format/2312.14231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building Your Own Product Copilot: Challenges, Opportunities, and Needs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parnin%2C+C">Chris Parnin</a>, 
<a href="/search/cs?searchtype=author&query=Soares%2C+G">Gustavo Soares</a>, 
<a href="/search/cs?searchtype=author&query=Pandita%2C+R">Rahul Pandita</a>, 
<a href="/search/cs?searchtype=author&query=Gulwani%2C+S">Sumit Gulwani</a>, 
<a href="/search/cs?searchtype=author&query=Rich%2C+J">Jessica Rich</a>, 
<a href="/search/cs?searchtype=author&query=Henley%2C+A+Z">Austin Z. Henley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">A race is underway to embed advanced AI capabilities into products. These
product copilots enable users to ask questions in natural language and receive
relevant responses that are specific to the user's context. In fact, virtually
every large technology company is looking to add these capabilities to their
software products. However, for most software engineers, this is often their
first encounter with integrating AI-powered technology. Furthermore, software
engineering processes and tools have not caught up with the challenges and
scale involved with building AI-powered applications. In this work, we present
the findings of an interview study with 26 professional software engineers
responsible for building product copilots at various companies. From our
interviews, we found pain points at every step of the engineering process and
the challenges that strained existing development practices. We then conducted
group brainstorming sessions to collaborative on opportunities and tool designs
for the broader software engineering community.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14232" title="Abstract">arXiv:2312.14232</a> [<a href="/pdf/2312.14232" title="Download PDF">pdf</a>, <a href="/format/2312.14232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parrot Captions Teach CLIP to Spot Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yiqi Lin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Conghui He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A+J">Alex Jinpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weijia Li</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project page: <a href="https://linyq17.github.io/CLIP-Parrot-Bias/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite CLIP being the foundation model in numerous vision-language
applications, the CLIP suffers from a severe text spotting bias. Such bias
causes CLIP models to `Parrot' the visual text embedded within images while
disregarding the authentic visual semantics. We uncover that in the most
popular image-text dataset LAION-2B, the captions also densely parrot (spell)
the text embedded in images. Our analysis shows that around \textbf{50\%} of
images are embedded with visual text content, and \textbf{90\%} of their
captions more or less parrot the visual text. Based on such observation, we
thoroughly inspect the different release d versions of CLIP models and verify
that the visual text is the dominant factor in measuring the LAION-style
image-text similarity for these models. To examine whether these parrot
captions shape the text spotting bias, we train a series of CLIP models with
LAION subsets curated by different parrot-caption-oriented criteria. We show
that training with parrot captions easily shapes such bias but harms the
expected visual-language representation learning in CLIP models. This suggests
that it is urgent to revisit either the design of CLIP-like models or the
existing image-text dataset curation pipeline built on CLIP score filtering.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14233" title="Abstract">arXiv:2312.14233</a> [<a href="/pdf/2312.14233" title="Download PDF">pdf</a>, <a href="/format/2312.14233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VCoder: Versatile Vision Encoders for Multimodal Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+J">Jitesh Jain</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Humphrey Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://praeclarumjj3.github.io/vcoder/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Humans possess the remarkable skill of Visual Perception, the ability to see
and understand the seen, helping them make sense of the visual world and, in
turn, reason. Multimodal Large Language Models (MLLM) have recently achieved
impressive performance on vision-language tasks ranging from visual
question-answering and image captioning to visual reasoning and image
generation. However, when prompted to identify or count (perceive) the entities
in a given image, existing MLLM systems fail. Working towards developing an
accurate MLLM system for perception and reasoning, we propose using Versatile
vision enCoders (VCoder) as perception eyes for Multimodal LLMs. We feed the
VCoder with perception modalities such as segmentation or depth maps, improving
the MLLM's perception abilities. Secondly, we leverage the images from COCO and
outputs from off-the-shelf vision perception models to create our COCO
Segmentation Text (COST) dataset for training and evaluating MLLMs on the
object perception task. Thirdly, we introduce metrics to assess the object
perception abilities in MLLMs on our COST dataset. Lastly, we provide extensive
experimental evidence proving the VCoder's improved object-level perception
skills over existing Multimodal LLMs, including GPT-4V. We open-source our
dataset, code, and models to promote research. We open-source our code at
https://github.com/SHI-Labs/VCoder
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14235" title="Abstract">arXiv:2312.14235</a> [<a href="/pdf/2312.14235" title="Download PDF">pdf</a>, <a href="/format/2312.14235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Spline Fields for Burst Image Fusion and Layer Separation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chugunov%2C+I">Ilya Chugunov</a>, 
<a href="/search/cs?searchtype=author&query=Shustin%2C+D">David Shustin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Ruyu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+C">Chenyang Lei</a>, 
<a href="/search/cs?searchtype=author&query=Heide%2C+F">Felix Heide</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project website: <a href="https://light.princeton.edu/publication/nsf">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Each photo in an image burst can be considered a sample of a complex 3D
scene: the product of parallax, diffuse and specular materials, scene motion,
and illuminant variation. While decomposing all of these effects from a stack
of misaligned images is a highly ill-conditioned task, the conventional
align-and-merge burst pipeline takes the other extreme: blending them into a
single image. In this work, we propose a versatile intermediate representation:
a two-layer alpha-composited image plus flow model constructed with neural
spline fields -- networks trained to map input coordinates to spline control
points. Our method is able to, during test-time optimization, jointly fuse a
burst image capture into one high-resolution reconstruction and decompose it
into transmission and obstruction layers. Then, by discarding the obstruction
layer, we can perform a range of tasks including seeing through occlusions,
reflection suppression, and shadow removal. Validated on complex synthetic and
in-the-wild captures we find that, with no post-processing steps or learned
priors, our generalizable model is able to outperform existing dedicated
single-image and multi-view obstruction removal approaches.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14238" title="Abstract">arXiv:2312.14238</a> [<a href="/pdf/2312.14238" title="Download PDF">pdf</a>, <a href="/format/2312.14238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InternVL: Scaling up Vision Foundation Models and Aligning for Generic  Visual-Linguistic Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiannan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+W">Weijie Su</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+S">Sen Xing</a>, 
<a href="/search/cs?searchtype=author&query=Muyan%2C+Z">Zhong Muyan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qinglong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xizhou Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Lewei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bin Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jifeng Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 5 figures, 28 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The exponential growth of large language models (LLMs) has opened up numerous
possibilities for multi-modal AGI systems. However, the progress in vision and
vision-language foundation models, which are also critical elements of
multi-modal AGI, has not kept pace with LLMs. In this work, we design a
large-scale vision-language foundation model (InternVL), which scales up the
vision foundation model to 6 billion parameters and progressively aligns it
with the large language model, using web-scale image-text data from various
sources. This model can be broadly applied to and achieve state-of-the-art
performance on visual perception tasks such as image-level or pixel-level
recognition, vision-language tasks such as zero-shot image/video
classification, zero-shot image/video-text retrieval, and link with LLMs to
create multi-modal dialogue systems. We hope that our research could contribute
to the development of multi-modal large models. Code and models are available
at https://github.com/OpenGVLab/InternVL.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14239" title="Abstract">arXiv:2312.14239</a> [<a href="/pdf/2312.14239" title="Download PDF">pdf</a>, <a href="/format/2312.14239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PlatoNeRF: 3D Reconstruction in Plato&#x27;s Cave via Single-View Two-Bounce  Lidar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klinghoffer%2C+T">Tzofi Klinghoffer</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+X">Xiaoyu Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Somasundaram%2C+S">Siddharth Somasundaram</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yuchen Fan</a>, 
<a href="/search/cs?searchtype=author&query=Richardt%2C+C">Christian Richardt</a>, 
<a href="/search/cs?searchtype=author&query=Raskar%2C+R">Ramesh Raskar</a>, 
<a href="/search/cs?searchtype=author&query=Ranjan%2C+R">Rakesh Ranjan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://platonerf.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">3D reconstruction from a single-view is challenging because of the ambiguity
from monocular cues and lack of information about occluded regions. Neural
radiance fields (NeRF), while popular for view synthesis and 3D reconstruction,
are typically reliant on multi-view images. Existing methods for single-view 3D
reconstruction with NeRF rely on either data priors to hallucinate views of
occluded regions, which may not be physically accurate, or shadows observed by
RGB cameras, which are difficult to detect in ambient light and low albedo
backgrounds. We propose using time-of-flight data captured by a single-photon
avalanche diode to overcome these limitations. Our method models two-bounce
optical paths with NeRF, using lidar transient data for supervision. By
leveraging the advantages of both NeRF and two-bounce light measured by lidar,
we demonstrate that we can reconstruct visible and occluded geometry without
data priors or reliance on controlled ambient lighting or scene albedo. In
addition, we demonstrate improved generalization under practical constraints on
sensor spatial- and temporal-resolution. We believe our method is a promising
direction as single-photon lidars become ubiquitous on consumer devices, such
as phones, tablets, and headsets.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14247" title="Abstract">arXiv:2312.14247</a> [<a href="/pdf/2312.14247" title="Download PDF">pdf</a>, <a href="/format/2312.14247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning Based Placement for Integrated Access  Backhauling in UAV-Assisted Wireless Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuhui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Farooq%2C+J">Junaid Farooq</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">The advent of fifth generation (5G) networks has opened new avenues for
enhancing connectivity, particularly in challenging environments like remote
areas or disaster-struck regions. Unmanned aerial vehicles (UAVs) have been
identified as a versatile tool in this context, particularly for improving
network performance through the Integrated access and backhaul (IAB) feature of
5G. However, existing approaches to UAV-assisted network enhancement face
limitations in dynamically adapting to varying user locations and network
demands. This paper introduces a novel approach leveraging deep reinforcement
learning (DRL) to optimize UAV placement in real-time, dynamically adjusting to
changing network conditions and user requirements. Our method focuses on the
intricate balance between fronthaul and backhaul links, a critical aspect often
overlooked in current solutions. The unique contribution of this work lies in
its ability to autonomously position UAVs in a way that not only ensures robust
connectivity to ground users but also maintains seamless integration with
central network infrastructure. Through various simulated scenarios, we
demonstrate how our approach effectively addresses these challenges, enhancing
coverage and network performance in critical areas. This research fills a
significant gap in UAV-assisted 5G networks, providing a scalable and adaptive
solution for future mobile networks.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14248" title="Abstract">arXiv:2312.14248</a> [<a href="/pdf/2312.14248" title="Download PDF">pdf</a>, <a href="/format/2312.14248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Understanding Underwater Weather Events in Rivers Using  Autonomous Surface Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+A+K">Alice K. Li</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yue Mao</a>, 
<a href="/search/cs?searchtype=author&query=Manjanna%2C+S">Sandeep Manjanna</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sixuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dhanoa%2C+J">Jasleen Dhanoa</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+B">Bharg Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Edwards%2C+V+M">Victoria M. Edwards</a>, 
<a href="/search/cs?searchtype=author&query=Ojeda%2C+F+C">Fernando Cladera Ojeda</a>, 
<a href="/search/cs?searchtype=author&query=Men%2C+M+L">Ma&#xeb;l Le Men</a>, 
<a href="/search/cs?searchtype=author&query=Sigg%2C+E">Eric Sigg</a>, 
<a href="/search/cs?searchtype=author&query=Ulloa%2C+H+N">Hugo N. Ulloa</a>, 
<a href="/search/cs?searchtype=author&query=Jerolmack%2C+D+J">Douglas J. Jerolmack</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+M+A">M. Ani Hsieh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published to IEEE OCEANS 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Climate change has increased the frequency and severity of extreme weather
events such as hurricanes and winter storms. The complex interplay of floods
with tides, runoff, and sediment creates additional hazards -- including
erosion and the undermining of urban infrastructure -- consequently impacting
the health of our rivers and ecosystems. Observations of these underwater
phenomena are rare, because satellites and sensors mounted on aerial vehicles
cannot penetrate the murky waters. Autonomous Surface Vehicles (ASVs) provides
a means to track and map these complex and dynamic underwater phenomena. This
work highlights preliminary results of high-resolution data gathering with
ASVs, equipped with a suite of sensors capable of measuring physical and
chemical parameters of the river. Measurements were acquired along the lower
Schuylkill River in the Philadelphia area at high-tide and low-tide conditions.
The data will be leveraged to improve our understanding of changes in
bathymetry due to floods; the dynamics of mixing and stagnation zones and their
impact on water quality; and the dynamics of suspension and resuspension of
fine sediment. The data will also provide insight into the development of
adaptive sampling strategies for ASVs that can maximize the information gain
for future field experiments.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14250" title="Abstract">arXiv:2312.14250</a> [<a href="/pdf/2312.14250" title="Download PDF">pdf</a>, <a href="/format/2312.14250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HElium: A Language and Compiler for Fully Homomorphic Encryption with  Support for Proxy Re-Encryption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%C3%BCnther%2C+M">Mirko G&#xfc;nther</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%BCtze%2C+L">Lars Sch&#xfc;tze</a>, 
<a href="/search/cs?searchtype=author&query=Becher%2C+K">Kilian Becher</a>, 
<a href="/search/cs?searchtype=author&query=Strufe%2C+T">Thorsten Strufe</a>, 
<a href="/search/cs?searchtype=author&query=Castrillon%2C+J">Jeronimo Castrillon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures, 1 algorithm
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Privacy-preserving analysis of confidential data can increase the value of
such data and even improve peoples' lives. Fully homomorphic encryption (FHE)
can enable privacy-preserving analysis. However, FHE adds a large amount of
computational overhead and its efficient use requires a high level of
expertise. Compilers can automate certain aspects such as parameterization and
circuit optimizations. This in turn makes FHE accessible to non-cryptographers.
Yet, multi-party scenarios remain complicated and exclude many promising use
cases such as analyses of large amounts of health records for medical research.
Proxy re-encryption (PRE), a technique that allows the conversion of data from
multiple sources to a joint encryption key, can enable FHE for multi-party
scenarios. Today, there are no optimizing compilers for FHE with PRE
capabilities.
<br />We propose HElium, the first optimizing FHE compiler with native support for
proxy re-encryption. HElium features HEDSL, a domain-specific language (DSL)
specifically designed for multi-party scenarios. By tracking encryption keys
and transforming the computation circuit during compilation, HElium minimizes
the number of expensive PRE operations. We evaluate the effectiveness of
HElium's optimizations based on the real-world use case of the tumor recurrence
rate, a well-known subject of medical research. Our empirical evaluation shows
that HElium substantially reduces the overhead introduced through complex PRE
operations, an effect that increases for larger amounts of input data.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14252" title="Abstract">arXiv:2312.14252</a> [<a href="/pdf/2312.14252" title="Download PDF">pdf</a>, <a href="/format/2312.14252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Adaptive Constraints in Nonlinear FETI-DP Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Klawonn%2C+A">Axel Klawonn</a>, 
<a href="/search/math?searchtype=author&query=Lanser%2C+M">Martin Lanser</a>, 
<a href="/search/math?searchtype=author&query=Weber%2C+J">Janine Weber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">While linear FETI-DP (Finite Element Tearing and Interconnecting - Dual
Primal) is an efficient iterative domain decomposition solver for discretized
linear PDEs (partial differential equations), nonlinear FETI-DP is its
consequent extension to the nonlinear case. In both methods, the parallel
efficiency of the method results from a decomposition of the computational
domain into nonoverlapping subdomains and a resulting localization of the
computational work. For a fast linear convergence of the linear FETI-DP method,
a global coarse problem has to be considered. Adaptive coarse spaces are
provably robust variants for many complicated micro-heterogeneous problems, as,
for example, stationary diffusion problems with large jumps in the diffusion
coefficient. Unfortunately, the set-up and exact computation of adaptive coarse
spaces is known to be computationally expensive. Therefore, recently, surrogate
models based on neural networks have been trained to directly predict the
adaptive coarse constraints. Here, these learned constraints are implemented in
nonlinear FETI-DP and it is shown numerically that they are able to improve the
nonlinear as well as linear convergence speed of nonlinear FETI-DP.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14254" title="Abstract">arXiv:2312.14254</a> [<a href="/pdf/2312.14254" title="Download PDF">pdf</a>, <a href="/format/2312.14254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextual Feature Selection with Conditional Stochastic Gates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sristi%2C+R+D">Ram Dyuthi Sristi</a>, 
<a href="/search/cs?searchtype=author&query=Lindenbaum%2C+O">Ofir Lindenbaum</a>, 
<a href="/search/cs?searchtype=author&query=Lavzin%2C+M">Maria Lavzin</a>, 
<a href="/search/cs?searchtype=author&query=Schiller%2C+J">Jackie Schiller</a>, 
<a href="/search/cs?searchtype=author&query=Mishne%2C+G">Gal Mishne</a>, 
<a href="/search/cs?searchtype=author&query=Benisty%2C+H">Hadas Benisty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">We study the problem of contextual feature selection, where the goal is to
learn a predictive function while identifying subsets of informative features
conditioned on specific contexts. Towards this goal, we generalize the recently
proposed stochastic gates (STG) Yamada et al. [2020] by modeling the
probabilistic gates as conditional Bernoulli variables whose parameters are
predicted based on the contextual variables. Our new scheme, termed
conditional-STG (c-STG), comprises two networks: a hypernetwork that
establishes the mapping between contextual variables and probabilistic feature
selection parameters and a prediction network that maps the selected feature to
the response variable. Training the two networks simultaneously ensures the
comprehensive incorporation of context and feature selection within a unified
model. We provide a theoretical analysis to examine several properties of the
proposed framework. Importantly, our model leads to improved flexibility and
adaptability of feature selection and, therefore, can better capture the
nuances and variations in the data. We apply c-STG to simulated and real-world
datasets, including healthcare, housing, and neuroscience, and demonstrate that
it effectively selects contextually meaningful features, thereby enhancing
predictive performance and interpretability.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14259" title="Abstract">arXiv:2312.14259</a> [<a href="/pdf/2312.14259" title="Download PDF">pdf</a>, <a href="/format/2312.14259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Bandit Learning through Heterogeneous Action Erasure  Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hanna%2C+O+A">Osama A. Hanna</a>, 
<a href="/search/cs?searchtype=author&query=Karakas%2C+M">Merve Karakas</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L+F">Lin F. Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fragouli%2C+C">Christina Fragouli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Multi-Armed Bandit (MAB) systems are witnessing an upswing in applications
within multi-agent distributed environments, leading to the advancement of
collaborative MAB algorithms. In such settings, communication between agents
executing actions and the primary learner making decisions can hinder the
learning process. A prevalent challenge in distributed learning is action
erasure, often induced by communication delays and/or channel noise. This
results in agents possibly not receiving the intended action from the learner,
subsequently leading to misguided feedback. In this paper, we introduce novel
algorithms that enable learners to interact concurrently with distributed
agents across heterogeneous action erasure channels with different action
erasure probabilities. We illustrate that, in contrast to existing bandit
algorithms, which experience linear regret, our algorithms assure sub-linear
regret guarantees. Our proposed solutions are founded on a meticulously crafted
repetition protocol and scheduling of learning across heterogeneous channels.
To our knowledge, these are the first algorithms capable of effectively
learning through heterogeneous action erasure channels. We substantiate the
superior performance of our algorithm through numerical experiments,
emphasizing their practical significance in addressing issues related to
communication constraints and delays in multi-agent environments.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14260" title="Abstract">arXiv:2312.14260</a> [<a href="/pdf/2312.14260" title="Download PDF">pdf</a>, <a href="/format/2312.14260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Elevating Defenses: Bridging Adversarial Training and Watermarking for  Model Resilience
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thakkar%2C+J">Janvi Thakkar</a>, 
<a href="/search/cs?searchtype=author&query=Zizzo%2C+G">Giulio Zizzo</a>, 
<a href="/search/cs?searchtype=author&query=Maffeis%2C+S">Sergio Maffeis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at DAI Workshop, AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Machine learning models are being used in an increasing number of critical
applications; thus, securing their integrity and ownership is critical. Recent
studies observed that adversarial training and watermarking have a conflicting
interaction. This work introduces a novel framework to integrate adversarial
training with watermarking techniques to fortify against evasion attacks and
provide confident model verification in case of intellectual property theft. We
use adversarial training together with adversarial watermarks to train a robust
watermarked model. The key intuition is to use a higher perturbation budget to
generate adversarial watermarks compared to the budget used for adversarial
training, thus avoiding conflict. We use the MNIST and Fashion-MNIST datasets
to evaluate our proposed technique on various model stealing attacks. The
results obtained consistently outperform the existing baseline in terms of
robustness performance and further prove the resilience of this defense against
pruning and fine-tuning removal attacks.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14261" title="Abstract">arXiv:2312.14261</a> [<a href="/pdf/2312.14261" title="Download PDF">pdf</a>, <a href="/format/2312.14261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-power event-based face detection with asynchronous neuromorphic  hardware
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caccavella%2C+C">Caterina Caccavella</a>, 
<a href="/search/cs?searchtype=author&query=Paredes-Vall%C3%A9s%2C+F">Federico Paredes-Vall&#xe9;s</a>, 
<a href="/search/cs?searchtype=author&query=Cannici%2C+M">Marco Cannici</a>, 
<a href="/search/cs?searchtype=author&query=Khacef%2C+L">Lyes Khacef</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">The rise of mobility, IoT and wearables has shifted processing to the edge of
the sensors, driven by the need to reduce latency, communication costs and
overall energy consumption. While deep learning models have achieved remarkable
results in various domains, their deployment at the edge for real-time
applications remains computationally expensive. Neuromorphic computing emerges
as a promising paradigm shift, characterized by co-localized memory and
computing as well as event-driven asynchronous sensing and processing. In this
work, we demonstrate the possibility of solving the ubiquitous computer vision
task of object detection at the edge with low-power requirements, using the
event-based N-Caltech101 dataset. We present the first instance of an on-chip
spiking neural network for event-based face detection deployed on the SynSense
Speck neuromorphic chip, which comprises both an event-based sensor and a
spike-based asynchronous processor implementing Integrate-and-Fire neurons. We
show how to reduce precision discrepancies between off-chip clock-driven
simulation used for training and on-chip event-driven inference. This involves
using a multi-spike version of the Integrate-and-Fire neuron on simulation,
where spikes carry values that are proportional to the extent the membrane
potential exceeds the firing threshold. We propose a robust strategy to train
spiking neural networks with back-propagation through time using multi-spike
activation and firing rate regularization and demonstrate how to decode output
spikes into bounding boxes. We show that the power consumption of the chip is
directly proportional to the number of synaptic operations in the spiking
neural network, and we explore the trade-off between power consumption and
detection precision with different firing rate regularization, achieving an
on-chip face detection mAP[0.5] of ~0.6 while consuming only ~20 mW.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14262" title="Abstract">arXiv:2312.14262</a> [<a href="/pdf/2312.14262" title="Download PDF">pdf</a>, <a href="/ps/2312.14262" title="Download PostScript">ps</a>, <a href="/format/2312.14262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the intersection of Generative AI and Software Development
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Calegario%2C+F">Filipe Calegario</a>, 
<a href="/search/cs?searchtype=author&query=Bur%C3%A9gio%2C+V">Vanilson Bur&#xe9;gio</a>, 
<a href="/search/cs?searchtype=author&query=Erivaldo%2C+F">Francisco Erivaldo</a>, 
<a href="/search/cs?searchtype=author&query=Andrade%2C+D+M+C">Daniel Moraes Costa Andrade</a>, 
<a href="/search/cs?searchtype=author&query=Felix%2C+K">Kailane Felix</a>, 
<a href="/search/cs?searchtype=author&query=Barbosa%2C+N">Nathalia Barbosa</a>, 
<a href="/search/cs?searchtype=author&query=da+Silva+Lucena%2C+P+L">Pedro Lucas da Silva Lucena</a>, 
<a href="/search/cs?searchtype=author&query=Fran%C3%A7a%2C+C">C&#xe9;sar Fran&#xe7;a</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the ever-evolving landscape of Artificial Intelligence (AI), the synergy
between generative AI and Software Engineering emerges as a transformative
frontier. This whitepaper delves into the unexplored realm, elucidating how
generative AI techniques can revolutionize software development. Spanning from
project management to support and updates, we meticulously map the demands of
each development stage and unveil the potential of generative AI in addressing
them. Techniques such as zero-shot prompting, self-consistency, and multimodal
chain-of-thought are explored, showcasing their unique capabilities in
enhancing generative AI models. The significance of vector embeddings, context,
plugins, tools, and code assistants is underscored, emphasizing their role in
capturing semantic information and amplifying generative AI capabilities.
Looking ahead, this intersection promises to elevate productivity, improve code
quality, and streamline the software development process. This whitepaper
serves as a guide for stakeholders, urging discussions and experiments in the
application of generative AI in Software Engineering, fostering innovation and
collaboration for a qualitative leap in the efficiency and effectiveness of
software development.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14264" title="Abstract">arXiv:2312.14264</a> [<a href="/pdf/2312.14264" title="Download PDF">pdf</a>, <a href="/ps/2312.14264" title="Download PostScript">ps</a>, <a href="/format/2312.14264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimental demonstration of magnetic tunnel junction-based  computational random-access memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lv%2C+Y">Yang Lv</a>, 
<a href="/search/cs?searchtype=author&query=Zink%2C+B+R">Brandon R. Zink</a>, 
<a href="/search/cs?searchtype=author&query=Bloom%2C+R+P">Robert P. Bloom</a>, 
<a href="/search/cs?searchtype=author&query=C%C4%B1lasun%2C+H">H&#xfc;srev C&#x131;lasun</a>, 
<a href="/search/cs?searchtype=author&query=Khanal%2C+P">Pravin Khanal</a>, 
<a href="/search/cs?searchtype=author&query=Resch%2C+S">Salonik Resch</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+Z">Zamshed Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Habiboglu%2C+A">Ali Habiboglu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weigang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sapatnekar%2C+S+S">Sachin S. Sapatnekar</a>, 
<a href="/search/cs?searchtype=author&query=Karpuczu%2C+U">Ulya Karpuczu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jian-Ping Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Mesoscale and Nanoscale Physics (cond-mat.mes-hall); Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR); Systems and Control (eess.SY)

</div>
<p class="mathjax">Conventional computing paradigm struggles to fulfill the rapidly growing
demands from emerging applications, especially those for machine intelligence,
because much of the power and energy is consumed by constant data transfers
between logic and memory modules. A new paradigm, called "computational
random-access memory (CRAM)" has emerged to address this fundamental
limitation. CRAM performs logic operations directly using the memory cells
themselves, without having the data ever leave the memory. The energy and
performance benefits of CRAM for both conventional and emerging applications
have been well established by prior numerical studies. However, there lacks an
experimental demonstration and study of CRAM to evaluate its computation
accuracy, which is a realistic and application-critical metrics for its
technological feasibility and competitiveness. In this work, a CRAM array based
on magnetic tunnel junctions (MTJs) is experimentally demonstrated. First,
basic memory operations as well as 2-, 3-, and 5-input logic operations are
studied. Then, a 1-bit full adder with two different designs is demonstrated.
Based on the experimental results, a suite of modeling has been developed to
characterize the accuracy of CRAM computation. Further analysis of scalar
addition, multiplication, and matrix multiplication shows promising results.
These results are then applied to a complete application: a neural network
based handwritten digit classifier, as an example to show the connection
between the application performance and further MTJ development. The classifier
achieved almost-perfect classification accuracy, with reasonable projections of
future MTJ development. With the confirmation of MTJ-based CRAM's accuracy,
there is a strong case that this technology will have a significant impact on
power- and energy-demanding applications of machine intelligence.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14276" title="Abstract">arXiv:2312.14276</a> [<a href="/pdf/2312.14276" title="Download PDF">pdf</a>, <a href="/ps/2312.14276" title="Download PostScript">ps</a>, <a href="/format/2312.14276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Neural Networks and Finite Elements of Any Order on Arbitrary  Dimensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=He%2C+J">Juncai He</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+J">Jinchao Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this study, we establish that deep neural networks employing ReLU and
ReLU$^2$ activation functions are capable of representing Lagrange finite
element functions of any order on simplicial meshes across arbitrary
dimensions. We introduce a novel global formulation of the basis functions for
Lagrange elements, grounded in a geometric decomposition of these elements and
leveraging two essential properties of high-dimensional simplicial meshes and
barycentric coordinate functions. This representation theory facilitates a
natural approximation result for such deep neural networks. Our findings
present the first demonstration of how deep neural networks can systematically
generate general continuous piecewise polynomial functions.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14279" title="Abstract">arXiv:2312.14279</a> [<a href="/pdf/2312.14279" title="Download PDF">pdf</a>, <a href="/format/2312.14279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing and Classifying Developer Forum Posts with their  Intentions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xingfang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Laufer%2C+E">Eric Laufer</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Heng Li</a>, 
<a href="/search/cs?searchtype=author&query=Khomh%2C+F">Foutse Khomh</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+S">Santhosh Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jayden Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">With the rapid growth of the developer community, the amount of posts on
online technical forums has been growing rapidly, which poses difficulties for
users to filter useful posts and find important information. Tags provide a
concise feature dimension for users to locate their interested posts and for
search engines to index the most relevant posts according to the queries.
However, most tags are only focused on the technical perspective (e.g., program
language, platform, tool). In most cases, forum posts in online developer
communities reveal the author's intentions to solve a problem, ask for advice,
share information, etc. The modeling of the intentions of posts can provide an
extra dimension to the current tag taxonomy. By referencing previous studies
and learning from industrial perspectives, we create a refined taxonomy for the
intentions of technical forum posts. Through manual labeling and analysis on a
sampled post dataset extracted from online forums, we understand the relevance
between the constitution of posts (code, error messages) and their intentions.
Furthermore, inspired by our manual study, we design a pre-trained
transformer-based model to automatically predict post intentions. The best
variant of our intention prediction framework, which achieves a Micro F1-score
of 0.589, Top 1-3 accuracy of 62.6% to 87.8%, and an average AUC of 0.787,
outperforms the state-of-the-art baseline approach. Our characterization and
automated classification of forum posts regarding their intentions may help
forum maintainers or third-party tool developers improve the organization and
retrieval of posts on technical forums. We have released our annotated dataset
and codes in our supplementary material package.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14280" title="Abstract">arXiv:2312.14280</a> [<a href="/pdf/2312.14280" title="Download PDF">pdf</a>, <a href="/format/2312.14280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-grained Forecasting Models Via Gaussian Process Blurring Effect
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koohfar%2C+S">Sepideh Koohfar</a>, 
<a href="/search/cs?searchtype=author&query=Dietz%2C+L">Laura Dietz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Time series forecasting is a challenging task due to the existence of complex
and dynamic temporal dependencies. This can lead to incorrect predictions by
even the best forecasting models. Using more training data is one way to
improve the accuracy, but this source is often limited. In contrast, we are
building on successful denoising approaches for image generation by advocating
for an end-to-end forecasting and denoising paradigm.
<br />We propose an end-to-end forecast-blur-denoise forecasting framework by
encouraging a division of labors between the forecasting and the denoising
models. The initial forecasting model is directed to focus on accurately
predicting the coarse-grained behavior, while the denoiser model focuses on
capturing the fine-grained behavior that is locally blurred by integrating a
Gaussian Process model. All three parts are interacting for the best end-to-end
performance. Our extensive experiments demonstrate that our proposed approach
is able to improve the forecasting accuracy of several state-of-the-art
forecasting models as well as several other denoising approaches.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14291" title="Abstract">arXiv:2312.14291</a> [<a href="/pdf/2312.14291" title="Download PDF">pdf</a>, <a href="/format/2312.14291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Join
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghadakchi%2C+V">Vahid Ghadakchi</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+M">Mian Xie</a>, 
<a href="/search/cs?searchtype=author&query=Termehchy%2C+A">Arash Termehchy</a>, 
<a href="/search/cs?searchtype=author&query=Doskenov%2C+B">Bakhtiyar Doskenov</a>, 
<a href="/search/cs?searchtype=author&query=Srikhakollu%2C+B">Bharghav Srikhakollu</a>, 
<a href="/search/cs?searchtype=author&query=Haque%2C+S">Summit Haque</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huazheng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">It is crucial to provide real-time performance in many applications, such as
interactive and exploratory data analysis. In these settings, users often need
to view subsets of query results quickly. It is challenging to deliver such
results over large datasets for relational operators over multiple relations,
such as join. Join algorithms usually spend a long time on scanning and
attempting to join parts of relations that may not generate any result. Current
solutions usually require lengthy and repeated preprocessing, which is costly
and may not be possible to do in many settings. Also, they often support
restricted types of joins. In this paper, we outline a novel approach for
achieving efficient join processing in which a scan operator of the join learns
during query execution, the portions of its relations that might satisfy the
join predicate. We further improve this method using an algorithm in which both
scan operators collaboratively learn an efficient join execution strategy. We
also show that this approach generalizes traditional and non-learning methods
for joining. Our extensive empirical studies using standard benchmarks indicate
that this approach outperforms similar methods considerably.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14292" title="Abstract">arXiv:2312.14292</a> [<a href="/pdf/2312.14292" title="Download PDF">pdf</a>, <a href="/format/2312.14292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Multi-Agent Preference-based Reinforcement Learning for  Human-AI Teaming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhambri%2C+S">Siddhant Bhambri</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+M">Mudit Verma</a>, 
<a href="/search/cs?searchtype=author&query=Murthy%2C+A">Anil Murthy</a>, 
<a href="/search/cs?searchtype=author&query=Kambhampati%2C+S">Subbarao Kambhampati</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Preference-based Reinforcement Learning (PbRL) is an active area of research,
and has made significant strides in single-agent actor and in observer
human-in-the-loop scenarios. However, its application within the co-operative
multi-agent RL frameworks, where humans actively participate and express
preferences for agent behavior, remains largely uncharted. We consider a
two-agent (Human-AI) cooperative setup where both the agents are rewarded
according to human's reward function for the team. However, the agent does not
have access to it, and instead, utilizes preference-based queries to elicit its
objectives and human's preferences for the robot in the human-robot team. We
introduce the notion of Human-Flexibility, i.e. whether the human partner is
amenable to multiple team strategies, with a special case being Specified
Orchestration where the human has a single team policy in mind (most
constrained case). We propose a suite of domains to study PbRL for Human-AI
cooperative setup which explicitly require forced cooperation. Adapting
state-of-the-art single-agent PbRL algorithms to our two-agent setting, we
conduct a comprehensive benchmarking study across our domain suite. Our
findings highlight the challenges associated with high degree of
Human-Flexibility and the limited access to the human's envisioned policy in
PbRL for Human-AI cooperation. Notably, we observe that PbRL algorithms exhibit
effective performance exclusively in the case of Specified Orchestration which
can be seen as an upper bound PbRL performance for future research.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14293" title="Abstract">arXiv:2312.14293</a> [<a href="/pdf/2312.14293" title="Download PDF">pdf</a>, <a href="/format/2312.14293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Friends with Costs and Benefits: Community Formation with Myopic,  Boundedly-Rational Actors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balepur%2C+N">Naina Balepur</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+A">Andy Lee</a>, 
<a href="/search/cs?searchtype=author&query=Sundaram%2C+H">Hari Sundaram</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">In this paper we address how complex social communities emerge from local
decisions by individuals with limited attention and knowledge. This problem is
critical; if we understand community formation mechanisms, it may be possible
to intervene to improve social welfare. We propose an interpretable, novel
model for attributed community formation driven by resource-bounded
individuals' strategic, selfish behavior. In our stylized model, attributed
individuals act strategically in two dimensions: attribute and network
structure. Agents are endowed with limited attention, and communication costs
limit the number of active connections. In each time step, each agent proposes
a new friendship. Agents then accept proposals, decline proposals, or remove
friends, consistent with their strategy to maximize payoff. We identify
criteria (number of stable triads) for convergence to some community structure
and prove that our community formation model converges to a stable network.
Ablations justify the ecological validity of our model and show that each
aspect of the model is essential. Our empirical results on a physical world
microfinance community demonstrate excellent model fits compared to baseline
models.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14295" title="Abstract">arXiv:2312.14295</a> [<a href="/pdf/2312.14295" title="Download PDF">pdf</a>, <a href="/format/2312.14295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Separating Path and Tree Systems in Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biniaz%2C+A">Ahmad Biniaz</a>, 
<a href="/search/cs?searchtype=author&query=Bose%2C+P">Prosenjit Bose</a>, 
<a href="/search/cs?searchtype=author&query=De+Carufel%2C+J">Jean-Lou De Carufel</a>, 
<a href="/search/cs?searchtype=author&query=Maheshwari%2C+A">Anil Maheshwari</a>, 
<a href="/search/cs?searchtype=author&query=Miraftab%2C+B">Babak Miraftab</a>, 
<a href="/search/cs?searchtype=author&query=Odak%2C+S">Saeed Odak</a>, 
<a href="/search/cs?searchtype=author&query=Smid%2C+M">Michiel Smid</a>, 
<a href="/search/cs?searchtype=author&query=Smorodinsky%2C+S">Shakhar Smorodinsky</a>, 
<a href="/search/cs?searchtype=author&query=Yuditsky%2C+Y">Yelena Yuditsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 page, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">We explore the concept of separating systems of vertex sets of graphs. A
separating system of a set $X$ is a collection of subsets of $X$ such that for
any pair of distinct elements in $X$, there exists a set in the separating
system that contains exactly one of the two elements. A separating system of
the vertex set of a graph $G$ is called a vertex-separating path (tree) system
of $G$ if the elements of the separating system are paths (trees) in the graph
$G$. In this paper, we focus on the size of the smallest vertex-separating path
(tree) system for different types of graphs, including trees, grids, and
maximal outerplanar graphs.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14299" title="Abstract">arXiv:2312.14299</a> [<a href="/pdf/2312.14299" title="Download PDF">pdf</a>, <a href="/ps/2312.14299" title="Download PostScript">ps</a>, <a href="/format/2312.14299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fairness in Submodular Maximization over a Matroid Constraint
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Halabi%2C+M+E">Marwa El Halabi</a>, 
<a href="/search/cs?searchtype=author&query=Tarnawski%2C+J">Jakub Tarnawski</a>, 
<a href="/search/cs?searchtype=author&query=Norouzi-Fard%2C+A">Ashkan Norouzi-Fard</a>, 
<a href="/search/cs?searchtype=author&query=Vuong%2C+T">Thuy-Duong Vuong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS); Combinatorics (math.CO); Optimization and Control (math.OC)

</div>
<p class="mathjax">Submodular maximization over a matroid constraint is a fundamental problem
with various applications in machine learning. Some of these applications
involve decision-making over datapoints with sensitive attributes such as
gender or race. In such settings, it is crucial to guarantee that the selected
solution is fairly distributed with respect to this attribute. Recently,
fairness has been investigated in submodular maximization under a cardinality
constraint in both the streaming and offline settings, however the more general
problem with matroid constraint has only been considered in the streaming
setting and only for monotone objectives. This work fills this gap. We propose
various algorithms and impossibility results offering different trade-offs
between quality, fairness, and generality.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14300" title="Abstract">arXiv:2312.14300</a> [<a href="/pdf/2312.14300" title="Download PDF">pdf</a>, <a href="/format/2312.14300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asynchronous Entanglement Routing for the Quantum Internet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zebo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ghubaish%2C+A">Ali Ghubaish</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+R">Raj Jain</a>, 
<a href="/search/cs?searchtype=author&query=Shapourian%2C+H">Hassan Shapourian</a>, 
<a href="/search/cs?searchtype=author&query=Shabani%2C+A">Alireza Shabani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article has been accepted for publication in the AVS Quantum Science journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">With the emergence of the Quantum Internet, the need for advanced quantum
networking techniques has significantly risen. Various models of quantum
repeaters have been presented, each delineating a unique strategy to ensure
quantum communication over long distances. We focus on repeaters that employ
entanglement generation and swapping. This revolves around establishing remote
end-to-end entanglement through repeaters, a concept we denote as the
"quantum-native" repeaters (also called "first-generation" repeaters in some
literature). The challenges in routing with quantum-native repeaters arise from
probabilistic entanglement generation and restricted coherence time. Current
approaches use synchronized time slots to search for entanglement-swapping
paths, resulting in inefficiencies. Here, we propose a new set of asynchronous
routing protocols for quantum networks by incorporating the idea of maintaining
a dynamic topology in a distributed manner, which has been extensively studied
in classical routing for lossy networks, such as using a destination-oriented
directed acyclic graph (DODAG) or a spanning tree. The protocols update the
entanglement-link topology asynchronously, identify optimal
entanglement-swapping paths, and preserve unused direct-link entanglements. Our
results indicate that asynchronous protocols achieve a larger upper bound with
an appropriate setting and significantly higher entanglement rate than existing
synchronous approaches, and the rate increases with coherence time, suggesting
that it will have a much more profound impact on quantum networks as technology
advances.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14301" title="Abstract">arXiv:2312.14301</a> [<a href="/pdf/2312.14301" title="Download PDF">pdf</a>, <a href="/format/2312.14301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autoencoder Based Face Verification System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Solomon%2C+E">Enoch Solomon</a>, 
<a href="/search/cs?searchtype=author&query=Woubie%2C+A">Abraham Woubie</a>, 
<a href="/search/cs?searchtype=author&query=Emiru%2C+E+S">Eyael Solomon Emiru</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">The primary objective of this work is to present an alternative approach
aimed at reducing the dependency on labeled data. Our proposed method involves
utilizing autoencoder pre-training within a face image recognition task with
two step processes. Initially, an autoencoder is trained in an unsupervised
manner using a substantial amount of unlabeled training dataset. Subsequently,
a deep learning model is trained with initialized parameters from the
pre-trained autoencoder. This deep learning training process is conducted in a
supervised manner, employing relatively limited labeled training dataset.
During evaluation phase, face image embeddings is generated as the output of
deep neural network layer. Our training is executed on the CelebA dataset,
while evaluation is performed using benchmark face recognition datasets such as
Labeled Faces in the Wild (LFW) and YouTube Faces (YTF). Experimental results
demonstrate that by initializing the deep neural network with pre-trained
autoencoder parameters achieve comparable results to state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14302" title="Abstract">arXiv:2312.14302</a> [<a href="/pdf/2312.14302" title="Download PDF">pdf</a>, <a href="/format/2312.14302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Novel GPT-4 APIs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pelrine%2C+K">Kellin Pelrine</a>, 
<a href="/search/cs?searchtype=author&query=Taufeeque%2C+M">Mohammad Taufeeque</a>, 
<a href="/search/cs?searchtype=author&query=Zaj%C4%85c%2C+M">Micha&#x142; Zaj&#x105;c</a>, 
<a href="/search/cs?searchtype=author&query=McLean%2C+E">Euan McLean</a>, 
<a href="/search/cs?searchtype=author&query=Gleave%2C+A">Adam Gleave</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 1 figure, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Language model attacks typically assume one of two extreme threat models:
full white-box access to model weights, or black-box access limited to a text
generation API. However, real-world APIs are often more flexible than just text
generation: these APIs expose ``gray-box'' access leading to new threat
vectors. To explore this, we red-team three new functionalities exposed in the
GPT-4 APIs: fine-tuning, function calling and knowledge retrieval. We find that
fine-tuning a model on as few as 15 harmful examples or 100 benign examples can
remove core safeguards from GPT-4, enabling a range of harmful outputs.
Furthermore, we find that GPT-4 Assistants readily divulge the function call
schema and can be made to execute arbitrary function calls. Finally, we find
that knowledge retrieval can be hijacked by injecting instructions into
retrieval documents. These vulnerabilities highlight that any additions to the
functionality exposed by an API can create new vulnerabilities.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14305" title="Abstract">arXiv:2312.14305</a> [<a href="/pdf/2312.14305" title="Download PDF">pdf</a>, <a href="/format/2312.14305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Exact Spanning Ratio of the Parallelogram Delaunay Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bose%2C+P">Prosenjit Bose</a>, 
<a href="/search/cs?searchtype=author&query=De+Carufel%2C+J">Jean-Lou De Carufel</a>, 
<a href="/search/cs?searchtype=author&query=Njoo%2C+S">Sandrine Njoo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">Finding the exact spanning ratio of a Delaunay graph has been one of the
longstanding open problems in Computational Geometry. Currently there are only
four convex shapes for which the exact spanning ratio of their Delaunay graph
is known: the equilateral triangle, the square, the regular hexagon and the
rectangle. In this paper, we show the exact spanning ratio of the parallelogram
Delaunay graph, making the parallelogram the fifth convex shape for which an
exact bound is known. The worst-case spanning ratio is exactly
$$\frac{\sqrt{2}\sqrt{1+A^2+2A\cos(\theta_0)+(A+\cos(\theta_0))\sqrt{1+A^2+2A\cos(\theta_0)}}}{\sin(\theta_0)}
.$$ where $A$ is the aspect ratio and $\theta_0$ is the non-obtuse angle of the
parallelogram. Moreover, we show how to construct a parallelogram Delaunay
graph whose spanning ratio matches the above mentioned spanning ratio.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14306" title="Abstract">arXiv:2312.14306</a> [<a href="/pdf/2312.14306" title="Download PDF">pdf</a>, <a href="/format/2312.14306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social Recommendation through Heterogeneous Graph Modeling of the  Long-term and Short-term Preference Defined by Dynamic Periods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jafari%2C+B+M">Behafarid Mohammad Jafari</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Jafari%2C+A">Ali Jafari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Social recommendations have been widely adopted in substantial domains.
Recently, graph neural networks (GNN) have been employed in recommender systems
due to their success in graph representation learning. However, dealing with
the dynamic property of social network data is a challenge. This research
presents a novel method that provides social recommendations by incorporating
the dynamic property of social network data in a heterogeneous graph. The model
aims to capture user preference over time without going through the
complexities of a dynamic graph by adding period nodes to define users'
long-term and short-term preferences and aggregating assigned edge weights. The
model is applied to real-world data to argue its superior performance.
Promising results demonstrate the effectiveness of this model.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14309" title="Abstract">arXiv:2312.14309</a> [<a href="/pdf/2312.14309" title="Download PDF">pdf</a>, <a href="/format/2312.14309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Quantum Long Short-term Memory (FedQLSTM)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chehimi%2C+M">Mahdi Chehimi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S+Y">Samuel Yen-Chi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Saad%2C+W">Walid Saad</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+S">Shinjae Yoo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI); Quantum Physics (quant-ph)

</div>
<p class="mathjax">Quantum federated learning (QFL) can facilitate collaborative learning across
multiple clients using quantum machine learning (QML) models, while preserving
data privacy. Although recent advances in QFL span different tasks like
classification while leveraging several data types, no prior work has focused
on developing a QFL framework that utilizes temporal data to approximate
functions useful to analyze the performance of distributed quantum sensing
networks. In this paper, a novel QFL framework that is the first to integrate
quantum long short-term memory (QLSTM) models with temporal data is proposed.
The proposed federated QLSTM (FedQLSTM) framework is exploited for performing
the task of function approximation. In this regard, three key use cases are
presented: Bessel function approximation, sinusoidal delayed quantum feedback
control function approximation, and Struve function approximation. Simulation
results confirm that, for all considered use cases, the proposed FedQLSTM
framework achieves a faster convergence rate under one local training epoch,
minimizing the overall computations, and saving 25-33% of the number of
communication rounds needed until convergence compared to an FL framework with
classical LSTM models.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14312" title="Abstract">arXiv:2312.14312</a> [<a href="/pdf/2312.14312" title="Download PDF">pdf</a>, <a href="/ps/2312.14312" title="Download PostScript">ps</a>, <a href="/format/2312.14312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vector Multispaces and Multispace Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kova%C4%8Devi%C4%87%2C+M">Mladen Kova&#x10d;evi&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">Basic algebraic and combinatorial properties of finite vector spaces in which
individual vectors are allowed to have multiplicities larger than $ 1 $ are
derived. An application in coding theory is illustrated by showing that
multispace codes that are introduced here may be used in random linear network
coding scenarios, and that they in fact generalize standard subspace codes
(defined in the set of all subspaces of $ \mathbb{F}_q^n $) and extend them to
an infinitely larger set of parameters. In particular, in contrast to subspace
codes, multispace codes of arbitrarily large cardinality and minimum distance
exist for any fixed $ n $ and $ q $.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14321" title="Abstract">arXiv:2312.14321</a> [<a href="/pdf/2312.14321" title="Download PDF">pdf</a>, <a href="/format/2312.14321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel ML-driven Test Case Selection Approach for Enhancing the  Performance of Grammatical Evolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupt%2C+K+K">Krishn Kumar Gupt</a>, 
<a href="/search/cs?searchtype=author&query=Kshirsagar%2C+M">Meghana Kshirsagar</a>, 
<a href="/search/cs?searchtype=author&query=Dias%2C+D+M">Douglas Mota Dias</a>, 
<a href="/search/cs?searchtype=author&query=Sullivan%2C+J+P">Joseph P. Sullivan</a>, 
<a href="/search/cs?searchtype=author&query=Ryan%2C+C">Conor Ryan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Computational cost in metaheuristics such as Evolutionary Algorithms (EAs) is
often a major concern, particularly with their ability to scale. In data-based
training, traditional EAs typically use a significant portion, if not all, of
the dataset for model training and fitness evaluation in each generation. This
makes EAs suffer from high computational costs incurred during the fitness
evaluation of the population, particularly when working with large datasets. To
mitigate this issue, we propose a Machine Learning (ML)-driven Distance-based
Selection (DBS) algorithm that reduces the fitness evaluation time by
optimizing test cases. We test our algorithm by applying it to 24 benchmark
problems from Symbolic Regression (SR) and digital circuit domains and then
using Grammatical Evolution (GE) to train models using the reduced dataset. We
use GE to test DBS on SR and produce a system flexible enough to test it on
digital circuit problems further. The quality of the solutions is tested and
compared against the conventional training method to measure the coverage of
training data selected using DBS, i.e., how well the subset matches the
statistical properties of the entire dataset. Moreover, the effect of optimized
training data on run time and the effective size of the evolved solutions is
analyzed. Experimental and statistical evaluations of the results show our
method empowered GE to yield superior or comparable solutions to the baseline
(using the full datasets) with smaller sizes and demonstrates computational
efficiency in terms of speed.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14326" title="Abstract">arXiv:2312.14326</a> [<a href="/pdf/2312.14326" title="Download PDF">pdf</a>, <a href="/ps/2312.14326" title="Download PostScript">ps</a>, <a href="/format/2312.14326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast data-driven iterative learning control for linear system with  output disturbance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jia Wang</a>, 
<a href="/search/eess?searchtype=author&query=Hemelhof%2C+L">Leander Hemelhof</a>, 
<a href="/search/eess?searchtype=author&query=Markovsky%2C+I">Ivan Markovsky</a>, 
<a href="/search/eess?searchtype=author&query=Patrinos%2C+P">Panagiotis Patrinos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper studies data-driven iterative learning control (ILC) for linear
time-invariant (LTI) systems with unknown dynamics, output disturbances and
input box-constraints. Our main contributions are: 1) using a non-parametric
data-driven representation of the system dynamics, for dealing with the unknown
system dynamics in the context of ILC, 2) design of a fast ILC method for
dealing with output disturbances, model uncertainty and input constraints. A
complete design method is given in this paper, which consists of the
data-driven representation, controller formulation, acceleration strategy and
convergence analysis. A batch of numerical experiments and a case study on a
high-precision robotic motion system are given in the end to show the
effectiveness of the proposed method.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14327" title="Abstract">arXiv:2312.14327</a> [<a href="/pdf/2312.14327" title="Download PDF">pdf</a>, <a href="/format/2312.14327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameter Efficient Tuning Allows Scalable Personalization of LLMs for  Text Entry: A Case Study on Abbreviation Expansion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tomanek%2C+K">Katrin Tomanek</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+S">Shanqing Cai</a>, 
<a href="/search/cs?searchtype=author&query=Venugopalan%2C+S">Subhashini Venugopalan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Abbreviation expansion is a strategy used to speed up communication by
limiting the amount of typing and using a language model to suggest expansions.
Here we look at personalizing a Large Language Model's (LLM) suggestions based
on prior conversations to enhance the relevance of predictions, particularly
when the user data is small (~1000 samples). Specifically, we compare
fine-tuning, prompt-tuning, and retrieval augmented generation of expanded text
suggestions for abbreviated inputs. Our case study with a deployed 8B parameter
LLM on a real user living with ALS, and experiments on movie character
personalization indicates that (1) customization may be necessary in some
scenarios and prompt-tuning generalizes well to those, (2) fine-tuning on
in-domain data (with as few as 600 samples) still shows some gains, however (3)
retrieval augmented few-shot selection also outperforms fine-tuning. (4)
Parameter efficient tuning allows for efficient and scalable personalization.
For prompt-tuning, we also find that initializing the learned "soft-prompts" to
user relevant concept tokens leads to higher accuracy than random
initialization.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14328" title="Abstract">arXiv:2312.14328</a> [<a href="/pdf/2312.14328" title="Download PDF">pdf</a>, <a href="/format/2312.14328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An unfitted high-order HDG method for two-fluid Stokes flow with exact  NURBS geometries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Piccardo%2C+S">Stefano Piccardo</a>, 
<a href="/search/math?searchtype=author&query=Giacomini%2C+M">Matteo Giacomini</a>, 
<a href="/search/math?searchtype=author&query=Huerta%2C+A">Antonio Huerta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 23 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Engineering, Finance, and Science (cs.CE); Computational Physics (physics.comp-ph); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">A high-order, degree-adaptive hybridizable discontinuous Galerkin (HDG)
method is presented for two-fluid incompressible Stokes flows, with boundaries
and interfaces described using NURBS. The NURBS curves are embedded in a fixed
Cartesian grid, yielding an unfitted HDG scheme capable of treating the exact
geometry of the boundaries/interfaces, circumventing the need for fitted,
high-order, curved meshes. The framework of the NURBS-enhanced finite element
method (NEFEM) is employed for accurate quadrature along immersed NURBS and in
elements cut by NURBS curves. A Nitsche's formulation is used to enforce
Dirichlet conditions on embedded surfaces, yielding unknowns only on the mesh
skeleton as in standard HDG, without introducing any additional degree of
freedom on non-matching boundaries/interfaces. The resulting unfitted HDG-NEFEM
method combines non-conforming meshes, exact NURBS geometry and high-order
approximations to provide high-fidelity results on coarse meshes, independent
of the geometric features of the domain. Numerical examples illustrate the
optimal accuracy and robustness of the method, even in the presence of badly
cut cells or faces, and its suitability to simulate microfluidic systems from
CAD geometries.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14329" title="Abstract">arXiv:2312.14329</a> [<a href="/pdf/2312.14329" title="Download PDF">pdf</a>, <a href="/format/2312.14329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invariant Anomaly Detection under Distribution Shifts: A Causal  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carvalho%2C+J+B+S">Jo&#xe3;o B. S. Carvalho</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengtao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Geyer%2C+R">Robin Geyer</a>, 
<a href="/search/cs?searchtype=author&query=Cotrini%2C+C">Carlos Cotrini</a>, 
<a href="/search/cs?searchtype=author&query=Buhmann%2C+J+M">Joachim M. Buhmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Anomaly detection (AD) is the machine learning task of identifying highly
discrepant abnormal samples by solely relying on the consistency of the normal
training samples. Under the constraints of a distribution shift, the assumption
that training samples and test samples are drawn from the same distribution
breaks down. In this work, by leveraging tools from causal inference we attempt
to increase the resilience of anomaly detection models to different kinds of
distribution shifts. We begin by elucidating a simple yet necessary statistical
property that ensures invariant representations, which is critical for robust
AD under both domain and covariate shifts. From this property, we derive a
regularization term which, when minimized, leads to partial distribution
invariance across environments. Through extensive experimental evaluation on
both synthetic and real-world tasks, covering a range of six different AD
methods, we demonstrated significant improvements in out-of-distribution
performance. Under both covariate and domain shift, models regularized with our
proposed term showed marked increased robustness. Code is available at:
https://github.com/JoaoCarv/invariant-anomaly-detection.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14331" title="Abstract">arXiv:2312.14331</a> [<a href="/pdf/2312.14331" title="Download PDF">pdf</a>, <a href="/format/2312.14331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximum entropy GFlowNets with soft Q-learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohammadpour%2C+S">Sobhan Mohammadpour</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+E">Emmanuel Bengio</a>, 
<a href="/search/cs?searchtype=author&query=Frejinger%2C+E">Emma Frejinger</a>, 
<a href="/search/cs?searchtype=author&query=Bacon%2C+P">Pierre-Luc Bacon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Generative Flow Networks (GFNs) have emerged as a powerful tool for sampling
discrete objects from unnormalized distributions, offering a scalable
alternative to Markov Chain Monte Carlo (MCMC) methods. While GFNs draw
inspiration from maximum entropy reinforcement learning (RL), the connection
between the two has largely been unclear and seemingly applicable only in
specific cases. This paper addresses the connection by constructing an
appropriate reward function, thereby establishing an exact relationship between
GFNs and maximum entropy RL. This construction allows us to introduce maximum
entropy GFNs, which, in contrast to GFNs with uniform backward policy, achieve
the maximum entropy attainable by GFNs without constraints on the state space.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14333" title="Abstract">arXiv:2312.14333</a> [<a href="/pdf/2312.14333" title="Download PDF">pdf</a>, <a href="/format/2312.14333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Behaviour Modelling of Social Animals via Causal Structure Discovery and  Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gendron%2C+G">Ga&#xeb;l Gendron</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Rogers%2C+M">Mitchell Rogers</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Azhar%2C+M">Mihailo Azhar</a>, 
<a href="/search/cs?searchtype=author&query=Heidari%2C+S">Shahrokh Heidari</a>, 
<a href="/search/cs?searchtype=author&query=Valdez%2C+D+A+S">David Arturo Soriano Valdez</a>, 
<a href="/search/cs?searchtype=author&query=Knowles%2C+K">Kobe Knowles</a>, 
<a href="/search/cs?searchtype=author&query=O%27Leary%2C+P">Padriac O&#x27;Leary</a>, 
<a href="/search/cs?searchtype=author&query=Eyre%2C+S">Simon Eyre</a>, 
<a href="/search/cs?searchtype=author&query=Witbrock%2C+M">Michael Witbrock</a>, 
<a href="/search/cs?searchtype=author&query=Dobbie%2C+G">Gillian Dobbie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiamou Liu</a>, 
<a href="/search/cs?searchtype=author&query=Delmas%2C+P">Patrice Delmas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 7 figures, accepted as an extended abstract and poster at AAMAS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Better understanding the natural world is a crucial task with a wide range of
applications. In environments with close proximity between humans and animals,
such as zoos, it is essential to better understand the causes behind animal
behaviour and what interventions are responsible for changes in their
behaviours. This can help to predict unusual behaviours, mitigate detrimental
effects and increase the well-being of animals. There has been work on
modelling the dynamics behind swarms of birds and insects but the complex
social behaviours of mammalian groups remain less explored. In this work, we
propose a method to build behavioural models using causal structure discovery
and graph neural networks for time series. We apply this method to a mob of
meerkats in a zoo environment and study its ability to predict future actions
and model the behaviour distribution at an individual-level and at a group
level. We show that our method can match and outperform standard deep learning
architectures and generate more realistic data, while using fewer parameters
and providing increased interpretability.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14334" title="Abstract">arXiv:2312.14334</a> [<a href="/pdf/2312.14334" title="Download PDF">pdf</a>, <a href="/format/2312.14334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DP-AdamBC: Your DP-Adam Is Actually DP-SGD (Unless You Apply Bias  Correction)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Q">Qiaoyue Tang</a>, 
<a href="/search/cs?searchtype=author&query=Shpilevskiy%2C+F">Frederick Shpilevskiy</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%A9cuyer%2C+M">Mathias L&#xe9;cuyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper at the 38th Annual AAAI Conference on Artificial Intelligence, Vancouver, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The Adam optimizer is a popular choice in contemporary deep learning, due to
its strong empirical performance. However we observe that in privacy sensitive
scenarios, the traditional use of Differential Privacy (DP) with the Adam
optimizer leads to sub-optimal performance on several tasks. We find that this
performance degradation is due to a DP bias in Adam's second moment estimator,
introduced by the addition of independent noise in the gradient computation to
enforce DP guarantees. This DP bias leads to a different scaling for low
variance parameter updates, that is inconsistent with the behavior of
non-private Adam. We propose DP-AdamBC, an optimization algorithm which removes
the bias in the second moment estimation and retrieves the expected behaviour
of Adam. Empirically, DP-AdamBC significantly improves the optimization
performance of DP-Adam by up to 3.5% in final accuracy in image, text, and
graph node classification tasks.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14335" title="Abstract">arXiv:2312.14335</a> [<a href="/pdf/2312.14335" title="Download PDF">pdf</a>, <a href="/ps/2312.14335" title="Download PostScript">ps</a>, <a href="/format/2312.14335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-aware Decoding Reduces Hallucination in Query-focused  Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhichao Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Query-focused summarization (QFS) aims to provide a summary of a single
document/multi documents that can satisfy the information needs of a given
query. It is useful for various real-world applications, such as abstractive
snippet generation or more recent retrieval augmented generation (RAG). A
prototypical QFS pipeline consists of a retriever (sparse or dense retrieval)
and a generator (usually a large language model). However, applying large
language models (LLM) potentially leads to hallucinations, especially when the
evidence contradicts the prior belief of LLMs. There has been growing interest
in developing new decoding methods to improve generation quality and reduce
hallucination. In this work, we conduct a large-scale reproducibility on one
recently proposed decoding method -- Context-aware Decoding (CAD). In addition
to replicating CAD's experiments on news summarization datasets, we include
experiments on QFS datasets, and conduct more rigorous analysis on
computational complexity and hyperparameter sensitivity. Experiments with eight
different language models show that performance-wise, CAD improves QFS quality
by (1) reducing factuality errors/hallucinations while (2) mostly retaining the
match of lexical patterns, measured by ROUGE scores, while also at a cost of
increased inference-time FLOPs and reduced decoding speed. The code
implementation based on Huggingface Library is made available
https://github.com/zhichaoxu-shufe/context-aware-decoding-qfs
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14336" title="Abstract">arXiv:2312.14336</a> [<a href="/pdf/2312.14336" title="Download PDF">pdf</a>, <a href="/format/2312.14336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constraint-Informed Learning for Warm Starting Trajectory Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Briden%2C+J">Julia Briden</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+C">Changrak Choi</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+K">Kyongsik Yun</a>, 
<a href="/search/cs?searchtype=author&query=Linares%2C+R">Richard Linares</a>, 
<a href="/search/cs?searchtype=author&query=Cauligi%2C+A">Abhishek Cauligi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Future spacecraft and surface robotic missions require increasingly capable
autonomy stacks for exploring challenging and unstructured domains and
trajectory optimization will be a cornerstone of such autonomy stacks. However,
the nonlinear optimization solvers required remain too slow for use on
relatively resource constrained flight-grade computers. In this work, we turn
towards amortized optimization, a learning-based technique for accelerating
optimization run times, and present TOAST: Trajectory Optimization with Merit
Function Warm Starts. Offline, using data collected from a simulation, we train
a neural network to learn a mapping to the full primal and dual solutions given
the problem parameters. Crucially, we build upon recent results from
decision-focused learning and present a set of decision-focused loss functions
using the notion of merit functions for optimization problems. We show that
training networks with such constraint-informed losses can better encode the
structure of the trajectory optimization problem and jointly learn to
reconstruct the primal-dual solution while also yielding improved constraint
satisfaction. Through numerical experiments on a Lunar rover problem, we
demonstrate that TOAST outperforms benchmark approaches in terms of both
computation times and network prediction constraint satisfaction.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14345" title="Abstract">arXiv:2312.14345</a> [<a href="/pdf/2312.14345" title="Download PDF">pdf</a>, <a href="/format/2312.14345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Logic-Scaffolding: Personalized Aspect-Instructed Recommendation  Explanation Generation using LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahdari%2C+B">Behnam Rahdari</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Hao Ding</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Ziwei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yifei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuotong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Deoras%2C+A">Anoop Deoras</a>, 
<a href="/search/cs?searchtype=author&query=Kveton%2C+B">Branislav Kveton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 17th ACM International Conference on Web Search and Data Mining (WSDM 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">The unique capabilities of Large Language Models (LLMs), such as the natural
language text generation ability, position them as strong candidates for
providing explanation for recommendations. However, despite the size of the
LLM, most existing models struggle to produce zero-shot explanations reliably.
To address this issue, we propose a framework called Logic-Scaffolding, that
combines the ideas of aspect-based explanation and chain-of-thought prompting
to generate explanations through intermediate reasoning steps. In this paper,
we share our experience in building the framework and present an interactive
demonstration for exploring our results.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14346" title="Abstract">arXiv:2312.14346</a> [<a href="/pdf/2312.14346" title="Download PDF">pdf</a>, <a href="/format/2312.14346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Don&#x27;t Believe Everything You Read: Enhancing Summarization  Interpretability through Automatic Identification of Hallucinations in Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vakharia%2C+P">Priyesh Vakharia</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+D">Devavrat Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Chavan%2C+M">Meenal Chavan</a>, 
<a href="/search/cs?searchtype=author&query=Sonawane%2C+D">Dhananjay Sonawane</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+B">Bhrigu Garg</a>, 
<a href="/search/cs?searchtype=author&query=Mazaheri%2C+P">Parsa Mazaheri</a>, 
<a href="/search/cs?searchtype=author&query=Lane%2C+I">Ian Lane</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> All authors contributed equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) are adept at text manipulation -- tasks such as
machine translation and text summarization. However, these models can also be
prone to hallucination, which can be detrimental to the faithfulness of any
answers that the model provides. Recent works in combating hallucinations in
LLMs deal with identifying hallucinated sentences and categorizing the
different ways in which models hallucinate. This paper takes a deep dive into
LLM behavior with respect to hallucinations, defines a token-level approach to
identifying different kinds of hallucinations, and further utilizes this
token-level tagging to improve the interpretability and faithfulness of LLMs in
dialogue summarization tasks. Through this, the paper presents a new, enhanced
dataset and a new training paradigm.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14358" title="Abstract">arXiv:2312.14358</a> [<a href="/pdf/2312.14358" title="Download PDF">pdf</a>, <a href="/ps/2312.14358" title="Download PostScript">ps</a>, <a href="/format/2312.14358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A utility belt for an agricultural robot: reflection-in-action for  applied design research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Friedman%2C+N">Natalie Friedman</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+A">Asmita Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Love%2C+K">Kari Love</a>, 
<a href="/search/cs?searchtype=author&query=Bremers%2C+A">Alexandra Bremers</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+A">Awsaf Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+W">Wendy Ju</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Clothing for robots can help expand a robot's functionality and also clarify
the robot's purpose to bystanders. In studying how to design clothing for
robots, we can shed light on the functional role of aesthetics in interactive
system design. We present a case study of designing a utility belt for an
agricultural robot. We use reflection-in-action to consider the ways that
observation, in situ making, and documentation serve to illuminate how
pragmatic, aesthetic, and intellectual inquiry are layered in this applied
design research project. Themes explored in this pictorial include 1)
contextual discovery of materials, tools, and practices, 2) design space
exploration of materials in context, 3) improvising spaces for making, and 4)
social processes in design. These themes emerged from the qualitative coding of
25 reflection-in-action videos from the researcher. We conclude with feedback
on the utility belt prototypes for an agriculture robot and our learnings about
context, materials, and people needed to design successful novel clothing forms
for robots.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14359" title="Abstract">arXiv:2312.14359</a> [<a href="/pdf/2312.14359" title="Download PDF">pdf</a>, <a href="/format/2312.14359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training Neural Networks with Internal State, Unconstrained  Connectivity, and Discrete Activations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grushin%2C+A">Alexander Grushin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Today's most powerful machine learning approaches are typically designed to
train stateless architectures with predefined layers and differentiable
activation functions. While these approaches have led to unprecedented
successes in areas such as natural language processing and image recognition,
the trained models are also susceptible to making mistakes that a human would
not. In this paper, we take the view that true intelligence may require the
ability of a machine learning model to manage internal state, but that we have
not yet discovered the most effective algorithms for training such models. We
further postulate that such algorithms might not necessarily be based on
gradient descent over a deep architecture, but rather, might work best with an
architecture that has discrete activations and few initial topological
constraints (such as multiple predefined layers). We present one attempt in our
ongoing efforts to design such a training algorithm, applied to an architecture
with binary activations and only a single matrix of weights, and show that it
is able to form useful representations of natural language text, but is also
limited in its ability to leverage large quantities of training data. We then
provide ideas for improving the algorithm and for designing other training
algorithms for similar architectures. Finally, we discuss potential benefits
that could be gained if an effective training algorithm is found, and suggest
experiments for evaluating whether these benefits exist in practice.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14360" title="Abstract">arXiv:2312.14360</a> [<a href="/pdf/2312.14360" title="Download PDF">pdf</a>, <a href="/format/2312.14360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing a Skilled Soccer Team for RoboCup: Exploring  Skill-Set-Primitives through Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abreu%2C+M">Miguel Abreu</a>, 
<a href="/search/cs?searchtype=author&query=Reis%2C+L+P">Luis Paulo Reis</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+N">Nuno Lau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Codebase release at <a href="https://github.com/m-abr/FCPCodebase">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The RoboCup 3D Soccer Simulation League serves as a competitive platform for
showcasing innovation in autonomous humanoid robot agents through simulated
soccer matches. Our team, FC Portugal, developed a new codebase from scratch in
Python after RoboCup 2021. The team's performance is based on a set of skills
centered around novel unifying primitives and a custom, symmetry-extended
version of the Proximal Policy Optimization algorithm. Our methods have been
thoroughly tested in official RoboCup matches, where FC Portugal has won the
last two main competitions, in 2022 and 2023. This paper presents our training
framework, as well as a timeline of skills developed using our
skill-set-primitives, which considerably improve the sample efficiency and
stability of skills, and motivate seamless transitions. We start with a
significantly fast sprint-kick developed in 2021 and progress to the most
recent skill set, which includes a multi-purpose omnidirectional walk, a
dribble with unprecedented ball control, a solid kick, and a push skill. The
push tackles both low-level collision-prone scenarios and high-level strategies
to increase ball possession. We address the resource-intensive nature of this
task through an innovative multi-agent learning approach. Finally, we release
the codebase of our team to the RoboCup community, enabling other teams to
transition to Python more easily and providing new teams with a robust and
modern foundation upon which they can build new features.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14364" title="Abstract">arXiv:2312.14364</a> [<a href="/pdf/2312.14364" title="Download PDF">pdf</a>, <a href="/format/2312.14364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GreenScan: Towards large-scale monitoring the health of urban trees  using mobile sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gupta%2C+A">Akshit Gupta</a>, 
<a href="/search/eess?searchtype=author&query=Mora%2C+S">Simone Mora</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Rutten%2C+M">Martine Rutten</a>, 
<a href="/search/eess?searchtype=author&query=Prasad%2C+R+V">R. Venkatesha Prasad</a>, 
<a href="/search/eess?searchtype=author&query=Ratti%2C+C">Carlo Ratti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Healthy urban greenery is a fundamental asset to mitigate climate change
phenomenons such as extreme heat and air pollution. However, urban trees are
often affected by abiotic and biotic stressors that hamper their functionality,
and whenever not timely managed, even their survival. While current visual or
instrumented inspection techniques can help take effective measures, they often
require a high amount of human labor, making frequent assessments infeasible at
a city-wide scale. In this paper, we present GreenScan, a ground-based sensing
system designed to provide health assessment of urban trees at high
spatio-temporal resolutions, with low costs. The system utilises thermal and
multi-spectral imaging sensors fused using custom computer vision models in
order to estimate two tree health indexes. The evaluation of the system was
performed through data collection experiments in Cambridge, USA. Overall, this
approach illustrates the potential of autonomous mobile ground-based tree
health monitoring on city-wide scales at high temporal resolutions with
low-costs.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14367" title="Abstract">arXiv:2312.14367</a> [<a href="/pdf/2312.14367" title="Download PDF">pdf</a>, <a href="/ps/2312.14367" title="Download PostScript">ps</a>, <a href="/format/2312.14367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A force-based higher-order shear beam element model with rational shear  stress distribution for accurate analyses of FG sandwich beams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenxiong Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huiyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Suiyin Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">This study introduces a force-based higher-order shear deformable beam finite
element model that incorporates a rational shear stress distribution, designed
for the precise analysis of functionally graded sandwich beams. Unlike
conventional higher-order shear beam finite elements that regard generalized
displacements as unknown fields, this model considers the distributions of
stress resultants along the beam axis as the unknown fields. The specific forms
of these stress resultants and the generalized displacements are analytically
determined, based on the differential equilibrium equations of the higher-order
shear beam. This approach effectively circumvents numerical errors that can
arise from finite element discretization. Furthermore, the model introduces a
stress equilibrium equation to accurately depict the distribution of transverse
shear stress across the beam thickness. A corrected shear stiffness, which
takes into account rational shear stress, is derived and incorporated into the
proposed beam element. Numerical examples underscore the accuracy and efficacy
of the proposed higher-order beam element model in the static analysis of
functionally graded sandwich beams, particularly in terms of true transverse
shear stress distribution.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14369" title="Abstract">arXiv:2312.14369</a> [<a href="/pdf/2312.14369" title="Download PDF">pdf</a>, <a href="/format/2312.14369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quality-Diversity Generative Sampling for Learning with Synthetic Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+A">Allen Chang</a>, 
<a href="/search/cs?searchtype=author&query=Fontaine%2C+M+C">Matthew C. Fontaine</a>, 
<a href="/search/cs?searchtype=author&query=Booth%2C+S">Serena Booth</a>, 
<a href="/search/cs?searchtype=author&query=Matari%C4%87%2C+M+J">Maja J. Matari&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Nikolaidis%2C+S">Stefanos Nikolaidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024; 7 pages main, 12 pages total, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Generative models can serve as surrogates for some real data sources by
creating synthetic training datasets, but in doing so they may transfer biases
to downstream tasks. We focus on protecting quality and diversity when
generating synthetic training datasets. We propose quality-diversity generative
sampling (QDGS), a framework for sampling data uniformly across a user-defined
measure space, despite the data coming from a biased generator. QDGS is a
model-agnostic framework that uses prompt guidance to optimize a quality
objective across measures of diversity for synthetically generated data,
without fine-tuning the generative model. Using balanced synthetic datasets
generated by QDGS, we first debias classifiers trained on color-biased shape
datasets as a proof-of-concept. By applying QDGS to facial data synthesis, we
prompt for desired semantic concepts, such as skin tone and age, to create an
intersectional dataset with a combined blend of visual features. Leveraging
this balanced data for training classifiers improves fairness while maintaining
accuracy on facial recognition benchmarks. Code available at:
https://github.com/Cylumn/qd-generative-sampling
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14370" title="Abstract">arXiv:2312.14370</a> [<a href="/pdf/2312.14370" title="Download PDF">pdf</a>, <a href="/format/2312.14370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Partitioned neural network approximation for partial differential  equations enhanced with Lagrange multipliers and localized loss functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jang%2C+D">Deok-Kyu Jang</a>, 
<a href="/search/math?searchtype=author&query=Kim%2C+K">Kyungsoo Kim</a>, 
<a href="/search/math?searchtype=author&query=Kim%2C+H+H">Hyea Hyun Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Partitioned neural network functions are used to approximate the solution of
partial differential equations. The problem domain is partitioned into
non-overlapping subdomains and the partitioned neural network functions are
defined on the given non-overlapping subdomains. Each neural network function
then approximates the solution in each subdomain. To obtain the convergent
neural network solution, certain continuity conditions on the partitioned
neural network functions across the subdomain interface need to be included in
the loss function, that is used to train the parameters in the neural network
functions. In our work, by introducing suitable interface values, the loss
function is reformulated into a sum of localized loss functions and each
localized loss function is used to train the corresponding local neural network
parameters. In addition, to accelerate the neural network solution convergence,
the localized loss function is enriched with an augmented Lagrangian term,
where the interface condition and the boundary condition are enforced as
constraints on the local solutions by using Lagrange multipliers. The local
neural network parameters and Lagrange multipliers are then found by optimizing
the localized loss function. To take the advantage of the localized loss
function for the parallel computation, an iterative algorithm is also proposed.
For the proposed algorithms, their training performance and convergence are
numerically studied for various test examples.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14371" title="Abstract">arXiv:2312.14371</a> [<a href="/pdf/2312.14371" title="Download PDF">pdf</a>, <a href="/format/2312.14371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Necknasium: A Virtual Reality Rehabilitation Game for Managing Faulty  Neck Posture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Youssef%2C+A+R">Aliaa Rehan Youssef</a>, 
<a href="/search/cs?searchtype=author&query=Gumaa%2C+M">Mohammed Gumaa</a>, 
<a href="/search/cs?searchtype=author&query=Al-Kabbany%2C+A">Ahmad Al-Kabbany</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This study is concerned with the application of virtual reality (VR) in
rehabilitation programs for faulty neck posture which is a primary source of
neck pain (NP). The latter is a highly prevalent musculoskeletal disorder that
is associated with serious societal and economic burden. VR has been shown to
be effective in the physical rehabilitation of various diseases. Specifically,
it has been shown to improve the adherence of patients and engagement to carry
out physical exercises on a regular basis. Many games have been used to manage
NP with different immersion levels. Towards this goal, we present a VR-based
system that targets a specific neck problem, the so called forward head posture
(FHP), which is a faulty head position that abnormally stresses neck
structures. The system can also generalize well to other neck-related disorders
and rehabilitation goals. We show the steps for designing and developing the
system, and we highlight the aspects of interaction between usability and
various game elements. Using a three-point scale for user experience, we also
present preliminary insights on the evaluation of the system prototype, and we
discuss future enhancement directions based on the feedback from users.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14373" title="Abstract">arXiv:2312.14373</a> [<a href="/pdf/2312.14373" title="Download PDF">pdf</a>, <a href="/format/2312.14373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Socio-Temporal Graphs for Multi-Agent Trajectory Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuke Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lixiong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guangyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+C">Ching-Yao Chan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Anzellotti%2C+S">Stefano Anzellotti</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+D">Donglai Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In order to predict a pedestrian's trajectory in a crowd accurately, one has
to take into account her/his underlying socio-temporal interactions with other
pedestrians consistently. Unlike existing work that represents the relevant
information separately, partially, or implicitly, we propose a complete
representation for it to be fully and explicitly captured and analyzed. In
particular, we introduce a Directed Acyclic Graph-based structure, which we
term Socio-Temporal Graph (STG), to explicitly capture pair-wise socio-temporal
interactions among a group of people across both space and time. Our model is
built on a time-varying generative process, whose latent variables determine
the structure of the STGs. We design an attention-based model named STGformer
that affords an end-to-end pipeline to learn the structure of the STGs for
trajectory prediction. Our solution achieves overall state-of-the-art
prediction accuracy in two large-scale benchmark datasets. Our analysis shows
that a person's past trajectory is critical for predicting another person's
future path. Our model learns this relationship with a strong notion of
socio-temporal localities. Statistics show that utilizing this information
explicitly for prediction yields a noticeable performance gain with respect to
the trajectory-only approaches.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14374" title="Abstract">arXiv:2312.14374</a> [<a href="/pdf/2312.14374" title="Download PDF">pdf</a>, <a href="/ps/2312.14374" title="Download PostScript">ps</a>, <a href="/format/2312.14374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Modular Approach to Metatheoretic Reasoning for Extensible Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Michaelson%2C+D">Dawn Michaelson</a>, 
<a href="/search/cs?searchtype=author&query=Nadathur%2C+G">Gopalan Nadathur</a>, 
<a href="/search/cs?searchtype=author&query=Van+Wyk%2C+E">Eric Van Wyk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">This paper concerns the development of metatheory for extensible languages.
It uses as its starting point a view that programming languages tailored to
specific application domains are to be constructed by composing components from
an open library of independently-developed extensions to a host language. In
the elaboration of this perspective, static analyses (such as typing) and
dynamic semantics (such as evaluation) are described via relations whose
specifications are distributed across the host language and extensions and are
given in a rule-based fashion. Metatheoretic properties, which ensure that
static analyses accurately gauge runtime behavior, are represented in this
context by formulas over such relations. These properties may be fundamental to
the language, introduced by the host language, or they may pertain to analyses
introduced by individual extensions. We expose the problem of modular
metatheory, i.e., the notion that proofs of relevant properties can be
constructed by reasoning independently within each component in the library. To
solve this problem, we propose the twin ideas of decomposing proofs around
language fragments and of reasoning generically about extensions based on
broad, a priori constraints imposed on their behavior. We establish the
soundness of these styles of reasoning by showing how complete proofs of the
properties can be automatically constructed for any language obtained by
composing the independent parts. Mathematical precision is given to our
discussions by framing them within a logic that encodes inductive rule-based
specifications via least fixed-point definitions. We also sketch the structure
of a practical system for metatheoretic reasoning for extensible languages
based on the ideas developed.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14375" title="Abstract">arXiv:2312.14375</a> [<a href="/pdf/2312.14375" title="Download PDF">pdf</a>, <a href="/ps/2312.14375" title="Download PostScript">ps</a>, <a href="/format/2312.14375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> R-Pool and Settlement Markets for Recoverable ERC-20R Tokens
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kaili Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qinchen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+C">Calvin Cai</a>, 
<a href="/search/cs?searchtype=author&query=Boneh%2C+D">Dan Boneh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in 2023 ACM Workshop on Decentralized Finance and Security (ACM DeFi 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">ERC-20R is a wrapper around ERC-20 that supports asset recovery within a
limited time window after an asset is transferred. It is designed to reduce
theft and losses on the blockchain by allowing a victim to recover their stolen
or lost assets during the recovery window. When an honest recipient receives an
ERC-20R asset, they must wait until the recovery windows elapses (say, 24
hours), before they can unwrap the asset back to its base ERC-20 form. We argue
that many DeFi services will likely refuse to accept unsettled recoverable
assets because they can interfere with their normal operations. Consequently,
when Alice receives an ERC-20R token, she must wait 24 hours before she can use
it with a DeFi service. But what if Alice is willing to pay a fee to exchange
the wrapped token for an unwrapped ERC-20 token that can be used right away? In
this paper we explore how to design a pool to exchange an unsettled ERC-20R
asset for a base ERC-20 of the same asset. Designing such a pool raises several
challenging questions and we present our solutions.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14378" title="Abstract">arXiv:2312.14378</a> [<a href="/pdf/2312.14378" title="Download PDF">pdf</a>, <a href="/format/2312.14378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Attention Merging for Improved Speech Recognition and Audio  Event Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sundar%2C+A+S">Anirudh S. Sundar</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C+H">Chao-Han Huck Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+D+M">David M. Chan</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Shalini Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Ravichandran%2C+V">Venkatesh Ravichandran</a>, 
<a href="/search/cs?searchtype=author&query=Nidadavolu%2C+P+S">Phani Sankar Nidadavolu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Training large foundation models using self-supervised objectives on
unlabeled data, followed by fine-tuning on downstream tasks, has emerged as a
standard procedure. Unfortunately, the efficacy of this approach is often
constrained by both limited fine-tuning compute and scarcity in labeled
downstream data. We introduce Multimodal Attention Merging (MAM), an attempt
that facilitates direct knowledge transfer from attention matrices of models
rooted in high resource modalities, text and images, to those in
resource-constrained domains, speech and audio, employing a zero-shot paradigm.
MAM reduces the relative Word Error Rate (WER) of an Automatic Speech
Recognition (ASR) model by up to 6.70%, and relative classification error of an
Audio Event Classification (AEC) model by 10.63%. In cases where some
data/compute is available, we present Learnable-MAM, a data-driven approach to
merging attention matrices, resulting in a further 2.90% relative reduction in
WER for ASR and 18.42% relative reduction in AEC compared to fine-tuning.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14380" title="Abstract">arXiv:2312.14380</a> [<a href="/pdf/2312.14380" title="Download PDF">pdf</a>, <a href="/format/2312.14380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning with Projected Trajectory Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tiejin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yuanpu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yujia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+C">Cho-Jui Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinghui Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Federated learning enables joint training of machine learning models from
distributed clients without sharing their local data. One key challenge in
federated learning is to handle non-identically distributed data across the
clients, which leads to deteriorated model training performances. Prior works
in this line of research mainly focus on utilizing last-step global model
parameters/gradients or the linear combinations of the past model
parameters/gradients, which do not fully exploit the potential of global
information from the model training trajectory. In this paper, we propose a
novel federated learning framework with projected trajectory regularization
(FedPTR) for tackling the data heterogeneity issue, which proposes a unique way
to better extract the essential global information from the model training
trajectory. Specifically, FedPTR allows local clients or the server to optimize
an auxiliary (synthetic) dataset that mimics the learning dynamics of the
recent model update and utilizes it to project the next-step model trajectory
for local training regularization. We conduct rigorous theoretical analysis for
our proposed framework under nonconvex stochastic settings to verify its fast
convergence under heterogeneous data distributions. Experiments on various
benchmark datasets and non-i.i.d. settings validate the effectiveness of our
proposed framework.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14383" title="Abstract">arXiv:2312.14383</a> [<a href="/pdf/2312.14383" title="Download PDF">pdf</a>, <a href="/format/2312.14383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Removing Interference and Recovering Content Imaginatively for Visible  Watermark Removal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leng%2C+Y">Yicheng Leng</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chaowei Fang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gen Li</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yixiang Fang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanbin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Visible watermarks, while instrumental in protecting image copyrights,
frequently distort the underlying content, complicating tasks like scene
interpretation and image editing. Visible watermark removal aims to eliminate
the interference of watermarks and restore the background content. However,
existing methods often implement watermark component removal and background
restoration tasks within a singular branch, leading to residual watermarks in
the predictions and ignoring cases where watermarks heavily obscure the
background. To address these limitations, this study introduces the Removing
Interference and Recovering Content Imaginatively (RIRCI) framework. RIRCI
embodies a two-stage approach: the initial phase centers on discerning and
segregating the watermark component, while the subsequent phase focuses on
background content restoration. To achieve meticulous background restoration,
our proposed model employs a dual-path network capable of fully exploring the
intrinsic background information beneath semi-transparent watermarks and
peripheral contextual information from unaffected regions. Moreover, a Global
and Local Context Interaction module is built upon multi-layer perceptrons and
bidirectional feature transformation for comprehensive representation modeling
in the background restoration phase. The efficacy of our approach is
empirically validated across two large-scale datasets, and our findings reveal
a marked enhancement over existing watermark removal techniques.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14385" title="Abstract">arXiv:2312.14385</a> [<a href="/pdf/2312.14385" title="Download PDF">pdf</a>, <a href="/format/2312.14385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative AI Beyond LLMs: System Implications of Multi-Modal Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Golden%2C+A">Alicia Golden</a>, 
<a href="/search/cs?searchtype=author&query=Hsia%2C+S">Samuel Hsia</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Fei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Acun%2C+B">Bilge Acun</a>, 
<a href="/search/cs?searchtype=author&query=Hosmer%2C+B">Basil Hosmer</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yejin Lee</a>, 
<a href="/search/cs?searchtype=author&query=DeVito%2C+Z">Zachary DeVito</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+J">Jeff Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+G">Gu-Yeon Wei</a>, 
<a href="/search/cs?searchtype=author&query=Brooks%2C+D">David Brooks</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Carole-Jean Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">As the development of large-scale Generative AI models evolve beyond text
(1D) generation to include image (2D) and video (3D) generation, processing
spatial and temporal information presents unique challenges to quality,
performance, and efficiency. We present the first work towards understanding
this new system design space for multi-modal text-to-image (TTI) and
text-to-video (TTV) generation models. Current model architecture designs are
bifurcated into 2 categories: Diffusion- and Transformer-based models. Our
systematic performance characterization on a suite of eight representative
TTI/TTV models shows that after state-of-the-art optimization techniques such
as Flash Attention are applied, Convolution accounts for up to 44% of execution
time for Diffusion-based TTI models, while Linear layers consume up to 49% of
execution time for Transformer-based models. We additionally observe that
Diffusion-based TTI models resemble the Prefill stage of LLM inference, and
benefit from 1.1-2.5x greater speedup from Flash Attention than
Transformer-based TTI models that resemble the Decode phase. Since
optimizations designed for LLMs do not map directly onto TTI/TTV models, we
must conduct a thorough characterization of these workloads to gain insights
for new optimization opportunities. In doing so, we define sequence length in
the context of TTI/TTV models and observe sequence length can vary up to 4x in
Diffusion model inference. We additionally observe temporal aspects of TTV
workloads pose unique system bottlenecks, with Temporal Attention accounting
for over 60% of total Attention time. Overall, our in-depth system performance
characterization is a critical first step towards designing efficient and
deployable systems for emerging TTI/TTV workloads.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14387" title="Abstract">arXiv:2312.14387</a> [<a href="/pdf/2312.14387" title="Download PDF">pdf</a>, <a href="/format/2312.14387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variance-insensitive and Target-preserving Mask Refinement for  Interactive Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chaowei Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Ziyin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junye Chen</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hanjing Su</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingyao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanbin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Point-based interactive image segmentation can ease the burden of mask
annotation in applications such as semantic segmentation and image editing.
However, fully extracting the target mask with limited user inputs remains
challenging. We introduce a novel method, Variance-Insensitive and
Target-Preserving Mask Refinement to enhance segmentation quality with fewer
user inputs. Regarding the last segmentation result as the initial mask, an
iterative refinement process is commonly employed to continually enhance the
initial mask. Nevertheless, conventional techniques suffer from sensitivity to
the variance in the initial mask. To circumvent this problem, our proposed
method incorporates a mask matching algorithm for ensuring consistent
inferences from different types of initial masks. We also introduce a
target-aware zooming algorithm to preserve object information during
downsampling, balancing efficiency and accuracy. Experiments on GrabCut,
Berkeley, SBD, and DAVIS datasets demonstrate our method's state-of-the-art
performance in interactive image segmentation.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14388" title="Abstract">arXiv:2312.14388</a> [<a href="/pdf/2312.14388" title="Download PDF">pdf</a>, <a href="/format/2312.14388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generalized Shuffle Framework for Privacy Amplification: Strengthening  Privacy Guarantees and Enhancing Utility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">E Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yifei Ge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">The shuffle model of local differential privacy is an advanced method of
privacy amplification designed to enhance privacy protection with high utility.
It achieves this by randomly shuffling sensitive data, making linking
individual data points to specific individuals more challenging. However, most
existing studies have focused on the shuffle model based on
$(\epsilon_0,0)$-Locally Differentially Private (LDP) randomizers, with limited
consideration for complex scenarios such as $(\epsilon_0,\delta_0)$-LDP or
personalized LDP (PLDP). This hinders a comprehensive understanding of the
shuffle model's potential and limits its application in various settings. To
bridge this research gap, we propose a generalized shuffle framework that can
be applied to any $(\epsilon_i,\delta_i)$-PLDP setting with personalized
privacy parameters. This generalization allows for a broader exploration of the
privacy-utility trade-off and facilitates the design of privacy-preserving
analyses in diverse contexts. We prove that shuffled
$(\epsilon_i,\delta_i)$-PLDP process approximately preserves $\mu$-Gaussian
Differential Privacy with \mu = \sqrt{\frac{2}{\sum_{i=1}^{n}
\frac{1-\delta_i}{1+e^{\epsilon_i}}-\max_{i}{\frac{1-\delta_{i}}{1+e^{\epsilon_{i}}}}}}.
$
<br />This approach allows us to avoid the limitations and potential inaccuracies
associated with inequality estimations. To strengthen the privacy guarantee, we
improve the lower bound by utilizing hypothesis testing} instead of relying on
rough estimations like the Chernoff bound or Hoeffding's inequality.
Furthermore, extensive comparative evaluations clearly show that our approach
outperforms existing methods in achieving strong central privacy guarantees
while preserving the utility of the global model. We have also carefully
designed corresponding algorithms for average function, frequency estimation,
and stochastic gradient descent.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14389" title="Abstract">arXiv:2312.14389</a> [<a href="/pdf/2312.14389" title="Download PDF">pdf</a>, <a href="/format/2312.14389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StyleRetoucher: Generalized Portrait Image Retouching with GAN Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+W">Wanchao Su</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Can Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+H">Hangzhou Han</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Hongbo Fu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+J">Jing Liao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Creating fine-retouched portrait images is tedious and time-consuming even
for professional artists. There exist automatic retouching methods, but they
either suffer from over-smoothing artifacts or lack generalization ability. To
address such issues, we present StyleRetoucher, a novel automatic portrait
image retouching framework, leveraging StyleGAN's generation and generalization
ability to improve an input portrait image's skin condition while preserving
its facial details. Harnessing the priors of pretrained StyleGAN, our method
shows superior robustness: a). performing stably with fewer training samples
and b). generalizing well on the out-domain data. Moreover, by blending the
spatial features of the input image and intermediate features of the StyleGAN
layers, our method preserves the input characteristics to the largest extent.
We further propose a novel blemish-aware feature selection mechanism to
effectively identify and remove the skin blemishes, improving the image skin
condition. Qualitative and quantitative evaluations validate the great
generalization capability of our method. Further experiments show
StyleRetoucher's superior performance to the alternative solutions in the image
retouching task. We also conduct a user perceptive study to confirm the
superior retouching performance of our method over the existing
state-of-the-art alternatives.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14394" title="Abstract">arXiv:2312.14394</a> [<a href="/pdf/2312.14394" title="Download PDF">pdf</a>, <a href="/format/2312.14394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdapTraj: A Multi-Source Domain Generalization Framework for Multi-Agent  Trajectory Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+T">Tangwen Qian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yile Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cong%2C+G">Gao Cong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yongjun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICDE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Multi-agent trajectory prediction, as a critical task in modeling complex
interactions of objects in dynamic systems, has attracted significant research
attention in recent years. Despite the promising advances, existing studies all
follow the assumption that data distribution observed during model learning
matches that encountered in real-world deployments. However, this assumption
often does not hold in practice, as inherent distribution shifts might exist in
the mobility patterns for deployment environments, thus leading to poor domain
generalization and performance degradation. Consequently, it is appealing to
leverage trajectories from multiple source domains to mitigate such
discrepancies for multi-agent trajectory prediction task. However, the
development of multi-source domain generalization in this task presents two
notable issues: (1) negative transfer; (2) inadequate modeling for external
factors. To address these issues, we propose a new causal formulation to
explicitly model four types of features: domain-invariant and domain-specific
features for both the focal agent and neighboring agents. Building upon the new
formulation, we propose AdapTraj, a multi-source domain generalization
framework specifically tailored for multi-agent trajectory prediction. AdapTraj
serves as a plug-and-play module that is adaptable to a variety of models.
Extensive experiments on four datasets with different domains demonstrate that
AdapTraj consistently outperforms other baselines by a substantial margin.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14395" title="Abstract">arXiv:2312.14395</a> [<a href="/pdf/2312.14395" title="Download PDF">pdf</a>, <a href="/format/2312.14395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Deep Learning Image Verification Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Solomon%2C+E">Enoch Solomon</a>, 
<a href="/search/cs?searchtype=author&query=Woubie%2C+A">Abraham Woubie</a>, 
<a href="/search/cs?searchtype=author&query=Emiru%2C+E+S">Eyael Solomon Emiru</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Although deep learning are commonly employed for image recognition, usually
huge amount of labeled training data is required, which may not always be
readily available. This leads to a noticeable performance disparity when
compared to state-of-the-art unsupervised face verification techniques. In this
work, we propose a method to narrow this gap by leveraging an autoencoder to
convert the face image vector into a novel representation. Notably, the
autoencoder is trained to reconstruct neighboring face image vectors rather
than the original input image vectors. These neighbor face image vectors are
chosen through an unsupervised process based on the highest cosine scores with
the training face image vectors. The proposed method achieves a relative
improvement of 56\% in terms of EER over the baseline system on Labeled Faces
in the Wild (LFW) dataset. This has successfully narrowed down the performance
gap between cosine and PLDA scoring systems.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14396" title="Abstract">arXiv:2312.14396</a> [<a href="/pdf/2312.14396" title="Download PDF">pdf</a>, <a href="/format/2312.14396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoCo: Graph Storage and Software Prefetch Co-Design for Dynamic Graph  Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongfu Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">There has been growing demands in the dynamic graph, in which a continuous
stream of graph updates is mixed with graph computation. For the above
scenarios, the compact physically continuous structures and the dispersed but
logically continuous structures become the two ends of the scale. In principle,
the Pointers become the weights. The number of them determines which side of
the scale the data structure leans towards. The Pointers make it easier to
update the graph but they will result in poor cache locality. This paper
presents SoCo, a graph storage and software prefetch co-design for dynamic
graph processing that significantly improves on both graph updating and graph
computation. We utilize C++20 coroutines and software prefetching techniques to
optimize cache miss overhead during computation, and design a data structure
that not only meets the requirements of dynamic graph processing but is also
more suitable for prefetching. We also conduct extensive experiments on
different datasets and show that SoCo could outperform state-of-the-arts by
10.48x on average and at the same time guarantee a pioneer insertion
performance (1st place in 5 cases and 2nd place in 2 cases).
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14398" title="Abstract">arXiv:2312.14398</a> [<a href="/pdf/2312.14398" title="Download PDF">pdf</a>, <a href="/format/2312.14398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZMM-TTS: Zero-shot Multilingual and Multispeaker Speech Synthesis  Conditioned on Self-supervised Discrete Speech Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+C">Cheng Gong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cooper%2C+E">Erica Cooper</a>, 
<a href="/search/cs?searchtype=author&query=Wells%2C+D">Dan Wells</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Longbiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+J">Jianwu Dang</a>, 
<a href="/search/cs?searchtype=author&query=Richmond%2C+K">Korin Richmond</a>, 
<a href="/search/cs?searchtype=author&query=Yamagishi%2C+J">Junichi Yamagishi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Neural text-to-speech (TTS) has achieved human-like synthetic speech for
single-speaker, single-language synthesis. Multilingual TTS systems are limited
to resource-rich languages due to the lack of large paired text and
studio-quality audio data. In most cases, TTS systems are built using a single
speaker's voice. However, there is growing interest in developing systems that
can synthesize voices for new speakers using only a few seconds of their
speech. This paper presents ZMM-TTS, a multilingual and multispeaker framework
utilizing quantized latent speech representations from a large-scale,
pre-trained, self-supervised model. Our paper is the first to incorporate the
representations from text-based and speech-based self-supervised learning
models into multilingual speech synthesis tasks. We conducted comprehensive
subjective and objective evaluations through a series of experiments. Our model
has been proven effective in terms of speech naturalness and similarity for
both seen and unseen speakers in six high-resource languages. We also tested
the efficiency of our method on two hypothetical low-resource languages. The
results are promising, indicating that our proposed approach can synthesize
audio that is intelligible and has a high degree of similarity to the target
speaker's voice, even without any training data for the new, unseen language.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14400" title="Abstract">arXiv:2312.14400</a> [<a href="/pdf/2312.14400" title="Download PDF">pdf</a>, <a href="/format/2312.14400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling Backbone Effects in CLIP: Exploring Representational Synergies  and Variances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rodriguez-Opazo%2C+C">Cristian Rodriguez-Opazo</a>, 
<a href="/search/cs?searchtype=author&query=Marrese-Taylor%2C+E">Edison Marrese-Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Abbasnejad%2C+E">Ehsan Abbasnejad</a>, 
<a href="/search/cs?searchtype=author&query=Damirchi%2C+H">Hamed Damirchi</a>, 
<a href="/search/cs?searchtype=author&query=Jara%2C+I+M">Ignacio M. Jara</a>, 
<a href="/search/cs?searchtype=author&query=Bravo-Marquez%2C+F">Felipe Bravo-Marquez</a>, 
<a href="/search/cs?searchtype=author&query=van+den+Hengel%2C+A">Anton van den Hengel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Contrastive Language-Image Pretraining (CLIP) stands out as a prominent
method for image representation learning. Various neural architectures,
spanning Transformer-based models like Vision Transformers (ViTs) to
Convolutional Networks (ConvNets) like ResNets, are trained with CLIP and serve
as universal backbones across diverse vision tasks. Despite utilizing the same
data and training objectives, the effectiveness of representations learned by
these architectures raises a critical question. Our investigation explores the
differences in CLIP performance among these backbone architectures, revealing
significant disparities in their classifications. Notably, normalizing these
representations results in substantial performance variations. Our findings
showcase a remarkable possible synergy between backbone predictions that could
reach an improvement of over 20% through informed selection of the appropriate
backbone. Moreover, we propose a simple, yet effective approach to combine
predictions from multiple backbones, leading to a notable performance boost of
up to 6.34\%. We will release the code for reproducing the results.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14401" title="Abstract">arXiv:2312.14401</a> [<a href="/pdf/2312.14401" title="Download PDF">pdf</a>, <a href="/format/2312.14401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards an Exploratory Visual Analytics System for Griefer  Identification in MOBA Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zixin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shiyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhihua Jin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gaoping Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chao%2C+Y">Yang Chao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhenchuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Quan Li</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+H">Huamin Qu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE VIS 2023 (Poster)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Multiplayer Online Battle Arenas (MOBAs) have gained a significant player
base worldwide, generating over two billion US dollars in annual game revenue.
However, the presence of griefers, who deliberately irritate and harass other
players within the game, can have a detrimental impact on players' experience,
compromising game fairness and potentially leading to the emergence of gray
industries. Unfortunately, the absence of a standardized criterion, and the
lack of high-quality labeled and annotated data has made it challenging to
detect the presence of griefers. Given the complexity of the multivariant
spatiotemporal data for MOBA games, game developers heavily rely on manual
review of entire game video recordings to label and annotate griefers, which is
a time-consuming process. To alleviate this issue, we have collaborated with a
team of game specialists to develop an interactive visual analysis interface,
called GrieferLens. It overviews players' behavior analysis and synthesizes
their key match events. By presenting multiple views of information,
GrieferLens can help the game design team efficiently recognize and label
griefers in MOBA games and build up a foundation for creating a more enjoyable
and fair gameplay environment.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14402" title="Abstract">arXiv:2312.14402</a> [<a href="/pdf/2312.14402" title="Download PDF">pdf</a>, <a href="/format/2312.14402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Fairness Fair: Bringing Human Perception into Collective  Decision-Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hosseini%2C+H">Hadi Hosseini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at AAAI Conference on Artificial Intelligence (AAAI) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA); Theoretical Economics (econ.TH)

</div>
<p class="mathjax">Fairness is one of the most desirable societal principles in collective
decision-making. It has been extensively studied in the past decades for its
axiomatic properties and has received substantial attention from the multiagent
systems community in recent years for its theoretical and computational aspects
in algorithmic decision-making. However, these studies are often not
sufficiently rich to capture the intricacies of human perception of fairness in
the ambivalent nature of the real-world problems. We argue that not only fair
solutions should be deemed desirable by social planners (designers), but they
should be governed by human and societal cognition, consider perceived outcomes
based on human judgement, and be verifiable. We discuss how achieving this goal
requires a broad transdisciplinary approach ranging from computing and AI to
behavioral economics and human-AI interaction. In doing so, we identify
shortcomings and long-term challenges of the current literature of fair
division, describe recent efforts in addressing them, and more importantly,
highlight a series of open research directions.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14404" title="Abstract">arXiv:2312.14404</a> [<a href="/pdf/2312.14404" title="Download PDF">pdf</a>, <a href="/format/2312.14404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Covariate Gait Recognition: A Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+S">Shinan Zou</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+J">Jianbo Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chuanfu Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shiqi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jin Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by AAAI2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Gait datasets are essential for gait research. However, this paper observes
that present benchmarks, whether conventional constrained or emerging
real-world datasets, fall short regarding covariate diversity. To bridge this
gap, we undertake an arduous 20-month effort to collect a cross-covariate gait
recognition (CCGR) dataset. The CCGR dataset has 970 subjects and about 1.6
million sequences; almost every subject has 33 views and 53 different
covariates. Compared to existing datasets, CCGR has both population and
individual-level diversity. In addition, the views and covariates are well
labeled, enabling the analysis of the effects of different factors. CCGR
provides multiple types of gait data, including RGB, parsing, silhouette, and
pose, offering researchers a comprehensive resource for exploration. In order
to delve deeper into addressing cross-covariate gait recognition, we propose
parsing-based gait recognition (ParsingGait) by utilizing the newly proposed
parsing data. We have conducted extensive experiments. Our main results show:
1) Cross-covariate emerges as a pivotal challenge for practical applications of
gait recognition. 2) ParsingGait demonstrates remarkable potential for further
advancement. 3) Alarmingly, existing SOTA methods achieve less than 43%
accuracy on the CCGR, highlighting the urgency of exploring cross-covariate
gait recognition. Link: https://github.com/ShinanZou/CCGR.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14405" title="Abstract">arXiv:2312.14405</a> [<a href="/pdf/2312.14405" title="Download PDF">pdf</a>, <a href="/format/2312.14405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Attention-Based Symmetry Constraint Extraction for Analog Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Song Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lin Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yi Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages,9 figures,3 tables, 1 algorithm
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In recent years, analog circuits have received extensive attention and are
widely used in many emerging applications. The high demand for analog circuits
necessitates shorter circuit design cycles. To achieve the desired performance
and specifications, various geometrical symmetry constraints must be carefully
considered during the analog layout process. However, the manual labeling of
these constraints by experienced analog engineers is a laborious and
time-consuming process. To handle the costly runtime issue, we propose a
graph-based learning framework to automatically extract symmetric constraints
in analog circuit layout. The proposed framework leverages the connection
characteristics of circuits and the devices'information to learn the general
rules of symmetric constraints, which effectively facilitates the extraction of
device-level constraints on circuit netlists. The experimental results
demonstrate that compared to state-of-the-art symmetric constraint detection
approaches, our framework achieves higher accuracy and lower false positive
rate.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14406" title="Abstract">arXiv:2312.14406</a> [<a href="/pdf/2312.14406" title="Download PDF">pdf</a>, <a href="/format/2312.14406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Pretraining at Scale: Transformer-Based Encoding of  Transactional Behavior for Fraud Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z+Y">Ze Yu Zhao</a> (1), 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zheng Zhu</a> (1), 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guilin Li</a> (1), 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhan Wang</a> (1), 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bo Wang</a> (1) ((1) Tencent, WeChat Pay)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this work, we introduce an innovative autoregressive model leveraging
Generative Pretrained Transformer (GPT) architectures, tailored for fraud
detection in payment systems. Our approach innovatively confronts token
explosion and reconstructs behavioral sequences, providing a nuanced
understanding of transactional behavior through temporal and contextual
analysis. Utilizing unsupervised pretraining, our model excels in feature
representation without the need for labeled data. Additionally, we integrate a
differential convolutional approach to enhance anomaly detection, bolstering
the security and efficacy of one of the largest online payment merchants in
China. The scalability and adaptability of our model promise broad
applicability in various transactional contexts.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14407" title="Abstract">arXiv:2312.14407</a> [<a href="/pdf/2312.14407" title="Download PDF">pdf</a>, <a href="/format/2312.14407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdvCloak: Customized Adversarial Cloak for Privacy Protection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuannan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yaoyao Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+X">Xing Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peipei Li</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+W">Weihong Deng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With extensive face images being shared on social media, there has been a
notable escalation in privacy concerns. In this paper, we propose AdvCloak, an
innovative framework for privacy protection using generative models. AdvCloak
is designed to automatically customize class-wise adversarial masks that can
maintain superior image-level naturalness while providing enhanced
feature-level generalization ability. Specifically, AdvCloak sequentially
optimizes the generative adversarial networks by employing a two-stage training
strategy. This strategy initially focuses on adapting the masks to the unique
individual faces via image-specific training and then enhances their
feature-level generalization ability to diverse facial variations of
individuals via person-specific training. To fully utilize the limited training
data, we combine AdvCloak with several general geometric modeling methods, to
better describe the feature subspace of source identities. Extensive
quantitative and qualitative evaluations on both common and celebrity datasets
demonstrate that AdvCloak outperforms existing state-of-the-art methods in
terms of efficiency and effectiveness.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14408" title="Abstract">arXiv:2312.14408</a> [<a href="/pdf/2312.14408" title="Download PDF">pdf</a>, <a href="/ps/2312.14408" title="Download PostScript">ps</a>, <a href="/format/2312.14408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extended p-median problems for balancing service efficiency and equality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+Y">Yunfeng Kong</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+C">Chenchen Lian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guangli Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+S">Shiyan Zhai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 4 tables, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">This article deals with the location problem for balancing the service
efficiency and equality. In public service systems, some people may feel envy
in case that they need longer travel distance to access services than others.
The strength of the envy can be measured by comparing one's travel distance to
service facility with a threshold distance. Using the total envy function, four
extended p-median problems are proposed for trade-off between service
efficiency and equality. Five analytical properties of the new problems are
mathematically proven. The new problems were tested on three sets of
well-designed instances. The experimentation shows that the equality measures,
such as the standard deviation, the mean absolute deviation, and the Gini
coefficient between travel distances, can be substantially improved by
minimizing the travel cost and the spatial envy. The experimentation also shows
that, when the service supply is given in terms of the number of facilities,
the service equality can be considerably improved by slightly increasing the
travel distance. When the service supply is increased in terms of the number of
facilities, both the service efficiency and spatial equality can be
significantly improved.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14410" title="Abstract">arXiv:2312.14410</a> [<a href="/pdf/2312.14410" title="Download PDF">pdf</a>, <a href="/format/2312.14410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-Stage Adaptive Feature Fusion Neural Network for Multimodal Gait  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+S">Shinan Zou</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+J">Jianbo Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shiqi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jin Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by IJCB2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IJCB2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Gait recognition is a biometric technology that has received extensive
attention. Most existing gait recognition algorithms are unimodal, and a few
multimodal gait recognition algorithms perform multimodal fusion only once.
None of these algorithms may fully exploit the complementary advantages of the
multiple modalities. In this paper, by considering the temporal and spatial
characteristics of gait data, we propose a multi-stage feature fusion strategy
(MSFFS), which performs multimodal fusions at different stages in the feature
extraction process. Also, we propose an adaptive feature fusion module (AFFM)
that considers the semantic association between silhouettes and skeletons. The
fusion process fuses different silhouette areas with their more related
skeleton joints. Since visual appearance changes and time passage co-occur in a
gait period, we propose a multiscale spatial-temporal feature extractor
(MSSTFE) to learn the spatial-temporal linkage features thoroughly.
Specifically, MSSTFE extracts and aggregates spatial-temporal linkages
information at different spatial scales. Combining the strategy and modules
mentioned above, we propose a multi-stage adaptive feature fusion (MSAFF)
neural network, which shows state-of-the-art performance in many experiments on
three datasets. Besides, MSAFF is equipped with feature dimensional pooling (FD
Pooling), which can significantly reduce the dimension of the gait
representations without hindering the accuracy.
https://github.com/ShinanZou/MSAFF
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14418" title="Abstract">arXiv:2312.14418</a> [<a href="/pdf/2312.14418" title="Download PDF">pdf</a>, <a href="/format/2312.14418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sharp error estimates for target measure diffusion maps with  applications to the committor problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sule%2C+S">Shashank Sule</a>, 
<a href="/search/math?searchtype=author&query=Evans%2C+L">Luke Evans</a>, 
<a href="/search/math?searchtype=author&query=Cameron%2C+M">Maria Cameron</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We obtain asymptotically sharp error estimates for the consistency error of
the Target Measure Diffusion map (TMDmap) (Banisch et al. 2020), a variant of
diffusion maps featuring importance sampling and hence allowing input data
drawn from an arbitrary density. The derived error estimates include the bias
error and the variance error. The resulting convergence rates are consistent
with the approximation theory of graph Laplacians. The key novelty of our
results lies in the explicit quantification of all the prefactors on
leading-order terms. We also prove an error estimate for solutions of Dirichlet
BVPs obtained using TMDmap, showing that the solution error is controlled by
consistency error. We use these results to study an important application of
TMDmap in the analysis of rare events in systems governed by overdamped
Langevin dynamics using the framework of transition path theory (TPT). The
cornerstone ingredient of TPT is the solution of the committor problem, a
boundary value problem for the backward Kolmogorov PDE. Remarkably, we find
that the TMDmap algorithm is particularly suited as a meshless solver to the
committor problem due to the cancellation of several error terms in the
prefactor formula. Furthermore, significant improvements in bias and variance
errors occur when using a quasi-uniform sampling density. Our numerical
experiments show that these improvements in accuracy are realizable in practice
when using $\delta$-nets as spatially uniform inputs to the TMDmap algorithm.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14419" title="Abstract">arXiv:2312.14419</a> [<a href="/pdf/2312.14419" title="Download PDF">pdf</a>, <a href="/ps/2312.14419" title="Download PostScript">ps</a>, <a href="/format/2312.14419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An F5 Algorithm for Tropical Gr&#xf6;bner Bases in the Weyl Algebras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hartanto%2C+A+D">Ari Dwi Hartanto</a>, 
<a href="/search/cs?searchtype=author&query=Ohara%2C+K">Katsuyoshi Ohara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Rings and Algebras (math.RA)

</div>
<p class="mathjax">A Gr\"obner basis computation for the Weyl algebra with respect to a tropical
term order and by using a homogenization-dehomogenization technique is
sufficiently sluggish. A significant number of reductions to zero occur. To
improve the computation, a tropical F5 algorithm is developed for this context.
As a member of the family of signature-based algorithms, this algorithm keeps
track of where Weyl algebra elements come from to anticipate reductions to
zero. The total order for ordering module monomials or signatures in this paper
is designed as close as possible to the definition of the tropical term order.
As in Vaccon et al. (2021), this total order is not compatible with the
tropical term order.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14421" title="Abstract">arXiv:2312.14421</a> [<a href="/pdf/2312.14421" title="Download PDF">pdf</a>, <a href="/format/2312.14421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Actionable Formal Concept Identification with Base-Equivalent  Conceptual-Relevance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bobi%2C+A">Ayao Bobi</a>, 
<a href="/search/cs?searchtype=author&query=Missaoui%2C+R">Rokia Missaoui</a>, 
<a href="/search/cs?searchtype=author&query=Ibrahim%2C+M+H">Mohamed Hamza Ibrahim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In knowledge discovery applications, the pattern set generated from data can
be tremendously large and hard to explore by analysts. In the Formal Concept
Analysis (FCA) framework, there have been studies to identify important formal
concepts through the stability index and other quality measures. In this paper,
we introduce the Base-Equivalent Conceptual Relevance (BECR) score, a novel
conceptual relevance interestingness measure for improving the identification
of actionable concepts. From a conceptual perspective, the base and equivalent
attributes are considered meaningful information and are highly essential to
maintain the conceptual structure of concepts. Thus, the basic idea of BECR is
that the more base and equivalent attributes and minimal generators a concept
intent has, the more relevant it is. As such, BECR quantifies these attributes
and minimal generators per concept intent. Our preliminary experiments on
synthetic and real-world datasets show the efficiency of BECR compared to the
well-known stability index.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14423" title="Abstract">arXiv:2312.14423</a> [<a href="/pdf/2312.14423" title="Download PDF">pdf</a>, <a href="/format/2312.14423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficacy of Machine-Generated Instructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gulati%2C+S">Samaksh Gulati</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+A">Anshit Verma</a>, 
<a href="/search/cs?searchtype=author&query=Parmar%2C+M">Manoj Parmar</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhary%2C+P">Palash Chaudhary</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 pages references, 6 Tables, 8 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large "instruction-tuned" language models (i.e., finetuned to respond to
instructions) have demonstrated a remarkable ability to generalize zero-shot to
new tasks. Nevertheless, they depend heavily on human-written instruction data
that is often limited in quantity, diversity, and creativity, therefore
hindering the generality of the tuned model. We conducted a quantitative study
to figure out the efficacy of machine-generated annotations, where we compare
the results of a fine-tuned BERT model with human v/s machine-generated
annotations. Applying our methods to the vanilla GPT-3 model, we saw that
machine generated annotations were 78.54% correct and the fine-tuned model
achieved a 96.01% model performance compared to the performance with
human-labelled annotations. This result shows that machine-generated
annotations are a resource and cost effective way to fine-tune down-stream
models.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14424" title="Abstract">arXiv:2312.14424</a> [<a href="/pdf/2312.14424" title="Download PDF">pdf</a>, <a href="/format/2312.14424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lost in the Logistical Funhouse: Speculative Design as Synthetic Media  Enterprise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Horn%2C+Z">Zoe Horn</a>, 
<a href="/search/cs?searchtype=author&query=Magee%2C+L">Liam Magee</a>, 
<a href="/search/cs?searchtype=author&query=Munster%2C+A">Anna Munster</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">From the deployment of chatbots as procurement negotiators by corporations
such as Walmart to autonomous agents providing 'differentiated chat' for
managing overbooked flights, synthetic media are making the world of logistics
their 'natural' habitat. Here the coordination of commodities, parts and labour
design the problems and produce the training sets from which 'solutions' can be
synthesised. But to what extent might synthetic media, surfacing via
proto-platforms such as MidJourney and OpenAI and apps such as Eleven Labs and
D:ID, be understood as logistical media? This paper details synthetic media
experiments with 'ChatFOS', a GPT-based bot tasked with developing a logistics
design business. Using its prompt-generated media outputs, we assemble a
simulation and parody of AI's emerging functionalities within logistical
worlds. In the process, and with clunky 'human-in-the-loop' stitching, we
illustrate how large language models become media routers or switches,
governing production of image prompts, website code, promotional copy, and
investor pitch scenarios. Together these elements become links chained together
in media ensembles such as the corporate website or the promotional video,
fuelling the fictive logistics visualisation company we have 'founded'. The
processes and methods of producing speculative scenarios via ChatFOS lead us to
consider how synthetic media might be re-positioned as logistical media. Our
experiments probe the ways in which the media of logistics and the logistics of
media are increasingly enfolded. We ask: what can a (practice-based)
articulation of this double-becoming of logistics and synthetic mediality tell
us about the politics and aesthetics of contemporary computation and capital?
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14425" title="Abstract">arXiv:2312.14425</a> [<a href="/pdf/2312.14425" title="Download PDF">pdf</a>, <a href="/format/2312.14425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coriolis Factorizations and their Connections to Riemannian Geometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wensing%2C+P+M">Patrick M. Wensing</a>, 
<a href="/search/eess?searchtype=author&query=Englsberger%2C+J">Johannes Englsberger</a>, 
<a href="/search/eess?searchtype=author&query=Slotine%2C+J+E">Jean-Jacques E. Slotine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-submission working paper; comments welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Many energy-based control strategies for mechanical systems require the
choice of a Coriolis factorization satisfying a skew-symmetry property. This
paper explores (a) if and when a control designer has flexibility in this
choice, (b) what choice should be made, and (c) how to efficiently perform
control computations with it. We link the choice of a Coriolis factorization to
the notion of an affine connection on the configuration manifold and show how
properties of the connection relate with ones of the associated factorization.
Out of the choices available, the factorization based on the Christoffel
symbols is linked with a torsion-free property that limits the twisting of
system trajectories during passivity-based control. The machinery of Riemannian
geometry also offers a natural way to induce Coriolis factorizations for
constrained mechanisms from unconstrained ones, and this result provides a
pathway to use the theory for efficient control computations with
high-dimensional systems such as humanoids and quadruped robots.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14426" title="Abstract">arXiv:2312.14426</a> [<a href="/pdf/2312.14426" title="Download PDF">pdf</a>, <a href="/format/2312.14426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Room Occupancy Prediction: Exploring the Power of Machine Learning and  Temporal Insights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+S">Siqi Mao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yaping Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinpu Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziren Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuanxin Yao</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yixin Kang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Energy conservation in buildings is a paramount concern to combat greenhouse
gas emissions and combat climate change. The efficient management of room
occupancy, involving actions like lighting control and climate adjustment, is a
pivotal strategy to curtail energy consumption. In contexts where surveillance
technology isn't viable, non-intrusive sensors are employed to estimate room
occupancy. In this study, we present a predictive framework for room occupancy
that leverages a diverse set of machine learning models, with Random Forest
consistently achieving the highest predictive accuracy. Notably, this dataset
encompasses both temporal and spatial dimensions, revealing a wealth of
information. Intriguingly, our framework demonstrates robust performance even
in the absence of explicit temporal modeling. These findings underscore the
remarkable predictive power of traditional machine learning models. The success
can be attributed to the presence of feature redundancy, the simplicity of
linear spatial and temporal patterns, and the advantages of high-frequency data
sampling. While these results are compelling, it's essential to remain open to
the possibility that explicitly modeling the temporal dimension could unlock
deeper insights or further enhance predictive capabilities in specific
scenarios. In summary, our research not only validates the effectiveness of our
prediction framework for continuous and classification tasks but also
underscores the potential for improvements through the inclusion of temporal
aspects. The study highlights the promise of machine learning in shaping
energy-efficient practices and room occupancy management.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14427" title="Abstract">arXiv:2312.14427</a> [<a href="/pdf/2312.14427" title="Download PDF">pdf</a>, <a href="/format/2312.14427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GROOD: GRadient-aware Out-Of-Distribution detection in interpolated  manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=ElAraby%2C+M">Mostafa ElAraby</a>, 
<a href="/search/cs?searchtype=author&query=Sahoo%2C+S">Sabyasachi Sahoo</a>, 
<a href="/search/cs?searchtype=author&query=Pequignot%2C+Y">Yann Pequignot</a>, 
<a href="/search/cs?searchtype=author&query=Novello%2C+P">Paul Novello</a>, 
<a href="/search/cs?searchtype=author&query=Paull%2C+L">Liam Paull</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures, preprint under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep neural networks (DNNs) often fail silently with over-confident
predictions on out-of-distribution (OOD) samples, posing risks in real-world
deployments. Existing techniques predominantly emphasize either the feature
representation space or the gradient norms computed with respect to DNN
parameters, yet they overlook the intricate gradient distribution and the
topology of classification regions. To address this gap, we introduce
GRadient-aware Out-Of-Distribution detection in interpolated manifolds (GROOD),
a novel framework that relies on the discriminative power of gradient space to
distinguish between in-distribution (ID) and OOD samples. To build this space,
GROOD relies on class prototypes together with a prototype that specifically
captures OOD characteristics. Uniquely, our approach incorporates a targeted
mix-up operation at an early intermediate layer of the DNN to refine the
separation of gradient spaces between ID and OOD samples. We quantify OOD
detection efficacy using the distance to the nearest neighbor gradients derived
from the training set, yielding a robust OOD score. Experimental evaluations
substantiate that the introduction of targeted input mix-upamplifies the
separation between ID and OOD in the gradient space, yielding impressive
results across diverse datasets. Notably, when benchmarked against ImageNet-1k,
GROOD surpasses the established robustness of state-of-the-art baselines.
Through this work, we establish the utility of leveraging gradient spaces and
class prototypes for enhanced OOD detection for DNN in image classification.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14428" title="Abstract">arXiv:2312.14428</a> [<a href="/pdf/2312.14428" title="Download PDF">pdf</a>, <a href="/format/2312.14428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Industrial Large Knowledge Model Framework in Smart  Manufacturing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jay Lee</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hanqi Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been submitted to Manufacturing Letters (Under Review)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The recent emergence of large language models (LLMs) shows the potential for
artificial general intelligence, revealing new opportunities in industry 4.0
and smart manufacturing. However, a notable gap exists in applying these LLMs
in industry, primarily due to their training on general knowledge rather than
domain-specific knowledge. Such specialized domain knowledge is vital for
effectively addressing the complex needs of industrial applications. To bridge
this gap, this paper proposes an Industrial Large Knowledge Model (ILKM)
framework emphasizing their potential to revolutionize the industry in smart
manufacturing. In addition, ILKMs and LLMs are compared from eight
perspectives. Finally, "6S Principle" is proposed as the guideline for the
development of ILKMs in smart manufacturing.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14430" title="Abstract">arXiv:2312.14430</a> [<a href="/html/2312.14430" title="Download HTML">html</a>, <a href="/format/2312.14430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proceedings of the Dialogue Robot Competition 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Higashinaka%2C+R">Ryuichiro Higashinaka</a>, 
<a href="/search/cs?searchtype=author&query=Minato%2C+T">Takashi Minato</a>, 
<a href="/search/cs?searchtype=author&query=Nishizaki%2C+H">Hiromitsu Nishizaki</a>, 
<a href="/search/cs?searchtype=author&query=Nagai%2C+T">Takayuki Nagai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a proceedings of the Dialogue Robot Competition 2023. Totally 13 papers are indexed in the proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The Dialogic Robot Competition 2023 (DRC2023) is a competition for humanoid
robots (android robots that closely resemble humans) to compete in interactive
capabilities. This is the third year of the competition. The top four teams
from the preliminary competition held in November 2023 will compete in the
final competition on Saturday, December 23. The task for the interactive robots
is to recommend a tourism plan for a specific region. The robots can employ
multimodal behaviors, such as language and gestures, to engage the user in the
sightseeing plan they recommend. In the preliminary round, the interactive
robots were stationed in a travel agency office, where visitors conversed with
them and rated their performance via a questionnaire. In the final round,
dialogue researchers and tourism industry professionals interacted with the
robots and evaluated their performance. This event allows visitors to gain
insights into the types of dialogue services that future dialogue robots should
offer. The proceedings include papers on dialogue systems developed by the 12
teams participating in DRC2023, as well as an overview of the papers provided
by all the teams.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14432" title="Abstract">arXiv:2312.14432</a> [<a href="/pdf/2312.14432" title="Download PDF">pdf</a>, <a href="/format/2312.14432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable 3D Reconstruction From Single Particle X-Ray Diffraction Images  Based on Online Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shenoy%2C+J">Jay Shenoy</a>, 
<a href="/search/cs?searchtype=author&query=Levy%2C+A">Axel Levy</a>, 
<a href="/search/cs?searchtype=author&query=Poitevin%2C+F">Fr&#xe9;d&#xe9;ric Poitevin</a>, 
<a href="/search/cs?searchtype=author&query=Wetzstein%2C+G">Gordon Wetzstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="http://jayshenoy.com/xrai">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Biomolecules (q-bio.BM)

</div>
<p class="mathjax">X-ray free-electron lasers (XFELs) offer unique capabilities for measuring
the structure and dynamics of biomolecules, helping us understand the basic
building blocks of life. Notably, high-repetition-rate XFELs enable single
particle imaging (X-ray SPI) where individual, weakly scattering biomolecules
are imaged under near-physiological conditions with the opportunity to access
fleeting states that cannot be captured in cryogenic or crystallized
conditions. Existing X-ray SPI reconstruction algorithms, which estimate the
unknown orientation of a particle in each captured image as well as its shared
3D structure, are inadequate in handling the massive datasets generated by
these emerging XFELs. Here, we introduce X-RAI, an online reconstruction
framework that estimates the structure of a 3D macromolecule from large X-ray
SPI datasets. X-RAI consists of a convolutional encoder, which amortizes pose
estimation over large datasets, as well as a physics-based decoder, which
employs an implicit neural representation to enable high-quality 3D
reconstruction in an end-to-end, self-supervised manner. We demonstrate that
X-RAI achieves state-of-the-art performance for small-scale datasets in
simulation and challenging experimental settings and demonstrate its
unprecedented ability to process large datasets containing millions of
diffraction images in an online fashion. These abilities signify a paradigm
shift in X-ray SPI towards real-time capture and reconstruction.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14433" title="Abstract">arXiv:2312.14433</a> [<a href="/pdf/2312.14433" title="Download PDF">pdf</a>, <a href="/format/2312.14433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attribute-driven Disentangled Representation Learning for Multimodal  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yinwei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhiyong Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+L">Liqiang Nie</a>, 
<a href="/search/cs?searchtype=author&query=Kankanhalli%2C+M">Mohan Kankanhalli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Recommendation algorithms forecast user preferences by correlating user and
item representations derived from historical interaction patterns. In pursuit
of enhanced performance, many methods focus on learning robust and independent
representations by disentangling the intricate factors within interaction data
across various modalities in an unsupervised manner. However, such an approach
obfuscates the discernment of how specific factors (e.g., category or brand)
influence the outcomes, making it challenging to regulate their effects. In
response to this challenge, we introduce a novel method called Attribute-Driven
Disentangled Representation Learning (short for AD-DRL), which explicitly
incorporates attributes from different modalities into the disentangled
representation learning process. By assigning a specific attribute to each
factor in multimodal features, AD-DRL can disentangle the factors at both
attribute and attribute-value levels. To obtain robust and independent
representations for each factor associated with a specific attribute, we first
disentangle the representations of features both within and across different
modalities. Moreover, we further enhance the robustness of the representations
by fusing the multimodal features of the same factor. Empirical evaluations
conducted on three public real-world datasets substantiate the effectiveness of
AD-DRL, as well as its interpretability and controllability.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14434" title="Abstract">arXiv:2312.14434</a> [<a href="/pdf/2312.14434" title="Download PDF">pdf</a>, <a href="/format/2312.14434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Review on Searchable Encryption Functionality and the Evaluation of  Homomorphic Encryption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kishiyama%2C+B">Brian Kishiyama</a>, 
<a href="/search/cs?searchtype=author&query=Alsmadi%2C+I">Izzat Alsmadi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Cloud Service Providers, such as Google Cloud Platform, Microsoft Azure, or
Amazon Web Services, offer continuously evolving cloud services. It is a
growing industry. Businesses, such as Netflix and PayPal, rely on the Cloud for
data storage, computing power, and other services. For businesses, the cloud
reduces costs, provides flexibility, and allows for growth. However, there are
security and privacy concerns regarding the Cloud. Because Cloud services are
accessed through the internet, hackers and attackers could possibly access the
servers from anywhere. To protect data in the Cloud, it should be encrypted
before it is uploaded, it should be protected in storage and also in transit.
On the other hand, data owners may need to access their encrypted data. It may
also need to be altered, updated, deleted, read, searched, or shared with
others. If data is decrypted in the Cloud, sensitive data is exposed and could
be exposed and misused. One solution is to leave the data in its encrypted form
and use Searchable Encryption (SE) which operates on encrypted data. The
functionality of SE has improved since its inception and research continues to
explore ways to improve SE. This paper reviews the functionality of Searchable
Encryption, mostly related to Cloud services, in the years 2019 to 2023, and
evaluates one of its schemes, Fully Homomorphic Encryption. Overall, it seems
that research is at the point where SE efficiency is increased as multiple
functionalities are aggregated and tested.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14436" title="Abstract">arXiv:2312.14436</a> [<a href="/pdf/2312.14436" title="Download PDF">pdf</a>, <a href="/format/2312.14436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> REBEL: A Regularization-Based Solution for Reward Overoptimization in  Reinforcement Learning from Human Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+S">Souradip Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Bhaskar%2C+A">Amisha Bhaskar</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Anukriti Singh</a>, 
<a href="/search/cs?searchtype=author&query=Tokekar%2C+P">Pratap Tokekar</a>, 
<a href="/search/cs?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>, 
<a href="/search/cs?searchtype=author&query=Bedi%2C+A+S">Amrit Singh Bedi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this work, we propose REBEL, an algorithm for sample efficient reward
regularization based robotic reinforcement learning from human feedback
(RRLHF). Reinforcement learning (RL) performance for continuous control
robotics tasks is sensitive to the underlying reward function. In practice, the
reward function often ends up misaligned with human intent, values, social
norms, etc., leading to catastrophic failures in the real world. We leverage
human preferences to learn regularized reward functions and eventually align
the agents with the true intended behavior. We introduce a novel notion of
reward regularization to the existing RRLHF framework, which is termed as agent
preferences. So, we not only consider human feedback in terms of preferences,
we also propose to take into account the preference of the underlying RL agent
while learning the reward function. We show that this helps to improve the
over-optimization associated with the design of reward functions in RL. We
experimentally show that REBEL exhibits up to 70% improvement in sample
efficiency to achieve a similar level of episodic reward returns as compared to
the state-of-the-art methods such as PEBBLE and PEBBLE+SURF.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14438" title="Abstract">arXiv:2312.14438</a> [<a href="/pdf/2312.14438" title="Download PDF">pdf</a>, <a href="/format/2312.14438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PC-Conv: Unifying Homophily and Heterophily with Two-fold Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bingheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+E">Erlin Pan</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Z">Zhao Kang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Recently, many carefully crafted graph representation learning methods have
achieved impressive performance on either strong heterophilic or homophilic
graphs, but not both. Therefore, they are incapable of generalizing well across
real-world graphs with different levels of homophily. This is attributed to
their neglect of homophily in heterophilic graphs, and vice versa. In this
paper, we propose a two-fold filtering mechanism to extract homophily in
heterophilic graphs and vice versa. In particular, we extend the graph heat
equation to perform heterophilic aggregation of global information from a long
distance. The resultant filter can be exactly approximated by the
Possion-Charlier (PC) polynomials. To further exploit information at multiple
orders, we introduce a powerful graph convolution PC-Conv and its instantiation
PCNet for the node classification task. Compared with state-of-the-art GNNs,
PCNet shows competitive performance on well-known homophilic and heterophilic
graphs. Our implementation is available at https://github.com/uestclbh/PC-Conv.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14439" title="Abstract">arXiv:2312.14439</a> [<a href="/pdf/2312.14439" title="Download PDF">pdf</a>, <a href="/format/2312.14439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PUMA: Efficient Continual Graph Learning with Graph Condensation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yilun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+R">Ruihong Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yanran Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongzhi Yin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zi Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The code has been released in <a href="https://github.com/superallen13/PUMA.">this https URL</a> arXiv admin note: substantial text overlap with <a href="/abs/2309.09455">arXiv:2309.09455</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">When handling streaming graphs, existing graph representation learning models
encounter a catastrophic forgetting problem, where previously learned knowledge
of these models is easily overwritten when learning with newly incoming graphs.
In response, Continual Graph Learning emerges as a novel paradigm enabling
graph representation learning from static to streaming graphs. Our prior work,
CaT is a replay-based framework with a balanced continual learning procedure,
which designs a small yet effective memory bank for replaying data by
condensing incoming graphs. Although the CaT alleviates the catastrophic
forgetting problem, there exist three issues: (1) The graph condensation
algorithm derived in CaT only focuses on labelled nodes while neglecting
abundant information carried by unlabelled nodes; (2) The continual training
scheme of the CaT overemphasises on the previously learned knowledge, limiting
the model capacity to learn from newly added memories; (3) Both the
condensation process and replaying process of the CaT are time-consuming. In
this paper, we propose a psudo-label guided memory bank (PUMA) CGL framework,
extending from the CaT to enhance its efficiency and effectiveness by
overcoming the above-mentioned weaknesses and limits. To fully exploit the
information in a graph, PUMA expands the coverage of nodes during graph
condensation with both labelled and unlabelled nodes. Furthermore, a
training-from-scratch strategy is proposed to upgrade the previous continual
learning scheme for a balanced training between the historical and the new
graphs. Besides, PUMA uses a one-time prorogation and wide graph encoders to
accelerate the graph condensation and the graph encoding process in the
training stage to improve the efficiency of the whole framework. Extensive
experiments on four datasets demonstrate the state-of-the-art performance and
efficiency over existing methods.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14440" title="Abstract">arXiv:2312.14440</a> [<a href="/pdf/2312.14440" title="Download PDF">pdf</a>, <a href="/format/2312.14440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymmetric Bias in Text-to-Image Generation with Adversarial Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shahgir%2C+H+S">Haz Sameen Shahgir</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+X">Xianghao Kong</a>, 
<a href="/search/cs?searchtype=author&query=Steeg%2C+G+V">Greg Ver Steeg</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yue Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The widespread use of Text-to-Image (T2I) models in content generation
requires careful examination of their safety, including their robustness to
adversarial attacks. Despite extensive research into this, the reasons for
their effectiveness are underexplored. This paper presents an empirical study
on adversarial attacks against T2I models, focusing on analyzing factors
associated with attack success rates (ASRs). We introduce a new attack
objective - entity swapping using adversarial suffixes and two gradient-based
attack algorithms. Human and automatic evaluations reveal the asymmetric nature
of ASRs on entity swap: for example, it is easier to replace "human" with
"robot" in the prompt "a human dancing in the rain." with an adversarial suffix
but is significantly harder in reverse. We further propose probing metrics to
establish indicative signals from the model's beliefs to the adversarial ASR.
We identify conditions resulting in a 60% success probability for adversarial
attacks and others where this likelihood drops below 5%.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14441" title="Abstract">arXiv:2312.14441</a> [<a href="/pdf/2312.14441" title="Download PDF">pdf</a>, <a href="/format/2312.14441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DMC4ML: Data Movement Complexity for Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ding%2C+C">Chen Ding</a>, 
<a href="/search/eess?searchtype=author&query=Kanan%2C+C">Christopher Kanan</a>, 
<a href="/search/eess?searchtype=author&query=McKellips%2C+D">Dylan McKellips</a>, 
<a href="/search/eess?searchtype=author&query=Ozawa%2C+T">Toranosuke Ozawa</a>, 
<a href="/search/eess?searchtype=author&query=Shahmirza%2C+A">Arian Shahmirza</a>, 
<a href="/search/eess?searchtype=author&query=Smith%2C+W">Wesley Smith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The greatest demand for today's computing is machine learning. This paper
analyzes three machine learning algorithms: transformers, spatial convolution,
and FFT. The analysis is novel in three aspects. First, it measures the cost of
memory access on an abstract memory hierarchy, instead of traditional time or
space complexity. Second, the analysis is asymptotic and identifies the primary
sources of the memory cost. Finally, the result is symbolic, which can be used
to select algorithmic parameters such as the group size in grouped query
attention for any dimension size and number of heads and the batch size for
batched convolution for any image size and kernel size.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14446" title="Abstract">arXiv:2312.14446</a> [<a href="/pdf/2312.14446" title="Download PDF">pdf</a>, <a href="/format/2312.14446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Modal Object Tracking via Modality-Aware Fusion Network and A  Large-Scale Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Cheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenglong Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jin Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Peer Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual tracking often faces challenges such as invalid targets and decreased
performance in low-light conditions when relying solely on RGB image sequences.
While incorporating additional modalities like depth and infrared data has
proven effective, existing multi-modal imaging platforms are complex and lack
real-world applicability. In contrast, near-infrared (NIR) imaging, commonly
used in surveillance cameras, can switch between RGB and NIR based on light
intensity. However, tracking objects across these heterogeneous modalities
poses significant challenges, particularly due to the absence of modality
switch signals during tracking. To address these challenges, we propose an
adaptive cross-modal object tracking algorithm called Modality-Aware Fusion
Network (MAFNet). MAFNet efficiently integrates information from both RGB and
NIR modalities using an adaptive weighting mechanism, effectively bridging the
appearance gap and enabling a modality-aware target representation. It consists
of two key components: an adaptive weighting module and a modality-specific
representation module......
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14447" title="Abstract">arXiv:2312.14447</a> [<a href="/pdf/2312.14447" title="Download PDF">pdf</a>, <a href="/format/2312.14447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Effectiveness of Unlearning in Session-Based Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xin%2C+X">Xin Xin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Ziqi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+P">Pengjie Ren</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhumin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhaochun Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Session-based recommendation predicts users' future interests from previous
interactions in a session. Despite the memorizing of historical samples, the
request of unlearning, i.e., to remove the effect of certain training samples,
also occurs for reasons such as user privacy or model fidelity. However,
existing studies on unlearning are not tailored for the session-based
recommendation. On the one hand, these approaches cannot achieve satisfying
unlearning effects due to the collaborative correlations and sequential
connections between the unlearning item and the remaining items in the session.
On the other hand, seldom work has conducted the research to verify the
unlearning effectiveness in the session-based recommendation scenario. In this
paper, we propose SRU, a session-based recommendation unlearning framework,
which enables high unlearning efficiency, accurate recommendation performance,
and improved unlearning effectiveness in session-based recommendation.
Specifically, we first partition the training sessions into separate sub-models
according to the similarity across the sessions, then we utilize an
attention-based aggregation layer to fuse the hidden states according to the
correlations between the session and the centroid of the data in the sub-model.
To improve the unlearning effectiveness, we further propose three extra data
deletion strategies, including collaborative extra deletion (CED), neighbor
extra deletion (NED), and random extra deletion (RED). Besides, we propose an
evaluation metric that measures whether the unlearning sample can be inferred
after the data deletion to verify the unlearning effectiveness. We implement
SRU with three representative session-based recommendation models and conduct
experiments on three benchmark datasets. Experimental results demonstrate the
effectiveness of our methods.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14448" title="Abstract">arXiv:2312.14448</a> [<a href="/pdf/2312.14448" title="Download PDF">pdf</a>, <a href="/format/2312.14448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum-Assisted Joint Caching and Power Allocation for Integrated  Satellite-Terrestrial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yanmin Gong</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhu Han</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuanxiong Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Low earth orbit (LEO) satellite network can complement terrestrial networks
for achieving global wireless coverage and improving delay-sensitive Internet
services. This paper proposes an integrated satellite-terrestrial network
(ISTN) architecture to provide ground users with seamless and reliable content
delivery services. For optimal service provisioning in this architecture, we
formulate an optimization model to maximize the network throughput by jointly
optimizing content delivery policy, cache placement, and transmission power
allocation. The resulting optimization model is a large-scale mixed-integer
nonlinear program (MINLP) that is intractable for classical computer solvers.
Inspired by quantum computing techniques, we propose a hybrid quantum-classical
generalized Benders' decomposition (HQCGBD) algorithm to address this
challenge. Specifically, we first exploit the generalized Benders'
decomposition (GBD) to decompose the problem into a master problem and a
subproblem and then leverage the state-of-art quantum annealer to solve the
challenging master problem.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14452" title="Abstract">arXiv:2312.14452</a> [<a href="/pdf/2312.14452" title="Download PDF">pdf</a>, <a href="/format/2312.14452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Overcome Curse-of-Dimensionality for Out-of-Distribution  Detection?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghosal%2C+S+S">Soumya Suvra Ghosal</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yiyou Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yixuan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Machine learning models deployed in the wild can be challenged by
out-of-distribution (OOD) data from unknown classes. Recent advances in OOD
detection rely on distance measures to distinguish samples that are relatively
far away from the in-distribution (ID) data. Despite the promise,
distance-based methods can suffer from the curse-of-dimensionality problem,
which limits the efficacy in high-dimensional feature space. To combat this
problem, we propose a novel framework, Subspace Nearest Neighbor (SNN), for OOD
detection. In training, our method regularizes the model and its feature
representation by leveraging the most relevant subset of dimensions (i.e.
subspace). Subspace learning yields highly distinguishable distance measures
between ID and OOD data. We provide comprehensive experiments and ablations to
validate the efficacy of SNN. Compared to the current best distance-based
method, SNN reduces the average FPR95 by 15.96% on the CIFAR-100 benchmark.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14453" title="Abstract">arXiv:2312.14453</a> [<a href="/pdf/2312.14453" title="Download PDF">pdf</a>, <a href="/format/2312.14453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Aerodynamics-Based Model Predictive Control for a Tail-Sitter UAV
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bailun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Ching-Wei Chang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+C">Chih-Yung Wen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">It is challenging to model and control a tail-sitter unmanned aerial vehicle
(UAV) because its blended wing body generates complicated nonlinear aerodynamic
effects, such as wing lift, fuselage drag, and propeller-wing interactions. We
therefore devised a hybrid aerodynamic modeling method and model predictive
control (MPC) design for a quadrotor tail-sitter UAV. The hybrid model consists
of the Newton-Euler equation, which describes quadrotor dynamics, and a
feedforward neural network, which learns residual aerodynamic effects. This
hybrid model exhibits high predictive accuracy at a low computational cost and
was used to implement hybrid MPC, which optimizes the throttle, pitch angle,
and roll angle for position tracking. The controller performance was validated
in real-world experiments, which obtained a 57% tracking error reduction
compared with conventional nonlinear MPC. External wind disturbance was also
introduced and the experimental results confirmed the robustness of the
controller to these conditions.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14454" title="Abstract">arXiv:2312.14454</a> [<a href="/pdf/2312.14454" title="Download PDF">pdf</a>, <a href="/format/2312.14454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence of a conservative Crank-Nicolson finite difference scheme  for the KdV equation with smooth and non-smooth initial data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dwivedi%2C+M">Mukul Dwivedi</a>, 
<a href="/search/math?searchtype=author&query=Sarkar%2C+T">Tanmay Sarkar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we study the stability and convergence of a fully discrete
finite difference scheme for the initial value problem associated with the
Korteweg-De Vries (KdV) equation. We employ the Crank-Nicolson method for
temporal discretization and establish that the scheme is $L^2$-conservative.
The convergence analysis reveals that utilizing inherent Kato's local smoothing
effect, the proposed scheme converges to a classical solution for sufficiently
regular initial data $u_0 \in H^{3}(\mathbb{R})$ and to a weak solution in
$L^2(0,T;L^2_{\text{loc}}(\mathbb{R}))$ for non-smooth initial data $u_0 \in
L^2(\mathbb{R})$. Optimal convergence rates in both time and space for the
devised scheme are derived. The theoretical results are justified through
several numerical illustrations.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14457" title="Abstract">arXiv:2312.14457</a> [<a href="/pdf/2312.14457" title="Download PDF">pdf</a>, <a href="/format/2312.14457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QUAR-VLA: Vision-Language-Action Model for Quadruped Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+P">Pengxiang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Han Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhitao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhenyu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+S">Shangke Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Donglin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The important manifestation of robot intelligence is the ability to naturally
interact and autonomously make decisions. Traditional approaches to robot
control often compartmentalize perception, planning, and decision-making,
simplifying system design but limiting the synergy between different
information streams. This compartmentalization poses challenges in achieving
seamless autonomous reasoning, decision-making, and action execution. To
address these limitations, a novel paradigm, named Vision-Language-Action tasks
for QUAdruped Robots (QUAR-VLA), has been introduced in this paper. This
approach tightly integrates visual information and instructions to generate
executable actions, effectively merging perception, planning, and
decision-making. The central idea is to elevate the overall intelligence of the
robot. Within this framework, a notable challenge lies in aligning fine-grained
instructions with visual perception information. This emphasizes the complexity
involved in ensuring that the robot accurately interprets and acts upon
detailed instructions in harmony with its visual observations. Consequently, we
propose QUAdruped Robotic Transformer (QUART), a family of VLA models to
integrate visual information and instructions from diverse modalities as input
and generates executable actions for real-world robots and present QUAdruped
Robot Dataset (QUARD), a large-scale multi-task dataset including navigation,
complex terrain locomotion, and whole-body manipulation tasks for training
QUART models. Our extensive evaluation (4000 evaluation trials) shows that our
approach leads to performant robotic policies and enables QUART to obtain a
range of emergent capabilities.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14458" title="Abstract">arXiv:2312.14458</a> [<a href="/pdf/2312.14458" title="Download PDF">pdf</a>, <a href="/format/2312.14458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiagent Copilot Approach for Shared Autonomy between Human EEG and  TD3 Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phang%2C+C">Chun-Ren Phang</a>, 
<a href="/search/cs?searchtype=author&query=Hirata%2C+A">Akimasa Hirata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Deep reinforcement learning (RL) algorithms enable the development of fully
autonomous agents that can interact with the environment. Brain-computer
interface (BCI) systems decipher human implicit brain signals regardless of the
explicit environment. In this study, we integrated deep RL and BCI to improve
beneficial human interventions in autonomous systems and the performance in
decoding brain activities by considering environmental factors. Shared autonomy
was allowed between the action command decoded from the electroencephalography
(EEG) of the human agent and the action generated from the twin delayed DDPG
(TD3) agent for a given environment. Our proposed copilot control scheme with a
full blocker (Co-FB) significantly outperformed the individual EEG (EEG-NB) or
TD3 control. The Co-FB model achieved a higher target approaching score, lower
failure rate, and lower human workload than the EEG-NB model. The Co-FB control
scheme had a higher invisible target score and level of allowed human
intervention than the TD3 model. We also proposed a disparity d-index to
evaluate the effect of contradicting agent decisions on the control accuracy
and authority of the copilot model. We found a significant correlation between
the control authority of the TD3 agent and the performance improvement of human
EEG classification with respect to the d-index. We also observed that shifting
control authority to the TD3 agent improved performance when BCI decoding was
not optimal. These findings indicate that the copilot system can effectively
handle complex environments and that BCI performance can be improved by
considering environmental factors. Future work should employ continuous action
space and different multi-agent approaches to evaluate copilot performance.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14460" title="Abstract">arXiv:2312.14460</a> [<a href="/pdf/2312.14460" title="Download PDF">pdf</a>, <a href="/format/2312.14460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum computing with error mitigation for data-driven computational  mechanics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuang%2C+Z">Zengtao Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yongchun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kihal%2C+C+E">Chafik El Kihal</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Heng Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">As a crossover frontier of physics and mechanics, quantum computing is
showing its great potential in computational mechanics. However, quantum
hardware noise remains a critical barrier to achieving accurate simulation
results due to the limitation of the current hardware level. In this paper, we
integrate error-mitigated quantum computing in data-driven computational
mechanics, where the zero-noise extrapolation (ZNE) technique is employed to
improve the accuracy of quantum computing. Numerical examples including
multiscale simulation of a composite L-shaped beam are conducted with the
quantum computer simulator Qpanda, and the results validate the effectiveness
of the proposed method. We believe this work presents a promising step towards
using the power of quantum computing in computational mechanics.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14461" title="Abstract">arXiv:2312.14461</a> [<a href="/pdf/2312.14461" title="Download PDF">pdf</a>, <a href="/format/2312.14461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attacking Byzantine Robust Aggregation in High Dimensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choudhary%2C+S">Sarthak Choudhary</a>, 
<a href="/search/cs?searchtype=author&query=Kolluri%2C+A">Aashish Kolluri</a>, 
<a href="/search/cs?searchtype=author&query=Saxena%2C+P">Prateek Saxena</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Training modern neural networks or models typically requires averaging over a
sample of high-dimensional vectors. Poisoning attacks can skew or bias the
average vectors used to train the model, forcing the model to learn specific
patterns or avoid learning anything useful. Byzantine robust aggregation is a
principled algorithmic defense against such biasing. Robust aggregators can
bound the maximum bias in computing centrality statistics, such as mean, even
when some fraction of inputs are arbitrarily corrupted. Designing such
aggregators is challenging when dealing with high dimensions. However, the
first polynomial-time algorithms with strong theoretical bounds on the bias
have recently been proposed. Their bounds are independent of the number of
dimensions, promising a conceptual limit on the power of poisoning attacks in
their ongoing arms race against defenses.
<br />In this paper, we show a new attack called HIDRA on practical realization of
strong defenses which subverts their claim of dimension-independent bias. HIDRA
highlights a novel computational bottleneck that has not been a concern of
prior information-theoretic analysis. Our experimental evaluation shows that
our attacks almost completely destroy the model performance, whereas existing
attacks with the same goal fail to have much effect. Our findings leave the
arms race between poisoning attacks and provable defenses wide open.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14463" title="Abstract">arXiv:2312.14463</a> [<a href="/pdf/2312.14463" title="Download PDF">pdf</a>, <a href="/format/2312.14463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Programming-based Approximate Optimal Control for Model-Based  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mallick%2C+P">Prakash Mallick</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Z">Zhiyong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 Pages, 6 figures. arXiv admin note: text overlap with <a href="/abs/2010.00207">arXiv:2010.00207</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This article proposes an improved trajectory optimization approach for
stochastic optimal control of dynamical systems affected by measurement noise
by combining optimal control with maximum likelihood techniques to improve the
reduction of the cumulative cost-to-go. A modified optimization objective
function that incorporates dynamic programming-based controller design is
presented to handle the noise in the system and sensors. Empirical results
demonstrate the effectiveness of the approach in reducing stochasticity and
allowing for an intermediate step to switch optimization that can allow an
efficient balance of exploration and exploitation mechanism for complex tasks
by constraining policy parameters to parameters obtained as a result of this
improved optimization. This research study also includes theoretical work on
the uniqueness of control parameter estimates and also leverages a structure of
the likelihood function which has an established theoretical guarantees.
Furthermore, a theoretical result is also explored that bridge the gap between
the proposed optimization objective function and existing information theory
(relative entropy) and optimal control dualities.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14464" title="Abstract">arXiv:2312.14464</a> [<a href="/pdf/2312.14464" title="Download PDF">pdf</a>, <a href="/ps/2312.14464" title="Download PostScript">ps</a>, <a href="/format/2312.14464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Differential Evolution with Diversification: Addressing  Optimization Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maitra%2C+S">Sarit Maitra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Performance (cs.PF)

</div>
<p class="mathjax">The existing variants of the Differential Evolution (DE) algorithm come with
certain limitations, such as poor local search and susceptibility to premature
convergence. This study introduces Adaptive Differential Evolution with
Diversification (ADED), a method that dynamically modifies the neighborhood
structure by evaluating the trial solutions' fitness. Developed to work with
both convex and nonconvex objective functions, ADED is validated with 22
benchmark functions, including Rosenbrock, Rastrigin, Ackley, and
DeVilliers-Glasser02. The development is carried out in Google Cloud using
Jupyter Notebook and Python v3.10.12, with additional testing conducted on the
multi-objective benchmark ZDT test suite. ADED distinguishes itself with its
adaptive and diverse approach, which includes adaptive mutation and
crossover-rates, diverse mutation tactics, diversification measurements, local
search mechanisms, and convergence monitoring. The unique combination of these
features collectively enhances ADED's effectiveness in navigating complex and
diverse landscapes, positioning it as a promising tool for addressing
challenges in both single- and multi-objective optimization scenarios.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14465" title="Abstract">arXiv:2312.14465</a> [<a href="/pdf/2312.14465" title="Download PDF">pdf</a>, <a href="/format/2312.14465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FM-OV3D: Foundation Model-based Cross-modal Knowledge Blending for  Open-Vocabulary 3D Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ray Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shenghao Xie</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+W">Wei Xue</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaodong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanghang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024. Code will be released at <a href="https://github.com/dmzhang0425/FM-OV3D.git">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The superior performances of pre-trained foundation models in various visual
tasks underscore their potential to enhance the 2D models' open-vocabulary
ability. Existing methods explore analogous applications in the 3D space.
However, most of them only center around knowledge extraction from singular
foundation models, which limits the open-vocabulary ability of 3D models. We
hypothesize that leveraging complementary pre-trained knowledge from various
foundation models can improve knowledge transfer from 2D pre-trained visual
language models to the 3D space. In this work, we propose FM-OV3D, a method of
Foundation Model-based Cross-modal Knowledge Blending for Open-Vocabulary 3D
Detection, which improves the open-vocabulary localization and recognition
abilities of 3D model by blending knowledge from multiple pre-trained
foundation models, achieving true open-vocabulary without facing constraints
from original 3D datasets. Specifically, to learn the open-vocabulary 3D
localization ability, we adopt the open-vocabulary localization knowledge of
the Grounded-Segment-Anything model. For open-vocabulary 3D recognition
ability, We leverage the knowledge of generative foundation models, including
GPT-3 and Stable Diffusion models, and cross-modal discriminative models like
CLIP. The experimental results on two popular benchmarks for open-vocabulary 3D
object detection show that our model efficiently learns knowledge from multiple
foundation models to enhance the open-vocabulary ability of the 3D model and
successfully achieves state-of-the-art performance in open-vocabulary 3D object
detection tasks. Code is released at
https://github.com/dmzhang0425/FM-OV3D.git.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14466" title="Abstract">arXiv:2312.14466</a> [<a href="/pdf/2312.14466" title="Download PDF">pdf</a>, <a href="/format/2312.14466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Assessing Compliant Robotic Grasping from First-Object  Perspective via Instrumented Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Knopke%2C+M">Maceon Knopke</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Liguo Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Corke%2C+P">Peter Corke</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fangyi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Grasping compliant objects is difficult for robots -- applying too little
force may cause the grasp to fail, while too much force may lead to object
damage. A robot needs to apply the right amount of force to quickly and
confidently grasp the objects so that it can perform the required task.
Although some methods have been proposed to tackle this issue, performance
assessment is still a problem for directly measuring object property changes
and possible damage. To fill the gap, a new concept is introduced in this paper
to assess compliant robotic grasping using instrumented objects. A
proof-of-concept design is proposed to measure the force applied on a cuboid
object from a first-object perspective. The design can detect multiple contact
locations and applied forces on its surface by using multiple embedded 3D Hall
sensors to detect deformation relative to embedded magnets. The contact
estimation is achieved by interpreting the Hall-effect signals using neural
networks. In comprehensive experiments, the design achieved good performance in
estimating contacts from each single face of the cuboid and decent performance
in detecting contacts from multiple faces when being used to evaluate grasping
from a parallel jaw gripper, demonstrating the effectiveness of the design and
the feasibility of the concept.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14470" title="Abstract">arXiv:2312.14470</a> [<a href="/pdf/2312.14470" title="Download PDF">pdf</a>, <a href="/format/2312.14470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Reinforcement Learning with Instantaneous Constraints: The Role of  Aggressive Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Honghao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+L">Lei Ying</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper studies safe Reinforcement Learning (safe RL) with linear function
approximation and under hard instantaneous constraints where unsafe actions
must be avoided at each step. Existing studies have considered safe RL with
hard instantaneous constraints, but their approaches rely on several key
assumptions: $(i)$ the RL agent knows a safe action set for {\it every} state
or knows a {\it safe graph} in which all the state-action-state triples are
safe, and $(ii)$ the constraint/cost functions are {\it linear}. In this paper,
we consider safe RL with instantaneous hard constraints without assumption
$(i)$ and generalize $(ii)$ to Reproducing Kernel Hilbert Space (RKHS). Our
proposed algorithm, LSVI-AE, achieves $\tilde{\cO}(\sqrt{d^3H^4K})$ regret and
$\tilde{\cO}(H \sqrt{dK})$ hard constraint violation when the cost function is
linear and $\cO(H\gamma_K \sqrt{K})$ hard constraint violation when the cost
function belongs to RKHS. Here $K$ is the learning horizon, $H$ is the length
of each episode, and $\gamma_K$ is the information gain w.r.t the kernel used
to approximate cost functions. Our results achieve the optimal dependency on
the learning horizon $K$, matching the lower bound we provide in this paper and
demonstrating the efficiency of LSVI-AE. Notably, the design of our approach
encourages aggressive policy exploration, providing a unique perspective on
safe RL with general cost functions and no prior knowledge of safe actions,
which may be of independent interest.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14471" title="Abstract">arXiv:2312.14471</a> [<a href="/pdf/2312.14471" title="Download PDF">pdf</a>, <a href="/format/2312.14471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prototype-based Cross-Modal Object Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenglong Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Futian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Longfeng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jin Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Peer Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Cross-modal object tracking is an important research topic in the field of
information fusion, and it aims to address imaging limitations in challenging
scenarios by integrating switchable visible and near-infrared modalities.
However, existing tracking methods face some difficulties in adapting to
significant target appearance variations in the presence of modality switch.
For instance, model update based tracking methods struggle to maintain stable
tracking results during modality switching, leading to error accumulation and
model drift. Template based tracking methods solely rely on the template
information from first frame and/or last frame, which lacks sufficient
representation ability and poses challenges in handling significant target
appearance changes. To address this problem, we propose a prototype-based
cross-modal object tracker called ProtoTrack, which introduces a novel
prototype learning scheme to adapt to significant target appearance variations,
for cross-modal object tracking. In particular, we design a multi-modal
prototype to represent target information by multi-kind samples, including a
fixed sample from the first frame and two representative samples from different
modalities. Moreover, we develop a prototype generation algorithm based on two
new modules to ensure the prototype representative in different
challenges......
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14472" title="Abstract">arXiv:2312.14472</a> [<a href="/pdf/2312.14472" title="Download PDF">pdf</a>, <a href="/format/2312.14472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Not All Tasks Are Equally Difficult: Multi-Task Reinforcement Learning  with Dynamic Depth Routing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jinmin He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kai Li</a>, 
<a href="/search/cs?searchtype=author&query=Zang%2C+Y">Yifan Zang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Haobo Fu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Q">Qiang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+J">Junliang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jian Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024, with supplementary material
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 38th AAAI Conference on Artificial Intelligence (AAAI2024),
  Vancouver, BC, Canada, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Multi-task reinforcement learning endeavors to accomplish a set of different
tasks with a single policy. To enhance data efficiency by sharing parameters
across multiple tasks, a common practice segments the network into distinct
modules and trains a routing network to recombine these modules into
task-specific policies. However, existing routing approaches employ a fixed
number of modules for all tasks, neglecting that tasks with varying
difficulties commonly require varying amounts of knowledge. This work presents
a Dynamic Depth Routing (D2R) framework, which learns strategic skipping of
certain intermediate modules, thereby flexibly choosing different numbers of
modules for each task. Under this framework, we further introduce a ResRouting
method to address the issue of disparate routing paths between behavior and
target policies during off-policy training. In addition, we design an automatic
route-balancing mechanism to encourage continued routing exploration for
unmastered tasks without disturbing the routing of mastered ones. We conduct
extensive experiments on various robotics manipulation tasks in the Meta-World
benchmark, where D2R achieves state-of-the-art performance with significantly
improved learning efficiency.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14474" title="Abstract">arXiv:2312.14474</a> [<a href="/pdf/2312.14474" title="Download PDF">pdf</a>, <a href="/format/2312.14474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MonoLSS: Learnable Sample Selection For Monocular 3D Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenjia Li</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jinrang Jia</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yifeng Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">In the field of autonomous driving, monocular 3D detection is a critical task
which estimates 3D properties (depth, dimension, and orientation) of objects in
a single RGB image. Previous works have used features in a heuristic way to
learn 3D properties, without considering that inappropriate features could have
adverse effects. In this paper, sample selection is introduced that only
suitable samples should be trained to regress the 3D properties. To select
samples adaptively, we propose a Learnable Sample Selection (LSS) module, which
is based on Gumbel-Softmax and a relative-distance sample divider. The LSS
module works under a warm-up strategy leading to an improvement in training
stability. Additionally, since the LSS module dedicated to 3D property sample
selection relies on object-level features, we further develop a data
augmentation method named MixUp3D to enrich 3D property samples which conforms
to imaging principles without introducing ambiguity. As two orthogonal methods,
the LSS module and MixUp3D can be utilized independently or in conjunction.
Sufficient experiments have shown that their combined use can lead to
synergistic effects, yielding improvements that transcend the mere sum of their
individual applications. Leveraging the LSS module and the MixUp3D, without any
extra data, our method named MonoLSS ranks 1st in all three categories (Car,
Cyclist, and Pedestrian) on KITTI 3D object detection benchmark, and achieves
competitive results on both the Waymo dataset and KITTI-nuScenes cross-dataset
evaluation. The code is included in the supplementary material and will be
released to facilitate related academic and industrial studies.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14478" title="Abstract">arXiv:2312.14478</a> [<a href="/pdf/2312.14478" title="Download PDF">pdf</a>, <a href="/format/2312.14478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning via Input-Output Collaborative Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+X">Xuan Gong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shanglin Li</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+Y">Yuxiang Bao</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+B">Barry Yao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yawen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Ziyan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Baochang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yefeng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Doermann%2C+D">David Doermann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Federated learning (FL) is a machine learning paradigm in which distributed
local nodes collaboratively train a central model without sharing individually
held private data. Existing FL methods either iteratively share local model
parameters or deploy co-distillation. However, the former is highly susceptible
to private data leakage, and the latter design relies on the prerequisites of
task-relevant real data. Instead, we propose a data-free FL framework based on
local-to-central collaborative distillation with direct input and output space
exploitation. Our design eliminates any requirement of recursive local
parameter exchange or auxiliary task-relevant data to transfer knowledge,
thereby giving direct privacy control to local users. In particular, to cope
with the inherent data heterogeneity across locals, our technique learns to
distill input on which each local model produces consensual yet unique results
to represent each expertise. Our proposed FL framework achieves notable
privacy-utility trade-offs with extensive experiments on image classification
and segmentation tasks under various real-world heterogeneous federated
learning settings on both natural and medical images.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14479" title="Abstract">arXiv:2312.14479</a> [<a href="/pdf/2312.14479" title="Download PDF">pdf</a>, <a href="/format/2312.14479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating the Concurrency Landscape: A Survey of Race Condition  Vulnerability Detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Upadhyay%2C+A">Aishwarya Upadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Laxmi%2C+V">Vijay Laxmi</a>, 
<a href="/search/cs?searchtype=author&query=Naval%2C+S">Smita Naval</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">As technology continues to advance and we usher in the era of Industry 5.0,
there has been a profound paradigm shift in operating systems, file systems,
web, and network applications. The conventional utilization of multiprocessing
and multicore systems has made concurrent programming increasingly pervasive.
However, this transformation has brought about a new set of issues known as
concurrency bugs, which, due to their wide prevalence in concurrent programs,
have led to severe failures and potential security exploits. Over the past two
decades, numerous researchers have dedicated their efforts to unveiling,
detecting, mitigating, and preventing these bugs, with the last decade
witnessing a surge in research within this domain. Among the spectrum of
concurrency bugs, data races or race condition vulnerabilities stand out as the
most prevalent, accounting for a staggering 80\% of all concurrency bugs. This
survey paper is focused on the realm of race condition bug detectors. We
systematically categorize these detectors based on the diverse methodologies
they employ. Additionally, we delve into the techniques and algorithms
associated with race detection, tracing the evolution of this field over time.
Furthermore, we shed light on the application of fuzzing techniques in the
detection of race condition vulnerabilities. By reviewing these detectors and
their static analyses, we draw conclusions and outline potential future
research directions, including enhancing accuracy, performance, applicability,
and comprehensiveness in race condition vulnerability detection.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14480" title="Abstract">arXiv:2312.14480</a> [<a href="/pdf/2312.14480" title="Download PDF">pdf</a>, <a href="/format/2312.14480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MetaAID 2.5: A Secure Framework for Developing Metaverse Applications  via Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hongyin Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY)

</div>
<p class="mathjax">Large language models (LLMs) are increasingly being used in Metaverse
environments to generate dynamic and realistic content and to control the
behavior of non-player characters (NPCs). However, the cybersecurity concerns
associated with LLMs have become increasingly prominent. Previous research has
primarily focused on patching system vulnerabilities to enhance cybersecurity,
but these approaches are not well-suited to the Metaverse, where the virtual
space is more complex, LLMs are vulnerable, and ethical user interaction is
critical. Moreover, the scope of cybersecurity in the Metaverse is expected to
expand significantly. This paper proposes a method for enhancing cybersecurity
through the simulation of user interaction with LLMs. Our goal is to educate
users and strengthen their defense capabilities through exposure to a
comprehensive simulation system. This system includes extensive Metaverse
cybersecurity Q&amp;A and attack simulation scenarios. By engaging with these,
users will improve their ability to recognize and withstand risks.
Additionally, to address the ethical implications of user input, we propose
using LLMs as evaluators to assess user content across five dimensions. We
further adapt the models through vocabulary expansion training to better
understand personalized inputs and emoticons. We conduct experiments on
multiple LLMs and find that our approach is effective.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14481" title="Abstract">arXiv:2312.14481</a> [<a href="/pdf/2312.14481" title="Download PDF">pdf</a>, <a href="/format/2312.14481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Part to Whole: Collaborative Prompting for Surgical Instrument  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+W">Wenxi Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+K">Kun Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qiuxia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Z">Zongyuan Ge</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yong Xia</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiebo Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiyong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report. The source code will be released at <a href="https://github.com/wenxi-yue/SurgicalPart-SAM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Foundation models like the Segment Anything Model (SAM) have demonstrated
promise in generic object segmentation. However, directly applying SAM to
surgical instrument segmentation presents key challenges. First, SAM relies on
per-frame point-or-box prompts which complicate surgeon-computer interaction.
Also, SAM yields suboptimal performance on segmenting surgical instruments,
owing to insufficient surgical data in its pre-training as well as the complex
structure and fine-grained details of various surgical instruments. To address
these challenges, in this paper, we investigate text promptable surgical
instrument segmentation and propose SP-SAM (SurgicalPart-SAM), a novel
efficient-tuning approach that integrates surgical instrument structure
knowledge with the generic segmentation knowledge of SAM. Specifically, we
achieve this by proposing (1) collaborative prompts in the text form "[part
name] of [instrument category name]" that decompose instruments into
fine-grained parts; (2) a Cross-Modal Prompt Encoder that encodes text prompts
jointly with visual embeddings into discriminative part-level representations;
and (3) a Part-to-Whole Selective Fusion and a Hierarchical Decoding strategy
that selectively assemble the part-level representations into a whole for
accurate instrument segmentation. Built upon them, SP-SAM acquires a better
capability to comprehend surgical instrument structures and distinguish between
various categories. Extensive experiments on both the EndoVis2018 and
EndoVis2017 datasets demonstrate SP-SAM's state-of-the-art performance with
minimal tunable parameters. Code is at
https://github.com/wenxi-yue/SurgicalPart-SAM.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14483" title="Abstract">arXiv:2312.14483</a> [<a href="/pdf/2312.14483" title="Download PDF">pdf</a>, <a href="/ps/2312.14483" title="Download PostScript">ps</a>, <a href="/format/2312.14483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the accurate computation of the Newton form of the Lagrange  interpolant
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Khiar%2C+Y">Yasmina Khiar</a>, 
<a href="/search/math?searchtype=author&query=Mainar%2C+E">Esmeralda Mainar</a>, 
<a href="/search/math?searchtype=author&query=Royo-Amondarain%2C+E">Eduardo Royo-Amondarain</a>, 
<a href="/search/math?searchtype=author&query=Rubio%2C+B">Beatriz Rubio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In recent years many efforts have been devoted to finding bidiagonal
factorizations of nonsingular totally positive matrices, since their accurate
computation allows to numerically solve several important algebraic problems
with great precision, even for large ill-conditioned matrices. In this
framework, the present work provides the factorization of the collocation
matrices of Newton bases -- of relevance when considering the Lagrange
interpolation problem -- together with an algorithm that allows to numerically
compute it to high relative accuracy. This further allows to determine the
coefficients of the interpolating polynomial and to compute the singular values
and the inverse of the collocation matrix. Conditions that guarantee high
relative accuracy for these methods and, in the former case, for the classical
recursion formula of divided differences, are determined. Numerical errors due
to imprecise computer arithmetic or perturbed input data in the computation of
the factorization are analyzed. Finally, numerical experiments illustrate the
accuracy and effectiveness of the proposed methods with several algebraic
problems, in stark contrast with traditional approaches.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14487" title="Abstract">arXiv:2312.14487</a> [<a href="/pdf/2312.14487" title="Download PDF">pdf</a>, <a href="/format/2312.14487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic-based Loco-Manipulation for Human-Robot Collaboration in  Industrial Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rollo%2C+F">Federico Rollo</a>, 
<a href="/search/cs?searchtype=author&query=Raiola%2C+G">Gennaro Raiola</a>, 
<a href="/search/cs?searchtype=author&query=Tsagarakis%2C+N">Nikolaos Tsagarakis</a>, 
<a href="/search/cs?searchtype=author&query=Roveri%2C+M">Marco Roveri</a>, 
<a href="/search/cs?searchtype=author&query=Hoffman%2C+E+M">Enrico Mingo Hoffman</a>, 
<a href="/search/cs?searchtype=author&query=Ajoudani%2C+A">Arash Ajoudani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the European Robotic Forum (ERF) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robots with a high level of autonomy are increasingly requested by smart
industries. A way to reduce the workers' stress and effort is to optimize the
working environment by taking advantage of autonomous collaborative robots. A
typical task for Human-Robot Collaboration (HRC) which improves the working
setup in an industrial environment is the \textit{"bring me an object please"}
where the user asks the collaborator to search for an object while he/she is
focused on something else. As often happens, science fiction is ahead of the
times, indeed, in the \textit{Iron Man} movie, the robot \textit{Dum-E} helps
its creator, \textit{Tony Stark}, to create its famous armours. The ability of
the robot to comprehend the semantics of the environment and engage with it is
valuable for the human execution of more intricate tasks. In this work, we
reproduce this operation to enable a mobile robot with manipulation and
grasping capabilities to leverage its geometric and semantic understanding of
the environment for the execution of the \textit{Bring Me} action, thereby
assisting a worker autonomously. Results are provided to validate the proposed
workflow in a simulated environment populated with objects and people. This
framework aims to take a step forward in assistive robotics autonomy for
industries and domestic environments.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14488" title="Abstract">arXiv:2312.14488</a> [<a href="/pdf/2312.14488" title="Download PDF">pdf</a>, <a href="/format/2312.14488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Model is a Branch Predictor for Simultaneous Machine  Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+A">Aoxiong Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+T">Tianyun Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Siliang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhou Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The primary objective of simultaneous machine translation (SiMT) is to
minimize latency while preserving the quality of the final translation. Drawing
inspiration from CPU branch prediction techniques, we propose incorporating
branch prediction techniques in SiMT tasks to reduce translation latency.
Specifically, we utilize a language model as a branch predictor to predict
potential branch directions, namely, future source words. Subsequently, we
utilize the predicted source words to decode the output in advance. When the
actual source word deviates from the predicted source word, we use the real
source word to decode the output again, replacing the predicted output. To
further reduce computational costs, we share the parameters of the encoder and
the branch predictor, and utilize a pre-trained language model for
initialization. Our proposed method can be seamlessly integrated with any SiMT
model. Extensive experimental results demonstrate that our approach can improve
translation quality and latency at the same time. Our code is available at
https://github.com/YinAoXiong/simt_branch_predictor .
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14492" title="Abstract">arXiv:2312.14492</a> [<a href="/pdf/2312.14492" title="Download PDF">pdf</a>, <a href="/format/2312.14492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context Enhanced Transformer for Single Image Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+S">Seungjun An</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Seonghoon Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+G">Gyeongnyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Baek%2C+J">Jeongyeol Baek</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B">Byeongwon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungryong Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The project page and code will be made available at: <a href="https://ku-cvlab.github.io/CETR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the increasing importance of video data in real-world applications,
there is a rising need for efficient object detection methods that utilize
temporal information. While existing video object detection (VOD) techniques
employ various strategies to address this challenge, they typically depend on
locally adjacent frames or randomly sampled images within a clip. Although
recent Transformer-based VOD methods have shown promising results, their
reliance on multiple inputs and additional network complexity to incorporate
temporal information limits their practical applicability. In this paper, we
propose a novel approach to single image object detection, called Context
Enhanced TRansformer (CETR), by incorporating temporal context into DETR using
a newly designed memory module. To efficiently store temporal information, we
construct a class-wise memory that collects contextual information across data.
Additionally, we present a classification-based sampling technique to
selectively utilize the relevant memory for the current image. In the testing,
We introduce a test-time memory adaptation method that updates individual
memory functions by considering the test distribution. Experiments with CityCam
and ImageNet VID datasets exhibit the efficiency of the framework on various
video systems. The project page and code will be made available at:
https://ku-cvlab.github.io/CETR.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14494" title="Abstract">arXiv:2312.14494</a> [<a href="/pdf/2312.14494" title="Download PDF">pdf</a>, <a href="/format/2312.14494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Few-Shot Object Detection with Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madan%2C+A">Anish Madan</a>, 
<a href="/search/cs?searchtype=author&query=Peri%2C+N">Neehar Peri</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+S">Shu Kong</a>, 
<a href="/search/cs?searchtype=author&query=Ramanan%2C+D">Deva Ramanan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Few-shot object detection (FSOD) benchmarks have advanced techniques for
detecting new categories with limited annotations. Existing benchmarks
repurpose well-established datasets like COCO by partitioning categories into
base and novel classes for pre-training and fine-tuning respectively. However,
these benchmarks do not reflect how FSOD is deployed in practice. Rather than
only pre-training on a small number of base categories, we argue that it is
more practical to fine-tune a foundation model (e.g., a vision-language model
(VLM) pre-trained on web-scale data) for a target domain. Surprisingly, we find
that zero-shot inference from VLMs like GroundingDINO significantly outperforms
the state-of-the-art (48.3 vs. 33.1 AP) on COCO. However, such zero-shot models
can still be misaligned to target concepts of interest. For example, trailers
on the web may be different from trailers in the context of autonomous
vehicles. In this work, we propose Foundational FSOD, a new benchmark protocol
that evaluates detectors pre-trained on any external datasets and fine-tuned on
K-shots per target class. Further, we note that current FSOD benchmarks are
actually federated datasets containing exhaustive annotations for each category
on a subset of the data. We leverage this insight to propose simple strategies
for fine-tuning VLMs with federated losses. We demonstrate the effectiveness of
our approach on LVIS and nuImages, improving over prior work by 5.9 AP.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14495" title="Abstract">arXiv:2312.14495</a> [<a href="/pdf/2312.14495" title="Download PDF">pdf</a>, <a href="/format/2312.14495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beam Foreseeing in Millimeter-Wave Systems with Situational Awareness:  Fundamental Limits via Cram&#xe9;r-Rao Lower Bound
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shih%2C+W">Wan-Ting Shih</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+C">Chao-Kai Wen</a>, 
<a href="/search/cs?searchtype=author&query=Shang-Ho">Shang-Ho</a> (Lawrence)
<a href="/search/cs?searchtype=author&query=Tsai">Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Yuen%2C+C">Chau Yuen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 figures; IEEE Transactions on Wireless Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Millimeter-wave (mmWave) networks offer the potential for high-speed data
transfer and precise localization, leveraging large antenna arrays and
extensive bandwidths. However, these networks are challenged by significant
path loss and susceptibility to blockages. In this study, we delve into the use
of situational awareness for beam prediction within the 5G NR beam management
framework. We introduce an analytical framework based on the Cram\'{e}r-Rao
Lower Bound, enabling the quantification of 6D position-related information of
geometric reflectors. This includes both 3D locations and 3D orientation
biases, facilitating accurate determinations of the beamforming gain achievable
by each reflector or candidate beam. This framework empowers us to predict beam
alignment performance at any given location in the environment, ensuring
uninterrupted wireless access. Our analysis offers critical insights for
choosing the most effective beam and antenna module strategies, particularly in
scenarios where communication stability is threatened by blockages. Simulation
results show that our approach closely approximates the performance of an
ideal, Oracle-based solution within the existing 5G NR beam management system.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14499" title="Abstract">arXiv:2312.14499</a> [<a href="/pdf/2312.14499" title="Download PDF">pdf</a>, <a href="/format/2312.14499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hutchinson Trace Estimation for High-Dimensional and High-Order  Physics-Informed Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zheyuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zekun Shi</a>, 
<a href="/search/cs?searchtype=author&query=Karniadakis%2C+G+E">George Em Karniadakis</a>, 
<a href="/search/cs?searchtype=author&query=Kawaguchi%2C+K">Kenji Kawaguchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Dynamical Systems (math.DS); Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
<p class="mathjax">Physics-Informed Neural Networks (PINNs) have proven effective in solving
partial differential equations (PDEs), especially when some data are available
by blending seamlessly data and physics. However, extending PINNs to
high-dimensional and even high-order PDEs encounters significant challenges due
to the computational cost associated with automatic differentiation in the
residual loss. Herein, we address the limitations of PINNs in handling
high-dimensional and high-order PDEs by introducing Hutchinson Trace Estimation
(HTE). Starting with the second-order high-dimensional PDEs ubiquitous in
scientific computing, HTE transforms the calculation of the entire Hessian
matrix into a Hessian vector product (HVP). This approach alleviates the
computational bottleneck via Taylor-mode automatic differentiation and
significantly reduces memory consumption from the Hessian matrix to HVP. We
further showcase HTE's convergence to the original PINN loss and its unbiased
behavior under specific conditions. Comparisons with Stochastic Dimension
Gradient Descent (SDGD) highlight the distinct advantages of HTE, particularly
in scenarios with significant variance among dimensions. We further extend HTE
to higher-order and higher-dimensional PDEs, specifically addressing the
biharmonic equation. By employing tensor-vector products (TVP), HTE efficiently
computes the colossal tensor associated with the fourth-order high-dimensional
biharmonic equation, saving memory and enabling rapid computation. The
effectiveness of HTE is illustrated through experimental setups, demonstrating
comparable convergence rates with SDGD under memory and speed constraints.
Additionally, HTE proves valuable in accelerating the Gradient-Enhanced PINN
(gPINN) version as well as the Biharmonic equation. Overall, HTE opens up a new
capability in scientific machine learning for tackling high-order and
high-dimensional PDEs.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14502" title="Abstract">arXiv:2312.14502</a> [<a href="/pdf/2312.14502" title="Download PDF">pdf</a>, <a href="/format/2312.14502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViStripformer: A Token-Efficient Transformer for Versatile Video  Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsai%2C+F">Fu-Jen Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yan-Tsung Peng</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Chen-Yu Chang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chan-Yu Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yen-Yu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+C">Chung-Chi Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chia-Wen Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video restoration is a low-level vision task that seeks to restore clean,
sharp videos from quality-degraded frames. One would use the temporal
information from adjacent frames to make video restoration successful.
Recently, the success of the Transformer has raised awareness in the
computer-vision community. However, its self-attention mechanism requires much
memory, which is unsuitable for high-resolution vision tasks like video
restoration. In this paper, we propose ViStripformer (Video Stripformer), which
utilizes spatio-temporal strip attention to catch long-range data correlations,
consisting of intra-frame strip attention (Intra-SA) and inter-frame strip
attention (Inter-SA) for extracting spatial and temporal information. It
decomposes video frames into strip-shaped features in horizontal and vertical
directions for Intra-SA and Inter-SA to address degradation patterns with
various orientations and magnitudes. Besides, ViStripformer is an effective and
efficient transformer architecture with much lower memory usage than the
vanilla transformer. Extensive experiments show that the proposed model
achieves superior results with fast inference time on video restoration tasks,
including video deblurring, demoireing, and deraining.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14503" title="Abstract">arXiv:2312.14503</a> [<a href="/pdf/2312.14503" title="Download PDF">pdf</a>, <a href="/format/2312.14503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The influence of parasitic modes on &quot;weakly&#x27;&#x27; unstable multi-step Finite  Difference schemes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bellotti%2C+T">Thomas Bellotti</a> (IRMA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Numerical analysis for linear constant-coefficients Finite Difference schemes
was developed approximately fifty years ago. It relies on the assumption of
scheme stability and in particular -- for the $L^2$ setting -- on the absence
of multiple roots of the amplification polynomial on the unit circle. This
allows to decouple, while discussing the convergence of the method, the study
of the consistency of the scheme from the precise knowledge of its
parasitic/spurious modes, so that multi-step methods can be studied essentially
as they were one-step schemes. In other words, the global truncation error can
be inferred from the local truncation error. Furthermore, stability alleviates
the need to delve into the complexities of floating-point arithmetic on
computers, which can be challenging topics to address. In this paper, we show
that in the case of ``weakly'' unstable schemes with multiple roots on the unit
circle, although the schemes may remain stable, the consideration of parasitic
modes is essential in studying their consistency and, consequently, their
convergence. Otherwise said, the lack of genuine stability prevents bounding
the global truncation error using the local truncation error, and one is thus
compelled to study the former on its own. This research was prompted by
unexpected numerical results on lattice Boltzmann schemes, which can be
rewritten in terms of multi-step Finite Difference schemes. Initial
expectations suggested that third-order initialization schemes would suffice to
maintain the accuracy of a fourth-order multi-step scheme. However, this
assumption proved incorrect for ``weakly'' unstable schemes. This borderline
scenario underscores the significance of genuine stability in facilitating the
construction of Lax-Richtmyer-like theorems and in mastering the impact of
round-off errors. Despite the simplicity and apparent lack of practical usage
of the linear transport equation at constant velocity considered throughout the
paper, we demonstrate that high-order lattice Boltzmann schemes for this
equation can be used to tackle non-linear systems of conservation laws relying
on a Jin-Xin approximation and high-order splitting formulae.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14504" title="Abstract">arXiv:2312.14504</a> [<a href="/pdf/2312.14504" title="Download PDF">pdf</a>, <a href="/ps/2312.14504" title="Download PostScript">ps</a>, <a href="/format/2312.14504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Theory of Hallucinations based on Equivariance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shibata%2C+H">Hisaichi Shibata</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Equivariance is an important feature in machine learning, including language
models. It ensures that any sequences of phrases with the same meanings are
interpreted consistently. For example, the sentence 'There is a cat on the
table' should be interpreted by language models as it is, regardless of
variations in its token-level expression. Building on this insight, I propose a
new theory suggesting that insufficient equivariance in language models can
lead to hallucinations. According to this theory, which is both intuitive and
novel, language models trained on relatively small datasets tend to
misinterpret input texts and/or generate incorrect texts (i.e.,
hallucinations). To test this theory, I developed a toy model known as 'dancing
men', which is a character-level substitution cipher. Additionally, I propose a
novel technique based on the T5 (Text To Text Transfer Transformer) model to
efficiently decipher these codes without relying on frequency analysis. I have
found that this T5 model can almost completely solve the cipher, demonstrating
its ability to acquire equivariance in this frame. This method could be scaled
up to word-level and sentence-level substitution ciphers, analogous to large
language models without tokenizers or dictionaries. This scalability makes it
suitable for investigating the proposed link between inadequate equivariance
acquisition and the emergence of hallucinations.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14506" title="Abstract">arXiv:2312.14506</a> [<a href="/pdf/2312.14506" title="Download PDF">pdf</a>, <a href="/format/2312.14506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concurrent Asynchronous Byzantine Agreement in Expected-Constant Rounds,  Revisited
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cohen%2C+R">Ran Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Forghani%2C+P">Pouyan Forghani</a>, 
<a href="/search/cs?searchtype=author&query=Garay%2C+J">Juan Garay</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+R">Rutvik Patel</a>, 
<a href="/search/cs?searchtype=author&query=Zikas%2C+V">Vassilis Zikas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A preliminary version of this work appeared in TCC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">It is well known that without randomization, Byzantine agreement (BA)
requires a linear number of rounds in the synchronous setting, while it is flat
out impossible in the asynchronous setting. The primitive which allows to
bypass the above limitation is known as oblivious common coin (OCC). It allows
parties to agree with constant probability on a random coin, where agreement is
oblivious, i.e., players are not aware whether or not agreement has been
achieved.
<br />The starting point of our work is the observation that no known protocol
exists for information-theoretic multi-valued OCC with optimal resiliency in
the asynchronous setting (with eventual message delivery). This apparent hole
in the literature is particularly problematic, as multi-valued OCC is
implicitly or explicitly used in several constructions.
<br />In this paper, we present the first information-theoretic multi-valued OCC
protocol in the asynchronous setting with optimal resiliency, i.e., tolerating
$t &lt; n/3$ corruptions, thereby filling this important gap. Further, our
protocol efficiently implements OCC with an exponential-size domain, a property
which is not even achieved by known constructions in the simpler, synchronous
setting.
<br />We then turn to the problem of round-preserving parallel composition of
asynchronous BA. A protocol for this task was proposed by Ben-Or and El-Yaniv
[Distributed Computing '03]. Their construction, however, is flawed in several
ways. Thus, as a second contribution, we provide a simpler, more modular
protocol for the above task. Finally, and as a contribution of independent
interest, we provide proofs in Canetti's Universal Composability framework;
this makes our work the first one offering composability guarantees, which are
important as BA is a core building block of secure multi-party computation
protocols.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14507" title="Abstract">arXiv:2312.14507</a> [<a href="/pdf/2312.14507" title="Download PDF">pdf</a>, <a href="/format/2312.14507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Harmonic Parameter Estimation Using Differentiable DSP and  Spectral Optimal Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Torres%2C+B">Bernardo Torres</a> (S2A, IDS, LTCI), 
<a href="/search/cs?searchtype=author&query=Peeters%2C+G">Geoffroy Peeters</a> (S2A, IDS, LTCI), 
<a href="/search/cs?searchtype=author&query=Richard%2C+G">Ga&#xeb;l Richard</a> (S2A, IDS, LTCI)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE International Conference on Acoustics, Speech and Signal
  Processing, Apr 2024, Seoul, South Korea
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)

</div>
<p class="mathjax">In neural audio signal processing, pitch conditioning has been used to
enhance the performance of synthesizers. However, jointly training pitch
estimators and synthesizers is a challenge when using standard audio-to-audio
reconstruction loss, leading to reliance on external pitch trackers. To address
this issue, we propose using a spectral loss function inspired by optimal
transportation theory that minimizes the displacement of spectral energy. We
validate this approach through an unsupervised autoencoding task that fits a
harmonic template to harmonic signals. We jointly estimate the fundamental
frequency and amplitudes of harmonics using a lightweight encoder and
reconstruct the signals using a differentiable harmonic synthesizer. The
proposed approach offers a promising direction for improving unsupervised
parameter estimation in neural audio applications.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14510" title="Abstract">arXiv:2312.14510</a> [<a href="/pdf/2312.14510" title="Download PDF">pdf</a>, <a href="/format/2312.14510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strategic Bidding Wars in On-chain Auctions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Thiery%2C+T">Thomas Thiery</a>, 
<a href="/search/cs?searchtype=author&query=Leonardos%2C+S">Stefanos Leonardos</a>, 
<a href="/search/cs?searchtype=author&query=Ventre%2C+C">Carmine Ventre</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The Ethereum block-building process has changed significantly since the
emergence of Proposer-Builder Separation. Validators access blocks through a
marketplace, where block builders bid for the right to construct the block and
earn MEV (Maximal Extractable Value) rewards in an on-chain competition, known
as the MEV-boost auction. While more than 90% of blocks are currently built via
MEV-Boost, trade-offs between builders' strategic behaviors and auction design
remain poorly understood. In this paper we address this gap. We introduce a
game-theoretic model for MEV-Boost auctions and use simulations to study
different builders' bidding strategies observed in practice. We study various
strategic interactions and auction setups and evaluate how the interplay
between critical elements such as access to MEV opportunities and improved
connectivity to relays impact bidding performance. Our results demonstrate the
importance of latency on the effectiveness of builders' strategies and the
overall auction outcome from the proposer's perspective.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14511" title="Abstract">arXiv:2312.14511</a> [<a href="/pdf/2312.14511" title="Download PDF">pdf</a>, <a href="/ps/2312.14511" title="Download PostScript">ps</a>, <a href="/format/2312.14511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Programming of Patterned Heterogeneous Interface for 4D Smart  Robotics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kewei Song</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Chunfeng Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ze Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kunlin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+W">Weiyang Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Umezu%2C+S">Shinjiro Umezu</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+H">Hirotaka Sato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 Pages, 11 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Shape memory structures are playing an important role in many cutting-edge
intelligent fields. However, the existing technologies can only realize 4D
printing of a single polymer or metal, which limits practical applications.
Here, we report a construction strategy for TSMP/M heterointerface, which uses
Pd2+-containing shape memory polymer (AP-SMR) to induce electroless plating
reaction and relies on molecular dynamics, which has both shape memory
properties and metal activity and information processing power. Through
multi-material DLP 3D printing technology, the interface can be 3D selectively
programmed on functional substrate parts of arbitrary shapes to become 4D
electronic smart devices (Robotics). Microscopically, this type of interface
appears as a composite structure with a nanometer-micrometer interface height,
which is composed of a pure substrate layer (smart materials), an intermediate
layer (a composite structure in which metal particles are embedded in a polymer
cross-linked network) and a pure metal layer. The structure programmed by
TSMP/M heterointerface exhibits both SMA characteristics and metal properties,
thus having more intelligent functions (electroactive, electrothermal
deformation, electronically controlled denaturation) and higher performance
(selectivity of shape memory structures can be realized control, remote
control, inline control and low voltage control). This is expected to provide a
more flexible manufacturing process as platform technology for designing,
manufacturing and applying smart devices with new concepts, and promote the
development of cutting-edge industries such as smart robots and smart
electronics.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14514" title="Abstract">arXiv:2312.14514</a> [<a href="/pdf/2312.14514" title="Download PDF">pdf</a>, <a href="/ps/2312.14514" title="Download PostScript">ps</a>, <a href="/format/2312.14514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3-anti-power uniform morphisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wlazinski%2C+F">Francis Wlazinski</a> (LAMFA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">Words whose three successive factors of the same length are all different
i.e. 3-anti-power words are a natural extension of square-free words (two
successive factors of the same length are different). We give a way to verify
whether a uniform morphism preserves 3-anti-power words (the image of a
3-anti-power word is a 3-anti-power word). A consequence of the existence of
such morphisms is the possibility of generating an infinite 3-anti-power word.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14524" title="Abstract">arXiv:2312.14524</a> [<a href="/pdf/2312.14524" title="Download PDF">pdf</a>, <a href="/format/2312.14524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LSIAC-MRA for Nonuniform Meshes and Applications to Mesh Adaptivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Picklo%2C+M+J">Matthew J. Picklo</a>, 
<a href="/search/math?searchtype=author&query=Ryan%2C+J+K">Jennifer K. Ryan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this article we consider the extension of the (L)SIAC-MRA enhancement
procedure to nonuniform meshes. We demonstrate that error reduction can be
obtained on perturbed quadrilateral and Delaunay meshes, and investigate the
effect of limited resolution and its impact on the procedure for various
function types. We show that utilizing mesh-based localized kernel scalings,
which were shown to reduce approximation errors for LSIAC filters, improve the
performance of the LSIAC-MRA enhancement procedure. Lastly, we demonstrate the
usefulness of enhanced approximations generated by (L)SIAC-MRA in mesh
adaptivity applications, and show that SIAC reconstruction can be used in
identification of regions of high error in steady-state DG approximations.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14525" title="Abstract">arXiv:2312.14525</a> [<a href="/pdf/2312.14525" title="Download PDF">pdf</a>, <a href="/ps/2312.14525" title="Download PostScript">ps</a>, <a href="/format/2312.14525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Approach to Reduce Computational Load: Precalculating Gain Matrices  for an LQR Controller of a Four-Axis Manipulator Using State Space Kinematics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Keiller%2C+A">Alistair Keiller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The corresponding code is available here: <a href="https://github.com/AlistairKeiller/RobotIK">this https URL</a> 7 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">When designing a power or CPU constrained device where a four-axis robotic
arm is required and access to the Robot Operating System (ROS) is not an
option, finding an efficient state space controller for a four-axis arm can be
an obstacle. In this paper, I explore a method to optimize the computing power
required for a computer algebra system (CAS) to compute linear quadratic
regulator (LQR) matrices by precomputing the gain matrix for different states.
Example C++ code is provided on Github, along with ideas for further
exploration.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14528" title="Abstract">arXiv:2312.14528</a> [<a href="/pdf/2312.14528" title="Download PDF">pdf</a>, <a href="/format/2312.14528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An effective and efficient green federated learning method for one-layer  neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fontenla-Romero%2C+O">Oscar Fontenla-Romero</a>, 
<a href="/search/cs?searchtype=author&query=Guijarro-Berdi%C3%B1as%2C+B">Bertha Guijarro-Berdi&#xf1;as</a>, 
<a href="/search/cs?searchtype=author&query=Hern%C3%A1ndez-Pereira%2C+E">Elena Hern&#xe1;ndez-Pereira</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez-S%C3%A1nchez%2C+B">Beatriz P&#xe9;rez-S&#xe1;nchez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Nowadays, machine learning algorithms continue to grow in complexity and
require a substantial amount of computational resources and energy. For these
reasons, there is a growing awareness of the development of new green
algorithms and distributed AI can contribute to this. Federated learning (FL)
is one of the most active research lines in machine learning, as it allows the
training of collaborative models in a distributed way, an interesting option in
many real-world environments, such as the Internet of Things, allowing the use
of these models in edge computing devices. In this work, we present a FL
method, based on a neural network without hidden layers, capable of generating
a global collaborative model in a single training round, unlike traditional FL
methods that require multiple rounds for convergence. This allows obtaining an
effective and efficient model that simplifies the management of the training
process. Moreover, this method preserve data privacy by design, a crucial
aspect in current data protection regulations. We conducted experiments with
large datasets and a large number of federated clients. Despite being based on
a network model without hidden layers, it maintains in all cases competitive
accuracy results compared to more complex state-of-the-art machine learning
models. Furthermore, we show that the method performs equally well in both
identically and non-identically distributed scenarios. Finally, it is an
environmentally friendly algorithm as it allows significant energy savings
during the training process compared to its centralized counterpart.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14529" title="Abstract">arXiv:2312.14529</a> [<a href="/pdf/2312.14529" title="Download PDF">pdf</a>, <a href="/format/2312.14529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When is Shapley Value Computation a Matter of Counting?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bienvenu%2C+M">Meghyn Bienvenu</a>, 
<a href="/search/cs?searchtype=author&query=Figueira%2C+D">Diego Figueira</a>, 
<a href="/search/cs?searchtype=author&query=Lafourcade%2C+P">Pierre Lafourcade</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">The Shapley value provides a natural means of quantifying the contributions
of facts to database query answers. In this work, we seek to broaden our
understanding of Shapley value computation (SVC) in the database setting by
revealing how it relates to Fixed-size Generalized Model Counting (FGMC), which
is the problem of computing the number of sub-databases of a given size and
containing a given set of assumed facts that satisfy a fixed query. Our focus
will be on explaining the difficulty of SVC via FGMC, and to this end, we
identify general conditions on queries which enable reductions from FGMC to
SVC. As a byproduct, we not only obtain alternative explanations for most
existing results on SVC, but also new complexity results. In particular, we
establish FP-#P complexity dichotomies for constant-free connected UCQs and
homomorphism-closed connected graph queries. We further explore variants of
SVC, either in the absence of assumed facts, or where we measure the
contribution of constants rather than facts.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14530" title="Abstract">arXiv:2312.14530</a> [<a href="/pdf/2312.14530" title="Download PDF">pdf</a>, <a href="/format/2312.14530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZodiacEdge: a Datalog Engine With Incremental Rule Set Maintenance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weiqin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cur%C3%A9%2C+O">Olivier Cur&#xe9;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 12 figures, 3 tables, 4 algorithms
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we tackle the incremental maintenance of Datalog inference
materialisation when the rule set can be updated. This is particularly relevant
in the context of the Internet of Things and Edge computing where smart devices
may need to reason over newly acquired knowledge represented as Datalog rules.
Our solution is based on an adaptation of a stratification strategy applied to
a dependency hypergraph whose nodes correspond to rule sets in a Datalog
program. Our implementation supports recursive rules containing both negation
and aggregation. We demonstrate the effectiveness of our system on real and
synthetic data.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14532" title="Abstract">arXiv:2312.14532</a> [<a href="/pdf/2312.14532" title="Download PDF">pdf</a>, <a href="/format/2312.14532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DuaLight: Enhancing Traffic Signal Control by Leveraging  Scenario-Specific and Scenario-Shared Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiaming Lu</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+J">Jingqing Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Haoyuan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+H">Hangyu Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAMAS2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Reinforcement learning has been revolutionizing the traditional traffic
signal control task, showing promising power to relieve congestion and improve
efficiency. However, the existing methods lack effective learning mechanisms
capable of absorbing dynamic information inherent to a specific scenario and
universally applicable dynamic information across various scenarios. Moreover,
within each specific scenario, they fail to fully capture the essential
empirical experiences about how to coordinate between neighboring and target
intersections, leading to sub-optimal system-wide outcomes.
<br />Viewing these issues, we propose DuaLight, which aims to leverage both the
experiential information within a single scenario and the generalizable
information across various scenarios for enhanced decision-making.
Specifically, DuaLight introduces a scenario-specific experiential weight
module with two learnable parts: Intersection-wise and Feature-wise, guiding
how to adaptively utilize neighbors and input features for each scenario, thus
providing a more fine-grained understanding of different intersections.
Furthermore, we implement a scenario-shared Co-Train module to facilitate the
learning of generalizable dynamics information across different scenarios.
Empirical results on both real-world and synthetic scenarios show DuaLight
achieves competitive performance across various metrics, offering a promising
solution to alleviate traffic congestion, with 3-7\% improvements. The code is
available under: https://github.com/lujiaming-12138/DuaLight.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14533" title="Abstract">arXiv:2312.14533</a> [<a href="/pdf/2312.14533" title="Download PDF">pdf</a>, <a href="/format/2312.14533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-view user representation learning for user matching without  personal information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Hongliu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Baamrani%2C+I+E">Ilias El Baamrani</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+E">Eoin Thomas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">As the digitization of travel industry accelerates, analyzing and
understanding travelers' behaviors becomes increasingly important. However,
traveler data frequently exhibit high data sparsity due to the relatively low
frequency of user interactions with travel providers. Compounding this effect
the multiplication of devices, accounts and platforms while browsing travel
products online also leads to data dispersion. To deal with these challenges,
probabilistic traveler matching can be used. Most existing solutions for user
matching are not suitable for traveler matching as a traveler's browsing
history is typically short and URLs in the travel industry are very
heterogeneous with many tokens. To deal with these challenges, we propose the
similarity based multi-view information fusion to learn a better user
representation from URLs by treating the URLs as multi-view data. The
experimental results show that the proposed multi-view user representation
learning can take advantage of the complementary information from different
views, highlight the key information in URLs and perform significantly better
than other representation learning solutions for the user matching task.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14535" title="Abstract">arXiv:2312.14535</a> [<a href="/pdf/2312.14535" title="Download PDF">pdf</a>, <a href="/format/2312.14535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ADA-GAD: Anomaly-Denoised Autoencoders for Graph Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junwei He</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qianqian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yangbangyan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zitai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qingming Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI-2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the AAAI Conference on Artificial Intelligence,
  2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graph anomaly detection is crucial for identifying nodes that deviate from
regular behavior within graphs, benefiting various domains such as fraud
detection and social network. Although existing reconstruction-based methods
have achieved considerable success, they may face the \textit{Anomaly
Overfitting} and \textit{Homophily Trap} problems caused by the abnormal
patterns in the graph, breaking the assumption that normal nodes are often
better reconstructed than abnormal ones. Our observations indicate that models
trained on graphs with fewer anomalies exhibit higher detection performance.
Based on this insight, we introduce a novel two-stage framework called
Anomaly-Denoised Autoencoders for Graph Anomaly Detection (ADA-GAD). In the
first stage, we design a learning-free anomaly-denoised augmentation method to
generate graphs with reduced anomaly levels. We pretrain graph autoencoders on
these augmented graphs at multiple levels, which enables the graph autoencoders
to capture normal patterns. In the next stage, the decoders are retrained for
detection on the original graph, benefiting from the multi-level
representations learned in the previous stage. Meanwhile, we propose the node
anomaly distribution regularization to further alleviate \textit{Anomaly
Overfitting}. We validate the effectiveness of our approach through extensive
experiments on both synthetic and real-world datasets.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14536" title="Abstract">arXiv:2312.14536</a> [<a href="/pdf/2312.14536" title="Download PDF">pdf</a>, <a href="/format/2312.14536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Reconvergence-driven AIG Rewriting via Strategy Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+L">Liwei Ni</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zonglin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaxi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junfeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huawei Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+B">Biwei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinquan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 41st IEEE International Conference on Computer Design
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Rewriting is a common procedure in logic synthesis aimed at improving the
performance, power, and area (PPA) of circuits. The traditional
reconvergence-driven And-Inverter Graph (AIG) rewriting method focuses solely
on optimizing the reconvergence cone through Boolean algebra minimization.
However, there exist opportunities to incorporate other node-rewriting
algorithms that are better suited for specific cones. In this paper, we propose
an adaptive reconvergence-driven AIG rewriting algorithm that combines two key
techniques: multi-strategy-based AIG rewriting and strategy learning-based
algorithm selection. The multi-strategy-based rewriting method expands upon the
traditional approach by incorporating support for multi-node-rewriting
algorithms, thus expanding the optimization space. Additionally, the strategy
learning-based algorithm selection method determines the most suitable
node-rewriting algorithm for a given cone. Experimental results demonstrate
that our proposed method yields a significant average improvement of 5.567\% in
size and 5.327\% in depth.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14541" title="Abstract">arXiv:2312.14541</a> [<a href="/pdf/2312.14541" title="Download PDF">pdf</a>, <a href="/format/2312.14541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MEC: An Open-source Fine-grained Mapping Equivalence Checking Tool for  FPGA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+L">Liwei Ni</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zonglin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaxi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Changhong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianhua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+G">Guojie Luo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huawei Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+B">Biwei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingquan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Symposium of EDA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Technology mapping is an essential step in EDA flow. However, the function of
the circuit may be changed after technology mapping, and equivalence checking
(EC) based verification is highly necessary. The traditional EC method has
significant time and resource constraints, making it only feasible to carry out
at a coarse-grained level. To make it efficient for technology mapping, we
propose a fine-grained method called MEC, which leverages a combination of two
approaches to significantly reduce the time cost of verification. The local
block verification approach performs fast verification and the global graph
cover approach guarantees correctness. The proposed method is rigorously tested
and compared to three EC tools, and the results show that MEC technique offers
a substantial improvement in speed. MEC not only offers a faster and more
efficient way of performing EC on technology mapping but also opens up new
opportunities for more fine-grained verification in the future.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14542" title="Abstract">arXiv:2312.14542</a> [<a href="/pdf/2312.14542" title="Download PDF">pdf</a>, <a href="/format/2312.14542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Data Retrieval for Cross Lingual Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhatnagar%2C+N">Nikhilesh Bhatnagar</a>, 
<a href="/search/cs?searchtype=author&query=Urlana%2C+A">Ashok Urlana</a>, 
<a href="/search/cs?searchtype=author&query=Mujadia%2C+V">Vandan Mujadia</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+P">Pruthwik Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+D+M">Dipti Misra Sharma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 tables, 2 figures, conference: ICON 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Cross-lingual summarization involves the summarization of text written in one
language to a different one. There is a body of research addressing
cross-lingual summarization from English to other European languages. In this
work, we aim to perform cross-lingual summarization from English to Hindi. We
propose pairing up the coverage of newsworthy events in textual and video
format can prove to be helpful for data acquisition for cross lingual
summarization. We analyze the data and propose methods to match articles to
video descriptions that serve as document and summary pairs. We also outline
filtering methods over reasonable thresholds to ensure the correctness of the
summaries. Further, we make available 28,583 mono and cross-lingual
article-summary pairs https://github.com/tingc9/Cross-Sum-News-Aligned. We also
build and analyze multiple baselines on the collected data and report error
analysis.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14544" title="Abstract">arXiv:2312.14544</a> [<a href="/pdf/2312.14544" title="Download PDF">pdf</a>, <a href="/format/2312.14544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inclusive normalization of face images to passport format
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Hongliu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+M+N">Minh Nhat Do</a>, 
<a href="/search/cs?searchtype=author&query=Ravanel%2C+A">Alexis Ravanel</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+E">Eoin Thomas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Face recognition has been used more and more in real world applications in
recent years. However, when the skin color bias is coupled with intra-personal
variations like harsh illumination, the face recognition task is more likely to
fail, even during human inspection. Face normalization methods try to deal with
such challenges by removing intra-personal variations from an input image while
keeping the identity the same. However, most face normalization methods can
only remove one or two variations and ignore dataset biases such as skin color
bias. The outputs of many face normalization methods are also not realistic to
human observers. In this work, a style based face normalization model
(StyleFNM) is proposed to remove most intra-personal variations including large
changes in pose, bad or harsh illumination, low resolution, blur, facial
expressions, and accessories like sunglasses among others. The dataset bias is
also dealt with in this paper by controlling a pretrained GAN to generate a
balanced dataset of passport-like images. The experimental results show that
StyleFNM can generate more realistic outputs and can improve significantly the
accuracy and fairness of face recognition systems.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14548" title="Abstract">arXiv:2312.14548</a> [<a href="/pdf/2312.14548" title="Download PDF">pdf</a>, <a href="/format/2312.14548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuroRIS: Neuromorphic-Inspired Metasurfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tsinos%2C+C+G">Christos G. Tsinos</a>, 
<a href="/search/eess?searchtype=author&query=Boulogeorgos%2C+A+A">Alexandros-Apostolos A. Boulogeorgos</a>, 
<a href="/search/eess?searchtype=author&query=Tsiftsis%2C+T+A">Theodoros A. Tsiftsis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Reconfigurable intelligent surfaces (RISs) operate similarly to
electromagnetic (EM) mirrors and remarkably go beyond Snell law to generate an
applicable EM environment allowing for flexible adaptation and fostering
sustainability in terms of economic deployment and energy efficiency. However,
the conventional RIS is controlled through high-latency field programmable gate
array or micro-controller circuits usually implementing artificial neural
networks (ANNs) for tuning the RIS phase array that have also very high energy
requirements. Most importantly, conventional RIS are unable to function under
realistic scenarios i.e, high-mobility/low-end user equipment (UE). In this
paper, we benefit from the advanced computing power of neuromorphic processors
and design a new type of RIS named \emph{NeuroRIS}, to supporting high mobility
UEs through real time adaptation to the ever-changing wireless channel
conditions. To this end, the neuromorphic processing unit tunes all the RIS
meta-elements in the orders of $\rm{ns}$ for particular switching circuits
e.g., varactors while exhibiting significantly low energy requirements since it
is based on event-driven processing through spiking neural networks for
accurate and efficient phase-shift vector design. Numerical results show that
the NeuroRIS achieves very close rate performance to a conventional RIS-based
on ANNs, while requiring significantly reduced energy consumption with the
latter.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14556" title="Abstract">arXiv:2312.14556</a> [<a href="/pdf/2312.14556" title="Download PDF">pdf</a>, <a href="/format/2312.14556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CaptainCook4D: A dataset for understanding errors in procedural  activities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peddi%2C+R">Rohith Peddi</a>, 
<a href="/search/cs?searchtype=author&query=Arya%2C+S">Shivvrat Arya</a>, 
<a href="/search/cs?searchtype=author&query=Challa%2C+B">Bharath Challa</a>, 
<a href="/search/cs?searchtype=author&query=Pallapothula%2C+L">Likhitha Pallapothula</a>, 
<a href="/search/cs?searchtype=author&query=Vyas%2C+A">Akshay Vyas</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jikai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Komaragiri%2C+V">Vasundhara Komaragiri</a>, 
<a href="/search/cs?searchtype=author&query=Ragan%2C+E">Eric Ragan</a>, 
<a href="/search/cs?searchtype=author&query=Ruozzi%2C+N">Nicholas Ruozzi</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Y">Yu Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Gogate%2C+V">Vibhav Gogate</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 2023 International Conference on Machine Learning(ICML) workshop on Data-centric Machine Learning Research(DMLR), Project Page: <a href="https://captaincook4d.github.io/captain-cook/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Following step-by-step procedures is an essential component of various
activities carried out by individuals in their daily lives. These procedures
serve as a guiding framework that helps to achieve goals efficiently, whether
it is assembling furniture or preparing a recipe. However, the complexity and
duration of procedural activities inherently increase the likelihood of making
errors. Understanding such procedural activities from a sequence of frames is a
challenging task that demands an accurate interpretation of visual information
and the ability to reason about the structure of the activity. To this end, we
collect a new egocentric 4D dataset, CaptainCook4D, comprising 384 recordings
(94.5 hours) of people performing recipes in real kitchen environments. This
dataset consists of two distinct types of activity: one in which participants
adhere to the provided recipe instructions and another in which they deviate
and induce errors. We provide 5.3K step annotations and 10K fine-grained action
annotations and benchmark the dataset for the following tasks: supervised error
recognition, multistep localization, and procedure learning
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14557" title="Abstract">arXiv:2312.14557</a> [<a href="/pdf/2312.14557" title="Download PDF">pdf</a>, <a href="/format/2312.14557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aurora:Activating Chinese chat capability for Mistral-8x7B sparse  Mixture-of-Experts through Instruction-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rongsheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haoming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+R">Ruizhe Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yaofei Duan</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+K">Kunyan Cai</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Han Ma</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jiaxi Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jian Li</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+P+C">Patrick Cheong-Iao Pang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yapeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+T">Tao Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Existing research has demonstrated that refining large language models (LLMs)
through the utilization of machine-generated instruction-following data
empowers these models to exhibit impressive zero-shot capabilities for novel
tasks, without requiring human-authored instructions. In this paper, we
systematically investigate, preprocess, and integrate three Chinese
instruction-following datasets with the aim of enhancing the Chinese
conversational capabilities of Mixtral-8x7B sparse Mixture-of-Experts model.
Through instruction fine-tuning on this carefully processed dataset, we
successfully construct the Mixtral-8x7B sparse Mixture-of-Experts model named
"Aurora." To assess the performance of Aurora, we utilize three widely
recognized benchmark tests: C-Eval, MMLU, and CMMLU. Empirical studies validate
the effectiveness of instruction fine-tuning applied to Mixtral-8x7B sparse
Mixture-of-Experts model. This work is pioneering in the execution of
instruction fine-tuning on a sparse expert-mixed model, marking a significant
breakthrough in enhancing the capabilities of this model architecture. Our
code, data and model are publicly available at:
https://github.com/WangRongsheng/Aurora
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14561" title="Abstract">arXiv:2312.14561</a> [<a href="/pdf/2312.14561" title="Download PDF">pdf</a>, <a href="/format/2312.14561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Traffic Reconstruction and Analysis of Natural Driving Behaviors at  Unsignalized Intersections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarker%2C+S">Supriya Sarker</a>, 
<a href="/search/cs?searchtype=author&query=Poudel%2C+B">Bibek Poudel</a>, 
<a href="/search/cs?searchtype=author&query=Villarreal%2C+M">Michael Villarreal</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weizi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">This paper explores the intricacies of traffic behavior at unsignalized
intersections through the lens of a novel dataset, combining manual video data
labeling and advanced traffic simulation in SUMO. This research involved
recording traffic at various unsignalized intersections in Memphis, TN, during
different times of the day. After manually labeling video data to capture
specific variables, we reconstructed traffic scenarios in the SUMO simulation
environment. The output data from these simulations offered a comprehensive
analysis, including time-space diagrams for vehicle movement, travel time
frequency distributions, and speed-position plots to identify bottleneck
points. This approach enhances our understanding of traffic dynamics, providing
crucial insights for effective traffic management and infrastructure
improvements.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14564" title="Abstract">arXiv:2312.14564</a> [<a href="/pdf/2312.14564" title="Download PDF">pdf</a>, <a href="/format/2312.14564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Covering with Multiple Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kevi%2C+E">Enik&#x151; Kevi</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+K">Kim-Thang Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Machine Learning (cs.LG)

</div>
<p class="mathjax">Designing online algorithms with machine learning predictions is a recent
technique beyond the worst-case paradigm for various practically relevant
online problems (scheduling, caching, clustering, ski rental, etc.). While most
previous learning-augmented algorithm approaches focus on integrating the
predictions of a single oracle, we study the design of online algorithms with
\emph{multiple} experts. To go beyond the popular benchmark of a static best
expert in hindsight, we propose a new \emph{dynamic} benchmark (linear
combinations of predictions that change over time). We present a competitive
algorithm in the new dynamic benchmark with a performance guarantee of $O(\log
K)$, where $K$ is the number of experts, for $0-1$ online optimization
problems. Furthermore, our multiple-expert approach provides a new perspective
on how to combine in an online manner several online algorithms - a
long-standing central subject in the online algorithm research community.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14566" title="Abstract">arXiv:2312.14566</a> [<a href="/pdf/2312.14566" title="Download PDF">pdf</a>, <a href="/format/2312.14566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational approximation for a non-isothermal coupled phase-field  system: Structure-preservation &amp; Nonlinear stability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Brunk%2C+A">Aaron Brunk</a>, 
<a href="/search/math?searchtype=author&query=Habrich%2C+O">Oliver Habrich</a>, 
<a href="/search/math?searchtype=author&query=Oyedeji%2C+T+D">Timileyin David Oyedeji</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+Y">Yangyiwei Yang</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+B">Bai-Xiang Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages; 3 figures; 6 pages appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">A Cahn-Hilliard-Allen-Cahn phase-field model coupled with a heat transfer
equation, particularly with full non-diagonal mobility matrices, is studied.
After reformulating the problem w.r.t. the inverse of temperature, we proposed
and analysed a structure-preserving approximation for the semi-discretisation
in space and then a fully discrete approximation using conforming finite
elements and time-stepping methods. We prove structure-preserving property and
discrete stability using relative entropy methods for the semi-discrete and
fully discrete case. The theoretical results are illustrated by numerical
experiments.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14567" title="Abstract">arXiv:2312.14567</a> [<a href="/pdf/2312.14567" title="Download PDF">pdf</a>, <a href="/format/2312.14567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerated Convergence of Stochastic Heavy Ball Method under  Anisotropic Gradient Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+R">Rui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuxing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Heavy-ball momentum with decaying learning rates is widely used with SGD for
optimizing deep learning models. In contrast to its empirical popularity, the
understanding of its theoretical property is still quite limited, especially
under the standard anisotropic gradient noise condition for quadratic
regression problems. Although it is widely conjectured that heavy-ball momentum
method can provide accelerated convergence and should work well in large batch
settings, there is no rigorous theoretical analysis. In this paper, we fill
this theoretical gap by establishing a non-asymptotic convergence bound for
stochastic heavy-ball methods with step decay scheduler on quadratic
objectives, under the anisotropic gradient noise condition. As a direct
implication, we show that heavy-ball momentum can provide
$\tilde{\mathcal{O}}(\sqrt{\kappa})$ accelerated convergence of the bias term
of SGD while still achieving near-optimal convergence rate with respect to the
stochastic variance term. The combined effect implies an overall convergence
rate within log factors from the statistical minimax rate. This means SGD with
heavy-ball momentum is useful in the large-batch settings such as distributed
machine learning or federated learning, where a smaller number of iterations
can significantly reduce the number of communication rounds, leading to
acceleration in practice.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14568" title="Abstract">arXiv:2312.14568</a> [<a href="/pdf/2312.14568" title="Download PDF">pdf</a>, <a href="/format/2312.14568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Projection Method: a Unified Formalism for Community Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%C3%B6sgens%2C+M">Martijn G&#xf6;sgens</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Hofstad%2C+R">Remco van der Hofstad</a>, 
<a href="/search/cs?searchtype=author&query=Litvak%2C+N">Nelly Litvak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">We present the class of projection methods for community detection that
generalizes many popular community detection methods. In this framework, we
represent each clustering (partition) by a vector on a high-dimensional
hypersphere. A community detection method is a projection method if it can be
described by the following two-step approach: 1) the graph is mapped to a query
vector on the hypersphere; and 2) the query vector is projected on the set of
clustering vectors. This last projection step is performed by minimizing the
distance between the query vector and the clustering vector, over the set of
clusterings. We prove that optimizing Markov stability, modularity, the
likelihood of planted partition models and correlation clustering fit this
framework. A consequence of this equivalence is that algorithms for each of
these methods can be modified to perform the projection step in our framework.
In addition, we show that these different methods suffer from the same
granularity problem: they have parameters that control the granularity of the
resulting clustering, but choosing these to obtain clusterings of the desired
granularity is nontrivial. We provide a general heuristic to address this
granularity problem, which can be applied to any projection method. Finally, we
show how, given a generator of graphs with community structure, we can optimize
a projection method for this generator in order to obtain a community detection
method that performs well on this generator.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14569" title="Abstract">arXiv:2312.14569</a> [<a href="/pdf/2312.14569" title="Download PDF">pdf</a>, <a href="/format/2312.14569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Creating New Voices using Normalizing Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bilinski%2C+P">Piotr Bilinski</a>, 
<a href="/search/cs?searchtype=author&query=Merritt%2C+T">Thomas Merritt</a>, 
<a href="/search/cs?searchtype=author&query=Ezzerg%2C+A">Abdelhamid Ezzerg</a>, 
<a href="/search/cs?searchtype=author&query=Pokora%2C+K">Kamil Pokora</a>, 
<a href="/search/cs?searchtype=author&query=Cygert%2C+S">Sebastian Cygert</a>, 
<a href="/search/cs?searchtype=author&query=Yanagisawa%2C+K">Kayoko Yanagisawa</a>, 
<a href="/search/cs?searchtype=author&query=Barra-Chicote%2C+R">Roberto Barra-Chicote</a>, 
<a href="/search/cs?searchtype=author&query=Korzekwa%2C+D">Daniel Korzekwa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Interspeech 2022
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Interspeech 2022, 2958-2962
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Creating realistic and natural-sounding synthetic speech remains a big
challenge for voice identities unseen during training. As there is growing
interest in synthesizing voices of new speakers, here we investigate the
ability of normalizing flows in text-to-speech (TTS) and voice conversion (VC)
modes to extrapolate from speakers observed during training to create unseen
speaker identities. Firstly, we create an approach for TTS and VC, and then we
comprehensively evaluate our methods and baselines in terms of intelligibility,
naturalness, speaker similarity, and ability to create new voices. We use both
objective and subjective metrics to benchmark our techniques on 2 evaluation
tasks: zero-shot and new voice speech synthesis. The goal of the former task is
to measure the precision of the conversion to an unseen voice. The goal of the
latter is to measure the ability to create new voices. Extensive evaluations
demonstrate that the proposed approach systematically allows to obtain
state-of-the-art performance in zero-shot speech synthesis and creates various
new voices, unobserved in the training set. We consider this work to be the
first attempt to synthesize new voices based on mel-spectrograms and
normalizing flows, along with a comprehensive analysis and comparison of the
TTS and VC modes.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14570" title="Abstract">arXiv:2312.14570</a> [<a href="/pdf/2312.14570" title="Download PDF">pdf</a>, <a href="/format/2312.14570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BSS-Bench: Towards Reproducible and Effective Band Selection Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wenshuai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhenbo Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages,6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The key technology to overcome the drawbacks of hyperspectral imaging
(expensive, high capture delay, and low spatial resolution) and make it widely
applicable is to select only a few representative bands from hundreds of bands.
However, current band selection (BS) methods face challenges in fair
comparisons due to inconsistent train/validation settings, including the number
of bands, dataset splits, and retraining settings. To make BS methods easy and
reproducible, this paper presents the first band selection search benchmark
(BSS-Bench) containing 52k training and evaluation records of numerous band
combinations (BC) with different backbones for various hyperspectral analysis
tasks. The creation of BSS-Bench required a significant computational effort of
1.26k GPU days. By querying BSS-Bench, BS experiments can be performed easily
and reproducibly, and the gap between the searched result and the best
achievable performance can be measured. Based on BSS-Bench, we further discuss
the impact of various factors on BS, such as the number of bands, unsupervised
statistics, and different backbones. In addition to BSS-Bench, we present an
effective one-shot BS method called Single Combination One Shot (SCOS), which
learns the priority of any BCs through one-time training, eliminating the need
for repetitive retraining on different BCs. Furthermore, the search process of
SCOS is flexible and does not require training, making it efficient and
effective. Our extensive evaluations demonstrate that SCOS outperforms current
BS methods on multiple tasks, even with much fewer bands. Our BSS-Bench and
codes are available in the supplementary material and will be publicly
available.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14571" title="Abstract">arXiv:2312.14571</a> [<a href="/pdf/2312.14571" title="Download PDF">pdf</a>, <a href="/format/2312.14571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data is Moody: Discovering Data Modification Rules from Process Event  Logs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schuster%2C+M+B">Marco Bjarne Schuster</a>, 
<a href="/search/cs?searchtype=author&query=Wiegand%2C+B">Boris Wiegand</a>, 
<a href="/search/cs?searchtype=author&query=Vreeken%2C+J">Jilles Vreeken</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Although event logs are a powerful source to gain insight about the behavior
of the underlying business process, existing work primarily focuses on finding
patterns in the activity sequences of an event log, while ignoring event
attribute data. Event attribute data has mostly been used to predict event
occurrences and process outcome, but the state of the art neglects to mine
succinct and interpretable rules how event attribute data changes during
process execution. Subgroup discovery and rule-based classification approaches
lack the ability to capture the sequential dependencies present in event logs,
and thus lead to unsatisfactory results with limited insight into the process
behavior.
<br />Given an event log, we are interested in finding accurate yet succinct and
interpretable if-then rules how the process modifies data. We formalize the
problem in terms of the Minimum Description Length (MDL) principle, by which we
choose the model with the best lossless description of the data. Additionally,
we propose the greedy Moody algorithm to efficiently search for rules. By
extensive experiments on both synthetic and real-world data, we show Moody
indeed finds compact and interpretable rules, needs little data for accurate
discovery, and is robust to noise.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14574" title="Abstract">arXiv:2312.14574</a> [<a href="/pdf/2312.14574" title="Download PDF">pdf</a>, <a href="/format/2312.14574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MMGPL: Multimodal Medical Data Analysis with Graph Prompt Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+L">Liang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+S">Songyue Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zongqian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+H">Huifang Shang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaofeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoxiao Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Prompt learning has demonstrated impressive efficacy in the fine-tuning of
multimodal large models to a wide range of downstream tasks. Nonetheless,
applying existing prompt learning methods for the diagnosis of neurological
disorder still suffers from two issues: (i) existing methods typically treat
all patches equally, despite the fact that only a small number of patches in
neuroimaging are relevant to the disease, and (ii) they ignore the structural
information inherent in the brain connection network which is crucial for
understanding and diagnosing neurological disorders. To tackle these issues, we
introduce a novel prompt learning model by learning graph prompts during the
fine-tuning process of multimodal large models for diagnosing neurological
disorders. Specifically, we first leverage GPT-4 to obtain relevant disease
concepts and compute semantic similarity between these concepts and all
patches. Secondly, we reduce the weight of irrelevant patches according to the
semantic similarity between each patch and disease-related concepts. Moreover,
we construct a graph among tokens based on these concepts and employ a graph
convolutional network layer to extract the structural information of the graph,
which is used to prompt the pre-trained multimodal large models for diagnosing
neurological disorders. Extensive experiments demonstrate that our method
achieves superior performance for neurological disorder diagnosis compared with
state-of-the-art methods and validated by clinicians.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14577" title="Abstract">arXiv:2312.14577</a> [<a href="/pdf/2312.14577" title="Download PDF">pdf</a>, <a href="/ps/2312.14577" title="Download PostScript">ps</a>, <a href="/format/2312.14577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PoseViNet: Distracted Driver Action Recognition Framework Using  Multi-View Pose Estimation and Vision Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sengar%2C+N">Neha Sengar</a>, 
<a href="/search/cs?searchtype=author&query=Kumari%2C+I">Indra Kumari</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jihui Lee</a>, 
<a href="/search/cs?searchtype=author&query=Har%2C+D">Dongsoo Har</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is revised draft submitted to IEEE Sensors Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Driver distraction is a principal cause of traffic accidents. In a study
conducted by the National Highway Traffic Safety Administration, engaging in
activities such as interacting with in-car menus, consuming food or beverages,
or engaging in telephonic conversations while operating a vehicle can be
significant sources of driver distraction. From this viewpoint, this paper
introduces a novel method for detection of driver distraction using multi-view
driver action images. The proposed method is a vision transformer-based
framework with pose estimation and action inference, namely PoseViNet. The
motivation for adding posture information is to enable the transformer to focus
more on key features. As a result, the framework is more adept at identifying
critical actions. The proposed framework is compared with various
state-of-the-art models using SFD3 dataset representing 10 behaviors of
drivers. It is found from the comparison that the PoseViNet outperforms these
models. The proposed framework is also evaluated with the SynDD1 dataset
representing 16 behaviors of driver. As a result, the PoseViNet achieves 97.55%
validation accuracy and 90.92% testing accuracy with the challenging dataset.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14578" title="Abstract">arXiv:2312.14578</a> [<a href="/pdf/2312.14578" title="Download PDF">pdf</a>, <a href="/ps/2312.14578" title="Download PostScript">ps</a>, <a href="/format/2312.14578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CPS Workshop 2023 Proceedings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pilato%2C+C">Christian Pilato</a>, 
<a href="/search/cs?searchtype=author&query=Palumbo%2C+F">Francesca Palumbo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">These proceedings contain the contributions to the CPS workshop 2023
(<a href="http://www.cpsschool.eu/cps-workshop/">this http URL</a>). The CPS Workshop 2023 is an initiative
of the CPS Summer School 2023 community to offer participants close contact
with leading experts in the field and the opportunity to present and discuss
their ideas in a dynamic and friendly setting.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14579" title="Abstract">arXiv:2312.14579</a> [<a href="/pdf/2312.14579" title="Download PDF">pdf</a>, <a href="/format/2312.14579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Environment-Specific People
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ostrek%2C+M">Mirela Ostrek</a>, 
<a href="/search/cs?searchtype=author&query=Sanyal%2C+S">Soubhik Sanyal</a>, 
<a href="/search/cs?searchtype=author&query=O%27Sullivan%2C+C">Carol O&#x27;Sullivan</a>, 
<a href="/search/cs?searchtype=author&query=Black%2C+M+J">Michael J. Black</a>, 
<a href="/search/cs?searchtype=author&query=Thies%2C+J">Justus Thies</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite significant progress in generative image synthesis and full-body
generation in particular, state-of-the-art methods are either
context-independent, overly reliant to text prompts, or bound to the curated
training datasets, such as fashion images with monotonous backgrounds. Here,
our goal is to generate people in clothing that is semantically appropriate for
a given scene. To this end, we present ESP, a novel method for context-aware
full-body generation, that enables photo-realistic inpainting of people into
existing "in-the-wild" photographs. ESP is conditioned on a 2D pose and
contextual cues that are extracted from the environment photograph and
integrated into the generation process. Our models are trained on a dataset
containing a set of in-the-wild photographs of people covering a wide range of
different environments. The method is analyzed quantitatively and
qualitatively, and we show that ESP outperforms state-of-the-art on the task of
contextual full-body generation.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14587" title="Abstract">arXiv:2312.14587</a> [<a href="/pdf/2312.14587" title="Download PDF">pdf</a>, <a href="/ps/2312.14587" title="Download PostScript">ps</a>, <a href="/format/2312.14587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring well quasi-ordered finitary powersets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abriola%2C+S">Sergio Abriola</a>, 
<a href="/search/cs?searchtype=author&query=Halfon%2C+S">Simon Halfon</a>, 
<a href="/search/cs?searchtype=author&query=Lopez%2C+A">Aliaume Lopez</a>, 
<a href="/search/cs?searchtype=author&query=Schmitz%2C+S">Sylvain Schmitz</a>, 
<a href="/search/cs?searchtype=author&query=Schnoebelen%2C+P">Philippe Schnoebelen</a>, 
<a href="/search/cs?searchtype=author&query=Vialard%2C+I">Isa Vialard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">The complexity of a well-quasi-order (wqo) can be measured through three
classical ordinal invariants: the width as a measure of antichains, the height
as a measure of chains, and the maximal order type as a measure of bad
sequences. This article considers the "finitary powerset" construction: the
collection Pf(X) of finite subsets of a wqo X ordered with the Hoare embedding
relation remains a wqo. The width, height and maximal order type of Pf(X)
cannot be expressed as a function of the invariants of X, and we provide tight
upper and lower bounds for the three invariants. The article also identifies an
algebra of well-behaved wqos, that include finitary powersets as well as other
more classical constructions, and for which the ordinal invariants can be
computed compositionnally. This relies on a new ordinal invariant called the
approximated maximal order type.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14589" title="Abstract">arXiv:2312.14589</a> [<a href="/pdf/2312.14589" title="Download PDF">pdf</a>, <a href="/format/2312.14589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Denoising Forward-Time Diffusions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peluchetti%2C+S">Stefano Peluchetti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> original date: 18 Nov 2021; archival of ICLR submission (<a href="https://openreview.net/forum?id=oVfIKuhqfC">this https URL</a>); no differences
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">The scope of this paper is generative modeling through diffusion processes.
An approach falling within this paradigm is the work of Song et al. (2021),
which relies on a time-reversal argument to construct a diffusion process
targeting the desired data distribution. We show that the time-reversal
argument, common to all denoising diffusion probabilistic modeling proposals,
is not necessary. We obtain diffusion processes targeting the desired data
distribution by taking appropriate mixtures of diffusion bridges. The resulting
transport is exact by construction, allows for greater flexibility in choosing
the dynamics of the underlying diffusion, and can be approximated by means of a
neural network via novel training objectives. We develop a unifying view of the
drift adjustments corresponding to our and to time-reversal approaches and make
use of this representation to inspect the inner workings of diffusion-based
generative models. Finally, we leverage on scalable simulation and inference
techniques common in spatial statistics to move beyond fully factorial
distributions in the underlying diffusion dynamics. The methodological advances
contained in this work contribute toward establishing a general framework for
generative modeling based on diffusion processes.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14590" title="Abstract">arXiv:2312.14590</a> [<a href="/pdf/2312.14590" title="Download PDF">pdf</a>, <a href="/format/2312.14590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SIG: Speaker Identification in Literature via Prompt-Based Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+Z">Zhenlin Su</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Liyan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiangnan Li</a>, 
<a href="/search/cs?searchtype=author&query=Huangfu%2C+M">Mingdu Huangfu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Identifying speakers of quotations in narratives is an important task in
literary analysis, with challenging scenarios including the out-of-domain
inference for unseen speakers, and non-explicit cases where there are no
speaker mentions in surrounding context. In this work, we propose a simple and
effective approach SIG, a generation-based method that verbalizes the task and
quotation input based on designed prompt templates, which also enables easy
integration of other auxiliary tasks that further bolster the speaker
identification performance. The prediction can either come from direct
generation by the model, or be determined by the highest generation probability
of each speaker candidate. Based on our approach design, SIG supports
out-of-domain evaluation, and achieves open-world classification paradigm that
is able to accept any forms of candidate input. We perform both cross-domain
evaluation and in-domain evaluation on PDNC, the largest dataset of this task,
where empirical results suggest that SIG outperforms previous baselines of
complicated designs, as well as the zero-shot ChatGPT, especially excelling at
those hard non-explicit scenarios by up to 17% improvement. Additional
experiments on another dataset WP further corroborate the efficacy of SIG.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14591" title="Abstract">arXiv:2312.14591</a> [<a href="/pdf/2312.14591" title="Download PDF">pdf</a>, <a href="/format/2312.14591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reasons to Reject? Aligning Language Models with Judgments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weiwen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Deng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhisong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+W">Wai Lam</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our source codes and models are publicly available at <a href="https://github.com/wwxu21/CUT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">As humans, we consistently engage in interactions with our peers and receive
feedback in the form of natural language. This language feedback allows us to
reflect on our actions, maintain appropriate behavior, and rectify our errors.
The question arises naturally: can we use language feedback to align large
language models (LLMs)? In contrast to previous research that aligns LLMs with
reward or preference data, we present the first systematic exploration of
alignment through the lens of language feedback (i.e., judgment). We commence
with an in-depth investigation of potential methods that can be adapted for
aligning LLMs with judgments, revealing that these methods are unable to fully
capitalize on the judgments. To facilitate more effective utilization of
judgments, we propose a novel framework, Contrastive Unlikelihood Training
(CUT), that allows for fine-grained inappropriate content detection and
correction based on judgments. Our offline alignment results show that, with
merely 1317 off-the-shelf judgment data, CUT (LLaMA2-13b) can beat the 175B
DaVinci003 and surpass the best baseline by 52.34 points on AlpacaEval. The
online alignment results demonstrate that CUT can align LLMs (LLaMA2-chat-13b)
in an iterative fashion using model-specific judgment data, with a steady
performance improvement from 81.09 to 91.36 points on AlpacaEval. Our analysis
further suggests that judgments exhibit greater potential than rewards for LLM
alignment and warrant future research.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14593" title="Abstract">arXiv:2312.14593</a> [<a href="/pdf/2312.14593" title="Download PDF">pdf</a>, <a href="/format/2312.14593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Effect of Sparsity on $k$-Dominating Set and Related First-Order  Graph Properties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fischer%2C+N">Nick Fischer</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BCnnemann%2C+M">Marvin K&#xfc;nnemann</a>, 
<a href="/search/cs?searchtype=author&query=Redzic%2C+M">Mirza Redzic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We revisit $k$-Dominating Set, one of the first problems for which a tight
$n^k-o(1)$ conditional lower bound (for $k\ge 3$), based on SETH, was shown
(P\u{a}tra\c{s}cu and Williams, SODA 2007). However, the underlying reduction
creates dense graphs, raising the question: how much does the sparsity of the
graph affect its fine-grained complexity?
<br />We first settle the fine-grained complexity of $k$-Dominating Set in terms of
both the number of nodes $n$ and number of edges $m$. Specifically, we show an
$mn^{k-2-o(1)}$ lower bound based on SETH, for any dependence of $m$ on $n$.
This is complemented by an $mn^{k-2+o(1)}$-time algorithm for all $k\ge 3$. For
the $k=2$ case, we give a randomized algorithm that employs a Bloom-filter
inspired hashing to improve the state of the art of $n^{\omega+o(1)}$ to
$m^{\omega/2+o(1)}$. If $\omega=2$, this yields a conditionally tight bound for
all $k\ge 2$.
<br />To study if $k$-Dominating Set is special in its sensitivity to sparsity, we
consider a class of very related problems. The $k$-Dominating Set problem
belongs to a type of first-order definable graph properties that we call
monochromatic basic problems. These problems are the natural monochromatic
variants of the basic problems that were proven complete for the class FOP of
first-order definable properties (Gao, Impagliazzo, Kolokolova, and Williams,
TALG 2019). We show that among these problems, $k$-Dominating Set is the only
one whose fine-grained complexity decreases in sparse graphs. Only for the
special case of reflexive properties, is there an additional basic problem that
can be solved faster than $n^{k\pm o(1)}$ on sparse graphs.
<br />For the natural variant of distance-$r$ $k$-dominating set, we obtain a
hardness of $n^{k-o(1)}$ under SETH for every $r\ge 2$ already on sparse
graphs, which is tight for sufficiently large $k$.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14599" title="Abstract">arXiv:2312.14599</a> [<a href="/pdf/2312.14599" title="Download PDF">pdf</a>, <a href="/format/2312.14599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Polarization Opinion Model Inspired by Bounded Confidence  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cyranka%2C+J">Jacek Cyranka</a>, 
<a href="/search/cs?searchtype=author&query=Mucha%2C+P+B">Piotr B. Mucha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Systems and Control (eess.SY); Dynamical Systems (math.DS); Numerical Analysis (math.NA)

</div>
<p class="mathjax">We present an opinion model founded upon the principles of the bounded
confidence interaction among agents. Our objective is to explain the
polarization effects inherent to vector-valued opinions. The evolutionary
process adheres to the rule where each agent aspires to increase polarization
through communication with a single friend during each discrete time step. The
dynamics ensure that agents' ultimate (temporal) configuration will encompass a
finite number of outlier states. We introduce deterministic and stochastic
models, accompanied by a comprehensive mathematical analysis of their inherent
properties. Additionally, we provide compelling illustrative examples and
introduce a stochastic solver tailored for scenarios featuring an extensive set
of agents. Furthermore, in the context of smaller agent populations, we
scrutinize the suitability of neural networks for the rapid inference of limit
configurations.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14600" title="Abstract">arXiv:2312.14600</a> [<a href="/pdf/2312.14600" title="Download PDF">pdf</a>, <a href="/ps/2312.14600" title="Download PostScript">ps</a>, <a href="/format/2312.14600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Categorical models of subtyping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coraglia%2C+G">Greta Coraglia</a>, 
<a href="/search/cs?searchtype=author&query=Emmenegger%2C+J">Jacopo Emmenegger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted for publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Category Theory (math.CT)

</div>
<p class="mathjax">Most categorical models for dependent types have traditionally been heavily
set based: contexts form a category, and for each we have a set of types in
said context -- and for each type a set of terms of said type. This is the case
for categories with families, categories with attributes, and natural models;
in particular, all of them can be traced back to certain discrete Grothendieck
fibrations. We extend this intuition to the case of general, non necessarily
discrete, fibrations, so that over a given context one has not only a set but a
category of types.
<br />We argue that the added structure can be attributed to a notion of subtyping
that shares many features with that of coercive subtyping, in the sense that it
is the product of thinking about subtyping as an abbreviation mechanism: we say
that a given type $A'$ is a subtype of $A$ if there is a unique coercion from
$A'$ to $A$. Whenever we need a term of type $A$, then, it suffices to have a
term of type $A'$, which we can `plug-in' into $A$.
<br />For this version of subtyping we provide rules, coherences, and explicit
models, and we compare and contrast it to coercive subtyping as introduced by
Z. Luo and others. We conclude by suggesting how the tools we present can be
employed in finding appropriate rules relating subtyping and certain type
constructors.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14606" title="Abstract">arXiv:2312.14606</a> [<a href="/pdf/2312.14606" title="Download PDF">pdf</a>, <a href="/format/2312.14606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Multi-Camera 3D Object Detection with Transformer-Based  Saliency Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beemelmanns%2C+T">Till Beemelmanns</a>, 
<a href="/search/cs?searchtype=author&query=Zahr%2C+W">Wassim Zahr</a>, 
<a href="/search/cs?searchtype=author&query=Eckstein%2C+L">Lutz Eckstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Vision Transformers (ViTs) have achieved state-of-the-art results on various
computer vision tasks, including 3D object detection. However, their end-to-end
implementation also makes ViTs less explainable, which can be a challenge for
deploying them in safety-critical applications, such as autonomous driving,
where it is important for authorities, developers, and users to understand the
model's reasoning behind its predictions. In this paper, we propose a novel
method for generating saliency maps for a DetR-like ViT with multiple camera
inputs used for 3D object detection. Our method is based on the raw attention
and is more efficient than gradient-based methods. We evaluate the proposed
method on the nuScenes dataset using extensive perturbation tests and show that
it outperforms other explainability methods in terms of visual quality and
quantitative metrics. We also demonstrate the importance of aggregating
attention across different layers of the transformer. Our work contributes to
the development of explainable AI for ViTs, which can help increase trust in AI
applications by establishing more transparency regarding the inner workings of
AI models.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14607" title="Abstract">arXiv:2312.14607</a> [<a href="/pdf/2312.14607" title="Download PDF">pdf</a>, <a href="/format/2312.14607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT, Llama, can you write my report? An experiment on assisted  digital forensics reports written using (Local) Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Michelet%2C+G">Ga&#xeb;tan Michelet</a>, 
<a href="/search/cs?searchtype=author&query=Breitinger%2C+F">Frank Breitinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the Digital Forensics Research Conference (DFRWS EU) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Generative AIs, especially Large Language Models (LLMs) such as ChatGPT or
Llama, have advanced significantly, positioning them as valuable tools for
digital forensics. While initial studies have explored the potential of ChatGPT
in the context of investigations, the question of to what extent LLMs can
assist the forensic report writing process remains unresolved. To answer the
question, this article first examines forensic reports with the goal of
generalization (e.g., finding the `average structure' of a report). We then
evaluate the strengths and limitations of LLMs for generating the different
parts of the forensic report using a case study. This work thus provides
valuable insights into the automation of report writing, a critical facet of
digital forensics investigations. We conclude that combined with thorough
proofreading and corrections, LLMs may assist practitioners during the report
writing process but at this point cannot replace them.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14608" title="Abstract">arXiv:2312.14608</a> [<a href="/pdf/2312.14608" title="Download PDF">pdf</a>, <a href="/format/2312.14608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Discrete Physics-informed Neural Networks for Addressing  Evolutionary Partial Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+B">Bin Shan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Ye Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 20 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Physics-informed neural networks (PINNs) have shown promising potential for
solving partial differential equations (PDEs) using deep learning. However,
PINNs face training difficulties for evolutionary PDEs, particularly for
dynamical systems whose solutions exhibit multi-scale or turbulent behavior
over time. The reason is that PINNs may violate the temporal causality property
since all the temporal features in the PINNs loss are trained simultaneously.
This paper proposes to use implicit time differencing schemes to enforce
temporal causality, and use transfer learning to sequentially update the PINNs
in space as surrogates for PDE solutions in different time frames. The evolving
PINNs are better able to capture the varying complexities of the evolutionary
equations, while only requiring minor updates between adjacent time frames. Our
method is theoretically proven to be convergent if the time step is small and
each PINN in different time frames is well-trained. In addition, we provide
state-of-the-art (SOTA) numerical results for a variety of benchmarks for which
existing PINNs formulations may fail or be inefficient. We demonstrate that the
proposed method improves the accuracy of PINNs approximation for evolutionary
PDEs and improves efficiency by a factor of 4-40x.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14611" title="Abstract">arXiv:2312.14611</a> [<a href="/pdf/2312.14611" title="Download PDF">pdf</a>, <a href="/format/2312.14611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tuning-Free Inversion-Enhanced Control for Consistent Image Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+X">Xiaoyue Duan</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shuhao Cui</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+G">Guoliang Kang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Baochang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+Z">Zhengcong Fei</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+M">Mingyuan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Junshi Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Consistent editing of real images is a challenging task, as it requires
performing non-rigid edits (e.g., changing postures) to the main objects in the
input image without changing their identity or attributes. To guarantee
consistent attributes, some existing methods fine-tune the entire model or the
textual embedding for structural consistency, but they are time-consuming and
fail to perform non-rigid edits. Other works are tuning-free, but their
performances are weakened by the quality of Denoising Diffusion Implicit Model
(DDIM) reconstruction, which often fails in real-world scenarios. In this
paper, we present a novel approach called Tuning-free Inversion-enhanced
Control (TIC), which directly correlates features from the inversion process
with those from the sampling process to mitigate the inconsistency in DDIM
reconstruction. Specifically, our method effectively obtains inversion features
from the key and value features in the self-attention layers, and enhances the
sampling process by these inversion features, thus achieving accurate
reconstruction and content-consistent editing. To extend the applicability of
our method to general editing scenarios, we also propose a mask-guided
attention concatenation strategy that combines contents from both the inversion
and the naive DDIM editing processes. Experiments show that the proposed method
outperforms previous works in reconstruction and consistent editing, and
produces impressive results in various settings.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14619" title="Abstract">arXiv:2312.14619</a> [<a href="/pdf/2312.14619" title="Download PDF">pdf</a>, <a href="/format/2312.14619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Loose-Fitting Garment Animation via Generative Model of  Deformation Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yifu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoxia Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhiling Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wei Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing data-driven methods for garment animation, usually driven by linear
skinning, although effective on tight garments, do not handle loose-fitting
garments with complex deformations well. To address these limitations, we
develop a garment generative model based on deformation decomposition to
efficiently simulate loose garment deformation without directly using linear
skinning. Specifically, we learn a garment generative space with the proposed
generative model, where we decouple the latent representation into unposed
deformed garments and dynamic offsets during the decoding stage. With explicit
garment deformations decomposition, our generative model is able to generate
complex pose-driven deformations on canonical garment shapes. Furthermore, we
learn to transfer the body motions and previous state of the garment to the
latent space to regenerate dynamic results. In addition, we introduce a detail
enhancement module in an adversarial training setup to learn high-frequency
wrinkles. We demonstrate our method outperforms state-of-the-art data-driven
alternatives through extensive experiments and show qualitative and
quantitative analysis of results.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14620" title="Abstract">arXiv:2312.14620</a> [<a href="/pdf/2312.14620" title="Download PDF">pdf</a>, <a href="/format/2312.14620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure-Guided Automated Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bannach%2C+M">Max Bannach</a>, 
<a href="/search/cs?searchtype=author&query=Hecher%2C+M">Markus Hecher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">Algorithmic meta-theorems state that problems that can be formalized in a
fixed logic can be solved efficiently on classes of structures with certain
properties. A prominent example is Courcelle's Theorem, which states that all
problems expressible in monadic second-order logic can be solved efficiently on
structures of small treewidth. Such theorems are usually proven by a generic
algorithm for the model-checking problem of the given logic, which is often
complex and rarely leads to highly efficient solutions. Alternatively, we can
solve the model-checking problem by grounding the given logic to propositional
logic, for which dedicated solvers are available. Such encodings will, however,
usually not preserve the input's treewidth.
<br />This paper investigates whether all problems definable in monadic
second-order logic can efficiently be encoded into SAT such that the input's
treewidth bounds the treewidth of the resulting formula. We answer this in the
affirmative and, hence, provide an alternative proof of Courcelle's Theorem.
Our technique can naturally be extended: There are treewidth-aware reductions
from the optimization version of Courcelle's Theorem to MaxSAT and from the
counting version of the theorem to #SAT. By using encodings to SAT, we obtain,
ignoring polynomial factors, the same running time for the model-checking
problem as we would with dedicated algorithms. We complement our upper bounds
with new lower bounds based on ETH; and we show that the block size of the
input's formula and the treewidth of the input's structure are tightly linked.
We also provide matching upper and lower bounds for a fragment of guarded MSO,
only using SAT-based techniques.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14625" title="Abstract">arXiv:2312.14625</a> [<a href="/pdf/2312.14625" title="Download PDF">pdf</a>, <a href="/format/2312.14625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Multi-Agent Reinforcement Learning for Assessing False-Data  Injection Attacks on Transportation Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eghtesad%2C+T">Taha Eghtesad</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sirui Li</a>, 
<a href="/search/cs?searchtype=author&query=Vorobeychik%2C+Y">Yevgeniy Vorobeychik</a>, 
<a href="/search/cs?searchtype=author&query=Laszka%2C+A">Aron Laszka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">The increasing reliance of drivers on navigation applications has made
transportation networks more susceptible to data-manipulation attacks by
malicious actors. Adversaries may exploit vulnerabilities in the data
collection or processing of navigation services to inject false information,
and to thus interfere with the drivers' route selection. Such attacks can
significantly increase traffic congestions, resulting in substantial waste of
time and resources, and may even disrupt essential services that rely on road
networks. To assess the threat posed by such attacks, we introduce a
computational framework to find worst-case data-injection attacks against
transportation networks. First, we devise an adversarial model with a threat
actor who can manipulate drivers by increasing the travel times that they
perceive on certain roads. Then, we employ hierarchical multi-agent
reinforcement learning to find an approximate optimal adversarial strategy for
data manipulation. We demonstrate the applicability of our approach through
simulating attacks on the Sioux Falls, ND network topology.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14626" title="Abstract">arXiv:2312.14626</a> [<a href="/pdf/2312.14626" title="Download PDF">pdf</a>, <a href="/format/2312.14626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DSAP: Analyzing Bias Through Demographic Comparison of Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dominguez-Catena%2C+I">Iris Dominguez-Catena</a>, 
<a href="/search/cs?searchtype=author&query=Paternain%2C+D">Daniel Paternain</a>, 
<a href="/search/cs?searchtype=author&query=Galar%2C+M">Mikel Galar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the last few years, Artificial Intelligence systems have become
increasingly widespread. Unfortunately, these systems can share many biases
with human decision-making, including demographic biases. Often, these biases
can be traced back to the data used for training, where large uncurated
datasets have become the norm. Despite our knowledge of these biases, we still
lack general tools to detect and quantify them, as well as to compare the
biases in different datasets. Thus, in this work, we propose DSAP (Demographic
Similarity from Auxiliary Profiles), a two-step methodology for comparing the
demographic composition of two datasets. DSAP can be deployed in three key
applications: to detect and characterize demographic blind spots and bias
issues across datasets, to measure dataset demographic bias in single datasets,
and to measure dataset demographic shift in deployment scenarios. An essential
feature of DSAP is its ability to robustly analyze datasets without explicit
demographic labels, offering simplicity and interpretability for a wide range
of situations. To show the usefulness of the proposed methodology, we consider
the Facial Expression Recognition task, where demographic bias has previously
been found. The three applications are studied over a set of twenty datasets
with varying properties. The code is available at
https://github.com/irisdominguez/DSAP.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14628" title="Abstract">arXiv:2312.14628</a> [<a href="/pdf/2312.14628" title="Download PDF">pdf</a>, <a href="/format/2312.14628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards more sustainable enterprise data and application management with  cross silo Federated Learning and Analytics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Hongliu Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented in Sophia Summit 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">To comply with new legal requirements and policies committed to privacy
protection, more and more companies start to deploy cross-silo Federated
Learning at global scale, where several clients/silos collaboratively train a
global model under the coordination of a central server. Instead of data
sharing and transmission, clients train models using their private local data
and exchange model updates. However, there is little understanding of the
carbon emission impact of cross silo Federated Learning due to the lack of
related works. In this study, we first analyze the sustainability aspect of
cross-silo Federated Learning, across the AI product life cycle instead of
focusing only on the model training, with the comparison to the centralized
method. A more holistic quantitative cost and CO2 emission estimation method
for real world cross-silo Federated Learning setting is proposed. Secondly, we
propose a novel data and application management system using cross silo
Federated Learning and analytics to make IT companies more sustainable and cost
effective.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14630" title="Abstract">arXiv:2312.14630</a> [<a href="/pdf/2312.14630" title="Download PDF">pdf</a>, <a href="/format/2312.14630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Language-based solution to enable Metaverse Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdari%2C+A">Ali Abdari</a>, 
<a href="/search/cs?searchtype=author&query=Falcon%2C+A">Alex Falcon</a>, 
<a href="/search/cs?searchtype=author&query=Serra%2C+G">Giuseppe Serra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 30th International Conference on Multimedia Modeling- MMM2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, the Metaverse is becoming increasingly attractive, with millions of
users accessing the many available virtual worlds. However, how do users find
the one Metaverse which best fits their current interests? So far, the search
process is mostly done by word of mouth, or by advertisement on
technology-oriented websites. However, the lack of search engines similar to
those available for other multimedia formats (e.g., YouTube for videos) is
showing its limitations, since it is often cumbersome to find a Metaverse based
on some specific interests using the available methods, while also making it
difficult to discover user-created ones which lack strong advertisement. To
address this limitation, we propose to use language to naturally describe the
desired contents of the Metaverse a user wishes to find. Second, we highlight
that, differently from more conventional 3D scenes, Metaverse scenarios
represent a more complex data format since they often contain one or more types
of multimedia which influence the relevance of the scenario itself to a user
query. Therefore, in this work, we create a novel task, called
Text-to-Metaverse retrieval, which aims at modeling these aspects while also
taking the cross-modal relations with the textual data into account. Since we
are the first ones to tackle this problem, we also collect a dataset of 33000
Metaverses, each of which consists of a 3D scene enriched with multimedia
content. Finally, we design and implement a deep learning framework based on
contrastive learning, resulting in a thorough experimental setup.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14633" title="Abstract">arXiv:2312.14633</a> [<a href="/pdf/2312.14633" title="Download PDF">pdf</a>, <a href="/format/2312.14633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Security and Privacy Risk Postures of Virtual Assistants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalhor%2C+B">Borna Kalhor</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Sanchari Das</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Virtual assistants (VAs) have seen increased use in recent years due to their
ease of use for daily tasks. Despite their growing prevalence, their security
and privacy implications are still not well understood. To address this gap, we
conducted a study to evaluate the security and privacy postures of eight widely
used voice assistants: Alexa, Braina, Cortana, Google Assistant, Kalliope,
Mycroft, Hound, and Extreme. We used three vulnerability testing tools,
AndroBugs, RiskInDroid, and MobSF, to assess the security and privacy of these
VAs. Our analysis focused on five areas: code, access control, tracking, binary
analysis, and sensitive data confidentiality. The results revealed that these
VAs are vulnerable to a range of security threats, including not validating SSL
certificates, executing raw SQL queries, and using a weak mode of the AES
algorithm. These vulnerabilities could allow malicious actors to gain
unauthorized access to users' personal information. This study is a first step
toward understanding the risks associated with these technologies and provides
a foundation for future research to develop more secure and privacy-respecting
VAs.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14634" title="Abstract">arXiv:2312.14634</a> [<a href="/pdf/2312.14634" title="Download PDF">pdf</a>, <a href="/format/2312.14634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mining multi-modal communication patterns in interaction with  explainable and non-explainable robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bensch%2C+S">Suna Bensch</a>, 
<a href="/search/cs?searchtype=author&query=Eriksson%2C+A">Amanda Eriksson</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE RO-MAN 2023, 32nd IEEE International conference on Robot and
  Human Interactive Communication; Workshop Human-Robot Interaction for
  Explainability in Robotics, Busan, Korea, August 28-31, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We investigate interaction patterns for humans interacting with explainable
and non-explainable robots. Non-explainable robots are here robots that do not
explain their actions or non-actions, neither do they give any other feedback
during interaction, in contrast to explainable robots. We video recorded and
analyzed human behavior during a board game, where 20 humans verbally
instructed either an explainable or non-explainable Pepper robot to move
objects on the board. The transcriptions and annotations of the videos were
transformed into transactions for association rule mining. Association rules
discovered communication patterns in the interaction between the robots and the
humans, and the most interesting rules were also tested with regular chi-square
tests. Some statistically significant results are that there is a strong
correlation between men and non-explainable robots and women and explainable
robots, and that humans mirror some of the robot's modality. Our results also
show that it is important to contextualize human interaction patterns, and that
this can be easily done using association rules as an investigative tool. The
presented results are important when designing robots that should adapt their
behavior to become understandable for the interacting humans.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14635" title="Abstract">arXiv:2312.14635</a> [<a href="/pdf/2312.14635" title="Download PDF">pdf</a>, <a href="/format/2312.14635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fluid Simulation on Neural Flow Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yitong Deng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hong-Xing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Diyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Bo Zhu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM Trans. Graph. 42, 6, Article 248 (December 2023), 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">We introduce Neural Flow Maps, a novel simulation method bridging the
emerging paradigm of implicit neural representations with fluid simulation
based on the theory of flow maps, to achieve state-of-the-art simulation of
inviscid fluid phenomena. We devise a novel hybrid neural field representation,
Spatially Sparse Neural Fields (SSNF), which fuses small neural networks with a
pyramid of overlapping, multi-resolution, and spatially sparse grids, to
compactly represent long-term spatiotemporal velocity fields at high accuracy.
With this neural velocity buffer in hand, we compute long-term, bidirectional
flow maps and their Jacobians in a mechanistically symmetric manner, to
facilitate drastic accuracy improvement over existing solutions. These
long-range, bidirectional flow maps enable high advection accuracy with low
dissipation, which in turn facilitates high-fidelity incompressible flow
simulations that manifest intricate vortical structures. We demonstrate the
efficacy of our neural fluid simulation in a variety of challenging simulation
scenarios, including leapfrogging vortices, colliding vortices, vortex
reconnections, as well as vortex generation from moving obstacles and density
differences. Our examples show increased performance over existing methods in
terms of energy conservation, visual complexity, adherence to experimental
observations, and preservation of detailed vortical structures.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14638" title="Abstract">arXiv:2312.14638</a> [<a href="/pdf/2312.14638" title="Download PDF">pdf</a>, <a href="/format/2312.14638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balancing Energy Efficiency and Distributional Robustness in  Over-the-Air Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Badi%2C+M">Mohamed Badi</a>, 
<a href="/search/cs?searchtype=author&query=Issaid%2C+C+B">Chaouki Ben Issaid</a>, 
<a href="/search/cs?searchtype=author&query=Elgabli%2C+A">Anis Elgabli</a>, 
<a href="/search/cs?searchtype=author&query=Bennis%2C+M">Mehdi Bennis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The growing number of wireless edge devices has magnified challenges
concerning energy, bandwidth, latency, and data heterogeneity. These challenges
have become bottlenecks for distributed learning. To address these issues, this
paper presents a novel approach that ensures energy efficiency for
distributionally robust federated learning (FL) with over air computation
(AirComp). In this context, to effectively balance robustness with energy
efficiency, we introduce a novel client selection method that integrates two
complementary insights: a deterministic one that is designed for energy
efficiency, and a probabilistic one designed for distributional robustness.
Simulation results underscore the efficacy of the proposed algorithm, revealing
its superior performance compared to baselines from both robustness and energy
efficiency perspectives, achieving more than 3-fold energy savings compared to
the considered baselines.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14646" title="Abstract">arXiv:2312.14646</a> [<a href="/pdf/2312.14646" title="Download PDF">pdf</a>, <a href="/format/2312.14646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Synthesis of Patient Records through Multi-Visit Health  State Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hongda Sun</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hongzhan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rui Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Electronic health records (EHRs) have become the foundation of machine
learning applications in healthcare, while the utility of real patient records
is often limited by privacy and security concerns. Synthetic EHR generation
provides an additional perspective to compensate for this limitation. Most
existing methods synthesize new records based on real EHR data, without
consideration of different types of events in EHR data, which cannot control
the event combinations in line with medical common sense. In this paper, we
propose MSIC, a Multi-visit health Status Inference model for Collaborative EHR
synthesis to address these limitations. First, we formulate the synthetic EHR
generation process as a probabilistic graphical model and tightly connect
different types of events by modeling the latent health states. Then, we derive
a health state inference method tailored for the multi-visit scenario to
effectively utilize previous records to synthesize current and future records.
Furthermore, we propose to generate medical reports to add textual descriptions
for each medical event, providing broader applications for synthesized EHR
data. For generating different paragraphs in each visit, we incorporate a
multi-generator deliberation framework to collaborate the message passing of
multiple generators and employ a two-phase decoding strategy to generate
high-quality reports. Our extensive experiments on the widely used benchmarks,
MIMIC-III and MIMIC-IV, demonstrate that MSIC advances state-of-the-art results
on the quality of synthetic data while maintaining low privacy risks.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14647" title="Abstract">arXiv:2312.14647</a> [<a href="/pdf/2312.14647" title="Download PDF">pdf</a>, <a href="/format/2312.14647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pub/Sub Message Brokers for GenAI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saleh%2C+A">Alaa Saleh</a>, 
<a href="/search/cs?searchtype=author&query=Pirttikangas%2C+S">Susanna Pirttikangas</a>, 
<a href="/search/cs?searchtype=author&query=Lov%C3%A9n%2C+L">Lauri Lov&#xe9;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 282 references, 4 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">In today's digital world, Generative Artificial Intelligence (GenAI) such as
Large Language Models (LLMs) is becoming increasingly prevalent, extending its
reach across diverse applications. This surge in adoption has sparked a
significant increase in demand for data-centric GenAI models, highlighting the
necessity for robust data communication infrastructures. Central to this need
are message brokers, which serve as essential channels for data transfer within
various system components. This survey aims to delve into a comprehensive
analysis of traditional and modern message brokers, offering a comparative
study of prevalent platforms. Our study considers numerous criteria including,
but not limited to, open-source availability, integrated monitoring tools,
message prioritization mechanisms, capabilities for parallel processing,
reliability, distribution and clustering functionalities, authentication
processes, data persistence strategies, fault tolerance, and scalability.
Furthermore, we explore the intrinsic constraints that the design and operation
of each message broker might impose, recognizing that these limitations are
crucial in understanding their real-world applicability. We then leverage these
insights to propose a sophisticated message broker framework -- one designed
with the adaptability and robustness necessary to meet the evolving requisites
of GenAI applications. Finally, this study examines the enhancement of message
broker mechanisms specifically for GenAI contexts, emphasizing the criticality
of developing a versatile message broker framework. Such a framework would be
poised for quick adaptation, catering to the dynamic and growing demands of
GenAI in the foreseeable future. Through this dual-pronged approach, we intend
to contribute a foundational compendium that can guide future innovations and
infrastructural advancements in the realm of GenAI data communication.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14650" title="Abstract">arXiv:2312.14650</a> [<a href="/pdf/2312.14650" title="Download PDF">pdf</a>, <a href="/format/2312.14650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Global Occlusion-Aware Transformer for Robust Stereo Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zihua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yizhou Li</a>, 
<a href="/search/cs?searchtype=author&query=Okutomi%2C+M">Masatoshi Okutomi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite the remarkable progress facilitated by learning-based stereo-matching
algorithms, the performance in the ill-conditioned regions, such as the
occluded regions, remains a bottleneck. Due to the limited receptive field,
existing CNN-based methods struggle to handle these ill-conditioned regions
effectively. To address this issue, this paper introduces a novel
attention-based stereo-matching network called Global Occlusion-Aware
Transformer (GOAT) to exploit long-range dependency and occlusion-awareness
global context for disparity estimation. In the GOAT architecture, a parallel
disparity and occlusion estimation module PDO is proposed to estimate the
initial disparity map and the occlusion mask using a parallel attention
mechanism. To further enhance the disparity estimates in the occluded regions,
an occlusion-aware global aggregation module (OGA) is proposed. This module
aims to refine the disparity in the occluded regions by leveraging restricted
global correlation within the focus scope of the occluded areas. Extensive
experiments were conducted on several public benchmark datasets including
SceneFlow, KITTI 2015, and Middlebury. The results show that the proposed GOAT
demonstrates outstanding performance among all benchmarks, particularly in the
occluded regions.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14651" title="Abstract">arXiv:2312.14651</a> [<a href="/pdf/2312.14651" title="Download PDF">pdf</a>, <a href="/format/2312.14651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAVAE: Leveraging the variational Bayes autoencoder for survival  analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Apell%C3%A1niz%2C+P+A">Patricia A. Apell&#xe1;niz</a>, 
<a href="/search/cs?searchtype=author&query=Parras%2C+J">Juan Parras</a>, 
<a href="/search/cs?searchtype=author&query=Zazo%2C+S">Santiago Zazo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">As in many fields of medical research, survival analysis has witnessed a
growing interest in the application of deep learning techniques to model
complex, high-dimensional, heterogeneous, incomplete, and censored medical
data. Current methods often make assumptions about the relations between data
that may not be valid in practice. In response, we introduce SAVAE (Survival
Analysis Variational Autoencoder), a novel approach based on Variational
Autoencoders. SAVAE contributes significantly to the field by introducing a
tailored ELBO formulation for survival analysis, supporting various parametric
distributions for covariates and survival time (as long as the log-likelihood
is differentiable). It offers a general method that consistently performs well
on various metrics, demonstrating robustness and stability through different
experiments. Our proposal effectively estimates time-to-event, accounting for
censoring, covariate interactions, and time-varying risk associations. We
validate our model in diverse datasets, including genomic, clinical, and
demographic data, with varying levels of censoring. This approach demonstrates
competitive performance compared to state-of-the-art techniques, as assessed by
the Concordance Index and the Integrated Brier Score. SAVAE also offers an
interpretable model that parametrically models covariates and time. Moreover,
its generative architecture facilitates further applications such as
clustering, data imputation, and the generation of synthetic patient data
through latent space inference from survival data.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14656" title="Abstract">arXiv:2312.14656</a> [<a href="/pdf/2312.14656" title="Download PDF">pdf</a>, <a href="/ps/2312.14656" title="Download PostScript">ps</a>, <a href="/format/2312.14656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Completions of Kleene&#x27;s second model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Terwijn%2C+S+A">Sebastiaan A. Terwijn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Logic (math.LO)

</div>
<p class="mathjax">We investigate completions of partial combinatory algebras (pcas), in
particular of Kleene's second model $\mathcal{K}_2$ and generalizations
thereof. We consider weak and strong notions of embeddability and completion
that have been studied before. By a result of Klop it is known that not every
pca has a strong completion. The study of completions of $\mathcal{K}_2$ has as
corollaries that weak and strong embeddings are different, and that every
countable pca has a weak completion. We then consider generalizations of
$\mathcal{K}_2$ for larger cardinals, and use these to show that it is
consistent that every pca has a weak completion.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14657" title="Abstract">arXiv:2312.14657</a> [<a href="/pdf/2312.14657" title="Download PDF">pdf</a>, <a href="/format/2312.14657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Non-Parametric Time Series Forecaster
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rangapuram%2C+S+S">Syama Sundar Rangapuram</a>, 
<a href="/search/cs?searchtype=author&query=Gasthaus%2C+J">Jan Gasthaus</a>, 
<a href="/search/cs?searchtype=author&query=Stella%2C+L">Lorenzo Stella</a>, 
<a href="/search/cs?searchtype=author&query=Flunkert%2C+V">Valentin Flunkert</a>, 
<a href="/search/cs?searchtype=author&query=Salinas%2C+D">David Salinas</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Januschowski%2C+T">Tim Januschowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper presents non-parametric baseline models for time series
forecasting. Unlike classical forecasting models, the proposed approach does
not assume any parametric form for the predictive distribution and instead
generates predictions by sampling from the empirical distribution according to
a tunable strategy. By virtue of this, the model is always able to produce
reasonable forecasts (i.e., predictions within the observed data range) without
fail unlike classical models that suffer from numerical stability on some data
distributions. Moreover, we develop a global version of the proposed method
that automatically learns the sampling strategy by exploiting the information
across multiple related time series. The empirical evaluation shows that the
proposed methods have reasonable and consistent performance across all
datasets, proving them to be strong baselines to be considered in one's
forecasting toolbox.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14658" title="Abstract">arXiv:2312.14658</a> [<a href="/pdf/2312.14658" title="Download PDF">pdf</a>, <a href="/format/2312.14658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Room Acoustic Rendering Networks with Control of Scattering and Early  Reflections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scerbo%2C+M">Matteo Scerbo</a>, 
<a href="/search/cs?searchtype=author&query=Savioja%2C+L">Lauri Savioja</a>, 
<a href="/search/cs?searchtype=author&query=De+Sena%2C+E">Enzo De Sena</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE/ACM Transactions on Audio, Speech, and Language Processing. 12 pages, 12 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Room acoustic synthesis can be used in Virtual Reality (VR), Augmented
Reality (AR) and gaming applications to enhance listeners' sense of immersion,
realism and externalisation. A common approach is to use Geometrical Acoustics
(GA) models to compute impulse responses at interactive speed, and fast
convolution methods to apply said responses in real time. Alternatively,
delay-network-based models are capable of modeling certain aspects of room
acoustics, but with a significantly lower computational cost. In order to
bridge the gap between these classes of models, recent work introduced delay
network designs that approximate Acoustic Radiance Transfer (ART), a GA model
that simulates the transfer of acoustic energy between discrete surface patches
in an environment. This paper presents two key extensions of such designs. The
first extension involves a new physically-based and stability-preserving design
of the feedback matrices, enabling more accurate control of scattering and,
more in general, of late reverberation properties. The second extension allows
an arbitrary number of early reflections to be modeled with high accuracy,
meaning the network can be scaled at will between computational cost and early
reverb precision. The proposed extensions are compared to the baseline
ART-approximating delay network as well as two reference GA models. The
evaluation is based on objective measures of perceptually-relevant features,
including frequency-dependent reverberation times, echo density build-up, and
early decay time. Results show how the proposed extensions result in a
significant improvement over the baseline model, especially for the case of
non-convex geometries or the case of unevenly distributed wall absorption, both
scenarios of broad practical interest.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14664" title="Abstract">arXiv:2312.14664</a> [<a href="/pdf/2312.14664" title="Download PDF">pdf</a>, <a href="/format/2312.14664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Density Uncertainty Quantification with NeRF-Ensembles: Impact of Data  and Scene Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=J%C3%A4ger%2C+M">Miriam J&#xe4;ger</a>, 
<a href="/search/cs?searchtype=author&query=Landgraf%2C+S">Steven Landgraf</a>, 
<a href="/search/cs?searchtype=author&query=Jutzi%2C+B">Boris Jutzi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 12 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the fields of computer graphics, computer vision and photogrammetry,
Neural Radiance Fields (NeRFs) are a major topic driving current research and
development. However, the quality of NeRF-generated 3D scene reconstructions
and subsequent surface reconstructions, heavily relies on the network output,
particularly the density. Regarding this critical aspect, we propose to utilize
NeRF-Ensembles that provide a density uncertainty estimate alongside the mean
density. We demonstrate that data constraints such as low-quality images and
poses lead to a degradation of the training process, increased density
uncertainty and decreased predicted density. Even with high-quality input data,
the density uncertainty varies based on scene constraints such as acquisition
constellations, occlusions and material properties. NeRF-Ensembles not only
provide a tool for quantifying the uncertainty but exhibit two promising
advantages: Enhanced robustness and artifact removal. Through the utilization
of NeRF-Ensembles instead of single NeRFs, small outliers are removed, yielding
a smoother output with improved completeness of structures. Furthermore,
applying percentile-based thresholds on density uncertainty outliers proves to
be effective for the removal of large (foggy) artifacts in post-processing. We
conduct our methodology on 3 different datasets: (i) synthetic benchmark
dataset, (ii) real benchmark dataset, (iii) real data under realistic recording
conditions and sensors.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14667" title="Abstract">arXiv:2312.14667</a> [<a href="/pdf/2312.14667" title="Download PDF">pdf</a>, <a href="/format/2312.14667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Token-Level Contrastive Learning with Modality-Aware Prompting for  Multimodal Intent Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qianrui Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hua Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanlei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaohan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+K">Kai Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024 (Main Track, Long Paper)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Multimodal intent recognition aims to leverage diverse modalities such as
expressions, body movements and tone of speech to comprehend user's intent,
constituting a critical task for understanding human language and behavior in
real-world multimodal scenarios. Nevertheless, the majority of existing methods
ignore potential correlations among different modalities and own limitations in
effectively learning semantic features from nonverbal modalities. In this
paper, we introduce a token-level contrastive learning method with
modality-aware prompting (TCL-MAP) to address the above challenges. To
establish an optimal multimodal semantic environment for text modality, we
develop a modality-aware prompting module (MAP), which effectively aligns and
fuses features from text, video and audio modalities with similarity-based
modality alignment and cross-modality attention mechanism. Based on the
modality-aware prompt and ground truth labels, the proposed token-level
contrastive learning framework (TCL) constructs augmented samples and employs
NT-Xent loss on the label token. Specifically, TCL capitalizes on the optimal
textual semantic insights derived from intent labels to guide the learning
processes of other modalities in return. Extensive experiments show that our
method achieves remarkable improvements compared to state-of-the-art methods.
Additionally, ablation analyses demonstrate the superiority of the
modality-aware prompt over the handcrafted prompt, which holds substantial
significance for multimodal prompt learning. The codes are released at
https://github.com/thuiar/TCL-MAP.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14670" title="Abstract">arXiv:2312.14670</a> [<a href="/pdf/2312.14670" title="Download PDF">pdf</a>, <a href="/format/2312.14670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-shot Causal Graph Extrapolation from Text via LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Antonucci%2C+A">Alessandro Antonucci</a>, 
<a href="/search/cs?searchtype=author&query=Piqu%C3%A9%2C+G">Gregorio Piqu&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Zaffalon%2C+M">Marco Zaffalon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> XAI4Sci Workshop @ AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">We evaluate the ability of large language models (LLMs) to infer causal
relations from natural language. Compared to traditional natural language
processing and deep learning techniques, LLMs show competitive performance in a
benchmark of pairwise relations without needing (explicit) training samples.
This motivates us to extend our approach to extrapolating causal graphs through
iterated pairwise queries. We perform a preliminary analysis on a benchmark of
biomedical abstracts with ground-truth causal graphs validated by experts. The
results are promising and support the adoption of LLMs for such a crucial step
in causal inference, especially in medical domains, where the amount of
scientific text to analyse might be huge, and the causal statements are often
implicit.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14674" title="Abstract">arXiv:2312.14674</a> [<a href="/pdf/2312.14674" title="Download PDF">pdf</a>, <a href="/ps/2312.14674" title="Download PostScript">ps</a>, <a href="/format/2312.14674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error-Correction Performance of Regular Ring-Linear LDPC Codes over Lee  Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bariffi%2C+J">Jessica Bariffi</a>, 
<a href="/search/cs?searchtype=author&query=Bartz%2C+H">Hannes Bartz</a>, 
<a href="/search/cs?searchtype=author&query=Liva%2C+G">Gianluigi Liva</a>, 
<a href="/search/cs?searchtype=author&query=Rosenthal%2C+J">Joachim Rosenthal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Most low-density parity-check (LDPC) code constructions are considered over
finite fields. In this work, we focus on regular LDPC codes over integer
residue rings and analyze their performance with respect to the Lee metric.
Their error-correction performance is studied over two channel models, in the
Lee metric. The first channel model is a discrete memoryless channel, whereas
in the second channel model an error vector is drawn uniformly at random from
all vectors of a fixed Lee weight. It is known that the two channel laws
coincide in the asymptotic regime, meaning that their marginal distributions
match. For both channel models, we derive upper bounds on the block error
probability in terms of a random coding union bound as well as sphere packing
bounds that make use of the marginal distribution of the considered channels.
We estimate the decoding error probability of regular LDPC code ensembles over
the channels using the marginal distribution and determining the expected Lee
weight distribution of a random LDPC code over a finite integer ring. By means
of density evolution and finite-length simulations, we estimate the
error-correction performance of selected LDPC code ensembles under belief
propagation decoding and a low-complexity symbol message passing decoding
algorithm and compare the performances.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14676" title="Abstract">arXiv:2312.14676</a> [<a href="/pdf/2312.14676" title="Download PDF">pdf</a>, <a href="/format/2312.14676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Capitalizing on Next-Generation Optical Communication Systems with  Proactive Multi-Period Network Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+J">Jasper M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Patri%2C+S+K">Sai Kireet Patri</a>, 
<a href="/search/cs?searchtype=author&query=Di+Rosa%2C+G">Gabriele Di Rosa</a>, 
<a href="/search/cs?searchtype=author&query=Autenrieth%2C+A">Achim Autenrieth</a>, 
<a href="/search/cs?searchtype=author&query=Elbers%2C+J">J&#xf6;rg-Peter Elbers</a>, 
<a href="/search/cs?searchtype=author&query=Mas-Machuca%2C+C">Carmen Mas-Machuca</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The work has been partially funded by the German Federal Ministry of Education and Research in the project STARFALL (16KIS1418K)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> European Conference on Optical Communications (ECOC) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Optical transport network operators typically follow a pay-as-you-grow
strategy for their network deployment. We propose a proactive multi-period
planning approach based on heuristic network planning, supporting this
deployment strategy while enabling efficient network utilization through
next-generation technology. We report 60% less provisioned lightpaths.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14677" title="Abstract">arXiv:2312.14677</a> [<a href="/pdf/2312.14677" title="Download PDF">pdf</a>, <a href="/format/2312.14677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MEAOD: Model Extraction Attack against Object Detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zeyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chenghui Shi</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+Y">Yuwen Pu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yu Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinbao Li</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shouling Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The widespread use of deep learning technology across various industries has
made deep neural network models highly valuable and, as a result, attractive
targets for potential attackers. Model extraction attacks, particularly
query-based model extraction attacks, allow attackers to replicate a substitute
model with comparable functionality to the victim model and present a
significant threat to the confidentiality and security of MLaaS platforms.
While many studies have explored threats of model extraction attacks against
classification models in recent years, object detection models, which are more
frequently used in real-world scenarios, have received less attention. In this
paper, we investigate the challenges and feasibility of query-based model
extraction attacks against object detection models and propose an effective
attack method called MEAOD. It selects samples from the attacker-possessed
dataset to construct an efficient query dataset using active learning and
enhances the categories with insufficient objects. We additionally improve the
extraction effectiveness by updating the annotations of the query dataset.
According to our gray-box and black-box scenarios experiments, we achieve an
extraction performance of over 70% under the given condition of a 10k query
budget.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14681" title="Abstract">arXiv:2312.14681</a> [<a href="/pdf/2312.14681" title="Download PDF">pdf</a>, <a href="/format/2312.14681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Engineered Ordinary Differential Equations as Classification Algorithm  (EODECA): thorough characterization and testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marino%2C+R">Raffaele Marino</a>, 
<a href="/search/cs?searchtype=author&query=Buffoni%2C+L">Lorenzo Buffoni</a>, 
<a href="/search/cs?searchtype=author&query=Chicchi%2C+L">Lorenzo Chicchi</a>, 
<a href="/search/cs?searchtype=author&query=Giambagli%2C+L">Lorenzo Giambagli</a>, 
<a href="/search/cs?searchtype=author&query=Fanelli%2C+D">Duccio Fanelli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Statistical Mechanics (cond-mat.stat-mech); Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Pattern Formation and Solitons (nlin.PS)

</div>
<p class="mathjax">EODECA (Engineered Ordinary Differential Equations as Classification
Algorithm) is a novel approach at the intersection of machine learning and
dynamical systems theory, presenting a unique framework for classification
tasks [1]. This method stands out with its dynamical system structure,
utilizing ordinary differential equations (ODEs) to efficiently handle complex
classification challenges. The paper delves into EODECA's dynamical properties,
emphasizing its resilience against random perturbations and robust performance
across various classification scenarios. Notably, EODECA's design incorporates
the ability to embed stable attractors in the phase space, enhancing
reliability and allowing for reversible dynamics. In this paper, we carry out a
comprehensive analysis by expanding on the work [1], and employing a Euler
discretization scheme. In particular, we evaluate EODECA's performance across
five distinct classification problems, examining its adaptability and
efficiency. Significantly, we demonstrate EODECA's effectiveness on the MNIST
and Fashion MNIST datasets, achieving impressive accuracies of $98.06\%$ and
$88.21\%$, respectively. These results are comparable to those of a multi-layer
perceptron (MLP), underscoring EODECA's potential in complex data processing
tasks. We further explore the model's learning journey, assessing its evolution
in both pre and post training environments and highlighting its ability to
navigate towards stable attractors. The study also investigates the
invertibility of EODECA, shedding light on its decision-making processes and
internal workings. This paper presents a significant step towards a more
transparent and robust machine learning paradigm, bridging the gap between
machine learning algorithms and dynamical systems methodologies.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14687" title="Abstract">arXiv:2312.14687</a> [<a href="/pdf/2312.14687" title="Download PDF">pdf</a>, <a href="/format/2312.14687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cybersecurity in Motion: A Survey of Challenges and Requirements for  Future Test Facilities of CAVs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mavromatis%2C+I">Ioannis Mavromatis</a>, 
<a href="/search/cs?searchtype=author&query=Spyridopoulos%2C+T">Theodoros Spyridopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Carnelli%2C+P">Pietro Carnelli</a>, 
<a href="/search/cs?searchtype=author&query=Chin%2C+W+H">Woon Hau Chin</a>, 
<a href="/search/cs?searchtype=author&query=Khalil%2C+A">Ahmed Khalil</a>, 
<a href="/search/cs?searchtype=author&query=Chakravarty%2C+J">Jennifer Chakravarty</a>, 
<a href="/search/cs?searchtype=author&query=Kun%2C+L+C">Lucia Cipolina Kun</a>, 
<a href="/search/cs?searchtype=author&query=Piechocki%2C+R+J">Robert J. Piechocki</a>, 
<a href="/search/cs?searchtype=author&query=Robbins%2C+C">Colin Robbins</a>, 
<a href="/search/cs?searchtype=author&query=Cunnington%2C+D">Daniel Cunnington</a>, 
<a href="/search/cs?searchtype=author&query=Chase%2C+L">Leigh Chase</a>, 
<a href="/search/cs?searchtype=author&query=Chiazor%2C+L">Lamogha Chiazor</a>, 
<a href="/search/cs?searchtype=author&query=Preston%2C+C">Chris Preston</a>, 
<a href="/search/cs?searchtype=author&query=Rahul">Rahul</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Aftab Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at EAI Endorsed Transactions on Industrial Networks and Intelligent Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">The way we travel is changing rapidly, and Cooperative Intelligent
Transportation Systems (C-ITSs) are at the forefront of this evolution.
However, the adoption of C-ITSs introduces new risks and challenges, making
cybersecurity a top priority for ensuring safety and reliability. Building on
this premise, this paper presents an envisaged Cybersecurity Centre of
Excellence (CSCE) designed to bolster research, testing, and evaluation of the
cybersecurity of C-ITSs. We explore the design, functionality, and challenges
of CSCE's testing facilities, outlining the technological, security, and
societal requirements. Through a thorough survey and analysis, we assess the
effectiveness of these systems in detecting and mitigating potential threats,
highlighting their flexibility to adapt to future C-ITSs. Finally, we identify
current unresolved challenges in various C-ITS domains, with the aim of
motivating further research into the cybersecurity of C-ITSs.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14688" title="Abstract">arXiv:2312.14688</a> [<a href="/pdf/2312.14688" title="Download PDF">pdf</a>, <a href="/format/2312.14688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Mathematical Guide to Operator Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Boull%C3%A9%2C+N">Nicolas Boull&#xe9;</a>, 
<a href="/search/math?searchtype=author&query=Townsend%2C+A">Alex Townsend</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Operator learning aims to discover properties of an underlying dynamical
system or partial differential equation (PDE) from data. Here, we present a
step-by-step guide to operator learning. We explain the types of problems and
PDEs amenable to operator learning, discuss various neural network
architectures, and explain how to employ numerical PDE solvers effectively. We
also give advice on how to create and manage training data and conduct
optimization. We offer intuition behind the various neural network
architectures employed in operator learning by motivating them from the
point-of-view of numerical linear algebra.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14697" title="Abstract">arXiv:2312.14697</a> [<a href="/pdf/2312.14697" title="Download PDF">pdf</a>, <a href="/format/2312.14697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pola4All: survey of polarimetric applications and an open-source toolkit  to analyze polarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+J">Joaquin Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Lew-Yan-Voon%2C+L">Lew-Fock-Chong Lew-Yan-Voon</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+R">Renato Martins</a>, 
<a href="/search/cs?searchtype=author&query=Morel%2C+O">Olivier Morel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Polarization information of the light can provide rich cues for computer
vision and scene understanding tasks, such as the type of material, pose, and
shape of the objects. With the advent of new and cheap polarimetric sensors,
this imaging modality is becoming accessible to a wider public for solving
problems such as pose estimation, 3D reconstruction, underwater navigation, and
depth estimation. However, we observe several limitations regarding the usage
of this sensorial modality, as well as a lack of standards and publicly
available tools to analyze polarization images. Furthermore, although
polarization camera manufacturers usually provide acquisition tools to
interface with their cameras, they rarely include processing algorithms that
make use of the polarization information. In this paper, we review recent
advances in applications that involve polarization imaging, including a
comprehensive survey of recent advances on polarization for vision and robotics
perception tasks. We also introduce a complete software toolkit that provides
common standards to communicate with and process information from most of the
existing micro-grid polarization cameras on the market. The toolkit also
implements several image processing algorithms for this modality, and it is
publicly available on GitHub: https://github.com/vibot-lab/Pola4all_JEI_2023.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14698" title="Abstract">arXiv:2312.14698</a> [<a href="/pdf/2312.14698" title="Download PDF">pdf</a>, <a href="/format/2312.14698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-changed normalizing flows for accurate SDE modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bekri%2C+N+E">Naoufal El Bekri</a>, 
<a href="/search/cs?searchtype=author&query=Drumetz%2C+L">Lucas Drumetz</a>, 
<a href="/search/cs?searchtype=author&query=Vermet%2C+F">Franck Vermet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">The generative paradigm has become increasingly important in machine learning
and deep learning models. Among popular generative models are normalizing
flows, which enable exact likelihood estimation by transforming a base
distribution through diffeomorphic transformations. Extending the normalizing
flow framework to handle time-indexed flows gave dynamic normalizing flows, a
powerful tool to model time series, stochastic processes, and neural stochastic
differential equations (SDEs). In this work, we propose a novel variant of
dynamic normalizing flows, a Time Changed Normalizing Flow (TCNF), based on
time deformation of a Brownian motion which constitutes a versatile and
extensive family of Gaussian processes. This approach enables us to effectively
model some SDEs, that cannot be modeled otherwise, including standard ones such
as the well-known Ornstein-Uhlenbeck process, and generalizes prior
methodologies, leading to improved results and better inference and prediction
capability.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14706" title="Abstract">arXiv:2312.14706</a> [<a href="/pdf/2312.14706" title="Download PDF">pdf</a>, <a href="/format/2312.14706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BonnBeetClouds3D: A Dataset Towards Point Cloud-based Organ-level  Phenotyping of Sugar Beet Plants under Field Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marks%2C+E">Elias Marks</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%B6mer%2C+J">Jonas B&#xf6;mer</a>, 
<a href="/search/cs?searchtype=author&query=Magistri%2C+F">Federico Magistri</a>, 
<a href="/search/cs?searchtype=author&query=Sah%2C+A">Anurag Sah</a>, 
<a href="/search/cs?searchtype=author&query=Behley%2C+J">Jens Behley</a>, 
<a href="/search/cs?searchtype=author&query=Stachniss%2C+C">Cyrill Stachniss</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Agricultural production is facing severe challenges in the next decades
induced by climate change and the need for sustainability, reducing its impact
on the environment. Advancements in field management through non-chemical
weeding by robots in combination with monitoring of crops by autonomous
unmanned aerial vehicles (UAVs) and breeding of novel and more resilient crop
varieties are helpful to address these challenges. The analysis of plant
traits, called phenotyping, is an essential activity in plant breeding, it
however involves a great amount of manual labor. With this paper, we address
the problem of automatic fine-grained organ-level geometric analysis needed for
precision phenotyping. As the availability of real-world data in this domain is
relatively scarce, we propose a novel dataset that was acquired using UAVs
capturing high-resolution images of a real breeding trial containing 48 plant
varieties and therefore covering great morphological and appearance diversity.
This enables the development of approaches for autonomous phenotyping that
generalize well to different varieties. Based on overlapping high-resolution
images from multiple viewing angles, we compute photogrammetric dense point
clouds and provide detailed and accurate point-wise labels for plants, leaves,
and salient points as the tip and the base. Additionally, we include
measurements of phenotypic traits performed by experts from the German Federal
Plant Variety Office on the real plants, allowing the evaluation of new
approaches not only on segmentation and keypoint detection but also directly on
the downstream tasks. The provided labeled point clouds enable fine-grained
plant analysis and support further progress in the development of automatic
phenotyping approaches, but also enable further research in surface
reconstruction, point cloud completion, and semantic interpretation of point
clouds.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14708" title="Abstract">arXiv:2312.14708</a> [<a href="/pdf/2312.14708" title="Download PDF">pdf</a>, <a href="/format/2312.14708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balancing the Style-Content Trade-Off in Sentiment Transfer Using  Polarity-Aware Denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+S">Sourabrata Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Kasner%2C+Z">Zden&#x11b;k Kasner</a>, 
<a href="/search/cs?searchtype=author&query=Du%C5%A1ek%2C+O">Ond&#x159;ej Du&#x161;ek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in 25th International Conference on Text, Speech and Dialogue (TSD 2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Text sentiment transfer aims to flip the sentiment polarity of a sentence
(positive to negative or vice versa) while preserving its sentiment-independent
content. Although current models show good results at changing the sentiment,
content preservation in transferred sentences is insufficient. In this paper,
we present a sentiment transfer model based on polarity-aware denoising, which
accurately controls the sentiment attributes in generated text, preserving the
content to a great extent and helping to balance the style-content trade-off.
Our proposed model is structured around two key stages in the sentiment
transfer process: better representation learning using a shared encoder and
sentiment-controlled generation using separate sentiment-specific decoders.
Empirical results show that our methods outperforms state-of-the-art baselines
in terms of content preservation while staying competitive in terms of style
transfer accuracy and fluency.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14712" title="Abstract">arXiv:2312.14712</a> [<a href="/pdf/2312.14712" title="Download PDF">pdf</a>, <a href="/format/2312.14712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Machines Learn Robustly, Privately, and Efficiently?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Allouah%2C+Y">Youssef Allouah</a>, 
<a href="/search/cs?searchtype=author&query=Guerraoui%2C+R">Rachid Guerraoui</a>, 
<a href="/search/cs?searchtype=author&query=Stephan%2C+J">John Stephan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">The success of machine learning (ML) applications relies on vast datasets and
distributed architectures, which, as they grow, present challenges for ML. In
real-world scenarios, where data often contains sensitive information, issues
like data poisoning and hardware failures are common. Ensuring privacy and
robustness is vital for the broad adoption of ML in public life. This paper
examines the costs associated with achieving these objectives in distributed
architectures. We overview the meanings of privacy and robustness in
distributed ML, and clarify how they can be achieved efficiently in isolation.
However, we contend that the integration of these objectives entails a notable
compromise in computational efficiency. We delve into this intricate balance,
exploring the challenges and solutions for privacy, robustness, and
computational efficiency in ML applications.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14713" title="Abstract">arXiv:2312.14713</a> [<a href="/pdf/2312.14713" title="Download PDF">pdf</a>, <a href="/format/2312.14713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inverse Transfer Multiobjective Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhishek Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Ong%2C+Y">Yew-Soon Ong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Transfer optimization enables data-efficient optimization of a target task by
leveraging experiential priors from related source tasks. This is especially
useful in multiobjective optimization settings where a set of trade-off
solutions is sought under tight evaluation budgets. In this paper, we introduce
a novel concept of inverse transfer in multiobjective optimization. Inverse
transfer stands out by employing probabilistic inverse models to map
performance vectors in the objective space to population search distributions
in task-specific decision space, facilitating knowledge transfer through
objective space unification. Building upon this idea, we introduce the first
Inverse Transfer Multiobjective Evolutionary Optimizer (invTrEMO). A key
highlight of invTrEMO is its ability to harness the common objective functions
prevalent in many application areas, even when decision spaces do not precisely
align between tasks. This allows invTrEMO to uniquely and effectively utilize
information from heterogeneous source tasks as well. Furthermore, invTrEMO
yields high-precision inverse models as a significant byproduct, enabling the
generation of tailored solutions on-demand based on user preferences. Empirical
studies on multi- and many-objective benchmark problems, as well as a practical
case study, showcase the faster convergence rate and modelling accuracy of the
invTrEMO relative to state-of-the-art evolutionary and Bayesian optimization
algorithms. The source code of the invTrEMO is made available at
https://github.com/LiuJ-2023/invTrEMO.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14715" title="Abstract">arXiv:2312.14715</a> [<a href="/pdf/2312.14715" title="Download PDF">pdf</a>, <a href="/format/2312.14715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resilient asynchronous primal Schur method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gbikpi-Benissan%2C+G">Guillaume Gbikpi-Benissan</a>, 
<a href="/search/math?searchtype=author&query=Magoul%C3%A8s%2C+F">Fr&#xe9;d&#xe9;ric Magoul&#xe8;s</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper introduces the application of the asynchronous iterations theory
within the framework of the primal Schur domain decomposition method. A
suitable relaxation scheme is designed, which asynchronous convergence is
established under classical spectral radius conditions. For the usual case
where the local Schur complement matrices are not constructed, suitable
splittings only based on explicitly generated matrices are provided. Numerical
experiments are conducted on a supercomputer for both Poisson's and linear
elasticity problems. The asynchronous Schur solver outperformed the classical
conjugate-gradient-based one in case of compute node failures.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14716" title="Abstract">arXiv:2312.14716</a> [<a href="/pdf/2312.14716" title="Download PDF">pdf</a>, <a href="/format/2312.14716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mass lumping the dual cell method to arbitrary polynomial degree for  acoustic and electromagnetic waves
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wess%2C+M">Markus Wess</a>, 
<a href="/search/math?searchtype=author&query=Kapidani%2C+B">Bernard Kapidani</a>, 
<a href="/search/math?searchtype=author&query=Codecasa%2C+L">Lorenzo Codecasa</a>, 
<a href="/search/math?searchtype=author&query=Sch%C3%B6berl%2C+J">Joachim Sch&#xf6;berl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph)

</div>
<p class="mathjax">We present a fundamental improvement of a high polynomial degree time domain
cell method recently introduced by the last three authors. The published work
introduced a method featuring block-diagonal system matrices where the block
size and conditioning scaled poorly with respect to polynomial degree. The
issue is herein bypassed by the construction of new basis functions exploiting
quadrature rule based mass lumping techniques for arbitrary polynomial degrees
in two dimensions for the Maxwell equations and the acoustic wave equation in
the first order velocity pressure formulation. We characterize the degrees of
freedom of all new discrete approximation spaces we employ for differential
forms and show that the resulting block diagonal (inverse) mass matrices have
block sizes independent of the polynomial degree. We demonstrate on an
extensive number of examples how the new technique is applicable and efficient
for large scale computations.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14721" title="Abstract">arXiv:2312.14721</a> [<a href="/pdf/2312.14721" title="Download PDF">pdf</a>, <a href="/format/2312.14721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gerrymandering Planar Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dippel%2C+J">Jack Dippel</a>, 
<a href="/search/cs?searchtype=author&query=la+Tour%2C+M+D">Max Dupr&#xe9; la Tour</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+A">April Niu</a>, 
<a href="/search/cs?searchtype=author&query=Vetta%2C+A">Adrian Vetta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We study the computational complexity of the map redistricting problem
(gerrymandering). Mathematically, the electoral district designer
(gerrymanderer) attempts to partition a weighted graph into $k$ connected
components (districts) such that its candidate (party) wins as many districts
as possible. Prior work has principally concerned the special cases where the
graph is a path or a tree. Our focus concerns the realistic case where the
graph is planar. We prove that the gerrymandering problem is solvable in
polynomial time in $\lambda$-outerplanar graphs, when the number of candidates
and $\lambda$ are constants and the vertex weights (voting weights) are
polynomially bounded. In contrast, the problem is NP-complete in general planar
graphs even with just two candidates. This motivates the study of approximation
algorithms for gerrymandering planar graphs. However, when the number of
candidates is large, we prove it is hard to distinguish between instances where
the gerrymanderer cannot win a single district and instances where the
gerrymanderer can win at least one district. This immediately implies that the
redistricting problem is inapproximable in polynomial time in planar graphs,
unless P=NP. This conclusion appears terminal for the design of good
approximation algorithms -- but it is not. The inapproximability bound can be
circumvented as it only applies when the maximum number of districts the
gerrymanderer can win is extremely small, say one. Indeed, for a fixed number
of candidates, our main result is that there is a constant factor approximation
algorithm for redistricting unweighted planar graphs, provided the optimal
value is a large enough constant.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14723" title="Abstract">arXiv:2312.14723</a> [<a href="/pdf/2312.14723" title="Download PDF">pdf</a>, <a href="/format/2312.14723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of Project Performance in Participatory Budgeting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boehmer%2C+N">Niclas Boehmer</a>, 
<a href="/search/cs?searchtype=author&query=Faliszewski%2C+P">Piotr Faliszewski</a>, 
<a href="/search/cs?searchtype=author&query=Janeczko%2C+%C5%81">&#x141;ukasz Janeczko</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+D">Dominik Peters</a>, 
<a href="/search/cs?searchtype=author&query=Pierczy%C5%84ski%2C+G">Grzegorz Pierczy&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Schierreich%2C+%C5%A0">&#x160;imon Schierreich</a>, 
<a href="/search/cs?searchtype=author&query=Skowron%2C+P">Piotr Skowron</a>, 
<a href="/search/cs?searchtype=author&query=Szufa%2C+S">Stanis&#x142;aw Szufa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We study ways of evaluating the performance of losing projects in
participatory budgeting (PB) elections by seeking actions that would have led
to their victory. We focus on lowering the projects' costs, obtaining
additional approvals for them, and asking supporters to refrain from approving
other projects: The larger a change is needed, the less successful is the given
project. We seek efficient algorithms for computing our measures and we analyze
and compare them experimentally. We focus on the greedyAV, Phragm\'en, and
Equal-Shares PB rules.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14724" title="Abstract">arXiv:2312.14724</a> [<a href="/pdf/2312.14724" title="Download PDF">pdf</a>, <a href="/format/2312.14724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Images in Discrete Choice Modeling: Addressing Data Isomorphism in  Multi-Modality Inputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sifringer%2C+B">Brian Sifringer</a>, 
<a href="/search/cs?searchtype=author&query=Alahi%2C+A">Alexandre Alahi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 7 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper explores the intersection of Discrete Choice Modeling (DCM) and
machine learning, focusing on the integration of image data into DCM's utility
functions and its impact on model interpretability. We investigate the
consequences of embedding high-dimensional image data that shares isomorphic
information with traditional tabular inputs within a DCM framework. Our study
reveals that neural network (NN) components learn and replicate tabular
variable representations from images when co-occurrences exist, thereby
compromising the interpretability of DCM parameters. We propose and benchmark
two methodologies to address this challenge: architectural design adjustments
to segregate redundant information, and isomorphic information mitigation
through source information masking and inpainting. Our experiments, conducted
on a semi-synthetic dataset, demonstrate that while architectural modifications
prove inconclusive, direct mitigation at the data source shows to be a more
effective strategy in maintaining the integrity of DCM's interpretable
parameters. The paper concludes with insights into the applicability of our
findings in real-world settings and discusses the implications for future
research in hybrid modeling that combines complex data modalities. Full control
of tabular and image data congruence is attained by using the MIT moral machine
dataset, and both inputs are merged into a choice model by deploying the
Learning Multinomial Logit (L-MNL) framework.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14725" title="Abstract">arXiv:2312.14725</a> [<a href="/pdf/2312.14725" title="Download PDF">pdf</a>, <a href="/format/2312.14725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Text-to-SQL Translation for Financial System Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yewei Song</a>, 
<a href="/search/cs?searchtype=author&query=Ezzini%2C+S">Saad Ezzini</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xunzhu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Lothritz%2C+C">Cedric Lothritz</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+J">Jacques Klein</a>, 
<a href="/search/cs?searchtype=author&query=Bissyand%C3%A9%2C+T">Tegawend&#xe9; Bissyand&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Boytsov%2C+A">Andrey Boytsov</a>, 
<a href="/search/cs?searchtype=author&query=Ble%2C+U">Ulrick Ble</a>, 
<a href="/search/cs?searchtype=author&query=Goujon%2C+A">Anne Goujon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, ICSE-SEIP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Text-to-SQL, the task of translating natural language questions into SQL
queries, is part of various business processes. Its automation, which is an
emerging challenge, will empower software practitioners to seamlessly interact
with relational databases using natural language, thereby bridging the gap
between business needs and software capabilities. In this paper, we consider
Large Language Models (LLMs), which have achieved state of the art for various
NLP tasks. Specifically, we benchmark Text-to-SQL performance, the evaluation
methodologies, as well as input optimization (e.g., prompting). In light of the
empirical observations that we have made, we propose two novel metrics that
were designed to adequately measure the similarity between SQL queries.
Overall, we share with the community various findings, notably on how to select
the right LLM on Text-to-SQL tasks. We further demonstrate that a tree-based
edit distance constitutes a reliable metric for assessing the similarity
between generated SQL queries and the oracle for benchmarking Text2SQL
approaches. This metric is important as it relieves researchers from the need
to perform computationally expensive experiments such as executing generated
queries as done in prior works. Our work implements financial domain use cases
and, therefore contributes to the advancement of Text2SQL systems and their
practical adoption in this domain.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14730" title="Abstract">arXiv:2312.14730</a> [<a href="/pdf/2312.14730" title="Download PDF">pdf</a>, <a href="/format/2312.14730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To Fuse or Not to Fuse: Measuring Consistency in Multi-Sensor Fusion for  Aerial Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lanegger%2C+C">Christian Lanegger</a>, 
<a href="/search/cs?searchtype=author&query=Oleynikova%2C+H">Helen Oleynikova</a>, 
<a href="/search/cs?searchtype=author&query=Pantic%2C+M">Michael Pantic</a>, 
<a href="/search/cs?searchtype=author&query=Ott%2C+L">Lionel Ott</a>, 
<a href="/search/cs?searchtype=author&query=Siegwart%2C+R">Roland Siegwart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted and presented at the 18th International Symposium on Experimental Robotics (ISER 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Aerial vehicles are no longer limited to flying in open space: recent work
has focused on aerial manipulation and up-close inspection. Such applications
place stringent requirements on state estimation: the robot must combine state
information from many sources, including onboard odometry and global
positioning sensors. However, flying close to or in contact with structures is
a degenerate case for many sensing modalities, and the robot's state estimation
framework must intelligently choose which sensors are currently trustworthy. We
evaluate a number of metrics to judge the reliability of sensing modalities in
a multi-sensor fusion framework, then introduce a consensus-finding scheme that
uses this metric to choose which sensors to fuse or not to fuse. Finally, we
show that such a fusion framework is more robust and accurate than fusing all
sensors all the time and demonstrate how such metrics can be informative in
real-world experiments in indoor-outdoor flight and bridge inspection.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14733" title="Abstract">arXiv:2312.14733</a> [<a href="/pdf/2312.14733" title="Download PDF">pdf</a>, <a href="/format/2312.14733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing Diffusion Models for Visual Perception with Meta Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Q">Qiang Wan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zilong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+B">Bingyi Kang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiashi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The issue of generative pretraining for vision models has persisted as a
long-standing conundrum. At present, the text-to-image (T2I) diffusion model
demonstrates remarkable proficiency in generating high-definition images
matching textual inputs, a feat made possible through its pre-training on
large-scale image-text pairs. This leads to a natural inquiry: can diffusion
models be utilized to tackle visual perception tasks? In this paper, we propose
a simple yet effective scheme to harness a diffusion model for visual
perception tasks. Our key insight is to introduce learnable embeddings (meta
prompts) to the pre-trained diffusion models to extract proper features for
perception. The effect of meta prompts are two-fold. First, as a direct
replacement of the text embeddings in the T2I models, it can activate
task-relevant features during feature extraction. Second, it will be used to
re-arrange the extracted features to ensures that the model focuses on the most
pertinent features for the task on hand. Additionally, we design a recurrent
refinement training strategy that fully leverages the property of diffusion
models, thereby yielding stronger visual features. Extensive experiments across
various benchmarks validate the effectiveness of our approach. Our approach
achieves new performance records in depth estimation tasks on NYU depth V2 and
KITTI, and in semantic segmentation task on CityScapes. Concurrently, the
proposed method attains results comparable to the current state-of-the-art in
semantic segmentation on ADE20K and pose estimation on COCO datasets, further
exemplifying its robustness and versatility.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14737" title="Abstract">arXiv:2312.14737</a> [<a href="/pdf/2312.14737" title="Download PDF">pdf</a>, <a href="/ps/2312.14737" title="Download PostScript">ps</a>, <a href="/format/2312.14737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational Semantics and Evaluation Benchmark for Interrogative  Sentences via Combinatory Categorial Grammar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Funakura%2C+H">Hayate Funakura</a>, 
<a href="/search/cs?searchtype=author&query=Mineshima%2C+K">Koji Mineshima</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, to appear in the Proceedings of PACLIC37
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">We present a compositional semantics for various types of polar questions and
wh-questions within the framework of Combinatory Categorial Grammar (CCG). To
assess the explanatory power of our proposed analysis, we introduce a
question-answering dataset QSEM specifically designed to evaluate the semantics
of interrogative sentences. We implement our analysis using existing CCG
parsers and conduct evaluations using the dataset. Through the evaluation, we
have obtained annotated data with CCG trees and semantic representations for
about half of the samples included in QSEM. Furthermore, we discuss the
discrepancy between the theoretical capacity of CCG and the capabilities of
existing CCG parsers.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14743" title="Abstract">arXiv:2312.14743</a> [<a href="/pdf/2312.14743" title="Download PDF">pdf</a>, <a href="/ps/2312.14743" title="Download PostScript">ps</a>, <a href="/format/2312.14743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterated Entropy Derivatives and Binary Entropy Inequalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wakhare%2C+T">Tanay Wakhare</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Combinatorics (math.CO); Number Theory (math.NT)

</div>
<p class="mathjax">We embark on a systematic study of the $(k+1)$-th derivative of
$x^{k-r}H(x^r)$, where $H(x):=-x\log x-(1-x)\log(1-x)$ is the binary entropy
and $k&gt;r\geq 1$ are integers. Our motivation is the conjectural entropy
inequality $\alpha_k H(x^k)\geq x^{k-1}H(x)$, where $0&lt;\alpha_k&lt;1$ is given by
a functional equation. The $k=2$ case was the key technical tool driving recent
breakthroughs on the union-closed sets conjecture. We express $
\frac{d^{k+1}}{dx^{k+1}}x^{k-r}H(x^r)$ as a rational function, an infinite
series, and a sum over generalized Stirling numbers. This allows us to reduce
the proof of the entropy inequality for real $k$ to showing that an associated
polynomial has only two real roots in the interval $(0,1)$, which also allows
us to prove the inequality for fractional exponents such as $k=3/2$. The proof
suggests a new framework for proving tight inequalities for the sum of
polynomials times the logarithms of polynomials, which converts the inequality
into a statement about the real roots of a simpler associated polynomial.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14745" title="Abstract">arXiv:2312.14745</a> [<a href="/pdf/2312.14745" title="Download PDF">pdf</a>, <a href="/ps/2312.14745" title="Download PostScript">ps</a>, <a href="/format/2312.14745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strengthening Nash Equilibria
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geffner%2C+I">Ivan Geffner</a>, 
<a href="/search/cs?searchtype=author&query=Tennenholtz%2C+M">Moshe Tennenholtz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Nash equilibrium is often heralded as a guiding principle for rational
decision-making in strategic interactions. However, it is well-known that Nash
equilibrium sometimes fails as a reliable predictor of outcomes, with two of
the most notable issues being the fact that it is not resilient to collusion
and that there may be multiple Nash equilibria in a single game. In this paper,
we show that a mechanism designer can get around these two issues for free by
expanding the action sets of the original game. More precisely, given a
normal-form or Bayesian game $\Gamma$ and a Nash equilibrium $\vec{\sigma}$ in
$\Gamma$, a mechanism designer can construct a new game $\Gamma^{\vec{\sigma}}$
by expanding the action set of each player and defining appropriate utilities
in the action profiles that were not already in the original game. We show that
the designer can construct $\Gamma^{\vec{\sigma}}$ in such a way that (a)
$\vec{\sigma}$ is a semi-strong Nash equilibrium of $\Gamma^{\vec{\sigma}}$,
and (b) $\vec{\sigma}$ Pareto-dominates or quasi Pareto-dominates all other
Nash equilibria of $\Gamma^{\vec{\sigma}}$.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14746" title="Abstract">arXiv:2312.14746</a> [<a href="/pdf/2312.14746" title="Download PDF">pdf</a>, <a href="/ps/2312.14746" title="Download PostScript">ps</a>, <a href="/format/2312.14746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ESBMC v7.4: Harnessing the Power of Intervals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Menezes%2C+R">Rafael Menezes</a>, 
<a href="/search/cs?searchtype=author&query=Aldughaim%2C+M">Mohannad Aldughaim</a>, 
<a href="/search/cs?searchtype=author&query=Farias%2C+B">Bruno Farias</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xianzhiyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Manino%2C+E">Edoardo Manino</a>, 
<a href="/search/cs?searchtype=author&query=Shmarov%2C+F">Fedor Shmarov</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kunjian Song</a>, 
<a href="/search/cs?searchtype=author&query=Brau%C3%9Fe%2C+F">Franz Brau&#xdf;e</a>, 
<a href="/search/cs?searchtype=author&query=Gadelha%2C+M+R">Mikhail R. Gadelha</a>, 
<a href="/search/cs?searchtype=author&query=Tihanyi%2C+N">Norbert Tihanyi</a>, 
<a href="/search/cs?searchtype=author&query=Korovin%2C+K">Konstantin Korovin</a>, 
<a href="/search/cs?searchtype=author&query=Cordeiro%2C+L+C">Lucas C. Cordeiro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">ESBMC implements many state-of-the-art techniques for model checking. We
report on new and improved features that allow us to obtain verification
results for previously unsupported programs and properties. ESBMC employs a new
static interval analysis of expressions in programs to increase verification
performance. This includes interval-based reasoning over booleans and integers,
forward and backward contractors, and particular optimizations related to
singleton intervals because of their ubiquity. Other relevant improvements
concern the verification of concurrent programs, as well as several operational
models, internal ones, and also those of libraries such as pthread and the C
mathematics library. An extended memory safety analysis now allows tracking of
memory leaks that are considered still reachable.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14748" title="Abstract">arXiv:2312.14748</a> [<a href="/pdf/2312.14748" title="Download PDF">pdf</a>, <a href="/format/2312.14748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Progressing from Anomaly Detection to Automated Log Labeling and  Pioneering Root Cause Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wittkopp%2C+T">Thorsten Wittkopp</a>, 
<a href="/search/cs?searchtype=author&query=Acker%2C+A">Alexander Acker</a>, 
<a href="/search/cs?searchtype=author&query=Kao%2C+O">Odej Kao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at AIOPS workshop @ICDM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">The realm of AIOps is transforming IT landscapes with the power of AI and ML.
Despite the challenge of limited labeled data, supervised models show promise,
emphasizing the importance of leveraging labels for training, especially in
deep learning contexts. This study enhances the field by introducing a taxonomy
for log anomalies and exploring automated data labeling to mitigate labeling
challenges. It goes further by investigating the potential of diverse anomaly
detection techniques and their alignment with specific anomaly types. However,
the exploration doesn't stop at anomaly detection. The study envisions a future
where root cause analysis follows anomaly detection, unraveling the underlying
triggers of anomalies. This uncharted territory holds immense potential for
revolutionizing IT systems management. In essence, this paper enriches our
understanding of anomaly detection, and automated labeling, and sets the stage
for transformative root cause analysis. Together, these advances promise more
resilient IT systems, elevating operational efficiency and user satisfaction in
an ever-evolving technological landscape.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14749" title="Abstract">arXiv:2312.14749</a> [<a href="/pdf/2312.14749" title="Download PDF">pdf</a>, <a href="/format/2312.14749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Row-Merged Polar Codes: Analysis, Design and Decoder Implementation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zunker%2C+A">Andreas Zunker</a>, 
<a href="/search/cs?searchtype=author&query=Geiselhart%2C+M">Marvin Geiselhart</a>, 
<a href="/search/cs?searchtype=author&query=Johannsen%2C+L">Lucas Johannsen</a>, 
<a href="/search/cs?searchtype=author&query=Kestel%2C+C">Claus Kestel</a>, 
<a href="/search/cs?searchtype=author&query=Brink%2C+S+t">Stephan ten Brink</a>, 
<a href="/search/cs?searchtype=author&query=Vogt%2C+T">Timo Vogt</a>, 
<a href="/search/cs?searchtype=author&query=Wehn%2C+N">Norbert Wehn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures, Submitted to IEEE for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Row-merged polar codes are a family of pre-transformed polar codes (PTPCs)
with little precoding overhead. Providing an improved distance spectrum over
plain polar codes, they are capable to perform close to the finite-length
capacity bounds. However, there is still a lack of efficient design procedures
for row-merged polar codes. Using novel weight enumeration algorithms with low
computational complexity, we propose a design methodology for row-merged polar
codes that directly considers their minimum distance properties. The codes
significantly outperform state-of-the-art cyclic redundancy check (CRC)-aided
polar codes under successive cancellation list (SCL) decoding in
error-correction performance. Furthermore, we present fast simplified
successive cancellation list (Fast-SSCL) decoding of PTPCs, based on which we
derive a high-throughput, unrolled architecture template for fully pipelined
decoders. Implementation results of SCL decoders for row-merged polar codes in
a 12 nm technology additionally demonstrate the superiority of these codes with
respect to the implementation costs, compared to state-of-the-art reference
decoder implementations.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14750" title="Abstract">arXiv:2312.14750</a> [<a href="/pdf/2312.14750" title="Download PDF">pdf</a>, <a href="/format/2312.14750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Siracusa: A 16 nm Heterogenous RISC-V SoC for Extended Reality with  At-MRAM Neural Engine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prasad%2C+A+S">Arpan Suravi Prasad</a>, 
<a href="/search/cs?searchtype=author&query=Scherer%2C+M">Moritz Scherer</a>, 
<a href="/search/cs?searchtype=author&query=Conti%2C+F">Francesco Conti</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+D">Davide Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Di+Mauro%2C+A">Alfio Di Mauro</a>, 
<a href="/search/cs?searchtype=author&query=Eggimann%2C+M">Manuel Eggimann</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez%2C+J+T">Jorge T&#xf3;mas G&#xf3;mez</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziyun Li</a>, 
<a href="/search/cs?searchtype=author&query=Sarwar%2C+S+S">Syed Shakib Sarwar</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=De+Salvo%2C+B">Barbara De Salvo</a>, 
<a href="/search/cs?searchtype=author&query=Benini%2C+L">Luca Benini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-print manuscript submitted for review to the IEEE Journal of Solid-State Circuits
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Extended reality (XR) applications are Machine Learning (ML)-intensive,
featuring deep neural networks (DNNs) with millions of weights, tightly
latency-bound (10-20 ms end-to-end), and power-constrained (low tens of mW).
While ML performance and efficiency can be achieved by introducing neural
engines within low-power systems-on-chip (SoCs), system-level power for
nontrivial DNNs depends strongly on the energy of non-volatile memory (NVM)
access for network weights. This work introduces Siracusa, a near-sensor
heterogeneous SoC for next-generation XR devices manufactured in 16 nm CMOS.
Siracusa couples an octa-core cluster of RISC-V digital signal processing cores
with a novel tightly-coupled "At-Memory" integration between a state-of-the-art
digital neural engine called N-EUREKA and an on-chip NVM based on
magnetoresistive memory(MRAM), achieving 1.7x higher throughput and 4.1x better
energy efficiency than XR SoCs using MRAM as background memory. The fabricated
SoC prototype achieves an area efficiency of 65.2 GOp/s/mm2 and a peak energy
efficiency of 8.84 TOp/J for DNN inference while supporting complex
heterogeneous application workloads, which combine ML with conventional signal
processing and control.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14751" title="Abstract">arXiv:2312.14751</a> [<a href="/pdf/2312.14751" title="Download PDF">pdf</a>, <a href="/format/2312.14751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hazards from Increasingly Accessible Fine-Tuning of Downloadable  Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chan%2C+A">Alan Chan</a>, 
<a href="/search/cs?searchtype=author&query=Bucknall%2C+B">Ben Bucknall</a>, 
<a href="/search/cs?searchtype=author&query=Bradley%2C+H">Herbie Bradley</a>, 
<a href="/search/cs?searchtype=author&query=Krueger%2C+D">David Krueger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a spotlight workshop paper at the Socially Responsible Language Modelling Research (SoLaR) workshop, held at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Public release of the weights of pretrained foundation models, otherwise
known as downloadable access \citep{solaiman_gradient_2023}, enables
fine-tuning without the prohibitive expense of pretraining. Our work argues
that increasingly accessible fine-tuning of downloadable models may increase
hazards. First, we highlight research to improve the accessibility of
fine-tuning. We split our discussion into research that A) reduces the
computational cost of fine-tuning and B) improves the ability to share that
cost across more actors. Second, we argue that increasingly accessible
fine-tuning methods may increase hazard through facilitating malicious use and
making oversight of models with potentially dangerous capabilities more
difficult. Third, we discuss potential mitigatory measures, as well as benefits
of more accessible fine-tuning. Given substantial remaining uncertainty about
hazards, we conclude by emphasizing the urgent need for the development of
mitigations.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14756" title="Abstract">arXiv:2312.14756</a> [<a href="/pdf/2312.14756" title="Download PDF">pdf</a>, <a href="/format/2312.14756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data augmentation for the POD formulation of the parametric laminar  incompressible Navier-Stokes equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Muix%C3%AD%2C+A">Alba Muix&#xed;</a>, 
<a href="/search/math?searchtype=author&query=Zlotnik%2C+S">Sergio Zlotnik</a>, 
<a href="/search/math?searchtype=author&query=Giacomini%2C+M">Matteo Giacomini</a>, 
<a href="/search/math?searchtype=author&query=D%C3%ADez%2C+P">Pedro D&#xed;ez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 8 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Engineering, Finance, and Science (cs.CE); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">A posteriori reduced-order models, e.g. proper orthogonal decomposition, are
essential to affordably tackle realistic parametric problems. They rely on a
trustful training set, that is a family of full-order solutions (snapshots)
representative of all possible outcomes of the parametric problem. Having such
a rich collection of snapshots is not, in many cases, computationally viable. A
strategy for data augmentation, designed for parametric laminar incompressible
flows, is proposed to enrich poorly populated training sets. The goal is to
include in the new, artificial snapshots emerging features, not present in the
original basis, that do enhance the quality of the reduced-order solution. The
methodologies devised are based on exploiting basic physical principles, such
as mass and momentum conservation, to devise physically-relevant, artificial
snapshots at a fraction of the cost of additional full-order solutions.
Interestingly, the numerical results show that the ideas exploiting only mass
conservation (i.e., incompressibility) are not producing significant added
value with respect to the standard linear combinations of snapshots.
Conversely, accounting for the linearized momentum balance via the Oseen
equation does improve the quality of the resulting approximation and therefore
is an effective data augmentation strategy in the framework of viscous
incompressible laminar flows.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14758" title="Abstract">arXiv:2312.14758</a> [<a href="/pdf/2312.14758" title="Download PDF">pdf</a>, <a href="/format/2312.14758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Maps for Signal Filtering in Graph Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hildebrant%2C+T">Todd Hildebrant</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper explores the application diffusion maps as graph shift operators
in understanding the underlying geometry of graph signals. The study evaluates
the improvements in graph learning when using diffusion map generated filters
to the Markov Variation minimization problem. The paper showcases the
effectiveness of this approach through examples involving synthetically
generated and real-world temperature sensor data. These examples also compare
the diffusion map graph signal model with other commonly used graph signal
operators. The results provide new approaches for the analysis and
understanding of complex, non-Euclidean data structures.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14763" title="Abstract">arXiv:2312.14763</a> [<a href="/pdf/2312.14763" title="Download PDF">pdf</a>, <a href="/format/2312.14763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced Latent Multi-view Subspace Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Long Shi</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Lei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Badong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Latent multi-view subspace clustering has been demonstrated to have desirable
clustering performance. However, the original latent representation method
vertically concatenates the data matrices from multiple views into a single
matrix along the direction of dimensionality to recover the latent
representation matrix, which may result in an incomplete information recovery.
To fully recover the latent space representation, we in this paper propose an
Enhanced Latent Multi-view Subspace Clustering (ELMSC) method. The ELMSC method
involves constructing an augmented data matrix that enhances the representation
of multi-view data. Specifically, we stack the data matrices from various views
into the block-diagonal locations of the augmented matrix to exploit the
complementary information. Meanwhile, the non-block-diagonal entries are
composed based on the similarity between different views to capture the
consistent information. In addition, we enforce a sparse regularization for the
non-diagonal blocks of the augmented self-representation matrix to avoid
redundant calculations of consistency information. Finally, a novel iterative
algorithm based on the framework of Alternating Direction Method of Multipliers
(ADMM) is developed to solve the optimization problem for ELMSC. Extensive
experiments on real-world datasets demonstrate that our proposed ELMSC is able
to achieve higher clustering performance than some state-of-art multi-view
clustering methods.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14769" title="Abstract">arXiv:2312.14769</a> [<a href="/pdf/2312.14769" title="Download PDF">pdf</a>, <a href="/ps/2312.14769" title="Download PostScript">ps</a>, <a href="/format/2312.14769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model (LLM) Bias Index -- LLMBI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oketunji%2C+A+F">Abiodun Finbarrs Oketunji</a>, 
<a href="/search/cs?searchtype=author&query=Anas%2C+M">Muhammad Anas</a>, 
<a href="/search/cs?searchtype=author&query=Saina%2C+D">Deepthi Saina</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">The Large Language Model Bias Index (LLMBI) is a pioneering approach designed
to quantify and address biases inherent in large language models (LLMs), such
as GPT-4. We recognise the increasing prevalence and impact of LLMs across
diverse sectors. This research introduces a novel metric, LLMBI, to
systematically measure and mitigate biases potentially skewing model responses.
We formulated LLMBI using a composite scoring system incorporating multiple
dimensions of bias, including but not limited to age, gender, and racial
biases.
<br />To operationalise this metric, we engaged in a multi-step process involving
collecting and annotating LLM responses, applying sophisticated Natural
Language Processing (NLP) techniques for bias detection, and computing the
LLMBI score through a specially crafted mathematical formula. The formula
integrates weighted averages of various bias dimensions, a penalty for dataset
diversity deficiencies, and a correction for sentiment biases. Our empirical
analysis, conducted using responses from OpenAI's API, employs advanced
sentiment analysis as a representative method for bias detection.
<br />The research reveals LLMs, whilst demonstrating impressive capabilities in
text generation, exhibit varying degrees of bias across different dimensions.
LLMBI provides a quantifiable measure to compare biases across models and over
time, offering a vital tool for systems engineers, researchers and regulators
in enhancing the fairness and reliability of LLMs. It highlights the potential
of LLMs in mimicking unbiased human-like responses. Additionally, it
underscores the necessity of continuously monitoring and recalibrating such
models to align with evolving societal norms and ethical standards.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14770" title="Abstract">arXiv:2312.14770</a> [<a href="/pdf/2312.14770" title="Download PDF">pdf</a>, <a href="/format/2312.14770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integration Of Evolutionary Automated Machine Learning With Structural  Sensitivity Analysis For Composite Pipelines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nikitin%2C+N+O">Nikolay O. Nikitin</a>, 
<a href="/search/cs?searchtype=author&query=Pinchuk%2C+M">Maiia Pinchuk</a>, 
<a href="/search/cs?searchtype=author&query=Pokrovskii%2C+V">Valerii Pokrovskii</a>, 
<a href="/search/cs?searchtype=author&query=Shevchenko%2C+P">Peter Shevchenko</a>, 
<a href="/search/cs?searchtype=author&query=Getmanov%2C+A">Andrey Getmanov</a>, 
<a href="/search/cs?searchtype=author&query=Aksenkin%2C+Y">Yaroslav Aksenkin</a>, 
<a href="/search/cs?searchtype=author&query=Revin%2C+I">Ilia Revin</a>, 
<a href="/search/cs?searchtype=author&query=Stebenkov%2C+A">Andrey Stebenkov</a>, 
<a href="/search/cs?searchtype=author&query=Poslavskaya%2C+E">Ekaterina Poslavskaya</a>, 
<a href="/search/cs?searchtype=author&query=Kalyuzhnaya%2C+A+V">Anna V. Kalyuzhnaya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Automated machine learning (AutoML) systems propose an end-to-end solution to
a given machine learning problem, creating either fixed or flexible pipelines.
Fixed pipelines are task independent constructs: their general composition
remains the same, regardless of the data. In contrast, the structure of
flexible pipelines varies depending on the input, making them finely tailored
to individual tasks. However, flexible pipelines can be structurally
overcomplicated and have poor explainability. We propose the EVOSA approach
that compensates for the negative points of flexible pipelines by incorporating
a sensitivity analysis which increases the robustness and interpretability of
the flexible solutions. EVOSA quantitatively estimates positive and negative
impact of an edge or a node on a pipeline graph, and feeds this information to
the evolutionary AutoML optimizer. The correctness and efficiency of EVOSA was
validated in tabular, multimodal and computer vision tasks, suggesting
generalizability of the proposed approach across domains.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14775" title="Abstract">arXiv:2312.14775</a> [<a href="/pdf/2312.14775" title="Download PDF">pdf</a>, <a href="/ps/2312.14775" title="Download PostScript">ps</a>, <a href="/format/2312.14775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bounding the Communication Complexity of Fault-Tolerant Common Coin  Tossing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geffner%2C+I">Ivan Geffner</a>, 
<a href="/search/cs?searchtype=author&query=Halpern%2C+J+Y">Joseph Y. Halpern</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Protocols for tossing a common coin play a key role in the vast majority of
implementations of consensus. Even though the common coins in the literature
are usually \emph{fair} (they have equal chance of landing heads or tails), we
focus on the problem of implementing a \emph{biased} common coin such that the
probability of landing heads is $p \in [0,1]$. Even though biased common coins
can be implemented using fair common coins, we show that this can require
significant inter-party communication. In fact, we show that there is no bound
on the number of messages needed to generate a common coin of bias $p$ in a way
that tolerates even one malicious agent, even if we restrict $p$ to an
arbitrary infinite subset of $[0,1]$ (e.g., rational numbers of the form
$1/2^n$) and assume that the system is synchronous. By way of contrast, if we
do not require the protocol to tolerate a faulty agent, we can do this. Thus,
the cause of the message complexity is the requirement of fault tolerance.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14776" title="Abstract">arXiv:2312.14776</a> [<a href="/pdf/2312.14776" title="Download PDF">pdf</a>, <a href="/format/2312.14776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compressing Image-to-Image Translation GANs Using Local Density  Structures on Their Learned Manifold
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ganjdanesh%2C+A">Alireza Ganjdanesh</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shangqian Gao</a>, 
<a href="/search/cs?searchtype=author&query=Alipanah%2C+H">Hirad Alipanah</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Heng Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 38th Annual AAAI Conference on Artificial Intelligence, AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Generative Adversarial Networks (GANs) have shown remarkable success in
modeling complex data distributions for image-to-image translation. Still,
their high computational demands prohibit their deployment in practical
scenarios like edge devices. Existing GAN compression methods mainly rely on
knowledge distillation or convolutional classifiers' pruning techniques. Thus,
they neglect the critical characteristic of GANs: their local density structure
over their learned manifold. Accordingly, we approach GAN compression from a
new perspective by explicitly encouraging the pruned model to preserve the
density structure of the original parameter-heavy model on its learned
manifold. We facilitate this objective for the pruned model by partitioning the
learned manifold of the original generator into local neighborhoods around its
generated samples. Then, we propose a novel pruning objective to regularize the
pruned model to preserve the local density structure over each neighborhood,
resembling the kernel density estimation method. Also, we develop a
collaborative pruning scheme in which the discriminator and generator are
pruned by two pruning agents. We design the agents to capture interactions
between the generator and discriminator by exchanging their peer's feedback
when determining corresponding models' architectures. Thanks to such a design,
our pruning method can efficiently find performant sub-networks and can
maintain the balance between the generator and discriminator more effectively
compared to baselines during pruning, thereby showing more stable pruning
dynamics. Our experiments on image translation GAN models, Pix2Pix and
CycleGAN, with various benchmark datasets and architectures demonstrate our
method's effectiveness.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14777" title="Abstract">arXiv:2312.14777</a> [<a href="/pdf/2312.14777" title="Download PDF">pdf</a>, <a href="/ps/2312.14777" title="Download PostScript">ps</a>, <a href="/format/2312.14777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scheduling with conflicts: formulations, valid inequalities, and  computational experiments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moura%2C+P+F+S">Phablo F. S. Moura</a>, 
<a href="/search/cs?searchtype=author&query=Leus%2C+R">Roel Leus</a>, 
<a href="/search/cs?searchtype=author&query=Yaman%2C+H">Hande Yaman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">Given an undirected graph $G=(V,E)$ (i.e. the conflict graph) where $V$ is a
set of $n$ vertices (representing the jobs), processing times $p \colon V \to
\mathbb{Z}_&gt;$, and $m\geq 2$ identical machines the Parallel Machine Scheduling
with Conflicts (PMC) consists in finding an assignment $c \colon V \to
[m]:=\{1,\ldots, m\}$ with $c(u)\neq c(v)$ for all $\{u,v\} \in E$ that
minimizes the makespan $\max_{k \in [m]} \sum_{v \in V \colon c(v)=k} p(v)$.
First we consider the natural assignment formulation for PMC using binary
variables indexed by the jobs and machines, and discuss how to reduce the
symmetries in such model. Then we propose a compact mixed integer linear
programming formulation for PMC to tackle the issues related to symmetry and
unbalanced enumeration tree associated with the assignment model. The proposed
formulation for PMC uses a set of representative jobs (one in each machine) to
express feasible solutions of the problem, and it is based on the
representatives model for the vertex coloring problem. We present a polyhedral
study of the associated polytope, and show classes of valid inequalities
inherited from the stable set polytope. We describe branch-and-cut algorithms
for PMC, and report on preliminary computational experiments with benchmark
instances.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14781" title="Abstract">arXiv:2312.14781</a> [<a href="/pdf/2312.14781" title="Download PDF">pdf</a>, <a href="/format/2312.14781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ROS package search for robot software development: a knowledge  graph-based approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+X">Xinjun Mao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Menghan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages. Already submitted to Frontiers of Computer Science
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">ROS (Robot Operating System) packages have become increasingly popular as a
type of software artifact that can be effectively reused in robotic software
development. Indeed, finding suitable ROS packages that closely match the
software's functional requirements from the vast number of available packages
is a nontrivial task using current search methods. The traditional search
methods for ROS packages often involve inputting keywords related to robotic
tasks into general-purpose search engines or code hosting platforms to obtain
approximate results of all potentially suitable ROS packages. However, the
accuracy of these search methods remains relatively low because the
task-related keywords may not precisely match the functionalities offered by
the ROS packages. To improve the search accuracy of ROS packages, this paper
presents a novel semantic-based search approach that relies on the
semantic-level ROS Package Knowledge Graph (RPKG) to automatically retrieve the
most suitable ROS packages. Firstly, to construct the RPKG, we employ
multi-dimensional feature extraction techniques to extract semantic concepts
from the dataset of ROS package text descriptions. The semantic features
extracted from this process result in a substantial number of entities and
relationships. Subsequently, we create a robot domain-specific small corpus and
further fine-tune a pre-trained language model, BERT-ROS, to generate
embeddings that effectively represent the semantics of the extracted features.
These embeddings play a crucial role in facilitating semantic-level
understanding and comparisons during the ROS package search process within the
RPKG. Secondly, we introduce a novel semantic matching-based search algorithm
that incorporates the weighted similarities of multiple features from user
search queries, which searches out more accurate ROS packages than the
traditional keyword search method.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14788" title="Abstract">arXiv:2312.14788</a> [<a href="/pdf/2312.14788" title="Download PDF">pdf</a>, <a href="/ps/2312.14788" title="Download PostScript">ps</a>, <a href="/format/2312.14788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing the Final Control Error for Optimal Data-Driven Predictive  Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chiuso%2C+A">Alessandro Chiuso</a>, 
<a href="/search/eess?searchtype=author&query=Fabris%2C+M">Marco Fabris</a>, 
<a href="/search/eess?searchtype=author&query=Breschi%2C+V">Valentina Breschi</a>, 
<a href="/search/eess?searchtype=author&query=Formentin%2C+S">Simone Formentin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 2 figures, 1 table, submitted to Automatica
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Model Predictive Control (MPC) is a powerful method for complex system
regulation, but its reliance on accurate models poses many limitations in
real-world applications. Data-driven predictive control (DDPC) offers a valid
alternative, eliminating the need for model identification. However, it may
falter in the presence of noisy data. In response, in this work, we present a
unified stochastic framework for direct DDPC where control actions are obtained
by optimizing the Final Control Error, directly computed from available data
only, that automatically weighs the impact of uncertainty on the control
objective. Our approach generalizes existing DDPC methods, like regularized
Data-enabled Predictive Control (DeePC) and $\gamma$-DDPC, and thus provides a
path toward noise-tolerant data-based control, with rigorous optimality
guarantees. The theoretical investigation is complemented by a series of
numerical case studies, revealing that the proposed method consistently
outperforms or, at worst, matches existing techniques without requiring tuning
regularization parameters as methods do.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14791" title="Abstract">arXiv:2312.14791</a> [<a href="/pdf/2312.14791" title="Download PDF">pdf</a>, <a href="/format/2312.14791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EMF-Constrained Artificial Noise for Secrecy Rates with Stochastic  Eavesdropper Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roth%2C+S">Stefan Roth</a>, 
<a href="/search/cs?searchtype=author&query=Sezgin%2C+A">Aydin Sezgin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">An information-theoretic confidential communication is achievable if the
eavesdropper has a degraded channel compared to the legitimate receiver. In
wireless channels, beamforming and artificial noise can enable such
confidentiality. However, only distribution knowledge of the eavesdropper
channels can be assumed. Moreover, the transmission of artificial noise can
lead to an increased electromagnetic field (EMF) exposure, which depends on the
considered location and can thus also be seen as a random variable. Hence, we
optimize the $\varepsilon$-outage secrecy rate under a $\delta$-outage exposure
constraint in a setup, where the base station (BS) is communicating to a user
equipment (UE), while a single-antenna eavesdropper with Rayleigh distributed
channels is present. Therefore, we calculate the secrecy outage probability
(SOP) in closed-form. Based on this, we convexify the optimization problem and
optimize the $\varepsilon$-outage secrecy rate iteratively. Numerical results
show that for a moderate exposure constraint, artificial noise from the BS has
a relatively large impact due to beamforming, while for a strict exposure
constraint artificial noise from the UE is more important.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14792" title="Abstract">arXiv:2312.14792</a> [<a href="/pdf/2312.14792" title="Download PDF">pdf</a>, <a href="/ps/2312.14792" title="Download PostScript">ps</a>, <a href="/format/2312.14792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Rate-Distortion-Perception-Classification Tradeoff: Joint Source  Coding and Modulation via Inverse-Domain GANs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Junli Fang</a>, 
<a href="/search/cs?searchtype=author&query=Mota%2C+J+F+C">Jo&#xe3;o F. C. Mota</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+B">Baoshan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weicheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+X">Xuemin Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Information Theory (cs.IT); Probability (math.PR)

</div>
<p class="mathjax">The joint source coding and modulation (JSCM) framework was enabled by recent
developments in deep learning, which allows to automatically learn from data,
and in an end-to-end fashion, the best compression codes and modulation
schemes. In this paper, we show the existence of a strict tradeoff between
channel rate, distortion, perception, and classification accuracy in a JSCM
scenario. We then propose two image compression methods to navigate that
tradeoff: an inverse-domain generative adversarial network (ID-GAN), which
achieves extreme compression, and a simpler, heuristic method that reveals
insights about the performance of ID-GAN. Experiment results not only
corroborate the theoretical findings, but also demonstrate that the proposed
ID-GAN algorithm significantly improves system performance compared to
traditional separation-based methods and recent deep JSCM architectures.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14793" title="Abstract">arXiv:2312.14793</a> [<a href="/pdf/2312.14793" title="Download PDF">pdf</a>, <a href="/format/2312.14793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Value of Mediation in Long Cheap Talk
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arieli%2C+I">Itai Arieli</a>, 
<a href="/search/cs?searchtype=author&query=Geffner%2C+I">Ivan Geffner</a>, 
<a href="/search/cs?searchtype=author&query=Tennenholtz%2C+M">Moshe Tennenholtz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">In this paper, we study an extension of the classic long cheap talk
equilibrium introduced by Aumann and Hart~\citeN{aumann-hart-03}, and ask how
much can the players benefit from having a trusted mediator compared with the
standard unmediated model. We focus on a setting where a fully informed sender
without commitment power must disclose its information to influence the
behavior of a self-interested receiver. We show that, in the case of binary
actions, even though a mediator does not help neither the sender nor the
receiver directly, it may still allow improving the payoff of an external
decision-maker whose utility is affected by the realized state and the
receiver's action. Moreover, we show that if there are more than two actions,
there exist games in which both the sender and the receiver simultaneously
benefit from mediation.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14794" title="Abstract">arXiv:2312.14794</a> [<a href="/pdf/2312.14794" title="Download PDF">pdf</a>, <a href="/format/2312.14794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Study on Compliance with Ranking Transparency in the  Software Documentation of EU Online Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sovrano%2C+F">Francesco Sovrano</a>, 
<a href="/search/cs?searchtype=author&query=Lognoul%2C+M">Micha&#xeb;l Lognoul</a>, 
<a href="/search/cs?searchtype=author&query=Bacchelli%2C+A">Alberto Bacchelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the 46th International Conference on Software Engineering (ICSE 2024), Software Engineering in Society (SEIS) track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Compliance with the European Union's Platform-to-Business (P2B) Regulation is
challenging for online platforms, and assessing their compliance can be
difficult for public authorities. This is partly due to the lack of automated
tools for assessing the information (e.g., software documentation) platforms
provide concerning ranking transparency. Our study tackles this issue in two
ways. First, we empirically evaluate the compliance of six major platforms
(Amazon, Bing, Booking, Google, Tripadvisor, and Yahoo), revealing substantial
differences in their documentation. Second, we introduce and test automated
compliance assessment tools based on ChatGPT and information retrieval
technology. These tools are evaluated against human judgments, showing
promising results as reliable proxies for compliance assessments. Our findings
could help enhance regulatory compliance and align with the United Nations
Sustainable Development Goal 10.3, which seeks to reduce inequality, including
business disparities, on these platforms.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14798" title="Abstract">arXiv:2312.14798</a> [<a href="/pdf/2312.14798" title="Download PDF">pdf</a>, <a href="/format/2312.14798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Parsing for Complex Data Retrieval: Targeting Query Plans vs.  SQL for No-Code Access to Relational Databases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eyal%2C+B">Ben Eyal</a>, 
<a href="/search/cs?searchtype=author&query=Bachar%2C+A">Amir Bachar</a>, 
<a href="/search/cs?searchtype=author&query=Haroche%2C+O">Ophir Haroche</a>, 
<a href="/search/cs?searchtype=author&query=Elhadad%2C+M">Michael Elhadad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2310.13575">arXiv:2310.13575</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have spurred progress in text-to-SQL, the task
of generating SQL queries from natural language questions based on a given
database schema. Despite the declarative nature of SQL, it continues to be a
complex programming language. In this paper, we investigate the potential of an
alternative query language with simpler syntax and modular specification of
complex queries. The purpose is to create a query language that can be learned
more easily by modern neural semantic parsing architectures while also enabling
non-programmers to better assess the validity of the query plans produced by an
interactive query plan assistant.
<br />The proposed alternative query language is called Query Plan Language (QPL).
It is designed to be modular and can be translated into a restricted form of
SQL Common Table Expressions (CTEs). The aim of QPL is to make complex data
retrieval accessible to non-programmers by allowing users to express their
questions in natural language while also providing an easier-to-verify target
language. The paper demonstrates how neural LLMs can benefit from QPL's
modularity to generate complex query plans in a compositional manner. This
involves a question decomposition strategy and a planning stage.
<br />We conduct experiments on a version of the Spider text-to-SQL dataset that
has been converted to QPL. The hierarchical structure of QPL programs enables
us to measure query complexity naturally. Based on this assessment, we identify
the low accuracy of existing text-to-SQL systems on complex compositional
queries. We present ways to address the challenge of complex queries in an
iterative, user-controlled manner, using fine-tuned LLMs and a variety of
prompting strategies in a compositional manner.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14803" title="Abstract">arXiv:2312.14803</a> [<a href="/pdf/2312.14803" title="Download PDF">pdf</a>, <a href="/format/2312.14803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reduced order modelling of fully coupled electro-mechanical systems  through invariant manifolds with applications to microstructures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Frangi%2C+A">Attilio Frangi</a>, 
<a href="/search/math?searchtype=author&query=Colombo%2C+A">Alessio Colombo</a>, 
<a href="/search/math?searchtype=author&query=Vizzaccaro%2C+A">Alessandra Vizzaccaro</a>, 
<a href="/search/math?searchtype=author&query=Touz%C3%A9%2C+C">Cyril Touz&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper presents the first application of the direct parametrisation
method for invariant manifolds to a fully coupled multiphysics problem
involving the nonlinear vibrations of deformable structures subjected to an
electrostatic field. The formulation proposed is intended for model order
reduction of electrostatically actuated resonating Micro-Electro-Mechanical
Systems (MEMS). The continuous problem is first rewritten in a manner that can
be directly handled by the parametrisation method, which relies upon automated
asymptotic expansions. A new mixed fully Lagrangian formulation is thus
proposed which contains only explicit polynomial nonlinearities, which is then
discretised in the framework of finite element procedures. Validation is
performed on the classical parallel plate configuration, where different
formulations using either the general framework, or an approximation of the
electrostatic field due to the geometric configuration selected, are compared.
Reduced-order models along these formulations are also compared to full-order
simulations operated with a time integration approach. Numerical results show a
remarkable performance both in terms of accuracy and wealth of nonlinear
effects that can be accounted for. In particular, the transition from hardening
to softening behaviour of the primary resonance while increasing the constant
voltage component of the electric actuation, is recovered. Secondary resonances
leading to superharmonic and parametric resonances are also investigated with
the reduced-order model.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14804" title="Abstract">arXiv:2312.14804</a> [<a href="/pdf/2312.14804" title="Download PDF">pdf</a>, <a href="/format/2312.14804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Use large language models to promote equity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pierson%2C+E">Emma Pierson</a>, 
<a href="/search/cs?searchtype=author&query=Shanmugam%2C+D">Divya Shanmugam</a>, 
<a href="/search/cs?searchtype=author&query=Movva%2C+R">Rajiv Movva</a>, 
<a href="/search/cs?searchtype=author&query=Kleinberg%2C+J">Jon Kleinberg</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+M">Monica Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Dredze%2C+M">Mark Dredze</a>, 
<a href="/search/cs?searchtype=author&query=Ferryman%2C+K">Kadija Ferryman</a>, 
<a href="/search/cs?searchtype=author&query=Gichoya%2C+J+W">Judy Wawira Gichoya</a>, 
<a href="/search/cs?searchtype=author&query=Jurafsky%2C+D">Dan Jurafsky</a>, 
<a href="/search/cs?searchtype=author&query=Koh%2C+P+W">Pang Wei Koh</a>, 
<a href="/search/cs?searchtype=author&query=Levy%2C+K">Karen Levy</a>, 
<a href="/search/cs?searchtype=author&query=Mullainathan%2C+S">Sendhil Mullainathan</a>, 
<a href="/search/cs?searchtype=author&query=Obermeyer%2C+Z">Ziad Obermeyer</a>, 
<a href="/search/cs?searchtype=author&query=Suresh%2C+H">Harini Suresh</a>, 
<a href="/search/cs?searchtype=author&query=Vafa%2C+K">Keyon Vafa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Advances in large language models (LLMs) have driven an explosion of interest
about their societal impacts. Much of the discourse around how they will impact
social equity has been cautionary or negative, focusing on questions like "how
might LLMs be biased and how would we mitigate those biases?" This is a vital
discussion: the ways in which AI generally, and LLMs specifically, can entrench
biases have been well-documented. But equally vital, and much less discussed,
is the more opportunity-focused counterpoint: "what promising applications do
LLMs enable that could promote equity?" If LLMs are to enable a more equitable
world, it is not enough just to play defense against their biases and failure
modes. We must also go on offense, applying them positively to equity-enhancing
use cases to increase opportunities for underserved groups and reduce societal
discrimination. There are many choices which determine the impact of AI, and a
fundamental choice very early in the pipeline is the problems we choose to
apply it to. If we focus only later in the pipeline -- making LLMs marginally
more fair as they facilitate use cases which intrinsically entrench power -- we
will miss an important opportunity to guide them to equitable impacts. Here, we
highlight the emerging potential of LLMs to promote equity by presenting four
newly possible, promising research directions, while keeping risks and
cautionary points in clear view.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14806" title="Abstract">arXiv:2312.14806</a> [<a href="/pdf/2312.14806" title="Download PDF">pdf</a>, <a href="/format/2312.14806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Effects of Signal-to-Noise Ratio on Generative Adversarial Networks  Applied to Marine Bioacoustic Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atkinson%2C+G">Georgia Atkinson</a>, 
<a href="/search/cs?searchtype=author&query=Wright%2C+N">Nick Wright</a>, 
<a href="/search/cs?searchtype=author&query=McGough%2C+A+S">A. Stephen McGough</a>, 
<a href="/search/cs?searchtype=author&query=Berggren%2C+P">Per Berggren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In recent years generative adversarial networks (GANs) have been used to
supplement datasets within the field of marine bioacoustics. This is driven by
factors such as the cost to collect data, data sparsity and aid preprocessing.
One notable challenge with marine bioacoustic data is the low signal-to-noise
ratio (SNR) posing difficulty when applying deep learning techniques such as
GANs. This work investigates the effect SNR has on the audio-based GAN
performance and examines three different evaluation methodologies for GAN
performance, yielding interesting results on the effects of SNR on GANs,
specifically WaveGAN.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14808" title="Abstract">arXiv:2312.14808</a> [<a href="/pdf/2312.14808" title="Download PDF">pdf</a>, <a href="/format/2312.14808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Tricycle Model to Accurately Control an Autonomous Racecar with Locked  Differential
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Raji%2C+A">Ayoub Raji</a>, 
<a href="/search/eess?searchtype=author&query=Musiu%2C+N">Nicola Musiu</a>, 
<a href="/search/eess?searchtype=author&query=Toschi%2C+A">Alessandro Toschi</a>, 
<a href="/search/eess?searchtype=author&query=Prignoli%2C+F">Francesco Prignoli</a>, 
<a href="/search/eess?searchtype=author&query=Mascaro%2C+E">Eugenio Mascaro</a>, 
<a href="/search/eess?searchtype=author&query=Musso%2C+P">Pietro Musso</a>, 
<a href="/search/eess?searchtype=author&query=Amerotti%2C+F">Francesco Amerotti</a>, 
<a href="/search/eess?searchtype=author&query=Liniger%2C+A">Alexander Liniger</a>, 
<a href="/search/eess?searchtype=author&query=Sorrentino%2C+S">Silvio Sorrentino</a>, 
<a href="/search/eess?searchtype=author&query=Bertogna%2C+M">Marko Bertogna</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the 2023 IEEE 11th International Conference on Systems and Control, Sousse, Tunisia, December 18-20, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO); Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper, we present a novel formulation to model the effects of a
locked differential on the lateral dynamics of an autonomous open-wheel
racecar. The model is used in a Model Predictive Controller in which we
included a micro-steps discretization approach to accurately linearize the
dynamics and produce a prediction suitable for real-time implementation. The
stability analysis of the model is presented, as well as a brief description of
the overall planning and control scheme which includes an offline trajectory
generation pipeline, an online local speed profile planner, and a low-level
longitudinal controller. An improvement of the lateral path tracking is
demonstrated in preliminary experimental results that have been produced on a
Dallara AV-21 during the first Indy Autonomous Challenge event on the Monza F1
racetrack. Final adjustments and tuning have been performed in a high-fidelity
simulator demonstrating the effectiveness of the solution when performing close
to the tire limits.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14810" title="Abstract">arXiv:2312.14810</a> [<a href="/pdf/2312.14810" title="Download PDF">pdf</a>, <a href="/format/2312.14810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Bayesian Optimal Experimental Design with  Derivative-Informed Neural Operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Go%2C+J">Jinwoo Go</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peng Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Optimization and Control (math.OC); Methodology (stat.ME)

</div>
<p class="mathjax">We consider optimal experimental design (OED) for nonlinear Bayesian inverse
problems governed by large-scale partial differential equations (PDEs). For the
optimality criteria of Bayesian OED, we consider both expected information gain
and summary statistics including the trace and determinant of the information
matrix that involves the evaluation of the parameter-to-observable (PtO) map
and its derivatives. However, it is prohibitive to compute and optimize these
criteria when the PDEs are very expensive to solve, the parameters to estimate
are high-dimensional, and the optimization problem is combinatorial,
high-dimensional, and non-convex. To address these challenges, we develop an
accurate, scalable, and efficient computational framework to accelerate the
solution of Bayesian OED. In particular, the framework is developed based on
derivative-informed neural operator (DINO) surrogates with proper dimension
reduction techniques and a modified swapping greedy algorithm. We demonstrate
the high accuracy of the DINO surrogates in the computation of the PtO map and
the optimality criteria compared to high-fidelity finite element
approximations. We also show that the proposed method is scalable with
increasing parameter dimensions. Moreover, we demonstrate that it achieves high
efficiency with over 1000X speedup compared to a high-fidelity Bayesian OED
solution for a three-dimensional PDE example with tens of thousands of
parameters, including both online evaluation and offline construction costs of
the surrogates.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14812" title="Abstract">arXiv:2312.14812</a> [<a href="/pdf/2312.14812" title="Download PDF">pdf</a>, <a href="/format/2312.14812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PARDINUS: Weakly supervised discarding of photo-trapping empty images  based on autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+la+Rosa%2C+D">David de la Rosa</a>, 
<a href="/search/cs?searchtype=author&query=Rivera%2C+A+J">Antonio J Rivera</a>, 
<a href="/search/cs?searchtype=author&query=del+Jesus%2C+M+J">Mar&#xed;a J del Jesus</a>, 
<a href="/search/cs?searchtype=author&query=Charte%2C+F">Francisco Charte</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Photo-trapping cameras are widely employed for wildlife monitoring. Those
cameras take photographs when motion is detected to capture images where
animals appear. A significant portion of these images are empty - no wildlife
appears in the image. Filtering out those images is not a trivial task since it
requires hours of manual work from biologists. Therefore, there is a notable
interest in automating this task. Automatic discarding of empty photo-trapping
images is still an open field in the area of Machine Learning. Existing
solutions often rely on state-of-the-art supervised convolutional neural
networks that require the annotation of the images in the training phase.
PARDINUS (Weakly suPervised discARDINg of photo-trapping empty images based on
aUtoencoderS) is constructed on the foundation of weakly supervised learning
and proves that this approach equals or even surpasses other fully supervised
methods that require further labeling work.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14820" title="Abstract">arXiv:2312.14820</a> [<a href="/pdf/2312.14820" title="Download PDF">pdf</a>, <a href="/format/2312.14820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Regularity of Self-Attention with Optimal Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castin%2C+V">Val&#xe9;rie Castin</a>, 
<a href="/search/cs?searchtype=author&query=Ablin%2C+P">Pierre Ablin</a>, 
<a href="/search/cs?searchtype=author&query=Peyr%C3%A9%2C+G">Gabriel Peyr&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Transformers and their multi-head attention mechanism have completely changed
the machine learning landscape in just a few years, by outperforming
state-of-art models in a wide range of domains. Still, little is known about
their robustness from a theoretical perspective. We tackle this problem by
studying the local Lipschitz constant of self-attention, that provides an
attack-agnostic way of measuring the robustness of a neural network. We adopt a
measure-theoretic framework, by viewing inputs as probability measures equipped
with the Wasserstein distance. This allows us to generalize attention to inputs
of infinite length, and to derive an upper bound and a lower bound on the
Lipschitz constant of self-attention on compact sets. The lower bound
significantly improves prior results, and grows more than exponentially with
the radius of the compact set, which rules out the possibility of obtaining
robustness guarantees without any additional constraint on the input space. Our
results also point out that measures with a high local Lipschitz constant are
typically made of a few diracs, with a very unbalanced distribution of mass.
Finally, we analyze the stability of self-attention under perturbations that
change the number of tokens, which appears to be a natural question in the
measure-theoretic framework. In particular, we show that for some inputs,
attacks that duplicate tokens before perturbing them are more efficient than
attacks that simply move tokens. We call this phenomenon mass splitting.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14821" title="Abstract">arXiv:2312.14821</a> [<a href="/pdf/2312.14821" title="Download PDF">pdf</a>, <a href="/format/2312.14821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AXI4MLIR: User-Driven Automatic Host Code Generation for Custom  AXI-Based Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agostini%2C+N+B">Nicolas Bohm Agostini</a>, 
<a href="/search/cs?searchtype=author&query=Haris%2C+J">Jude Haris</a>, 
<a href="/search/cs?searchtype=author&query=Gibson%2C+P">Perry Gibson</a>, 
<a href="/search/cs?searchtype=author&query=Jayaweera%2C+M">Malith Jayaweera</a>, 
<a href="/search/cs?searchtype=author&query=Rubin%2C+N">Norm Rubin</a>, 
<a href="/search/cs?searchtype=author&query=Tumeo%2C+A">Antonino Tumeo</a>, 
<a href="/search/cs?searchtype=author&query=Abell%C3%A1n%2C+J+L">Jos&#xe9; L. Abell&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Cano%2C+J">Jos&#xe9; Cano</a>, 
<a href="/search/cs?searchtype=author&query=Kaeli%2C+D">David Kaeli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 17 figures, to appear in CGO2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">This paper addresses the need for automatic and efficient generation of host
driver code for arbitrary custom AXI-based accelerators targeting linear
algebra algorithms, an important workload in various applications, including
machine learning and scientific computing. While existing tools have focused on
automating accelerator prototyping, little attention has been paid to the
host-accelerator interaction. This paper introduces AXI4MLIR, an extension of
the MLIR compiler framework designed to facilitate the automated generation of
host-accelerator driver code. With new MLIR attributes and transformations,
AXI4MLIR empowers users to specify accelerator features (including their
instructions) and communication patterns and exploit the host memory hierarchy.
We demonstrate AXI4MLIR's versatility across different types of accelerators
and problems, showcasing significant CPU cache reference reductions (up to 56%)
and up to a 1.65x speedup compared to manually optimized driver code
implementations. AXI4MLIR implementation is open-source and available at:
https://github.com/AXI4MLIR/axi4mlir.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14824" title="Abstract">arXiv:2312.14824</a> [<a href="/pdf/2312.14824" title="Download PDF">pdf</a>, <a href="/format/2312.14824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An investigation of belief-free DRL and MCTS for inspection and  maintenance planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koutas%2C+D">Daniel Koutas</a>, 
<a href="/search/cs?searchtype=author&query=Bismut%2C+E">Elizabeth Bismut</a>, 
<a href="/search/cs?searchtype=author&query=Straub%2C+D">Daniel Straub</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">We propose a novel Deep Reinforcement Learning (DRL) architecture for
sequential decision processes under uncertainty, as encountered in inspection
and maintenance (I&amp;M) planning. Unlike other DRL algorithms for (I&amp;M) planning,
the proposed +RQN architecture dispenses with computing the belief state and
directly handles erroneous observations instead. We apply the algorithm to a
basic I&amp;M planning problem for a one-component system subject to deterioration.
In addition, we investigate the performance of Monte Carlo tree search for the
I&amp;M problem and compare it to the +RQN. The comparison includes a statistical
analysis of the two methods' resulting policies, as well as their visualization
in the belief space.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14828" title="Abstract">arXiv:2312.14828</a> [<a href="/pdf/2312.14828" title="Download PDF">pdf</a>, <a href="/format/2312.14828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Plan, Posture and Go: Towards Open-World Text-to-Motion Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinpeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+W">Wenxun Dai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chunyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yiji Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yansong Tang</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+X">Xin Tong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Conventional text-to-motion generation methods are usually trained on limited
text-motion pairs, making them hard to generalize to open-world scenarios. Some
works use the CLIP model to align the motion space and the text space, aiming
to enable motion generation from natural language motion descriptions. However,
they are still constrained to generate limited and unrealistic in-place
motions. To address these issues, we present a divide-and-conquer framework
named PRO-Motion, which consists of three modules as motion planner,
posture-diffuser and go-diffuser. The motion planner instructs Large Language
Models (LLMs) to generate a sequence of scripts describing the key postures in
the target motion. Differing from natural languages, the scripts can describe
all possible postures following very simple text templates. This significantly
reduces the complexity of posture-diffuser, which transforms a script to a
posture, paving the way for open-world generation. Finally, go-diffuser,
implemented as another diffusion model, estimates whole-body translations and
rotations for all postures, resulting in realistic motions. Experimental
results have shown the superiority of our method with other counterparts, and
demonstrated its capability of generating diverse and realistic motions from
complex open-world prompts such as "Experiencing a profound sense of joy". The
project page is available at https://moonsliu.github.io/Pro-Motion.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14831" title="Abstract">arXiv:2312.14831</a> [<a href="/pdf/2312.14831" title="Download PDF">pdf</a>, <a href="/format/2312.14831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asynchronous Composition of LTL Properties over Infinite and Finite  Traces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bombardelli%2C+A">Alberto Bombardelli</a>, 
<a href="/search/cs?searchtype=author&query=Tonetta%2C+S">Stefano Tonetta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">The verification of asynchronous software components poses significant
challenges due to the way components interleave and exchange input/output data
concurrently. Compositional strategies aim to address this by separating the
task of verifying individual components on local properties from the task of
combining them to achieve global properties. This paper concentrates on
employing symbolic model checking techniques to verify properties specified in
Linear-time Temporal Logic (LTL) on asynchronous software components that
interact through data ports. Unlike event-based composition, local properties
can now impose constraints on input from other components, increasing the
complexity of their composition. We consider both the standard semantics over
infinite traces as well as the truncated semantics over finite traces to allow
scheduling components only finitely many times.
<br />We propose a novel LTL rewriting approach, which converts a local property
into a global one while considering the interleaving of infinite or finite
execution traces of components. We prove the semantic equivalence of local
properties and their rewritten version projected on the local symbols. The
rewriting is also optimized to reduce formula size and to leave it unchanged
when the temporal property is stutter invariant. These methods have been
integrated into the OCRA tool, as part of the contract refinement verification
suite. Finally, the different composition approaches were compared through an
experimental evaluation that covers various types of specifications.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14834" title="Abstract">arXiv:2312.14834</a> [<a href="/pdf/2312.14834" title="Download PDF">pdf</a>, <a href="/format/2312.14834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prototype-Guided Text-based Person Search based on Rich Chinese  Descriptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Ziqiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+B">Bingpeng Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-based person search aims to simultaneously localize and identify the
target person based on query text from uncropped scene images, which can be
regarded as the unified task of person detection and text-based person
retrieval task. In this work, we propose a large-scale benchmark dataset named
PRW-TPS-CN based on the widely used person search dataset PRW. Our dataset
contains 47,102 sentences, which means there is quite more information than
existing dataset. These texts precisely describe the person images from top to
bottom, which in line with the natural description order. We also provide both
Chinese and English descriptions in our dataset for more comprehensive
evaluation. These characteristics make our dataset more applicable. To
alleviate the inconsistency between person detection and text-based person
retrieval, we take advantage of the rich texts in PRW-TPS-CN dataset. We
propose to aggregate multiple texts as text prototypes to maintain the
prominent text features of a person, which can better reflect the whole
character of a person. The overall prototypes lead to generating the image
attention map to eliminate the detection misalignment causing the decrease of
text-based person retrieval. Thus, the inconsistency between person detection
and text-based person retrieval is largely alleviated. We conduct extensive
experiments on the PRW-TPS-CN dataset. The experimental results show the
PRW-TPS-CN dataset's effectiveness and the state-of-the-art performance of our
approach.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14836" title="Abstract">arXiv:2312.14836</a> [<a href="/pdf/2312.14836" title="Download PDF">pdf</a>, <a href="/format/2312.14836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Lagrangian Multipliers for the Travelling Salesman Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parjadis%2C+A">Augustin Parjadis</a>, 
<a href="/search/cs?searchtype=author&query=Cappart%2C+Q">Quentin Cappart</a>, 
<a href="/search/cs?searchtype=author&query=Dilkina%2C+B">Bistra Dilkina</a>, 
<a href="/search/cs?searchtype=author&query=Ferber%2C+A">Aaron Ferber</a>, 
<a href="/search/cs?searchtype=author&query=Rousseau%2C+L">Louis-Martin Rousseau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">Lagrangian relaxation is a versatile mathematical technique employed to relax
constraints in an optimization problem, enabling the generation of dual bounds
to prove the optimality of feasible solutions and the design of efficient
propagators in constraint programming (such as the weighted circuit
constraint). However, the conventional process of deriving Lagrangian
multipliers (e.g., using subgradient methods) is often computationally
intensive, limiting its practicality for large-scale or time-sensitive
problems. To address this challenge, we propose an innovative unsupervised
learning approach that harnesses the capabilities of graph neural networks to
exploit the problem structure, aiming to generate accurate Lagrangian
multipliers efficiently. We apply this technique to the well-known Held-Karp
Lagrangian relaxation for the travelling salesman problem. The core idea is to
predict accurate Lagrangian multipliers and to employ them as a warm start for
generating Held-Karp relaxation bounds. These bounds are subsequently utilized
to enhance the filtering process carried out by branch-and-bound algorithms. In
contrast to much of the existing literature, which primarily focuses on finding
feasible solutions, our approach operates on the dual side, demonstrating that
learning can also accelerate the proof of optimality. We conduct experiments
across various distributions of the metric travelling salesman problem,
considering instances with up to 200 cities. The results illustrate that our
approach can improve the filtering level of the weighted circuit global
constraint, reduce the optimality gap by a factor two for unsolved instances up
to a timeout, and reduce the execution time for solved instances by 10%.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14839" title="Abstract">arXiv:2312.14839</a> [<a href="/pdf/2312.14839" title="Download PDF">pdf</a>, <a href="/format/2312.14839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulating Parametric Thin Shells by Bicubic Hermite Elements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+X">Xingyu Ni</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuwen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Cheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Baoquan Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">In this study, we present the bicubic Hermite element method (BHEM), a new
computational framework devised for the elastodynamic simulation of parametric
thin-shell structures. The BHEM is constructed based on parametric
quadrilateral Hermite patches, which serve as a unified representation for
shell geometry, simulation, collision avoidance, as well as rendering. Compared
with the commonly utilized linear FEM, the BHEM offers higher-order solution
spaces, enabling the capture of more intricate and smoother geometries while
employing significantly fewer finite elements. In comparison to other
high-order methods, the BHEM achieves conforming $\mathcal{C}^1$ continuity for
Kirchhoff-Love (KL) shells with minimal complexity. Furthermore, by leveraging
the subdivision and convex hull properties of Hermite patches, we develop an
efficient algorithm for ray-patch intersections, facilitating collision
handling in simulations and ray tracing in rendering. This eliminates the need
for laborious remodeling of the pre-existing parametric surface as the
conventional approaches do. We substantiate our claims with comprehensive
experiments, which demonstrate the high accuracy and versatility of the
proposed method.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14843" title="Abstract">arXiv:2312.14843</a> [<a href="/pdf/2312.14843" title="Download PDF">pdf</a>, <a href="/ps/2312.14843" title="Download PostScript">ps</a>, <a href="/format/2312.14843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SusDevOps: Promoting Sustainability to a First Principle in Software  Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=David%2C+I">Istvan David</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Sustainability is becoming a key property of modern software systems. While
there is a substantial and growing body of knowledge on engineering sustainable
software, end-to-end frameworks that situate sustainability-related activities
within the software delivery lifecycle are missing. In this article, we propose
the SusDevOps framework that promotes sustainability to a first principle
within a DevOps context. We demonstrate the lifecycle phases and techniques of
SusDevOps through the case of a software development startup company.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14845" title="Abstract">arXiv:2312.14845</a> [<a href="/pdf/2312.14845" title="Download PDF">pdf</a>, <a href="/format/2312.14845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Use of Metaphor Translation in Psychiatry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wong%2C+L">Lois Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Providing mental healthcare to individuals with limited English proficiency
(LEP) remains a pressing problem within psychiatry. Because the majority of
individuals trained in providing psychiatric care are English speakers, the
quality of mental healthcare given to LEP patients is significantly lower than
that provided for English speakers. The provision of mental healthcare is
contingent on communication and understanding between the patient and
healthcare provider, much more so than in the realm of physical healthcare, and
English speakers are often unable to comprehend figurative language such as
metaphors used by LEPs. Hence, Figurative Language Translation is invaluable to
providing equitable psychiatric care. Now, metaphor has been shown to be
paramount in both identifying individuals struggling with mental problems and
helping those individuals understand and communicate their experiences.
Therefore, this paper aims to survey the potential of Machine Translation for
providing equitable psychiatric healthcare and highlights the need for further
research on the transferability of existing machine and metaphor translation
research in the domain of psychiatry.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14852" title="Abstract">arXiv:2312.14852</a> [<a href="/pdf/2312.14852" title="Download PDF">pdf</a>, <a href="/format/2312.14852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TACO: Topics in Algorithmic COde generation dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rongao Li</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a> (1), 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo-Wen Zhang</a> (1), 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tao Huang</a> (2), 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhihong Sun</a> (2), 
<a href="/search/cs?searchtype=author&query=Lyu%2C+C">Chen Lyu</a> (2), 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guang Liu</a> (1), 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhi Jin</a> (3), 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Ge Li</a> (3) ((1) Beijing Academy of Artificial Intelligence, (2) School of Information Science and Engineering, Shandong Normal University, China, (3) Key Lab of HCST (PKU), MOE, SCS, Peking University, China)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">We introduce TACO, an open-source, large-scale code generation dataset, with
a focus on the optics of algorithms, designed to provide a more challenging
training dataset and evaluation benchmark in the field of code generation
models. TACO includes competition-level programming questions that are more
challenging, to enhance or evaluate problem understanding and reasoning
abilities in real-world programming scenarios. There are 25433 and 1000 coding
problems in training and test set, as well as up to 1.55 million diverse
solution answers. Moreover, each TACO problem includes several fine-grained
labels such as task topics, algorithms, programming skills, and difficulty
levels, providing a more precise reference for the training and evaluation of
code generation models. The dataset and evaluation scripts are available on
Hugging Face Hub (https://huggingface.co/datasets/BAAI/TACO) and Github
(https://github.com/FlagOpen/TACO).
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14856" title="Abstract">arXiv:2312.14856</a> [<a href="/pdf/2312.14856" title="Download PDF">pdf</a>, <a href="/format/2312.14856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Turbulence: Systematically and Automatically Testing Instruction-Tuned  Large Language Models for Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Honarvar%2C+S">Shahin Honarvar</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Wilk%2C+M">Mark van der Wilk</a>, 
<a href="/search/cs?searchtype=author&query=Donaldson%2C+A">Alastair Donaldson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present a method for systematically evaluating the correctness and
robustness of instruction-tuned large language models (LLMs) for code
generation via a new benchmark, Turbulence. Turbulence consists of a large set
of natural language $\textit{question templates}$, each of which is a
programming problem, parameterised so that it can be asked in many different
forms. Each question template has an associated $\textit{test oracle}$ that
judges whether a code solution returned by an LLM is correct. Thus, from a
single question template, it is possible to ask an LLM a
$\textit{neighbourhood}$ of very similar programming questions, and assess the
correctness of the result returned for each question. This allows gaps in an
LLM's code generation abilities to be identified, including
$\textit{anomalies}$ where the LLM correctly solves $\textit{almost all}$
questions in a neighbourhood but fails for particular parameter instantiations.
We present experiments against five LLMs from OpenAI, Cohere and Meta, each at
two temperature configurations. Our findings show that, across the board,
Turbulence is able to reveal gaps in LLM reasoning ability. This goes beyond
merely highlighting that LLMs sometimes produce wrong code (which is no
surprise): by systematically identifying cases where LLMs are able to solve
some problems in a neighbourhood but do not manage to generalise to solve the
whole neighbourhood, our method is effective at highlighting
$\textit{robustness}$ issues. We present data and examples that shed light on
the kinds of mistakes that LLMs make when they return incorrect code results.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14860" title="Abstract">arXiv:2312.14860</a> [<a href="/pdf/2312.14860" title="Download PDF">pdf</a>, <a href="/format/2312.14860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing VAD Systems Based on Multi-Task Learning with Improved Model  Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zuo%2C+L">Lingyun Zuo</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+K">Keyu An</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhijie Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In a speech recognition system, voice activity detection (VAD) is a crucial
frontend module. Addressing the issues of poor noise robustness in traditional
binary VAD systems based on DFSMN, the paper further proposes semantic VAD
based on multi-task learning with improved models for real-time and offline
systems, to meet specific application requirements. Evaluations on internal
datasets show that, compared to the real-time VAD system based on DFSMN, the
real-time semantic VAD system based on RWKV achieves relative decreases in CER
of 7.0\%, DCF of 26.1\% and relative improvement in NRR of 19.2\%. Similarly,
when compared to the offline VAD system based on DFSMN, the offline VAD system
based on SAN-M demonstrates relative decreases in CER of 4.4\%, DCF of 18.6\%
and relative improvement in NRR of 3.5\%.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14861" title="Abstract">arXiv:2312.14861</a> [<a href="/pdf/2312.14861" title="Download PDF">pdf</a>, <a href="/format/2312.14861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Pilot Mixtures in Coded Random Access
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valentini%2C+L">Lorenzo Valentini</a>, 
<a href="/search/cs?searchtype=author&query=Bernardi%2C+E">Elena Bernardi</a>, 
<a href="/search/cs?searchtype=author&query=Paolini%2C+E">Enrico Paolini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Communications Letters, vol. 27, no. 12, pp. 3330-3334, Dec.
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The construction of preamble sequences for channel estimation by
superposition of orthogonal pilots can improve performance of massive
grant-free uplink from machine-type devices. In this letter, a technique is
proposed to obtain full benefit from these "pilot mixtures" in presence of a
base station with a massive number of antennas. The proposed technique consists
of combining pilot mixtures with an intra-slot successive interference
cancellation (SIC) algorithm, referred to as inner SIC, to increase the number
of decoded messages per slot. In framed systems, the synergic effect of inner
SIC and of an outer SIC algorithm across slots, typical of coded random access
protocols, allows achieving a very high reliability with a low number of packet
replicas per active user.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14862" title="Abstract">arXiv:2312.14862</a> [<a href="/pdf/2312.14862" title="Download PDF">pdf</a>, <a href="/format/2312.14862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> YAYI 2: Multilingual Open-Source Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Q">Qingchao Kong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+N">Nan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jia Cao</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+B">Bao Hao</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+B">Baoyu Qu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chenyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Donglei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Feifei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hailong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hanxuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+H">Haojun Pan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jianbin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Jiangtao Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junfeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Liduo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+L">Lifeng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lili Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Minzheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P">Ping Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qingxiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rui Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+R">Rui Zou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruiqun Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Taiwen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaodong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaofei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xina Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+X">Xing Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xinglin Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yanni Hao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yigang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Ying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yongyu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yungan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangsheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhaoxin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhen Luo</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+W">Wenji Mao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+D">Dajun Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As the latest advancements in natural language processing, large language
models (LLMs) have achieved human-level language understanding and generation
abilities in many real-world tasks, and even have been regarded as a potential
path to the artificial general intelligence. To better facilitate research on
LLMs, many open-source LLMs, such as Llama 2 and Falcon, have recently been
proposed and gained comparable performances to proprietary models. However,
these models are primarily designed for English scenarios and exhibit poor
performances in Chinese contexts. In this technical report, we propose YAYI 2,
including both base and chat models, with 30 billion parameters. YAYI 2 is
pre-trained from scratch on a multilingual corpus which contains 2.65 trillion
tokens filtered by our pre-training data processing pipeline. The base model is
aligned with human values through supervised fine-tuning with millions of
instructions and reinforcement learning from human feedback. Extensive
experiments on multiple benchmarks, such as MMLU and CMMLU, consistently
demonstrate that the proposed YAYI 2 outperforms other similar sized
open-source models.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14867" title="Abstract">arXiv:2312.14867</a> [<a href="/pdf/2312.14867" title="Download PDF">pdf</a>, <a href="/format/2312.14867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VIEScore: Towards Explainable Metrics for Conditional Image Synthesis  Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ku%2C+M">Max Ku</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Dongfu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+C">Cong Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+X">Xiang Yue</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenhu Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multimedia (cs.MM)

</div>
<p class="mathjax">In the rapidly advancing field of conditional image generation research,
challenges such as limited explainability lie in effectively evaluating the
performance and capabilities of various models. This paper introduces VIESCORE,
a Visual Instruction-guided Explainable metric for evaluating any conditional
image generation tasks. VIESCORE leverages general knowledge from Multimodal
Large Language Models (MLLMs) as the backbone and does not require training or
fine-tuning. We evaluate VIESCORE on seven prominent tasks in conditional image
tasks and found: (1) VIESCORE (GPT4-v) achieves a high Spearman correlation of
0.3 with human evaluations, while the human-to-human correlation is 0.45. (2)
VIESCORE (with open-source MLLM) is significantly weaker than GPT-4v in
evaluating synthetic images. (3) VIESCORE achieves a correlation on par with
human ratings in the generation tasks but struggles in editing tasks. With
these results, we believe VIESCORE shows its great potential to replace human
judges in evaluating image synthesis tasks.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14869" title="Abstract">arXiv:2312.14869</a> [<a href="/pdf/2312.14869" title="Download PDF">pdf</a>, <a href="/format/2312.14869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatiotemporal-Linear: Towards Universal Multivariate Time Series  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zuo%2C+A">Aiyinsi Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haixi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zirui Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Ce Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Within the field of complicated multivariate time series forecasting (TSF),
popular techniques frequently rely on intricate deep learning architectures,
ranging from transformer-based designs to recurrent neural networks. However,
recent findings suggest that simple Linear models can surpass sophisticated
constructs on diverse datasets. These models directly map observation to
multiple future time steps, thereby minimizing error accumulation in iterative
multi-step prediction. Yet, these models fail to incorporate spatial and
temporal information within the data, which is critical for capturing patterns
and dependencies that drive insightful predictions. This oversight often leads
to performance bottlenecks, especially under specific sequence lengths and
dataset conditions, preventing their universal application. In response, we
introduce the SpatioTemporal-Linear (STL) framework. STL seamlessly integrates
time-embedded and spatially-informed bypasses to augment the Linear-based
architecture. These extra routes offer a more robust and refined regression to
the data, particularly when the amount of observation is limited and the
capacity of simple linear layers to capture dependencies declines. Empirical
evidence highlights STL's prowess, outpacing both Linear and Transformer
benchmarks across varied observation and prediction durations and datasets.
Such robustness accentuates its suitability across a spectrum of applications,
including but not limited to, traffic trajectory and rare disease progression
forecasting. Through this discourse, we not only validate the STL's distinctive
capacities to become a more general paradigm in multivariate time-series
prediction using deep-learning techniques but also stress the need to tackle
data-scarce prediction scenarios for universal application. Code will be made
available.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14870" title="Abstract">arXiv:2312.14870</a> [<a href="/pdf/2312.14870" title="Download PDF">pdf</a>, <a href="/format/2312.14870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical Reasoning for Financial Reports
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arun%2C+A">Abhinav Arun</a>, 
<a href="/search/cs?searchtype=author&query=Dhiman%2C+A">Ashish Dhiman</a>, 
<a href="/search/cs?searchtype=author&query=Soni%2C+M">Mehul Soni</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yibei Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 11 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Financial reports offer critical insights into a company's operations, yet
their extensive length typically spanning 30 40 pages poses challenges for
swift decision making in dynamic markets. To address this, we leveraged
finetuned Large Language Models (LLMs) to distill key indicators and
operational metrics from these reports basis questions from the user. We
devised a method to locate critical data, and leverage the FinQA dataset to
fine-tune both Llama-2 7B and T5 models for customized question answering. We
achieved results comparable to baseline on the final numerical answer, a
competitive accuracy in numerical reasoning and calculation.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14871" title="Abstract">arXiv:2312.14871</a> [<a href="/pdf/2312.14871" title="Download PDF">pdf</a>, <a href="/format/2312.14871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BrainVis: Exploring the Bridge between Brain and Visual Signals via  Image Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Honghao Fu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhiqi Shen</a>, 
<a href="/search/cs?searchtype=author&query=Chin%2C+J+J">Jing Jih Chin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Analyzing and reconstructing visual stimuli from brain signals effectively
advances understanding of the human visual system. However, the EEG signals are
complex and contain a amount of noise. This leads to substantial limitations in
existing works of visual stimuli reconstruction from EEG, such as difficulties
in aligning EEG embeddings with the fine-grained semantic information and a
heavy reliance on additional large self-collected dataset for training. To
address these challenges, we propose a novel approach called BrainVis. Firstly,
we divide the EEG signals into various units and apply a self-supervised
approach on them to obtain EEG time-domain features, in an attempt to ease the
training difficulty. Additionally, we also propose to utilize the
frequency-domain features to enhance the EEG representations. Then, we
simultaneously align EEG time-frequency embeddings with the interpolation of
the coarse and fine-grained semantics in the CLIP space, to highlight the
primary visual components and reduce the cross-modal alignment difficulty.
Finally, we adopt the cascaded diffusion models to reconstruct images. Our
proposed BrainVis outperforms state of the arts in both semantic fidelity
reconstruction and generation quality. Notably, we reduce the training data
scale to 10% of the previous work.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14874" title="Abstract">arXiv:2312.14874</a> [<a href="/pdf/2312.14874" title="Download PDF">pdf</a>, <a href="/format/2312.14874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallel Prefix Sum with SIMD
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wangda Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanbin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ross%2C+K+A">Kenneth A. Ross</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The prefix sum operation is a useful primitive with a broad range of
applications. For database systems, it is a building block of many important
operators including join, sort and filter queries. In this paper, we study
different methods of computing prefix sums with SIMD instructions and multiple
threads. For SIMD, we implement and compare horizontal and vertical
computations, as well as a theoretically work-efficient balanced tree version
using gather/scatter instructions. With multithreading, the memory bandwidth
can become the bottleneck of prefix sum computations. We propose a new method
that partitions data into cache-sized smaller partitions to achieve better data
locality and reduce bandwidth demands from RAM. We also investigate four
different ways of organizing the computation sub-procedures, which have
different performance and usability characteristics. In the experiments we find
that the most efficient prefix sum computation using our partitioning technique
is up to 3x faster than two standard library implementations that already use
SIMD and multithreading.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14875" title="Abstract">arXiv:2312.14875</a> [<a href="/pdf/2312.14875" title="Download PDF">pdf</a>, <a href="/format/2312.14875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automating the Design of Multigrid Methods with Evolutionary Program  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Schmitt%2C+J">Jonas Schmitt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Formal Languages and Automata Theory (cs.FL); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Many of the most fundamental laws of nature can be formulated as partial
differential equations (PDEs). Understanding these equations is, therefore, of
exceptional importance for many branches of modern science and engineering.
However, since the general solution of many PDEs is unknown, the efficient
approximate solution of these equations is one of humanity's greatest
challenges. While multigrid represents one of the most effective methods for
solving PDEs numerically, in many cases, the design of an efficient or at least
working multigrid solver is an open problem. This thesis demonstrates that
grammar-guided genetic programming, an evolutionary program synthesis
technique, can discover multigrid methods of unprecedented structure that
achieve a high degree of efficiency and generalization. For this purpose, we
develop a novel context-free grammar that enables the automated generation of
multigrid methods in a symbolically-manipulable formal language, based on which
we can apply the same multigrid-based solver to problems of different sizes
without having to adapt its internal structure. Treating the automated design
of an efficient multigrid method as a program synthesis task allows us to find
novel sequences of multigrid operations, including the combination of different
smoothing and coarse-grid correction steps on each level of the discretization
hierarchy. To prove the feasibility of this approach, we present its
implementation in the form of the Python framework EvoStencils, which is freely
available as open-source software. This implementation comprises all steps from
representing the algorithmic sequence of a multigrid method in the form of a
directed acyclic graph of Python objects to its automatic generation and
optimization using the capabilities of the code generation framework
ExaStencils and the evolutionary computation library DEAP.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14877" title="Abstract">arXiv:2312.14877</a> [<a href="/pdf/2312.14877" title="Download PDF">pdf</a>, <a href="/format/2312.14877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Knowledge Extraction from Large Language Models using Social  Choice Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Potyka%2C+N">Nico Potyka</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuqicheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yunjie He</a>, 
<a href="/search/cs?searchtype=author&query=Kharlamov%2C+E">Evgeny Kharlamov</a>, 
<a href="/search/cs?searchtype=author&query=Staab%2C+S">Steffen Staab</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAMAS 2024 as a full paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large-language models (LLMs) have the potential to support a wide range of
applications like conversational agents, creative writing, text improvement,
and general query answering. However, they are ill-suited for query answering
in high-stake domains like medicine because they generate answers at random and
their answers are typically not robust - even the same query can result in
different answers when prompted multiple times. In order to improve the
robustness of LLM queries, we propose using ranking queries repeatedly and to
aggregate the queries using methods from social choice theory. We study ranking
queries in diagnostic settings like medical and fault diagnosis and discuss how
the Partial Borda Choice function from the literature can be applied to merge
multiple query results. We discuss some additional interesting properties in
our setting and evaluate the robustness of our approach empirically.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14878" title="Abstract">arXiv:2312.14878</a> [<a href="/pdf/2312.14878" title="Download PDF">pdf</a>, <a href="/format/2312.14878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pangu-Agent: A Fine-Tunable Generalist Agent with Structured Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Christianos%2C+F">Filippos Christianos</a>, 
<a href="/search/cs?searchtype=author&query=Papoudakis%2C+G">Georgios Papoudakis</a>, 
<a href="/search/cs?searchtype=author&query=Zimmer%2C+M">Matthieu Zimmer</a>, 
<a href="/search/cs?searchtype=author&query=Coste%2C+T">Thomas Coste</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhihao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingxuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Khandelwal%2C+K">Khyati Khandelwal</a>, 
<a href="/search/cs?searchtype=author&query=Doran%2C+J">James Doran</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xidong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiacheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zheng Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yicheng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jianye Hao</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+K">Kun Shao</a>, 
<a href="/search/cs?searchtype=author&query=Bou-Ammar%2C+H">Haitham Bou-Ammar</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> paper and appendix, 27 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">A key method for creating Artificial Intelligence (AI) agents is
Reinforcement Learning (RL). However, constructing a standalone RL policy that
maps perception to action directly encounters severe problems, chief among them
being its lack of generality across multiple tasks and the need for a large
amount of training data. The leading cause is that it cannot effectively
integrate prior information into the perception-action cycle when devising the
policy. Large language models (LLMs) emerged as a fundamental way to
incorporate cross-domain knowledge into AI agents but lack crucial learning and
adaptation toward specific decision problems. This paper presents a general
framework model for integrating and learning structured reasoning into AI
agents' policies. Our methodology is motivated by the modularity found in the
human brain. The framework utilises the construction of intrinsic and extrinsic
functions to add previous understandings of reasoning structures. It also
provides the adaptive ability to learn models inside every module or function,
consistent with the modular structure of cognitive processes. We describe the
framework in-depth and compare it with other AI pipelines and existing
frameworks. The paper explores practical applications, covering experiments
that show the effectiveness of our method. Our results indicate that AI agents
perform and adapt far better when organised reasoning and prior knowledge are
embedded. This opens the door to more resilient and general AI agent systems.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14880" title="Abstract">arXiv:2312.14880</a> [<a href="/pdf/2312.14880" title="Download PDF">pdf</a>, <a href="/format/2312.14880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SutraNets: Sub-series Autoregressive Networks for Long-Sequence,  Probabilistic Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bergsma%2C+S">Shane Bergsma</a>, 
<a href="/search/cs?searchtype=author&query=Zeyl%2C+T">Timothy Zeyl</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Lei Guo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of 37th Conference on Neural Information Processing
  Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We propose SutraNets, a novel method for neural probabilistic forecasting of
long-sequence time series. SutraNets use an autoregressive generative model to
factorize the likelihood of long sequences into products of conditional
probabilities. When generating long sequences, most autoregressive approaches
suffer from harmful error accumulation, as well as challenges in modeling
long-distance dependencies. SutraNets treat long, univariate prediction as
multivariate prediction over lower-frequency sub-series. Autoregression
proceeds across time and across sub-series in order to ensure coherent
multivariate (and, hence, high-frequency univariate) outputs. Since sub-series
can be generated using fewer steps, SutraNets effectively reduce error
accumulation and signal path distances. We find SutraNets to significantly
improve forecasting accuracy over competitive alternatives on six real-world
datasets, including when we vary the number of sub-series and scale up the
depth and width of the underlying sequence models.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14886" title="Abstract">arXiv:2312.14886</a> [<a href="/pdf/2312.14886" title="Download PDF">pdf</a>, <a href="/ps/2312.14886" title="Download PostScript">ps</a>, <a href="/format/2312.14886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample Path Regularity of Gaussian Processes from the Covariance Kernel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Da+Costa%2C+N">Natha&#xeb;l Da Costa</a>, 
<a href="/search/cs?searchtype=author&query=Pf%C3%B6rtner%2C+M">Marvin Pf&#xf6;rtner</a>, 
<a href="/search/cs?searchtype=author&query=Da+Costa%2C+L">Lancelot Da Costa</a>, 
<a href="/search/cs?searchtype=author&query=Hennig%2C+P">Philipp Hennig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Probability (math.PR); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">Gaussian processes (GPs) are the most common formalism for defining
probability distributions over spaces of functions. While applications of GPs
are myriad, a comprehensive understanding of GP sample paths, i.e. the function
spaces over which they define a probability measure on, is lacking. In
practice, GPs are not constructed through a probability measure, but instead
through a mean function and a covariance kernel. In this paper we provide
necessary and sufficient conditions on the covariance kernel for the sample
paths of the corresponding GP to attain a given regularity. We use the
framework of H\"older regularity as it grants us particularly straightforward
conditions, which simplify further in the cases of stationary and isotropic
GPs. We then demonstrate that our results allow for novel and unusually tight
characterisations of the sample path regularities of the GPs commonly used in
machine learning applications, such as the Mat\'ern GPs.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14890" title="Abstract">arXiv:2312.14890</a> [<a href="/pdf/2312.14890" title="Download PDF">pdf</a>, <a href="/format/2312.14890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NPHardEval: Dynamic Benchmark on Reasoning Ability of Large Language  Models via Complexity Classes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lizhou Fan</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+W">Wenyue Hua</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lingyao Li</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+H">Haoyang Ling</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hemphill%2C+L">Libby Hemphill</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 6 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computational Complexity (cs.CC); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Complex reasoning ability is one of the most important features of current
LLMs, which has also been leveraged to play an integral role in complex
decision-making tasks. Therefore, the investigation into the reasoning
capabilities of Large Language Models (LLMs) is critical: numerous benchmarks
have been established to assess the reasoning abilities of LLMs. However,
current benchmarks are inadequate in offering a rigorous evaluation of the full
extent of reasoning abilities that LLMs are capable of achieving. They are also
prone to the risk of overfitting, as these benchmarks, being publicly
accessible and static, allow models to potentially tailor their responses to
specific benchmark metrics, thereby inflating their performance. Addressing
these limitations, our research introduces a new benchmark, named NPHardEval.
This benchmark is designed to evaluate the reasoning abilities of LLMs across a
broad spectrum of 900 algorithmic questions, extending up to the NP-Hard
complexity class. These questions are meticulously chosen to represent a wide
range of complexity class below the NP-hard complexity class, offering a
rigorous measure of the reasoning ability of LLMs. Through this study, we shed
light on the current state of reasoning in LLMs, providing an objective and
rigorous perspective through the comparison of LLMs' performance across complex
classes. Moreover, this benchmark is designed with a dynamic update mechanism,
where the datapoints are refreshed on a monthly basis. Such regular updates
play a crucial role in mitigating the risk of LLMs overfitting to the
benchmark, promoting a more accurate and reliable assessment of their reasoning
capabilities. The benchmark dataset and code of NPHardEval are available at
https://github.com/casmlab/NPHardEval.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14895" title="Abstract">arXiv:2312.14895</a> [<a href="/pdf/2312.14895" title="Download PDF">pdf</a>, <a href="/format/2312.14895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FAST: Feature Aware Similarity Thresholding for Weak Unlearning in  Black-Box Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Panda%2C+S">Subhodip Panda</a>, 
<a href="/search/cs?searchtype=author&query=AP%2C+P">Prathosh AP</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The heightened emphasis on the regulation of deep generative models,
propelled by escalating concerns pertaining to privacy and compliance with
regulatory frameworks, underscores the imperative need for precise control
mechanisms over these models. This urgency is particularly underscored by
instances in which generative models generate outputs that encompass
objectionable, offensive, or potentially injurious content. In response,
machine unlearning has emerged to selectively forget specific knowledge or
remove the influence of undesirable data subsets from pre-trained models.
However, modern machine unlearning approaches typically assume access to model
parameters and architectural details during unlearning, which is not always
feasible. In multitude of downstream tasks, these models function as black-box
systems, with inaccessible pre-trained parameters, architectures, and training
data. In such scenarios, the possibility of filtering undesired outputs becomes
a practical alternative. The primary goal of this study is twofold: first, to
elucidate the relationship between filtering and unlearning processes, and
second, to formulate a methodology aimed at mitigating the display of
undesirable outputs generated from models characterized as black-box systems.
Theoretical analysis in this study demonstrates that, in the context of
black-box models, filtering can be seen as a form of weak unlearning. Our
proposed \textbf{\textit{Feature Aware Similarity Thresholding(FAST)}} method
effectively suppresses undesired outputs by systematically encoding the
representation of unwanted features in the latent space.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14896" title="Abstract">arXiv:2312.14896</a> [<a href="/pdf/2312.14896" title="Download PDF">pdf</a>, <a href="/format/2312.14896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strong anti-Hebbian plasticity alters the convexity of network attractor  landscapes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+L">Lulu Gong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xudong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ching%2C+S">ShiNung Ching</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Systems and Control (eess.SY); Dynamical Systems (math.DS); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">In this paper, we study recurrent neural networks in the presence of pairwise
learning rules. We are specifically interested in how the attractor landscapes
of such networks become altered as a function of the strength and nature
(Hebbian vs. anti-Hebbian) of learning, which may have a bearing on the ability
of such rules to mediate large-scale optimization problems. Through formal
analysis, we show that a transition from Hebbian to anti-Hebbian learning
brings about a pitchfork bifurcation that destroys convexity in the network
attractor landscape. In larger-scale settings, this implies that anti-Hebbian
plasticity will bring about multiple stable equilibria, and such effects may be
outsized at interconnection or `choke' points. Furthermore, attractor
landscapes are more sensitive to slower learning rates than faster ones. These
results provide insight into the types of objective functions that can be
encoded via different pairwise plasticity rules.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14897" title="Abstract">arXiv:2312.14897</a> [<a href="/pdf/2312.14897" title="Download PDF">pdf</a>, <a href="/format/2312.14897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the Design of Linear Controllers for Homogeneous Platooning  under Disturbances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=da+Silva%2C+E+A">Emerson A. da Silva</a>, 
<a href="/search/cs?searchtype=author&query=Mozelli%2C+L+A">Leonardo A. Mozelli</a>, 
<a href="/search/cs?searchtype=author&query=Neto%2C+A+A">Armando A. Neto</a>, 
<a href="/search/cs?searchtype=author&query=Souza%2C+F+O">Fernando O. Souza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper addresses the problem of longitudinal platooning control of
homogeneous vehicles subject to external disturbances, such as wind gusts, road
slopes, and parametric uncertainties. Our control objective is to maintain the
relative distance of the cars regarding their nearby teammates in a
decentralized manner. Therefore, we proposed a novel control law to compute the
acceleration commands of each vehicle that includes the integral of the spacing
error, which endows the controller with the capability to mitigate external
disturbances in steady-state conditions. We adopt a constant distance spacing
policy and employ generalized look-ahead and bidirectional network topologies.
We provide formal conditions for the controller synthesis that ensure the
internal stability of the platoon under the proposed control law in the
presence of constant and bounded disturbances affecting multiple vehicles.
Experiments considering nonlinear vehicle models in the high-fidelity CARLA
simulator environment under different disturbances, parametric uncertainties,
and several network topologies demonstrate the effectiveness of our approach.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14898" title="Abstract">arXiv:2312.14898</a> [<a href="/pdf/2312.14898" title="Download PDF">pdf</a>, <a href="/format/2312.14898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enriching Automatic Test Case Generation by Extracting Relevant Test  Inputs from Bug Reports
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ou%C3%A9draogo%2C+W+C">Wendk&#xfb;uni C. Ou&#xe9;draogo</a>, 
<a href="/search/cs?searchtype=author&query=Plein%2C+L">Laura Plein</a>, 
<a href="/search/cs?searchtype=author&query=Kabor%C3%A9%2C+K">Kader Kabor&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Habib%2C+A">Andrew Habib</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+J">Jacques Klein</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>, 
<a href="/search/cs?searchtype=author&query=Bissyand%C3%A9%2C+T+F">Tegawend&#xe9; F. Bissyand&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The quality of a software is highly dependent on the quality of the tests it
is submitted to. Writing tests for bug detection is thus essential. However, it
is time-consuming when done manually. Automating test cases generation has
therefore been an exciting research area in the software engineering community.
Most approaches have been focused on generating unit tests. Unfortunately,
current efforts often do not lead to the generation of relevant inputs, which
limits the efficiency of automatically generated tests. Towards improving the
relevance of test inputs, we present \name, a technique for exploring bug
reports to identify input values that can be fed to automatic test generation
tools. In this work, we investigate the performance of using inputs extracted
from bug reports with \name to generate test cases with Evosuite. The
evaluation is performed on the Defects4J benchmark. For Defects4J projects, our
study has shown that \name successfully extracted 68.68\% of relevant inputs
when using regular expression in its approach versus 50.21\% relevant inputs
without regular expression. Further, our study has shown the potential to
improve the Line and Instruction Coverage across all projects. Overall, we
successfully collected relevant inputs that led to the detection of 45 bugs
that were previously undetected by the baseline.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14915" title="Abstract">arXiv:2312.14915</a> [<a href="/pdf/2312.14915" title="Download PDF">pdf</a>, <a href="/format/2312.14915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PoseGen: Learning to Generate 3D Human Pose Dataset with NeRF
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gholami%2C+M">Mohsen Gholami</a>, 
<a href="/search/cs?searchtype=author&query=Ward%2C+R">Rabab Ward</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z+J">Z. Jane Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper proposes an end-to-end framework for generating 3D human pose
datasets using Neural Radiance Fields (NeRF). Public datasets generally have
limited diversity in terms of human poses and camera viewpoints, largely due to
the resource-intensive nature of collecting 3D human pose data. As a result,
pose estimators trained on public datasets significantly underperform when
applied to unseen out-of-distribution samples. Previous works proposed
augmenting public datasets by generating 2D-3D pose pairs or rendering a large
amount of random data. Such approaches either overlook image rendering or
result in suboptimal datasets for pre-trained models. Here we propose PoseGen,
which learns to generate a dataset (human 3D poses and images) with a feedback
loss from a given pre-trained pose estimator. In contrast to prior art, our
generated data is optimized to improve the robustness of the pre-trained model.
The objective of PoseGen is to learn a distribution of data that maximizes the
prediction error of a given pre-trained model. As the learned data distribution
contains OOD samples of the pre-trained model, sampling data from such a
distribution for further fine-tuning a pre-trained model improves the
generalizability of the model. This is the first work that proposes NeRFs for
3D human data generation. NeRFs are data-driven and do not require 3D scans of
humans. Therefore, using NeRF for data generation is a new direction for
convenient user-specific data generation. Our extensive experiments show that
the proposed PoseGen improves two baseline models (SPIN and HybrIK) on four
datasets with an average 6% relative improvement.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14916" title="Abstract">arXiv:2312.14916</a> [<a href="/pdf/2312.14916" title="Download PDF">pdf</a>, <a href="/format/2312.14916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complexity of Local Search for Euclidean Clustering Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manthey%2C+B">Bodo Manthey</a>, 
<a href="/search/cs?searchtype=author&query=Morawietz%2C+N">Nils Morawietz</a>, 
<a href="/search/cs?searchtype=author&query=van+Rhijn%2C+J">Jesse van Rhijn</a>, 
<a href="/search/cs?searchtype=author&query=Sommer%2C+F">Frank Sommer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We show that the simplest local search heuristics for two natural Euclidean
clustering problems are PLS-complete. First, we show that the Hartigan--Wong
method for $k$-Means clustering is PLS-complete, even when $k = 2$. Second, we
show the same result for the Flip heuristic for Max Cut, even when the edge
weights are given by the (squared) Euclidean distances between the points in
some set $\mathcal{X} \subseteq \mathbb{R}^d$; a problem which is equivalent to
Min Sum 2-Clustering.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14919" title="Abstract">arXiv:2312.14919</a> [<a href="/pdf/2312.14919" title="Download PDF">pdf</a>, <a href="/format/2312.14919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lift-Attend-Splat: Bird&#x27;s-eye-view camera-lidar fusion using  transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gunn%2C+J">James Gunn</a>, 
<a href="/search/cs?searchtype=author&query=Lenyk%2C+Z">Zygmunt Lenyk</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Anuj Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Donati%2C+A">Andrea Donati</a>, 
<a href="/search/cs?searchtype=author&query=Buburuzan%2C+A">Alexandru Buburuzan</a>, 
<a href="/search/cs?searchtype=author&query=Redford%2C+J">John Redford</a>, 
<a href="/search/cs?searchtype=author&query=Mueller%2C+R">Romain Mueller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Combining complementary sensor modalities is crucial to providing robust
perception for safety-critical robotics applications such as autonomous driving
(AD). Recent state-of-the-art camera-lidar fusion methods for AD rely on
monocular depth estimation which is a notoriously difficult task compared to
using depth information from the lidar directly. Here, we find that this
approach does not leverage depth as expected and show that naively improving
depth estimation does not lead to improvements in object detection performance
and that, strikingly, removing depth estimation altogether does not degrade
object detection performance. This suggests that relying on monocular depth
could be an unnecessary architectural bottleneck during camera-lidar fusion. In
this work, we introduce a novel fusion method that bypasses monocular depth
estimation altogether and instead selects and fuses camera and lidar features
in a bird's-eye-view grid using a simple attention mechanism. We show that our
model can modulate its use of camera features based on the availability of
lidar features and that it yields better 3D object detection on the nuScenes
dataset than baselines relying on monocular depth estimation.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14920" title="Abstract">arXiv:2312.14920</a> [<a href="/pdf/2312.14920" title="Download PDF">pdf</a>, <a href="/ps/2312.14920" title="Download PostScript">ps</a>, <a href="/format/2312.14920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Sampled Clustering Algorithm for Rice Phenotypic Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+M">Mithun Singh</a>, 
<a href="/search/cs?searchtype=author&query=Ahuja%2C+K">Kapil Ahuja</a>, 
<a href="/search/cs?searchtype=author&query=Ratnaparkhe%2C+M+B">Milind B. Ratnaparkhe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 Pages, 2 Figures, 6 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Phenotypic (or Physical) characteristics of plant species are commonly used
to perform clustering. In one of our recent works (Shastri et al. (2021)), we
used a probabilistically sampled (using pivotal sampling) and spectrally
clustered algorithm to group soybean species. These techniques were used to
obtain highly accurate clusterings at a reduced cost. In this work, we extend
the earlier algorithm to cluster rice species. We improve the base algorithm in
three ways. First, we propose a new function to build the similarity matrix in
Spectral Clustering. Commonly, a natural exponential function is used for this
purpose. Based upon the spectral graph theory and the involved Cheeger's
inequality, we propose the use a base "a" exponential function instead. This
gives a similarity matrix spectrum favorable for clustering, which we support
via an eigenvalue analysis.
<br />Second, the function used to build the similarity matrix in Spectral
Clustering was earlier scaled with a fixed factor (called global scaling).
Based upon the idea of Zelnik-Manor and Perona (2004), we now use a factor that
varies with matrix elements (called local scaling) and works better. Third, to
compute the inclusion probability of a specie in the pivotal sampling
algorithm, we had earlier used the notion of deviation that captured how far
specie's characteristic values were from their respective base values (computed
over all species). A maximum function was used before to find the base values.
We now use a median function, which is more intuitive. We support this choice
using a statistical analysis. With experiments on 1865 rice species, we
demonstrate that in terms of silhouette values, our new Sampled Spectral
Clustering is 61% better than Hierarchical Clustering (currently prevalent).
Also, our new algorithm is significantly faster than Hierarchical Clustering
due to the involved sampling.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14923" title="Abstract">arXiv:2312.14923</a> [<a href="/pdf/2312.14923" title="Download PDF">pdf</a>, <a href="/format/2312.14923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast-NTK: Parameter-Efficient Unlearning for Large-Scale Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guihong Li</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+H">Hsiang Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chun-Fu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Marculescu%2C+R">Radu Marculescu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The rapid growth of machine learning has spurred legislative initiatives such
as ``the Right to be Forgotten,'' allowing users to request data removal. In
response, ``machine unlearning'' proposes the selective removal of unwanted
data without the need for retraining from scratch. While the
Neural-Tangent-Kernel-based (NTK-based) unlearning method excels in
performance, it suffers from significant computational complexity, especially
for large-scale models and datasets. Our work introduces ``Fast-NTK,'' a novel
NTK-based unlearning algorithm that significantly reduces the computational
complexity by incorporating parameter-efficient fine-tuning methods, such as
fine-tuning batch normalization layers in a CNN or visual prompts in a vision
transformer. Our experimental results demonstrate scalability to much larger
neural networks and datasets (e.g., 88M parameters; 5k images), surpassing the
limitations of previous full-model NTK-based approaches designed for smaller
cases (e.g., 8M parameters; 500 images). Notably, our approach maintains a
performance comparable to the traditional method of retraining on the retain
set alone. Fast-NTK can thus enable for practical and scalable NTK-based
unlearning in deep neural networks.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14924" title="Abstract">arXiv:2312.14924</a> [<a href="/pdf/2312.14924" title="Download PDF">pdf</a>, <a href="/format/2312.14924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training Convolutional Neural Networks with the Forward-Forward  algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scodellaro%2C+R">Riccardo Scodellaro</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+A">Ajinkya Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Alves%2C+F">Frauke Alves</a>, 
<a href="/search/cs?searchtype=author&query=Schr%C3%B6ter%2C+M">Matthias Schr&#xf6;ter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The recent successes in analyzing images with deep neural networks are almost
exclusively achieved with Convolutional Neural Networks (CNNs). The training of
these CNNs, and in fact of all deep neural network architectures, uses the
backpropagation algorithm where the output of the network is compared with the
desired result and the difference is then used to tune the weights of the
network towards the desired outcome. In a 2022 preprint, Geoffrey Hinton
suggested an alternative way of training which passes the desired results
together with the images at the input of the network. This so called Forward
Forward (FF) algorithm has up to now only been used in fully connected
networks. In this paper, we show how the FF paradigm can be extended to CNNs.
Our FF-trained CNN, featuring a novel spatially-extended labeling technique,
achieves a classification accuracy of 99.0% on the MNIST hand-written digits
dataset. We show how different hyperparameters affect the performance of the
proposed algorithm and compare the results with CNN trained with the standard
backpropagation approach. Furthermore, we use Class Activation Maps to
investigate which type of features are learnt by the FF algorithm.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14925" title="Abstract">arXiv:2312.14925</a> [<a href="/pdf/2312.14925" title="Download PDF">pdf</a>, <a href="/format/2312.14925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Reinforcement Learning from Human Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaufmann%2C+T">Timo Kaufmann</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+P">Paul Weng</a>, 
<a href="/search/cs?searchtype=author&query=Bengs%2C+V">Viktor Bengs</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%BCllermeier%2C+E">Eyke H&#xfc;llermeier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Reinforcement learning from human feedback (RLHF) is a variant of
reinforcement learning (RL) that learns from human feedback instead of relying
on an engineered reward function. Building on prior work on the related setting
of preference-based reinforcement learning (PbRL), it stands at the
intersection of artificial intelligence and human-computer interaction. This
positioning offers a promising avenue to enhance the performance and
adaptability of intelligent systems while also improving the alignment of their
objectives with human values. The training of Large Language Models (LLMs) has
impressively demonstrated this potential in recent years, where RLHF played a
decisive role in targeting the model's capabilities toward human objectives.
This article provides a comprehensive overview of the fundamentals of RLHF,
exploring the intricate dynamics between machine agents and human input. While
recent focus has been on RLHF for LLMs, our survey adopts a broader
perspective, examining the diverse applications and wide-ranging impact of the
technique. We delve into the core principles that underpin RLHF, shedding light
on the symbiotic relationship between algorithms and human feedback, and
discuss the main research trends in the field. By synthesizing the current
landscape of RLHF research, this article aims to provide researchers as well as
practitioners with a comprehensive understanding of this rapidly growing field
of research.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14929" title="Abstract">arXiv:2312.14929</a> [<a href="/pdf/2312.14929" title="Download PDF">pdf</a>, <a href="/format/2312.14929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MACS: Mass Conditioned 3D Hand and Object Motion Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shimada%2C+S">Soshi Shimada</a>, 
<a href="/search/cs?searchtype=author&query=Mueller%2C+F">Franziska Mueller</a>, 
<a href="/search/cs?searchtype=author&query=Bednarik%2C+J">Jan Bednarik</a>, 
<a href="/search/cs?searchtype=author&query=Doosti%2C+B">Bardia Doosti</a>, 
<a href="/search/cs?searchtype=author&query=Bickel%2C+B">Bernd Bickel</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+D">Danhang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Golyanik%2C+V">Vladislav Golyanik</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+J">Jonathan Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Theobalt%2C+C">Christian Theobalt</a>, 
<a href="/search/cs?searchtype=author&query=Beeler%2C+T">Thabo Beeler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">The physical properties of an object, such as mass, significantly affect how
we manipulate it with our hands. Surprisingly, this aspect has so far been
neglected in prior work on 3D motion synthesis. To improve the naturalness of
the synthesized 3D hand object motions, this work proposes MACS the first MAss
Conditioned 3D hand and object motion Synthesis approach. Our approach is based
on cascaded diffusion models and generates interactions that plausibly adjust
based on the object mass and interaction type. MACS also accepts a manually
drawn 3D object trajectory as input and synthesizes the natural 3D hand motions
conditioned by the object mass. This flexibility enables MACS to be used for
various downstream applications, such as generating synthetic training data for
ML tasks, fast animation of hands for graphics workflows, and generating
character interactions for computer games. We show experimentally that a
small-scale dataset is sufficient for MACS to reasonably generalize across
interpolated and extrapolated object masses unseen during the training.
Furthermore, MACS shows moderate generalization to unseen objects, thanks to
the mass-conditioned contact labels generated by our surface contact synthesis
model ConNet. Our comprehensive user study confirms that the synthesized 3D
hand-object interactions are highly plausible and realistic.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Mon, 25 Dec 23</h3>
<dl>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14190" title="Abstract">arXiv:2312.14190</a> (cross-list from physics.data-an) [<a href="/pdf/2312.14190" title="Download PDF">pdf</a>, <a href="/format/2312.14190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning for Anomaly Detection in Particle Physics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Belis%2C+V">Vasilis Belis</a>, 
<a href="/search/physics?searchtype=author&query=Odagiu%2C+P">Patrick Odagiu</a>, 
<a href="/search/physics?searchtype=author&query=%C3%85rrestad%2C+T+K">Thea Kl&#xe6;boe &#xc5;rrestad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Invited review article, Reviews in Physics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Analysis, Statistics and Probability (physics.data-an)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex); Quantum Physics (quant-ph)

</div>
<p class="mathjax">The detection of out-of-distribution data points is a common task in particle
physics. It is used for monitoring complex particle detectors or for
identifying rare and unexpected events that may be indicative of new phenomena
or physics beyond the Standard Model. Recent advances in Machine Learning for
anomaly detection have encouraged the utilization of such techniques on
particle physics problems. This review article provides an overview of the
state-of-the-art techniques for anomaly detection in particle physics using
machine learning. We discuss the challenges associated with anomaly detection
in large and complex data sets, such as those produced by high-energy particle
colliders, and highlight some of the successful applications of anomaly
detection in particle physics experiments.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14203" title="Abstract">arXiv:2312.14203</a> (cross-list from q-fin.PM) [<a href="/pdf/2312.14203" title="Download PDF">pdf</a>, <a href="/format/2312.14203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shai: A large language model for asset management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Guo%2C+Z">Zhongyang Guo</a>, 
<a href="/search/q-fin?searchtype=author&query=Jiang%2C+G">Guanran Jiang</a>, 
<a href="/search/q-fin?searchtype=author&query=Zhang%2C+Z">Zhongdan Zhang</a>, 
<a href="/search/q-fin?searchtype=author&query=Li%2C+P">Peng Li</a>, 
<a href="/search/q-fin?searchtype=author&query=Wang%2C+Z">Zhefeng Wang</a>, 
<a href="/search/q-fin?searchtype=author&query=Wang%2C+Y">Yinchun Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Portfolio Management (q-fin.PM)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper introduces "Shai" a 10B level large language model specifically
designed for the asset management industry, built upon an open-source
foundational model. With continuous pre-training and fine-tuning using a
targeted corpus, Shai demonstrates enhanced performance in tasks relevant to
its domain, outperforming baseline models. Our research includes the
development of an innovative evaluation framework, which integrates
professional qualification exams, tailored tasks, open-ended question
answering, and safety assessments, to comprehensively assess Shai's
capabilities. Furthermore, we discuss the challenges and implications of
utilizing large language models like GPT-4 for performance assessment in asset
management, suggesting a combination of automated evaluation and human
judgment. Shai's development, showcasing the potential and versatility of
10B-level large language models in the financial sector with significant
performance and modest computational requirements, hopes to provide practical
insights and methodologies to assist industry peers in their similar endeavors.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14204" title="Abstract">arXiv:2312.14204</a> (cross-list from eess.IV) [<a href="/pdf/2312.14204" title="Download PDF">pdf</a>, <a href="/format/2312.14204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta Transfer of Self-Supervised Knowledge: Foundation Model in Action  for Post-Traumatic Epilepsy Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cui%2C+W">Wenhui Cui</a>, 
<a href="/search/eess?searchtype=author&query=Akrami%2C+H">Haleh Akrami</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+G">Ganning Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Joshi%2C+A+A">Anand A. Joshi</a>, 
<a href="/search/eess?searchtype=author&query=Leahy%2C+R+M">Richard M. Leahy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Despite the impressive advancements achieved using deep-learning for
functional brain activity analysis, the heterogeneity of functional patterns
and scarcity of imaging data still pose challenges in tasks such as prediction
of future onset of Post-Traumatic Epilepsy (PTE) from data acquired shortly
after traumatic brain injury (TBI). Foundation models pre-trained on separate
large-scale datasets can improve the performance from scarce and heterogeneous
datasets. For functional Magnetic Resonance Imaging (fMRI), while data may be
abundantly available from healthy controls, clinical data is often scarce,
limiting the ability of foundation models to identify clinically-relevant
features. We overcome this limitation by introducing a novel training strategy
for our foundation model by integrating meta-learning with self-supervised
learning to improve the generalization from normal to clinical features. In
this way we enable generalization to other downstream clinical tasks, in our
case prediction of PTE. To achieve this, we perform self-supervised training on
the control dataset to focus on inherent features that are not limited to a
particular supervised task while applying meta-learning, which strongly
improves the model's generalizability using bi-level optimization. Through
experiments on neurological disorder classification tasks, we demonstrate that
the proposed strategy significantly improves task performance on small-scale
clinical datasets. To explore the generalizability of the foundation model in
downstream applications, we then apply the model to an unseen TBI dataset for
prediction of PTE using zero-shot learning. Results further demonstrated the
enhanced generalizability of our foundation model.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14212" title="Abstract">arXiv:2312.14212</a> (cross-list from astro-ph.IM) [<a href="/pdf/2312.14212" title="Download PDF">pdf</a>, <a href="/ps/2312.14212" title="Download PostScript">ps</a>, <a href="/format/2312.14212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond mirkwood: Enhancing SED Modeling with Conformal Predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Gilda%2C+S">Sankalp Gilda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages + 1 reference page. Accepted to the 3rd AI2ASE workshop at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Astrophysics of Galaxies (astro-ph.GA); Machine Learning (cs.LG)

</div>
<p class="mathjax">Traditional spectral energy distribution (SED) fitting techniques face
uncertainties due to assumptions in star formation histories and dust
attenuation curves. We propose an advanced machine learning-based approach that
enhances flexibility and uncertainty quantification in SED fitting. Unlike the
fixed NGBoost model used in mirkwood, our approach allows for any
sklearn-compatible model, including deterministic models. We incorporate
conformalized quantile regression to convert point predictions into error bars,
enhancing interpretability and reliability. Using CatBoost as the base
predictor, we compare results with and without conformal prediction,
demonstrating improved performance using metrics such as coverage and interval
width. Our method offers a more versatile and accurate tool for deriving galaxy
physical properties from observational data.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14213" title="Abstract">arXiv:2312.14213</a> (cross-list from math.OC) [<a href="/pdf/2312.14213" title="Download PDF">pdf</a>, <a href="/format/2312.14213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Reinforcement-Learning-based Multiple-Column Selection Strategy for  Column Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yuan%2C+H">Haofeng Yuan</a>, 
<a href="/search/math?searchtype=author&query=Fang%2C+L">Lichang Fang</a>, 
<a href="/search/math?searchtype=author&query=Song%2C+S">Shiji Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Column generation (CG) is one of the most successful approaches for solving
large-scale linear programming (LP) problems. Given an LP with a prohibitively
large number of variables (i.e., columns), the idea of CG is to explicitly
consider only a subset of columns and iteratively add potential columns to
improve the objective value. While adding the column with the most negative
reduced cost can guarantee the convergence of CG, it has been shown that adding
multiple columns per iteration rather than a single column can lead to faster
convergence. However, it remains a challenge to design a multiple-column
selection strategy to select the most promising columns from a large number of
candidate columns. In this paper, we propose a novel
reinforcement-learning-based (RL) multiple-column selection strategy. To the
best of our knowledge, it is the first RL-based multiple-column selection
strategy for CG. The effectiveness of our approach is evaluated on two sets of
problems: the cutting stock problem and the graph coloring problem. Compared to
several widely used single-column and multiple-column selection strategies, our
RL-based multiple-column selection strategy leads to faster convergence and
achieves remarkable reductions in the number of CG iterations and runtime.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14220" title="Abstract">arXiv:2312.14220</a> (cross-list from q-bio.GN) [<a href="/pdf/2312.14220" title="Download PDF">pdf</a>, <a href="/format/2312.14220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-Cell RNA-seq Synthesis with Latent Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+Y">Yixuan Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+S">Shuangyin Li</a>, 
<a href="/search/q-bio?searchtype=author&query=DI%2C+S">Shimin DI</a>, 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+L">Lei Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The single-cell RNA sequencing (scRNA-seq) technology enables researchers to
study complex biological systems and diseases with high resolution. The central
challenge is synthesizing enough scRNA-seq samples; insufficient samples can
impede downstream analysis and reproducibility. While various methods have been
attempted in past research, the resulting scRNA-seq samples were often of poor
quality or limited in terms of useful specific cell subpopulations. To address
these issues, we propose a novel method called Single-Cell Latent Diffusion
(SCLD) based on the Diffusion Model. This method is capable of synthesizing
large-scale, high-quality scRNA-seq samples, including both 'holistic' or
targeted specific cellular subpopulations within a unified framework. A
pre-guidance mechanism is designed for synthesizing specific cellular
subpopulations, while a post-guidance mechanism aims to enhance the quality of
scRNA-seq samples. The SCLD can synthesize large-scale and high-quality
scRNA-seq samples for various downstream tasks. Our experimental results
demonstrate state-of-the-art performance in cell classification and data
distribution distances when evaluated on two scRNA-seq benchmarks.
Additionally, visualization experiments show the SCLD's capability in
synthesizing specific cellular subpopulations.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14221" title="Abstract">arXiv:2312.14221</a> (cross-list from eess.IV) [<a href="/pdf/2312.14221" title="Download PDF">pdf</a>, <a href="/format/2312.14221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noninvasive Estimation of Mean Pulmonary Artery Pressure Using MRI,  Computer Models, and Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Grzeszczyk%2C+M+K">Michal K. Grzeszczyk</a>, 
<a href="/search/eess?searchtype=author&query=Satlawa%2C+T">Tadeusz Satlawa</a>, 
<a href="/search/eess?searchtype=author&query=Lungu%2C+A">Angela Lungu</a>, 
<a href="/search/eess?searchtype=author&query=Swift%2C+A">Andrew Swift</a>, 
<a href="/search/eess?searchtype=author&query=Narracott%2C+A">Andrew Narracott</a>, 
<a href="/search/eess?searchtype=author&query=Hose%2C+R">Rod Hose</a>, 
<a href="/search/eess?searchtype=author&query=Trzcinski%2C+T">Tomasz Trzcinski</a>, 
<a href="/search/eess?searchtype=author&query=Sitek%2C+A">Arkadiusz Sitek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for ICCS 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Pulmonary Hypertension (PH) is a severe disease characterized by an elevated
pulmonary artery pressure. The gold standard for PH diagnosis is measurement of
mean Pulmonary Artery Pressure (mPAP) during an invasive Right Heart
Catheterization. In this paper, we investigate noninvasive approach to PH
detection utilizing Magnetic Resonance Imaging, Computer Models and Machine
Learning. We show using the ablation study, that physics-informed feature
engineering based on models of blood circulation increases the performance of
Gradient Boosting Decision Trees-based algorithms for classification of PH and
regression of values of mPAP. We compare results of regression (with
thresholding of estimated mPAP) and classification and demonstrate that metrics
achieved in both experiments are comparable. The predicted mPAP values are more
informative to the physicians than the probability of PH returned by
classification models. They provide the intuitive explanation of the outcome of
the machine learning model (clinicians are accustomed to the mPAP metric,
contrary to the PH probability).
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14237" title="Abstract">arXiv:2312.14237</a> (cross-list from physics.comp-ph) [<a href="/pdf/2312.14237" title="Download PDF">pdf</a>, <a href="/format/2312.14237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-Lorenz: A physics-data-driven framework for black-box and gray-box  identification of chaotic systems with symbolic regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=De+Florio%2C+M">Mario De Florio</a>, 
<a href="/search/physics?searchtype=author&query=Kevrekidis%2C+I+G">Ioannis G. Kevrekidis</a>, 
<a href="/search/physics?searchtype=author&query=Karniadakis%2C+G+E">George Em Karniadakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 15 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Machine Learning (cs.LG); Chaotic Dynamics (nlin.CD); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">Discovering mathematical models that characterize the observed behavior of
dynamical systems remains a major challenge, especially for systems in a
chaotic regime. The challenge is even greater when the physics underlying such
systems is not yet understood, and scientific inquiry must solely rely on
empirical data. Driven by the need to fill this gap, we develop a framework
that learns mathematical expressions modeling complex dynamical behaviors by
identifying differential equations from noisy and sparse observable data. We
train a small neural network to learn the dynamics of a system, its rate of
change in time, and missing model terms, which are used as input for a symbolic
regression algorithm to autonomously distill the explicit mathematical terms.
This, in turn, enables us to predict the future evolution of the dynamical
behavior. The performance of this framework is validated by recovering the
right-hand sides and unknown terms of certain complex, chaotic systems such as
the well-known Lorenz system, a six-dimensional hyperchaotic system, and the
non-autonomous Sprott chaotic system, and comparing them with their known
analytical expressions.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14249" title="Abstract">arXiv:2312.14249</a> (cross-list from q-bio.GN) [<a href="/pdf/2312.14249" title="Download PDF">pdf</a>, <a href="/format/2312.14249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GenoCraft: A Comprehensive, User-Friendly Web-Based Platform for  High-Throughput Omics Data Analysis and Visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Lu%2C+Y">Yingzhou Lu</a>, 
<a href="/search/q-bio?searchtype=author&query=Shen%2C+M">Minjie Shen</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhao%2C+Y">Yue Zhao</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+C">Chenhao Li</a>, 
<a href="/search/q-bio?searchtype=author&query=Meng%2C+F">Fan Meng</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Herrington%2C+D">David Herrington</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+Y">Yue Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Fu%2C+T">Tim Fu</a>, 
<a href="/search/q-bio?searchtype=author&query=Van+Rechem%2C+C">Capucine Van Rechem</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The surge in high-throughput omics data has reshaped the landscape of
biological research, underlining the need for powerful, user-friendly data
analysis and interpretation tools. This paper presents GenoCraft, a web-based
comprehensive software solution designed to handle the entire pipeline of omics
data processing. GenoCraft offers a unified platform featuring advanced
bioinformatics tools, covering all aspects of omics data analysis. It
encompasses a range of functionalities, such as normalization, quality control,
differential analysis, network analysis, pathway analysis, and diverse
visualization techniques. This software makes state-of-the-art omics data
analysis more accessible to a wider range of users. With GenoCraft, researchers
and data scientists have access to an array of cutting-edge bioinformatics
tools under a user-friendly interface, making it a valuable resource for
managing and analyzing large-scale omics data. The API with an interactive web
interface is publicly available at https://genocraft.stanford. edu/. We also
release all the codes in https://github.com/futianfan/GenoCraft.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14256" title="Abstract">arXiv:2312.14256</a> (cross-list from econ.TH) [<a href="/pdf/2312.14256" title="Download PDF">pdf</a>, <a href="/ps/2312.14256" title="Download PostScript">ps</a>, <a href="/format/2312.14256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An extension of May&#x27;s Theorem to three alternatives: axiomatizing  Minimax voting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Holliday%2C+W+H">Wesley H. Holliday</a>, 
<a href="/search/econ?searchtype=author&query=Pacuit%2C+E">Eric Pacuit</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 15 diagrams
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">May's Theorem [K. O. May, Econometrica 20 (1952) 680-684] characterizes
majority voting on two alternatives as the unique preferential voting method
satisfying several simple axioms. Here we show that by adding some desirable
axioms to May's axioms, we can uniquely determine how to vote on three
alternatives. In particular, we add two axioms stating that the voting method
should mitigate spoiler effects and avoid the so-called strong no show paradox.
We prove a theorem stating that any preferential voting method satisfying our
enlarged set of axioms, which includes some weak homogeneity and preservation
axioms, agrees with Minimax voting in all three-alternative elections, except
perhaps in some improbable knife-edged elections in which ties may arise and be
broken in different ways.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14274" title="Abstract">arXiv:2312.14274</a> (cross-list from q-bio.NC) [<a href="/pdf/2312.14274" title="Download PDF">pdf</a>, <a href="/format/2312.14274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear Model Predictive Control of a Conductance-Based Neuron Model  via Data-Driven Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Fehrman%2C+C">Christof Fehrman</a>, 
<a href="/search/q-bio?searchtype=author&query=Meliza%2C+C+D">C. Daniel Meliza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Precise control of neural systems is essential to experimental investigations
of how the brain controls behavior and holds the potential for therapeutic
manipulations to correct aberrant network states like epilepsy. Although purely
reactive controllers work well with single neurons and other simple neural
systems, more sophisticated techniques are likely to be needed to control
complex circuits and systems with nonlinear recurrent dynamics, high levels of
exogenous noise, and limited information about the connectivity and state of
the network. One potential approach is model predictive control (MPC), which
uses a dynamical model to find optimal control inputs by forecasting how the
system will respond. However, the challenge still remains of selecting the
right model, constraining its parameters, and synchronizing to the neural
system. As a proof of principle, we used recent advances in data-driven
forecasting to construct a nonlinear machine-learning model of a Hodgkin-Huxley
type neuron when only the membrane voltage is observable and there are an
unknown number of intrinsic currents. We show that this approach is able to
learn the dynamics of different neuron types and can be used with MPC to force
the neuron to engage in arbitrary, researcher-defined spiking behaviors.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14285" title="Abstract">arXiv:2312.14285</a> (cross-list from q-bio.NC) [<a href="/pdf/2312.14285" title="Download PDF">pdf</a>, <a href="/format/2312.14285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probing Biological and Artificial Neural Networks with Task-dependent  Neural Manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Kuoch%2C+M">Michael Kuoch</a>, 
<a href="/search/q-bio?searchtype=author&query=Chou%2C+C">Chi-Ning Chou</a>, 
<a href="/search/q-bio?searchtype=author&query=Parthasarathy%2C+N">Nikhil Parthasarathy</a>, 
<a href="/search/q-bio?searchtype=author&query=Dapello%2C+J">Joel Dapello</a>, 
<a href="/search/q-bio?searchtype=author&query=DiCarlo%2C+J+J">James J. DiCarlo</a>, 
<a href="/search/q-bio?searchtype=author&query=Sompolinsky%2C+H">Haim Sompolinsky</a>, 
<a href="/search/q-bio?searchtype=author&query=Chung%2C+S">SueYeon Chung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the proceedings of the Conference on Parsimony and Learning (CPAL) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Recently, growth in our understanding of the computations performed in both
biological and artificial neural networks has largely been driven by either
low-level mechanistic studies or global normative approaches. However, concrete
methodologies for bridging the gap between these levels of abstraction remain
elusive. In this work, we investigate the internal mechanisms of neural
networks through the lens of neural population geometry, aiming to provide
understanding at an intermediate level of abstraction, as a way to bridge that
gap. Utilizing manifold capacity theory (MCT) from statistical physics and
manifold alignment analysis (MAA) from high-dimensional statistics, we probe
the underlying organization of task-dependent manifolds in deep neural networks
and macaque neural recordings. Specifically, we quantitatively characterize how
different learning objectives lead to differences in the organizational
strategies of these models and demonstrate how these geometric analyses are
connected to the decodability of task-relevant information. These analyses
present a strong direction for bridging mechanistic and normative theories in
neural networks through neural population geometry, potentially opening up many
future research avenues in both machine learning and neuroscience.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14303" title="Abstract">arXiv:2312.14303</a> (cross-list from eess.SP) [<a href="/pdf/2312.14303" title="Download PDF">pdf</a>, <a href="/format/2312.14303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geo2SigMap: High-Fidelity RF Signal Mapping Using Geographic Databases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yiming Li</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zeyu Li</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+Z">Zhihui Gao</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+T">Tingjun Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Radio frequency (RF) signal mapping, which is the process of analyzing and
predicting the RF signal strength and distribution across specific areas, is
crucial for cellular network planning and deployment. Traditional approaches to
RF signal mapping rely on statistical models constructed based on measurement
data, which offer low complexity but often lack accuracy, or ray tracing tools,
which provide enhanced precision for the target area but suffer from increased
computational complexity. Recently, machine learning (ML) has emerged as a
data-driven method for modeling RF signal propagation, which leverages models
trained on synthetic datasets to perform RF signal mapping in "unseen" areas.
<br />In this paper, we present Geo2SigMap, an ML-based framework for efficient and
high-fidelity RF signal mapping using geographic databases. First, we develop
an automated framework that seamlessly integrates three open-source tools:
OpenStreetMap (geographic databases), Blender (computer graphics), and Sionna
(ray tracing), enabling the efficient generation of large-scale 3D building
maps and ray tracing models. Second, we propose a cascaded U-Net model, which
is pre-trained on synthetic datasets and employed to generate detailed RF
signal maps, leveraging environmental information and sparse measurement data.
Finally, we evaluate the performance of Geo2SigMap via a real-world measurement
campaign, where three types of user equipment (UE) collect over 45,000 data
points related to cellular information from six LTE cells operating in the
citizens broadband radio service (CBRS) band. Our results show that Geo2SigMap
achieves an average root-mean-square-error (RMSE) of 6.04 dB for predicting the
reference signal received power (RSRP) at the UE, representing an average RMSE
improvement of 3.59 dB compared to existing methods.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14322" title="Abstract">arXiv:2312.14322</a> (cross-list from cond-mat.mes-hall) [<a href="/pdf/2312.14322" title="Download PDF">pdf</a>, <a href="/ps/2312.14322" title="Download PostScript">ps</a>, <a href="/format/2312.14322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Needs and Challenges of Quantum Dot Devices Automation: Workshop  Report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Zwolak%2C+J+P">Justyna P. Zwolak</a>, 
<a href="/search/cond-mat?searchtype=author&query=Taylor%2C+J+M">Jacob M. Taylor</a>, 
<a href="/search/cond-mat?searchtype=author&query=Andrews%2C+R">Reed Andrews</a>, 
<a href="/search/cond-mat?searchtype=author&query=Benson%2C+J">Jared Benson</a>, 
<a href="/search/cond-mat?searchtype=author&query=Bryant%2C+G">Garnett Bryant</a>, 
<a href="/search/cond-mat?searchtype=author&query=Buterakos%2C+D">Donovan Buterakos</a>, 
<a href="/search/cond-mat?searchtype=author&query=Chatterjee%2C+A">Anasua Chatterjee</a>, 
<a href="/search/cond-mat?searchtype=author&query=Sarma%2C+S+D">Sankar Das Sarma</a>, 
<a href="/search/cond-mat?searchtype=author&query=Eriksson%2C+M+A">Mark A. Eriksson</a>, 
<a href="/search/cond-mat?searchtype=author&query=Greplov%C3%A1%2C+E">Eli&#x161;ka Greplov&#xe1;</a>, 
<a href="/search/cond-mat?searchtype=author&query=Gullans%2C+M+J">Michael J. Gullans</a>, 
<a href="/search/cond-mat?searchtype=author&query=Hader%2C+F">Fabian Hader</a>, 
<a href="/search/cond-mat?searchtype=author&query=Kovach%2C+T+J">Tyler J. Kovach</a>, 
<a href="/search/cond-mat?searchtype=author&query=Mundada%2C+P+S">Pranav S. Mundada</a>, 
<a href="/search/cond-mat?searchtype=author&query=Ramsey%2C+M">Mick Ramsey</a>, 
<a href="/search/cond-mat?searchtype=author&query=Rasmussen%2C+T">Torbjoern Rasmussen</a>, 
<a href="/search/cond-mat?searchtype=author&query=Severin%2C+B">Brandon Severin</a>, 
<a href="/search/cond-mat?searchtype=author&query=Sigillito%2C+A">Anthony Sigillito</a>, 
<a href="/search/cond-mat?searchtype=author&query=Undseth%2C+B">Brennan Undseth</a>, 
<a href="/search/cond-mat?searchtype=author&query=Weber%2C+B">Brian Weber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> White paper/overview based on a workshop held at the National Institute of Standards and Technology, Gaithersburg, MD. 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mesoscale and Nanoscale Physics (cond-mat.mes-hall)</span>; Databases (cs.DB); Machine Learning (cs.LG); Quantum Physics (quant-ph)

</div>
<p class="mathjax">Gate-defined quantum dots are a promising candidate system to realize
scalable, coupled qubit systems and serve as a fundamental building block for
quantum computers. However, present-day quantum dot devices suffer from
imperfections that must be accounted for, which hinders the characterization,
tuning, and operation process. Moreover, with an increasing number of quantum
dot qubits, the relevant parameter space grows sufficiently to make heuristic
control infeasible. Thus, it is imperative that reliable and scalable
autonomous tuning approaches are developed. In this report, we outline current
challenges in automating quantum dot device tuning and operation with a
particular focus on datasets, benchmarking, and standardization. We also
present ideas put forward by the quantum dot community on how to overcome them.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14339" title="Abstract">arXiv:2312.14339</a> (cross-list from eess.AS) [<a href="/pdf/2312.14339" title="Download PDF">pdf</a>, <a href="/format/2312.14339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The UmboMic: A PVDF Cantilever Microphone
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yeiser%2C+A+J">Aaron J. Yeiser</a>, 
<a href="/search/eess?searchtype=author&query=Wawrzynek%2C+E+F">Emma F. Wawrzynek</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J+Z">John Z. Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Graf%2C+L">Lukas Graf</a>, 
<a href="/search/eess?searchtype=author&query=McHugh%2C+C+I">Christopher I. McHugh</a>, 
<a href="/search/eess?searchtype=author&query=Kymissis%2C+I">Ioannis Kymissis</a>, 
<a href="/search/eess?searchtype=author&query=Olson%2C+E+S">Elizabeth S. Olson</a>, 
<a href="/search/eess?searchtype=author&query=Lang%2C+J+H">Jeffrey H. Lang</a>, 
<a href="/search/eess?searchtype=author&query=Nakajima%2C+H+H">Hideko Heidi Nakajima</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Objective: We present the "UmboMic," a prototype piezoelectric cantilever
microphone designed for future use with totally-implantable cochlear implants.
Methods: The UmboMic sensor is made from polyvinylidene difluoride (PVDF)
because of its low Young's modulus and biocompatibility. The sensor is designed
to fit in the middle ear and measure the motion of the underside of the eardrum
at the umbo. To maximize its performance, we developed a low noise charge
amplifier in tandem with the UmboMic sensor. This paper presents the
performance of the UmboMic sensor and amplifier in fresh cadaveric human
temporal bones. Results: When tested in human temporal bones, the UmboMic
apparatus achieves an equivalent input noise of 32.3 dB SPL over the frequency
range 100 Hz to 7 kHz, good linearity, and a flat frequency response to within
10 dB from about 100 Hz to 6 kHz. Conclusion: These results demonstrate the
feasibility of a PVDF-based microphone when paired with a low-noise amplifier.
The reported UmboMic apparatus is comparable in performance to a conventional
hearing aid microphone. Significance: The proof-of-concept UmboMic apparatus is
a promising step towards creating a totally-implantable cochlear implant. A
completely internal system would enhance the quality of life of cochlear
implant users.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14372" title="Abstract">arXiv:2312.14372</a> (cross-list from physics.data-an) [<a href="/pdf/2312.14372" title="Download PDF">pdf</a>, <a href="/format/2312.14372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Models for Simulation of KamLAND-Zen
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Fu%2C+Z">Z. Fu</a>, 
<a href="/search/physics?searchtype=author&query=Grant%2C+C">C. Grant</a>, 
<a href="/search/physics?searchtype=author&query=Krawiec%2C+D+M">D. M. Krawiec</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+A">A. Li</a>, 
<a href="/search/physics?searchtype=author&query=Winslow%2C+L">L. Winslow</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to EPJC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Analysis, Statistics and Probability (physics.data-an)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The next generation of searches for neutrinoless double beta decay
(0{\nu}\b{eta}\b{eta}) are poised to answer deep questions on the nature of
neutrinos and the source of the Universe's matter-antimatter asymmetry. They
will be looking for event rates of less than one event per ton of instrumented
isotope per year. To claim discovery, accurate and efficient simulations of
detector events that mimic 0{\nu}\b{eta}\b{eta} is critical. Traditional Monte
Carlo (MC) simulations can be supplemented by machine-learning-based generative
models. In this work, we describe the performance of generative models designed
for monolithic liquid scintillator detectors like KamLAND to produce highly
accurate simulation data without a predefined physics model. We demonstrate its
ability to recover low-level features and perform interpolation. In the future,
the results of these generative models can be used to improve event
classification and background rejection by providing high-quality abundant
generated data.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14397" title="Abstract">arXiv:2312.14397</a> (cross-list from math.CO) [<a href="/pdf/2312.14397" title="Download PDF">pdf</a>, <a href="/format/2312.14397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deciding Foot-sortability and Minimal 2-bounded Non-foot-sortable Sock  Orderings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yu%2C+H+H">Hung-Hsun Hans Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">A sock ordering is a sequence of socks with different colors. A sock ordering
is foot-sortable if the sequence of socks can be sorted by a stack so that
socks with the same color form a contiguous block. The problem of deciding
whether a given sock ordering is foot-sortable was first considered by Defant
and Kravitz, who resolved the case for alignment-free 2-uniform sock orderings.
In this paper, we resolve the problem in a more general setting, where each
color appears in the sock ordering at most twice. A key component of the
argument is a fast algorithm that determines the foot-sortability of a sock
ordering of length $N$ in time $O(N\log N)$, which is also an interesting
result on its own.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14473" title="Abstract">arXiv:2312.14473</a> (cross-list from math.OC) [<a href="/pdf/2312.14473" title="Download PDF">pdf</a>, <a href="/format/2312.14473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coordinated Active-Reactive Power Management of ReP2H Systems with  Multiple Electrolyzers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zeng%2C+Y">Yangjun Zeng</a> (1), 
<a href="/search/math?searchtype=author&query=Zhou%2C+B">Buxiang Zhou</a> (1), 
<a href="/search/math?searchtype=author&query=Zhu%2C+J">Jie Zhu</a> (1), 
<a href="/search/math?searchtype=author&query=Li%2C+J">Jiarong Li</a> (2), 
<a href="/search/math?searchtype=author&query=Yang%2C+B">Bosen Yang</a> (2), 
<a href="/search/math?searchtype=author&query=Lin%2C+J">Jin Lin</a> (2), 
<a href="/search/math?searchtype=author&query=Qiu%2C+Y">Yiwei Qiu</a> (1) ((1) College of Electrical Engineering, Sichuan University, (2) Department of Electrical Engineering, Tsinghua University)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Utility-scale renewable power-to-hydrogen (ReP2H) production typically uses
thyristor rectifiers (TRs) to supply power to multiple electrolyzers (ELZs).
They exhibit a nonlinear and non-decouplable relation between active and
reactive power. The on-off scheduling and load allocation of multiple ELZs
simultaneously impact energy conversion efficiency and AC-side active and
reactive power flow. Improper scheduling may result in excessive reactive power
demand, causing voltage violations and increased network losses, compromising
safety and economy. To address these challenges, this paper first explores
trade-offs between the efficiency and the reactive load of the electrolyzers.
Subsequently, we propose a coordinated approach for scheduling the active and
reactive power in the ReP2H system. A mixed-integer second-order cone
programming (MISOCP) is established to jointly optimize active and reactive
power by coordinating the ELZs, renewable energy sources, energy storage (ES),
and var compensations. Case studies demonstrate that the proposed method
reduces losses by 3.06% in an off-grid ReP2H system while increasing hydrogen
production by 5.27% in average.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14518" title="Abstract">arXiv:2312.14518</a> (cross-list from q-bio.NC) [<a href="/pdf/2312.14518" title="Download PDF">pdf</a>, <a href="/format/2312.14518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Learning Neuronal Skeleton and Brain Circuit Topology with  Permutation Invariant Encoders for Neuron Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Liao%2C+M">Minghui Liao</a>, 
<a href="/search/q-bio?searchtype=author&query=Wan%2C+G">Guojia Wan</a>, 
<a href="/search/q-bio?searchtype=author&query=Du%2C+B">Bo Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages,8 figures,
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Determining the types of neurons within a nervous system plays a significant
role in the analysis of brain connectomics and the investigation of
neurological diseases. However, the efficiency of utilizing anatomical,
physiological, or molecular characteristics of neurons is relatively low and
costly. With the advancements in electron microscopy imaging and analysis
techniques for brain tissue, we are able to obtain whole-brain connectome
consisting neuronal high-resolution morphology and connectivity information.
However, few models are built based on such data for automated neuron
classification. In this paper, we propose NeuNet, a framework that combines
morphological information of neurons obtained from skeleton and topological
information between neurons obtained from neural circuit. Specifically, NeuNet
consists of three components, namely Skeleton Encoder, Connectome Encoder, and
Readout Layer. Skeleton Encoder integrates the local information of neurons in
a bottom-up manner, with a one-dimensional convolution in neural skeleton's
point data; Connectome Encoder uses a graph neural network to capture the
topological information of neural circuit; finally, Readout Layer fuses the
above two information and outputs classification results. We reprocess and
release two new datasets for neuron classification task from volume electron
microscopy(VEM) images of human brain cortex and Drosophila brain. Experiments
on these two datasets demonstrated the effectiveness of our model with accuracy
of 0.9169 and 0.9363, respectively. Code and data are available at:
https://github.com/WHUminghui/NeuNet.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14521" title="Abstract">arXiv:2312.14521</a> (cross-list from quant-ph) [<a href="/pdf/2312.14521" title="Download PDF">pdf</a>, <a href="/format/2312.14521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tuning Quantum Computing Privacy through Quantum Error Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Zhong%2C+H">Hui Zhong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ju%2C+K">Keyi Ju</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sistla%2C+M">Manojna Sistla</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+X">Xinyue Zhang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Qin%2C+X">Xiaoqi Qin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Fu%2C+X">Xin Fu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pan%2C+M">Miao Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Quantum computing is a promising paradigm for efficiently solving large and
high-complexity problems. To protect quantum computing privacy, pioneering
research efforts proposed to redefine differential privacy (DP) in quantum
computing, i.e., quantum differential privacy (QDP), and harvest inherent
noises generated by quantum computing to implement QDP. However, such an
implementation approach is limited by the amount of inherent noises, which
makes the privacy budget of the QDP mechanism fixed and uncontrollable. To
address this issue, in this paper, we propose to leverage quantum error
correction (QEC) techniques to reduce quantum computing errors, while tuning
the privacy protection levels in QDP. In short, we gradually decrease the
quantum noise error rate by deciding whether to apply QEC operations on the
gate in a multiple single qubit gates circuit. We have derived a new
calculation formula for the general error rate and corresponding privacy
budgets after QEC operation. Then, we expand to achieve further noise reduction
using multi-level concatenated QEC operation. Through extensive numerical
simulations, we demonstrate that QEC is a feasible way to regulate the degree
of privacy protection in quantum computing.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14552" title="Abstract">arXiv:2312.14552</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2312.14552" title="Download PDF">pdf</a>, <a href="/format/2312.14552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine learning for structure-guided materials and process design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Morand%2C+L">Lukas Morand</a>, 
<a href="/search/cond-mat?searchtype=author&query=Iraki%2C+T">Tarek Iraki</a>, 
<a href="/search/cond-mat?searchtype=author&query=Dornheim%2C+J">Johannes Dornheim</a>, 
<a href="/search/cond-mat?searchtype=author&query=Sandfeld%2C+S">Stefan Sandfeld</a>, 
<a href="/search/cond-mat?searchtype=author&query=Link%2C+N">Norbert Link</a>, 
<a href="/search/cond-mat?searchtype=author&query=Helm%2C+D">Dirk Helm</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, there has been a growing interest in accelerated materials
innovation in both, research and industry. However, to truly add value to the
development of new advanced materials, it is inevitable to take into account
manufacturing processes and thereby tailor materials design approaches to
support downstream process design approaches. As a major step into this
direction, we present a holistic optimization approach that covers the entire
materials process-structure-property chain. Our approach specifically employs
machine learning techniques to address two critical identification problems.
The first is to solve a materials design problem, which involves identifying
near-optimal material structures that exhibit desired macroscopic properties.
The second is to solve a process design problem that is to find an optimal
processing path to manufacture these material structures. Both identification
problems are typically ill-posed, which presents a significant challenge for
solution approaches. However, the non-unique nature of these problems also
offers an important advantage for processing: By having several target
structures that perform similarly well, the corresponding processes can be
efficiently guided towards manufacturing the best reachable structure. In
particular, we apply deep reinforcement learning for process design in
combination with a multi-task learning-based optimization approach for
materials design. The functionality of the approach will be demonstrated by
using it to manufacture crystallographic textures with desired properties in a
metal forming process.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14565" title="Abstract">arXiv:2312.14565</a> (cross-list from econ.GN) [<a href="/pdf/2312.14565" title="Download PDF">pdf</a>, <a href="/ps/2312.14565" title="Download PostScript">ps</a>, <a href="/format/2312.14565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Economics of Human Oversight: How Norms and Incentives Affect Costs  and Performance of AI Workers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Laux%2C+J">Johann Laux</a>, 
<a href="/search/econ?searchtype=author&query=Stephany%2C+F">Fabian Stephany</a>, 
<a href="/search/econ?searchtype=author&query=Liefgreen%2C+A">Alice Liefgreen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 8 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Artificial Intelligence (cs.AI); Applications (stat.AP)

</div>
<p class="mathjax">The global surge in AI applications is transforming industries, leading to
displacement and complementation of existing jobs, while also giving rise to
new employment opportunities. Human oversight of AI is an emerging task in
which human workers interact with an AI model to improve its performance,
safety, and compliance with normative principles. Data annotation, encompassing
the labelling of images or annotating of texts, serves as a critical human
oversight process, as the quality of a dataset directly influences the quality
of AI models trained on it. Therefore, the efficiency of human oversight work
stands as an important competitive advantage for AI developers. This paper
delves into the foundational economics of human oversight, with a specific
focus on the impact of norm design and monetary incentives on data quality and
costs. An experimental study involving 307 data annotators examines six groups
with varying task instructions (norms) and monetary incentives. Results reveal
that annotators provided with clear rules exhibit higher accuracy rates,
outperforming those with vague standards by 14%. Similarly, annotators
receiving an additional monetary incentive perform significantly better, with
the highest accuracy rate recorded in the group working with both clear rules
and incentives (87.5% accuracy). However, both groups require more time to
complete tasks, with a 31% increase in average task completion time compared to
those working with standards and no incentives. These empirical findings
underscore the trade-off between data quality and efficiency in data curation,
shedding light on the nuanced impact of norm design and incentives on the
economics of AI development. The paper contributes experimental insights to
discussions on the economical, ethical, and legal considerations of AI
technologies.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14576" title="Abstract">arXiv:2312.14576</a> (cross-list from math.CO) [<a href="/pdf/2312.14576" title="Download PDF">pdf</a>, <a href="/ps/2312.14576" title="Download PostScript">ps</a>, <a href="/format/2312.14576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Packing coloring of hypercubes with extended Hamming codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gregor%2C+P">Petr Gregor</a>, 
<a href="/search/math?searchtype=author&query=Kranjc%2C+J">Jaka Kranjc</a>, 
<a href="/search/math?searchtype=author&query=Lu%C5%BEar%2C+B">Borut Lu&#x17e;ar</a>, 
<a href="/search/math?searchtype=author&query=%C5%A0torgel%2C+K">Kenny &#x160;torgel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">A {\em packing coloring} of a graph $G$ is a mapping assigning a positive
integer (a color) to every vertex of $G$ such that every two vertices of color
$k$ are at distance at least $k+1$. The least number of colors needed for a
packing coloring of $G$ is called the {\em packing chromatic number} of $G$. In
this paper, we continue the study of the packing chromatic number of hypercubes
and we improve the upper bounds reported by Torres and Valencia-Pabon ({\em P.
Torres, M. Valencia-Pabon, The packing chromatic number of hypercubes, Discrete
Appl. Math. 190--191 (2015), 127--140}) by presenting recursive constructions
of subsets of distant vertices making use of the properties of the extended
Hamming codes. We also answer in negative a question on packing coloring of
Cartesian products raised by Bre\v{s}ar, Klav\v{z}ar, and Rall ({\em Problem 5,
Bre\v{s}ar et al., On the packing chromatic number of Cartesian products,
hexagonal lattice, and trees. Discrete Appl. Math. 155 (2007), 2303--2311.}).
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14586" title="Abstract">arXiv:2312.14586</a> (cross-list from eess.AS) [<a href="/pdf/2312.14586" title="Download PDF">pdf</a>, <a href="/format/2312.14586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noise Morphing for Audio Time Stretching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Moliner%2C+E">Eloi Moliner</a>, 
<a href="/search/eess?searchtype=author&query=Fierro%2C+L">Leonardo Fierro</a>, 
<a href="/search/eess?searchtype=author&query=Wright%2C+A">Alec Wright</a>, 
<a href="/search/eess?searchtype=author&query=H%C3%A4m%C3%A4l%C3%A4inen%2C+M">Matti H&#xe4;m&#xe4;l&#xe4;inen</a>, 
<a href="/search/eess?searchtype=author&query=V%C3%A4lim%C3%A4ki%2C+V">Vesa V&#xe4;lim&#xe4;ki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE Signal Processing Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">This letter introduces an innovative method to enhance the quality of audio
time stretching by precisely decomposing a sound into sines, transients, and
noise and by improving the processing of the latter component. While there are
established methods for time-stretching sines and transients with high quality,
the manipulation of noise or residual components has lacked robust solutions in
prior research. The proposed method combines sound decomposition with previous
techniques for audio spectral resynthesis. The time-stretched noise component
is achieved by morphing its time-interpolated spectral magnitude with a
white-noise excitation signal. This method stands out for its simplicity,
efficiency, and audio quality. The results of a subjective experiment affirm
the superiority of this approach over current state-of-the-art methods across
all evaluated stretch factors. The proposed technique notably excels in extreme
stretching scenarios, signifying a substantial elevation in performance. The
proposed method holds promise for a wide range of applications in slow-motion
media content, such as music or sports video production.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14588" title="Abstract">arXiv:2312.14588</a> (cross-list from math.PR) [<a href="/pdf/2312.14588" title="Download PDF">pdf</a>, <a href="/format/2312.14588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On a Near-Optimal \&amp; Efficient Algorithm for the Sparse Pooled Data  Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hahn-Klimroth%2C+M">Max Hahn-Klimroth</a>, 
<a href="/search/math?searchtype=author&query=van+der+Hofstad%2C+R">Remco van der Hofstad</a>, 
<a href="/search/math?searchtype=author&query=M%C3%BCller%2C+N">Noela M&#xfc;ller</a>, 
<a href="/search/math?searchtype=author&query=Riddlesden%2C+C">Connor Riddlesden</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Discrete Mathematics (cs.DM); Information Theory (cs.IT); Machine Learning (stat.ML)

</div>
<p class="mathjax">The pooled data problem asks to identify the unknown labels of a set of items
from condensed measurements. More precisely, given $n$ items, assume that each
item has a label in $\cbc{0,1,\ldots, d}$, encoded via the ground-truth
$\SIGMA$. We call the pooled data problem sparse if the number of non-zero
entries of $\SIGMA$ scales as $k \sim n^{\theta}$ for $\theta \in (0,1)$. The
information that is revealed about $\SIGMA$ comes from pooled measurements,
each indicating how many items of each label are contained in the pool. The
most basic question is to design a pooling scheme that uses as few pools as
possible, while reconstructing $\SIGMA$ with high probability. Variants of the
problem and its combinatorial ramifications have been studied for at least 35
years. However, the study of the modern question of \emph{efficient} inference
of the labels has suggested a statistical-to-computational gap of order $\log
n$ in the minimum number of pools needed for theoretically possible versus
efficient inference. In this article, we resolve the question whether this
$\log n$-gap is artificial or of a fundamental nature by the design of an
efficient algorithm, called \algoname, based upon a novel pooling scheme on a
number of pools very close to the information-theoretic threshold.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14609" title="Abstract">arXiv:2312.14609</a> (cross-list from eess.AS) [<a href="/pdf/2312.14609" title="Download PDF">pdf</a>, <a href="/ps/2312.14609" title="Download PostScript">ps</a>, <a href="/format/2312.14609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BLSTM-Based Confidence Estimation for End-to-End Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ogawa%2C+A">Atsunori Ogawa</a>, 
<a href="/search/eess?searchtype=author&query=Tawara%2C+N">Naohiro Tawara</a>, 
<a href="/search/eess?searchtype=author&query=Kano%2C+T">Takatomo Kano</a>, 
<a href="/search/eess?searchtype=author&query=Delcroix%2C+M">Marc Delcroix</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Confidence estimation, in which we estimate the reliability of each
recognized token (e.g., word, sub-word, and character) in automatic speech
recognition (ASR) hypotheses and detect incorrectly recognized tokens, is an
important function for developing ASR applications. In this study, we perform
confidence estimation for end-to-end (E2E) ASR hypotheses. Recent E2E ASR
systems show high performance (e.g., around 5% token error rates) for various
ASR tasks. In such situations, confidence estimation becomes difficult since we
need to detect infrequent incorrect tokens from mostly correct token sequences.
To tackle this imbalanced dataset problem, we employ a bidirectional long
short-term memory (BLSTM)-based model as a strong binary-class
(correct/incorrect) sequence labeler that is trained with a class balancing
objective. We experimentally confirmed that, by utilizing several types of ASR
decoding scores as its auxiliary features, the model steadily shows high
confidence estimation performance under highly imbalanced settings. We also
confirmed that the BLSTM-based model outperforms Transformer-based confidence
estimation models, which greatly underestimate incorrect tokens.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14671" title="Abstract">arXiv:2312.14671</a> (cross-list from math.CO) [<a href="/pdf/2312.14671" title="Download PDF">pdf</a>, <a href="/format/2312.14671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discrete Algebraic sets in Discrete Manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Knill%2C+O">Oliver Knill</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">A discrete d-manifold is a finite simple graph G=(V,E) where all unit spheres
are (d-1)-spheres. A d-sphere is a d-manifold for which one can remove a vertex
to make it contractible. A graph is contractible if one can remove a vertex
with contractible unit sphere to get a contractible graph. We prove a discrete
Morse-Sard theorem: if G=(V,E) is a d-manifold and f:V to R^k an arbitrary map,
then for any c not in f(V), a level set { f = c } is always a (d-k)-manifold or
empty. While a priori open sets in the simplicial complex of G, they are
sub-manifolds in the Barycentric refinement of G. Level sets are orientable if
G is orientable. Any complex-valued function psi on a discrete 4-manifold M
defines so level surfaces {psi=c} which are except for c in f(V) always
2-manifolds or empty.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14685" title="Abstract">arXiv:2312.14685</a> (cross-list from q-bio.NC) [<a href="/pdf/2312.14685" title="Download PDF">pdf</a>, <a href="/format/2312.14685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kernel Heterogeneity Improves Sparseness of Natural Images  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Ladret%2C+H+J">Hugo J. Ladret</a>, 
<a href="/search/q-bio?searchtype=author&query=Casanova%2C+C">Christian Casanova</a>, 
<a href="/search/q-bio?searchtype=author&query=Perrinet%2C+L+U">Laurent Udo Perrinet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Both biological and artificial neural networks inherently balance their
performance with their operational cost, which balances their computational
abilities. Typically, an efficient neuromorphic neural network is one that
learns representations that reduce the redundancies and dimensionality of its
input. This is for instance achieved in sparse coding, and sparse
representations derived from natural images yield representations that are
heterogeneous, both in their sampling of input features and in the variance of
those features. Here, we investigated the connection between natural images'
structure, particularly oriented features, and their corresponding sparse
codes. We showed that representations of input features scattered across
multiple levels of variance substantially improve the sparseness and resilience
of sparse codes, at the cost of reconstruction performance. This echoes the
structure of the model's input, allowing to account for the heterogeneously
aleatoric structures of natural images. We demonstrate that learning kernel
from natural images produces heterogeneity by balancing between approximate and
dense representations, which improves all reconstruction metrics. Using a
parametrized control of the kernels' heterogeneity used by a convolutional
sparse coding algorithm, we show that heterogeneity emphasizes sparseness,
while homogeneity improves representation granularity. In a broader context,
these encoding strategy can serve as inputs to deep convolutional neural
networks. We prove that such variance-encoded sparse image datasets enhance
computational efficiency, emphasizing the benefits of kernel heterogeneity to
leverage naturalistic and variant input structures and possible applications to
improve the throughput of neuromorphic hardware.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14690" title="Abstract">arXiv:2312.14690</a> (cross-list from math.OC) [<a href="/pdf/2312.14690" title="Download PDF">pdf</a>, <a href="/format/2312.14690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Stochastic Bilevel Optimization: Improved Complexity and  Heterogeneity Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Niu%2C+Y">Youcheng Niu</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+J">Jinming Xu</a>, 
<a href="/search/math?searchtype=author&query=Sun%2C+Y">Ying Sun</a>, 
<a href="/search/math?searchtype=author&query=Huang%2C+Y">Yan Huang</a>, 
<a href="/search/math?searchtype=author&query=Chai%2C+L">Li Chai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 51 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Distributed bilevel optimization has gained increasing popularity due to its
wide applications in large-scale machine learning. This paper focuses on a
class of nonconvex-strongly-convex distributed stochastic bilevel optimization
(DSBO) problems with personalized inner-level objectives. Existing algorithms
require extra computation loops to compute inner-level solutions accurately and
Hessian inverse matrices for estimating the hypergradient, which incurs high
computational complexity of gradient evaluation. To address this issue, we
propose a loopless personalized distributed algorithm (termed LoPA) that
leverages iterative approximation for the inner-level solutions and Hessian
inverse matrices. Theoretical analysis shows that LoPA has a sublinear rate of
${{\mathcal{O}}}( {\frac{{1}}{{(1-\rho)^2K}} + \frac{{b^{\frac{2}{3}}
}}{{\left( {1 - \rho } \right)^{\frac{2}{3}}K^{\frac{2}{3}} }} +
\frac{{1}}{\sqrt{ K }} ( \sigma_{\rm{p}} + \frac{1}{\sqrt{m}}\sigma_{\rm{c}}) }
)$, where $K$ is the total number of iterations, $b$ quantifies the data
heterogeneity across nodes, and $\sigma_{\rm p}, \sigma_{\rm c}$ represent the
gradient sampling variances associated with the inner-level and out-level
variables, respectively. We provide an explicit characterization of the
heterogeneity, and develop a variant of LoPA based on gradient tracking to
eliminate the heterogeneity, yielding a rate of ${{\mathcal{O}}}(\frac{{{1}}}{{
(1-\rho)^4K }} + \frac{1}{{\sqrt{K}}}( \sigma_{\rm{p}} +
\frac{1}{\sqrt{m}}\sigma_{\rm{c}} ) )$. The computational complexity of LoPA is
shown to be of the order of ${{\mathcal{O}}}({\epsilon^{-2}})$ thanks to the
loopless structure, outperforming existing counterparts for DSBO by an order of
${{\mathcal{O}}}(\log{\epsilon^{-1}})$. Numerical experiments demonstrate the
effectiveness of the proposed algorithm.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14705" title="Abstract">arXiv:2312.14705</a> (cross-list from eess.IV) [<a href="/pdf/2312.14705" title="Download PDF">pdf</a>, <a href="/format/2312.14705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCUNet++: Assessment of Pulmonary Embolism CT Image Segmentation  Leveraging Swin-UNet and CNN Bottleneck Hybrid Architecture with Multi-Fusion  Dense Skip Connection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yifei Chen</a>, 
<a href="/search/eess?searchtype=author&query=Zou%2C+B">Binfeng Zou</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+Z">Zhaoxin Guo</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yiyu Huang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yifan Huang</a>, 
<a href="/search/eess?searchtype=author&query=Qin%2C+F">Feiwei Qin</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Q">Qinhai Li</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Changmiao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures, accept wacv2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> wacv 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Pulmonary embolism (PE) is a prevalent lung disease that can lead to right
ventricular hypertrophy and failure in severe cases, ranking second in severity
only to myocardial infarction and sudden death. Pulmonary artery CT angiography
(CTPA) is a widely used diagnostic method for PE. However, PE detection
presents challenges in clinical practice due to limitations in imaging
technology. CTPA can produce noises similar to PE, making confirmation of its
presence time-consuming and prone to overdiagnosis. Nevertheless, the
traditional segmentation method of PE can not fully consider the hierarchical
structure of features, local and global spatial features of PE CT images. In
this paper, we propose an automatic PE segmentation method called SCUNet++
(Swin Conv UNet++). This method incorporates multiple fusion dense skip
connections between the encoder and decoder, utilizing the Swin Transformer as
the encoder. And fuses features of different scales in the decoder subnetwork
to compensate for spatial information loss caused by the inevitable
downsampling in Swin-UNet or other state-of-the-art methods, effectively
solving the above problem. We provide a theoretical analysis of this method in
detail and validate it on publicly available PE CT image datasets FUMPE and
CAD-PE. The experimental results indicate that our proposed method achieved a
Dice similarity coefficient (DSC) of 83.47% and a Hausdorff distance 95th
percentile (HD95) of 3.83 on the FUMPE dataset, as well as a DSC of 83.42% and
an HD95 of 5.10 on the CAD-PE dataset. These findings demonstrate that our
method exhibits strong performance in PE segmentation tasks, potentially
enhancing the accuracy of automatic segmentation of PE and providing a powerful
diagnostic tool for clinical physicians. Our source code and new FUMPE dataset
are available at https://github.com/JustlfC03/SCUNet-plusplus.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14717" title="Abstract">arXiv:2312.14717</a> (cross-list from physics.data-an) [<a href="/pdf/2312.14717" title="Download PDF">pdf</a>, <a href="/ps/2312.14717" title="Download PostScript">ps</a>, <a href="/format/2312.14717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kinematic Characterization of Micro-Mobility Vehicles During Evasive  Maneuvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Terranova%2C+P">Paolo Terranova</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+S">Shu-Yuan Liu</a>, 
<a href="/search/physics?searchtype=author&query=Jain%2C+S">Sparsh Jain</a>, 
<a href="/search/physics?searchtype=author&query=Engstrom%2C+J">Johan Engstrom</a>, 
<a href="/search/physics?searchtype=author&query=Perez%2C+M">Miguel Perez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Analysis, Statistics and Probability (physics.data-an)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">There is an increasing need to comprehensively characterize the kinematic
performances of different Micromobility Vehicles (MMVs). This study aims to: 1)
characterize the kinematic behaviors of different MMVs during emergency
maneuvers; 2) explore the influence of different MMV power sources on the
device performances; 3) investigate if piecewise linear models are suitable for
modeling MMV trajectories. A test track experiment where 40 frequent riders
performed emergency braking and swerving maneuvers riding a subset of electric
MMVs, their traditional counterparts, and, in some cases, behaving as running
pedestrians. A second experiment was conducted to determine the MMVs swerving
lower boundaries. Device power source resulted having a statistically
significant influence on kinematic capabilities of the MMVs: while e-MMVs
displayed superior braking capabilities compared to their traditional
counterparts, the opposite was observed in terms of swerving performance.
Furthermore, performances varied significantly across the different MMV
typologies, with handlebar-based devices consistently outperforming the
handlebar-less devices across the metrics considered. The piecewise linear
models used for braking profiles fit well for most MMVs, except for skateboards
and pedestrians due to foot-ground engagement. These findings underscore that
the effectiveness of steering or braking in preventing collisions may vary
depending on the type and power source of the device. This study also
demonstrates the applicability of piecewise linear models for generating
parameterized functions that accurately model braking trajectories, providing a
valuable resource for automated systems developers. The model, however, also
reveals that the single brake ramp assumption does not apply for certain types
of MMVs or for pedestrians, indicating the necessity for further improvements.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14773" title="Abstract">arXiv:2312.14773</a> (cross-list from eess.IV) [<a href="/pdf/2312.14773" title="Download PDF">pdf</a>, <a href="/format/2312.14773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Age and Cross-Site Domain Shift Impacts on Deep Learning-Based  White Matter Fiber Estimation in Newborn and Baby Brains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lin%2C+R">Rizhong Lin</a>, 
<a href="/search/eess?searchtype=author&query=Gholipour%2C+A">Ali Gholipour</a>, 
<a href="/search/eess?searchtype=author&query=Thiran%2C+J">Jean-Philippe Thiran</a>, 
<a href="/search/eess?searchtype=author&query=Karimi%2C+D">Davood Karimi</a>, 
<a href="/search/eess?searchtype=author&query=Kebiri%2C+H">Hamza Kebiri</a>, 
<a href="/search/eess?searchtype=author&query=Cuadra%2C+M+B">Meritxell Bach Cuadra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures, submitted to ISBI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Deep learning models have shown great promise in estimating tissue
microstructure from limited diffusion magnetic resonance imaging data. However,
these models face domain shift challenges when test and train data are from
different scanners and protocols, or when the models are applied to data with
inherent variations such as the developing brains of infants and children
scanned at various ages. Several techniques have been proposed to address some
of these challenges, such as data harmonization or domain adaptation in the
adult brain. However, those techniques remain unexplored for the estimation of
fiber orientation distribution functions in the rapidly developing brains of
infants. In this work, we extensively investigate the age effect and domain
shift within and across two different cohorts of 201 newborns and 165 babies
using the Method of Moments and fine-tuning strategies. Our results show that
reduced variations in the microstructural development of babies in comparison
to newborns directly impact the deep learning models' cross-age performance. We
also demonstrate that a small number of target domain samples can significantly
mitigate domain shift problems.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14795" title="Abstract">arXiv:2312.14795</a> (cross-list from stat.ML) [<a href="/pdf/2312.14795" title="Download PDF">pdf</a>, <a href="/format/2312.14795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On support vector machines under a multiple-cost scenario
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ben%C3%ADtez-Pe%C3%B1a%2C+S">Sandra Ben&#xed;tez-Pe&#xf1;a</a>, 
<a href="/search/stat?searchtype=author&query=Blanquero%2C+R">Rafael Blanquero</a>, 
<a href="/search/stat?searchtype=author&query=Carrizosa%2C+E">Emilio Carrizosa</a>, 
<a href="/search/stat?searchtype=author&query=Ram%C3%ADrez-Cobo%2C+P">Pepa Ram&#xed;rez-Cobo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Advances in Data Analysis and Classification (2019) 663-382
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Support Vector Machine (SVM) is a powerful tool in binary classification,
known to attain excellent misclassification rates. On the other hand, many
realworld classification problems, such as those found in medical diagnosis,
churn or fraud prediction, involve misclassification costs which may be
different in the different classes. However, it may be hard for the user to
provide precise values for such misclassification costs, whereas it may be much
easier to identify acceptable misclassification rates values. In this paper we
propose a novel SVM model in which misclassification costs are considered by
incorporating performance constraints in the problem formulation. Specifically,
our aim is to seek the hyperplane with maximal margin yielding
misclassification rates below given threshold values. Such maximal margin
hyperplane is obtained by solving a quadratic convex problem with linear
constraints and integer variables. The reported numerical experience shows that
our model gives the user control on the misclassification rates in one class
(possibly at the expense of an increase in misclassification rates for the
other class) and is feasible in terms of running times.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14830" title="Abstract">arXiv:2312.14830</a> (cross-list from physics.med-ph) [<a href="/pdf/2312.14830" title="Download PDF">pdf</a>, <a href="/format/2312.14830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dreaming of Electrical Waves: Generative Modeling of Cardiac Excitation  Waves using Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Baranwal%2C+T">Tanish Baranwal</a>, 
<a href="/search/physics?searchtype=author&query=Lebert%2C+J">Jan Lebert</a>, 
<a href="/search/physics?searchtype=author&query=Christoph%2C+J">Jan Christoph</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV); Biological Physics (physics.bio-ph); Tissues and Organs (q-bio.TO)

</div>
<p class="mathjax">Electrical waves in the heart form rotating spiral or scroll waves during
life-threatening arrhythmias such as atrial or ventricular fibrillation. The
wave dynamics are typically modeled using coupled partial differential
equations, which describe reaction-diffusion dynamics in excitable media. More
recently, data-driven generative modeling has emerged as an alternative to
generate spatio-temporal patterns in physical and biological systems. Here, we
explore denoising diffusion probabilistic models for the generative modeling of
electrical wave patterns in cardiac tissue. We trained diffusion models with
simulated electrical wave patterns to be able to generate such wave patterns in
unconditional and conditional generation tasks. For instance, we explored
inpainting tasks, such as reconstructing three-dimensional wave dynamics from
superficial two-dimensional measurements, and evolving and generating
parameter-specific dynamics. We characterized and compared the
diffusion-generated solutions to solutions obtained with biophysical models and
found that diffusion models learn to replicate spiral and scroll waves dynamics
so well that they could serve as an alternative data-driven approach for the
modeling of excitation waves in cardiac tissue. For instance, we found that it
is possible to initiate ventricular fibrillation (VF) dynamics instantaneously
without having to apply pacing protocols in order to induce wavebreak. The VF
dynamics can be created in arbitrary ventricular geometries and can be evolved
over time. However, we also found that diffusion models `hallucinate' wave
patterns when given insufficient constraints. Regardless of these limitations,
diffusion models are an interesting and powerful tool with many potential
applications in cardiac arrhythmia research and diagnostics.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14844" title="Abstract">arXiv:2312.14844</a> (cross-list from eess.AS) [<a href="/pdf/2312.14844" title="Download PDF">pdf</a>, <a href="/format/2312.14844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Implantable Piezofilm Middle Ear Microphone: Performance in Human  Cadaveric Temporal Bones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J+Z">John Z. Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Graf%2C+L">Lukas Graf</a>, 
<a href="/search/eess?searchtype=author&query=Banerjee%2C+A">Annesya Banerjee</a>, 
<a href="/search/eess?searchtype=author&query=Yeiser%2C+A">Aaron Yeiser</a>, 
<a href="/search/eess?searchtype=author&query=McHugh%2C+C+I">Christopher I. McHugh</a>, 
<a href="/search/eess?searchtype=author&query=Kymissis%2C+I">Ioannis Kymissis</a>, 
<a href="/search/eess?searchtype=author&query=Lang%2C+J+H">Jeffrey H. Lang</a>, 
<a href="/search/eess?searchtype=author&query=Olson%2C+E+S">Elizabeth S. Olson</a>, 
<a href="/search/eess?searchtype=author&query=Nakajima%2C+H+H">Hideko Heidi Nakajima</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Purpose: One of the major reasons that totally implantable cochlear
microphones are not readily available is the lack of good implantable
microphones. An implantable microphone has the potential to provide a range of
benefits over external microphones for cochlear implant users including the
filtering ability of the outer ear, cosmetics, and usability in all situations.
This paper presents results from experiments in human cadaveric ears of a
piezofilm microphone concept under development as a possible component of a
future implantable microphone system for use with cochlear implants. This
microphone is referred to here as a drum microphone (DrumMic) that senses the
robust and predictable motion of the umbo, the tip of the malleus. Methods: The
performance was measured of five DrumMics inserted in four different human
cadaveric temporal bones. Sensitivity, linearity, bandwidth, and equivalent
input noise were measured during these experiments using a sound stimulus and
measurement setup. Results: The sensitivity of the DrumMics was found to be
tightly clustered across different microphones and ears despite differences in
umbo and middle ear anatomy. The DrumMics were shown to behave linearly across
a large dynamic range (46 dB SPL to 100 dB SPL) across a wide bandwidth (100 Hz
to 8 kHz). The equivalent input noise (0.1-10 kHz) of the DrumMic and amplifier
referenced to the ear canal was measured to be 54 dB SPL and estimated to be 46
dB SPL after accounting for the pressure gain of the outer ear. Conclusion: The
results demonstrate that the DrumMic behaves robustly across ears and
fabrication. The equivalent input noise performance was shown to approach that
of commercial hearing aid microphones. To advance this demonstration of the
DrumMic concept to a future prototype implantable in humans, work on
encapsulation, biocompatibility, connectorization will be required.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14847" title="Abstract">arXiv:2312.14847</a> (cross-list from physics.bio-ph) [<a href="/pdf/2312.14847" title="Download PDF">pdf</a>, <a href="/format/2312.14847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Scale Traning of Graph Neural Networks for Optimal Markov-Chain  Partitioning Using the Kemeny Constant
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Martino%2C+S+A">Sam Alexander Martino</a>, 
<a href="/search/physics?searchtype=author&query=Morado%2C+J">Jo&#xe3;o Morado</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+C">Chenghao Li</a>, 
<a href="/search/physics?searchtype=author&query=Lu%2C+Z">Zhenghao Lu</a>, 
<a href="/search/physics?searchtype=author&query=Rosta%2C+E">Edina Rosta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biological Physics (physics.bio-ph)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Traditional clustering algorithms often struggle to capture the complex
relationships within graphs and generalise to arbitrary clustering criteria.
The emergence of graph neural networks (GNNs) as a powerful framework for
learning representations of graph data provides new approaches to solving the
problem. Previous work has shown GNNs to be capable of proposing partitionings
using a variety of criteria, however, these approaches have not yet been
extended to work on Markov chains or kinetic networks. These arise frequently
in the study of molecular systems and are of particular interest to the
biochemical modelling community. In this work, we propose several GNN-based
architectures to tackle the graph partitioning problem for Markov Chains
described as kinetic networks. This approach aims to minimize how much a
proposed partitioning changes the Kemeny constant. We propose using an
encoder-decoder architecture and show how simple GraphSAGE-based GNNs with
linear layers can outperform much larger and more expressive attention-based
models in this context. As a proof of concept, we first demonstrate the
method's ability to cluster randomly connected graphs. We also use a linear
chain architecture corresponding to a 1D free energy profile as our kinetic
network. Subsequently, we demonstrate the effectiveness of our method through
experiments on a data set derived from molecular dynamics. We compare the
performance of our method to other partitioning techniques such as PCCA+. We
explore the importance of feature and hyperparameter selection and propose a
general strategy for large-scale parallel training of GNNs for discovering
optimal graph partitionings.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14882" title="Abstract">arXiv:2312.14882</a> (cross-list from math.ST) [<a href="/pdf/2312.14882" title="Download PDF">pdf</a>, <a href="/ps/2312.14882" title="Download PostScript">ps</a>, <a href="/format/2312.14882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sampling and estimation on manifolds using the Langevin diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bharath%2C+K">Karthik Bharath</a>, 
<a href="/search/math?searchtype=author&query=Lewis%2C+A">Alexander Lewis</a>, 
<a href="/search/math?searchtype=author&query=Sharma%2C+A">Akash Sharma</a>, 
<a href="/search/math?searchtype=author&query=Tretyakov%2C+M+V">Michael V Tretyakov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Numerical Analysis (math.NA); Probability (math.PR); Computation (stat.CO); Machine Learning (stat.ML)

</div>
<p class="mathjax">Error bounds are derived for sampling and estimation using a discretization
of an intrinsically defined Langevin diffusion with invariant measure
$d\mu_\phi \propto e^{-\phi} \mathrm{dvol}_g $ on a compact Riemannian
manifold. Two estimators of linear functionals of $\mu_\phi $ based on the
discretized Markov process are considered: a time-averaging estimator based on
a single trajectory and an ensemble-averaging estimator based on multiple
independent trajectories. Imposing no restrictions beyond a nominal level of
smoothness on $\phi$, first-order error bounds, in discretization step size, on
the bias and variances of both estimators are derived. The order of error
matches the optimal rate in Euclidean and flat spaces, and leads to a
first-order bound on distance between the invariant measure $\mu_\phi$ and a
stationary measure of the discretized Markov process. Generality of the proof
techniques, which exploit links between two partial differential equations and
the semigroup of operators corresponding to the Langevin diffusion, renders
them amenable for the study of a more general class of sampling algorithms
related to the Langevin diffusion. Conditions for extending analysis to the
case of non-compact manifolds are discussed. Numerical illustrations with
distributions, log-concave and otherwise, on the manifolds of positive and
negative curvature elucidate on the derived bounds and demonstrate practical
utility of the sampling algorithm.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14889" title="Abstract">arXiv:2312.14889</a> (cross-list from stat.ML) [<a href="/pdf/2312.14889" title="Download PDF">pdf</a>, <a href="/ps/2312.14889" title="Download PostScript">ps</a>, <a href="/format/2312.14889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On rate-optimal classification from non-private and from private data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Cs%C3%A1ji%2C+B+C">Bal&#xe1;zs Csan&#xe1;d Cs&#xe1;ji</a>, 
<a href="/search/stat?searchtype=author&query=Gy%C3%B6rfi%2C+L">L&#xe1;szl&#xf3; Gy&#xf6;rfi</a>, 
<a href="/search/stat?searchtype=author&query=Tam%C3%A1s%2C+A">Ambrus Tam&#xe1;s</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
<p class="mathjax">In this paper we revisit the classical problem of classification, but impose
privacy constraints. Under such constraints, the raw data
$(X_1,Y_1),\ldots,(X_n,Y_n)$ cannot be directly observed, and all classifiers
are functions of the randomised outcome of a suitable local differential
privacy mechanism. The statistician is free to choose the form of this privacy
mechanism, and here we add Laplace distributed noise to a discretisation of the
location of each feature vector $X_i$ and to its label $Y_i$. The
classification rule is the privatized version of the well-studied partitioning
classification rule. In addition to the standard Lipschitz and margin
conditions, a novel characteristic is introduced, by which the exact rate of
convergence of the classification error probability is calculated, both for
non-private and private data.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14891" title="Abstract">arXiv:2312.14891</a> (cross-list from eess.IV) [<a href="/pdf/2312.14891" title="Download PDF">pdf</a>, <a href="/format/2312.14891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DRStageNet: Deep Learning for Diabetic Retinopathy Staging from Fundus  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Men%2C+Y">Yevgeniy Men</a>, 
<a href="/search/eess?searchtype=author&query=Fhima%2C+J">Jonathan Fhima</a>, 
<a href="/search/eess?searchtype=author&query=Celi%2C+L+A">Leo Anthony Celi</a>, 
<a href="/search/eess?searchtype=author&query=Ribeiro%2C+L+Z">Lucas Zago Ribeiro</a>, 
<a href="/search/eess?searchtype=author&query=Nakayama%2C+L+F">Luis Filipe Nakayama</a>, 
<a href="/search/eess?searchtype=author&query=Behar%2C+J+A">Joachim A. Behar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Diabetic retinopathy (DR) is a prevalent complication of diabetes associated
with a significant risk of vision loss. Timely identification is critical to
curb vision impairment. Algorithms for DR staging from digital fundus images
(DFIs) have been recently proposed. However, models often fail to generalize
due to distribution shifts between the source domain on which the model was
trained and the target domain where it is deployed. A common and particularly
challenging shift is often encountered when the source- and target-domain
supports do not fully overlap. In this research, we introduce DRStageNet, a
deep learning model designed to mitigate this challenge. We used seven publicly
available datasets, comprising a total of 93,534 DFIs that cover a variety of
patient demographics, ethnicities, geographic origins and comorbidities. We
fine-tune DINOv2, a pretrained model of self-supervised vision transformer, and
implement a multi-source domain fine-tuning strategy to enhance generalization
performance. We benchmark and demonstrate the superiority of our method to two
state-of-the-art benchmarks, including a recently published foundation model.
We adapted the grad-rollout method to our regression task in order to provide
high-resolution explainability heatmaps. The error analysis showed that 59\% of
the main errors had incorrect reference labels. DRStageNet is accessible at URL
[upon acceptance of the manuscript].
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14922" title="Abstract">arXiv:2312.14922</a> (cross-list from stat.ML) [<a href="/pdf/2312.14922" title="Download PDF">pdf</a>, <a href="/format/2312.14922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning from higher-order statistics, efficiently: hypothesis tests,  random features, and neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sz%C3%A9kely%2C+E">Eszter Sz&#xe9;kely</a>, 
<a href="/search/stat?searchtype=author&query=Bardone%2C+L">Lorenzo Bardone</a>, 
<a href="/search/stat?searchtype=author&query=Gerace%2C+F">Federica Gerace</a>, 
<a href="/search/stat?searchtype=author&query=Goldt%2C+S">Sebastian Goldt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG)

</div>
<p class="mathjax">Neural networks excel at discovering statistical patterns in high-dimensional
data sets. In practice, higher-order cumulants, which quantify the non-Gaussian
correlations between three or more variables, are particularly important for
the performance of neural networks. But how efficient are neural networks at
extracting features from higher-order cumulants? We study this question in the
spiked cumulant model, where the statistician needs to recover a privileged
direction or "spike" from the order-$p\ge 4$ cumulants of~$d$-dimensional
inputs. We first characterise the fundamental statistical and computational
limits of recovering the spike by analysing the number of samples~$n$ required
to strongly distinguish between inputs from the spiked cumulant model and
isotropic Gaussian inputs. We find that statistical distinguishability requires
$n\gtrsim d$ samples, while distinguishing the two distributions in polynomial
time requires $n \gtrsim d^2$ samples for a wide class of algorithms, i.e.
those covered by the low-degree conjecture. These results suggest the existence
of a wide statistical-to-computational gap in this problem. Numerical
experiments show that neural networks learn to distinguish the two
distributions with quadratic sample complexity, while "lazy" methods like
random features are not better than random guessing in this regime. Our results
show that neural networks extract information from higher-order correlations in
the spiked cumulant model efficiently, and reveal a large gap in the amount of
data required by neural networks and random features to learn from higher-order
cumulants.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Mon, 25 Dec 23</h3>
<dl>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1812.02207" title="Abstract">arXiv:1812.02207</a> (replaced) [<a href="/pdf/1812.02207" title="Download PDF">pdf</a>, <a href="/format/1812.02207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Better Trees: An empirical study on hyperparameter tuning of  classification decision tree induction algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mantovani%2C+R+G">Rafael Gomes Mantovani</a>, 
<a href="/search/cs?searchtype=author&query=Horv%C3%A1th%2C+T">Tom&#xe1;&#x161; Horv&#xe1;th</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+A+L+D">Andr&#xe9; L. D. Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Cerri%2C+R">Ricardo Cerri</a>, 
<a href="/search/cs?searchtype=author&query=Junior%2C+S+B">Sylvio Barbon Junior</a>, 
<a href="/search/cs?searchtype=author&query=Vanschoren%2C+J">Joaquin Vanschoren</a>, 
<a href="/search/cs?searchtype=author&query=de+Leon+Ferreira+de+Carvalho%2C+A+C+P">Andr&#xe9; Carlos Ponce de Leon Ferreira de Carvalho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 60 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2008.08628" title="Abstract">arXiv:2008.08628</a> (replaced) [<a href="/pdf/2008.08628" title="Download PDF">pdf</a>, <a href="/ps/2008.08628" title="Download PostScript">ps</a>, <a href="/format/2008.08628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Connections Between Association Schemes and Analyses of Polyhedral  and Positive Semidefinite Lift-and-Project Relaxations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Au%2C+Y+H">Yu Hin Au</a>, 
<a href="/search/math?searchtype=author&query=Lindzey%2C+N">Nathan Lindzey</a>, 
<a href="/search/math?searchtype=author&query=Tun%C3%A7el%2C+L">Levent Tun&#xe7;el</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.11080" title="Abstract">arXiv:2106.11080</a> (replaced) [<a href="/pdf/2106.11080" title="Download PDF">pdf</a>, <a href="/ps/2106.11080" title="Download PostScript">ps</a>, <a href="/format/2106.11080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear Codes Associated to Symmetric Determinantal Varieties: Even Rank  Case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beelen%2C+P">Peter Beelen</a>, 
<a href="/search/cs?searchtype=author&query=Johnsen%2C+T">Trygve Johnsen</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+P">Prasant Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Algebraic Geometry (math.AG)

</div>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.13010" title="Abstract">arXiv:2108.13010</a> (replaced) [<a href="/pdf/2108.13010" title="Download PDF">pdf</a>, <a href="/ps/2108.13010" title="Download PostScript">ps</a>, <a href="/format/2108.13010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Piecewise monotone estimation in one-parameter exponential family
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Matsuda%2C+T">Takeru Matsuda</a>, 
<a href="/search/stat?searchtype=author&query=Miyatake%2C+Y">Yuto Miyatake</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Numerical Analysis (math.NA); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.09751" title="Abstract">arXiv:2110.09751</a> (replaced) [<a href="/pdf/2110.09751" title="Download PDF">pdf</a>, <a href="/format/2110.09751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Lightweight, High-Extension, Planar 3-Degree-of-Freedom Manipulator  Using Pinched Bistable Tapes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Osele%2C+O+G">O. Godson Osele</a>, 
<a href="/search/cs?searchtype=author&query=Okamura%2C+A+M">Allison M. Okamura</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+B+H">Brian H. Do</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICRA 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.10425" title="Abstract">arXiv:2112.10425</a> (replaced) [<a href="/pdf/2112.10425" title="Download PDF">pdf</a>, <a href="/format/2112.10425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-based Clustering with Missing Not At Random Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sportisse%2C+A">Aude Sportisse</a> (UCA, MAASAI), 
<a href="/search/stat?searchtype=author&query=Marbac%2C+M">Matthieu Marbac</a> (UR, ENSAI, CNRS, CREST), 
<a href="/search/stat?searchtype=author&query=Laporte%2C+F">Fabien Laporte</a> (Nantes Univ, CNRS, ITX-lab), 
<a href="/search/stat?searchtype=author&query=Celeux%2C+G">Gilles Celeux</a> (CELESTE), 
<a href="/search/stat?searchtype=author&query=Boyer%2C+C">Claire Boyer</a> (SU, LPSM (UMR\_8001), MOKAPLAN), 
<a href="/search/stat?searchtype=author&query=Josse%2C+J">Julie Josse</a> (IDESP, PREMEDICAL), 
<a href="/search/stat?searchtype=author&query=Biernacki%2C+C">Christophe Biernacki</a> (CNRS, MODAL)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.11126" title="Abstract">arXiv:2112.11126</a> (replaced) [<a href="/pdf/2112.11126" title="Download PDF">pdf</a>, <a href="/format/2112.11126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-shot Learning of Surrogates in PDE-constrained Optimization Under  Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Guth%2C+P+A">Philipp A. Guth</a>, 
<a href="/search/math?searchtype=author&query=Schillings%2C+C">Claudia Schillings</a>, 
<a href="/search/math?searchtype=author&query=Weissmann%2C+S">Simon Weissmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.11763" title="Abstract">arXiv:2112.11763</a> (replaced) [<a href="/pdf/2112.11763" title="Download PDF">pdf</a>, <a href="/ps/2112.11763" title="Download PostScript">ps</a>, <a href="/format/2112.11763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Divisible Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kurz%2C+S">Sascha Kurz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 105 pages; typos corrected and references updated
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.11766" title="Abstract">arXiv:2112.11766</a> (replaced) [<a href="/pdf/2112.11766" title="Download PDF">pdf</a>, <a href="/ps/2112.11766" title="Download PostScript">ps</a>, <a href="/format/2112.11766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constructions and bounds for subspace codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kurz%2C+S">Sascha Kurz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 105 pages; typos corrected and references updated
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.02395" title="Abstract">arXiv:2201.02395</a> (replaced) [<a href="/pdf/2201.02395" title="Download PDF">pdf</a>, <a href="/format/2201.02395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-Free Nonlinear Feedback Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=He%2C+Z">Zhiyu He</a>, 
<a href="/search/math?searchtype=author&query=Bolognani%2C+S">Saverio Bolognani</a>, 
<a href="/search/math?searchtype=author&query=He%2C+J">Jianping He</a>, 
<a href="/search/math?searchtype=author&query=D%C3%B6rfler%2C+F">Florian D&#xf6;rfler</a>, 
<a href="/search/math?searchtype=author&query=Guan%2C+X">Xinping Guan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published on IEEE Transactions on Automatic Control
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.05021" title="Abstract">arXiv:2201.05021</a> (replaced) [<a href="/pdf/2201.05021" title="Download PDF">pdf</a>, <a href="/format/2201.05021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustness against Read Committed for Transaction Templates with  Functional Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vandevoort%2C+B">Brecht Vandevoort</a>, 
<a href="/search/cs?searchtype=author&query=Ketsman%2C+B">Bas Ketsman</a>, 
<a href="/search/cs?searchtype=author&query=Koch%2C+C">Christoph Koch</a>, 
<a href="/search/cs?searchtype=author&query=Neven%2C+F">Frank Neven</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.01772" title="Abstract">arXiv:2204.01772</a> (replaced) [<a href="/pdf/2204.01772" title="Download PDF">pdf</a>, <a href="/format/2204.01772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Partitioning axis-parallel lines in 3D
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aronov%2C+B">Boris Aronov</a>, 
<a href="/search/cs?searchtype=author&query=Basit%2C+A">Abdul Basit</a>, 
<a href="/search/cs?searchtype=author&query=de+Berg%2C+M">Mark de Berg</a>, 
<a href="/search/cs?searchtype=author&query=Gudmundsson%2C+J">Joachim Gudmundsson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, minor changes, accepted to Computing in Geometry and Topology
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computing in Geometry and Topology, 2.1(2023), 9:1-9:20
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.12098" title="Abstract">arXiv:2205.12098</a> (replaced) [<a href="/pdf/2205.12098" title="Download PDF">pdf</a>, <a href="/format/2205.12098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COVID-19: An exploration of consecutive systemic barriers to  pathogen-related data sharing during a pandemic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yehudi%2C+Y">Yo Yehudi</a>, 
<a href="/search/cs?searchtype=author&query=Hughes-Noehrer%2C+L">Lukas Hughes-Noehrer</a>, 
<a href="/search/cs?searchtype=author&query=Goble%2C+C">Carole Goble</a>, 
<a href="/search/cs?searchtype=author&query=Jay%2C+C">Caroline Jay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages including references, three figures. To be submitted to Data and Policy
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.12703" title="Abstract">arXiv:2205.12703</a> (replaced) [<a href="/pdf/2205.12703" title="Download PDF">pdf</a>, <a href="/format/2205.12703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> All about unambiguous polynomial closure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Place%2C+T">Thomas Place</a>, 
<a href="/search/cs?searchtype=author&query=Zeitoun%2C+M">Marc Zeitoun</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> TheoretiCS, Volume 2 (2023), Article 11, 1-74
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.07861" title="Abstract">arXiv:2206.07861</a> (replaced) [<a href="/pdf/2206.07861" title="Download PDF">pdf</a>, <a href="/format/2206.07861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text normalization for low-resource languages: the case of Ligurian
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lusito%2C+S">Stefano Lusito</a>, 
<a href="/search/cs?searchtype=author&query=Ferrante%2C+E">Edoardo Ferrante</a>, 
<a href="/search/cs?searchtype=author&query=Maillard%2C+J">Jean Maillard</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of the Sixth Workshop on the Use of Computational
  Methods in the Study of Endangered Languages, p. 98-103 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.11004" title="Abstract">arXiv:2206.11004</a> (replaced) [<a href="/pdf/2206.11004" title="Download PDF">pdf</a>, <a href="/format/2206.11004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auto-Encoding Adversarial Imitation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaifeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.11267" title="Abstract">arXiv:2206.11267</a> (replaced) [<a href="/pdf/2206.11267" title="Download PDF">pdf</a>, <a href="/format/2206.11267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Implicit Manifold Learning for Topology-Aware Density Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ross%2C+B+L">Brendan Leigh Ross</a>, 
<a href="/search/stat?searchtype=author&query=Loaiza-Ganem%2C+G">Gabriel Loaiza-Ganem</a>, 
<a href="/search/stat?searchtype=author&query=Caterini%2C+A+L">Anthony L. Caterini</a>, 
<a href="/search/stat?searchtype=author&query=Cresswell%2C+J+C">Jesse C. Cresswell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to TMLR in 2023. Code: <a href="https://github.com/layer6ai-labs/implicit-manifolds">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.10438" title="Abstract">arXiv:2207.10438</a> (replaced) [<a href="/e-print/2207.10438" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incorporating Prior Knowledge into Reinforcement Learning for Soft  Tissue Manipulation with Autonomous Grasping Point Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xian He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shanlin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+B">Bo Ouyang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Withdrawn for major revisions that are necessary to address important reviewer comments and concerns
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.02691" title="Abstract">arXiv:2208.02691</a> (replaced) [<a href="/pdf/2208.02691" title="Download PDF">pdf</a>, <a href="/ps/2208.02691" title="Download PostScript">ps</a>, <a href="/format/2208.02691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Infinite Separation between General and Chromatic Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kozachinskiy%2C+A">Alexander Kozachinskiy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of the LATIN 2024 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.12459" title="Abstract">arXiv:2208.12459</a> (replaced) [<a href="/pdf/2208.12459" title="Download PDF">pdf</a>, <a href="/format/2208.12459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta Objective Guided Disambiguation for Partial Label Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+B">Bo-Shi Zou</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+M">Ming-Kun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Sheng-Jun Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.07662" title="Abstract">arXiv:2209.07662</a> (replaced) [<a href="/pdf/2209.07662" title="Download PDF">pdf</a>, <a href="/format/2209.07662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NELLIE: A Neuro-Symbolic Inference Engine for Grounded, Compositional,  and Explainable Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weir%2C+N">Nathaniel Weir</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+P">Peter Clark</a>, 
<a href="/search/cs?searchtype=author&query=Van+Durme%2C+B">Benjamin Van Durme</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.11899" title="Abstract">arXiv:2209.11899</a> (replaced) [<a href="/pdf/2209.11899" title="Download PDF">pdf</a>, <a href="/ps/2209.11899" title="Download PostScript">ps</a>, <a href="/format/2209.11899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two Bicomplex and One Multicomplex Least Mean Square algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alpay%2C+D">Daniel Alpay</a>, 
<a href="/search/cs?searchtype=author&query=Diki%2C+K">Kamal Diki</a>, 
<a href="/search/cs?searchtype=author&query=Vajiac%2C+M">Mihaela Vajiac</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.11413" title="Abstract">arXiv:2210.11413</a> (replaced) [<a href="/pdf/2210.11413" title="Download PDF">pdf</a>, <a href="/format/2210.11413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimizing low-rank models of high-order tensors: Hardness, span, tight  relaxation, and applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sidiropoulos%2C+N+D">Nicholas D. Sidiropoulos</a>, 
<a href="/search/eess?searchtype=author&query=Karakasis%2C+P">Paris Karakasis</a>, 
<a href="/search/eess?searchtype=author&query=Konar%2C+A">Aritra Konar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 11 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in IEEE Transactions on Signal Processing, vol. 72, pp. 129-142,
  2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.16940" title="Abstract">arXiv:2210.16940</a> (replaced) [<a href="/pdf/2210.16940" title="Download PDF">pdf</a>, <a href="/format/2210.16940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FI-ODE: Certifiably Robust Forward Invariance in Neural ODEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yujia Huang</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+I+D+J">Ivan Dario Jimenez Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yuanyuan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yisong Yue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.09053" title="Abstract">arXiv:2211.09053</a> (replaced) [<a href="/pdf/2211.09053" title="Download PDF">pdf</a>, <a href="/format/2211.09053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A moving horizon state and parameter estimation scheme with guaranteed  robust convergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Schiller%2C+J+D">Julian D. Schiller</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%BCller%2C+M+A">Matthias A. M&#xfc;ller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Replaced by final version. Presented at IFAC World Congress 2023, Yokohama, Japan
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IFAC-PapersOnLine, Volume 56, Issue 2, 2023, Pages 6759-6764
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.15608" title="Abstract">arXiv:2211.15608</a> (replaced) [<a href="/pdf/2211.15608" title="Download PDF">pdf</a>, <a href="/format/2211.15608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representation with Incomplete Votes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Halpern%2C+D">Daniel Halpern</a>, 
<a href="/search/cs?searchtype=author&query=Kehne%2C+G">Gregory Kehne</a>, 
<a href="/search/cs?searchtype=author&query=Procaccia%2C+A+D">Ariel D. Procaccia</a>, 
<a href="/search/cs?searchtype=author&query=Tucker-Foltz%2C+J">Jamie Tucker-Foltz</a>, 
<a href="/search/cs?searchtype=author&query=W%C3%BCthrich%2C+M">Manuel W&#xfc;thrich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.03131" title="Abstract">arXiv:2212.03131</a> (replaced) [<a href="/pdf/2212.03131" title="Download PDF">pdf</a>, <a href="/format/2212.03131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainability as statistical inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Senetaire%2C+H+H+J">Hugo Henri Joseph Senetaire</a>, 
<a href="/search/cs?searchtype=author&query=Garreau%2C+D">Damien Garreau</a>, 
<a href="/search/cs?searchtype=author&query=Frellsen%2C+J">Jes Frellsen</a>, 
<a href="/search/cs?searchtype=author&query=Mattei%2C+P">Pierre-Alexandre Mattei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 22 figures, submitted at ICLR 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 40th International Conference on Machine
  Learning, PMLR 202:30584-30612, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11997" title="Abstract">arXiv:2301.11997</a> (replaced) [<a href="/pdf/2301.11997" title="Download PDF">pdf</a>, <a href="/format/2301.11997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt-Based Editing for Text Style Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+G">Guoqing Luo</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y+T">Yu Tong Han</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+L">Lili Mou</a>, 
<a href="/search/cs?searchtype=author&query=Firdaus%2C+M">Mauajama Firdaus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP Findings 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00845" title="Abstract">arXiv:2302.00845</a> (replaced) [<a href="/pdf/2302.00845" title="Download PDF">pdf</a>, <a href="/format/2302.00845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coordinating Distributed Example Orders for Provably Accelerated  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cooper%2C+A+F">A. Feder Cooper</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wentao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+K">Khiem Pham</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+T">Tiancheng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+C+F">Charlie F. Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yucheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=De+Sa%2C+C">Christopher De Sa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01250" title="Abstract">arXiv:2302.01250</a> (replaced) [<a href="/pdf/2302.01250" title="Download PDF">pdf</a>, <a href="/format/2302.01250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying regions of importance in wall-bounded turbulence through  explainable deep learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Cremades%2C+A">Andres Cremades</a>, 
<a href="/search/physics?searchtype=author&query=Hoyas%2C+S">Sergio Hoyas</a>, 
<a href="/search/physics?searchtype=author&query=Deshpande%2C+R">Rahul Deshpande</a>, 
<a href="/search/physics?searchtype=author&query=Quintero%2C+P">Pedro Quintero</a>, 
<a href="/search/physics?searchtype=author&query=Lellep%2C+M">Martin Lellep</a>, 
<a href="/search/physics?searchtype=author&query=Lee%2C+W+J">Will Junghoon Lee</a>, 
<a href="/search/physics?searchtype=author&query=Monty%2C+J">Jason Monty</a>, 
<a href="/search/physics?searchtype=author&query=Hutchins%2C+N">Nicholas Hutchins</a>, 
<a href="/search/physics?searchtype=author&query=Linkmann%2C+M">Moritz Linkmann</a>, 
<a href="/search/physics?searchtype=author&query=Marusic%2C+I">Ivan Marusic</a>, 
<a href="/search/physics?searchtype=author&query=Vinuesa%2C+R">Ricardo Vinuesa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06117" title="Abstract">arXiv:2302.06117</a> (replaced) [<a href="/pdf/2302.06117" title="Download PDF">pdf</a>, <a href="/format/2302.06117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Framework Tax: Disparities Between Inference Efficiency in NLP  Research and Deployment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fernandez%2C+J">Jared Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=Kahn%2C+J">Jacob Kahn</a>, 
<a href="/search/cs?searchtype=author&query=Na%2C+C">Clara Na</a>, 
<a href="/search/cs?searchtype=author&query=Bisk%2C+Y">Yonatan Bisk</a>, 
<a href="/search/cs?searchtype=author&query=Strubell%2C+E">Emma Strubell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10510" title="Abstract">arXiv:2302.10510</a> (replaced) [<a href="/pdf/2302.10510" title="Download PDF">pdf</a>, <a href="/format/2302.10510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Future Aware Pricing and Matching for Sustainable On-demand Ride Pooling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xianjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Varakantham%2C+P">Pradeep Varakantham</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hao Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures, published to AAAI-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12194" title="Abstract">arXiv:2302.12194</a> (replaced) [<a href="/pdf/2302.12194" title="Download PDF">pdf</a>, <a href="/format/2302.12194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Circuits to SoC Processors: Arithmetic Approximation Techniques &amp;  Embedded Computing Methodologies for DSP Acceleration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leon%2C+V">Vasileios Leon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD Dissertation, National Technical University of Athens
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01667" title="Abstract">arXiv:2303.01667</a> (replaced) [<a href="/pdf/2303.01667" title="Download PDF">pdf</a>, <a href="/format/2303.01667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizing Lloyd&#x27;s algorithm for graph clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zaman%2C+T">Tareq Zaman</a>, 
<a href="/search/math?searchtype=author&query=Nytko%2C+N">Nicolas Nytko</a>, 
<a href="/search/math?searchtype=author&query=Taghibakhshi%2C+A">Ali Taghibakhshi</a>, 
<a href="/search/math?searchtype=author&query=MacLachlan%2C+S">Scott MacLachlan</a>, 
<a href="/search/math?searchtype=author&query=Olson%2C+L">Luke Olson</a>, 
<a href="/search/math?searchtype=author&query=West%2C+M">Matthew West</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02370" title="Abstract">arXiv:2303.02370</a> (replaced) [<a href="/pdf/2303.02370" title="Download PDF">pdf</a>, <a href="/format/2303.02370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Learning for Place Representation Generalization across  Appearance Changes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Musallam%2C+M+A">Mohamed Adel Musallam</a>, 
<a href="/search/cs?searchtype=author&query=Gaudilli%C3%A8re%2C+V">Vincent Gaudilli&#xe8;re</a>, 
<a href="/search/cs?searchtype=author&query=Aouada%2C+D">Djamila Aouada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures, WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05915" title="Abstract">arXiv:2303.05915</a> (replaced) [<a href="/pdf/2303.05915" title="Download PDF">pdf</a>, <a href="/format/2303.05915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convolutional Cross-View Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+Z">Zimin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Booij%2C+O">Olaf Booij</a>, 
<a href="/search/cs?searchtype=author&query=Kooij%2C+J+F+P">Julian F. P. Kooij</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09565" title="Abstract">arXiv:2303.09565</a> (replaced) [<a href="/pdf/2303.09565" title="Download PDF">pdf</a>, <a href="/format/2303.09565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPSysML: A meta-model for quantitative evaluation of Simulation-Physical  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dudek%2C+W">Wojciech Dudek</a>, 
<a href="/search/cs?searchtype=author&query=Miguel%2C+N">Narcis Miguel</a>, 
<a href="/search/cs?searchtype=author&query=Winiarski%2C+T">Tomasz Winiarski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Hardware Architecture (cs.AR); Multiagent Systems (cs.MA); Robotics (cs.RO); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11959" title="Abstract">arXiv:2303.11959</a> (replaced) [<a href="/pdf/2303.11959" title="Download PDF">pdf</a>, <a href="/format/2303.11959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Trading Strategies in Quantitative Markets using Multi-Agent  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Zhang%2C+H">Hengxi Zhang</a>, 
<a href="/search/q-fin?searchtype=author&query=Shi%2C+Z">Zhendong Shi</a>, 
<a href="/search/q-fin?searchtype=author&query=Hu%2C+Y">Yuanquan Hu</a>, 
<a href="/search/q-fin?searchtype=author&query=Ding%2C+W">Wenbo Ding</a>, 
<a href="/search/q-fin?searchtype=author&query=Kuruoglu%2C+E+E">Ercan E. Kuruoglu</a>, 
<a href="/search/q-fin?searchtype=author&query=Zhang%2C+X">Xiao-Ping Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Trading and Market Microstructure (q-fin.TR)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12966" title="Abstract">arXiv:2303.12966</a> (replaced) [<a href="/pdf/2303.12966" title="Download PDF">pdf</a>, <a href="/format/2303.12966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rate-Tunable Control Barrier Functions: Methods and Algorithms for  Online Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Parwana%2C+H">Hardik Parwana</a>, 
<a href="/search/math?searchtype=author&query=Panagou%2C+D">Dimitra Panagou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13001" title="Abstract">arXiv:2303.13001</a> (replaced) [<a href="/pdf/2303.13001" title="Download PDF">pdf</a>, <a href="/format/2303.13001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is ChatGPT A Good Keyphrase Generator? A Preliminary Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Mingyang Song</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Haiyun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+S">Songfang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shilong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huafeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+L">Liping Jing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report, 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00917" title="Abstract">arXiv:2304.00917</a> (replaced) [<a href="/pdf/2304.00917" title="Download PDF">pdf</a>, <a href="/format/2304.00917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Bridge Mixture Transports, Schr&#xf6;dinger Bridge Problems and  Generative Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Peluchetti%2C+S">Stefano Peluchetti</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Machine Learning Research 24(374):1-51, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02086" title="Abstract">arXiv:2304.02086</a> (replaced) [<a href="/pdf/2304.02086" title="Download PDF">pdf</a>, <a href="/format/2304.02086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized and Privacy-Preserving Learning of Approximate Stackelberg  Solutions in Energy Trading Games with Demand Response Aggregators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kampezidou%2C+S+I">Styliani I. Kampezidou</a>, 
<a href="/search/cs?searchtype=author&query=Romberg%2C+J">Justin Romberg</a>, 
<a href="/search/cs?searchtype=author&query=Vamvoudakis%2C+K+G">Kyriakos G. Vamvoudakis</a>, 
<a href="/search/cs?searchtype=author&query=Mavris%2C+D+N">Dimitri N. Mavris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04164" title="Abstract">arXiv:2304.04164</a> (replaced) [<a href="/pdf/2304.04164" title="Download PDF">pdf</a>, <a href="/format/2304.04164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient Sparsification for Efficient Wireless Federated Learning with  Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+K">Kang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Ming Ding</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+F">Feng Shu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haitao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hongbo Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05684" title="Abstract">arXiv:2304.05684</a> (replaced) [<a href="/pdf/2304.05684" title="Download PDF">pdf</a>, <a href="/format/2304.05684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InterGen: Diffusion-based Multi-human Motion Generation under Complex  Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+H">Han Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenqian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jingyi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11241" title="Abstract">arXiv:2304.11241</a> (replaced) [<a href="/pdf/2304.11241" title="Download PDF">pdf</a>, <a href="/format/2304.11241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoNeRF: Training Implicit Scene Representations with Autonomous Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marza%2C+P">Pierre Marza</a>, 
<a href="/search/cs?searchtype=author&query=Matignon%2C+L">Laetitia Matignon</a>, 
<a href="/search/cs?searchtype=author&query=Simonin%2C+O">Olivier Simonin</a>, 
<a href="/search/cs?searchtype=author&query=Batra%2C+D">Dhruv Batra</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+C">Christian Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Chaplot%2C+D+S">Devendra Singh Chaplot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14291" title="Abstract">arXiv:2304.14291</a> (replaced) [<a href="/pdf/2304.14291" title="Download PDF">pdf</a>, <a href="/format/2304.14291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EDAPS: Enhanced Domain-Adaptive Panoptic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saha%2C+S">Suman Saha</a>, 
<a href="/search/cs?searchtype=author&query=Hoyer%2C+L">Lukas Hoyer</a>, 
<a href="/search/cs?searchtype=author&query=Obukhov%2C+A">Anton Obukhov</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+D">Dengxin Dai</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01658" title="Abstract">arXiv:2305.01658</a> (replaced) [<a href="/pdf/2305.01658" title="Download PDF">pdf</a>, <a href="/format/2305.01658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlightBERT++: A Non-autoregressive Multi-Horizon Flight Trajectory  Prediction Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Dongyue Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhen Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yi Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02693" title="Abstract">arXiv:2305.02693</a> (replaced) [<a href="/pdf/2305.02693" title="Download PDF">pdf</a>, <a href="/format/2305.02693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-supervised Domain Adaptation via Prototype-based Multi-level  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xinyang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chuang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenkai Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IJCAI 2023. To avoid confusion, update to a more complete version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05107" title="Abstract">arXiv:2305.05107</a> (replaced) [<a href="/pdf/2305.05107" title="Download PDF">pdf</a>, <a href="/format/2305.05107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Viral Information Spreading via Directed Acyclic Graph  Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dinesh%2C+C">Chinthaka Dinesh</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+G">Gene Cheung</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuejiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H+V">H. Vicky Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05400" title="Abstract">arXiv:2305.05400</a> (replaced) [<a href="/pdf/2305.05400" title="Download PDF">pdf</a>, <a href="/format/2305.05400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating the Corruption Robustness of Image Classifiers with Random  Lp-norm Corruptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Siedel%2C+G">Georg Siedel</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+W">Weijia Shao</a>, 
<a href="/search/cs?searchtype=author&query=Vock%2C+S">Silvia Vock</a>, 
<a href="/search/cs?searchtype=author&query=Morozov%2C+A">Andrey Morozov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera-ready version submitted to VISAPP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06972" title="Abstract">arXiv:2305.06972</a> (replaced) [<a href="/pdf/2305.06972" title="Download PDF">pdf</a>, <a href="/ps/2305.06972" title="Download PostScript">ps</a>, <a href="/format/2305.06972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spear Phishing With Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hazell%2C+J">Julian Hazell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11356" title="Abstract">arXiv:2305.11356</a> (replaced) [<a href="/pdf/2305.11356" title="Download PDF">pdf</a>, <a href="/format/2305.11356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Div-Div-Conforming Symmetric Tensor Finite Element Space with  Applications to the Biharmonic Equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+L">Long Chen</a>, 
<a href="/search/math?searchtype=author&query=Huang%2C+X">Xuehai Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14171" title="Abstract">arXiv:2305.14171</a> (replaced) [<a href="/pdf/2305.14171" title="Download PDF">pdf</a>, <a href="/format/2305.14171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Context Probing: Toward Building Robust Classifiers via Probing Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amini%2C+A">Afra Amini</a>, 
<a href="/search/cs?searchtype=author&query=Ciaramita%2C+M">Massimiliano Ciaramita</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15930" title="Abstract">arXiv:2305.15930</a> (replaced) [<a href="/pdf/2305.15930" title="Download PDF">pdf</a>, <a href="/format/2305.15930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-End Meta-Bayesian Optimisation with Transformer Neural Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maraval%2C+A">Alexandre Maraval</a>, 
<a href="/search/cs?searchtype=author&query=Zimmer%2C+M">Matthieu Zimmer</a>, 
<a href="/search/cs?searchtype=author&query=Grosnit%2C+A">Antoine Grosnit</a>, 
<a href="/search/cs?searchtype=author&query=Ammar%2C+H+B">Haitham Bou Ammar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17349" title="Abstract">arXiv:2305.17349</a> (replaced) [<a href="/pdf/2305.17349" title="Download PDF">pdf</a>, <a href="/format/2305.17349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Condition-Invariant Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sakaridis%2C+C">Christos Sakaridis</a>, 
<a href="/search/cs?searchtype=author&query=Bruggemann%2C+D">David Bruggemann</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Fisher Yu</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for review to IEEE T-PAMI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19228" title="Abstract">arXiv:2305.19228</a> (replaced) [<a href="/pdf/2305.19228" title="Download PDF">pdf</a>, <a href="/format/2305.19228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Melody-to-Lyric Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yufei Tian</a>, 
<a href="/search/cs?searchtype=author&query=Narayan-Chen%2C+A">Anjali Narayan-Chen</a>, 
<a href="/search/cs?searchtype=author&query=Oraby%2C+S">Shereen Oraby</a>, 
<a href="/search/cs?searchtype=author&query=Cervone%2C+A">Alessandra Cervone</a>, 
<a href="/search/cs?searchtype=author&query=Sigurdsson%2C+G">Gunnar Sigurdsson</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+C">Chenyang Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenbo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiwen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+T">Tagyoung Chung</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+N">Nanyun Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACL 2023. arXiv admin note: substantial text overlap with <a href="/abs/2305.07760">arXiv:2305.07760</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19735" title="Abstract">arXiv:2305.19735</a> (replaced) [<a href="/pdf/2305.19735" title="Download PDF">pdf</a>, <a href="/format/2305.19735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IT/OT Integration by Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sch%C3%A4fer%2C+G">Georg Sch&#xe4;fer</a>, 
<a href="/search/cs?searchtype=author&query=Waclawek%2C+H">Hannes Waclawek</a>, 
<a href="/search/cs?searchtype=author&query=Riedmann%2C+S">Sarah Riedmann</a>, 
<a href="/search/cs?searchtype=author&query=Binder%2C+C">Christoph Binder</a>, 
<a href="/search/cs?searchtype=author&query=Neureiter%2C+C">Christian Neureiter</a>, 
<a href="/search/cs?searchtype=author&query=Huber%2C+S">Stefan Huber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to INCOSE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03638" title="Abstract">arXiv:2306.03638</a> (replaced) [<a href="/pdf/2306.03638" title="Download PDF">pdf</a>, <a href="/ps/2306.03638" title="Download PostScript">ps</a>, <a href="/format/2306.03638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provable convergence guarantees for black-box variational inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Domke%2C+J">Justin Domke</a>, 
<a href="/search/cs?searchtype=author&query=Garrigos%2C+G">Guillaume Garrigos</a>, 
<a href="/search/cs?searchtype=author&query=Gower%2C+R">Robert Gower</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05059" title="Abstract">arXiv:2306.05059</a> (replaced) [<a href="/pdf/2306.05059" title="Download PDF">pdf</a>, <a href="/format/2306.05059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconciling Predictive and Statistical Parity: A Causal Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Plecko%2C+D">Drago Plecko</a>, 
<a href="/search/cs?searchtype=author&query=Bareinboim%2C+E">Elias Bareinboim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05745" title="Abstract">arXiv:2306.05745</a> (replaced) [<a href="/pdf/2306.05745" title="Download PDF">pdf</a>, <a href="/format/2306.05745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two Independent Teachers are Better Role Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Khaled%2C+A">Afifa Khaled</a>, 
<a href="/search/eess?searchtype=author&query=Mubarak%2C+A+A">Ahmed A. Mubarak</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+K">Kun He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This manuscript contains 14 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05832" title="Abstract">arXiv:2306.05832</a> (replaced) [<a href="/pdf/2306.05832" title="Download PDF">pdf</a>, <a href="/format/2306.05832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sketch Beautification: Learning Part Beautification and Structure  Refinement for Sketches of Man-made Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Deng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+M">Manfred Lau</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Lin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Hongbo Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Visualization and Computer Graphics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06209" title="Abstract">arXiv:2306.06209</a> (replaced) [<a href="/pdf/2306.06209" title="Download PDF">pdf</a>, <a href="/format/2306.06209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backdoor Attack with Sparse and Invisible Trigger
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yinghua Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiming Li</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+X">Xueluan Gong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhifeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shu-Tao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qian Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors contributed equally to this work. 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11706" title="Abstract">arXiv:2306.11706</a> (replaced) [<a href="/pdf/2306.11706" title="Download PDF">pdf</a>, <a href="/format/2306.11706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoboCat: A Self-Improving Generalist Agent for Robotic Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bousmalis%2C+K">Konstantinos Bousmalis</a>, 
<a href="/search/cs?searchtype=author&query=Vezzani%2C+G">Giulia Vezzani</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+D">Dushyant Rao</a>, 
<a href="/search/cs?searchtype=author&query=Devin%2C+C">Coline Devin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+A+X">Alex X. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Bauza%2C+M">Maria Bauza</a>, 
<a href="/search/cs?searchtype=author&query=Davchev%2C+T">Todor Davchev</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuxiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Agrim Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Raju%2C+A">Akhil Raju</a>, 
<a href="/search/cs?searchtype=author&query=Laurens%2C+A">Antoine Laurens</a>, 
<a href="/search/cs?searchtype=author&query=Fantacci%2C+C">Claudio Fantacci</a>, 
<a href="/search/cs?searchtype=author&query=Dalibard%2C+V">Valentin Dalibard</a>, 
<a href="/search/cs?searchtype=author&query=Zambelli%2C+M">Martina Zambelli</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+M">Murilo Martins</a>, 
<a href="/search/cs?searchtype=author&query=Pevceviciute%2C+R">Rugile Pevceviciute</a>, 
<a href="/search/cs?searchtype=author&query=Blokzijl%2C+M">Michiel Blokzijl</a>, 
<a href="/search/cs?searchtype=author&query=Denil%2C+M">Misha Denil</a>, 
<a href="/search/cs?searchtype=author&query=Batchelor%2C+N">Nathan Batchelor</a>, 
<a href="/search/cs?searchtype=author&query=Lampe%2C+T">Thomas Lampe</a>, 
<a href="/search/cs?searchtype=author&query=Parisotto%2C+E">Emilio Parisotto</a>, 
<a href="/search/cs?searchtype=author&query=%C5%BBo%C5%82na%2C+K">Konrad &#x17b;o&#x142;na</a>, 
<a href="/search/cs?searchtype=author&query=Reed%2C+S">Scott Reed</a>, 
<a href="/search/cs?searchtype=author&query=Colmenarejo%2C+S+G">Sergio G&#xf3;mez Colmenarejo</a>, 
<a href="/search/cs?searchtype=author&query=Scholz%2C+J">Jon Scholz</a>, 
<a href="/search/cs?searchtype=author&query=Abdolmaleki%2C+A">Abbas Abdolmaleki</a>, 
<a href="/search/cs?searchtype=author&query=Groth%2C+O">Oliver Groth</a>, 
<a href="/search/cs?searchtype=author&query=Regli%2C+J">Jean-Baptiste Regli</a>, 
<a href="/search/cs?searchtype=author&query=Sushkov%2C+O">Oleg Sushkov</a>, 
<a href="/search/cs?searchtype=author&query=Roth%C3%B6rl%2C+T">Tom Roth&#xf6;rl</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J+E">Jos&#xe9; Enrique Chen</a>, 
<a href="/search/cs?searchtype=author&query=Aytar%2C+Y">Yusuf Aytar</a>, 
<a href="/search/cs?searchtype=author&query=Barker%2C+D">Dave Barker</a>, 
<a href="/search/cs?searchtype=author&query=Ortiz%2C+J">Joy Ortiz</a>, 
<a href="/search/cs?searchtype=author&query=Riedmiller%2C+M">Martin Riedmiller</a>, 
<a href="/search/cs?searchtype=author&query=Springenberg%2C+J+T">Jost Tobias Springenberg</a>, 
<a href="/search/cs?searchtype=author&query=Hadsell%2C+R">Raia Hadsell</a>, 
<a href="/search/cs?searchtype=author&query=Nori%2C+F">Francesco Nori</a>, 
<a href="/search/cs?searchtype=author&query=Heess%2C+N">Nicolas Heess</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Transactions on Machine Learning Research (12/2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11758" title="Abstract">arXiv:2306.11758</a> (replaced) [<a href="/pdf/2306.11758" title="Download PDF">pdf</a>, <a href="/format/2306.11758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MRFI: An Open Source Multi-Resolution Fault Injection Framework for  Neural Network Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haitong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+X">Xinghua Xue</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huawei Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaowei Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 12 figures, source code is on <a href="https://github.com/fffasttime/MRFI">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15774" title="Abstract">arXiv:2306.15774</a> (replaced) [<a href="/pdf/2306.15774" title="Download PDF">pdf</a>, <a href="/ps/2306.15774" title="Download PostScript">ps</a>, <a href="/format/2306.15774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Next Steps for Human-Centered Generative AI: A Technical Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X+%27">Xiang &#x27;Anthony&#x27; Chen</a>, 
<a href="/search/cs?searchtype=author&query=Burke%2C+J">Jeff Burke</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+R">Ruofei Du</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+M+K">Matthew K. Hong</a>, 
<a href="/search/cs?searchtype=author&query=Jacobs%2C+J">Jennifer Jacobs</a>, 
<a href="/search/cs?searchtype=author&query=Laban%2C+P">Philippe Laban</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dingzeyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+N">Nanyun Peng</a>, 
<a href="/search/cs?searchtype=author&query=Willis%2C+K+D+D">Karl D. D. Willis</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chien-Sheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bolei Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17602" title="Abstract">arXiv:2306.17602</a> (replaced) [<a href="/pdf/2306.17602" title="Download PDF">pdf</a>, <a href="/format/2306.17602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> S.T.A.R.-Track: Latent Motion Models for End-to-End 3D Object Tracking  with Adaptive Spatio-Temporal Appearance Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doll%2C+S">Simon Doll</a>, 
<a href="/search/cs?searchtype=author&query=Hanselmann%2C+N">Niklas Hanselmann</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+L">Lukas Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Schulz%2C+R">Richard Schulz</a>, 
<a href="/search/cs?searchtype=author&query=Enzweiler%2C+M">Markus Enzweiler</a>, 
<a href="/search/cs?searchtype=author&query=Lensch%2C+H+P+A">Hendrik P.A. Lensch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> \c{opyright} 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00348" title="Abstract">arXiv:2307.00348</a> (replaced) [<a href="/pdf/2307.00348" title="Download PDF">pdf</a>, <a href="/format/2307.00348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lottery and Sprint: Generate a Board Game with Design Sprint Method on  AutoGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Torii%2C+M+G">Maya Grace Torii</a>, 
<a href="/search/cs?searchtype=author&query=Murakami%2C+T">Takahito Murakami</a>, 
<a href="/search/cs?searchtype=author&query=Ochiai%2C+Y">Yoichi Ochiai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures, author's version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05936" title="Abstract">arXiv:2307.05936</a> (replaced) [<a href="/pdf/2307.05936" title="Download PDF">pdf</a>, <a href="/format/2307.05936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Introducing Packet-Level Analysis in Programmable Data Planes to Advance  Network Intrusion Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doriguzzi-Corin%2C+R">Roberto Doriguzzi-Corin</a>, 
<a href="/search/cs?searchtype=author&query=Knob%2C+L+A+D">Luis Augusto Dias Knob</a>, 
<a href="/search/cs?searchtype=author&query=Mendozzi%2C+L">Luca Mendozzi</a>, 
<a href="/search/cs?searchtype=author&query=Siracusa%2C+D">Domenico Siracusa</a>, 
<a href="/search/cs?searchtype=author&query=Savi%2C+M">Marco Savi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08159" title="Abstract">arXiv:2307.08159</a> (replaced) [<a href="/pdf/2307.08159" title="Download PDF">pdf</a>, <a href="/format/2307.08159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Gain as Privacy Loss in Local Privacy Accounting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+M">Mingen Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09619" title="Abstract">arXiv:2307.09619</a> (replaced) [<a href="/pdf/2307.09619" title="Download PDF">pdf</a>, <a href="/format/2307.09619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Federated Foundation Models: Scalable Dataset Pipelines for  Group-Structured Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Charles%2C+Z">Zachary Charles</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+N">Nicole Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Pillutla%2C+K">Krishna Pillutla</a>, 
<a href="/search/cs?searchtype=author&query=Reneer%2C+M">Michael Reneer</a>, 
<a href="/search/cs?searchtype=author&query=Garrett%2C+Z">Zachary Garrett</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Dataset Grouper is available at <a href="https://github.com/google-research/dataset_grouper">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023 (Datasets &amp; Benchmarks)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14685" title="Abstract">arXiv:2307.14685</a> (replaced) [<a href="/pdf/2307.14685" title="Download PDF">pdf</a>, <a href="/format/2307.14685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quinpi: Integrating stiff hyperbolic systems with implicit high order  finite volume schemes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Puppo%2C+G">Gabriella Puppo</a>, 
<a href="/search/math?searchtype=author&query=Semplice%2C+M">Matteo Semplice</a>, 
<a href="/search/math?searchtype=author&query=Visconti%2C+G">Giuseppe Visconti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 10 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16184" title="Abstract">arXiv:2307.16184</a> (replaced) [<a href="/pdf/2307.16184" title="Download PDF">pdf</a>, <a href="/format/2307.16184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UnIVAL: Unified Model for Image, Video, Audio and Language Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shukor%2C+M">Mustafa Shukor</a>, 
<a href="/search/cs?searchtype=author&query=Dancette%2C+C">Corentin Dancette</a>, 
<a href="/search/cs?searchtype=author&query=Rame%2C+A">Alexandre Rame</a>, 
<a href="/search/cs?searchtype=author&query=Cord%2C+M">Matthieu Cord</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at TMLR 2023. 40 pages. Project page: <a href="https://unival-model.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16516" title="Abstract">arXiv:2307.16516</a> (replaced) [<a href="/pdf/2307.16516" title="Download PDF">pdf</a>, <a href="/format/2307.16516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpatialNet: Extensively Learning Spatial Information for Multichannel  Joint Speech Separation, Denoising and Dereverberation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Quan%2C+C">Changsheng Quan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaofei Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01273" title="Abstract">arXiv:2308.01273</a> (replaced) [<a href="/pdf/2308.01273" title="Download PDF">pdf</a>, <a href="/format/2308.01273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Attachments to SEO: Click Here to Learn More about Clickbait PDFs!
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stivala%2C+G">Giada Stivala</a>, 
<a href="/search/cs?searchtype=author&query=Abdelnabi%2C+S">Sahar Abdelnabi</a>, 
<a href="/search/cs?searchtype=author&query=Mengascini%2C+A">Andrea Mengascini</a>, 
<a href="/search/cs?searchtype=author&query=Graziano%2C+M">Mariano Graziano</a>, 
<a href="/search/cs?searchtype=author&query=Fritz%2C+M">Mario Fritz</a>, 
<a href="/search/cs?searchtype=author&query=Pellegrino%2C+G">Giancarlo Pellegrino</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Corrected symbols in Table 1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04119" title="Abstract">arXiv:2308.04119</a> (replaced) [<a href="/pdf/2308.04119" title="Download PDF">pdf</a>, <a href="/format/2308.04119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constructing Custom Thermodynamics Using Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Chen%2C+X">Xiaoli Chen</a>, 
<a href="/search/cond-mat?searchtype=author&query=Soh%2C+B+W">Beatrice W. Soh</a>, 
<a href="/search/cond-mat?searchtype=author&query=Ooi%2C+Z">Zi-En Ooi</a>, 
<a href="/search/cond-mat?searchtype=author&query=Vissol-Gaudin%2C+E">Eleonore Vissol-Gaudin</a>, 
<a href="/search/cond-mat?searchtype=author&query=Yu%2C+H">Haijun Yu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Novoselov%2C+K+S">Kostya S. Novoselov</a>, 
<a href="/search/cond-mat?searchtype=author&query=Hippalgaonkar%2C+K">Kedar Hippalgaonkar</a>, 
<a href="/search/cond-mat?searchtype=author&query=Li%2C+Q">Qianxiao Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fix figure visibility issue
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Soft Condensed Matter (cond-mat.soft)</span>; Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07798" title="Abstract">arXiv:2308.07798</a> (replaced) [<a href="/pdf/2308.07798" title="Download PDF">pdf</a>, <a href="/format/2308.07798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving optimization problems with local light shift encoding on Rydberg  quantum annealers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Goswami%2C+K">Kapil Goswami</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mukherjee%2C+R">Rick Mukherjee</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ott%2C+H">Herwig Ott</a>, 
<a href="/search/quant-ph?searchtype=author&query=Schmelcher%2C+P">Peter Schmelcher</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 6 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Quantum Gases (cond-mat.quant-gas); Computational Complexity (cs.CC); Atomic Physics (physics.atom-ph)

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07972" title="Abstract">arXiv:2308.07972</a> (replaced) [<a href="/pdf/2308.07972" title="Download PDF">pdf</a>, <a href="/ps/2308.07972" title="Download PostScript">ps</a>, <a href="/format/2308.07972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PKE-RRT: Efficient Multi-Goal Path Finding Algorithm Driven by  Multi-Task Learning Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuan Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08806" title="Abstract">arXiv:2308.08806</a> (replaced) [<a href="/pdf/2308.08806" title="Download PDF">pdf</a>, <a href="/format/2308.08806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-distillation Regularized Connectionist Temporal Classification Loss  for Text Recognition: A Simple Yet Effective Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziyin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+N">Ning Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+M">Minghui Liao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yongshuai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Cheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Min Wang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wei Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Ziyin Zhang and Ning Lu are co-first authors. Accepted by AAAI2024. Repo: <a href="https://github.com/zzyhlyoko/DCTC">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09007" title="Abstract">arXiv:2308.09007</a> (replaced) [<a href="/pdf/2308.09007" title="Download PDF">pdf</a>, <a href="/format/2308.09007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A locally based construction of analysis-suitable $G^1$ multi-patch  spline surfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Farahat%2C+A">Andrea Farahat</a>, 
<a href="/search/math?searchtype=author&query=Kapl%2C+M">Mario Kapl</a>, 
<a href="/search/math?searchtype=author&query=Kosma%C4%8D%2C+A">Alja&#x17e; Kosma&#x10d;</a>, 
<a href="/search/math?searchtype=author&query=Vitrih%2C+V">Vito Vitrih</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09552" title="Abstract">arXiv:2308.09552</a> (replaced) [<a href="/pdf/2308.09552" title="Download PDF">pdf</a>, <a href="/format/2308.09552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attesting Distributional Properties of Training Data for Machine  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duddu%2C+V">Vasisht Duddu</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Anudeep Das</a>, 
<a href="/search/cs?searchtype=author&query=Khayata%2C+N">Nora Khayata</a>, 
<a href="/search/cs?searchtype=author&query=Yalame%2C+H">Hossein Yalame</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+T">Thomas Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Asokan%2C+N">N. Asokan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11197" title="Abstract">arXiv:2308.11197</a> (replaced) [<a href="/pdf/2308.11197" title="Download PDF">pdf</a>, <a href="/ps/2308.11197" title="Download PostScript">ps</a>, <a href="/format/2308.11197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Generalizable Machine Learning Models in Speech, Language, and  Hearing Sciences: Estimating Sample Size and Reducing Overfitting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghasemzadeh%2C+H">Hamzeh Ghasemzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Hillman%2C+R+E">Robert E. Hillman</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+D+D">Daryush D. Mehta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at JSLHR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11998" title="Abstract">arXiv:2308.11998</a> (replaced) [<a href="/pdf/2308.11998" title="Download PDF">pdf</a>, <a href="/format/2308.11998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Economic Recommender Systems -- A Systematic Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Biasio%2C+A">Alvise De Biasio</a>, 
<a href="/search/cs?searchtype=author&query=Navarin%2C+N">Nicol&#xf2; Navarin</a>, 
<a href="/search/cs?searchtype=author&query=Jannach%2C+D">Dietmar Jannach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12807" title="Abstract">arXiv:2308.12807</a> (replaced) [<a href="/pdf/2308.12807" title="Download PDF">pdf</a>, <a href="/format/2308.12807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Denoising Particle-In-Cell Data via Smoothness-Increasing  Accuracy-Conserving Filters with Application to Bohm Speed Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Picklo%2C+M+J">Matthew J. Picklo</a>, 
<a href="/search/math?searchtype=author&query=Tang%2C+Q">Qi Tang</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Y">Yanzeng Zhang</a>, 
<a href="/search/math?searchtype=author&query=Ryan%2C+J+K">Jennifer K. Ryan</a>, 
<a href="/search/math?searchtype=author&query=Tang%2C+X">Xian-Zhu Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15216" title="Abstract">arXiv:2308.15216</a> (replaced) [<a href="/pdf/2308.15216" title="Download PDF">pdf</a>, <a href="/format/2308.15216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On-the-Fly Guidance Training for Medical Image Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yicheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shengxiang Ji</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+Y">Yuelin Xin</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kun Han</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaohui Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01108" title="Abstract">arXiv:2309.01108</a> (replaced) [<a href="/pdf/2309.01108" title="Download PDF">pdf</a>, <a href="/format/2309.01108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Acoustic-to-articulatory inversion for dysarthric speech: Are  pre-trained self-supervised representations favorable?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Maharana%2C+S+K">Sarthak Kumar Maharana</a>, 
<a href="/search/eess?searchtype=author&query=Adidam%2C+K+K">Krishna Kamal Adidam</a>, 
<a href="/search/eess?searchtype=author&query=Nandi%2C+S">Shoumik Nandi</a>, 
<a href="/search/eess?searchtype=author&query=Srivastava%2C+A">Ajitesh Srivastava</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02139" title="Abstract">arXiv:2309.02139</a> (replaced) [<a href="/pdf/2309.02139" title="Download PDF">pdf</a>, <a href="/format/2309.02139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Pre-Training Boosts Semantic Scene Segmentation on LiDAR  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Car%C3%B3s%2C+M">Mariona Car&#xf3;s</a>, 
<a href="/search/cs?searchtype=author&query=Just%2C+A">Ariadna Just</a>, 
<a href="/search/cs?searchtype=author&query=Segu%C3%AD%2C+S">Santi Segu&#xed;</a>, 
<a href="/search/cs?searchtype=author&query=Vitri%C3%A0%2C+J">Jordi Vitri&#xe0;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International conference Machine Vision Applications 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06978" title="Abstract">arXiv:2309.06978</a> (replaced) [<a href="/pdf/2309.06978" title="Download PDF">pdf</a>, <a href="/format/2309.06978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable JPEG: The Devil is in the Details
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reich%2C+C">Christoph Reich</a>, 
<a href="/search/cs?searchtype=author&query=Debnath%2C+B">Biplob Debnath</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+D">Deep Patel</a>, 
<a href="/search/cs?searchtype=author&query=Chakradhar%2C+S">Srimat Chakradhar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024. Project page: <a href="https://christophreich1996.github.io/differentiable_jpeg/">this https URL</a> WACV paper: <a href="https://openaccess.thecvf.com/content/WACV2024/html/Reich_Differentiable_JPEG_The_Devil_Is_in_the_Details_WACV_2024_paper.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08049" title="Abstract">arXiv:2309.08049</a> (replaced) [<a href="/pdf/2309.08049" title="Download PDF">pdf</a>, <a href="/format/2309.08049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VoicePAT: An Efficient Open-source Evaluation Toolkit for Voice Privacy  Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meyer%2C+S">Sarina Meyer</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+X">Xiaoxiao Miao</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+N+T">Ngoc Thang Vu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by OJSP-ICASSP 2024 <a href="https://ieeexplore.ieee.org/document/10365329">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12204" title="Abstract">arXiv:2309.12204</a> (replaced) [<a href="/pdf/2309.12204" title="Download PDF">pdf</a>, <a href="/format/2309.12204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PrNet: A Neural Network for Correcting Pseudoranges to Improve  Positioning with Android Raw GNSS Measurements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weng%2C+X">Xu Weng</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+K+V">Keck Voon Ling</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haochen Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15639" title="Abstract">arXiv:2309.15639</a> (replaced) [<a href="/pdf/2309.15639" title="Download PDF">pdf</a>, <a href="/format/2309.15639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Sharpness-Aware Optimization Through Variance Suppression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bingcong Li</a>, 
<a href="/search/cs?searchtype=author&query=Giannakis%2C+G+B">Georgios B. Giannakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17093" title="Abstract">arXiv:2309.17093</a> (replaced) [<a href="/pdf/2309.17093" title="Download PDF">pdf</a>, <a href="/format/2309.17093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prototype-based Aleatoric Uncertainty Quantification for Cross-modal  Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jingkuan Song</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Lianli Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaosu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H+T">Heng Tao Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00334" title="Abstract">arXiv:2310.00334</a> (replaced) [<a href="/pdf/2310.00334" title="Download PDF">pdf</a>, <a href="/ps/2310.00334" title="Download PostScript">ps</a>, <a href="/format/2310.00334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bounded Simultaneous Messages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bogdanov%2C+A">Andrej Bogdanov</a>, 
<a href="/search/cs?searchtype=author&query=Dinesh%2C+K">Krishnamoorthy Dinesh</a>, 
<a href="/search/cs?searchtype=author&query=Filmus%2C+Y">Yuval Filmus</a>, 
<a href="/search/cs?searchtype=author&query=Ishai%2C+Y">Yuval Ishai</a>, 
<a href="/search/cs?searchtype=author&query=Kaplan%2C+A">Avi Kaplan</a>, 
<a href="/search/cs?searchtype=author&query=Sekar%2C+S">Sruthi Sekar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This version has a modified variant of the succinct subset sum candidate from the original version of this paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01438" title="Abstract">arXiv:2310.01438</a> (replaced) [<a href="/pdf/2310.01438" title="Download PDF">pdf</a>, <a href="/format/2310.01438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building Flexible, Scalable, and Machine Learning-ready Multimodal  Oncology Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tripathi%2C+A">Aakash Tripathi</a>, 
<a href="/search/cs?searchtype=author&query=Waqas%2C+A">Asim Waqas</a>, 
<a href="/search/cs?searchtype=author&query=Venkatesan%2C+K">Kavya Venkatesan</a>, 
<a href="/search/cs?searchtype=author&query=Yilmaz%2C+Y">Yasin Yilmaz</a>, 
<a href="/search/cs?searchtype=author&query=Rasool%2C+G">Ghulam Rasool</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05086" title="Abstract">arXiv:2310.05086</a> (replaced) [<a href="/pdf/2310.05086" title="Download PDF">pdf</a>, <a href="/format/2310.05086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Generalizable Agents via Saliency-Guided Features Decorrelation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Sili Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yanchao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jifeng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Siyuan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hechang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yi Chang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bo Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05707" title="Abstract">arXiv:2310.05707</a> (replaced) [<a href="/pdf/2310.05707" title="Download PDF">pdf</a>, <a href="/format/2310.05707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guiding Language Model Reasoning with Planning Tokens
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Caccia%2C+L">Lucas Caccia</a>, 
<a href="/search/cs?searchtype=author&query=Ostapenko%2C+O">Oleksiy Ostapenko</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xingdi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Sordoni%2C+A">Alessandro Sordoni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05782" title="Abstract">arXiv:2310.05782</a> (replaced) [<a href="/pdf/2310.05782" title="Download PDF">pdf</a>, <a href="/format/2310.05782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aligning Language Models with Human Preferences via a Bayesian Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiashuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haozhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenjie Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09433" title="Abstract">arXiv:2310.09433</a> (replaced) [<a href="/pdf/2310.09433" title="Download PDF">pdf</a>, <a href="/format/2310.09433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effects of cavity nonlinearities and linear losses on silicon  microring-based reservoir computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Castro%2C+B+J+G">Bernard J. Giron Castro</a>, 
<a href="/search/physics?searchtype=author&query=Peucheret%2C+C">Christophe Peucheret</a>, 
<a href="/search/physics?searchtype=author&query=Zibar%2C+D">Darko Zibar</a>, 
<a href="/search/physics?searchtype=author&query=Da+Ros%2C+F">Francesco Da Ros</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 11 figures, submitted to Optics Express (reviewed version)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Emerging Technologies (cs.ET); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12794" title="Abstract">arXiv:2310.12794</a> (replaced) [<a href="/pdf/2310.12794" title="Download PDF">pdf</a>, <a href="/format/2310.12794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Structural Concepts Universal in Transformer Language Models?  Towards Interpretable Cross-Lingual Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+N">Ningyu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jingting Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Menghan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP 2023 (Camera-Ready)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13230" title="Abstract">arXiv:2310.13230</a> (replaced) [<a href="/pdf/2310.13230" title="Download PDF">pdf</a>, <a href="/format/2310.13230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Absolute Policy Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Weiye Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Feihan Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yifan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Rui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+T">Tianhao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Changliu Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submission to Journal of Machine Learning Research
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19958" title="Abstract">arXiv:2310.19958</a> (replaced) [<a href="/pdf/2310.19958" title="Download PDF">pdf</a>, <a href="/format/2310.19958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PriPrune: Quantifying and Preserving Privacy in Pruned Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+T">Tianyue Chu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mengwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Laoutaris%2C+N">Nikolaos Laoutaris</a>, 
<a href="/search/cs?searchtype=author&query=Markopoulou%2C+A">Athina Markopoulou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02389" title="Abstract">arXiv:2311.02389</a> (replaced) [<a href="/pdf/2311.02389" title="Download PDF">pdf</a>, <a href="/format/2311.02389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiplayer Homicidal Chauffeur Reach-Avoid Games: A Pursuit Enclosure  Function Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yan%2C+R">Rui Yan</a>, 
<a href="/search/eess?searchtype=author&query=Duan%2C+X">Xiaoming Duan</a>, 
<a href="/search/eess?searchtype=author&query=Zou%2C+R">Rui Zou</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+X">Xin He</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+Z">Zongying Shi</a>, 
<a href="/search/eess?searchtype=author&query=Bullo%2C+F">Francesco Bullo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Computer Science and Game Theory (cs.GT); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03080" title="Abstract">arXiv:2311.03080</a> (replaced) [<a href="/pdf/2311.03080" title="Download PDF">pdf</a>, <a href="/format/2311.03080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Isogeometric collocation for solving the biharmonic equation over planar  multi-patch domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kapl%2C+M">Mario Kapl</a>, 
<a href="/search/math?searchtype=author&query=Kosma%C4%8D%2C+A">Alja&#x17e; Kosma&#x10d;</a>, 
<a href="/search/math?searchtype=author&query=Vitrih%2C+V">Vito Vitrih</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04448" title="Abstract">arXiv:2311.04448</a> (replaced) [<a href="/pdf/2311.04448" title="Download PDF">pdf</a>, <a href="/format/2311.04448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-based Resource-Oriented Intention Inference for Static Resource Leak  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+Y">Yiling Lou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06000" title="Abstract">arXiv:2311.06000</a> (replaced) [<a href="/pdf/2311.06000" title="Download PDF">pdf</a>, <a href="/format/2311.06000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Keystroke Verification Challenge (KVC): Biometric and Fairness Benchmark  Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stragapede%2C+G">Giuseppe Stragapede</a>, 
<a href="/search/cs?searchtype=author&query=Vera-Rodriguez%2C+R">Ruben Vera-Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Tolosana%2C+R">Ruben Tolosana</a>, 
<a href="/search/cs?searchtype=author&query=Morales%2C+A">Aythami Morales</a>, 
<a href="/search/cs?searchtype=author&query=Damer%2C+N">Naser Damer</a>, 
<a href="/search/cs?searchtype=author&query=Fierrez%2C+J">Julian Fierrez</a>, 
<a href="/search/cs?searchtype=author&query=Ortega-Garcia%2C+J">Javier Ortega-Garcia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figure, 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07831" title="Abstract">arXiv:2311.07831</a> (replaced) [<a href="/pdf/2311.07831" title="Download PDF">pdf</a>, <a href="/ps/2311.07831" title="Download PostScript">ps</a>, <a href="/format/2311.07831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Covering Codes, List-Decodable Codes and Strong Singleton-Like Bounds in  the Sum-Rank Metric
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, minor errors corrected
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08386" title="Abstract">arXiv:2311.08386</a> (replaced) [<a href="/pdf/2311.08386" title="Download PDF">pdf</a>, <a href="/format/2311.08386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Capacity of Summation over a Symmetric Quantum Erasure MAC with  Replicated Inputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuhang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Jafar%2C+S+A">Syed A. Jafar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08655" title="Abstract">arXiv:2311.08655</a> (replaced) [<a href="/pdf/2311.08655" title="Download PDF">pdf</a>, <a href="/ps/2311.08655" title="Download PostScript">ps</a>, <a href="/format/2311.08655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Review of AlexNet for Medical Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wenhao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Junding Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuihua Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yudong Zhang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EAI Endorsed Transactions on e-Learning, 2023, 9
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08791" title="Abstract">arXiv:2311.08791</a> (replaced) [<a href="/pdf/2311.08791" title="Download PDF">pdf</a>, <a href="/format/2311.08791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Direct Approach for Solving Cloud Computing Task Assignment with Soft  Deadlines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+G">Guang Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuxiang Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages,8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09049" title="Abstract">arXiv:2311.09049</a> (replaced) [<a href="/pdf/2311.09049" title="Download PDF">pdf</a>, <a href="/format/2311.09049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapting Large Language Models by Integrating Collaborative Semantics  for Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Bowen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yupeng Hou</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hongyu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W+X">Wayne Xin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Ming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09759" title="Abstract">arXiv:2311.09759</a> (replaced) [<a href="/pdf/2311.09759" title="Download PDF">pdf</a>, <a href="/format/2311.09759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scene Text Image Super-resolution based on Text-conditional Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Noguchi%2C+C">Chihiro Noguchi</a>, 
<a href="/search/cs?searchtype=author&query=Fukuda%2C+S">Shun Fukuda</a>, 
<a href="/search/cs?searchtype=author&query=Yamanaka%2C+M">Masao Yamanaka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10459" title="Abstract">arXiv:2311.10459</a> (replaced) [<a href="/pdf/2311.10459" title="Download PDF">pdf</a>, <a href="/ps/2311.10459" title="Download PostScript">ps</a>, <a href="/format/2311.10459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hermitian Pseudospectral Shattering, Cholesky, Hermitian Eigenvalues,  and Density Functional Theory in Nearly Matrix Multiplication Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sobczyk%2C+A">Aleksandros Sobczyk</a>, 
<a href="/search/cs?searchtype=author&query=Mladenovi%C4%87%2C+M">Marko Mladenovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Luisier%2C+M">Mathieu Luisier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12420" title="Abstract">arXiv:2311.12420</a> (replaced) [<a href="/pdf/2311.12420" title="Download PDF">pdf</a>, <a href="/format/2311.12420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Far Have We Gone in Vulnerability Detection Using Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zeyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuchen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13613" title="Abstract">arXiv:2311.13613</a> (replaced) [<a href="/pdf/2311.13613" title="Download PDF">pdf</a>, <a href="/format/2311.13613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spanning Training Progress: Temporal Dual-Depth Scoring (TDDS) for  Enhanced Dataset Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Jiawei Du</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunsong Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weiying Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J+T">Joey Tianyi Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16502" title="Abstract">arXiv:2311.16502</a> (replaced) [<a href="/pdf/2311.16502" title="Download PDF">pdf</a>, <a href="/format/2311.16502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning  Benchmark for Expert AGI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+X">Xiang Yue</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+Y">Yuansheng Ni</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tianyu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruoqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Ge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Stevens%2C+S">Samuel Stevens</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Dongfu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+W">Weiming Ren</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuxuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+C">Cong Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Botao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+R">Ruibin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+R">Renliang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+M">Ming Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Boyuan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhenzhu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yibo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenhao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Huan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yu Su</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenhu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 117 pages, 99 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17774" title="Abstract">arXiv:2311.17774</a> (replaced) [<a href="/pdf/2311.17774" title="Download PDF">pdf</a>, <a href="/ps/2311.17774" title="Download PostScript">ps</a>, <a href="/format/2311.17774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enumeration of Minimum Weight Codewords of Pre-Transformed Polar Codes  by Tree Intersection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zunker%2C+A">Andreas Zunker</a>, 
<a href="/search/cs?searchtype=author&query=Geiselhart%2C+M">Marvin Geiselhart</a>, 
<a href="/search/cs?searchtype=author&query=Brink%2C+S+t">Stephan ten Brink</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, submitted to IEEE for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18083" title="Abstract">arXiv:2311.18083</a> (replaced) [<a href="/pdf/2311.18083" title="Download PDF">pdf</a>, <a href="/format/2311.18083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta Co-Training: Two Views are Better than One
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rothenberger%2C+J+C">Jay C. Rothenberger</a>, 
<a href="/search/cs?searchtype=author&query=Diochnos%2C+D+I">Dimitrios I. Diochnos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 14 figures, 10 tables, for implementation see <a href="https://github.com/JayRothenberger/Meta-Co-Training">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00200" title="Abstract">arXiv:2312.00200</a> (replaced) [<a href="/pdf/2312.00200" title="Download PDF">pdf</a>, <a href="/format/2312.00200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance Analysis of Multi-Angle QAOA for p &gt; 1
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gaidai%2C+I">Igor Gaidai</a>, 
<a href="/search/cs?searchtype=author&query=Herrman%2C+R">Rebekah Herrman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01479" title="Abstract">arXiv:2312.01479</a> (replaced) [<a href="/pdf/2312.01479" title="Download PDF">pdf</a>, <a href="/format/2312.01479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenVoice: Versatile Instant Voice Cloning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zengyi Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenliang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xumin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xin Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03824" title="Abstract">arXiv:2312.03824</a> (replaced) [<a href="/pdf/2312.03824" title="Download PDF">pdf</a>, <a href="/ps/2312.03824" title="Download PostScript">ps</a>, <a href="/format/2312.03824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> nbi: the Astronomer&#x27;s Package for Neural Posterior Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Zhang%2C+K">Keming Zhang</a>, 
<a href="/search/astro-ph?searchtype=author&query=Bloom%2C+J+S">Joshua S. Bloom</a>, 
<a href="/search/astro-ph?searchtype=author&query=van+der+Walt%2C+S">St&#xe9;fan van der Walt</a>, 
<a href="/search/astro-ph?searchtype=author&query=Hernitschek%2C+N">Nina Hernitschek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Update references. Accepted to NeurIPS 2023 Workshop on Deep Learning and Inverse Problems. Initially appeared at ICML 2023 Workshop on Machine Learning for Astrophysics. Code at <a href="https://github.com/kmzzhang/nbi">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04324" title="Abstract">arXiv:2312.04324</a> (replaced) [<a href="/pdf/2312.04324" title="Download PDF">pdf</a>, <a href="/format/2312.04324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiaPer: End-to-End Neural Diarization with Perceiver-Based Attractors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Landini%2C+F">Federico Landini</a>, 
<a href="/search/eess?searchtype=author&query=Diez%2C+M">Mireia Diez</a>, 
<a href="/search/eess?searchtype=author&query=Stafylakis%2C+T">Themos Stafylakis</a>, 
<a href="/search/eess?searchtype=author&query=Burget%2C+L">Luk&#xe1;&#x161; Burget</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05756" title="Abstract">arXiv:2312.05756</a> (replaced) [<a href="/pdf/2312.05756" title="Download PDF">pdf</a>, <a href="/ps/2312.05756" title="Download PostScript">ps</a>, <a href="/format/2312.05756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A quantitative fusion strategy of stock picking and timing based on  Particle Swarm Optimized-Back Propagation Neural Network and Multivariate  Gaussian-Hidden Markov Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huajian Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Longjian Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jiajian Liang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+W">Weinan Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures, 4 tables, 26 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06275" title="Abstract">arXiv:2312.06275</a> (replaced) [<a href="/pdf/2312.06275" title="Download PDF">pdf</a>, <a href="/format/2312.06275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DG-TTA: Out-of-domain medical image segmentation through Domain  Generalization and Test-Time Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weihsbach%2C+C">Christian Weihsbach</a>, 
<a href="/search/cs?searchtype=author&query=Kruse%2C+C+N">Christian N. Kruse</a>, 
<a href="/search/cs?searchtype=author&query=Bigalke%2C+A">Alexander Bigalke</a>, 
<a href="/search/cs?searchtype=author&query=Heinrich%2C+M+P">Mattias P. Heinrich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06585" title="Abstract">arXiv:2312.06585</a> (replaced) [<a href="/pdf/2312.06585" title="Download PDF">pdf</a>, <a href="/format/2312.06585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Human Data: Scaling Self-Training for Problem-Solving with  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Avi Singh</a>, 
<a href="/search/cs?searchtype=author&query=Co-Reyes%2C+J+D">John D. Co-Reyes</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+R">Rishabh Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Anand%2C+A">Ankesh Anand</a>, 
<a href="/search/cs?searchtype=author&query=Patil%2C+P">Piyush Patil</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+X">Xavier Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P+J">Peter J. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Harrison%2C+J">James Harrison</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaehoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kelvin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Parisi%2C+A">Aaron Parisi</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Abhishek Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Alemi%2C+A">Alex Alemi</a>, 
<a href="/search/cs?searchtype=author&query=Rizkowsky%2C+A">Alex Rizkowsky</a>, 
<a href="/search/cs?searchtype=author&query=Nova%2C+A">Azade Nova</a>, 
<a href="/search/cs?searchtype=author&query=Adlam%2C+B">Ben Adlam</a>, 
<a href="/search/cs?searchtype=author&query=Bohnet%2C+B">Bernd Bohnet</a>, 
<a href="/search/cs?searchtype=author&query=Elsayed%2C+G">Gamaleldin Elsayed</a>, 
<a href="/search/cs?searchtype=author&query=Sedghi%2C+H">Hanie Sedghi</a>, 
<a href="/search/cs?searchtype=author&query=Mordatch%2C+I">Igor Mordatch</a>, 
<a href="/search/cs?searchtype=author&query=Simpson%2C+I">Isabelle Simpson</a>, 
<a href="/search/cs?searchtype=author&query=Gur%2C+I">Izzeddin Gur</a>, 
<a href="/search/cs?searchtype=author&query=Snoek%2C+J">Jasper Snoek</a>, 
<a href="/search/cs?searchtype=author&query=Pennington%2C+J">Jeffrey Pennington</a>, 
<a href="/search/cs?searchtype=author&query=Hron%2C+J">Jiri Hron</a>, 
<a href="/search/cs?searchtype=author&query=Kenealy%2C+K">Kathleen Kenealy</a>, 
<a href="/search/cs?searchtype=author&query=Swersky%2C+K">Kevin Swersky</a>, 
<a href="/search/cs?searchtype=author&query=Mahajan%2C+K">Kshiteej Mahajan</a>, 
<a href="/search/cs?searchtype=author&query=Culp%2C+L">Laura Culp</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Lechao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Bileschi%2C+M+L">Maxwell L. Bileschi</a>, 
<a href="/search/cs?searchtype=author&query=Constant%2C+N">Noah Constant</a>, 
<a href="/search/cs?searchtype=author&query=Novak%2C+R">Roman Novak</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Rosanne Liu</a>, 
<a href="/search/cs?searchtype=author&query=Warkentin%2C+T">Tris Warkentin</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yundi Qian</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+Y">Yamini Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Dyer%2C+E">Ethan Dyer</a>, 
<a href="/search/cs?searchtype=author&query=Neyshabur%2C+B">Behnam Neyshabur</a>, 
<a href="/search/cs?searchtype=author&query=Sohl-Dickstein%2C+J">Jascha Sohl-Dickstein</a>, 
<a href="/search/cs?searchtype=author&query=Fiedel%2C+N">Noah Fiedel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First three authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06709" title="Abstract">arXiv:2312.06709</a> (replaced) [<a href="/pdf/2312.06709" title="Download PDF">pdf</a>, <a href="/format/2312.06709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AM-RADIO: Agglomerative Model -- Reduce All Domains Into One
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ranzinger%2C+M">Mike Ranzinger</a>, 
<a href="/search/cs?searchtype=author&query=Heinrich%2C+G">Greg Heinrich</a>, 
<a href="/search/cs?searchtype=author&query=Kautz%2C+J">Jan Kautz</a>, 
<a href="/search/cs?searchtype=author&query=Molchanov%2C+P">Pavlo Molchanov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Version 2: Added more acknowledgements and updated table 7 with more recent results. Ensured that the link in the abstract to our code is working properly
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06914" title="Abstract">arXiv:2312.06914</a> (replaced) [<a href="/e-print/2312.06914" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Novel Object Recognition and Spontaneous Location Recognition  Machine Learning Analysis Techniques in Alzheimer&#x27;s Mice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bafana%2C+S">Soham Bafana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Aspects of the paper contain errors, and data in the pipeline must be vetted one more time. More testing is necessary
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07199" title="Abstract">arXiv:2312.07199</a> (replaced) [<a href="/pdf/2312.07199" title="Download PDF">pdf</a>, <a href="/format/2312.07199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeasFire as a Multivariate Earth System Datacube for Wildfire Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karasante%2C+I">Ilektra Karasante</a>, 
<a href="/search/cs?searchtype=author&query=Alonso%2C+L">Lazaro Alonso</a>, 
<a href="/search/cs?searchtype=author&query=Prapas%2C+I">Ioannis Prapas</a>, 
<a href="/search/cs?searchtype=author&query=Ahuja%2C+A">Akanksha Ahuja</a>, 
<a href="/search/cs?searchtype=author&query=Carvalhais%2C+N">Nuno Carvalhais</a>, 
<a href="/search/cs?searchtype=author&query=Papoutsis%2C+I">Ioannis Papoutsis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 9 figures, and 5 tables. Typos corrected
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07661" title="Abstract">arXiv:2312.07661</a> (replaced) [<a href="/pdf/2312.07661" title="Download PDF">pdf</a>, <a href="/format/2312.07661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIP as RNN: Segment Countless Visual Concepts without Training Endeavor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shuyang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Runjia Li</a>, 
<a href="/search/cs?searchtype=author&query=Torr%2C+P">Philip Torr</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+X">Xiuye Gu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Siyang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://torrvision.com/clip_as_rnn/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07884" title="Abstract">arXiv:2312.07884</a> (replaced) [<a href="/pdf/2312.07884" title="Download PDF">pdf</a>, <a href="/format/2312.07884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mutual-Learning Knowledge Distillation for Nighttime UAV Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yufeng Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08286" title="Abstract">arXiv:2312.08286</a> (replaced) [<a href="/pdf/2312.08286" title="Download PDF">pdf</a>, <a href="/format/2312.08286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolutionary Games on Infinite Strategy Sets: Convergence to Nash  Equilibria via Dissipativity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Anderson%2C+B+G">Brendon G. Anderson</a>, 
<a href="/search/math?searchtype=author&query=Sojoudi%2C+S">Somayeh Sojoudi</a>, 
<a href="/search/math?searchtype=author&query=Arcak%2C+M">Murat Arcak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Computer Science and Game Theory (cs.GT); Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08806" title="Abstract">arXiv:2312.08806</a> (replaced) [<a href="/pdf/2312.08806" title="Download PDF">pdf</a>, <a href="/format/2312.08806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Google Tag Manager: Hidden Data Leaks and its Potential Violations under  EU Data Protection Law
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mertens%2C+G">Gilles Mertens</a>, 
<a href="/search/cs?searchtype=author&query=Bielova%2C+N">Nataliia Bielova</a>, 
<a href="/search/cs?searchtype=author&query=Roca%2C+V">Vincent Roca</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+C">Cristiana Santos</a>, 
<a href="/search/cs?searchtype=author&query=Toth%2C+M">Michael Toth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08914" title="Abstract">arXiv:2312.08914</a> (replaced) [<a href="/pdf/2312.08914" title="Download PDF">pdf</a>, <a href="/format/2312.08914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CogAgent: A Visual Language Model for GUI Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+W">Wenyi Hong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weihan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Q">Qingsong Lv</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiazheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenmeng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Junhui Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juanzi Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuxiao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Ming Ding</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jie Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09854" title="Abstract">arXiv:2312.09854</a> (replaced) [<a href="/pdf/2312.09854" title="Download PDF">pdf</a>, <a href="/format/2312.09854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Q-Segment: Segmenting Images In-Sensor for Vessel-Based Medical  Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bonazzi%2C+P">Pietro Bonazzi</a>, 
<a href="/search/eess?searchtype=author&query=Moosmann%2C+J">Julian Moosmann</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yawei Li</a>, 
<a href="/search/eess?searchtype=author&query=Bian%2C+S">Sizhen Bian</a>, 
<a href="/search/eess?searchtype=author&query=Magno%2C+M">Michele Magno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09901" title="Abstract">arXiv:2312.09901</a> (replaced) [<a href="/pdf/2312.09901" title="Download PDF">pdf</a>, <a href="/format/2312.09901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporally and Distributionally Robust Optimization for Cold-start  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xinyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jujia Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fuli Feng</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10283" title="Abstract">arXiv:2312.10283</a> (replaced) [<a href="/pdf/2312.10283" title="Download PDF">pdf</a>, <a href="/format/2312.10283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cubic-quartic regularization models for solving polynomial subproblems  in third-order tensor methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhu%2C+W">Wenqi Zhu</a>, 
<a href="/search/math?searchtype=author&query=Cartis%2C+C">Coralia Cartis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10303" title="Abstract">arXiv:2312.10303</a> (replaced) [<a href="/pdf/2312.10303" title="Download PDF">pdf</a>, <a href="/ps/2312.10303" title="Download PostScript">ps</a>, <a href="/format/2312.10303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Restless Multi-Armed Bandits with Long-Term Fairness Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shufan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+G">Guojun Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jian Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10794" title="Abstract">arXiv:2312.10794</a> (replaced) [<a href="/pdf/2312.10794" title="Download PDF">pdf</a>, <a href="/format/2312.10794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A mathematical perspective on Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geshkovski%2C+B">Borjan Geshkovski</a>, 
<a href="/search/cs?searchtype=author&query=Letrouit%2C+C">Cyril Letrouit</a>, 
<a href="/search/cs?searchtype=author&query=Polyanskiy%2C+Y">Yury Polyanskiy</a>, 
<a href="/search/cs?searchtype=author&query=Rigollet%2C+P">Philippe Rigollet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Analysis of PDEs (math.AP); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11146" title="Abstract">arXiv:2312.11146</a> (replaced) [<a href="/pdf/2312.11146" title="Download PDF">pdf</a>, <a href="/format/2312.11146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OsmLocator: locating overlapping scatter marks with a non-training  generative perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yuming Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Pizurica%2C+A">Aleksandra Pizurica</a>, 
<a href="/search/cs?searchtype=author&query=Ming%2C+Q">Qi Ming</a>, 
<a href="/search/cs?searchtype=author&query=Nadisic%2C+N">Nicolas Nadisic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11274" title="Abstract">arXiv:2312.11274</a> (replaced) [<a href="/pdf/2312.11274" title="Download PDF">pdf</a>, <a href="/format/2312.11274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Student Learning with Hybrid Human-AI Tutoring: A Three-Study  Quasi-Experimental Investigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thomas%2C+D+R">Danielle R. Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jionghao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Gatz%2C+E">Erin Gatz</a>, 
<a href="/search/cs?searchtype=author&query=Gurung%2C+A">Ashish Gurung</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Shivang Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Norberg%2C+K">Kole Norberg</a>, 
<a href="/search/cs?searchtype=author&query=Fancsali%2C+S+E">Stephen E. Fancsali</a>, 
<a href="/search/cs?searchtype=author&query=Aleven%2C+V">Vincent Aleven</a>, 
<a href="/search/cs?searchtype=author&query=Branstetter%2C+L">Lee Branstetter</a>, 
<a href="/search/cs?searchtype=author&query=Brunskill%2C+E">Emma Brunskill</a>, 
<a href="/search/cs?searchtype=author&query=Koedinger%2C+K+R">Kenneth R. Koedinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11434" title="Abstract">arXiv:2312.11434</a> (replaced) [<a href="/pdf/2312.11434" title="Download PDF">pdf</a>, <a href="/ps/2312.11434" title="Download PostScript">ps</a>, <a href="/format/2312.11434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Factored Online Planning in Many-Agent POMDPs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Galesloot%2C+M+F+L">Maris F.L. Galesloot</a>, 
<a href="/search/cs?searchtype=author&query=Sim%C3%A3o%2C+T+D">Thiago D. Sim&#xe3;o</a>, 
<a href="/search/cs?searchtype=author&query=Junges%2C+S">Sebastian Junges</a>, 
<a href="/search/cs?searchtype=author&query=Jansen%2C+N">Nils Jansen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version (includes the Appendix) of the paper accepted at AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11537" title="Abstract">arXiv:2312.11537</a> (replaced) [<a href="/pdf/2312.11537" title="Download PDF">pdf</a>, <a href="/format/2312.11537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FastSR-NeRF: Improving NeRF Efficiency on Consumer Devices with A Simple  Super-Resolution Pipeline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chien-Yu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Q">Qichen Fu</a>, 
<a href="/search/cs?searchtype=author&query=Merth%2C+T">Thomas Merth</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Karren Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ranjan%2C+A">Anurag Ranjan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11706" title="Abstract">arXiv:2312.11706</a> (replaced) [<a href="/pdf/2312.11706" title="Download PDF">pdf</a>, <a href="/format/2312.11706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Some Fibonacci-Related Sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cloitre%2C+B">Benoit Cloitre</a>, 
<a href="/search/math?searchtype=author&query=Shallit%2C+J">Jeffrey Shallit</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12598" title="Abstract">arXiv:2312.12598</a> (replaced) [<a href="/pdf/2312.12598" title="Download PDF">pdf</a>, <a href="/format/2312.12598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Case Study on Test Case Construction with Large Language Models:  Unveiling Practical Insights and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Lima+Junior%2C+R+F">Roberto Francisco de Lima Junior</a>, 
<a href="/search/cs?searchtype=author&query=de+Barros+Presta%2C+L+F+P">Luiz Fernando Paes de Barros Presta</a>, 
<a href="/search/cs?searchtype=author&query=Borborema%2C+L+S">Lucca Santos Borborema</a>, 
<a href="/search/cs?searchtype=author&query=da+Silva%2C+V+N">Vanderson Nogueira da Silva</a>, 
<a href="/search/cs?searchtype=author&query=de+Melo+Dahia%2C+M+L">Marcio Leal de Melo Dahia</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+A+C+S+e">Anderson Carlos Sousa e Santos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12705" title="Abstract">arXiv:2312.12705</a> (replaced) [<a href="/pdf/2312.12705" title="Download PDF">pdf</a>, <a href="/format/2312.12705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Distributed Training on Frontier for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dash%2C+S">Sajal Dash</a>, 
<a href="/search/cs?searchtype=author&query=Lyngaas%2C+I">Isaac Lyngaas</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Junqi Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Egele%2C+R">Romain Egele</a>, 
<a href="/search/cs?searchtype=author&query=Cong%2C+G">Guojing Cong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Feiyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Balaprakash%2C+P">Prasanna Balaprakash</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Edited the abstract to better communicate the scope of the work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12811" title="Abstract">arXiv:2312.12811</a> (replaced) [<a href="/pdf/2312.12811" title="Download PDF">pdf</a>, <a href="/format/2312.12811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph-Based Generalization of Galam Model: Convergence Time and  Influential Nodes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sining Li</a>, 
<a href="/search/cs?searchtype=author&query=Zehmakan%2C+A+N">Ahad N. Zehmakan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Change the color of one paragraph on page 5
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Physics 2023, 5, 1094-1108
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12865" title="Abstract">arXiv:2312.12865</a> (replaced) [<a href="/pdf/2312.12865" title="Download PDF">pdf</a>, <a href="/format/2312.12865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RadEdit: stress-testing biomedical vision models via diffusion image  editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez-Garc%C3%ADa%2C+F">Fernando P&#xe9;rez-Garc&#xed;a</a>, 
<a href="/search/cs?searchtype=author&query=Bond-Taylor%2C+S">Sam Bond-Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Sanchez%2C+P+P">Pedro P. Sanchez</a>, 
<a href="/search/cs?searchtype=author&query=van+Breugel%2C+B">Boris van Breugel</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+D+C">Daniel C. Castro</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+H">Harshita Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Salvatelli%2C+V">Valentina Salvatelli</a>, 
<a href="/search/cs?searchtype=author&query=Wetscherek%2C+M+T+A">Maria T. A. Wetscherek</a>, 
<a href="/search/cs?searchtype=author&query=Richardson%2C+H">Hannah Richardson</a>, 
<a href="/search/cs?searchtype=author&query=Lungren%2C+M+P">Matthew P. Lungren</a>, 
<a href="/search/cs?searchtype=author&query=Nori%2C+A">Aditya Nori</a>, 
<a href="/search/cs?searchtype=author&query=Alvarez-Valle%2C+J">Javier Alvarez-Valle</a>, 
<a href="/search/cs?searchtype=author&query=Oktay%2C+O">Ozan Oktay</a>, 
<a href="/search/cs?searchtype=author&query=Ilse%2C+M">Maximilian Ilse</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12921" title="Abstract">arXiv:2312.12921</a> (replaced) [<a href="/pdf/2312.12921" title="Download PDF">pdf</a>, <a href="/format/2312.12921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoupling Judgment and Decision Making: A Tale of Two Tails
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oral%2C+B">Ba&#x15f;ak Oral</a>, 
<a href="/search/cs?searchtype=author&query=Dragicevic%2C+P">Pierre Dragicevic</a>, 
<a href="/search/cs?searchtype=author&query=Telea%2C+A">Alexandru Telea</a>, 
<a href="/search/cs?searchtype=author&query=Dimara%2C+E">Evanthia Dimara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13016" title="Abstract">arXiv:2312.13016</a> (replaced) [<a href="/pdf/2312.13016" title="Download PDF">pdf</a>, <a href="/format/2312.13016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffPortrait3D: Controllable Diffusion for Zero-Shot Portrait View  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuming Gu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">You Xie</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongyi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+G">Guoxian Song</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yichun Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+D">Di Chang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Linjie Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13091" title="Abstract">arXiv:2312.13091</a> (replaced) [<a href="/pdf/2312.13091" title="Download PDF">pdf</a>, <a href="/format/2312.13091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MoSAR: Monocular Semi-Supervised Model for Avatar Reconstruction using  Differentiable Shading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dib%2C+A">Abdallah Dib</a>, 
<a href="/search/cs?searchtype=author&query=Hafemann%2C+L+G">Luiz Gustavo Hafemann</a>, 
<a href="/search/cs?searchtype=author&query=Got%2C+E">Emeline Got</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+T">Trevor Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Fadaeinejad%2C+A">Amin Fadaeinejad</a>, 
<a href="/search/cs?searchtype=author&query=Cruz%2C+R+M+O">Rafael M. O. Cruz</a>, 
<a href="/search/cs?searchtype=author&query=Carbonneau%2C+M">Marc-Andre Carbonneau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://ubisoft-laforge.github.io/character/mosar/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13434" title="Abstract">arXiv:2312.13434</a> (replaced) [<a href="/pdf/2312.13434" title="Download PDF">pdf</a>, <a href="/format/2312.13434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-1-to-3: Domain-level Zero-shot Cognitive Diagnosis via One Batch of  Early-bird Students towards Three Diagnostic Objectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Weibo Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+L">Linan Yue</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+H">Haoyang Bi</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+F">Fangzhou Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuanjing He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13545" title="Abstract">arXiv:2312.13545</a> (replaced) [<a href="/pdf/2312.13545" title="Download PDF">pdf</a>, <a href="/ps/2312.13545" title="Download PostScript">ps</a>, <a href="/format/2312.13545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Developing Interactive Tourism Planning: A Dialogue Robot System Powered  by a Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoshikawa%2C+K">Katsumasa Yoshikawa</a>, 
<a href="/search/cs?searchtype=author&query=Yamazaki%2C+T">Takato Yamazaki</a>, 
<a href="/search/cs?searchtype=author&query=Ohagi%2C+M">Masaya Ohagi</a>, 
<a href="/search/cs?searchtype=author&query=Mizumoto%2C+T">Tomoya Mizumoto</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+K">Keiya Sato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is part of the proceedings of the Dialogue Robot Competition 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13646" title="Abstract">arXiv:2312.13646</a> (replaced) [<a href="/pdf/2312.13646" title="Download PDF">pdf</a>, <a href="/format/2312.13646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly Supervised Semantic Segmentation for Driving Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dongseob Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seungho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choe%2C+J">Junsuk Choe</a>, 
<a href="/search/cs?searchtype=author&query=Shim%2C+H">Hyunjung Shim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 accepted. First two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13649" title="Abstract">arXiv:2312.13649</a> (replaced) [<a href="/pdf/2312.13649" title="Download PDF">pdf</a>, <a href="/format/2312.13649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Smart Highway to Babel: the coexistence of different generations of  Intelligent Transport Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amador%2C+O">Oscar Amador</a>, 
<a href="/search/cs?searchtype=author&query=Soto%2C+I">Ignacio Soto</a>, 
<a href="/search/cs?searchtype=author&query=Calderon%2C+M">Maria Calderon</a>, 
<a href="/search/cs?searchtype=author&query=Urue%C3%B1a%2C+M">Manuel Urue&#xf1;a</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13695" title="Abstract">arXiv:2312.13695</a> (replaced) [<a href="/pdf/2312.13695" title="Download PDF">pdf</a>, <a href="/format/2312.13695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unexplored Frontiers: A Review of Empirical Studies of Exploratory  Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Medlar%2C+A">Alan Medlar</a>, 
<a href="/search/cs?searchtype=author&query=Kotkov%2C+D">Denis Kotkov</a>, 
<a href="/search/cs?searchtype=author&query=Glowacka%2C+D">Dorota Glowacka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Digital Libraries (cs.DL); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13729" title="Abstract">arXiv:2312.13729</a> (replaced) [<a href="/pdf/2312.13729" title="Download PDF">pdf</a>, <a href="/format/2312.13729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Splatting with NeRF-based Color and Opacity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malarz%2C+D">Dawid Malarz</a>, 
<a href="/search/cs?searchtype=author&query=Smolak%2C+W">Weronika Smolak</a>, 
<a href="/search/cs?searchtype=author&query=Tabor%2C+J">Jacek Tabor</a>, 
<a href="/search/cs?searchtype=author&query=Tadeja%2C+S">S&#x142;awomir Tadeja</a>, 
<a href="/search/cs?searchtype=author&query=Spurek%2C+P">Przemys&#x142;aw Spurek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13771" title="Abstract">arXiv:2312.13771</a> (replaced) [<a href="/pdf/2312.13771" title="Download PDF">pdf</a>, <a href="/format/2312.13771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AppAgent: Multimodal Agents as Smartphone Users
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaxuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yucheng Han</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zebiao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+B">Bin Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Gang Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page is <a href="https://appagent-official.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13913" title="Abstract">arXiv:2312.13913</a> (replaced) [<a href="/pdf/2312.13913" title="Download PDF">pdf</a>, <a href="/format/2312.13913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Paint3D: Paint Anything 3D with Lighting-Less Texture Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xianfang Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zhongqi Qi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zibo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhibin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+B">Bin Fu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Gang Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Website: <a href="https://github.com/OpenTexture/Paint3D">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13936" title="Abstract">arXiv:2312.13936</a> (replaced) [<a href="/pdf/2312.13936" title="Download PDF">pdf</a>, <a href="/format/2312.13936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GVE-Leiden: Fast Leiden Algorithm for Community Detection in Shared  Memory Setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sahu%2C+S">Subhajit Sahu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures, 1 table. arXiv admin note: substantial text overlap with <a href="/abs/2312.04876">arXiv:2312.04876</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13970" title="Abstract">arXiv:2312.13970</a> (replaced) [<a href="/pdf/2312.13970" title="Download PDF">pdf</a>, <a href="/format/2312.13970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Partial Optimal Transport: Revising the Infeasibility of Sinkhorn and  Efficient Gradient Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+A+D">Anh Duc Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+D">Tuan Dung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q+M">Quang Minh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H+H">Hoang H. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+L+M">Lam M. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Toh%2C+K">Kim-Chuan Toh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13975" title="Abstract">arXiv:2312.13975</a> (replaced) [<a href="/pdf/2312.13975" title="Download PDF">pdf</a>, <a href="/format/2312.13975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Joint Communication and Computation Design for Semantic Wireless  Communication with Probability Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhouxiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhaohui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+X">Xu Gan</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+Q">Quoc-Viet Pham</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chongwen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoyang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2310.00015">arXiv:2310.00015</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13977" title="Abstract">arXiv:2312.13977</a> (replaced) [<a href="/pdf/2312.13977" title="Download PDF">pdf</a>, <a href="/format/2312.13977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuSurf: On-Surface Priors for Neural Surface Reconstruction from Sparse  Input Views
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Han Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yulun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Junsheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+G">Ge Gao</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+M">Ming Gu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu-Shen Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024. Project page: <a href="https://alvin528.github.io/NeuSurf/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14059" title="Abstract">arXiv:2312.14059</a> (replaced) [<a href="/pdf/2312.14059" title="Download PDF">pdf</a>, <a href="/format/2312.14059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Protection of Vulnerable Road Users using Hybrid Vehicular Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amador%2C+O">Oscar Amador</a>, 
<a href="/search/cs?searchtype=author&query=Ronel%C3%B6v%2C+E">Erik Ronel&#xf6;v</a>, 
<a href="/search/cs?searchtype=author&query=Boustedt%2C+K">Katarina Boustedt</a>, 
<a href="/search/cs?searchtype=author&query=Blidkvist%2C+J">Jesper Blidkvist</a>, 
<a href="/search/cs?searchtype=author&query=Vinel%2C+A">Alexey Vinel</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2022 IEEE International Conference on Vehicular Electronics and
  Safety (ICVES)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item310">Cross-lists</a></li>
<li><a href="#item350">Replacements</a></li>
</ul>
<small>[ total of 510 entries:  <b>1-510</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2312">2312</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
