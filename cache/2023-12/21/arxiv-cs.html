<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Tue 19 Dec 23  to  Wed 20 Dec 23, announced Thu, 21 Dec 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item338">Cross-lists</a></li>
<li><a href="#item390">Replacements</a></li>
</ul>
<small>[ total of 630 entries:  <b>1-630</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Thu, 21 Dec 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12439" title="Abstract">arXiv:2312.12439</a> [<a href="/pdf/2312.12439" title="Download PDF">pdf</a>, <a href="/format/2312.12439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-pixel 3D imaging based on fusion temporal data of single photon  detector and millimeter-wave radar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+T">Tingqin Lai</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaolin Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xinyi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+L">Lianye Liao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xuelin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+P">Ping Su</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shihai Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Chinese Optics Letters, and comments are welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Optics (physics.optics)

</div>
<p class="mathjax">Recently, there has been increased attention towards 3D imaging using
single-pixel single-photon detection (also known as temporal data) due to its
potential advantages in terms of cost and power efficiency. However, to
eliminate the symmetry blur in the reconstructed images, a fixed background is
required. This paper proposes a fusion-data-based 3D imaging method that
utilizes a single-pixel single-photon detector and a millimeter-wave radar to
capture temporal histograms of a scene from multiple perspectives.
Subsequently, the 3D information can be reconstructed from the one-dimensional
fusion temporal data by using Artificial Neural Network (ANN). Both the
simulation and experimental results demonstrate that our fusion method
effectively eliminates symmetry blur and improves the quality of the
reconstructed images.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12441" title="Abstract">arXiv:2312.12441</a> [<a href="/pdf/2312.12441" title="Download PDF">pdf</a>, <a href="/format/2312.12441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffSpectralNet : Unveiling the Potential of Diffusion Models for  Hyperspectral Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sigger%2C+N">Neetu Sigger</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+T">Tuan Thanh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Tozzi%2C+G">Gianluca Tozzi</a>, 
<a href="/search/cs?searchtype=author&query=Vien%2C+Q">Quoc-Tuan Vien</a>, 
<a href="/search/cs?searchtype=author&query=Van+Nguyen%2C+S">Sinh Van Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Hyperspectral images (HSI) have become popular for analysing remotely sensed
images in multiple domain like agriculture, medical. However, existing models
struggle with complex relationships and characteristics of spectral-spatial
data due to the multi-band nature and data redundancy of hyperspectral data. To
address this limitation, we propose a new network called DiffSpectralNet, which
combines diffusion and transformer techniques. Our approach involves a two-step
process. First, we use an unsupervised learning framework based on the
diffusion model to extract both high-level and low-level spectral-spatial
features. The diffusion method is capable of extracting diverse and meaningful
spectral-spatial features, leading to improvement in HSI classification. Then,
we employ a pretrained denoising U-Net to extract intermediate hierarchical
features for classification. Finally, we use a supervised transformer-based
classifier to perform the HSI classification. Through comprehensive experiments
on HSI datasets, we evaluate the classification performance of DiffSpectralNet.
The results demonstrate that our framework significantly outperforms existing
approaches, achieving state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12442" title="Abstract">arXiv:2312.12442</a> [<a href="/pdf/2312.12442" title="Download PDF">pdf</a>, <a href="/ps/2312.12442" title="Download PostScript">ps</a>, <a href="/format/2312.12442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Classification System for Breast Cancer Specimen Report  (HCSBC) -- an end-to-end model for characterizing severity and diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santos%2C+T">Thiago Santos</a>, 
<a href="/search/cs?searchtype=author&query=Kamath%2C+H">Harish Kamath</a>, 
<a href="/search/cs?searchtype=author&query=McAdams%2C+C+R">Christopher R. McAdams</a>, 
<a href="/search/cs?searchtype=author&query=Newell%2C+M+S">Mary S. Newell</a>, 
<a href="/search/cs?searchtype=author&query=Mosunjac%2C+M">Marina Mosunjac</a>, 
<a href="/search/cs?searchtype=author&query=Oprea-Ilies%2C+G">Gabriela Oprea-Ilies</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+G">Geoffrey Smith</a>, 
<a href="/search/cs?searchtype=author&query=Lehman%2C+C">Constance Lehman</a>, 
<a href="/search/cs?searchtype=author&query=Gichoya%2C+J">Judy Gichoya</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+I">Imon Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Trivedi%2C+H">Hari Trivedi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Automated classification of cancer pathology reports can extract information
from unstructured reports and categorize each report into structured diagnosis
and severity categories. Thus, such system can reduce the burden for populating
tumor registries, help registration for clinical trial as well as developing
large dataset for deep learning model development using true pathologic ground
truth. However, the content of breast pathology reports can be difficult for
categorize due to the high linguistic variability in content and wide variety
of potential diagnoses &gt;50. Existing NLP models are primarily focused on
developing classifier for primary breast cancer types (e.g. IDC, DCIS, ILC) and
tumor characteristics, and ignore the rare diagnosis of cancer subtypes. We
then developed a hierarchical hybrid transformer-based pipeline (59 labels) -
Hierarchical Classification System for Breast Cancer Specimen Report (HCSBC),
which utilizes the potential of the transformer context-preserving NLP
technique and compared our model to several state of the art ML and DL models.
We trained the model on the EUH data and evaluated our model's performance on
two external datasets - MGH and Mayo Clinic. We publicly release the code and a
live application under Huggingface spaces repository
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12444" title="Abstract">arXiv:2312.12444</a> [<a href="/pdf/2312.12444" title="Download PDF">pdf</a>, <a href="/format/2312.12444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Makes Pre-Trained Visual Representations Successful for Robust  Manipulation?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Burns%2C+K">Kaylee Burns</a>, 
<a href="/search/cs?searchtype=author&query=Witzel%2C+Z">Zach Witzel</a>, 
<a href="/search/cs?searchtype=author&query=Hamid%2C+J+I">Jubayer Ibn Hamid</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tianhe Yu</a>, 
<a href="/search/cs?searchtype=author&query=Finn%2C+C">Chelsea Finn</a>, 
<a href="/search/cs?searchtype=author&query=Hausman%2C+K">Karol Hausman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Inspired by the success of transfer learning in computer vision, roboticists
have investigated visual pre-training as a means to improve the learning
efficiency and generalization ability of policies learned from pixels. To that
end, past work has favored large object interaction datasets, such as
first-person videos of humans completing diverse tasks, in pursuit of
manipulation-relevant features. Although this approach improves the efficiency
of policy learning, it remains unclear how reliable these representations are
in the presence of distribution shifts that arise commonly in robotic
applications. Surprisingly, we find that visual representations designed for
manipulation and control tasks do not necessarily generalize under subtle
changes in lighting and scene texture or the introduction of distractor
objects. To understand what properties do lead to robust representations, we
compare the performance of 15 pre-trained vision models under different visual
appearances. We find that emergent segmentation ability is a strong predictor
of out-of-distribution generalization among ViT models. The rank order induced
by this metric is more predictive than metrics that have previously guided
generalization research within computer vision and machine learning, such as
downstream ImageNet accuracy, in-domain accuracy, or shape-bias as evaluated by
cue-conflict performance. We test this finding extensively on a suite of
distribution shifts in ten tasks across two simulated manipulation
environments. On the ALOHA setup, segmentation score predicts real-world
performance after offline training with 50 demonstrations.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12445" title="Abstract">arXiv:2312.12445</a> [<a href="/pdf/2312.12445" title="Download PDF">pdf</a>, <a href="/format/2312.12445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparison of two efficient numerical techniques based on Chelyshkov  polynomial for solving stochastic It&#xf4;-Volterra integral equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gupta%2C+R">Reema Gupta</a>, 
<a href="/search/math?searchtype=author&query=Ray%2C+S+S">S. Saha Ray</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this study, two reliable approaches to solving the nonlinear stochastic
It\^o-Volterra integral equation are provided. These equations have been
evaluated using the orthonormal Chelyshkov spectral collocation technique and
the orthonormal Chelyshkov spectral Galerkin method. The techniques presented
here transform this problem into a collection of nonlinear algebraic equations
that have been numerically solved using the Newton method. Also, the
convergence analysis has been studied for both approaches. Two illustrative
examples have been provided to show the efficacy, plausibility, proficiency,
and applicability of the current approaches.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12450" title="Abstract">arXiv:2312.12450</a> [<a href="/pdf/2312.12450" title="Download PDF">pdf</a>, <a href="/format/2312.12450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can It Edit? Evaluating the Ability of Large Language Models to Follow  Code Editing Instructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cassano%2C+F">Federico Cassano</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Luisa Li</a>, 
<a href="/search/cs?searchtype=author&query=Sethi%2C+A">Akul Sethi</a>, 
<a href="/search/cs?searchtype=author&query=Shinn%2C+N">Noah Shinn</a>, 
<a href="/search/cs?searchtype=author&query=Brennan-Jones%2C+A">Abby Brennan-Jones</a>, 
<a href="/search/cs?searchtype=author&query=Lozhkov%2C+A">Anton Lozhkov</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+C">Carolyn Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Guha%2C+A">Arjun Guha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Programming Languages (cs.PL)

</div>
<p class="mathjax">A significant amount of research is focused on developing and evaluating
large language models for a variety of code synthesis tasks. These include
synthesizing code from natural language instructions, synthesizing tests from
code, and synthesizing explanations of code. In contrast, the behavior of
instructional code editing with LLMs is understudied. These are tasks in which
the model is instructed to update a block of code provided in a prompt. The
editing instruction may ask for a feature to added or removed, describe a bug
and ask for a fix, ask for a different kind of solution, or many other common
code editing tasks.
<br />We introduce a carefully crafted benchmark of code editing tasks and use it
evaluate several cutting edge LLMs. Our evaluation exposes a significant gap
between the capabilities of state-of-the-art open and closed models. For
example, even GPT-3.5-Turbo is 8.8% better than the best open model at editing
code.
<br />We also introduce a new, carefully curated, permissively licensed training
set of code edits coupled with natural language instructions. Using this
training set, we show that we can fine-tune open Code LLMs to significantly
improve their code editing capabilities.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12456" title="Abstract">arXiv:2312.12456</a> [<a href="/pdf/2312.12456" title="Download PDF">pdf</a>, <a href="/ps/2312.12456" title="Download PostScript">ps</a>, <a href="/format/2312.12456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PowerInfer: Fast Large Language Model Serving with a Consumer-grade GPU
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yixin Song</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+Z">Zeyu Mi</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Haotong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haibo Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Operating Systems (cs.OS)

</div>
<p class="mathjax">This paper introduces PowerInfer, a high-speed Large Language Model (LLM)
inference engine on a personal computer (PC) equipped with a single
consumer-grade GPU. The key underlying the design of PowerInfer is exploiting
the high locality inherent in LLM inference, characterized by a power-law
distribution in neuron activation. This distribution indicates that a small
subset of neurons, termed hot neurons, are consistently activated across
inputs, while the majority, cold neurons, vary based on specific inputs.
PowerInfer exploits such an insight to design a GPU-CPU hybrid inference
engine: hot-activated neurons are preloaded onto the GPU for fast access, while
cold-activated neurons are computed on the CPU, thus significantly reducing GPU
memory demands and CPU-GPU data transfers. PowerInfer further integrates
adaptive predictors and neuron-aware sparse operators, optimizing the
efficiency of neuron activation and computational sparsity. Evaluation shows
that PowerInfer attains an average token generation rate of 13.20 tokens/s,
with a peak of 29.08 tokens/s, across various LLMs (including OPT-175B) on a
single NVIDIA RTX 4090 GPU, only 18% lower than that achieved by a top-tier
server-grade A100 GPU. This significantly outperforms llama.cpp by up to 11.69x
while retaining model accuracy.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12457" title="Abstract">arXiv:2312.12457</a> [<a href="/pdf/2312.12457" title="Download PDF">pdf</a>, <a href="/format/2312.12457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Let AI Entertain You: Increasing User Engagement with Generative AI and  Rejection Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+J">Jingying Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jaewon Yang</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+W">Waleed Malik</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xiao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Richard Huang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qi He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">While generative AI excels in content generation, it does not always increase
user engagement. This can be attributed to two main factors. First, generative
AI generates content without incorporating explicit or implicit feedback about
user interactions. Even if the generated content seems to be more informative
or well-written, it does not necessarily lead to an increase in user
activities, such as clicks. Second, there is a concern with the quality of the
content generative AI produces, which often lacks the distinctiveness and
authenticity that human-created content possesses. These two factors can lead
to content that fails to meet specific needs and preferences of users,
ultimately reducing its potential to be engaging.
<br />This paper presents a generic framework of how to improve user engagement
with generative AI by leveraging user feedback. Our solutions employ rejection
sampling, a technique used in reinforcement learning, to boost engagement
metrics. We leveraged the framework in the context of email notification
subject lines generation for an online social network, and achieved significant
engagement metric lift including +1% Session and +0.4% Weekly Active Users. We
believe our work offers a universal framework that enhances user engagement
with generative AI, particularly when standard generative AI reaches its limits
in terms of enhancing content to be more captivating. To the best of our
knowledge, this represents an early milestone in the industry's successful use
of generative AI to enhance user engagement.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12458" title="Abstract">arXiv:2312.12458</a> [<a href="/pdf/2312.12458" title="Download PDF">pdf</a>, <a href="/format/2312.12458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Parameter-efficient Tuning Meets General-purpose Vision-language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhai%2C+Y">Yihang Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haixin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+J">Jianlong Chang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinlong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jinan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shikun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qi Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Instruction tuning has shown promising potential for developing
general-purpose AI capabilities by using large-scale pre-trained models and
boosts growing research to integrate multimodal information for creative
applications. However, existing works still face two main limitations: the high
training costs and heavy computing resource dependence of full model
fine-tuning, and the lack of semantic information in instructions, which
hinders multimodal alignment. Addressing these challenges, this paper proposes
a novel approach to utilize Parameter-Efficient Tuning for generAl-purpose
vision-Language models, namely PETAL. PETAL revolutionizes the training process
by requiring only 0.5% of the total parameters, achieved through a unique mode
approximation technique, which significantly reduces the training costs and
reliance on heavy computing resources. Furthermore, PETAL enhances the semantic
depth of instructions in two innovative ways: 1) by introducing adaptive
instruction mixture-of-experts(MOEs), and 2) by fortifying the score-based
linkage between parameter-efficient tuning and mutual information. Our
extensive experiments across five multimodal downstream benchmarks reveal that
PETAL not only outperforms current state-of-the-art methods in most scenarios
but also surpasses full fine-tuning models in effectiveness. Additionally, our
approach demonstrates remarkable advantages in few-shot settings, backed by
comprehensive visualization analyses. Our source code is available at:
https://github. com/melonking32/PETAL.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12459" title="Abstract">arXiv:2312.12459</a> [<a href="/pdf/2312.12459" title="Download PDF">pdf</a>, <a href="/ps/2312.12459" title="Download PostScript">ps</a>, <a href="/format/2312.12459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prediction of Crash Injury Severity in Florida&#x27;s Interstate-95
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anik%2C+B+M+T+H">B M Tazbiul Hassan Anik</a>, 
<a href="/search/cs?searchtype=author&query=Rashid%2C+M+M">Md Mobasshir Rashid</a>, 
<a href="/search/cs?searchtype=author&query=Ahsan%2C+M+J">Md Jamil Ahsan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Drivers can sustain serious injuries in traffic accidents. In this study,
traffic crashes on Florida's Interstate-95 from 2016 to 2021 were gathered, and
several classification methods were used to estimate the severity of driver
injuries. In the feature selection method, logistic regression was applied. To
compare model performances, various model assessment matrices such as accuracy,
recall, and area under curve (AUC) were developed. The Adaboost algorithm
outperformed the others in terms of recall and AUC. SHAP values were also
generated to explain the classification model's results. This analytical study
can be used to examine factors that contribute to the severity of driver
injuries in crashes.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12460" title="Abstract">arXiv:2312.12460</a> [<a href="/pdf/2312.12460" title="Download PDF">pdf</a>, <a href="/ps/2312.12460" title="Download PostScript">ps</a>, <a href="/format/2312.12460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Democratize with Care: The need for fairness specific features in  user-interface based open source AutoML tools
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+S">Sundaraparipurnan Narayanan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">AI is increasingly playing a pivotal role in businesses and organizations,
impacting the outcomes and interests of human users. Automated Machine Learning
(AutoML) streamlines the machine learning model development process by
automating repetitive tasks and making data-driven decisions, enabling even
non-experts to construct high-quality models efficiently. This democratization
allows more users (including non-experts) to access and utilize
state-of-the-art machine-learning expertise. However, AutoML tools may also
propagate bias in the way these tools handle the data, model choices, and
optimization approaches adopted. We conducted an experimental study of
User-interface-based open source AutoML tools (DataRobot, H2O Studio, Dataiku,
and Rapidminer Studio) to examine if they had features to assist users in
developing fairness-aware machine learning models. The experiments covered the
following considerations for the evaluation of features: understanding use case
context, data representation, feature relevance and sensitivity, data bias and
preprocessing techniques, data handling capabilities, training-testing split,
hyperparameter handling, and constraints, fairness-oriented model development,
explainability and ability to download and edit models by the user. The results
revealed inadequacies in features that could support in fairness-aware model
development. Further, the results also highlight the need to establish certain
essential features for promoting fairness in AutoML tools.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12461" title="Abstract">arXiv:2312.12461</a> [<a href="/pdf/2312.12461" title="Download PDF">pdf</a>, <a href="/format/2312.12461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bird Movement Prediction Using Long Short-Term Memory Networks to  Prevent Bird Strikes with Low Altitude Aircraft
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Varnousfaderani%2C+E+S">Elaheh Sabziyan Varnousfaderani</a>, 
<a href="/search/cs?searchtype=author&query=Shihab%2C+S+A+M">Syed A. M. Shihab</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 84 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The number of collisions between aircraft and birds in the airspace has been
increasing at an alarming rate over the past decade due to increasing bird
population, air traffic and usage of quieter aircraft. Bird strikes with
aircraft are anticipated to increase dramatically when emerging Advanced Air
Mobility aircraft start operating in the low altitude airspace where
probability of bird strikes is the highest. Not only do such bird strikes can
result in human and bird fatalities, but they also cost the aviation industry
millions of dollars in damages to aircraft annually. To better understand the
causes and effects of bird strikes, research to date has mainly focused on
analyzing factors which increase the probability of bird strikes, identifying
high risk birds in different locations, predicting the future number of bird
strike incidents, and estimating cost of bird strike damages. However, research
on bird movement prediction for use in flight planning algorithms to minimize
the probability of bird strikes is very limited. To address this gap in
research, we implement four different types of Long Short-Term Memory (LSTM)
models to predict bird movement latitudes and longitudes. A publicly available
data set on the movement of pigeons is utilized to train the models and
evaluate their performances. Using the bird flight track predictions, aircraft
departures from Cleveland Hopkins airport are simulated to be delayed by
varying amounts to avoid potential bird strikes with aircraft during takeoff.
Results demonstrate that the LSTM models can predict bird movement with high
accuracy, achieving a Mean Absolute Error of less than 100 meters,
outperforming linear and nonlinear regression models. Our findings indicate
that incorporating bird movement prediction into flight planning can be highly
beneficial.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12463" title="Abstract">arXiv:2312.12463</a> [<a href="/pdf/2312.12463" title="Download PDF">pdf</a>, <a href="/format/2312.12463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open Vocabulary Semantic Scene Sketch Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bourouis%2C+A">Ahmed Bourouis</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J+E">Judith Ellen Fan</a>, 
<a href="/search/cs?searchtype=author&query=Gryaditskaya%2C+Y">Yulia Gryaditskaya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We study the underexplored but fundamental vision problem of machine
understanding of abstract freehand scene sketches. We introduce a sketch
encoder that results in semantically-aware feature space, which we evaluate by
testing its performance on a semantic sketch segmentation task. To train our
model we rely only on the availability of bitmap sketches with their brief
captions and do not require any pixel-level annotations. To obtain
generalization to a large set of sketches and categories, we build on a vision
transformer encoder pretrained with the CLIP model. We freeze the text encoder
and perform visual-prompt tuning of the visual encoder branch while introducing
a set of critical modifications. Firstly, we augment the classical key-query
(k-q) self-attention blocks with value-value (v-v) self-attention blocks.
Central to our model is a two-level hierarchical network design that enables
efficient semantic disentanglement: The first level ensures holistic scene
sketch encoding, and the second level focuses on individual categories. We,
then, in the second level of the hierarchy, introduce a cross-attention between
textual and visual branches. Our method outperforms zero-shot CLIP pixel
accuracy of segmentation results by 37 points, reaching an accuracy of $85.5\%$
on the FS-COCO sketch dataset. Finally, we conduct a user study that allows us
to identify further improvements needed over our method to reconcile machine
and human understanding of scene sketches.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12464" title="Abstract">arXiv:2312.12464</a> [<a href="/pdf/2312.12464" title="Download PDF">pdf</a>, <a href="/format/2312.12464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Better Serialization of Tabular Data for Few-shot Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jaitly%2C+S">Sukriti Jaitly</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+T">Tanay Shah</a>, 
<a href="/search/cs?searchtype=author&query=Shugani%2C+A">Ashish Shugani</a>, 
<a href="/search/cs?searchtype=author&query=Grewal%2C+R+S">Razik Singh Grewal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">We present a study on the integration of Large Language Models (LLMs) in
tabular data classification, emphasizing an efficient framework. Building upon
existing work done in TabLLM (<a href="/abs/2210.10723">arXiv:2210.10723</a>), we introduce three novel
serialization techniques, including the standout LaTeX serialization method.
This method significantly boosts the performance of LLMs in processing
domain-specific datasets, Our method stands out for its memory efficiency and
ability to fully utilize complex data structures. Through extensive
experimentation, including various serialization approaches like feature
combination and importance, we demonstrate our work's superiority in accuracy
and efficiency over traditional models.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12466" title="Abstract">arXiv:2312.12466</a> [<a href="/pdf/2312.12466" title="Download PDF">pdf</a>, <a href="/ps/2312.12466" title="Download PostScript">ps</a>, <a href="/format/2312.12466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Users Approach on Providing Feedback for Smart Home Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pogaku%2C+S">Santhosh Pogaku</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2312.11817">arXiv:2312.11817</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Smart Home technology has accomplished extraordinary interest in making
individuals' lives more straightforward and more relaxing as of late.
Technology as of late brought about delivering numerous savvy and refined
frameworks which advanced clever living innovation. In this paper, we will be
investigating the behavioural intention of user's approach on providing
feedback for smart home devices. We will be conducting an online survey for
sample of three to five students selected by simple random sampling to study
the user's motto for giving feedback on smart home devices and their
expectations. We have observed that most users are ready to share their
feedback on smart home devices actively to improvise the service and quality of
the product to fulfill the user needs and make their lives easier.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12467" title="Abstract">arXiv:2312.12467</a> [<a href="/pdf/2312.12467" title="Download PDF">pdf</a>, <a href="/format/2312.12467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Flexible Body Collision Dynamics with Hierarchical Contact Mesh  Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Youn-Yeol Yu</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jeongwhan Choi</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+W">Woojin Cho</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kookjin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+N">Nayong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kiseok Chang</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+C">ChangSeung Woo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+I">Ilho Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">SeokWoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J+Y">Joon Young Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S">Sooyoung Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+N">Noseong Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Recently, many mesh-based graph neural network (GNN) models have been
proposed for modeling complex high-dimensional physical systems. Remarkable
achievements have been made in significantly reducing the solving time compared
to traditional numerical solvers. These methods are typically designed to i)
reduce the computational cost in solving physical dynamics and/or ii) propose
techniques to enhance the solution accuracy in fluid and rigid body dynamics.
However, it remains under-explored whether they are effective in addressing the
challenges of flexible body dynamics, where instantaneous collisions occur
within a very short timeframe. In this paper, we present Hierarchical Contact
Mesh Transformer (HCMT), which uses hierarchical mesh structures and can learn
long-range dependencies (occurred by collisions) among spatially distant
positions of a body -- two close positions in a higher-level mesh corresponds
to two distant positions in a lower-level mesh. HCMT enables long-range
interactions, and the hierarchical mesh structure quickly propagates collision
effects to faraway positions. To this end, it consists of a contact mesh
Transformer and a hierarchical mesh Transformer (CMT and HMT, respectively).
Lastly, we propose a flexible body dynamics dataset, consisting of trajectories
that reflect experimental settings frequently used in the display industry for
product designs. We also compare the performance of several baselines using
well-known benchmark datasets. Our results show that HCMT provides significant
performance improvements over existing methods.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12468" title="Abstract">arXiv:2312.12468</a> [<a href="/pdf/2312.12468" title="Download PDF">pdf</a>, <a href="/format/2312.12468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MaskINT: Video Editing via Interpolative Non-autoregressive Masked  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Haoyu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Mahdizadehaghdam%2C+S">Shahin Mahdizadehaghdam</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bichen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhipeng Fan</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuchao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenliang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shapira%2C+L">Lior Shapira</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaohui Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advances in generative AI have significantly enhanced image and video
editing, particularly in the context of text prompt control. State-of-the-art
approaches predominantly rely on diffusion models to accomplish these tasks.
However, the computational demands of diffusion-based methods are substantial,
often necessitating large-scale paired datasets for training, and therefore
challenging the deployment in practical applications. This study addresses this
challenge by breaking down the text-based video editing process into two
separate stages. In the first stage, we leverage an existing text-to-image
diffusion model to simultaneously edit a few keyframes without additional
fine-tuning. In the second stage, we introduce an efficient model called
MaskINT, which is built on non-autoregressive masked generative transformers
and specializes in frame interpolation between the keyframes, benefiting from
structural guidance provided by intermediate frames. Our comprehensive set of
experiments illustrates the efficacy and efficiency of MaskINT when compared to
other diffusion-based methodologies. This research offers a practical solution
for text-based video editing and showcases the potential of non-autoregressive
masked generative transformers in this domain.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12469" title="Abstract">arXiv:2312.12469</a> [<a href="/pdf/2312.12469" title="Download PDF">pdf</a>, <a href="/format/2312.12469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distilling Autoregressive Models to Obtain High-Performance  Non-Autoregressive Solvers for Vehicle Routing Problems with Faster Inference  Speed
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yubin Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mingzhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Changliang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">You Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures, accepted by AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Neural construction models have shown promising performance for Vehicle
Routing Problems (VRPs) by adopting either the Autoregressive (AR) or
Non-Autoregressive (NAR) learning approach. While AR models produce
high-quality solutions, they generally have a high inference latency due to
their sequential generation nature. Conversely, NAR models generate solutions
in parallel with a low inference latency but generally exhibit inferior
performance. In this paper, we propose a generic Guided Non-Autoregressive
Knowledge Distillation (GNARKD) method to obtain high-performance NAR models
having a low inference latency. GNARKD removes the constraint of sequential
generation in AR models while preserving the learned pivotal components in the
network architecture to obtain the corresponding NAR models through knowledge
distillation. We evaluate GNARKD by applying it to three widely adopted AR
models to obtain NAR VRP solvers for both synthesized and real-world instances.
The experimental results demonstrate that GNARKD significantly reduces the
inference time (4-5 times faster) with acceptable performance drop (2-3\%). To
the best of our knowledge, this study is first-of-its-kind to obtain NAR VRP
solvers from AR ones through knowledge distillation.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12470" title="Abstract">arXiv:2312.12470</a> [<a href="/pdf/2312.12470" title="Download PDF">pdf</a>, <a href="/format/2312.12470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rotated Multi-Scale Interaction Network for Referring Remote Sensing  Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sihan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yiwei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haowei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Jiayi Ji</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaoshuai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+R">Rongrong Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Referring Remote Sensing Image Segmentation (RRSIS) is a new challenge that
combines computer vision and natural language processing, delineating specific
regions in aerial images as described by textual queries. Traditional Referring
Image Segmentation (RIS) approaches have been impeded by the complex spatial
scales and orientations found in aerial imagery, leading to suboptimal
segmentation results. To address these challenges, we introduce the Rotated
Multi-Scale Interaction Network (RMSIN), an innovative approach designed for
the unique demands of RRSIS. RMSIN incorporates an Intra-scale Interaction
Module (IIM) to effectively address the fine-grained detail required at
multiple scales and a Cross-scale Interaction Module (CIM) for integrating
these details coherently across the network. Furthermore, RMSIN employs an
Adaptive Rotated Convolution (ARC) to account for the diverse orientations of
objects, a novel contribution that significantly enhances segmentation
accuracy. To assess the efficacy of RMSIN, we have curated an expansive dataset
comprising 17,402 image-caption-mask triplets, which is unparalleled in terms
of scale and variety. This dataset not only presents the model with a wide
range of spatial and rotational scenarios but also establishes a stringent
benchmark for the RRSIS task, ensuring a rigorous evaluation of performance.
Our experimental evaluations demonstrate the exceptional performance of RMSIN,
surpassing existing state-of-the-art models by a significant margin. All
datasets and code are made available at https://github.com/Lsan2401/RMSIN.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12471" title="Abstract">arXiv:2312.12471</a> [<a href="/pdf/2312.12471" title="Download PDF">pdf</a>, <a href="/format/2312.12471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Atlantis: Enabling Underwater Depth Estimation with Stable Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+S">Shaodi You</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yu Li</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Ying Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Monocular depth estimation has experienced significant progress on
terrestrial images in recent years, largely due to deep learning advancements.
However, it remains inadequate for underwater scenes, primarily because of data
scarcity. Given the inherent challenges of light attenuation and backscattering
in water, acquiring clear underwater images or precise depth information is
notably difficult and costly. Consequently, learning-based approaches often
rely on synthetic data or turn to unsupervised or self-supervised methods to
mitigate this lack of data. Nonetheless, the performance of these methods is
often constrained by the domain gap and looser constraints. In this paper, we
propose a novel pipeline for generating photorealistic underwater images using
accurate terrestrial depth data. This approach facilitates the training of
supervised models for underwater depth estimation, effectively reducing the
performance disparity between terrestrial and underwater environments. Contrary
to prior synthetic datasets that merely apply style transfer to terrestrial
images without altering the scene content, our approach uniquely creates
vibrant, non-existent underwater scenes by leveraging terrestrial depth data
through the innovative Stable Diffusion model. Specifically, we introduce a
unique Depth2Underwater ControlNet, trained on specially prepared \{Underwater,
Depth, Text\} data triplets, for this generation task. Our newly developed
dataset enables terrestrial depth estimation models to achieve considerable
improvements, both quantitatively and qualitatively, on unseen underwater
images, surpassing their terrestrial pre-trained counterparts. Moreover, the
enhanced depth accuracy for underwater scenes also aids underwater image
restoration techniques that rely on depth maps, further demonstrating our
dataset's utility. The dataset will be available at
https://github.com/zkawfanx/Atlantis.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12472" title="Abstract">arXiv:2312.12472</a> [<a href="/pdf/2312.12472" title="Download PDF">pdf</a>, <a href="/format/2312.12472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Performance Evaluation of a Quantized Large Language Model on Various  Smartphones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%87%C3%B6pl%C3%BC%2C+T">Tolga &#xc7;&#xf6;pl&#xfc;</a>, 
<a href="/search/cs?searchtype=author&query=Loedi%2C+M">Marc Loedi</a>, 
<a href="/search/cs?searchtype=author&query=Bendiken%2C+A">Arto Bendiken</a>, 
<a href="/search/cs?searchtype=author&query=Makohin%2C+M">Mykhailo Makohin</a>, 
<a href="/search/cs?searchtype=author&query=Bouw%2C+J+J">Joshua J. Bouw</a>, 
<a href="/search/cs?searchtype=author&query=Cobb%2C+S">Stephen Cobb</a> (Haltia, Inc.)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper explores the feasibility and performance of on-device large
language model (LLM) inference on various Apple iPhone models. Amidst the rapid
evolution of generative AI, on-device LLMs offer solutions to privacy,
security, and connectivity challenges inherent in cloud-based models.
Leveraging existing literature on running multi-billion parameter LLMs on
resource-limited devices, our study examines the thermal effects and
interaction speeds of a high-performing LLM across different smartphone
generations. We present real-world performance results, providing insights into
on-device inference capabilities.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12473" title="Abstract">arXiv:2312.12473</a> [<a href="/pdf/2312.12473" title="Download PDF">pdf</a>, <a href="/ps/2312.12473" title="Download PostScript">ps</a>, <a href="/format/2312.12473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study on Social Robot Behavior in Group Conversation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Tung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nichols%2C+E">Eric Nichols</a>, 
<a href="/search/cs?searchtype=author&query=Gomez%2C+R">Randy Gomez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, research in human-robot interaction began to consider a robot's
influence at the group level. Despite the recent growth in research
investigating the effects of robots within groups of people, our overall
understanding of what happens when robots are placed within groups or teams of
people is still limited. This paper investigates several key problems for soci
robots that manage conversations in a group setting, where the number of
participants is more than two. In a group setting, the conversation dynamics
are a lot more complicated than the conventional one-to-one conversation, thus,
there are more challenges need to be solved.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12474" title="Abstract">arXiv:2312.12474</a> [<a href="/pdf/2312.12474" title="Download PDF">pdf</a>, <a href="/format/2312.12474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Principled Weight Initialisation for Input-Convex Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoedt%2C+P">Pieter-Jan Hoedt</a>, 
<a href="/search/cs?searchtype=author&query=Klambauer%2C+G">G&#xfc;nter Klambauer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Input-Convex Neural Networks (ICNNs) are networks that guarantee convexity in
their input-output mapping. These networks have been successfully applied for
energy-based modelling, optimal transport problems and learning invariances.
The convexity of ICNNs is achieved by using non-decreasing convex activation
functions and non-negative weights. Because of these peculiarities, previous
initialisation strategies, which implicitly assume centred weights, are not
effective for ICNNs. By studying signal propagation through layers with
non-negative weights, we are able to derive a principled weight initialisation
for ICNNs. Concretely, we generalise signal propagation theory by removing the
assumption that weights are sampled from a centred distribution. In a set of
experiments, we demonstrate that our principled initialisation effectively
accelerates learning in ICNNs and leads to better generalisation. Moreover, we
find that, in contrast to common belief, ICNNs can be trained without
skip-connections when initialised correctly. Finally, we apply ICNNs to a
real-world drug discovery task and show that they allow for more effective
molecular latent space exploration.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12475" title="Abstract">arXiv:2312.12475</a> [<a href="/pdf/2312.12475" title="Download PDF">pdf</a>, <a href="/format/2312.12475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Reweight for Graph Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhengyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Teng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+K">Kun Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Z">Zheqi Lv</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jinluan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chengqiang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongxia Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fei Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Graph Neural Networks (GNNs) show promising results for graph tasks. However,
existing GNNs' generalization ability will degrade when there exist
distribution shifts between testing and training graph data. The cardinal
impetus underlying the severe degeneration is that the GNNs are architected
predicated upon the I.I.D assumptions. In such a setting, GNNs are inclined to
leverage imperceptible statistical correlations subsisting in the training set
to predict, albeit it is a spurious correlation. In this paper, we study the
problem of the generalization ability of GNNs in Out-Of-Distribution (OOD)
settings. To solve this problem, we propose the Learning to Reweight for
Generalizable Graph Neural Network (L2R-GNN) to enhance the generalization
ability for achieving satisfactory performance on unseen testing graphs that
have different distributions with training graphs. We propose a novel nonlinear
graph decorrelation method, which can substantially improve the
out-of-distribution generalization ability and compares favorably to previous
methods in restraining the over-reduced sample size. The variables of the graph
representation are clustered based on the stability of the correlation, and the
graph decorrelation method learns weights to remove correlations between the
variables of different clusters rather than any two variables. Besides, we
interpose an efficacious stochastic algorithm upon bi-level optimization for
the L2R-GNN framework, which facilitates simultaneously learning the optimal
weights and GNN parameters, and avoids the overfitting problem. Experimental
results show that L2R-GNN greatly outperforms baselines on various graph
prediction benchmarks under distribution shifts.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12477" title="Abstract">arXiv:2312.12477</a> [<a href="/pdf/2312.12477" title="Download PDF">pdf</a>, <a href="/format/2312.12477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survey on Trustworthy Graph Neural Networks: From A Causal Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wenzhao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
<p class="mathjax">Graph Neural Networks (GNNs) have emerged as powerful representation learning
tools for capturing complex dependencies within diverse graph-structured data.
Despite their success in a wide range of graph mining tasks, GNNs have raised
serious concerns regarding their trustworthiness, including susceptibility to
distribution shift, biases towards certain populations, and lack of
explainability. Recently, integrating causal learning techniques into GNNs has
sparked numerous ground-breaking studies since most of the trustworthiness
issues can be alleviated by capturing the underlying data causality rather than
superficial correlations. In this survey, we provide a comprehensive review of
recent research efforts on causality-inspired GNNs. Specifically, we first
present the key trustworthy risks of existing GNN models through the lens of
causality. Moreover, we introduce a taxonomy of Causality-Inspired GNNs
(CIGNNs) based on the type of causal learning capability they are equipped
with, i.e., causal reasoning and causal representation learning. Besides, we
systematically discuss typical methods within each category and demonstrate how
they mitigate trustworthiness risks. Finally, we summarize useful resources and
discuss several future directions, hoping to shed light on new research
opportunities in this emerging field. The representative papers, along with
open-source data and codes, are available in
https://github.com/usail-hkust/Causality-Inspired-GNNs.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12478" title="Abstract">arXiv:2312.12478</a> [<a href="/pdf/2312.12478" title="Download PDF">pdf</a>, <a href="/format/2312.12478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProS: Prompting-to-simulate Generalized knowledge for Universal  Cross-Domain Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+K">Kaipeng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jingkuan Song</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Lianli Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+P">Pengpeng Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhi-Qi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiyao Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H+T">Heng Tao Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The goal of Universal Cross-Domain Retrieval (UCDR) is to achieve robust
performance in generalized test scenarios, wherein data may belong to strictly
unknown domains and categories during training. Recently, pre-trained models
with prompt tuning have shown strong generalization capabilities and attained
noteworthy achievements in various downstream tasks, such as few-shot learning
and video-text retrieval. However, applying them directly to UCDR may not
sufficiently to handle both domain shift (i.e., adapting to unfamiliar domains)
and semantic shift (i.e., transferring to unknown categories). To this end, we
propose Prompting-to-Simulate (ProS), the first method to apply prompt tuning
for UCDR. ProS employs a two-step process to simulate Content-aware Dynamic
Prompts (CaDP) which can impact models to produce generalized features for
UCDR. Concretely, in Prompt Units Learning stage, we introduce two Prompt Units
to individually capture domain and semantic knowledge in a mask-and-align way.
Then, in Context-aware Simulator Learning stage, we train a Content-aware
Prompt Simulator under a simulated test scenarios to produce the corresponding
CaDP. Extensive experiments conducted on three benchmark datasets show that our
method achieves new state-of-the-art performance without bringing excessive
parameters. Our method is publicly available at
https://anonymous.4open.science/r/ProS
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12479" title="Abstract">arXiv:2312.12479</a> [<a href="/pdf/2312.12479" title="Download PDF">pdf</a>, <a href="/format/2312.12479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-shot Building Attribute Extraction from Large-Scale Vision and  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+F">Fei Pan</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+S">Sangryul Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Brian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mckenna%2C+F">Frank Mckenna</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S+X">Stella X. Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV 2024, Project Page: <a href="https://sites.google.com/view/zobae/home">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing building recognition methods, exemplified by BRAILS, utilize
supervised learning to extract information from satellite and street-view
images for classification and segmentation. However, each task module requires
human-annotated data, hindering the scalability and robustness to regional
variations and annotation imbalances. In response, we propose a new zero-shot
workflow for building attribute extraction that utilizes large-scale vision and
language models to mitigate reliance on external annotations. The proposed
workflow contains two key components: image-level captioning and segment-level
captioning for the building images based on the vocabularies pertinent to
structural and civil engineering. These two components generate descriptive
captions by computing feature representations of the image and the
vocabularies, and facilitating a semantic match between the visual and textual
representations. Consequently, our framework offers a promising avenue to
enhance AI-driven captioning for building attribute extraction in the
structural and civil engineering domains, ultimately reducing reliance on human
annotations while bolstering performance and adaptability.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12480" title="Abstract">arXiv:2312.12480</a> [<a href="/pdf/2312.12480" title="Download PDF">pdf</a>, <a href="/format/2312.12480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Distribution Masked Autoencoders for Continual Test-Time  Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Senqiao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Renrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qizhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zehui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yandong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanghang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Continual Test-Time Adaptation (CTTA) is proposed to migrate a source
pre-trained model to continually changing target distributions, addressing
real-world dynamism. Existing CTTA methods mainly rely on entropy minimization
or teacher-student pseudo-labeling schemes for knowledge extraction in
unlabeled target domains. However, dynamic data distributions cause
miscalibrated predictions and noisy pseudo-labels in existing self-supervised
learning methods, hindering the effective mitigation of error accumulation and
catastrophic forgetting problems during the continual adaptation process. To
tackle these issues, we propose a continual self-supervised method, Adaptive
Distribution Masked Autoencoders (ADMA), which enhances the extraction of
target domain knowledge while mitigating the accumulation of distribution
shifts. Specifically, we propose a Distribution-aware Masking (DaM) mechanism
to adaptively sample masked positions, followed by establishing consistency
constraints between the masked target samples and the original target samples.
Additionally, for masked tokens, we utilize an efficient decoder to reconstruct
a hand-crafted feature descriptor (e.g., Histograms of Oriented Gradients),
leveraging its invariant properties to boost task-relevant representations.
Through conducting extensive experiments on four widely recognized benchmarks,
our proposed method attains state-of-the-art performance in both classification
and segmentation CTTA tasks.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12481" title="Abstract">arXiv:2312.12481</a> [<a href="/pdf/2312.12481" title="Download PDF">pdf</a>, <a href="/format/2312.12481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling Spaces: Architecturally meaningful semantic descriptions from  images of interior spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tas%2C+D">Demircan Tas</a>, 
<a href="/search/cs?searchtype=author&query=Sanatani%2C+R+P">Rohit Priyadarshi Sanatani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Written for 6.869, Advances in Computer Vision at MIT, Spring 2022. 9 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">There has been a growing adoption of computer vision tools and technologies
in architectural design workflows over the past decade. Notable use cases
include point cloud generation, visual content analysis, and spatial awareness
for robotic fabrication. Multiple image classification, object detection, and
semantic pixel segmentation models have become popular for the extraction of
high-level symbolic descriptions and semantic content from two-dimensional
images and videos. However, a major challenge in this regard has been the
extraction of high-level architectural structures (walls, floors, ceilings
windows etc.) from diverse imagery where parts of these elements are occluded
by furniture, people, or other non-architectural elements. This project aims to
tackle this problem by proposing models that are capable of extracting
architecturally meaningful semantic descriptions from two-dimensional scenes of
populated interior spaces. 1000 virtual classrooms are parametrically
generated, randomized along key spatial parameters such as length, width,
height, and door/window positions. The positions of cameras, and
non-architectural visual obstructions (furniture/objects) are also randomized.
A Generative Adversarial Network (GAN) for image-to-image translation (Pix2Pix)
is trained on synthetically generated rendered images of these enclosures,
along with corresponding image abstractions representing high-level
architectural structure. The model is then tested on unseen synthetic imagery
of new enclosures, and outputs are compared to ground truth using pixel-wise
comparison for evaluation. A similar model evaluation is also carried out on
photographs of existing indoor enclosures, to measure its performance in
real-world settings.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12483" title="Abstract">arXiv:2312.12483</a> [<a href="/pdf/2312.12483" title="Download PDF">pdf</a>, <a href="/format/2312.12483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCoTTi: Save Computation at Training Time with an adaptive framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Ziyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Tartaglione%2C+E">Enzo Tartaglione</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V">Van-Tam Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">On-device training is an emerging approach in machine learning where models
are trained on edge devices, aiming to enhance privacy protection and real-time
performance. However, edge devices typically possess restricted computational
power and resources, making it challenging to perform computationally intensive
model training tasks. Consequently, reducing resource consumption during
training has become a pressing concern in this field. To this end, we propose
SCoTTi (Save Computation at Training Time), an adaptive framework that
addresses the aforementioned challenge. It leverages an optimizable threshold
parameter to effectively reduce the number of neuron updates during training
which corresponds to a decrease in memory and computation footprint. Our
proposed approach demonstrates superior performance compared to the
state-of-the-art methods regarding computational resource savings on various
commonly employed benchmarks and popular architectures, including ResNets,
MobileNet, and Swin-T.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12484" title="Abstract">arXiv:2312.12484</a> [<a href="/pdf/2312.12484" title="Download PDF">pdf</a>, <a href="/format/2312.12484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SkyMask: Attack-agnostic Robust Federated Learning with Fine-grained  Learnable Masks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+P">Peishen Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+T">Tao Song</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+Y">Yang Hua</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+R">Ruhui Ma</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+N">Ningxin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Haghighat%2C+M+R">Mohammad R. Haghighat</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+H">Haibing Guan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated Learning (FL) is becoming a popular paradigm for leveraging
distributed data and preserving data privacy. However, due to the distributed
characteristic, FL systems are vulnerable to Byzantine attacks that compromised
clients attack the global model by uploading malicious model updates. Most
existing Byzantine-robust FL systems statistically analyze the weights of whole
individual model updates uploaded by clients to defend against Byzantine
attacks. With the development of layer-level and parameter-level fine-grained
attacks, the attacks' stealthiness and effectiveness have been significantly
improved. Due to unawareness or overreaction, the existing model-level defense
methods degrade the training efficiency and model performance. To address this
problem, we propose SkyMask, a new attack-agnostic robust FL system that
leverages fine-grained learnable masks to identify malicious model updates at
the parameter-level. Specifically, the FL server applies parameter-level masks
to model updates uploaded by clients and trains the masks over a small clean
dataset (i.e., root dataset) to learn the subtle difference between benign and
malicious model updates in a high-dimension space. Our extensive experiments
involve different models on three public datasets under state-of-the-art (SOTA)
attacks, where the results show that SkyMask achieves up to 10% higher testing
accuracy compared with SOTA defense strategies and successfully defends against
attacks with malicious clients of a high fraction up to 80%. In the meantime,
the experimental results demonstrate the scalability of our approach and the
weak dependence on the data distribution of the root dataset.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12486" title="Abstract">arXiv:2312.12486</a> [<a href="/pdf/2312.12486" title="Download PDF">pdf</a>, <a href="/ps/2312.12486" title="Download PostScript">ps</a>, <a href="/format/2312.12486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision-Based Automatic Groceries Tracking System -- Smart Homes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mereddy%2C+D">Divya Mereddy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With advanced AI, while every industry is growing at rocket speed, the smart
home industry has not reached the next generation. There is still a huge leap
of innovation that needs to happen before we call a home a Smart home. A Smart
home should predict residents' needs and fulfill them in a timely manner. One
of the important tasks of maintaining a home is timely grocery tracking and
supply maintenance. Grocery tracking models are very famous in the retail
industry but they are nonexistent in the common household. Groceries detection
in household refrigerators or storage closets is very complicated compared to
retail shelving data. In this paper, home grocery tracking problem is resolved
by combining retail shelving data and fruits dataset with real-time 360 view
data points collected from home groceries storage. By integrating this
vision-based object detection system along with supply chain and user food
interest prediction systems, complete automation of groceries ordering can be
achieved.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12487" title="Abstract">arXiv:2312.12487</a> [<a href="/pdf/2312.12487" title="Download PDF">pdf</a>, <a href="/format/2312.12487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Guidance: Training-free Acceleration of Conditional Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castillo%2C+A">Angela Castillo</a>, 
<a href="/search/cs?searchtype=author&query=Kohler%2C+J">Jonas Kohler</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+J+C">Juan C. P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+J+P">Juan Pablo P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Pumarola%2C+A">Albert Pumarola</a>, 
<a href="/search/cs?searchtype=author&query=Ghanem%2C+B">Bernard Ghanem</a>, 
<a href="/search/cs?searchtype=author&query=Arbel%C3%A1ez%2C+P">Pablo Arbel&#xe1;ez</a>, 
<a href="/search/cs?searchtype=author&query=Thabet%2C+A">Ali Thabet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents a comprehensive study on the role of Classifier-Free
Guidance (CFG) in text-conditioned diffusion models from the perspective of
inference efficiency. In particular, we relax the default choice of applying
CFG in all diffusion steps and instead search for efficient guidance policies.
We formulate the discovery of such policies in the differentiable Neural
Architecture Search framework. Our findings suggest that the denoising steps
proposed by CFG become increasingly aligned with simple conditional steps,
which renders the extra neural network evaluation of CFG redundant, especially
in the second half of the denoising process. Building upon this insight, we
propose "Adaptive Guidance" (AG), an efficient variant of CFG, that adaptively
omits network evaluations when the denoising process displays convergence. Our
experiments demonstrate that AG preserves CFG's image quality while reducing
computation by 25%. Thus, AG constitutes a plug-and-play alternative to
Guidance Distillation, achieving 50% of the speed-ups of the latter while being
training-free and retaining the capacity to handle negative prompts. Finally,
we uncover further redundancies of CFG in the first half of the diffusion
process, showing that entire neural function evaluations can be replaced by
simple affine transformations of past score estimates. This method, termed
LinearAG, offers even cheaper inference at the cost of deviating from the
baseline model. Our findings provide insights into the efficiency of the
conditional denoising process that contribute to more practical and swift
deployment of text-conditioned diffusion models.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12488" title="Abstract">arXiv:2312.12488</a> [<a href="/pdf/2312.12488" title="Download PDF">pdf</a>, <a href="/format/2312.12488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foreseeing Reconstruction Quality of Gradient Inversion: An Optimization  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+H">HyeongGwon Hong</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+Y">Yooshin Cho</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+H">Hanbyel Cho</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+J">Jaesung Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Junmo Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Gradient inversion attacks can leak data privacy when clients share weight
updates with the server in federated learning (FL). Existing studies mainly use
L2 or cosine distance as the loss function for gradient matching in the attack.
Our empirical investigation shows that the vulnerability ranking varies with
the loss function used. Gradient norm, which is commonly used as a
vulnerability proxy for gradient inversion attack, cannot explain this as it
remains constant regardless of the loss function for gradient matching. In this
paper, we propose a loss-aware vulnerability proxy (LAVP) for the first time.
LAVP refers to either the maximum or minimum eigenvalue of the Hessian with
respect to gradient matching loss at ground truth. This suggestion is based on
our theoretical findings regarding the local optimization of the gradient
inversion in proximity to the ground truth, which corresponds to the worst case
attack scenario. We demonstrate the effectiveness of LAVP on various
architectures and datasets, showing its consistent superiority over the
gradient norm in capturing sample vulnerabilities. The performance of each
proxy is measured in terms of Spearman's rank correlation with respect to
several similarity scores. This work will contribute to enhancing FL security
against any potential loss functions beyond L2 or cosine distance in the
future.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12489" title="Abstract">arXiv:2312.12489</a> [<a href="/pdf/2312.12489" title="Download PDF">pdf</a>, <a href="/format/2312.12489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> H-ensemble: An Information Theoretic Approach to Reliable Few-Shot  Multi-Source-Free Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yanru Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianning Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weida Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multi-source transfer learning is an effective solution to data scarcity by
utilizing multiple source tasks for the learning of the target task. However,
access to source data and model details is limited in the era of commercial
models, giving rise to the setting of multi-source-free (MSF) transfer learning
that aims to leverage source domain knowledge without such access. As a newly
defined problem paradigm, MSF transfer learning remains largely underexplored
and not clearly formulated. In this work, we adopt an information theoretic
perspective on it and propose a framework named H-ensemble, which dynamically
learns the optimal linear combination, or ensemble, of source models for the
target task, using a generalization of maximal correlation regression. The
ensemble weights are optimized by maximizing an information theoretic metric
for transferability. Compared to previous works, H-ensemble is characterized
by: 1) its adaptability to a novel and realistic MSF setting for few-shot
target tasks, 2) theoretical reliability, 3) a lightweight structure easy to
interpret and adapt. Our method is empirically validated by ablation studies,
along with extensive comparative analysis with other task ensemble and transfer
learning methods. We show that the H-ensemble can successfully learn the
optimal task ensemble, as well as outperform prior arts.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12490" title="Abstract">arXiv:2312.12490</a> [<a href="/pdf/2312.12490" title="Download PDF">pdf</a>, <a href="/format/2312.12490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InstructVideo: Instructing Video Diffusion Models with Human Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Hangjie Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yujie Wei</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+T">Tao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yining Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Albanie%2C+S">Samuel Albanie</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+D">Dong Ni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://instructvideo.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">Diffusion models have emerged as the de facto paradigm for video generation.
However, their reliance on web-scale data of varied quality often yields
results that are visually unappealing and misaligned with the textual prompts.
To tackle this problem, we propose InstructVideo to instruct text-to-video
diffusion models with human feedback by reward fine-tuning. InstructVideo has
two key ingredients: 1) To ameliorate the cost of reward fine-tuning induced by
generating through the full DDIM sampling chain, we recast reward fine-tuning
as editing. By leveraging the diffusion process to corrupt a sampled video,
InstructVideo requires only partial inference of the DDIM sampling chain,
reducing fine-tuning cost while improving fine-tuning efficiency. 2) To
mitigate the absence of a dedicated video reward model for human preferences,
we repurpose established image reward models, e.g., HPSv2. To this end, we
propose Segmental Video Reward, a mechanism to provide reward signals based on
segmental sparse sampling, and Temporally Attenuated Reward, a method that
mitigates temporal modeling degradation during fine-tuning. Extensive
experiments, both qualitative and quantitative, validate the practicality and
efficacy of using image reward models in InstructVideo, significantly enhancing
the visual quality of generated videos without compromising generalization
capabilities. Code and models will be made publicly available.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12491" title="Abstract">arXiv:2312.12491</a> [<a href="/pdf/2312.12491" title="Download PDF">pdf</a>, <a href="/format/2312.12491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StreamDiffusion: A Pipeline-level Solution for Real-time Interactive  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kodaira%2C+A">Akio Kodaira</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chenfeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hazama%2C+T">Toshiki Hazama</a>, 
<a href="/search/cs?searchtype=author&query=Yoshimoto%2C+T">Takanori Yoshimoto</a>, 
<a href="/search/cs?searchtype=author&query=Ohno%2C+K">Kohei Ohno</a>, 
<a href="/search/cs?searchtype=author&query=Mitsuhori%2C+S">Shogo Mitsuhori</a>, 
<a href="/search/cs?searchtype=author&query=Sugano%2C+S">Soichi Sugano</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+H">Hanying Cho</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhijian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Keutzer%2C+K">Kurt Keutzer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> tech report, the code is available at <a href="https://github.com/cumulo-autumn/StreamDiffusion">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce StreamDiffusion, a real-time diffusion pipeline designed for
interactive image generation. Existing diffusion models are adept at creating
images from text or image prompts, yet they often fall short in real-time
interaction. This limitation becomes particularly evident in scenarios
involving continuous input, such as Metaverse, live video streaming, and
broadcasting, where high throughput is imperative. To address this, we present
a novel approach that transforms the original sequential denoising into the
batching denoising process. Stream Batch eliminates the conventional
wait-and-interact approach and enables fluid and high throughput streams. To
handle the frequency disparity between data input and model throughput, we
design a novel input-output queue for parallelizing the streaming process.
Moreover, the existing diffusion pipeline uses classifier-free guidance(CFG),
which requires additional U-Net computation. To mitigate the redundant
computations, we propose a novel residual classifier-free guidance (RCFG)
algorithm that reduces the number of negative conditional denoising steps to
only one or even zero. Besides, we introduce a stochastic similarity
filter(SSF) to optimize power consumption. Our Stream Batch achieves around
1.5x speedup compared to the sequential denoising method at different denoising
levels. The proposed RCFG leads to speeds up to 2.05x higher than the
conventional CFG. Combining the proposed strategies and existing mature
acceleration tools makes the image-to-image generation achieve up-to 91.07fps
on one RTX4090, improving the throughputs of AutoPipline developed by Diffusers
over 59.56x. Furthermore, our proposed StreamDiffusion also significantly
reduces the energy consumption by 2.39x on one RTX3060 and 1.99x on one
RTX4090, respectively.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12492" title="Abstract">arXiv:2312.12492</a> [<a href="/pdf/2312.12492" title="Download PDF">pdf</a>, <a href="/format/2312.12492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CodeLL: A Lifelong Learning Dataset to Support the Co-Evolution of Data  and Language Models of Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weyssow%2C+M">Martin Weyssow</a>, 
<a href="/search/cs?searchtype=author&query=Di+Sipio%2C+C">Claudio Di Sipio</a>, 
<a href="/search/cs?searchtype=author&query=Di+Ruscio%2C+D">Davide Di Ruscio</a>, 
<a href="/search/cs?searchtype=author&query=Sahraoui%2C+H">Houari Sahraoui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4+1 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Motivated by recent work on lifelong learning applications for language
models (LMs) of code, we introduce CodeLL, a lifelong learning dataset focused
on code changes. Our contribution addresses a notable research gap marked by
the absence of a long-term temporal dimension in existing code change datasets,
limiting their suitability in lifelong learning scenarios. In contrast, our
dataset aims to comprehensively capture code changes across the entire release
history of open-source software repositories. In this work, we introduce an
initial version of CodeLL, comprising 71 machine-learning-based projects mined
from Software Heritage. This dataset enables the extraction and in-depth
analysis of code changes spanning 2,483 releases at both the method and API
levels. CodeLL enables researchers studying the behaviour of LMs in lifelong
fine-tuning settings for learning code changes. Additionally, the dataset can
help studying data distribution shifts within software repositories and the
evolution of API usages over time.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12494" title="Abstract">arXiv:2312.12494</a> [<a href="/pdf/2312.12494" title="Download PDF">pdf</a>, <a href="/format/2312.12494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DDOS: The Drone Depth and Obstacle Segmentation Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kolbeinsson%2C+B">Benedikt Kolbeinsson</a>, 
<a href="/search/cs?searchtype=author&query=Mikolajczyk%2C+K">Krystian Mikolajczyk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Accurate depth and semantic segmentation are crucial for various computer
vision tasks. However, the scarcity of annotated real-world aerial datasets
poses a significant challenge for training and evaluating robust models.
Additionally, the detection and segmentation of thin objects, such as wires,
cables, and fences, present a critical concern for ensuring the safe operation
of drones. To address these limitations, we present a novel synthetic dataset
specifically designed for depth and semantic segmentation tasks in aerial
views. Leveraging photo-realistic rendering techniques, our dataset provides a
valuable resource for training models using a synthetic-supervision training
scheme while introducing new drone-specific metrics for depth accuracy.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12495" title="Abstract">arXiv:2312.12495</a> [<a href="/pdf/2312.12495" title="Download PDF">pdf</a>, <a href="/ps/2312.12495" title="Download PostScript">ps</a>, <a href="/format/2312.12495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Huffman based short message service compression technique using  adjacent distance array
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarker%2C+P">Pranta Sarker</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+L">Mir Lutfur Rahman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 9 figures, peer reviewed, accepted, in press, Journal article
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">The short message service (SMS) is a wireless medium of transmission that
allows you to send brief text messages. Cell phone devices have an uttermost
SMS capacity of 1,120 bits in the traditional system. Moreover, the
conventional SMS employs seven bits for each character, allowing the highest
160 characters for an SMS text message to be transmitted. This research
demonstrated that an SMS message could contain more than 200 characters by
representing around five bits each, introducing a data structure, namely,
adjacent distance array (ADA) using the Huffman principle. Allowing the concept
of lossless data compression technique, the proposed method of the research
generates character's codeword utilising the standard Huffman. However, the ADA
encodes the message by putting the ASCII value distances of all characters, and
decoding performs by avoiding the whole Huffman tree traverse, which is the
pivotal contribution of the research to develop an effective SMS compression
technique for personal digital assistants (PDAs). The encoding and decoding
processes have been discussed and contrasted with the conventional SMS text
message system, where our proposed ADA technique performs outstandingly better
from every aspect discovered after evaluating all outcomes.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12540" title="Abstract">arXiv:2312.12540</a> [<a href="/pdf/2312.12540" title="Download PDF">pdf</a>, <a href="/format/2312.12540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fixed-point Inversion for Text-to-image diffusion models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meiri%2C+B">Barak Meiri</a>, 
<a href="/search/cs?searchtype=author&query=Samuel%2C+D">Dvir Samuel</a>, 
<a href="/search/cs?searchtype=author&query=Darshan%2C+N">Nir Darshan</a>, 
<a href="/search/cs?searchtype=author&query=Chechik%2C+G">Gal Chechik</a>, 
<a href="/search/cs?searchtype=author&query=Avidan%2C+S">Shai Avidan</a>, 
<a href="/search/cs?searchtype=author&query=Ben-Ari%2C+R">Rami Ben-Ari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-guided diffusion models offer powerful new ways to generate and
manipulate images. Several applications of these models, including image
editing interpolation, and semantic augmentation, require diffusion inversion.
This is the process of finding a noise seed that can be used to generate a
given image. Current techniques for inverting a given image can be slow or
inaccurate. The technical challenge for inverting the diffusion process arises
from an implicit equation over the latent that cannot be solved in closed form.
Previous approaches proposed to solve this issue by approximation or various
learning schemes. Here, we formulate the problem as a fixed-point equation
problem and solve it using fixed-point iterations, a well-studied approach in
numerical analysis. We further identify a source of inconsistency that
significantly hurts the inversion of real images encoded to the latent space.
We show how to correct it by applying a prompt-aware adjustment of the
encoding. Our solution, Fixed-point inversion, is much faster than previous
techniques like EDICT and Null-text, with similar inversion quality. It can be
combined with any pretrained diffusion model and requires no model training,
prompt tuning, or additional parameters. In a series of experiments, we find
that Fixed-point inversion shows improved results in several downstream tasks:
image editing, image interpolation, and generation of rare objects.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12541" title="Abstract">arXiv:2312.12541</a> [<a href="/pdf/2312.12541" title="Download PDF">pdf</a>, <a href="/ps/2312.12541" title="Download PostScript">ps</a>, <a href="/format/2312.12541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blood Glucose Level Prediction: A Graph-based Explainable Method with  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Piao%2C+C">Chengzhe Piao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Ken Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In the UK, approximately 400,000 people with type 1 diabetes (T1D) rely on
insulin delivery due to insufficient pancreatic insulin production. Managing
blood glucose (BG) levels is crucial, with continuous glucose monitoring (CGM)
playing a key role. CGM, tracking BG every 5 minutes, enables effective blood
glucose level prediction (BGLP) by considering factors like carbohydrate intake
and insulin delivery.
<br />Recent research has focused on developing sequential models for BGLP using
historical BG data, incorporating additional attributes such as carbohydrate
intake, insulin delivery, and time. These methods have shown notable success in
BGLP, with some providing temporal explanations. However, they often lack clear
correlations between attributes and their impact on BGLP. Additionally, some
methods raise privacy concerns by aggregating participant data to learn
population patterns.
<br />Addressing these limitations, we introduced a graph attentive memory (GAM)
model, combining a graph attention network (GAT) with a gated recurrent unit
(GRU). GAT applies graph attention to model attribute correlations, offering
transparent, dynamic attribute relationships. Attention weights dynamically
gauge attribute significance over time. To ensure privacy, we employed
federated learning (FL), facilitating secure population pattern analysis.
<br />Our method was validated using the OhioT1DM'18 and OhioT1DM'20 datasets from
12 participants, focusing on 6 key attributes. We demonstrated our model's
stability and effectiveness through hyperparameter impact analysis.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12544" title="Abstract">arXiv:2312.12544</a> [<a href="/pdf/2312.12544" title="Download PDF">pdf</a>, <a href="/format/2312.12544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Dark Side of NFTs: A Large-Scale Empirical Study of Wash Trading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shijian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiachi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiangshan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiapu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanlin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zibin Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computational Engineering, Finance, and Science (cs.CE); Computers and Society (cs.CY)

</div>
<p class="mathjax">NFTs (Non-Fungible Tokens) have seen significant growth since they first
captured public attention in 2021. However, the NFT market is plagued by fake
transactions and economic bubbles, e.g., NFT wash trading. Wash trading
typically refers to a transaction involving the same person or two colluding
individuals, and has become a major threat to the NFT ecosystem. Previous
studies only detect NFT wash trading from the financial aspect, while the
real-world wash trading cases are much more complicated (e.g., not aiming at
inflating the market value). There is still a lack of multi-dimension analysis
to better understand NFT wash trading. Therefore, we present the most
comprehensive study of NFT wash trading, analyzing 8,717,031 transfer events
and 3,830,141 sale events from 2,701,883 NFTs. We first optimize the dataset
collected via the OpenSea API. Next, we identify three types of NFT wash
trading and propose identification algorithms. Our experimental results reveal
824 transfer events and 5,330 sale events (accounting for a total of
\$8,857,070.41) and 370 address pairs related to NFT wash trading behaviors,
causing a minimum loss of \$3,965,247.13. Furthermore, we provide insights from
six aspects, i.e., marketplace design, profitability, NFT project design,
payment token, user behavior, and NFT ecosystem
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12547" title="Abstract">arXiv:2312.12547</a> [<a href="/pdf/2312.12547" title="Download PDF">pdf</a>, <a href="/ps/2312.12547" title="Download PostScript">ps</a>, <a href="/format/2312.12547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable least-squares space-time boundary element methods for the wave  equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hoonhout%2C+D">Daniel Hoonhout</a>, 
<a href="/search/math?searchtype=author&query=L%C3%B6scher%2C+R">Richard L&#xf6;scher</a>, 
<a href="/search/math?searchtype=author&query=Steinbach%2C+O">Olaf Steinbach</a>, 
<a href="/search/math?searchtype=author&query=Urz%C3%BAa-Torres%2C+C">Carolina Urz&#xfa;a-Torres</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we recast the variational formulation corresponding to the
single layer boundary integral operator $\operatorname{V}$ for the wave
equation as a minimization problem in $L^2(\Sigma)$, where $\Sigma := \partial
\Omega \times (0,T)$ is the lateral boundary of the space-time domain $Q :=
\Omega \times (0,T)$. For discretization, the minimization problem is restated
as a mixed saddle point formulation. Unique solvability is established by
combining conforming nested boundary element spaces for the mixed formulation
such that the related bilinear form is discrete inf-sup stable. We analyze
under which conditions the discrete inf-sup stability is satisfied, and,
moreover, we show that the mixed formulation provides a simple error indicator,
which can be used for adaptivity. We present several numerical experiments
showing the applicability of the method to different time-domain boundary
integral formulations used in the literature.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12554" title="Abstract">arXiv:2312.12554</a> [<a href="/pdf/2312.12554" title="Download PDF">pdf</a>, <a href="/format/2312.12554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rectangle Search: An Anytime Beam Search (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lemons%2C+S">Sofia Lemons</a>, 
<a href="/search/cs?searchtype=author&query=Ruml%2C+W">Wheeler Ruml</a>, 
<a href="/search/cs?searchtype=author&query=Holte%2C+R+C">Robert C. Holte</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+C+L">Carlos Linares L&#xf3;pez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 200+ figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Anytime heuristic search algorithms try to find a (potentially suboptimal)
solution as quickly as possible and then work to find better and better
solutions until an optimal solution is obtained or time is exhausted. The most
widely-known anytime search algorithms are based on best-first search. In this
paper, we propose a new algorithm, rectangle search, that is instead based on
beam search, a variant of breadth-first search. It repeatedly explores
alternatives at all depth levels and is thus best-suited to problems featuring
deep local minima. Experiments using a variety of popular search benchmarks
suggest that rectangle search is competitive with fixed-width beam search and
often performs better than the previous best anytime search algorithms.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12556" title="Abstract">arXiv:2312.12556</a> [<a href="/pdf/2312.12556" title="Download PDF">pdf</a>, <a href="/format/2312.12556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tensor Train Decomposition for Adversarial Attacks on Computer Vision  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chertkov%2C+A">Andrei Chertkov</a>, 
<a href="/search/math?searchtype=author&query=Oseledets%2C+I">Ivan Oseledets</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Deep neural networks (DNNs) are widely used today, but they are vulnerable to
adversarial attacks. To develop effective methods of defense, it is important
to understand the potential weak spots of DNNs. Often attacks are organized
taking into account the architecture of models (white-box approach) and based
on gradient methods, but for real-world DNNs this approach in most cases is
impossible. At the same time, several gradient-free optimization algorithms are
used to attack black-box models. However, classical methods are often
ineffective in the multidimensional case. To organize black-box attacks for
computer vision models, in this work, we propose the use of an optimizer based
on the low-rank tensor train (TT) format, which has gained popularity in
various practical multidimensional applications in recent years. Combined with
the attribution of the target image, which is built by the auxiliary
(white-box) model, the TT-based optimization method makes it possible to
organize an effective black-box attack by small perturbation of pixels in the
target image. The superiority of the proposed approach over three popular
baselines is demonstrated for five modern DNNs on the ImageNet dataset.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12558" title="Abstract">arXiv:2312.12558</a> [<a href="/pdf/2312.12558" title="Download PDF">pdf</a>, <a href="/format/2312.12558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample Efficient Reinforcement Learning with Partial Dynamics Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alharbi%2C+M">Meshal Alharbi</a>, 
<a href="/search/cs?searchtype=author&query=Roozbehani%2C+M">Mardavij Roozbehani</a>, 
<a href="/search/cs?searchtype=author&query=Dahleh%2C+M">Munther Dahleh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the 38th Annual AAAI Conference on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">The problem of sample complexity of online reinforcement learning is often
studied in the literature without taking into account any partial knowledge
about the system dynamics that could potentially accelerate the learning
process. In this paper, we study the sample complexity of online Q-learning
methods when some prior knowledge about the dynamics is available or can be
learned efficiently. We focus on systems that evolve according to an additive
disturbance model of the form $S_{h+1} = f(S_h, A_h) + W_h$, where $f$
represents the underlying system dynamics, and $W_h$ are unknown disturbances
independent of states and actions. In the setting of finite episodic Markov
decision processes with $S$ states, $A$ actions, and episode length $H$, we
present an optimistic Q-learning algorithm that achieves
$\tilde{\mathcal{O}}(\text{Poly}(H)\sqrt{T})$ regret under perfect knowledge of
$f$, where $T$ is the total number of interactions with the system. This is in
contrast to the typical $\tilde{\mathcal{O}}(\text{Poly}(H)\sqrt{SAT})$ regret
for existing Q-learning methods. Further, if only a noisy estimate $\hat{f}$ of
$f$ is available, our method can learn an approximately optimal policy in a
number of samples that is independent of the cardinalities of state and action
spaces. The sub-optimality gap depends on the approximation error $\hat{f}-f$,
as well as the Lipschitz constant of the corresponding optimal value function.
Our approach does not require modeling of the transition probabilities and
enjoys the same memory complexity as model-free methods.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12559" title="Abstract">arXiv:2312.12559</a> [<a href="/pdf/2312.12559" title="Download PDF">pdf</a>, <a href="/ps/2312.12559" title="Download PostScript">ps</a>, <a href="/format/2312.12559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Fairness: Alternative Moral Dimensions for Assessing Algorithms  and Designing Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wenzel%2C+K">Kimi Wenzel</a>, 
<a href="/search/cs?searchtype=author&query=Kaufman%2C+G">Geoff Kaufman</a>, 
<a href="/search/cs?searchtype=author&query=Dabbish%2C+L">Laura Dabbish</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at pluralism@CSCW workshop (Many Worlds of Ethics: Ethical Pluralism in CSCW) and M2@NeurIPS workshop (AI Meets Moral Philosophy and Moral Psychology: An Interdisciplinary Dialogue about Computational Ethics at NeurIPS) in 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">The ethics of artificial intelligence (AI) systems has risen as an imminent
concern across scholarly communities. This concern has propagated a great
interest in algorithmic fairness. Large research agendas are now devoted to
increasing algorithmic fairness, assessing algorithmic fairness, and
understanding human perceptions of fairness. We argue that there is an
overreliance on fairness as a single dimension of morality, which comes at the
expense of other important human values. Drawing from moral psychology, we
present five moral dimensions that go beyond fairness, and suggest three ways
these alternative dimensions may contribute to ethical AI development.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12560" title="Abstract">arXiv:2312.12560</a> [<a href="/pdf/2312.12560" title="Download PDF">pdf</a>, <a href="/format/2312.12560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comprehensive Validation on Reweighting Samples for Bias Mitigation via  AIF360
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blow%2C+C+H">Christina Hastings Blow</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+L">Lijun Qian</a>, 
<a href="/search/cs?searchtype=author&query=Gibson%2C+C">Camille Gibson</a>, 
<a href="/search/cs?searchtype=author&query=Obiomon%2C+P">Pamela Obiomon</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xishuang Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Fairness AI aims to detect and alleviate bias across the entire AI
development life cycle, encompassing data curation, modeling, evaluation, and
deployment-a pivotal aspect of ethical AI implementation. Addressing data bias,
particularly concerning sensitive attributes like gender and race, reweighting
samples proves efficient for fairness AI. This paper contributes a systematic
examination of reweighting samples for traditional machine learning (ML)
models, employing five models for binary classification on the Adult Income and
COMPUS datasets with various protected attributes. The study evaluates
prediction results using five fairness metrics, uncovering the nuanced and
model-specific nature of reweighting sample effectiveness in achieving fairness
in traditional ML models, as well as revealing the complexity of bias dynamics.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12561" title="Abstract">arXiv:2312.12561</a> [<a href="/pdf/2312.12561" title="Download PDF">pdf</a>, <a href="/ps/2312.12561" title="Download PostScript">ps</a>, <a href="/format/2312.12561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizations of data-driven balancing: what to sample for different  balancing-based reduced models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Reiter%2C+S">Sean Reiter</a>, 
<a href="/search/math?searchtype=author&query=Gosea%2C+I+V">Ion Victor Gosea</a>, 
<a href="/search/math?searchtype=author&query=Gugercin%2C+S">Serkan Gugercin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">The Quadrature-based Balanced Truncation (QuadBT) framework of
<a href="/abs/2104.01006">arXiv:2104.01006</a> is a "non-intrusive" reformulation of balanced truncation; a
classical projection-based model-order reduction technique for linear systems.
QuadBT is non-intrusive in the sense that it builds approximate balanced
reduced-order models entirely from system response data (e.g., transfer
function measurements) without the need to reference an explicit state-space
realization of the underlying full-order model. In this work, we generalize and
extend QuadBT to other types of balanced truncation model reduction. Namely, we
develop non-intrusive implementations for balanced stochastic truncation,
positive-real balanced truncation, and bounded-real balanced truncation. We
show that the data-driven construction of these balanced reduced-order models
requires sampling certain spectral factors associated with the system of
interest. Numerical examples are included in each case to validate our
approach.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12564" title="Abstract">arXiv:2312.12564</a> [<a href="/pdf/2312.12564" title="Download PDF">pdf</a>, <a href="/format/2312.12564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leading the Pack: N-player Opponent Shaping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Souly%2C+A">Alexandra Souly</a>, 
<a href="/search/cs?searchtype=author&query=Willi%2C+T">Timon Willi</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Akbir Khan</a>, 
<a href="/search/cs?searchtype=author&query=Kirk%2C+R">Robert Kirk</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chris Lu</a>, 
<a href="/search/cs?searchtype=author&query=Grefenstette%2C+E">Edward Grefenstette</a>, 
<a href="/search/cs?searchtype=author&query=Rockt%C3%A4schel%2C+T">Tim Rockt&#xe4;schel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Reinforcement learning solutions have great success in the 2-player general
sum setting. In this setting, the paradigm of Opponent Shaping (OS), in which
agents account for the learning of their co-players, has led to agents which
are able to avoid collectively bad outcomes, whilst also maximizing their
reward. These methods have currently been limited to 2-player game. However,
the real world involves interactions with many more agents, with interactions
on both local and global scales. In this paper, we extend Opponent Shaping (OS)
methods to environments involving multiple co-players and multiple shaping
agents. We evaluate on over 4 different environments, varying the number of
players from 3 to 5, and demonstrate that model-based OS methods converge to
equilibrium with better global welfare than naive learning. However, we find
that when playing with a large number of co-players, OS methods' relative
performance reduces, suggesting that in the limit OS methods may not perform
well. Finally, we explore scenarios where more than one OS method is present,
noticing that within games requiring a majority of cooperating agents, OS
methods converge to outcomes with poor global welfare.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12565" title="Abstract">arXiv:2312.12565</a> [<a href="/pdf/2312.12565" title="Download PDF">pdf</a>, <a href="/format/2312.12565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Precise Coil Alignment for Dynamic Wireless Charging of Electric  Vehicles with RFID Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haijian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R+Q">Rose Qingyang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Christensen%2C+R">Randy Christensen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE magazine for potential publication. 5 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Electric vehicle (EV) has emerged as a transformative force for the
sustainable and environmentally friendly future. To alleviate range anxiety
caused by battery and charging facility, dynamic wireless power transfer (DWPT)
is increasingly recognized as a key enabler for widespread EV adoption, yet it
faces significant technical challenges, primarily in precise coil alignment.
This article begins by reviewing current alignment methodologies and evaluates
their advantages and limitations. We observe that achieving the necessary
alignment precision is challenging with these existing methods. To address
this, we present an innovative RFID-based DWPT coil alignment system, utilizing
coherent phase detection and a maximum likelihood estimation algorithm, capable
of achieving sub-10 cm accuracy. This system's efficacy in providing both
lateral and vertical misalignment estimates has been verified through
laboratory and experimental tests. We also discuss potential challenges in
broader system implementation and propose corresponding solutions. This
research offers a viable and promising solution for enhancing DWPT efficiency.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12566" title="Abstract">arXiv:2312.12566</a> [<a href="/pdf/2312.12566" title="Download PDF">pdf</a>, <a href="/format/2312.12566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Johnsen-Rahbek Capstan Clutch: A High Torque Electrostatic Clutch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amish%2C+T+E">Timothy E. Amish</a>, 
<a href="/search/cs?searchtype=author&query=Auletta%2C+J+T">Jeffrey T. Auletta</a>, 
<a href="/search/cs?searchtype=author&query=Kessens%2C+C+C">Chad C. Kessens</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+J+R">Joshua R. Smith</a>, 
<a href="/search/cs?searchtype=author&query=Lipton%2C+J+I">Jeffrey I. Lipton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In many robotic systems, the holding state consumes power, limits operating
time, and increases operating costs. Electrostatic clutches have the potential
to improve robotic performance by generating holding torques with low power
consumption. The key limitation of electrostatic clutches has been their
limited ability to generate the holding torques, or high specific shear
stresses needed in many applications. Here we show how combining the
Johnsen-Rahbek (JR) effect with the exponential tension scaling capstan effect
can produce clutches with the highest specific shear stress in the literature.
Our system generated 31.3 N/cm^2 sheer stress and a total holding torque of 7.1
Nm while consuming only 2.5 mW/cm^2 at 500 V. We demonstrate a theoretical
model of an electrostatic adhesive capstan clutch and demonstrate how large
angle (theta &gt; 2 pi) designs increase efficiency over planar or small angle
(theta &lt; pi) clutch designs. We also report the first unfilled polymeric
material, polybenzimidazole (PBI), to exhibit the JR-effect.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12568" title="Abstract">arXiv:2312.12568</a> [<a href="/pdf/2312.12568" title="Download PDF">pdf</a>, <a href="/format/2312.12568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Opponent Shaping to High Dimensional Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Akbir Khan</a>, 
<a href="/search/cs?searchtype=author&query=Willi%2C+T">Timon Willi</a>, 
<a href="/search/cs?searchtype=author&query=Kwan%2C+N">Newton Kwan</a>, 
<a href="/search/cs?searchtype=author&query=Tacchetti%2C+A">Andrea Tacchetti</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chris Lu</a>, 
<a href="/search/cs?searchtype=author&query=Grefenstette%2C+E">Edward Grefenstette</a>, 
<a href="/search/cs?searchtype=author&query=Rockt%C3%A4schel%2C+T">Tim Rockt&#xe4;schel</a>, 
<a href="/search/cs?searchtype=author&query=Foerster%2C+J">Jakob Foerster</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In multi-agent settings with mixed incentives, methods developed for zero-sum
games have been shown to lead to detrimental outcomes. To address this issue,
opponent shaping (OS) methods explicitly learn to influence the learning
dynamics of co-players and empirically lead to improved individual and
collective outcomes. However, OS methods have only been evaluated in
low-dimensional environments due to the challenges associated with estimating
higher-order derivatives or scaling model-free meta-learning. Alternative
methods that scale to more complex settings either converge to undesirable
solutions or rely on unrealistic assumptions about the environment or
co-players. In this paper, we successfully scale an OS-based approach to
general-sum games with temporally-extended actions and long-time horizons for
the first time. After analysing the representations of the meta-state and
history used by previous algorithms, we propose a simplified version called
Shaper. We show empirically that Shaper leads to improved individual and
collective outcomes in a range of challenging settings from literature. We
further formalize a technique previously implicit in the literature, and
analyse its contribution to opponent shaping. We show empirically that this
technique is helpful for the functioning of prior methods in certain
environments. Lastly, we show that previous environments, such as the CoinGame,
are inadequate for analysing temporally-extended general-sum interactions.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12573" title="Abstract">arXiv:2312.12573</a> [<a href="/pdf/2312.12573" title="Download PDF">pdf</a>, <a href="/format/2312.12573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoK: Security of Cross-chain Bridges: Attack Surfaces, Defenses, and  Open Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaokuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Barbee%2C+J">Josh Barbee</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yinqian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhiqiang Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Cross-chain bridges are used to facilitate token and data exchanges across
blockchains. Although bridges are becoming increasingly popular, they are still
in their infancy and have been attacked multiple times recently, causing
significant financial loss. Although there are numerous reports online
explaining each of the incidents on cross-chain bridges, they are scattered
over the Internet, and there is no work that analyzes the security landscape of
cross-chain bridges in a holistic manner. To fill the gap, in this paper, we
performed a systematic study of cross-chain bridge security issues. First, we
summarize the characteristics of existing cross-chain bridges, including their
usages, verification mechanisms, communication models, and three
categorizations. Based on these characteristics, we identify 12 potential
attack vectors that attackers may exploit. Next, we introduce a taxonomy that
categorizes cross-chain attacks in the past two years into 10 distinct types,
and then provide explanations for each vulnerability type, accompanied by
Solidity code examples. We also discuss existing and potential defenses, as
well as open questions and future research directions on cross-chain bridges.
We believe that this systematization can shed light on designing and
implementing cross-chain bridges with higher security and, more importantly,
facilitating future research on building a better cross-chain bridge ecosystem.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12574" title="Abstract">arXiv:2312.12574</a> [<a href="/pdf/2312.12574" title="Download PDF">pdf</a>, <a href="/format/2312.12574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generator Assisted Mixture of Experts For Feature Acquisition in Batch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Asgaonkar%2C+V">Vedang Asgaonkar</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Aditya Jain</a>, 
<a href="/search/cs?searchtype=author&query=De%2C+A">Abir De</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Given a set of observations, feature acquisition is about finding the subset
of unobserved features which would enhance accuracy. Such problems have been
explored in a sequential setting in prior work. Here, the model receives
feedback from every new feature acquired and chooses to explore more features
or to predict. However, sequential acquisition is not feasible in some settings
where time is of the essence. We consider the problem of feature acquisition in
batch, where the subset of features to be queried in batch is chosen based on
the currently observed features, and then acquired as a batch, followed by
prediction. We solve this problem using several technical innovations. First,
we use a feature generator to draw a subset of the synthetic features for some
examples, which reduces the cost of oracle queries. Second, to make the feature
acquisition problem tractable for the large heterogeneous observed features, we
partition the data into buckets, by borrowing tools from locality sensitive
hashing and then train a mixture of experts model. Third, we design a tractable
lower bound of the original objective. We use a greedy algorithm combined with
model training to solve the underlying problem. Experiments with four datasets
show that our approach outperforms these methods in terms of trade-off between
accuracy and feature acquisition cost.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12575" title="Abstract">arXiv:2312.12575</a> [<a href="/pdf/2312.12575" title="Download PDF">pdf</a>, <a href="/format/2312.12575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Large Language Models Identify And Reason About Security  Vulnerabilities? Not Yet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ullah%2C+S">Saad Ullah</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+M">Mingji Han</a>, 
<a href="/search/cs?searchtype=author&query=Pujar%2C+S">Saurabh Pujar</a>, 
<a href="/search/cs?searchtype=author&query=Pearce%2C+H">Hammond Pearce</a>, 
<a href="/search/cs?searchtype=author&query=Coskun%2C+A">Ayse Coskun</a>, 
<a href="/search/cs?searchtype=author&query=Stringhini%2C+G">Gianluca Stringhini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have been suggested for use in automated
vulnerability repair, but benchmarks showing they can consistently identify
security-related bugs are lacking. We thus perform the most detailed
investigation to date on whether LLMs can reliably identify security-related
bugs. We construct a series of 228 code scenarios and analyze eight of the most
capable LLMs across eight different investigative dimensions in an automated
framework. Our evaluation shows LLMs provide non-deterministic responses,
incorrect and unfaithful reasoning, and perform poorly in real-world scenarios
outside their knowledge cut-off date. Most importantly, our findings reveal
significant non-robustness in even the most advanced models like `PaLM2' and
`GPT-4': by merely changing function or variable names, or by the addition of
library functions in the source code, these models can yield incorrect answers
in 26% and 17% of cases, respectively. These findings demonstrate that further
LLM advances are needed before LLMs can be used as general purpose security
assistants.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12577" title="Abstract">arXiv:2312.12577</a> [<a href="/pdf/2312.12577" title="Download PDF">pdf</a>, <a href="/format/2312.12577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An integrated EOS, pore-crush, strength and damage model framework for  near-field ground-shock
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bennett%2C+K+C">Kane C. Bennett</a>, 
<a href="/search/cs?searchtype=author&query=Stahl%2C+A+M">Alyson M. Stahl</a>, 
<a href="/search/cs?searchtype=author&query=Canfield%2C+T+R">Thomas R. Canfield</a>, 
<a href="/search/cs?searchtype=author&query=Euler%2C+G+G">Garrett G. Euler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">An integrated Equation of State (EOS) and strength/pore-crush/damage model
framework is provided for modeling near to source (near-field) ground-shock
response, where large deformations and pressures necessitate coupling EOS with
pressure-dependent plastic yield and damage. Nonlinear pressure-dependence of
strength up to high-pressures is combined with a Modified Cam-Clay-like
cap-plasticity model in a way to allow degradation of strength from pore-crush
damage, what we call the ``Yp-Cap'' model. Nonlinear hardening under compaction
allows modeling the crush-out of pores in combination with a fully saturated
EOS, i.e., for modeling partially saturated ground-shock response, where
air-filled voids crush. Attention is given to algorithmic clarity and
efficiency of the provided model, and the model is employed in example
numerical simulations, including finite element simulations of underground
explosions to exemplify its robustness and utility.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12578" title="Abstract">arXiv:2312.12578</a> [<a href="/pdf/2312.12578" title="Download PDF">pdf</a>, <a href="/format/2312.12578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the Expressive Power of Deep Neural Networks through Integral  Activation Transform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zezhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+F">Feng Bao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guannan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The impressive expressive power of deep neural networks (DNNs) underlies
their widespread applicability. However, while the theoretical capacity of deep
architectures is high, the practical expressive power achieved through
successful training often falls short. Building on the insights gained from
Neural ODEs, which explore the depth of DNNs as a continuous variable, in this
work, we generalize the traditional fully connected DNN through the concept of
continuous width. In the Generalized Deep Neural Network (GDNN), the
traditional notion of neurons in each layer is replaced by a continuous state
function. Using the finite rank parameterization of the weight integral kernel,
we establish that GDNN can be obtained by employing the Integral Activation
Transform (IAT) as activation layers within the traditional DNN framework. The
IAT maps the input vector to a function space using some basis functions,
followed by nonlinear activation in the function space, and then extracts
information through the integration with another collection of basis functions.
A specific variant, IAT-ReLU, featuring the ReLU nonlinearity, serves as a
smooth generalization of the scalar ReLU activation. Notably, IAT-ReLU exhibits
a continuous activation pattern when continuous basis functions are employed,
making it smooth and enhancing the trainability of the DNN. Our numerical
experiments demonstrate that IAT-ReLU outperforms regular ReLU in terms of
trainability and better smoothness.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12582" title="Abstract">arXiv:2312.12582</a> [<a href="/pdf/2312.12582" title="Download PDF">pdf</a>, <a href="/ps/2312.12582" title="Download PostScript">ps</a>, <a href="/format/2312.12582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Discontinuous Galerkin Method for Optimal Control of the Obstacle  Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Antil%2C+H">Harbir Antil</a>, 
<a href="/search/math?searchtype=author&query=Khandelwal%2C+R">Rohit Khandelwal</a>, 
<a href="/search/math?searchtype=author&query=Rakhimov%2C+U">Umarkhon Rakhimov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This article provides quasi-optimal a priori error estimates for an optimal
control problem constrained by an elliptic obstacle problem where the finite
element discretization is carried out using the symmetric interior penalty
discontinuous Galerkin method. The main proofs are based on the improved
$L^2$-error estimates for the obstacle problem, the discrete maximum principle,
and a well-known quadratic growth property. The standard (restrictive)
assumptions on mesh are not assumed here.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12583" title="Abstract">arXiv:2312.12583</a> [<a href="/pdf/2312.12583" title="Download PDF">pdf</a>, <a href="/format/2312.12583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Observation-Augmented Contextual Multi-Armed Bandits for Robotic  Exploration with Uncertain Semantic Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wakayama%2C+S">Shohei Wakayama</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+N">Nisar Ahmed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">For robotic decision-making under uncertainty, the balance between
exploitation and exploration of available options must be carefully taken into
account. In this study, we introduce a new variant of contextual multi-armed
bandits called observation-augmented CMABs (OA-CMABs) wherein a decision-making
agent can utilize extra outcome observations from an external information
source. CMABs model the expected option outcomes as a function of context
features and hidden parameters, which are inferred from previous option
outcomes. In OA-CMABs, external observations are also a function of context
features and thus provide additional evidence about the hidden parameters. Yet,
if an external information source is error-prone, the resulting posterior
updates can harm decision-making performance unless the presence of errors is
considered. To this end, we propose a robust Bayesian inference process for
OA-CMABs that is based on the concept of probabilistic data validation. Our
approach handles complex mixture model parameter priors and hybrid observation
likelihoods for semantic data sources, allowing us to develop validation
algorithms based on recently develop probabilistic semantic data association
techniques. Furthermore, to more effectively cope with the combined sources of
uncertainty in OA-CMABs, we derive a new active inference algorithm for option
selection based on expected free energy minimization. This generalizes previous
work on active inference for bandit-based robotic decision-making by accounting
for faulty observations and non-Gaussian inference. Our approaches are
demonstrated on a simulated asynchronous search site selection problem for
space exploration. The results show that even if incorrect observations are
provided by external information sources, efficient decision-making and robust
parameter inference are still achieved in a wide variety of experimental
conditions.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12584" title="Abstract">arXiv:2312.12584</a> [<a href="/pdf/2312.12584" title="Download PDF">pdf</a>, <a href="/ps/2312.12584" title="Download PostScript">ps</a>, <a href="/format/2312.12584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Faster Combinatorial Algorithm for Maximum Bipartite Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chuzhoy%2C+J">Julia Chuzhoy</a>, 
<a href="/search/cs?searchtype=author&query=Khanna%2C+S">Sanjeev Khanna</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">The maximum bipartite matching problem is among the most fundamental and
well-studied problems in combinatorial optimization. A beautiful and celebrated
combinatorial algorithm of Hopcroft and Karp (1973) shows that maximum
bipartite matching can be solved in $O(m \sqrt{n})$ time on a graph with $n$
vertices and $m$ edges. For the case of very dense graphs, a fast matrix
multiplication based approach gives a running time of $O(n^{2.371})$. These
results represented the fastest known algorithms for the problem until 2013,
when Madry introduced a new approach based on continuous techniques achieving
much faster runtime in sparse graphs. This line of research has culminated in a
spectacular recent breakthrough due to Chen et al. (2022) that gives an
$m^{1+o(1)}$ time algorithm for maximum bipartite matching (and more generally,
for min cost flows).
<br />This raises a natural question: are continuous techniques essential to
obtaining fast algorithms for the bipartite matching problem? Our work makes
progress on this question by presenting a new, purely combinatorial algorithm
for bipartite matching, that runs in $\tilde{O}(m^{1/3}n^{5/3})$ time, and
hence outperforms both Hopcroft-Karp and the fast matrix multiplication based
algorithms on moderately dense graphs. Using a standard reduction, we also
obtain an $\tilde{O}(m^{1/3}n^{5/3})$ time deterministic algorithm for maximum
vertex-capacitated $s$-$t$ flow in directed graphs when all vertex capacities
are identical.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12585" title="Abstract">arXiv:2312.12585</a> [<a href="/pdf/2312.12585" title="Download PDF">pdf</a>, <a href="/format/2312.12585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BadRL: Sparse Targeted Backdoor Attack Against Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jing Cui</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yufei Han</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yuzhe Ma</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+J">Jianbin Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junge Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of the submission accepted by AAAI 2024. It is revised by integrating review comments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Backdoor attacks in reinforcement learning (RL) have previously employed
intense attack strategies to ensure attack success. However, these methods
suffer from high attack costs and increased detectability. In this work, we
propose a novel approach, BadRL, which focuses on conducting highly sparse
backdoor poisoning efforts during training and testing while maintaining
successful attacks. Our algorithm, BadRL, strategically chooses state
observations with high attack values to inject triggers during training and
testing, thereby reducing the chances of detection. In contrast to the previous
methods that utilize sample-agnostic trigger patterns, BadRL dynamically
generates distinct trigger patterns based on targeted state observations,
thereby enhancing its effectiveness. Theoretical analysis shows that the
targeted backdoor attack is always viable and remains stealthy under specific
assumptions. Empirical results on various classic RL tasks illustrate that
BadRL can substantially degrade the performance of a victim agent with minimal
poisoning efforts 0.003% of total training steps) during training and
infrequent attacks during testing.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12586" title="Abstract">arXiv:2312.12586</a> [<a href="/pdf/2312.12586" title="Download PDF">pdf</a>, <a href="/ps/2312.12586" title="Download PostScript">ps</a>, <a href="/format/2312.12586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards dynamic Narrow path walking on NU&#x27;s Husky
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+K+V">Kaushik Venkatesh Krishnamurthy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 60 pages, 27 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This research focuses on enabling Northeastern University's Husky, a
multi-modal quadrupedal robot, to navigate narrow paths akin to various animals
in nature. The Husky is equipped with thrusters to stabilize its body during
dynamic maneuvers, addressing challenges inherent in aerial-legged systems. The
approach involves modeling the robot as HROM (Husky Reduced Model) and creating
an optimal control framework using linearized dynamics for narrow path walking.
The thesis introduces a gait scheduling method to generate an open-loop walking
gait and validates these gaits through a high-fidelity Simscape simulation.
Experimental results of the open-loop walking are presented, accompanied by
potential directions for advancing this robotic system.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12588" title="Abstract">arXiv:2312.12588</a> [<a href="/pdf/2312.12588" title="Download PDF">pdf</a>, <a href="/format/2312.12588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical study of Unsupervised Neural Machine Translation: analyzing  NMT output, model&#x27;s behavior and sentences&#x27; contribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tourni%2C+I+C">Isidora Chara Tourni</a>, 
<a href="/search/cs?searchtype=author&query=Wijaya%2C+D">Derry Wijaya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Unsupervised Neural Machine Translation (UNMT) focuses on improving NMT
results under the assumption there is no human translated parallel data, yet
little work has been done so far in highlighting its advantages compared to
supervised methods and analyzing its output in aspects other than translation
accuracy. We focus on three very diverse languages, French, Gujarati, and
Kazakh, and train bilingual NMT models, to and from English, with various
levels of supervision, in high- and low- resource setups, measure quality of
the NMT output and compare the generated sequences' word order and semantic
similarity to source and reference sentences. We also use Layer-wise Relevance
Propagation to evaluate the source and target sentences' contribution to the
result, expanding the findings of previous works to the UNMT paradigm.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12589" title="Abstract">arXiv:2312.12589</a> [<a href="/pdf/2312.12589" title="Download PDF">pdf</a>, <a href="/format/2312.12589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 400Gbps benchmark of XRootD HTTP-TPC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arora%2C+A">Aashay Arora</a>, 
<a href="/search/cs?searchtype=author&query=Guiang%2C+J">Jonathan Guiang</a>, 
<a href="/search/cs?searchtype=author&query=Davila%2C+D">Diego Davila</a>, 
<a href="/search/cs?searchtype=author&query=W%C3%BCrthwein%2C+F">Frank W&#xfc;rthwein</a>, 
<a href="/search/cs?searchtype=author&query=Balcas%2C+J">Justas Balcas</a>, 
<a href="/search/cs?searchtype=author&query=Newman%2C+H">Harvey Newman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, submitted to CHEP'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Due to the increased demand of network traffic expected during the HL-LHC
era, the T2 sites in the USA will be required to have 400Gbps of available
bandwidth to their storage solution. With the above in mind we are pursuing a
scale test of XRootD software when used to perform Third Party Copy transfers
using the HTTP protocol. Our main objective is to understand the possible
limitations in the software stack to achieve the target transfer rate; to that
end we have set up a testbed of multiple XRootD servers in both UCSD and
Caltech which are connected through a dedicated link capable of 400 Gbps
end-to-end. Building upon our experience deploying containerized XRootD
servers, we use Kubernetes to easily deploy and test different configurations
of our testbed. In this work, we will present our experience doing these tests
and the lessons learned.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12597" title="Abstract">arXiv:2312.12597</a> [<a href="/pdf/2312.12597" title="Download PDF">pdf</a>, <a href="/format/2312.12597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Machine Learning by Transforming and Augmenting Imperfect  Training Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Creager%2C+E">Elliot Creager</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A thesis submitted in conformity with the requirements for the degree of Doctor of Philosophy, Department of Computer Science, University of Toronto
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Machine Learning (ML) is an expressive framework for turning data into
computer programs. Across many problem domains -- both in industry and policy
settings -- the types of computer programs needed for accurate prediction or
optimal control are difficult to write by hand. On the other hand, collecting
instances of desired system behavior may be relatively more feasible. This
makes ML broadly appealing, but also induces data sensitivities that often
manifest as unexpected failure modes during deployment. In this sense, the
training data available tend to be imperfect for the task at hand. This thesis
explores several data sensitivities of modern machine learning and how to
address them. We begin by discussing how to prevent ML from codifying prior
human discrimination measured in the training data, where we take a fair
representation learning approach. We then discuss the problem of learning from
data containing spurious features, which provide predictive fidelity during
training but are unreliable upon deployment. Here we observe that insofar as
standard training methods tend to learn such features, this propensity can be
leveraged to search for partitions of training data that expose this
inconsistency, ultimately promoting learning algorithms invariant to spurious
features. Finally, we turn our attention to reinforcement learning from data
with insufficient coverage over all possible states and actions. To address the
coverage issue, we discuss how causal priors can be used to model the
single-step dynamics of the setting where data are collected. This enables a
new type of data augmentation where observed trajectories are stitched together
to produce new but plausible counterfactual trajectories.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12598" title="Abstract">arXiv:2312.12598</a> [<a href="/pdf/2312.12598" title="Download PDF">pdf</a>, <a href="/format/2312.12598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Case Study on Test Case Construction with Large Language Models:  Unveiling Practical Insights and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Lima+Junior%2C+R+F">Roberto Francisco de Lima Junior</a>, 
<a href="/search/cs?searchtype=author&query=de+Barros+Presta%2C+L+F+P">Luiz Fernando Paes de Barros Presta</a>, 
<a href="/search/cs?searchtype=author&query=Borborema%2C+L+S">Lucca Santos Borborema</a>, 
<a href="/search/cs?searchtype=author&query=da+Silva%2C+V+N">Vanderson Nogueira da Silva</a>, 
<a href="/search/cs?searchtype=author&query=de+Melo+Dahia%2C+M+L">Marcio Leal de Melo Dahia</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+A+C+S+e">Anderson Carlos Sousa e Santos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents a detailed case study examining the application of Large
Language Models (LLMs) in the construction of test cases within the context of
software engineering. LLMs, characterized by their advanced natural language
processing capabilities, are increasingly garnering attention as tools to
automate and enhance various aspects of the software development lifecycle.
Leveraging a case study methodology, we systematically explore the integration
of LLMs in the test case construction process, aiming to shed light on their
practical efficacy, challenges encountered, and implications for software
quality assurance.
<br />The study encompasses the selection of a representative software application,
the formulation of test case construction methodologies employing LLMs, and the
subsequent evaluation of outcomes. Through a blend of qualitative and
quantitative analyses, we assess the impact of LLMs on test case
comprehensiveness, accuracy, and efficiency. Additionally, we delve into
challenges such as model interpretability, ethical considerations, and
adaptation to diverse software contexts.
<br />The findings from this case study contribute nuanced insights into the
practical utility of LLMs in the domain of test case construction, elucidating
their potential benefits and limitations. By addressing real-world scenarios
and complexities, this research aims to inform software practitioners and
researchers alike about the tangible implications of incorporating LLMs into
the software testing landscape, fostering a more comprehensive understanding of
their role in optimizing the software development process.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12600" title="Abstract">arXiv:2312.12600</a> [<a href="/pdf/2312.12600" title="Download PDF">pdf</a>, <a href="/format/2312.12600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Behind the Intent of Extract Method Refactoring: A Systematic Literature  Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=AlOmar%2C+E+A">Eman Abdullah AlOmar</a>, 
<a href="/search/cs?searchtype=author&query=Mkaouer%2C+M+W">Mohamed Wiem Mkaouer</a>, 
<a href="/search/cs?searchtype=author&query=Ouni%2C+A">Ali Ouni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Code refactoring is widely recognized as an essential software engineering
practice to improve the understandability and maintainability of the source
code. The Extract Method refactoring is considered as "Swiss army knife" of
refactorings, as developers often apply it to improve their code quality. In
recent years, several studies attempted to recommend Extract Method
refactorings allowing the collection, analysis, and revelation of actionable
data-driven insights about refactoring practices within software projects. In
this paper, we aim at reviewing the current body of knowledge on existing
Extract Method refactoring research and explore their limitations and potential
improvement opportunities for future research efforts. Hence, researchers and
practitioners begin to be aware of the state-of-the-art and identify new
research opportunities in this context. We review the body of knowledge related
to Extract Method refactoring in the form of a systematic literature review
(SLR). After compiling an initial pool of 1,367 papers, we conducted a
systematic selection and our final pool included 83 primary studies. We define
three sets of research questions and systematically develop and refine a
classification schema based on several criteria including their methodology,
applicability, and degree of automation. The results construct a catalog of 83
Extract Method approaches indicating that several techniques have been proposed
in the literature. Our results show that: (i) 38.6% of Extract Method
refactoring studies primarily focus on addressing code clones; (ii) Several of
the Extract Method tools incorporate the developer's involvement in the
decision-making process when applying the method extraction, and (iii) the
existing benchmarks are heterogeneous and do not contain the same type of
information, making standardizing them for the purpose of benchmarking
difficult.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12604" title="Abstract">arXiv:2312.12604</a> [<a href="/pdf/2312.12604" title="Download PDF">pdf</a>, <a href="/ps/2312.12604" title="Download PostScript">ps</a>, <a href="/format/2312.12604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Studying the Practices of Testing Machine Learning Software in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Openja%2C+M">Moses Openja</a>, 
<a href="/search/cs?searchtype=author&query=Khomh%2C+F">Foutse Khomh</a>, 
<a href="/search/cs?searchtype=author&query=Foundjem%2C+A">Armstrong Foundjem</a>, 
<a href="/search/cs?searchtype=author&query=Ming%2C+Z">Zhen Ming</a> (Jack)
<a href="/search/cs?searchtype=author&query=Jiang">Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Abidi%2C+M">Mouna Abidi</a>, 
<a href="/search/cs?searchtype=author&query=Hassan%2C+A+E">Ahmed E. Hassan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Background: We are witnessing an increasing adoption of machine learning
(ML), especially deep learning (DL) algorithms in many software systems,
including safety-critical systems such as health care systems or autonomous
driving vehicles. Ensuring the software quality of these systems is yet an open
challenge for the research community, mainly due to the inductive nature of ML
software systems. Traditionally, software systems were constructed deductively,
by writing down the rules that govern the behavior of the system as program
code. However, for ML software, these rules are inferred from training data.
Few recent research advances in the quality assurance of ML systems have
adapted different concepts from traditional software testing, such as mutation
testing, to help improve the reliability of ML software systems. However, it is
unclear if any of these proposed testing techniques from research are adopted
in practice. There is little empirical evidence about the testing strategies of
ML engineers. Aims: To fill this gap, we perform the first fine-grained
empirical study on ML testing practices in the wild, to identify the ML
properties being tested, the followed testing strategies, and their
implementation throughout the ML workflow. Method: First, we systematically
summarized the different testing strategies (e.g., Oracle Approximation), the
tested ML properties (e.g., Correctness, Bias, and Fairness), and the testing
methods (e.g., Unit test) from the literature. Then, we conducted a study to
understand the practices of testing ML software. Results: In our findings: 1)
we identified four (4) major categories of testing strategy including Grey-box,
White-box, Black-box, and Heuristic-based techniques that are used by the ML
engineers to find software bugs. 2) We identified 16 ML properties that are
tested in the ML workflow.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12606" title="Abstract">arXiv:2312.12606</a> [<a href="/pdf/2312.12606" title="Download PDF">pdf</a>, <a href="/format/2312.12606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Neural Networks with Gradient Lexicase Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Li Ding</a>, 
<a href="/search/cs?searchtype=author&query=Spector%2C+L">Lee Spector</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2022
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Conference on Learning Representations (2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">One potential drawback of using aggregated performance measurement in machine
learning is that models may learn to accept higher errors on some training
cases as compromises for lower errors on others, with the lower errors actually
being instances of overfitting. This can lead to both stagnation at local
optima and poor generalization. Lexicase selection is an uncompromising method
developed in evolutionary computation, which selects models on the basis of
sequences of individual training case errors instead of using aggregated
metrics such as loss and accuracy. In this paper, we investigate how lexicase
selection, in its general form, can be integrated into the context of deep
learning to enhance generalization. We propose Gradient Lexicase Selection, an
optimization framework that combines gradient descent and lexicase selection in
an evolutionary fashion. Our experimental results demonstrate that the proposed
method improves the generalization performance of various widely-used deep
neural network architectures across three image classification benchmarks.
Additionally, qualitative analysis suggests that our method assists networks in
learning more diverse representations. Our source code is available on GitHub:
https://github.com/ld-ing/gradient-lexicase.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12608" title="Abstract">arXiv:2312.12608</a> [<a href="/pdf/2312.12608" title="Download PDF">pdf</a>, <a href="/format/2312.12608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trust, But Verify: A Survey of Randomized Smoothing Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumari%2C+A">Anupriya Kumari</a>, 
<a href="/search/cs?searchtype=author&query=Bhardwaj%2C+D">Devansh Bhardwaj</a>, 
<a href="/search/cs?searchtype=author&query=Jindal%2C+S">Sukrit Jindal</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Sarthak Gupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Machine Learning (stat.ML)

</div>
<p class="mathjax">Machine learning models have demonstrated remarkable success across diverse
domains but remain vulnerable to adversarial attacks. Empirical defence
mechanisms often fall short, as new attacks constantly emerge, rendering
existing defences obsolete. A paradigm shift from empirical defences to
certification-based defences has been observed in response. Randomized
smoothing has emerged as a promising technique among notable advancements. This
study reviews the theoretical foundations, empirical effectiveness, and
applications of randomized smoothing in verifying machine learning classifiers.
We provide an in-depth exploration of the fundamental concepts underlying
randomized smoothing, highlighting its theoretical guarantees in certifying
robustness against adversarial perturbations. Additionally, we discuss the
challenges of existing methodologies and offer insightful perspectives on
potential solutions. This paper is novel in its attempt to systemise the
existing knowledge in the context of randomized smoothing.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12611" title="Abstract">arXiv:2312.12611</a> [<a href="/pdf/2312.12611" title="Download PDF">pdf</a>, <a href="/ps/2312.12611" title="Download PostScript">ps</a>, <a href="/format/2312.12611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Semi-Analytical Approach for State-Space Electromagnetic Transient  Simulation Using the Differential Transformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xiong%2C+M">Min Xiong</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+K">Kaiyang Huang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/eess?searchtype=author&query=Yao%2C+R">Rui Yao</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+K">Kai Sun</a>, 
<a href="/search/eess?searchtype=author&query=Qiu%2C+F">Feng Qiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Dynamical Systems (math.DS); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Electromagnetic transient (EMT) simulation is a crucial tool for power system
dynamic analysis because of its detailed component modeling and high simulation
accuracy. However, it suffers from computational burdens for large power grids
since a tiny time step is typically required for accuracy. This paper proposes
an efficient and accurate semi-analytical approach for state-space EMT
simulations of power grids. It employs high-order semi-analytical solutions
derived using the differential transformation from the state-space EMT grid
model. The approach incorporates a proposed variable time step strategy based
on equation imbalance, leveraging structural information of the grid model, to
enlarge the time step and accelerate simulations, while high resolution is
maintained by reconstructing detailed fast EMT dynamics through an efficient
dense output mechanism. It also addresses limit-induced switches during large
time steps by using a binary search-enhanced quadratic interpolation algorithm.
Case studies are conducted on EMT models of the IEEE 39-bus system and a
synthetic 390-bus system to demonstrate the merits of the new simulation
approach against traditional methods.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12619" title="Abstract">arXiv:2312.12619</a> [<a href="/pdf/2312.12619" title="Download PDF">pdf</a>, <a href="/format/2312.12619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Vision Transformers for Context-Aware Prostate Cancer  Grading in Whole Slide Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grisi%2C+C">Cl&#xe9;ment Grisi</a>, 
<a href="/search/cs?searchtype=author&query=Litjens%2C+G">Geert Litjens</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Laak%2C+J">Jeroen van der Laak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Medical Imaging meets NeurIPS 2023 workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Vision Transformers (ViTs) have ushered in a new era in computer vision,
showcasing unparalleled performance in many challenging tasks. However, their
practical deployment in computational pathology has largely been constrained by
the sheer size of whole slide images (WSIs), which result in lengthy input
sequences. Transformers faced a similar limitation when applied to long
documents, and Hierarchical Transformers were introduced to circumvent it.
Given the analogous challenge with WSIs and their inherent hierarchical
structure, Hierarchical Vision Transformers (H-ViTs) emerge as a promising
solution in computational pathology. This work delves into the capabilities of
H-ViTs, evaluating their efficiency for prostate cancer grading in WSIs. Our
results show that they achieve competitive performance against existing
state-of-the-art solutions.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12620" title="Abstract">arXiv:2312.12620</a> [<a href="/pdf/2312.12620" title="Download PDF">pdf</a>, <a href="/ps/2312.12620" title="Download PostScript">ps</a>, <a href="/format/2312.12620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;It Can Relate to Real Lives&quot;: Attitudes and Expectations in  Justice-Centered Data Structures &amp; Algorithms for Non-Majors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Batra%2C+A">Anna Batra</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+I">Iris Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S+Y">Suh Young Choi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chongjiu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yanbing Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Fereidooni%2C+S">Sonia Fereidooni</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kevin Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Experience Reports and Tools paper in the Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1 (SIGCSE 2024); 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Prior work has argued for a more justice-centered approach to postsecondary
computing education by emphasizing ethics, identity, and political vision. In
this experience report, we examine how postsecondary students of diverse gender
and racial identities experience a justice-centered Data Structures and
Algorithms designed for undergraduate non-computer science majors. Through a
quantitative and qualitative analysis of two quarters of student survey data
collected at the start and end of each quarter, we report on student attitudes
and expectations.
<br />Across the class, we found a significant increase in the following attitudes:
computing confidence and sense of belonging. While women, non-binary, and other
students not identifying as men (WNB+) also increased in these areas, they
still reported significantly lower confidence and sense of belonging than men
at the end of the quarter. Black, Latinx, Middle Eastern and North African,
Native American, and Pacific Islander (BLMNPI) students had no significant
differences compared to white and Asian students.
<br />We also analyzed end-of-quarter student self-reflections on their fulfillment
of expectations prior to taking the course. While the majority of students
reported a positive overall sentiment about the course and many students
specifically appreciated the justice-centered approach, some desired more
practice with program implementation and interview preparation. We discuss
implications for practice and articulate a political vision for holding both
appreciation for computing ethics and a desire for professional preparation
together through iterative design.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12621" title="Abstract">arXiv:2312.12621</a> [<a href="/pdf/2312.12621" title="Download PDF">pdf</a>, <a href="/format/2312.12621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blox: A Modular Toolkit for Deep Learning Schedulers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+S">Saurabh Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Phanishayee%2C+A">Amar Phanishayee</a>, 
<a href="/search/cs?searchtype=author&query=Venkataraman%2C+S">Shivaram Venkataraman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be presented at Eurosys'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Deep Learning (DL) workloads have rapidly increased in popularity in
enterprise clusters and several new cluster schedulers have been proposed in
recent years to support these workloads. With rapidly evolving DL workloads, it
is challenging to quickly prototype and compare scheduling policies across
workloads. Further, as prior systems target different aspects of scheduling
(resource allocation, placement, elasticity etc.), it is also challenging to
combine these techniques and understand the overall benefits. To address these
challenges we propose Blox, a modular toolkit which allows developers to
compose individual components and realize diverse scheduling frameworks. We
identify a set of core abstractions for DL scheduling, implement several
existing schedulers using these abstractions, and verify the fidelity of these
implementations by reproducing results from prior research. We also highlight
how we can evaluate and compare existing schedulers in new settings: different
workload traces, higher cluster load, change in DNN workloads and deployment
characteristics. Finally, we showcase Blox's extensibility by composing
policies from different schedulers, and implementing novel policies with
minimal code changes. Blox is available at
\url{https://github.com/msr-fiddle/blox}.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12624" title="Abstract">arXiv:2312.12624</a> [<a href="/pdf/2312.12624" title="Download PDF">pdf</a>, <a href="/format/2312.12624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building a Llama2-finetuned LLM for Odia Language Utilizing Domain  Knowledge Instruction Set
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kohli%2C+G+S">Guneet Singh Kohli</a>, 
<a href="/search/cs?searchtype=author&query=Parida%2C+S">Shantipriya Parida</a>, 
<a href="/search/cs?searchtype=author&query=Sekhar%2C+S">Sambit Sekhar</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+S">Samirit Saha</a>, 
<a href="/search/cs?searchtype=author&query=Nair%2C+N+B">Nipun B Nair</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+P">Parul Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Khosla%2C+S">Sonal Khosla</a>, 
<a href="/search/cs?searchtype=author&query=Patiyal%2C+K">Kusumlata Patiyal</a>, 
<a href="/search/cs?searchtype=author&query=Dhal%2C+D">Debasish Dhal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Building LLMs for languages other than English is in great demand due to the
unavailability and performance of multilingual LLMs, such as understanding the
local context. The problem is critical for low-resource languages due to the
need for instruction sets. In a multilingual country like India, there is a
need for LLMs supporting Indic languages to provide generative AI and LLM-based
technologies and services to its citizens.
<br />This paper presents our approach of i) generating a large Odia instruction
set, including domain knowledge data suitable for LLM fine-tuning, and ii)
building a Llama2-finetuned model tailored for enhanced performance in the Odia
domain. The proposed work will help researchers build an instruction set and
LLM, particularly for Indic languages. We will release the model and
instruction set for the public for research and noncommercial purposes.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12633" title="Abstract">arXiv:2312.12633</a> [<a href="/pdf/2312.12633" title="Download PDF">pdf</a>, <a href="/format/2312.12633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long-run Behaviour of Multi-fidelity Bayesian Optimisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dovonon%2C+G+J">Gbetondji J-S Dovonon</a>, 
<a href="/search/cs?searchtype=author&query=Zeitler%2C+J">Jakob Zeitler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Workshop on Adaptive Experimental Design and Active Learning in the Real World
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Multi-fidelity Bayesian Optimisation (MFBO) has been shown to generally
converge faster than single-fidelity Bayesian Optimisation (SFBO) (Poloczek et
al. (2017)). Inspired by recent benchmark papers, we are investigating the
long-run behaviour of MFBO, based on observations in the literature that it
might under-perform in certain scenarios (Mikkola et al. (2023), Eggensperger
et al. (2021)). An under-performance of MBFO in the long-run could
significantly undermine its application to many research tasks, especially when
we are not able to identify when the under-performance begins. We create a
simple benchmark study, showcase empirical results and discuss scenarios and
possible reasons of under-performance.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12634" title="Abstract">arXiv:2312.12634</a> [<a href="/pdf/2312.12634" title="Download PDF">pdf</a>, <a href="/format/2312.12634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MotionScript: Natural Language Descriptions for Expressive 3D Human  Motions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yazdian%2C+P+J">Payam Jome Yazdian</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+E">Eric Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Li Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+A">Angelica Lim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Robotics (cs.RO)

</div>
<p class="mathjax">This paper proposes MotionScript, a motion-to-text conversion algorithm and
natural language representation for human body motions. MotionScript aims to
describe movements in greater detail and with more accuracy than previous
natural language approaches. Many motion datasets describe relatively objective
and simple actions with little variation on the way they are expressed (e.g.
sitting, walking, dribbling a ball). But for expressive actions that contain a
diversity of movements in the class (e.g. being sad, dancing), or for actions
outside the domain of standard motion capture datasets (e.g. stylistic walking,
sign-language), more specific and granular natural language descriptions are
needed. Our proposed MotionScript descriptions differ from existing natural
language representations in that it provides direct descriptions in natural
language instead of simple action labels or high-level human captions. To the
best of our knowledge, this is the first attempt at translating 3D motions to
natural language descriptions without requiring training data. Our experiments
show that when MotionScript representations are used in a text-to-motion neural
task, body movements are more accurately reconstructed, and large language
models can be used to generate unseen complex motions.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12635" title="Abstract">arXiv:2312.12635</a> [<a href="/pdf/2312.12635" title="Download PDF">pdf</a>, <a href="/format/2312.12635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RealCraft: Attention Control as A Solution for Zero-shot Long Video  Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shutong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruiyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pokorny%2C+F+T">Florian T. Pokorny</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Although large-scale text-to-image generative models have shown promising
performance in synthesizing high-quality images, directly applying these models
to image editing remains a significant challenge. This challenge is further
amplified in video editing due to the additional dimension of time. Especially
for editing real videos as it necessitates maintaining a stable semantic layout
across the frames while executing localized edits precisely without disrupting
the existing backgrounds. In this paper, we propose \textit{RealCraft}, an
attention-control-based method for zero-shot editing in real videos. By
employing the object-centric manipulation of cross-attention between prompts
and frames and spatial-temporal attention within the frames, we achieve precise
shape-wise editing along with enhanced consistency. Our model can be used
directly with Stable Diffusion and operates without the need for additional
localized information. We showcase our zero-shot attention-control-based method
across a range of videos, demonstrating localized, high-fidelity, shape-precise
and time-consistent editing in videos of various lengths, up to 64 frames.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12637" title="Abstract">arXiv:2312.12637</a> [<a href="/pdf/2312.12637" title="Download PDF">pdf</a>, <a href="/format/2312.12637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain-Independent Disperse and Pick method for Robotic Grasping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raj%2C+P">Prem Raj</a>, 
<a href="/search/cs?searchtype=author&query=Singhal%2C+A">Aniruddha Singhal</a>, 
<a href="/search/cs?searchtype=author&query=Sanap%2C+V">Vipul Sanap</a>, 
<a href="/search/cs?searchtype=author&query=Behera%2C+L">L. Behera</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+R">Rajesh Sinha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at 2022 International Joint Conference on Neural Networks (IJCNN)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 10.1109/IJCNN55064.2022.9892672
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Picking unseen objects from clutter is a difficult problem because of the
variability in objects (shape, size, and material) and occlusion due to
clutter. As a result, it becomes difficult for grasping methods to segment the
objects properly and they fail to singulate the object to be picked. This may
result in grasp failure or picking of multiple objects together in a single
attempt. A push-to-move action by the robot will be beneficial to disperse the
objects in the workspace and thus assist the grasping and vision algorithm. We
propose a disperse and pick method for domain-independent robotic grasping in a
highly cluttered heap of objects. The novel contribution of our framework is
the introduction of a heuristic clutter removal method that does not require
deep learning and can work on unseen objects. At each iteration of the
algorithm, the robot either performs a push-to-move action or a grasp action
based on the estimated clutter profile. For grasp planning, we present an
improved and adaptive version of a recent domain-independent grasping method.
The efficacy of the integrated system is demonstrated in simulation as well as
in the real-world.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12639" title="Abstract">arXiv:2312.12639</a> [<a href="/pdf/2312.12639" title="Download PDF">pdf</a>, <a href="/format/2312.12639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collective Anomaly Perception During Multi-Robot Patrol: Constrained  Interactions Can Promote Accurate Consensus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madin%2C+Z+R">Zachary R. Madin</a>, 
<a href="/search/cs?searchtype=author&query=Lawry%2C+J">Jonathan Lawry</a>, 
<a href="/search/cs?searchtype=author&query=Hunt%2C+E+R">Edmund R. Hunt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">An important real-world application of multi-robot systems is multi-robot
patrolling (MRP), where robots must carry out the activity of going through an
area at regular intervals. Motivations for MRP include the detection of
anomalies that may represent security threats. While MRP algorithms show some
maturity in development, a key potential advantage has been unexamined: the
ability to exploit collective perception of detected anomalies to prioritize
the location ordering of security checks. This is because noisy
individual-level detection of an anomaly may be compensated for by group-level
consensus formation regarding whether an anomaly is likely to be truly present.
Here, we examine the performance of unmodified idleness-based patrolling
algorithms when given the additional objective of reaching an environmental
perception consensus via local pairwise communication and a quorum threshold.
We find that generally, MRP algorithms that promote physical mixing of robots,
as measured by a higher connectivity of their emergent communication network,
reach consensus more quickly. However, when there is noise present in anomaly
detection, a more moderate (constrained) level of connectivity is preferable
because it reduces the spread of false positive detections, as measured by a
group-level F-score. These findings can inform user choice of MRP algorithm and
future algorithm development.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12642" title="Abstract">arXiv:2312.12642</a> [<a href="/pdf/2312.12642" title="Download PDF">pdf</a>, <a href="/format/2312.12642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LoLa: Low-Latency Realtime Video Conferencing over Multiple Cellular  Carriers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ayoubi%2C+S">Sara Ayoubi</a>, 
<a href="/search/cs?searchtype=author&query=Grassi%2C+G">Giulio Grassi</a>, 
<a href="/search/cs?searchtype=author&query=Pau%2C+G">Giovanni Pau</a>, 
<a href="/search/cs?searchtype=author&query=Jamieson%2C+K">Kyle Jamieson</a>, 
<a href="/search/cs?searchtype=author&query=Teixeira%2C+R">Renata Teixeira</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">LoLa is a novel multi-path system for video conferencing applications over
cellular networks. It provides significant gains over single link solutions
when the link quality over different cellular networks fluctuate dramatically
and independently over time, or when aggregating the throughput across
different cellular links improves the perceived video quality. LoLa achieves
this by continuously estimating the quality of available cellular links to
decide how to strip video packets across them without inducing delays or packet
drops. It is also tightly coupled with state-of-the-art video codec to
dynamically adapt video frame size to respond quickly to changing network
conditions. Using multiple traces collected over 4 different cellular operators
in a large metropolitan city, we demonstrate that LoLa provides significant
gains in terms of throughput and delays compared to state-of-the-art real-time
video conferencing solution.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12648" title="Abstract">arXiv:2312.12648</a> [<a href="/pdf/2312.12648" title="Download PDF">pdf</a>, <a href="/format/2312.12648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IS-DARTS: Stabilizing DARTS through Precise Measurement on Candidate  Importance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+H">Hongyi He</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Longjun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haonan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+N">Nanning Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by AAAI2024, paper + supplementary, 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Among existing Neural Architecture Search methods, DARTS is known for its
efficiency and simplicity. This approach applies continuous relaxation of
network representation to construct a weight-sharing supernet and enables the
identification of excellent subnets in just a few GPU days. However,
performance collapse in DARTS results in deteriorating architectures filled
with parameter-free operations and remains a great challenge to the robustness.
To resolve this problem, we reveal that the fundamental reason is the biased
estimation of the candidate importance in the search space through theoretical
and experimental analysis, and more precisely select operations via
information-based measurements. Furthermore, we demonstrate that the excessive
concern over the supernet and inefficient utilization of data in bi-level
optimization also account for suboptimal results. We adopt a more realistic
objective focusing on the performance of subnets and simplify it with the help
of the information-based measurements. Finally, we explain theoretically why
progressively shrinking the width of the supernet is necessary and reduce the
approximation error of optimal weights in DARTS. Our proposed method, named
IS-DARTS, comprehensively improves DARTS and resolves the aforementioned
problems. Extensive experiments on NAS-Bench-201 and DARTS-based search space
demonstrate the effectiveness of IS-DARTS.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12651" title="Abstract">arXiv:2312.12651</a> [<a href="/pdf/2312.12651" title="Download PDF">pdf</a>, <a href="/format/2312.12651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toxic Bias: Perspective API Misreads German as More Toxic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nogara%2C+G">Gianluca Nogara</a>, 
<a href="/search/cs?searchtype=author&query=Pierri%2C+F">Francesco Pierri</a>, 
<a href="/search/cs?searchtype=author&query=Cresci%2C+S">Stefano Cresci</a>, 
<a href="/search/cs?searchtype=author&query=Luceri%2C+L">Luca Luceri</a>, 
<a href="/search/cs?searchtype=author&query=T%C3%B6rnberg%2C+P">Petter T&#xf6;rnberg</a>, 
<a href="/search/cs?searchtype=author&query=Giordano%2C+S">Silvia Giordano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 7 figures, working paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Proprietary public APIs play a crucial and growing role as research tools
among social scientists. Among such APIs, Google's machine learning-based
Perspective API is extensively utilized for assessing the toxicity of social
media messages, providing both an important resource for researchers and
automatic content moderation. However, this paper exposes an important bias in
Perspective API concerning German language text. Through an in-depth
examination of several datasets, we uncover intrinsic language biases within
the multilingual model of Perspective API. We find that the toxicity assessment
of German content produces significantly higher toxicity levels than other
languages. This finding is robust across various translations, topics, and data
sources, and has significant consequences for both research and moderation
strategies that rely on Perspective API. For instance, we show that, on
average, four times more tweets and users would be moderated when using the
German language compared to their English translation. Our findings point to
broader risks associated with the widespread use of proprietary APIs within the
computational social sciences.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12654" title="Abstract">arXiv:2312.12654</a> [<a href="/pdf/2312.12654" title="Download PDF">pdf</a>, <a href="/format/2312.12654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FairFlow Protocol: Equitable Maximal Extractable Value (MEV) mitigation  in Ethereum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+D">Dipankar Sarkar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Ethereum has emerged as a leading platform for decentralized applications
(dApps) due to its robust smart contract capabilities. One of the critical
issues in the Ethereum ecosystem is Maximal Extractable Value (MEV), a concept
that has gained significant attention in the blockchain community. However, MEV
has remained a major challenge with significant implications for the platform's
operation and integrity. This paper introduces the FairFlow protocol, a novel
framework designed to mitigate the effects of MEV within Ethereum's existing
infrastructure. The protocol aims to provide a more equitable environment,
preventing exploitation by miners or validators, and protecting user data. The
combined approach of auction-based block space allocation and randomized
transaction ordering significantly reduces the potential for MEV exploitation.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12655" title="Abstract">arXiv:2312.12655</a> [<a href="/pdf/2312.12655" title="Download PDF">pdf</a>, <a href="/format/2312.12655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Transformers Learn Sequential Function Classes In Context?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Campbell%2C+R">Ryan Campbell</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+E">Emma Guo</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+E">Evan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Vir%2C+R">Reya Vir</a>, 
<a href="/search/cs?searchtype=author&query=Hsiao%2C+E">Ethan Hsiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">In-context learning (ICL) has revolutionized the capabilities of transformer
models in NLP. In our project, we extend the understanding of the mechanisms
underpinning ICL by exploring whether transformers can learn from sequential,
non-textual function class data distributions. We introduce a novel sliding
window sequential function class and employ toy-sized transformers with a GPT-2
architecture to conduct our experiments. Our analysis indicates that these
models can indeed leverage ICL when trained on non-textual sequential function
classes. Additionally, our experiments with randomized y-label sequences
highlights that transformers retain some ICL capabilities even when the label
associations are obfuscated. We provide evidence that transformers can reason
with and understand sequentiality encoded within function classes, as reflected
by the effective learning of our proposed tasks. Our results also show that the
performance deteriorated with increasing randomness in the labels, though not
to the extent one might expect, implying a potential robustness of learned
sequentiality against label noise. Future research may want to look into how
previous explanations of transformers, such as induction heads and task
vectors, relate to sequentiality in ICL in these toy examples. Our
investigation lays the groundwork for further research into how transformers
process and perceive sequential data.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12657" title="Abstract">arXiv:2312.12657</a> [<a href="/pdf/2312.12657" title="Download PDF">pdf</a>, <a href="/format/2312.12657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Convex Landscape of Neural Networks: Characterizing Global Optima  and Stationary Points via Lasso Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ergen%2C+T">Tolga Ergen</a>, 
<a href="/search/cs?searchtype=author&query=Pilanci%2C+M">Mert Pilanci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A preliminary version of part of this work was published at ICML 2020 with the title "Neural Networks are Convex Regularizers: Exact Polynomial-time Convex Optimization Formulations for Two-layer Networks"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Due to the non-convex nature of training Deep Neural Network (DNN) models,
their effectiveness relies on the use of non-convex optimization heuristics.
Traditional methods for training DNNs often require costly empirical methods to
produce successful models and do not have a clear theoretical foundation. In
this study, we examine the use of convex optimization theory and sparse
recovery models to refine the training process of neural networks and provide a
better interpretation of their optimal weights. We focus on training two-layer
neural networks with piecewise linear activations and demonstrate that they can
be formulated as a finite-dimensional convex program. These programs include a
regularization term that promotes sparsity, which constitutes a variant of
group Lasso. We first utilize semi-infinite programming theory to prove strong
duality for finite width neural networks and then we express these
architectures equivalently as high dimensional convex sparse recovery models.
Remarkably, the worst-case complexity to solve the convex program is polynomial
in the number of samples and number of neurons when the rank of the data matrix
is bounded, which is the case in convolutional networks. To extend our method
to training data of arbitrary rank, we develop a novel polynomial-time
approximation scheme based on zonotope subsampling that comes with a guaranteed
approximation ratio. We also show that all the stationary of the nonconvex
training objective can be characterized as the global optimum of a subsampled
convex program. Our convex models can be trained using standard convex solvers
without resorting to heuristics or extensive hyper-parameter tuning unlike
non-convex methods. Through extensive numerical experiments, we show that
convex models can outperform traditional non-convex methods and are not
sensitive to optimizer hyperparameters.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12659" title="Abstract">arXiv:2312.12659</a> [<a href="/pdf/2312.12659" title="Download PDF">pdf</a>, <a href="/format/2312.12659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expediting Contrastive Language-Image Pretraining via Self-distilled  Encoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Bumsoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jinhyung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jo%2C+Y">Yeonsik Jo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S+H">Seung Hwan Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advances in vision language pretraining (VLP) have been largely
attributed to the large-scale data collected from the web. However, uncurated
dataset contains weakly correlated image-text pairs, causing data inefficiency.
To address the issue, knowledge distillation have been explored at the expense
of extra image and text momentum encoders to generate teaching signals for
misaligned image-text pairs. In this paper, our goal is to resolve the
misalignment problem with an efficient distillation framework. To this end, we
propose ECLIPSE: Expediting Contrastive Language-Image Pretraining with
Self-distilled Encoders. ECLIPSE features a distinctive distillation
architecture wherein a shared text encoder is utilized between an online image
encoder and a momentum image encoder. This strategic design choice enables the
distillation to operate within a unified projected space of text embedding,
resulting in better performance. Based on the unified text embedding space,
ECLIPSE compensates for the additional computational cost of the momentum image
encoder by expediting the online image encoder. Through our extensive
experiments, we validate that there is a sweet spot between expedition and
distillation where the partial view from the expedited online image encoder
interacts complementarily with the momentum teacher. As a result, ECLIPSE
outperforms its counterparts while achieving substantial acceleration in
inference speed.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12660" title="Abstract">arXiv:2312.12660</a> [<a href="/pdf/2312.12660" title="Download PDF">pdf</a>, <a href="/ps/2312.12660" title="Download PostScript">ps</a>, <a href="/format/2312.12660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is post-editing really faster than human translation?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Terribile%2C+S">Silvia Terribile</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 11 tables, 7 figures. This article has been published in Translation Spaces. This is the author accepted manuscript. Please find the published version at: <a href="https://doi.org/10.1075/ts.22044.ter">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Time efficiency is paramount for the localisation industry, which demands
ever-faster turnaround times. However, translation speed is largely
underresearched, and there is a lack of clarity about how language service
providers (LSPs) can evaluate the performance of their post-editing (PE) and
human translation (HT) services. This study constitutes the first large-scale
investigation of translation and revision speed in HT and in the PE of neural
machine translation, based on real-world data from an LSP. It uses an
exploratory data analysis approach to investigate data for 90 million words
translated by 879 linguists across 11 language pairs, over 2.5 years. The
results of this research indicate that (a) PE is usually but not always faster
than HT; (b) average speed values may be misleading; (c) translation speed is
highly variable; and (d) edit distance cannot be used as a proxy for
post-editing productivity, because it does not correlate strongly with speed.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12661" title="Abstract">arXiv:2312.12661</a> [<a href="/pdf/2312.12661" title="Download PDF">pdf</a>, <a href="/format/2312.12661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Misalign, Contrast then Distill: Rethinking Misalignments in  Language-Image Pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Bumsoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jo%2C+Y">Yeonsik Jo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jinhyung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S+H">Seung Hwan Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Contrastive Language-Image Pretraining has emerged as a prominent approach
for training vision and text encoders with uncurated image-text pairs from the
web. To enhance data-efficiency, recent efforts have introduced additional
supervision terms that involve random-augmented views of the image. However,
since the image augmentation process is unaware of its text counterpart, this
procedure could cause various degrees of image-text misalignments during
training. Prior methods either disregarded this discrepancy or introduced
external models to mitigate the impact of misalignments during training. In
contrast, we propose a novel metric learning approach that capitalizes on these
misalignments as an additional training source, which we term "Misalign,
Contrast then Distill (MCD)". Unlike previous methods that treat augmented
images and their text counterparts as simple positive pairs, MCD predicts the
continuous scales of misalignment caused by the augmentation. Our extensive
experimental results show that our proposed MCD achieves state-of-the-art
transferability in multiple classification and retrieval downstream datasets.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12664" title="Abstract">arXiv:2312.12664</a> [<a href="/pdf/2312.12664" title="Download PDF">pdf</a>, <a href="/format/2312.12664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UnionDet: Union-Level Detector Towards Real-Time Human-Object  Interaction Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Bumsoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+T">Taeho Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jaewoo Kang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H+J">Hyunwoo J. Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ECCV 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advances in deep neural networks have achieved significant progress in
detecting individual objects from an image. However, object detection is not
sufficient to fully understand a visual scene. Towards a deeper visual
understanding, the interactions between objects, especially humans and objects
are essential. Most prior works have obtained this information with a bottom-up
approach, where the objects are first detected and the interactions are
predicted sequentially by pairing the objects. This is a major bottleneck in
HOI detection inference time. To tackle this problem, we propose UnionDet, a
one-stage meta-architecture for HOI detection powered by a novel union-level
detector that eliminates this additional inference stage by directly capturing
the region of interaction. Our one-stage detector for human-object interaction
shows a significant reduction in interaction prediction time 4x~14x while
outperforming state-of-the-art methods on two public datasets: V-COCO and
HICO-DET.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12666" title="Abstract">arXiv:2312.12666</a> [<a href="/pdf/2312.12666" title="Download PDF">pdf</a>, <a href="/format/2312.12666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incremental Semi-supervised Federated Learning for Health Inference via  Mobile Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+G">Guimin Dong</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+L">Lihua Cai</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+M">Mingyue Tang</a>, 
<a href="/search/cs?searchtype=author&query=Barnes%2C+L+E">Laura E. Barnes</a>, 
<a href="/search/cs?searchtype=author&query=Boukhechba%2C+M">Mehdi Boukhechba</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Mobile sensing appears as a promising solution for health inference problem
(e.g., influenza-like symptom recognition) by leveraging diverse smart sensors
to capture fine-grained information about human behaviors and ambient contexts.
Centralized training of machine learning models can place mobile users'
sensitive information under privacy risks due to data breach and
misexploitation. Federated Learning (FL) enables mobile devices to
collaboratively learn global models without the exposure of local private data.
However, there are challenges of on-device FL deployment using mobile sensing:
1) long-term and continuously collected mobile sensing data may exhibit domain
shifts as sensing objects (e.g. humans) have varying behaviors as a result of
internal and/or external stimulus; 2) model retraining using all available data
may increase computation and memory burden; and 3) the sparsity of annotated
crowd-sourced data causes supervised FL to lack robustness. In this work, we
propose FedMobile, an incremental semi-supervised federated learning algorithm,
to train models semi-supervisedly and incrementally in a decentralized online
fashion. We evaluate FedMobile using a real-world mobile sensing dataset for
influenza-like symptom recognition. Our empirical results show that
FedMobile-trained models achieve the best results in comparison to the selected
baseline methods.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12667" title="Abstract">arXiv:2312.12667</a> [<a href="/pdf/2312.12667" title="Download PDF">pdf</a>, <a href="/format/2312.12667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering Malicious Signatures in Software from Structural  Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+C">Chenzhong Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hantang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Mingxi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xiongye Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinghe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xin Ren</a>, 
<a href="/search/cs?searchtype=author&query=Bogdan%2C+P">Paul Bogdan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2024, Accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Malware represents a significant security concern in today's digital
landscape, as it can destroy or disable operating systems, steal sensitive user
information, and occupy valuable disk space. However, current malware detection
methods, such as static-based and dynamic-based approaches, struggle to
identify newly developed (``zero-day") malware and are limited by customized
virtual machine (VM) environments. To overcome these limitations, we propose a
novel malware detection approach that leverages deep learning, mathematical
techniques, and network science. Our approach focuses on static and dynamic
analysis and utilizes the Low-Level Virtual Machine (LLVM) to profile
applications within a complex network. The generated network topologies are
input into the GraphSAGE architecture to efficiently distinguish between benign
and malicious software applications, with the operation names denoted as node
features. Importantly, the GraphSAGE models analyze the network's topological
geometry to make predictions, enabling them to detect state-of-the-art malware
and prevent potential damage during execution in a VM. To evaluate our
approach, we conduct a study on a dataset comprising source code from 24,376
applications, specifically written in C/C++, sourced directly from
widely-recognized malware and various types of benign software. The results
show a high detection performance with an Area Under the Receiver Operating
Characteristic Curve (AUROC) of 99.85%. Our approach marks a substantial
improvement in malware detection, providing a notably more accurate and
efficient solution when compared to current state-of-the-art malware detection
methods.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12668" title="Abstract">arXiv:2312.12668</a> [<a href="/pdf/2312.12668" title="Download PDF">pdf</a>, <a href="/format/2312.12668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convolutional Channel-wise Competitive Learning for the Forward-Forward  Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papachristodoulou%2C+A">Andreas Papachristodoulou</a>, 
<a href="/search/cs?searchtype=author&query=Kyrkou%2C+C">Christos Kyrkou</a>, 
<a href="/search/cs?searchtype=author&query=Timotheou%2C+S">Stelios Timotheou</a>, 
<a href="/search/cs?searchtype=author&query=Theocharides%2C+T">Theocharis Theocharides</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in AAAI 2024, 11 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The Forward-Forward (FF) Algorithm has been recently proposed to alleviate
the issues of backpropagation (BP) commonly used to train deep neural networks.
However, its current formulation exhibits limitations such as the generation of
negative data, slower convergence, and inadequate performance on complex tasks.
In this paper, we take the main ideas of FF and improve them by leveraging
channel-wise competitive learning in the context of convolutional neural
networks for image classification tasks. A layer-wise loss function is
introduced that promotes competitive learning and eliminates the need for
negative data construction. To enhance both the learning of compositional
features and feature space partitioning, a channel-wise feature separator and
extractor block is proposed that complements the competitive learning process.
Our method outperforms recent FF-based models on image classification tasks,
achieving testing errors of 0.58%, 7.69%, 21.89%, and 48.77% on MNIST,
Fashion-MNIST, CIFAR-10 and CIFAR-100 respectively. Our approach bridges the
performance gap between FF learning and BP methods, indicating the potential of
our proposed approach to learn useful representations in a layer-wise modular
fashion, enabling more efficient and flexible learning.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12670" title="Abstract">arXiv:2312.12670</a> [<a href="/pdf/2312.12670" title="Download PDF">pdf</a>, <a href="/ps/2312.12670" title="Download PostScript">ps</a>, <a href="/format/2312.12670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Role of Server Momentum in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jianhui Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xidong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Heng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Aidong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated Averaging (FedAvg) is known to experience convergence issues when
encountering significant clients system heterogeneity and data heterogeneity.
Server momentum has been proposed as an effective mitigation. However, existing
server momentum works are restrictive in the momentum formulation, do not
properly schedule hyperparameters and focus only on system homogeneous
settings, which leaves the role of server momentum still an under-explored
problem. In this paper, we propose a general framework for server momentum,
that (a) covers a large class of momentum schemes that are unexplored in
federated learning (FL), (b) enables a popular stagewise hyperparameter
scheduler, (c) allows heterogeneous and asynchronous local computing. We
provide rigorous convergence analysis for the proposed framework. To our best
knowledge, this is the first work that thoroughly analyzes the performances of
server momentum with a hyperparameter scheduler and system heterogeneity.
Extensive experiments validate the effectiveness of our proposed framework.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12672" title="Abstract">arXiv:2312.12672</a> [<a href="/pdf/2312.12672" title="Download PDF">pdf</a>, <a href="/format/2312.12672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Categorical, Ratio, and Professorial Data: The Case for Reciprocal Rank
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moffat%2C+A">Alistair Moffat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Search engine results pages are usually abstracted as binary relevance
vectors and hence are categorical data, meaning that only a limited set of
operations is permitted, most notably tabulation of occurrence frequencies,
with determination of medians and averages not possible. To compare retrieval
systems it is thus usual to make use of a categorical-to-numeric effectiveness
mapping. A previous paper has argued that any desired categorical-to-numeric
mapping may be used, provided only that there is an argued connection between
each category of SERP and the score that is assigned to that category by the
mapping. Further, once that plausible connection has been established, then the
mapped values can be treated as real-valued observations on a ratio scale,
allowing the computation of averages. This article is written in support of
that point of view, and to respond to ongoing claims that SERP scores may only
be averaged if very restrictive conditions are imposed on the effectiveness
mapping.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12675" title="Abstract">arXiv:2312.12675</a> [<a href="/pdf/2312.12675" title="Download PDF">pdf</a>, <a href="/format/2312.12675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparison of Waymo Rider-Only Crash Data to Human Benchmarks at 7.1  Million Miles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kusano%2C+K+D">Kristofer D. Kusano</a>, 
<a href="/search/cs?searchtype=author&query=Scanlon%2C+J+M">John M. Scanlon</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yin-Hsiu Chen</a>, 
<a href="/search/cs?searchtype=author&query=McMurry%2C+T+L">Timothy L. McMurry</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruoshu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gode%2C+T">Tilia Gode</a>, 
<a href="/search/cs?searchtype=author&query=Victor%2C+T">Trent Victor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper examines the safety performance of the Waymo Driver, an SAE level
4 automated driving system (ADS) used in a rider-only (RO) ride-hailing
application without a human driver, either in the vehicle or remotely. ADS
crash data was derived from NHTSA's Standing General Order (SGO) reporting over
7.14 million RO miles through the end of October 2023 in Phoenix, AZ, San
Francisco, CA, and Los Angeles, CA. This study is one of the first to compare
overall crashed vehicle rates using only RO data (as opposed to ADS testing
with a human behind the wheel) to a human benchmark that also corrects for
biases caused by underreporting and unequal reporting thresholds reported in
the literature. When considering all locations together, the
any-injury-reported crashed vehicle rate was 0.41 incidents per million miles
(IPMM) for the ADS vs 2.78 IPMM for the human benchmark, an 85% reduction or a
6.8 times lower rate. Police-reported crashed vehicle rates for all locations
together were 2.1 IPMM for the ADS vs. 4.85 IPMM for the human benchmark, a 57%
reduction or 2.3 times lower rate. Police-reported and any-injury-reported
crashed vehicle rate reductions for the ADS were statistically significant when
compared in San Francisco and Phoenix as well as combined across all locations.
The comparison in Los Angeles, which to date has low mileage and no reported
events, was not statistically significant. In general, the Waymo ADS had a
lower any property damage or injury rate than the human benchmarks. Given
imprecision in the benchmark estimate and multiple potential sources of
underreporting biasing the benchmarks, caution should be taken when
interpreting the results of the any property damage or injury comparison.
Together, these crash-rate results should be interpreted as a directional and
continuous confidence growth indicator, together with other methodologies, in a
safety case approach.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12676" title="Abstract">arXiv:2312.12676</a> [<a href="/pdf/2312.12676" title="Download PDF">pdf</a>, <a href="/format/2312.12676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combinatorial Gaussian Process Bandits in Bayesian Settings: Theory and  Application for Energy-Efficient Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sandberg%2C+J">Jack Sandberg</a>, 
<a href="/search/cs?searchtype=author&query=%C3%85kerblom%2C+N">Niklas &#xc5;kerblom</a>, 
<a href="/search/cs?searchtype=author&query=Chehreghani%2C+M+H">Morteza Haghir Chehreghani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We consider a combinatorial Gaussian process semi-bandit problem with
time-varying arm availability. Each round, an agent is provided a set of
available base arms and must select a subset of them to maximize the long-term
cumulative reward. Assuming the expected rewards are sampled from a Gaussian
process (GP) over the arm space, the agent can efficiently learn. We study the
Bayesian setting and provide novel Bayesian regret bounds for three GP-based
algorithms: GP-UCB, Bayes-GP-UCB and GP-TS. Our bounds extend previous results
for GP-UCB and GP-TS to a combinatorial setting with varying arm availability
and to the best of our knowledge, we provide the first Bayesian regret bound
for Bayes-GP-UCB. Time-varying arm availability encompasses other widely
considered bandit problems such as contextual bandits. We formulate the online
energy-efficient navigation problem as a combinatorial and contextual bandit
and provide a comprehensive experimental study on synthetic and real-world road
networks with detailed simulations. The contextual GP model obtains lower
regret and is less dependent on the informativeness of the prior compared to
the non-contextual Bayesian inference model. In addition, Thompson sampling
obtains lower regret than Bayes-UCB for both the contextual and non-contextual
model.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12677" title="Abstract">arXiv:2312.12677</a> [<a href="/pdf/2312.12677" title="Download PDF">pdf</a>, <a href="/format/2312.12677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synchronous Consensus in Partial Synchrony
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klianev%2C+I">Ivan Klianev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">We demonstrate a deterministic Byzantine consensus algorithm with synchronous
performance in partial synchrony and naturally leaderless operation. Each
message is authenticated only with the digital signature of its creator and
resilience to any number of tolerated Byzantine processes requires two
communication rounds. The algorithm terminates within a bounded interval of
time. It is resilient to transient link faults and asynchrony in a fraction of
links with a known distinct size per actual number of faulty processes - links
asynchrony and faults are circumvented with up to 3-hop epidemic dissemination.
Key finding: resilience to asynchrony of links and the enabled by it leaderless
consensus ensure algorithm operation with simultaneous validity, safety, and
bounded liveness.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12679" title="Abstract">arXiv:2312.12679</a> [<a href="/pdf/2312.12679" title="Download PDF">pdf</a>, <a href="/format/2312.12679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Efficient Verification of Quantized Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+P">Pei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoze Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuting Yang</a>, 
<a href="/search/cs?searchtype=author&query=Daukantas%2C+I">Ieva Daukantas</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Min Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yedi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Barrett%2C+C">Clark Barrett</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Quantization replaces floating point arithmetic with integer arithmetic in
deep neural network models, providing more efficient on-device inference with
less power and memory. In this work, we propose a framework for formally
verifying properties of quantized neural networks. Our baseline technique is
based on integer linear programming which guarantees both soundness and
completeness. We then show how efficiency can be improved by utilizing
gradient-based heuristic search methods and also bound-propagation techniques.
We evaluate our approach on perception networks quantized with PyTorch. Our
results show that we can verify quantized networks with better scalability and
efficiency than the previous state of the art.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12680" title="Abstract">arXiv:2312.12680</a> [<a href="/pdf/2312.12680" title="Download PDF">pdf</a>, <a href="/ps/2312.12680" title="Download PostScript">ps</a>, <a href="/format/2312.12680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trajectory Approximation of Video Based on Phase Correlation for Forward  Facing Camera
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdulkadhem%2C+A+A">Abdulkadhem A. Abdulkadhem</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Multimedia (cs.MM); Robotics (cs.RO)

</div>
<p class="mathjax">In this paper, we introduce an innovative approach for extracting
trajectories from a camera sensor in GPS-denied environments, leveraging visual
odometry. The system takes video footage captured by a forward-facing camera
mounted on a vehicle as input, with the output being a chain code representing
the camera's trajectory. The proposed methodology involves several key steps.
Firstly, we employ phase correlation between consecutive frames of the video to
extract essential information. Subsequently, we introduce a novel chain code
method termed "dynamic chain code," which is based on the x-shift values
derived from the phase correlation. The third step involves determining
directional changes (forward, left, right) by establishing thresholds and
extracting the corresponding chain code. This extracted code is then stored in
a buffer for further processing. Notably, our system outperforms traditional
methods reliant on spatial features, exhibiting greater speed and robustness in
noisy environments. Importantly, our approach operates without external camera
calibration information. Moreover, by incorporating visual odometry, our system
enhances its accuracy in estimating camera motion, providing a more
comprehensive understanding of trajectory dynamics. Finally, the system
culminates in the visualization of the normalized camera motion trajectory.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12681" title="Abstract">arXiv:2312.12681</a> [<a href="/pdf/2312.12681" title="Download PDF">pdf</a>, <a href="/format/2312.12681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imitation of Life: A Search Engine for Biologically Inspired Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Emuna%2C+H">Hen Emuna</a>, 
<a href="/search/cs?searchtype=author&query=Borenstein%2C+N">Nadav Borenstein</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+X">Xin Qian</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+H">Hyeonsu Kang</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+J">Joel Chan</a>, 
<a href="/search/cs?searchtype=author&query=Kittur%2C+A">Aniket Kittur</a>, 
<a href="/search/cs?searchtype=author&query=Shahaf%2C+D">Dafna Shahaf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the AAAI 2024 Proceedings Main Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Biologically Inspired Design (BID), or Biomimicry, is a problem-solving
methodology that applies analogies from nature to solve engineering challenges.
For example, Speedo engineers designed swimsuits based on shark skin. Finding
relevant biological solutions for real-world problems poses significant
challenges, both due to the limited biological knowledge engineers and
designers typically possess and to the limited BID resources. Existing BID
datasets are hand-curated and small, and scaling them up requires costly human
annotations.
<br />In this paper, we introduce BARcode (Biological Analogy Retriever), a search
engine for automatically mining bio-inspirations from the web at scale. Using
advances in natural language understanding and data programming, BARcode
identifies potential inspirations for engineering challenges. Our experiments
demonstrate that BARcode can retrieve inspirations that are valuable to
engineers and designers tackling real-world problems, as well as recover famous
historical BID examples. We release data and code; we view BARcode as a step
towards addressing the challenges that have historically hindered the practical
application of BID to engineering innovation.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12682" title="Abstract">arXiv:2312.12682</a> [<a href="/pdf/2312.12682" title="Download PDF">pdf</a>, <a href="/format/2312.12682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mini-GPTs: Efficient Large Language Models through Contextual Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valicenti%2C+T">Tim Valicenti</a>, 
<a href="/search/cs?searchtype=author&query=Vidal%2C+J">Justice Vidal</a>, 
<a href="/search/cs?searchtype=author&query=Patnaik%2C+R">Ritik Patnaik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, Neurips 2023 styling
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In AI research, the optimization of Large Language Models (LLMs) remains a
significant challenge, crucial for advancing the field's practical applications
and sustainability. Building upon the foundational work of Professor Song Han's
lab at MIT, this paper introduces a novel approach in developing Mini-GPTs via
contextual pruning. Our methodology strategically prunes the computational
architecture of traditional LLMs, like Phi-1.5, focusing on retaining core
functionalities while drastically reducing model sizes. We employ the technique
across diverse and complex datasets, including US law, Medical Q&amp;A, Skyrim
dialogue, English-Taiwanese translation, and Economics articles. The results
underscore the efficiency and effectiveness of contextual pruning, not merely
as a theoretical concept but as a practical tool in developing domain-specific,
resource-efficient LLMs. Contextual pruning is a promising method for building
domain-specific LLMs, and this research is a building block towards future
development with more hardware compute, refined fine-tuning, and quantization.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12683" title="Abstract">arXiv:2312.12683</a> [<a href="/pdf/2312.12683" title="Download PDF">pdf</a>, <a href="/format/2312.12683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Turning English-centric LLMs Into Polyglots: How Much Multilinguality Is  Needed?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kew%2C+T">Tannon Kew</a>, 
<a href="/search/cs?searchtype=author&query=Schottmann%2C+F">Florian Schottmann</a>, 
<a href="/search/cs?searchtype=author&query=Sennrich%2C+R">Rico Sennrich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The vast majority of today's large language models are English-centric,
having been pretrained predominantly on English text. Yet, in order to meet
user expectations, models need to be able to respond appropriately in multiple
languages once deployed in downstream applications. Given limited exposure to
other languages during pretraining, cross-lingual transfer is important for
achieving decent performance in non-English settings. In this work, we
investigate just how much multilinguality is required during finetuning to
elicit strong cross-lingual generalisation across a range of tasks and target
languages. We find that, compared to English-only finetuning, multilingual
instruction tuning with as few as three languages significantly improves a
model's cross-lingual transfer abilities on generative tasks that assume
input/output language agreement, while being of less importance for highly
structured tasks. Our code and data is available at
https://github.com/ZurichNLP/multilingual-instruction-tuning.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12687" title="Abstract">arXiv:2312.12687</a> [<a href="/pdf/2312.12687" title="Download PDF">pdf</a>, <a href="/format/2312.12687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Distributed Solution for Efficient K Shortest Paths Computation over  Dynamic Road Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Ziqiang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiaohui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Koudas%2C+N">Nick Koudas</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yueting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A shorter version of this technical report has been accepted for publication as a regular paper in TKDE. arXiv admin note: substantial text overlap with <a href="/abs/2004.02580">arXiv:2004.02580</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">The problem of identifying the k-shortest paths KSPs for short in a dynamic
road network is essential to many location-based services. Road networks are
dynamic in the sense that the weights of the edges in the corresponding graph
constantly change over time, representing evolving traffic conditions. Very
often such services have to process numerous KSP queries over large road
networks at the same time, thus there is a pressing need to identify
distributed solutions for this problem. However, most existing approaches are
designed to identify KSPs on a static graph in a sequential manner, restricting
their scalability and applicability in a distributed setting. We therefore
propose KSP-DG, a distributed algorithm for identifying k-shortest paths in a
dynamic graph. It is based on partitioning the entire graph into smaller
subgraphs, and reduces the problem of determining KSPs into the computation of
partial KSPs in relevant subgraphs, which can execute in parallel on a cluster
of servers. A distributed two-level index called DTLP is developed to
facilitate the efficient identification of relevant subgraphs. A salient
feature of DTLP is that it indexes a set of virtual paths that are insensitive
to varying traffic conditions in an efficient and compact fashion, leading to
very low maintenance cost in dynamic road networks. This is the first treatment
of the problem of processing KSP queries over dynamic road networks. Extensive
experiments conducted on real road networks confirm the superiority of our
proposal over baseline methods.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12688" title="Abstract">arXiv:2312.12688</a> [<a href="/pdf/2312.12688" title="Download PDF">pdf</a>, <a href="/format/2312.12688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ODIN: Object Density Aware Index for CkNN Queries over Moving Objects on  Road Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Ziqiang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiaohui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yueting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bohan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A shorter version of this technical report has been accepted for publication as a regular paper in TKDE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">We study the problem of processing continuous k nearest neighbor (CkNN)
queries over moving objects on road networks, which is an essential operation
in a variety of applications. We are particularly concerned with scenarios
where the object densities in different parts of the road network evolve over
time as the objects move. Existing methods on CkNN query processing are
ill-suited for such scenarios as they utilize index structures with fixed
granularities and are thus unable to keep up with the evolving object
densities. In this paper, we directly address this problem and propose an
object density aware index structure called ODIN that is an elastic tree built
on a hierarchical partitioning of the road network. It is equipped with the
unique capability of dynamically folding/unfolding its nodes, thereby adapting
to varying object densities. We further present the ODIN-KNN-Init and
ODIN-KNN-Inc algorithms for the initial identification of the kNNs and the
incremental update of query result as objects move. Thorough experiments on
both real and synthetic datasets confirm the superiority of our proposal over
several baseline methods.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12691" title="Abstract">arXiv:2312.12691</a> [<a href="/pdf/2312.12691" title="Download PDF">pdf</a>, <a href="/format/2312.12691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Good Are Deep Generative Models for Solving Inverse Problems?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Shichong Peng</a>, 
<a href="/search/cs?searchtype=author&query=Moazeni%2C+A">Alireza Moazeni</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Ke Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Deep generative models, such as diffusion models, GANs, and IMLE, have shown
impressive capability in tackling inverse problems. However, the validity of
model-generated solutions w.r.t. the forward problem and the reliability of
associated uncertainty estimates remain understudied. This study evaluates
recent diffusion-based, GAN-based, and IMLE-based methods on three inverse
problems, i.e., $16\times$ super-resolution, colourization, and image
decompression. We assess the validity of these models' outputs as solutions to
the inverse problems and conduct a thorough analysis of the reliability of the
models' estimates of uncertainty over the solution. Overall, we find that the
IMLE-based CHIMLE method outperforms other methods in terms of producing valid
solutions and reliable uncertainty estimates.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12693" title="Abstract">arXiv:2312.12693</a> [<a href="/pdf/2312.12693" title="Download PDF">pdf</a>, <a href="/format/2312.12693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anderson Accelerated Gauss-Newton-guided deep learning for nonlinear  inverse problems with Application to Electrical Impedance Tomography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhou%2C+Q">Qingping Zhou</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+G">Guixian Xu</a>, 
<a href="/search/math?searchtype=author&query=Wen%2C+Z">Zhexin Wen</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+H">Hongqiao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Physics-guided deep learning is an important prevalent research topic in
scientific machine learning, which has tremendous potential in various complex
applications including science and engineering. In these applications, data is
expensive to acquire and high accuracy is required for making decisions. In
this work, we introduce an efficient physics-guided deep learning framework for
the variational modeling of nonlinear inverse problems, which is then applied
to solve an electrical impedance tomography (EIT) inverse problem. The
framework is achieved by unrolling the proposed Anderson accelerated
Gauss-Newton (GNAA) algorithm into an end-to-end deep learning method. Firstly,
we show the convergence of the GNAA algorithm in both cases: Anderson depth is
equal to one and Anderson depth is greater than one. Then, we propose three
types of strategies by combining the complementary strengths of GNAA and deep
learning: GNAA of learned regularization (GNAA-LRNet), where the singular
values of the regularization matrix are learned by a deep neural network; GNAA
of learned proximity (GNAA-LPNet), where the regularization proximal operator
is learned by using a deep neural network; GNAA of plug-and-play method
(GNAA-PnPNet) where the regularization proximal operator is replaced by a
pre-trained deep denoisers. Lastly, we present some numerical experiments to
illustrate that the proposed approaches greatly improve the convergence rate
and the quality of inverse solutions.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12697" title="Abstract">arXiv:2312.12697</a> [<a href="/pdf/2312.12697" title="Download PDF">pdf</a>, <a href="/format/2312.12697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DGCLUSTER: A Neural Framework for Attributed Graph Clustering via  Modularity Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhowmick%2C+A">Aritra Bhowmick</a>, 
<a href="/search/cs?searchtype=author&query=Kosan%2C+M">Mert Kosan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zexi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Ambuj Singh</a>, 
<a href="/search/cs?searchtype=author&query=Medya%2C+S">Sourav Medya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graph clustering is a fundamental and challenging task in the field of graph
mining where the objective is to group the nodes into clusters taking into
consideration the topology of the graph. It has several applications in diverse
domains spanning social network analysis, recommender systems, computer vision,
and bioinformatics. In this work, we propose a novel method, DGCluster, which
primarily optimizes the modularity objective using graph neural networks and
scales linearly with the graph size. Our method does not require the number of
clusters to be specified as a part of the input and can also leverage the
availability of auxiliary node level information. We extensively test DGCluster
on several real-world datasets of varying sizes, across multiple popular
cluster quality metrics. Our approach consistently outperforms the
state-of-the-art methods, demonstrating significant performance gains in almost
all settings.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12698" title="Abstract">arXiv:2312.12698</a> [<a href="/pdf/2312.12698" title="Download PDF">pdf</a>, <a href="/format/2312.12698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stand-Up Indulgent Gathering on Lines for Myopic Luminous Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bramas%2C+Q">Quentin Bramas</a>, 
<a href="/search/cs?searchtype=author&query=Kakugawa%2C+H">Hirotsugu Kakugawa</a>, 
<a href="/search/cs?searchtype=author&query=Kamei%2C+S">Sayaka Kamei</a>, 
<a href="/search/cs?searchtype=author&query=Lamani%2C+A">Anissa Lamani</a>, 
<a href="/search/cs?searchtype=author&query=Ooshita%2C+F">Fukuhito Ooshita</a>, 
<a href="/search/cs?searchtype=author&query=Shibata%2C+M">Masahiro Shibata</a>, 
<a href="/search/cs?searchtype=author&query=Tixeuil%2C+S">S&#xe9;bastien Tixeuil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">We consider a strong variant of the crash fault-tolerant gathering problem
called stand-up indulgent gathering (SUIG), by robots endowed with limited
visibility sensors and lights on line-shaped networks. In this problem, a group
of mobile robots must eventually gather at a single location, not known
beforehand, regardless of the occurrence of crashes. Differently from previous
work that considered unlimited visibility, we assume that robots can observe
nodes only within a certain fixed distance (that is, they are myopic), and emit
a visible color from a fixed set (that is, they are luminous), without
multiplicity detection. We consider algorithms depending on two parameters
related to the initial configuration: $M_{init}$, which denotes the number of
nodes between two border nodes, and $O_{init}$, which denotes the number of
nodes hosting robots between two border nodes. In both cases, a border node is
a node hosting one or more robots that cannot see other robots on at least one
side. Our main contribution is to prove that, if $M_{init}$ or $O_{init}$ is
odd, SUIG can be solved in the fully synchronous model.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12699" title="Abstract">arXiv:2312.12699</a> [<a href="/pdf/2312.12699" title="Download PDF">pdf</a>, <a href="/ps/2312.12699" title="Download PostScript">ps</a>, <a href="/format/2312.12699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability of the numerical scheme for stochastic McKean-Vlasov equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+Z">Zhuoqi Liu</a>, 
<a href="/search/math?searchtype=author&query=Gao%2C+S">Shuaibin Gao</a>, 
<a href="/search/math?searchtype=author&query=Yuan%2C+C">Chenggui Yuan</a>, 
<a href="/search/math?searchtype=author&query=Guo%2C+Q">Qian Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper studies the infinite-time stability of the numerical scheme for
stochastic McKean-Vlasov equations (SMVEs) via stochastic particle method. The
long-time propagation of chaos in mean-square sense is obtained, with which the
almost sure propagation in infinite horizon is proved by exploiting the
Chebyshev inequality and the Borel-Cantelli lemma. Then the mean-square and
almost sure exponential stabilities of the Euler-Maruyama scheme associated
with the corresponding interacting particle system are shown through an
ingenious manipulation of empirical measure. Combining the assertions enables
the numerical solutions to reproduce the stabilities of the original SMVEs. The
examples are demonstrated to reveal the importance of this study.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12703" title="Abstract">arXiv:2312.12703</a> [<a href="/pdf/2312.12703" title="Download PDF">pdf</a>, <a href="/format/2312.12703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning with Extremely Noisy Clients via Negative  Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yonggang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bo Han</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+Y">Yiu-ming Cheung</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanzi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Federated learning (FL) has shown remarkable success in cooperatively
training deep models, while typically struggling with noisy labels. Advanced
works propose to tackle label noise by a re-weighting strategy with a strong
assumption, i.e., mild label noise. However, it may be violated in many
real-world FL scenarios because of highly contaminated clients, resulting in
extreme noise ratios, e.g., $&gt;$90%. To tackle extremely noisy clients, we study
the robustness of the re-weighting strategy, showing a pessimistic conclusion:
minimizing the weight of clients trained over noisy data outperforms
re-weighting strategies. To leverage models trained on noisy clients, we
propose a novel approach, called negative distillation (FedNed). FedNed first
identifies noisy clients and employs rather than discards the noisy clients in
a knowledge distillation manner. In particular, clients identified as noisy
ones are required to train models using noisy labels and pseudo-labels obtained
by global models. The model trained on noisy labels serves as a `bad teacher'
in knowledge distillation, aiming to decrease the risk of providing incorrect
information. Meanwhile, the model trained on pseudo-labels is involved in model
aggregation if not identified as a noisy client. Consequently, through
pseudo-labeling, FedNed gradually increases the trustworthiness of models
trained on noisy clients, while leveraging all clients for model aggregation
through negative distillation. To verify the efficacy of FedNed, we conduct
extensive experiments under various settings, demonstrating that FedNed can
consistently outperform baselines and achieve state-of-the-art performance. Our
code is available at https://github.com/linChen99/FedNed.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12705" title="Abstract">arXiv:2312.12705</a> [<a href="/pdf/2312.12705" title="Download PDF">pdf</a>, <a href="/format/2312.12705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Distributed Training on Frontier for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dash%2C+S">Sajal Dash</a>, 
<a href="/search/cs?searchtype=author&query=Lyngaas%2C+I">Isaac Lyngaas</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Junqi Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Egele%2C+R">Romain Egele</a>, 
<a href="/search/cs?searchtype=author&query=Cong%2C+G">Guojing Cong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Feiyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Balaprakash%2C+P">Prasanna Balaprakash</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLM) are showing tremendous success as foundation
models, and many downstream applications benefit from fine-tuning. Prior works
on loss scaling have demonstrated that the larger LLMs perform better than
their smaller counterparts. However, training LLMs with billions of parameters
requires considerable computational resources; to train a one trillion
GPT-style model on 20 trillion tokens, we need to perform 120 million exaflops.
Frontier is the world's first and fastest exascale supercomputer for open
science and is equipped with 75264 MI250X GPUs. This work explores efficient
distributed strategies such as tensor parallelism, pipeline parallelism, and
sharded data parallelism to train a trillion-parameter model on the Frontier
exascale supercomputer. We analyze these distributed training techniques and
associated parameters individually to decide which techniques to use and what
associated parameters to select for a particular technique. We perform
hyperparameter tuning on these techniques to understand their complex
interplay. Combined with these two tuning efforts, we have found optimal
strategies to train three models of size 22B, 175B, and 1T parameters with
$38.38\%$ , $36.14\%$ , and $31.96\%$ achieved throughput. For training the
175B parameter model and 1T model, we have achieved $100\%$ weak scaling
efficiency and $89\%$ and $87\%$ strong scaling efficiency, respectively. Our
work presents a set of strategies for distributed training of LLMs through
experimental findings and hyperparameter tuning.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12713" title="Abstract">arXiv:2312.12713</a> [<a href="/pdf/2312.12713" title="Download PDF">pdf</a>, <a href="/format/2312.12713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Response Enhanced Semi-Supervised Dialogue Query Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jianheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Ante Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Linfeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Linfeng Song</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Jinsong Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Leveraging vast and continually updated knowledge from the Internet has been
considered an important ability for a dialogue system. Therefore, the dialogue
query generation task is proposed for generating search queries from dialogue
histories, which will be submitted to a search engine for retrieving relevant
websites on the Internet. In this regard, previous efforts were devoted to
collecting conversations with annotated queries and training a query producer
(QP) via standard supervised learning. However, these studies still face the
challenges of data scarcity and domain adaptation. To address these issues, in
this paper, we propose a semi-supervised learning framework -- SemiDQG, to
improve model performance with unlabeled conversations. Based on the
observation that the search query is typically related to the topic of dialogue
response, we train a response-augmented query producer (RA) to provide rich and
effective training signals for QP. We first apply a similarity-based query
selection strategy to select high-quality RA-generated pseudo queries, which
are used to construct pseudo instances for training QP and RA. Then, we adopt
the REINFORCE algorithm to further enhance QP, with RA-provided rewards as
fine-grained training signals. Experimental results and in-depth analysis of
three benchmarks show the effectiveness of our framework in cross-domain and
low-resource scenarios. Particularly, SemiDQG significantly surpasses ChatGPT
and competitive baselines. Our code is available at
\url{https://github.com/DeepLearnXMU/SemiDQG}.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12716" title="Abstract">arXiv:2312.12716</a> [<a href="/pdf/2312.12716" title="Download PDF">pdf</a>, <a href="/format/2312.12716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BloomVQA: Assessing Hierarchical Multi-modal Comprehension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yunye Gong</a>, 
<a href="/search/cs?searchtype=author&query=Shrestha%2C+R">Robik Shrestha</a>, 
<a href="/search/cs?searchtype=author&query=Claypoole%2C+J">Jared Claypoole</a>, 
<a href="/search/cs?searchtype=author&query=Cogswell%2C+M">Michael Cogswell</a>, 
<a href="/search/cs?searchtype=author&query=Ray%2C+A">Arijit Ray</a>, 
<a href="/search/cs?searchtype=author&query=Kanan%2C+C">Christopher Kanan</a>, 
<a href="/search/cs?searchtype=author&query=Divakaran%2C+A">Ajay Divakaran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose a novel VQA dataset, based on picture stories designed for
educating young children, that aims to facilitate comprehensive evaluation and
characterization of vision-language models on comprehension tasks. Unlike
current VQA datasets that often focus on fact-based memorization and simple
reasoning tasks without principled scientific grounding, we collect data
containing tasks reflecting different levels of comprehension and underlying
cognitive processes, as laid out in Bloom's Taxonomy, a classic framework
widely adopted in education research. The proposed BloomVQA dataset can be
mapped to a hierarchical graph-based representation of visual stories, enabling
automatic data augmentation and novel measures characterizing model consistency
across the underlying taxonomy. We demonstrate graded evaluation and
reliability analysis based on our proposed consistency metrics on
state-of-the-art vision-language models. Our results suggest that, while
current models achieve the most gain on low-level comprehension tasks, they
generally fall short on high-level tasks requiring more advanced comprehension
and cognitive skills, as 38.0% drop in VQA accuracy is observed comparing
lowest and highest level tasks. Furthermore, current models show consistency
patterns misaligned with human comprehension in various scenarios, suggesting
emergent structures of model behaviors.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12717" title="Abstract">arXiv:2312.12717</a> [<a href="/pdf/2312.12717" title="Download PDF">pdf</a>, <a href="/format/2312.12717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DoDo-Code: a Deep Levenshtein Distance Embedding-based Code for IDS  Channel and DNA Storage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+A+J+X">Alan J.X. Guo</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Sihan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+M">Mengyi Wei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xin Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently, DNA storage has emerged as a promising data storage solution,
offering significant advantages in storage density, maintenance cost
efficiency, and parallel replication capability. Mathematically, the DNA
storage pipeline can be viewed as an insertion, deletion, and substitution
(IDS) channel. Because of the mathematical terra incognita of the Levenshtein
distance, designing an IDS-correcting code is still a challenge. In this paper,
we propose an innovative approach that utilizes deep Levenshtein distance
embedding to bypass these mathematical challenges. By representing the
Levenshtein distance between two sequences as a conventional distance between
their corresponding embedding vectors, the inherent structural property of
Levenshtein distance is revealed in the friendly embedding space. Leveraging
this embedding space, we introduce the DoDo-Code, an IDS-correcting code that
incorporates deep embedding of Levenshtein distance, deep embedding-based
codeword search, and deep embedding-based segment correcting. To address the
requirements of DNA storage, we also present a preliminary algorithm for long
sequence decoding. As far as we know, the DoDo-Code is the first IDS-correcting
code designed using plausible deep learning methodologies, potentially paving
the way for a new direction in error-correcting code research. It is also the
first IDS code that exhibits characteristics of being `optimal' in terms of
redundancy, significantly outperforming the mainstream IDS-correcting codes of
the Varshamov-Tenengolts code family in code rate.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12720" title="Abstract">arXiv:2312.12720</a> [<a href="/pdf/2312.12720" title="Download PDF">pdf</a>, <a href="/format/2312.12720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdvST: Revisiting Data Augmentations for Single Domain Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+G">Guangtao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Huai%2C+M">Mengdi Huai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Aidong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Single domain generalization (SDG) aims to train a robust model against
unknown target domain shifts using data from a single source domain. Data
augmentation has been proven an effective approach to SDG. However, the utility
of standard augmentations, such as translate, or invert, has not been fully
exploited in SDG; practically, these augmentations are used as a part of a data
preprocessing procedure. Although it is intuitive to use many such
augmentations to boost the robustness of a model to out-of-distribution domain
shifts, we lack a principled approach to harvest the benefit brought from
multiple these augmentations. Here, we conceptualize standard data
augmentations with learnable parameters as semantics transformations that can
manipulate certain semantics of a sample, such as the geometry or color of an
image. Then, we propose Adversarial learning with Semantics Transformations
(AdvST) that augments the source domain data with semantics transformations and
learns a robust model with the augmented data. We theoretically show that AdvST
essentially optimizes a distributionally robust optimization objective defined
on a set of semantics distributions induced by the parameters of semantics
transformations. We demonstrate that AdvST can produce samples that expand the
coverage on target domain data. Compared with the state-of-the-art methods,
AdvST, despite being a simple method, is surprisingly competitive and achieves
the best average SDG performance on the Digits, PACS, and DomainNet datasets.
Our code is available at https://github.com/gtzheng/AdvST.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12721" title="Abstract">arXiv:2312.12721</a> [<a href="/pdf/2312.12721" title="Download PDF">pdf</a>, <a href="/format/2312.12721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Modal Reasoning with Event Correlation for Video Question  Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+C">Chengxiang Yin</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+Z">Zhengping Che</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiyuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Q">Qinru Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jian Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video Question Answering (VideoQA) is a very attractive and challenging
research direction aiming to understand complex semantics of heterogeneous data
from two domains, i.e., the spatio-temporal video content and the word sequence
in question. Although various attention mechanisms have been utilized to manage
contextualized representations by modeling intra- and inter-modal relationships
of the two modalities, one limitation of the predominant VideoQA methods is the
lack of reasoning with event correlation, that is, sensing and analyzing
relationships among abundant and informative events contained in the video. In
this paper, we introduce the dense caption modality as a new auxiliary and
distill event-correlated information from it to infer the correct answer. To
this end, we propose a novel end-to-end trainable model, Event-Correlated Graph
Neural Networks (EC-GNNs), to perform cross-modal reasoning over information
from the three modalities (i.e., caption, video, and question). Besides the
exploitation of a brand new modality, we employ cross-modal reasoning modules
for explicitly modeling inter-modal relationships and aggregating relevant
information across different modalities, and we propose a question-guided
self-adaptive multi-modal fusion module to collect the question-oriented and
event-correlated evidence through multi-step reasoning. We evaluate our model
on two widely-used benchmark datasets and conduct an ablation study to justify
the effectiveness of each proposed component.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12722" title="Abstract">arXiv:2312.12722</a> [<a href="/pdf/2312.12722" title="Download PDF">pdf</a>, <a href="/format/2312.12722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Grained Knowledge Selection and Restoration for Non-Exemplar Class  Incremental Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhai%2C+J">Jiang-Tian Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xialei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Ming-Ming Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to appear at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Non-exemplar class incremental learning aims to learn both the new and old
tasks without accessing any training data from the past. This strict
restriction enlarges the difficulty of alleviating catastrophic forgetting
since all techniques can only be applied to current task data. Considering this
challenge, we propose a novel framework of fine-grained knowledge selection and
restoration. The conventional knowledge distillation-based methods place too
strict constraints on the network parameters and features to prevent
forgetting, which limits the training of new tasks. To loose this constraint,
we proposed a novel fine-grained selective patch-level distillation to
adaptively balance plasticity and stability. Some task-agnostic patches can be
used to preserve the decision boundary of the old task. While some patches
containing the important foreground are favorable for learning the new task.
<br />Moreover, we employ a task-agnostic mechanism to generate more realistic
prototypes of old tasks with the current task sample for reducing classifier
bias for fine-grained knowledge restoration. Extensive experiments on CIFAR100,
TinyImageNet and ImageNet-Subset demonstrate the effectiveness of our method.
Code is available at https://github.com/scok30/vit-cil.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12723" title="Abstract">arXiv:2312.12723</a> [<a href="/pdf/2312.12723" title="Download PDF">pdf</a>, <a href="/format/2312.12723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Clue Reasoning with Memory Augmentation for Knowledge-based Visual  Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+C">Chengxiang Yin</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+Z">Zhengping Che</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiyuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jian Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual Question Answering (VQA) has emerged as one of the most challenging
tasks in artificial intelligence due to its multi-modal nature. However, most
existing VQA methods are incapable of handling Knowledge-based Visual Question
Answering (KB-VQA), which requires external knowledge beyond visible contents
to answer questions about a given image. To address this issue, we propose a
novel framework that endows the model with capabilities of answering more
general questions, and achieves a better exploitation of external knowledge
through generating Multiple Clues for Reasoning with Memory Neural Networks
(MCR-MemNN). Specifically, a well-defined detector is adopted to predict
image-question related relation phrases, each of which delivers two
complementary clues to retrieve the supporting facts from external knowledge
base (KB), which are further encoded into a continuous embedding space using a
content-addressable memory. Afterwards, mutual interactions between
visual-semantic representation and the supporting facts stored in memory are
captured to distill the most relevant information in three modalities (i.e.,
image, question, and KB). Finally, the optimal answer is predicted by choosing
the supporting fact with the highest score. We conduct extensive experiments on
two widely-used benchmarks. The experimental results well justify the
effectiveness of MCR-MemNN, as well as its superiority over other KB-VQA
methods.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12724" title="Abstract">arXiv:2312.12724</a> [<a href="/pdf/2312.12724" title="Download PDF">pdf</a>, <a href="/format/2312.12724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Progressive Poisoned Data Isolation for Training-time Backdoor Defense
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haiwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiantao Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep Neural Networks (DNN) are susceptible to backdoor attacks where
malicious attackers manipulate the model's predictions via data poisoning. It
is hence imperative to develop a strategy for training a clean model using a
potentially poisoned dataset. Previous training-time defense mechanisms
typically employ an one-time isolation process, often leading to suboptimal
isolation outcomes. In this study, we present a novel and efficacious defense
method, termed Progressive Isolation of Poisoned Data (PIPD), that
progressively isolates poisoned data to enhance the isolation accuracy and
mitigate the risk of benign samples being misclassified as poisoned ones. Once
the poisoned portion of the dataset has been identified, we introduce a
selective training process to train a clean model. Through the implementation
of these techniques, we ensure that the trained model manifests a significantly
diminished attack success rate against the poisoned data. Extensive experiments
on multiple benchmark datasets and DNN models, assessed against nine
state-of-the-art backdoor attacks, demonstrate the superior performance of our
PIPD method for backdoor defense. For instance, our PIPD achieves an average
True Positive Rate (TPR) of 99.95% and an average False Positive Rate (FPR) of
0.06% for diverse attacks over CIFAR-10 dataset, markedly surpassing the
performance of state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12726" title="Abstract">arXiv:2312.12726</a> [<a href="/pdf/2312.12726" title="Download PDF">pdf</a>, <a href="/format/2312.12726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing Shape-Radiance Ambiguity in Radiance Fields with a Closed-Form  Color Estimation Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+Q">Qihang Fang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yafei Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Keqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Bo%2C+L">Liefeng Bo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been published in NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural radiance field (NeRF) enables the synthesis of cutting-edge realistic
novel view images of a 3D scene. It includes density and color fields to model
the shape and radiance of a scene, respectively. Supervised by the photometric
loss in an end-to-end training manner, NeRF inherently suffers from the
shape-radiance ambiguity problem, i.e., it can perfectly fit training views but
does not guarantee decoupling the two fields correctly. To deal with this
issue, existing works have incorporated prior knowledge to provide an
independent supervision signal for the density field, including total variation
loss, sparsity loss, distortion loss, etc. These losses are based on general
assumptions about the density field, e.g., it should be smooth, sparse, or
compact, which are not adaptive to a specific scene. In this paper, we propose
a more adaptive method to reduce the shape-radiance ambiguity. The key is a
rendering method that is only based on the density field. Specifically, we
first estimate the color field based on the density field and posed images in a
closed form. Then NeRF's rendering process can proceed. We address the problems
in estimating the color field, including occlusion and non-uniformly
distributed views. Afterward, it is applied to regularize NeRF's density field.
As our regularization is guided by photometric loss, it is more adaptive
compared to existing ones. Experimental results show that our method improves
the density field of NeRF both qualitatively and quantitatively. Our code is
available at https://github.com/qihangGH/Closed-form-color-field.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12727" title="Abstract">arXiv:2312.12727</a> [<a href="/pdf/2312.12727" title="Download PDF">pdf</a>, <a href="/format/2312.12727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Black Content Creators&#x27; Responses and Resistance Strategies on TikTok
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Williams%2C+G">Gianna Williams</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Social media wields a profound influence on social and economic dynamics
worldwide, people on social media began to forge a livelihood through their
online presence through creative labor. This surge in social media Content
Creators significantly shaped the trends and cultural landscape of the
internet. While many of the social media trends we observe today can be
attributed to the creative contributions of Black Content Creators, digital
platforms routinely marginalize and undermine these creators through
algorithmic recommendation systems that produce systemic bias against Black and
Brown people. To address this problem, we conducted a content analysis to
assess how algorithms specifically illicit harassment, interact, and unfairly
target Black Content Creators.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12728" title="Abstract">arXiv:2312.12728</a> [<a href="/pdf/2312.12728" title="Download PDF">pdf</a>, <a href="/format/2312.12728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lookahead: An Inference Acceleration Framework for Large Language Model  with Lossless Generation Accuracy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhitian Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+C">Chenyi Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinjie Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">As Large Language Models (LLMs) have made significant advancements across
various tasks, such as question answering, translation, text summarization, and
dialogue systems, the need for accuracy in information becomes crucial,
especially for serious financial products serving billions of users like
Alipay. To address this, Alipay has developed a Retrieval-Augmented Generation
(RAG) system that grounds LLMs on the most accurate and up-to-date information.
However, for a real-world product serving millions of users, the inference
speed of LLMs becomes a critical factor compared to a mere experimental model.
<br />Hence, this paper presents a generic framework for accelerating the inference
process, resulting in a substantial increase in speed and cost reduction for
our RAG system, with lossless generation accuracy. In the traditional inference
process, each token is generated sequentially by the LLM, leading to a time
consumption proportional to the number of generated tokens. To enhance this
process, our framework, named \textit{lookahead}, introduces a
\textit{multi-branch} strategy. Instead of generating a single token at a time,
we propose a \textit{Trie-based Retrieval} (TR) process that enables the
generation of multiple branches simultaneously, each of which is a sequence of
tokens. Subsequently, for each branch, a \textit{Verification and Accept} (VA)
process is performed to identify the longest correct sub-sequence as the final
output. Our strategy offers two distinct advantages: (1) it guarantees absolute
correctness of the output, avoiding any approximation algorithms, and (2) the
worst-case performance of our approach is equivalent to the conventional
process. We conduct extensive experiments to demonstrate the significant
improvements achieved by applying our inference acceleration framework.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12729" title="Abstract">arXiv:2312.12729</a> [<a href="/pdf/2312.12729" title="Download PDF">pdf</a>, <a href="/format/2312.12729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment Anything Model Meets Image Harmonization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haoxing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaohui Li</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Z">Zhangxuan Gu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhuoer Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+J">Jun Lan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huaxiong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image harmonization is a crucial technique in image composition that aims to
seamlessly match the background by adjusting the foreground of composite
images. Current methods adopt either global-level or pixel-level feature
matching. Global-level feature matching ignores the proximity prior, treating
foreground and background as separate entities. On the other hand, pixel-level
feature matching loses contextual information. Therefore, it is necessary to
use the information from semantic maps that describe different objects to guide
harmonization. In this paper, we propose Semantic-guided Region-aware Instance
Normalization (SRIN) that can utilize the semantic segmentation maps output by
a pre-trained Segment Anything Model (SAM) to guide the visual consistency
learning of foreground and background features. Abundant experiments
demonstrate the superiority of our method for image harmonization over
state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12730" title="Abstract">arXiv:2312.12730</a> [<a href="/pdf/2312.12730" title="Download PDF">pdf</a>, <a href="/format/2312.12730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Closer Look at the Few-Shot Adaptation of Large Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Silva-Rodriguez%2C+J">Julio Silva-Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Hajimiri%2C+S">Sina Hajimiri</a>, 
<a href="/search/cs?searchtype=author&query=Ayed%2C+I+B">Ismail Ben Ayed</a>, 
<a href="/search/cs?searchtype=author&query=Dolz%2C+J">Jose Dolz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code available at <a href="https://github.com/jusiro/CLAP">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Efficient transfer learning (ETL) is receiving increasing attention to adapt
large pre-trained language-vision models on downstream tasks with a few labeled
samples. While significant progress has been made, we reveal that
state-of-the-art ETL approaches exhibit strong performance only in
narrowly-defined experimental setups, and with a careful adjustment of
hyperparameters based on a large corpus of labeled samples. In particular, we
make two interesting, and surprising empirical observations. First, to
outperform a simple Linear Probing baseline, these methods require to optimize
their hyper-parameters on each target task. And second, they typically
underperform -- sometimes dramatically -- standard zero-shot predictions in the
presence of distributional drifts. Motivated by the unrealistic assumptions
made in the existing literature, i.e., access to a large validation set and
case-specific grid-search for optimal hyperparameters, we propose a novel
approach that meets the requirements of real-world scenarios. More concretely,
we introduce a CLass-Adaptive linear Probe (CLAP) objective, whose balancing
term is optimized via an adaptation of the general Augmented Lagrangian method
tailored to this context. We comprehensively evaluate CLAP on a broad span of
datasets and scenarios, demonstrating that it consistently outperforms SoTA
approaches, while yet being a much more efficient alternative.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12731" title="Abstract">arXiv:2312.12731</a> [<a href="/pdf/2312.12731" title="Download PDF">pdf</a>, <a href="/format/2312.12731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustly Improving Bandit Algorithms with Confounded and Selection  Biased Offline Data: A Causal Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xintao Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper studies bandit problems where an agent has access to offline data
that might be utilized to potentially improve the estimation of each arm's
reward distribution. A major obstacle in this setting is the existence of
compound biases from the observational data. Ignoring these biases and blindly
fitting a model with the biased data could even negatively affect the online
learning phase. In this work, we formulate this problem from a causal
perspective. First, we categorize the biases into confounding bias and
selection bias based on the causal structure they imply. Next, we extract the
causal bound for each arm that is robust towards compound biases from biased
observational data. The derived bounds contain the ground truth mean reward and
can effectively guide the bandit agent to learn a nearly-optimal decision
policy. We also conduct regret analysis in both contextual and non-contextual
bandit settings and show that prior causal bounds could help consistently
reduce the asymptotic regret.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12732" title="Abstract">arXiv:2312.12732</a> [<a href="/pdf/2312.12732" title="Download PDF">pdf</a>, <a href="/format/2312.12732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strassen&#x27;s Matrix Multiplication Algorithm Is Still Faster
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%27Alberto%2C+P">Paolo D&#x27;Alberto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 images, mathematical software
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Software (cs.MS)</span>; Performance (cs.PF)

</div>
<p class="mathjax">Recently, reinforcement algorithms discovered new algorithms that really
jump-started a wave of excitements and a flourishing of publications. However,
there is little on implementations, applications, and, especially, no absolute
performance and, we show here they are not here to replace Strassen's original
fast matrix multiplication yet. We present Matrix Flow, this is a simple Python
project for the automatic formulation, design, implementation, code generation,
and execution of fast matrix multiplication algorithms for CPUs, using BLAS
interface GPUs, and in the future other accelerators. We shall not play with
module-2 (Z2) algorithms and, for simplicity, we present only square
double-precision matrices. By means of factorizing the operand matrices we can
express many algorithms and prove them correct. These algorithms are
represented by Data Flows and matrix data partitions: a Directed Acyclic Graph.
We show that Strassen's original algorithm is still the top choice even for
modern GPUs. We also address error analysis in double precision, because
integer computations are correct, always
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12735" title="Abstract">arXiv:2312.12735</a> [<a href="/pdf/2312.12735" title="Download PDF">pdf</a>, <a href="/ps/2312.12735" title="Download PostScript">ps</a>, <a href="/format/2312.12735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MetaSegNet: Metadata-collaborative Vision-Language Representation  Learning for Semantic Segmentation of Remote Sensing Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Libo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+S">Sijun Dong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Ying Chen</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+X">Xiaoliang Meng</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+S">Shenghui Fang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semantic segmentation of remote sensing images plays a vital role in a wide
range of Earth Observation (EO) applications, such as land use land cover
mapping, environment monitoring, and sustainable development. Driven by rapid
developments in Artificial Intelligence (AI), deep learning (DL) has emerged as
the mainstream tool for semantic segmentation and achieved many breakthroughs
in the field of remote sensing. However, the existing DL-based methods mainly
focus on unimodal visual data while ignoring the rich multimodal information
involved in the real world, usually demonstrating weak reliability and
generlization. Inspired by the success of Vision Transformers and large
language models, we propose a novel metadata-collaborative multimodal
segmentation network (MetaSegNet) that applies vision-language representation
learning for semantic segmentation of remote sensing images. Unlike the common
model structure that only uses unimodal visual data, we extract the key
characteristic (i.e. the climate zone) from freely available remote sensing
image metadata and transfer it into knowledge-based text prompts via the
generic ChatGPT. Then, we construct an image encoder, a text encoder and a
crossmodal attention fusion subnetwork to extract the image and text feature
and apply image-text interaction. Benefiting from such a design, the proposed
MetaSegNet demonstrates superior generalization and achieves competitive
accuracy with state-of-the-art semantic segmentation methods on the large-scale
OpenEarthMap dataset (68.6% mIoU) and Potsdam dataset (93.3% mean F1 score) as
well as LoveDA dataset (52.2% mIoU).
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12736" title="Abstract">arXiv:2312.12736</a> [<a href="/pdf/2312.12736" title="Download PDF">pdf</a>, <a href="/format/2312.12736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning and Forgetting Unsafe Examples in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiachen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhun Deng</a>, 
<a href="/search/cs?searchtype=author&query=Madras%2C+D">David Madras</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">James Zou</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+M">Mengye Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">As the number of large language models (LLMs) released to the public grows,
there is a pressing need to understand the safety implications associated with
these models learning from third-party custom finetuning data. We explore the
behavior of LLMs finetuned on noisy custom data containing unsafe content,
represented by datasets that contain biases, toxicity, and harmfulness, finding
that while aligned LLMs can readily learn this unsafe content, they also tend
to forget it more significantly than other examples when subsequently finetuned
on safer content. Drawing inspiration from the discrepancies in forgetting, we
introduce the "ForgetFilter" algorithm, which filters unsafe data based on how
strong the model's forgetting signal is for that data. We demonstrate that the
ForgetFilter algorithm ensures safety in customized finetuning without
compromising downstream task performance, unlike sequential safety finetuning.
ForgetFilter outperforms alternative strategies like replay and moral
self-correction in curbing LLMs' ability to assimilate unsafe content during
custom finetuning, e.g. 75% lower than not applying any safety measures and 62%
lower than using self-correction in toxicity score.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12737" title="Abstract">arXiv:2312.12737</a> [<a href="/pdf/2312.12737" title="Download PDF">pdf</a>, <a href="/format/2312.12737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FSscore: A Machine Learning-based Synthetic Feasibility Score Leveraging  Human Expertise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neeser%2C+R+M">Rebecca M. Neeser</a>, 
<a href="/search/cs?searchtype=author&query=Correia%2C+B">Bruno Correia</a>, 
<a href="/search/cs?searchtype=author&query=Schwaller%2C+P">Philippe Schwaller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)

</div>
<p class="mathjax">Determining whether a molecule can be synthesized is crucial for many aspects
of chemistry and drug discovery, allowing prioritization of experimental work
and ranking molecules in de novo design tasks. Existing scoring approaches to
assess synthetic feasibility struggle to extrapolate to out-of-distribution
chemical spaces or fail to discriminate based on minor differences such as
chirality that might be obvious to trained chemists. This work aims to address
these limitations by introducing the Focused Synthesizability score (FSscore),
which learns to rank structures based on binary preferences using a graph
attention network. First, a baseline trained on an extensive set of
reactant-product pairs is established that subsequently is fine-tuned with
expert human feedback on a chemical space of interest. Fine-tuning on focused
datasets improves performance on these chemical scopes over the pre-trained
model exhibiting moderate performance and generalizability. This enables
distinguishing hard- from easy-to-synthesize molecules and improving the
synthetic accessibility of generative model outputs. On very complex scopes
with limited labels achieving satisfactory gains remains challenging. The
FSscore showcases how human expert feedback can be utilized to optimize the
assessment of synthetic feasibility for a variety of applications.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12740" title="Abstract">arXiv:2312.12740</a> [<a href="/pdf/2312.12740" title="Download PDF">pdf</a>, <a href="/ps/2312.12740" title="Download PostScript">ps</a>, <a href="/format/2312.12740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-tuning Large Language Models for Adaptive Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moslem%2C+Y">Yasmin Moslem</a>, 
<a href="/search/cs?searchtype=author&query=Haque%2C+R">Rejwanul Haque</a>, 
<a href="/search/cs?searchtype=author&query=Way%2C+A">Andy Way</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">This paper presents the outcomes of fine-tuning Mistral 7B, a general-purpose
large language model (LLM), for adaptive machine translation (MT). The
fine-tuning process involves utilising a combination of zero-shot and one-shot
translation prompts within the medical domain. The primary objective is to
enhance real-time adaptive MT capabilities of Mistral 7B, enabling it to adapt
translations to the required domain at inference time. The results,
particularly for Spanish-to-English MT, showcase the efficacy of the fine-tuned
model, demonstrating quality improvements in both zero-shot and one-shot
translation scenarios, surpassing Mistral 7B's baseline performance. Notably,
the fine-tuned Mistral outperforms ChatGPT "gpt-3.5-turbo" in zero-shot
translation while achieving comparable one-shot translation quality. Moreover,
the zero-shot translation of the fine-tuned Mistral matches NLLB 3.3B's
performance, and its one-shot translation quality surpasses that of NLLB 3.3B.
These findings emphasise the significance of fine-tuning efficient LLMs like
Mistral 7B to yield high-quality zero-shot translations comparable to
task-oriented models like NLLB 3.3B. Additionally, the adaptive gains achieved
in one-shot translation are comparable to those of commercial LLMs such as
ChatGPT. Our experiments demonstrate that, with a relatively small dataset of
20,000 segments that incorporate a mix of zero-shot and one-shot prompts,
fine-tuning significantly enhances Mistral's in-context learning ability,
especially for real-time adaptive MT.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12741" title="Abstract">arXiv:2312.12741</a> [<a href="/pdf/2312.12741" title="Download PDF">pdf</a>, <a href="/ps/2312.12741" title="Download PostScript">ps</a>, <a href="/format/2312.12741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Locally Optimal Fixed-Budget Best Arm Identification in Two-Armed  Gaussian Bandits with Unknown Variances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kato%2C+M">Masahiro Kato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Econometrics (econ.EM); Statistics Theory (math.ST); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">We address the problem of best arm identification (BAI) with a fixed budget
for two-armed Gaussian bandits. In BAI, given multiple arms, we aim to find the
best arm, an arm with the highest expected reward, through an adaptive
experiment. Kaufmann et al. (2016) develops a lower bound for the probability
of misidentifying the best arm. They also propose a strategy, assuming that the
variances of rewards are known, and show that it is asymptotically optimal in
the sense that its probability of misidentification matches the lower bound as
the budget approaches infinity. However, an asymptotically optimal strategy is
unknown when the variances are unknown. For this open issue, we propose a
strategy that estimates variances during an adaptive experiment and draws arms
with a ratio of the estimated standard deviations. We refer to this strategy as
the Neyman Allocation (NA)-Augmented Inverse Probability weighting (AIPW)
strategy. We then demonstrate that this strategy is asymptotically optimal by
showing that its probability of misidentification matches the lower bound when
the budget approaches infinity, and the gap between the expected rewards of two
arms approaches zero (small-gap regime). Our results suggest that under the
worst-case scenario characterized by the small-gap regime, our strategy, which
employs estimated variance, is asymptotically optimal even when the variances
are unknown.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12742" title="Abstract">arXiv:2312.12742</a> [<a href="/pdf/2312.12742" title="Download PDF">pdf</a>, <a href="/format/2312.12742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cached Transformers: Improving Transformers with Differentiable Memory  Cache
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+W">Wenqi Shao</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yixiao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaogang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinwei Gu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This work introduces a new Transformer model called Cached Transformer, which
uses Gated Recurrent Cached (GRC) attention to extend the self-attention
mechanism with a differentiable memory cache of tokens. GRC attention enables
attending to both past and current tokens, increasing the receptive field of
attention and allowing for exploring long-range dependencies. By utilizing a
recurrent gating unit to continuously update the cache, our model achieves
significant advancements in \textbf{six} language and vision tasks, including
language modeling, machine translation, ListOPs, image classification, object
detection, and instance segmentation. Furthermore, our approach surpasses
previous memory-based techniques in tasks such as language modeling and
displays the ability to be applied to a broader range of situations.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12743" title="Abstract">arXiv:2312.12743</a> [<a href="/pdf/2312.12743" title="Download PDF">pdf</a>, <a href="/format/2312.12743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PointeNet: A Lightweight Framework for Effective and Efficient Point  Cloud Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+L">Lipeng Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xuefeng Yan</a>, 
<a href="/search/cs?searchtype=author&query=Nan%2C+L">Liangliang Nan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Dingkun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Honghua Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+M">Mingqiang Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Current methodologies in point cloud analysis predominantly explore 3D
geometries, often achieved through the introduction of intricate learnable
geometric extractors in the encoder or by deepening networks with repeated
blocks. However, these approaches inevitably lead to a significant number of
learnable parameters, resulting in substantial computational costs and imposing
memory burdens on CPU/GPU. Additionally, the existing strategies are primarily
tailored for object-level point cloud classification and segmentation tasks,
with limited extensions to crucial scene-level applications, such as autonomous
driving. In response to these limitations, we introduce PointeNet, an efficient
network designed specifically for point cloud analysis. PointeNet distinguishes
itself with its lightweight architecture, low training cost, and plug-and-play
capability, effectively capturing representative features. The network consists
of a Multivariate Geometric Encoding (MGE) module and an optional
Distance-aware Semantic Enhancement (DSE) module. The MGE module employs
operations of sampling, grouping, and multivariate geometric aggregation to
lightweightly capture and adaptively aggregate multivariate geometric features,
providing a comprehensive depiction of 3D geometries. The DSE module, designed
for real-world autonomous driving scenarios, enhances the semantic perception
of point clouds, particularly for distant points. Our method demonstrates
flexibility by seamlessly integrating with a classification/segmentation head
or embedding into off-the-shelf 3D object detection networks, achieving notable
performance improvements at a minimal cost. Extensive experiments on
object-level datasets, including ModelNet40, ScanObjectNN, ShapeNetPart, and
the scene-level dataset KITTI, demonstrate the superior performance of
PointeNet over state-of-the-art methods in point cloud analysis.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12744" title="Abstract">arXiv:2312.12744</a> [<a href="/pdf/2312.12744" title="Download PDF">pdf</a>, <a href="/ps/2312.12744" title="Download PostScript">ps</a>, <a href="/format/2312.12744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D-CLMI: A Motor Imagery EEG Classification Model via Fusion of 3D-CNN  and LSTM with Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Shiwei Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yuejiang Hao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Due to the limitations in the accuracy and robustness of current
electroencephalogram (EEG) classification algorithms, applying motor imagery
(MI) for practical Brain-Computer Interface (BCI) applications remains
challenging. This paper proposed a model that combined a three-dimensional
convolutional neural network (CNN) with a long short-term memory (LSTM) network
with attention to classify MI-EEG signals. This model combined MI-EEG signals
from different channels into three-dimensional features and extracted spatial
features through convolution operations with multiple three-dimensional
convolutional kernels of different scales. At the same time, to ensure the
integrity of the extracted MI-EEG signal temporal features, the LSTM network
was directly trained on the preprocessed raw signal. Finally, the features
obtained from these two networks were combined and used for classification.
Experimental results showed that this model achieved a classification accuracy
of 92.7% and an F1-score of 0.91 on the public dataset BCI Competition IV
dataset 2a, which were both higher than the state-of-the-art models in the
field of MI tasks. Additionally, 12 participants were invited to complete a
four-class MI task in our lab, and experiments on the collected dataset showed
that the 3D-CLMI model also maintained the highest classification accuracy and
F1-score. The model greatly improved the classification accuracy of users'
motor imagery intentions, giving brain-computer interfaces better application
prospects in emerging fields such as autonomous vehicles and medical
rehabilitation.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12746" title="Abstract">arXiv:2312.12746</a> [<a href="/pdf/2312.12746" title="Download PDF">pdf</a>, <a href="/format/2312.12746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatFDA: Medical Records Risk Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+M">M Tran</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">C Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">In healthcare, the emphasis on patient safety and the minimization of medical
errors cannot be overstated. Despite concerted efforts, many healthcare
systems, especially in low-resource regions, still grapple with preventing
these errors effectively. This study explores a pioneering application aimed at
addressing this challenge by assisting caregivers in gauging potential risks
derived from medical notes. The application leverages data from openFDA,
delivering real-time, actionable insights regarding prescriptions. Preliminary
analyses conducted on the MIMIC-III \cite{mimic} dataset affirm a proof of
concept highlighting a reduction in medical errors and an amplification in
patient safety. This tool holds promise for drastically enhancing healthcare
outcomes in settings with limited resources. To bolster reproducibility and
foster further research, the codebase underpinning our methodology is
accessible on
https://github.com/autonlab/2023.hackAuton/tree/main/prescription_checker. This
is a submission for the 30th HackAuton CMU.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12747" title="Abstract">arXiv:2312.12747</a> [<a href="/pdf/2312.12747" title="Download PDF">pdf</a>, <a href="/format/2312.12747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ALMANACS: A Simulatability Benchmark for Language Model Explainability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mills%2C+E">Edmund Mills</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+S">Shiye Su</a>, 
<a href="/search/cs?searchtype=author&query=Russell%2C+S">Stuart Russell</a>, 
<a href="/search/cs?searchtype=author&query=Emmons%2C+S">Scott Emmons</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at https://github.com/edmundmills/ALMANACS}{<a href="https://github.com/edmundmills/ALMANACS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
<p class="mathjax">How do we measure the efficacy of language model explainability methods?
While many explainability methods have been developed, they are typically
evaluated on bespoke tasks, preventing an apples-to-apples comparison. To help
fill this gap, we present ALMANACS, a language model explainability benchmark.
ALMANACS scores explainability methods on simulatability, i.e., how well the
explanations improve behavior prediction on new inputs. The ALMANACS scenarios
span twelve safety-relevant topics such as ethical reasoning and advanced AI
behaviors; they have idiosyncratic premises to invoke model-specific behavior;
and they have a train-test distributional shift to encourage faithful
explanations. By using another language model to predict behavior based on the
explanations, ALMANACS is a fully automated benchmark. We use ALMANACS to
evaluate counterfactuals, rationalizations, attention, and Integrated Gradients
explanations. Our results are sobering: when averaged across all topics, no
explanation method outperforms the explanation-free control. We conclude that
despite modest successes in prior work, developing an explanation method that
aids simulatability in ALMANACS remains an open challenge.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12748" title="Abstract">arXiv:2312.12748</a> [<a href="/pdf/2312.12748" title="Download PDF">pdf</a>, <a href="/format/2312.12748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergence of Fairness Behavior Driven by Reputation-Based Voluntary  Participation in Evolutionary Dictator Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanling Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yin Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaojie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+G">Guangming Xie</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> "Emergence of Fairness Behavior Driven by Reputation-Based
  Voluntary Participation in Evolutionary Dictator Games," in IEEE Transactions
  on Computational Social Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Recently, reputation-based indirect reciprocity has been widely applied to
the study on fairness behavior. Previous works mainly investigate indirect
reciprocity by considering compulsory participation. While in reality,
individuals may choose voluntary participation according to the opponent's
reputation. It is still unclear how such reputation-based voluntary
participation influences the evolution of fairness. To address this question,
we introduce indirect reciprocity with voluntary participation into the
dictator game (DG). We respectively consider good dictators or recipients can
voluntarily participate in games when the opponents are assessed as bad. We
theoretically calculate the fairness level under all social norms of
third-order information. Our findings reveal that several social norms induce
the high fairness level in both scenarios. However, more social norms lead to a
high fairness level for voluntary participation of recipients, compared with
the one of good dictators. The results also hold when the probability of
voluntary participation is not low. Our results demonstrate that recipients'
voluntary participation is more effective in promoting the emergence of
fairness behavior.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12750" title="Abstract">arXiv:2312.12750</a> [<a href="/pdf/2312.12750" title="Download PDF">pdf</a>, <a href="/format/2312.12750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallel Ranking of Ads and Creatives in Real-Time Advertising Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhiguang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chun Gan</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+L">Liufang Sang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenlong Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jie He</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Changping Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhangang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jingping Shao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures, AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">"Creativity is the heart and soul of advertising services". Effective
creatives can create a win-win scenario: advertisers can reach target users and
achieve marketing objectives more effectively, users can more quickly find
products of interest, and platforms can generate more advertising revenue. With
the advent of AI-Generated Content, advertisers now can produce vast amounts of
creative content at a minimal cost. The current challenge lies in how
advertising systems can select the most pertinent creative in real-time for
each user personally. Existing methods typically perform serial ranking of ads
or creatives, limiting the creative module in terms of both effectiveness and
efficiency. In this paper, we propose for the first time a novel architecture
for online parallel estimation of ads and creatives ranking, as well as the
corresponding offline joint optimization model. The online architecture enables
sophisticated personalized creative modeling while reducing overall latency.
The offline joint model for CTR estimation allows mutual awareness and
collaborative optimization between ads and creatives. Additionally, we optimize
the offline evaluation metrics for the implicit feedback sorting task involved
in ad creative ranking. We conduct extensive experiments to compare ours with
two state-of-the-art approaches. The results demonstrate the effectiveness of
our approach in both offline evaluations and real-world advertising platforms
online in terms of response time, CTR, and CPM.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12751" title="Abstract">arXiv:2312.12751</a> [<a href="/pdf/2312.12751" title="Download PDF">pdf</a>, <a href="/format/2312.12751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-Centred Learning Analytics and AI in Education: a Systematic  Literature Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alfredo%2C+R">Riordan Alfredo</a>, 
<a href="/search/cs?searchtype=author&query=Echeverria%2C+V">Vanessa Echeverria</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yueqiao Jin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Lixiang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Swiecki%2C+Z">Zachari Swiecki</a>, 
<a href="/search/cs?searchtype=author&query=Ga%C5%A1evi%C4%87%2C+D">Dragan Ga&#x161;evi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Martinez-Maldonado%2C+R">Roberto Martinez-Maldonado</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 6 figures, 1 table in Appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">The rapid expansion of Learning Analytics (LA) and Artificial Intelligence in
Education (AIED) offers new scalable, data-intensive systems but also raises
concerns about data privacy and agency. Excluding stakeholders -- like students
and teachers -- from the design process can potentially lead to mistrust and
inadequately aligned tools. Despite a shift towards human-centred design in
recent LA and AIED research, there remain gaps in our understanding of the
importance of human control, safety, reliability, and trustworthiness in the
design and implementation of these systems. We conducted a systematic
literature review to explore these concerns and gaps. We analysed 108 papers to
provide insights about i) the current state of human-centred LA/AIED research;
ii) the extent to which educational stakeholders have contributed to the design
process of human-centred LA/AIED systems; iii) the current balance between
human control and computer automation of such systems; and iv) the extent to
which safety, reliability and trustworthiness have been considered in the
literature. Results indicate some consideration of human control in LA/AIED
system design, but limited end-user involvement in actual design. Based on
these findings, we recommend: 1) carefully balancing stakeholders' involvement
in designing and deploying LA/AIED systems throughout all design phases, 2)
actively involving target end-users, especially students, to delineate the
balance between human control and automation, and 3) exploring safety,
reliability, and trustworthiness as principles in future human-centred LA/AIED
systems.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12754" title="Abstract">arXiv:2312.12754</a> [<a href="/pdf/2312.12754" title="Download PDF">pdf</a>, <a href="/format/2312.12754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral Prompt Tuning:Unveiling Unseen Classes for Zero-Shot Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wenhao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Rongtao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Changwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shibiao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Li Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Man Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaopeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024 Accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Recently, CLIP has found practical utility in the domain of pixel-level
zero-shot segmentation tasks. The present landscape features two-stage
methodologies beset by issues such as intricate pipelines and elevated
computational costs. While current one-stage approaches alleviate these
concerns and incorporate Visual Prompt Training (VPT) to uphold CLIP's
generalization capacity, they still fall short in fully harnessing CLIP's
potential for pixel-level unseen class demarcation and precise pixel
predictions. To further stimulate CLIP's zero-shot dense prediction capability,
we propose SPT-SEG, a one-stage approach that improves CLIP's adaptability from
image to pixel. Specifically, we initially introduce Spectral Prompt Tuning
(SPT), incorporating spectral prompts into the CLIP visual encoder's shallow
layers to capture structural intricacies of images, thereby enhancing
comprehension of unseen classes. Subsequently, we introduce the Spectral Guided
Decoder (SGD), utilizing both high and low-frequency information to steer the
network's spatial focus towards more prominent classification features,
enabling precise pixel-level prediction outcomes. Through extensive experiments
on two public datasets, we demonstrate the superiority of our method over
state-of-the-art approaches, performing well across all classes and
particularly excelling in handling unseen classes. Code is available
at:https://github.com/clearxu/SPT.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12759" title="Abstract">arXiv:2312.12759</a> [<a href="/pdf/2312.12759" title="Download PDF">pdf</a>, <a href="/format/2312.12759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Control Barrier Functions with Bayesian Inference for Unknown  Stochastic Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Chuanzheng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Meng%2C+Y">Yiming Meng</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jun Liu</a>, 
<a href="/search/eess?searchtype=author&query=Smith%2C+S">Stephen Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2104.02585">arXiv:2104.02585</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Control barrier functions are widely used to synthesize safety-critical
controls. However, the presence of Gaussian-type noise in dynamical systems can
generate unbounded signals and potentially result in severe consequences.
Although research has been conducted in the field of safety-critical control
for stochastic systems, in many real-world scenarios, we do not have precise
knowledge about the stochastic dynamics. In this paper, we delve into the
safety-critical control for stochastic systems where both the drift and
diffusion components are unknown. We employ Bayesian inference as a data-driven
approach to approximate the system. To be more specific, we utilize Bayesian
linear regression along with the central limit theorem to estimate the drift
term, and employ Bayesian inference to approximate the diffusion term. Through
simulations, we verify our findings by applying them to a nonlinear dynamical
model and an adaptive cruise control model.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12763" title="Abstract">arXiv:2312.12763</a> [<a href="/pdf/2312.12763" title="Download PDF">pdf</a>, <a href="/format/2312.12763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AMD:Anatomical Motion Diffusion with Interpretable Motion Decomposition  and Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jing%2C+B">Beibei Jing</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Youjia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zikai Song</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Junqing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wei Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generating realistic human motion sequences from text descriptions is a
challenging task that requires capturing the rich expressiveness of both
natural language and human motion.Recent advances in diffusion models have
enabled significant progress in human motion synthesis.However, existing
methods struggle to handle text inputs that describe complex or long motions.In
this paper, we propose the Adaptable Motion Diffusion (AMD) model, which
leverages a Large Language Model (LLM) to parse the input text into a sequence
of concise and interpretable anatomical scripts that correspond to the target
motion.This process exploits the LLM's ability to provide anatomical guidance
for complex motion synthesis.We then devise a two-branch fusion scheme that
balances the influence of the input text and the anatomical scripts on the
inverse diffusion process, which adaptively ensures the semantic fidelity and
diversity of the synthesized motion.Our method can effectively handle texts
with complex or long motion descriptions, where existing methods often fail.
Experiments on datasets with relatively more complex motions, such as CLCD1 and
CLCD2, demonstrate that our AMD significantly outperforms existing
state-of-the-art models.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12766" title="Abstract">arXiv:2312.12766</a> [<a href="/pdf/2312.12766" title="Download PDF">pdf</a>, <a href="/format/2312.12766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IOPS: An Unified SpMM Accelerator Based on Inner-Outer-Hybrid Product
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wenhao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wendi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Song Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yi Kang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Sparse matrix multiplication (SpMM) is widely applied to numerous domains,
such as graph processing, machine learning, and data analytics. However, inner
product based SpMM induces redundant zero-element computing for mismatched
nonzero operands, while outer product based approach lacks input reuse across
Process Elements (PEs) and poor output locality for accumulating partial sum
(psum) matrices. Besides, current works only focus on sparse-sparse matrix
multiplication (SSMM) or sparse-dense matrix multiplication (SDMM), rarely
performing efficiently for both. To address these problems, this paper proposes
an unified SpMM accelerator, called IOPS, hybridizing inner with outer
products. It reuses the input matrix among PEs with inner product dataflow, and
removes zero-element calculations with outer product approach in each PE, which
can efficiently process SSMM and SDMM. Moreover, an address mapping method is
designed to accumulate the irregular sparse psum matrices, reducing the latency
and DRAM access of psum accumulating. Furthermore, an adaptive partition
strategy is proposed to tile the input matrices based on their sparsity ratios,
effectively utilizing the storage of architecture and reducing DRAM access.
Compared with the SSMM accelerator, SpArch, we achieve 1.7x~6.3x energy
efficiency and 1.2x~4.4x resource efficiency, with 1.4x~2.1x DRAM access
saving.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12768" title="Abstract">arXiv:2312.12768</a> [<a href="/pdf/2312.12768" title="Download PDF">pdf</a>, <a href="/format/2312.12768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mutual-modality Adversarial Attack with Semantic Perturbation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jingwen Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+R">Ruonan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Songhua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinchao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Adversarial attacks constitute a notable threat to machine learning systems,
given their potential to induce erroneous predictions and classifications.
However, within real-world contexts, the essential specifics of the deployed
model are frequently treated as a black box, consequently mitigating the
vulnerability to such attacks. Thus, enhancing the transferability of the
adversarial samples has become a crucial area of research, which heavily relies
on selecting appropriate surrogate models. To address this challenge, we
propose a novel approach that generates adversarial attacks in a
mutual-modality optimization scheme. Our approach is accomplished by leveraging
the pre-trained CLIP model. Firstly, we conduct a visual attack on the clean
image that causes semantic perturbations on the aligned embedding space with
the other textual modality. Then, we apply the corresponding defense on the
textual modality by updating the prompts, which forces the re-matching on the
perturbed embedding space. Finally, to enhance the attack transferability, we
utilize the iterative training strategy on the visual attack and the textual
defense, where the two processes optimize from each other. We evaluate our
approach on several benchmark datasets and demonstrate that our mutual-modal
attack strategy can effectively produce high-transferable attacks, which are
stable regardless of the target networks. Our approach outperforms
state-of-the-art attack methods and can be readily deployed as a plug-and-play
solution.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12771" title="Abstract">arXiv:2312.12771</a> [<a href="/pdf/2312.12771" title="Download PDF">pdf</a>, <a href="/format/2312.12771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational formulation and monolithic solution of computational  homogenization methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hesch%2C+C">Christian Hesch</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+F">Felix Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Schu%C3%9F%2C+S">Stefan Schu&#xdf;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">In this contribution, we derive a consistent variational formulation for
computational homogenization methods and show that traditional FE2 and IGA2
approaches are special discretization and solution techniques of this most
general framework. This allows us to enhance dramatically the numerical
analysis as well as the solution of the arising algebraic system. In
particular, we expand the dimension of the continuous system, discretize the
higher dimensional problem consistently and apply afterwards a discrete
null-space matrix to remove the additional dimensions. A benchmark problem, for
which we can obtain an analytical solution, demonstrates the superiority of the
chosen approach aiming to reduce the immense computational costs of traditional
FE2 and IGA2 formulations to a fraction of the original requirements. Finally,
we demonstrate a further reduction of the computational costs for the solution
of general non-linear problems.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12772" title="Abstract">arXiv:2312.12772</a> [<a href="/pdf/2312.12772" title="Download PDF">pdf</a>, <a href="/format/2312.12772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Realistic Rainy Weather Simulation for LiDARs in CARLA Simulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Donglin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenfeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wentao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+G">Guohang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xing Gao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Botian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Si Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xinyu Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Employing data augmentation methods to enhance perception performance in
adverse weather has attracted considerable attention recently. Most of the
LiDAR augmentation methods post-process the existing dataset by physics-based
models or machine-learning methods. However, due to the limited environmental
annotations and the fixed vehicle trajectories in the existing dataset, it is
challenging to edit the scene and expand the diversity of traffic flow and
scenario. To this end, we propose a simulator-based physical modeling approach
to augment LiDAR data in rainy weather in order to improve the perception
performance of LiDAR in this scenario. We complete the modeling task of the
rainy weather in the CARLA simulator and establish a pipeline for LiDAR data
collection. In particular, we pay special attention to the spray and splash
rolled up by the wheels of surrounding vehicles in rain and complete the
simulation of this special scenario through the Spray Emitter method we
developed. In addition, we examine the influence of different weather
conditions on the intensity of the LiDAR echo, develop a prediction network for
the intensity of the LiDAR echo, and complete the simulation of 4-feat LiDAR
point cloud data. In the experiment, we observe that the model augmented by the
synthetic data improves the object detection task's performance in the rainy
sequence of the Waymo Open Dataset. Both the code and the dataset will be made
publicly available at https://github.com/PJLab-ADG/PCSim#rainypcsim.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12773" title="Abstract">arXiv:2312.12773</a> [<a href="/pdf/2312.12773" title="Download PDF">pdf</a>, <a href="/ps/2312.12773" title="Download PostScript">ps</a>, <a href="/format/2312.12773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segmenting Messy Text: Detecting Boundaries in Text Derived from  Historical Newspaper Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anderson%2C+C">Carol Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Crone%2C+P">Phil Crone</a> (Ancestry.com)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2020 25th International Conference on Pattern Recognition (ICPR),
  Milan, Italy, 2021, pp. 5543-5550
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Text segmentation, the task of dividing a document into sections, is often a
prerequisite for performing additional natural language processing tasks.
Existing text segmentation methods have typically been developed and tested
using clean, narrative-style text with segments containing distinct topics.
Here we consider a challenging text segmentation task: dividing newspaper
marriage announcement lists into units of one announcement each. In many cases
the information is not structured into sentences, and adjacent segments are not
topically distinct from each other. In addition, the text of the announcements,
which is derived from images of historical newspapers via optical character
recognition, contains many typographical errors. As a result, these
announcements are not amenable to segmentation with existing techniques. We
present a novel deep learning-based model for segmenting such text and show
that it significantly outperforms an existing state-of-the-art method on our
task.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12774" title="Abstract">arXiv:2312.12774</a> [<a href="/pdf/2312.12774" title="Download PDF">pdf</a>, <a href="/format/2312.12774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Extraction, Transformation, and Loading Process Automation for  Algorithmic Trading Machine Learning Modelling and Performance Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ebadifard%2C+N">Nassi Ebadifard</a>, 
<a href="/search/cs?searchtype=author&query=Parihar%2C+A">Ajitesh Parihar</a>, 
<a href="/search/cs?searchtype=author&query=Khmelevsky%2C+Y">Youry Khmelevsky</a>, 
<a href="/search/cs?searchtype=author&query=Hains%2C+G">Gaetan Hains</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+A">Albert Wong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Frank Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">A data warehouse efficiently prepares data for effective and fast data
analysis and modelling using machine learning algorithms. This paper discusses
existing solutions for the Data Extraction, Transformation, and Loading (ETL)
process and automation for algorithmic trading algorithms. Integrating the Data
Warehouses and, in the future, the Data Lakes with the Machine Learning
Algorithms gives enormous opportunities in research when performance and data
processing time become critical non-functional requirements.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12776" title="Abstract">arXiv:2312.12776</a> [<a href="/pdf/2312.12776" title="Download PDF">pdf</a>, <a href="/format/2312.12776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational homogenization of phase-field fracture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+F">Felix Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Schu%C3%9F%2C+S">Stefan Schu&#xdf;</a>, 
<a href="/search/cs?searchtype=author&query=Hesch%2C+C">Christian Hesch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">In this contribution we investigate the application of phase-field fracture
models on non-linear multiscale computational homogenization schemes. In
particular, we introduce different phase-fields on a two-scale problem and
develop a thermodynamically consistent model. This allows on the one hand for
the prediction of local micro-fracture patterns, which effectively acts as an
anisotropic damage model on the macroscale. On the other and, the
macro-fracture phase-field model allows to predict complex fracture pattern
with regard to local microstructures. Both phase-fields are introduced in a
common framework, such that a joint consistent linearization for the
Newton-Raphson iteration can be developed. Finally, the limits of both models
as well as the applicability are shown in different numerical examples.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12778" title="Abstract">arXiv:2312.12778</a> [<a href="/pdf/2312.12778" title="Download PDF">pdf</a>, <a href="/ps/2312.12778" title="Download PostScript">ps</a>, <a href="/format/2312.12778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative business intelligence virtual assistant
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cherednichenko%2C+O">Olga Cherednichenko</a>, 
<a href="/search/cs?searchtype=author&query=Muhammad%2C+F">Fahad Muhammad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MoMLeT+DS 2023: 5th International Workshop on Modern Machine Learning Technologies and Data Science, June 3, 2023, Lviv, Ukraine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The present-day business landscape necessitates novel methodologies that
integrate intelligent technologies and tools capable of swiftly providing
precise and dependable information for decision-making purposes. Contemporary
society is characterized by vast amounts of accumulated data across various
domains, which hold considerable potential for informing and guiding
decision-making processes. However, these data are typically collected and
stored by disparate and unrelated software systems, stored in diverse formats,
and offer varying levels of accessibility and security. To address the
challenges associated with processing such large volumes of data, organizations
often rely on data analysts. Nonetheless, a significant hurdle in harnessing
the benefits of accumulated data lies in the lack of direct communication
between technical specialists, decision-makers, and business process analysts.
To overcome this issue, the application of collaborative business intelligence
(CBI) emerges as a viable solution. This research focuses on the applications
of data mining and aims to model CBI processes within distributed virtual teams
through the interaction of users and a CBI Virtual Assistant. The proposed
virtual assistant for CBI endeavors to enhance data exploration accessibility
for a wider range of users and streamline the time and effort required for data
analysis. The key contributions of this study encompass: 1) a reference model
representing collaborative BI, inspired by linguistic theory; 2) an approach
that enables the transformation of user queries into executable commands,
thereby facilitating their utilization within data exploration software; and 3)
the primary workflow of a conversational agent designed for data analytics.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12781" title="Abstract">arXiv:2312.12781</a> [<a href="/pdf/2312.12781" title="Download PDF">pdf</a>, <a href="/format/2312.12781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DynaLay: An Introspective Approach to Dynamic Layer Selection for Deep  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mathur%2C+M">Mrinal Mathur</a>, 
<a href="/search/cs?searchtype=author&query=Plis%2C+S">Sergey Plis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep learning models have become increasingly computationally intensive,
requiring extensive computational resources and time for both training and
inference. A significant contributing factor to this challenge is the uniform
computational effort expended on each input example, regardless of its
complexity. We introduce \textbf{DynaLay}, an alternative architecture that
features a decision-making agent to adaptively select the most suitable layers
for processing each input, thereby endowing the model with a remarkable level
of introspection. DynaLay reevaluates more complex inputs during inference,
adjusting the computational effort to optimize both performance and efficiency.
The core of the system is a main model equipped with Fixed-Point Iterative
(FPI) layers, capable of accurately approximating complex functions, paired
with an agent that chooses these layers or a direct action based on the
introspection of the models inner state. The model invests more time in
processing harder examples, while minimal computation is required for easier
ones. This introspective approach is a step toward developing deep learning
models that "think" and "ponder", rather than "ballistically'' produce answers.
Our experiments demonstrate that DynaLay achieves accuracy comparable to
conventional deep models while significantly reducing computational demands.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12784" title="Abstract">arXiv:2312.12784</a> [<a href="/pdf/2312.12784" title="Download PDF">pdf</a>, <a href="/format/2312.12784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Cell Library Characterization for Design Technology Co-Optimization  Based on Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Tianliang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhihui Deng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xuguang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+L">Leilai Shao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Design technology co-optimization (DTCO) plays a critical role in achieving
optimal power, performance, and area (PPA) for advanced semiconductor process
development. Cell library characterization is essential in DTCO flow, but
traditional methods are time-consuming and costly. To overcome these
challenges, we propose a graph neural network (GNN)-based machine learning
model for rapid and accurate cell library characterization. Our model
incorporates cell structures and demonstrates high prediction accuracy across
various process-voltage-temperature (PVT) corners and technology parameters.
Validation with 512 unseen technology corners and over one million test data
points shows accurate predictions of delay, power, and input pin capacitance
for 33 types of cells, with a mean absolute percentage error (MAPE) $\le$ 0.95%
and a speed-up of 100X compared with SPICE simulations. Additionally, we
investigate system-level metrics such as worst negative slack (WNS), leakage
power, and dynamic power using predictions obtained from the GNN-based model on
unseen corners. Our model achieves precise predictions, with absolute error
$\le$3.0 ps for WNS, percentage errors $\le$0.60% for leakage power, and
$\le$0.99% for dynamic power, when compared to golden reference. With the
developed model, we further proposed a fine-grained drive strength
interpolation methodology to enhance PPA for small-to-medium-scale designs,
resulting in an approximate 1-3% improvement.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12787" title="Abstract">arXiv:2312.12787</a> [<a href="/pdf/2312.12787" title="Download PDF">pdf</a>, <a href="/format/2312.12787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calderon-preconditioned boundary integral equations of the Burton-Miller  type for transmission problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Matsumoto%2C+Y">Yasuhiro Matsumoto</a>, 
<a href="/search/math?searchtype=author&query=Yoshiki%2C+A">Akihiro Yoshiki</a>, 
<a href="/search/math?searchtype=author&query=Isakari%2C+H">Hiroshi Isakari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper proposes well-conditioned boundary integral equations based on the
Burton-Miller method for solving transmission problems. The Burton-Miller
method is widely accepted as a highly accurate numerical method based on the
boundary integral equation for solving exterior wave problems. While this
method can also be applied to solve the transmission problems, a
straightforward formulation may yield ill-conditioned integral equations.
Consequently, the resulting linear algebraic equations may involve a
coefficient matrix with a huge condition number, leading to poor convergence of
Krylov-based linear solvers. To address this challenge, our study enhances
Burton-Miller-type boundary integral equations tailored for transmission
problems by exploiting the Calderon formula. In cases where a single material
exists in an unbounded host medium, we demonstrate the formulation of the
boundary integral equation such that the underlying integral operator ${\cal
A}$ is spectrally well-conditioned. Specifically, ${\cal A}$ can be designed in
a simple manner that ensures ${\cal A}^2$ is bounded and has only a single
eigenvalue accumulation point. Furthermore, we extend our analysis to the
multi-material case, proving that the square of the proposed operator has only
a few eigenvalues except for a compact perturbation. Through numerical examples
of several benchmark problems, we illustrate that our formulation reduces the
iteration number required by iterative linear solvers, even in the presence of
material junction points; locations where three or more sub-domains meet on the
boundary.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12791" title="Abstract">arXiv:2312.12791</a> [<a href="/pdf/2312.12791" title="Download PDF">pdf</a>, <a href="/format/2312.12791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-Based Control with Sparse Neural Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Genggeng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jeff He</a>, 
<a href="/search/cs?searchtype=author&query=Marcucci%2C+T">Tobia Marcucci</a>, 
<a href="/search/cs?searchtype=author&query=Fei-Fei%2C+L">Li Fei-Fei</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunzhu Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023. For tutorial code and additional visualizations, see <a href="https://robopil.github.io/Sparse-Dynamics/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Learning predictive models from observations using deep neural networks
(DNNs) is a promising new approach to many real-world planning and control
problems. However, common DNNs are too unstructured for effective planning, and
current control methods typically rely on extensive sampling or local gradient
descent. In this paper, we propose a new framework for integrated model
learning and predictive control that is amenable to efficient optimization
algorithms. Specifically, we start with a ReLU neural model of the system
dynamics and, with minimal losses in prediction accuracy, we gradually sparsify
it by removing redundant neurons. This discrete sparsification process is
approximated as a continuous problem, enabling an end-to-end optimization of
both the model architecture and the weight parameters. The sparsified model is
subsequently used by a mixed-integer predictive controller, which represents
the neuron activations as binary variables and employs efficient
branch-and-bound algorithms. Our framework is applicable to a wide variety of
DNNs, from simple multilayer perceptrons to complex graph neural dynamics. It
can efficiently handle tasks involving complicated contact dynamics, such as
object pushing, compositional object sorting, and manipulation of deformable
objects. Numerical and hardware experiments show that, despite the aggressive
sparsification, our framework can deliver better closed-loop performance than
existing state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12792" title="Abstract">arXiv:2312.12792</a> [<a href="/pdf/2312.12792" title="Download PDF">pdf</a>, <a href="/ps/2312.12792" title="Download PostScript">ps</a>, <a href="/format/2312.12792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cut elimination for propositional cyclic proof systems with fixed-point  operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hori%2C+H">Hiromasa Hori</a>, 
<a href="/search/cs?searchtype=author&query=Nakazawa%2C+K">Koji Nakazawa</a>, 
<a href="/search/cs?searchtype=author&query=Tatsuta%2C+M">Makoto Tatsuta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Logic (math.LO)

</div>
<p class="mathjax">Infinitary and cyclic proof systems are proof systems for logical formulas
with fixed-point operators or inductive definitions. A cyclic proof system is a
restriction of the corresponding infinitary proof system. Hence, these proof
systems are generally not the same, as in the cyclic system may be weaker than
the infinitary system. For several logics, the infinitary proof systems are
shown to be cut-free complete. However, cyclic proof systems are characterized
with many unknown problems on the (cut-free) completeness or the
cut-elimination property. In this study, we show that the provability of
infinitary and cyclic proof systems are the same for some propositional logics
with fixed-point operators or inductive definitions and that the cyclic proof
systems are cut-free complete.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12794" title="Abstract">arXiv:2312.12794</a> [<a href="/pdf/2312.12794" title="Download PDF">pdf</a>, <a href="/format/2312.12794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bandit Sequential Posted Pricing via Half-Concavity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singla%2C+S">Sahil Singla</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Sequential posted pricing auctions are popular because of their simplicity in
practice and their tractability in theory. A usual assumption in their study is
that the Bayesian prior distributions of the buyers are known to the seller,
while in reality these priors can only be accessed from historical data. To
overcome this assumption, we study sequential posted pricing in the bandit
learning model, where the seller interacts with $n$ buyers over $T$ rounds: In
each round the seller posts $n$ prices for the $n$ buyers and the first buyer
with a valuation higher than the price takes the item. The only feedback that
the seller receives in each round is the revenue.
<br />Our main results obtain nearly-optimal regret bounds for single-item
sequential posted pricing in the bandit learning model. In particular, we
achieve an $\tilde{O}(\mathsf{poly}(n)\sqrt{T})$ regret for buyers with
(Myerson's) regular distributions and an
$\tilde{O}(\mathsf{poly}(n)T^{{2}/{3}})$ regret for buyers with general
distributions, both of which are tight in the number of rounds $T$. Our result
for regular distributions was previously not known even for the single-buyer
setting and relies on a new half-concavity property of the revenue function in
the value space. For $n$ sequential buyers, our technique is to run a
generalized single-buyer algorithm for all the buyers and to carefully bound
the regret from the sub-optimal pricing of the suffix buyers.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12795" title="Abstract">arXiv:2312.12795</a> [<a href="/pdf/2312.12795" title="Download PDF">pdf</a>, <a href="/ps/2312.12795" title="Download PostScript">ps</a>, <a href="/format/2312.12795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Trading and Scheduling among Coupled Carbon-Electricity-Heat-Gas  Industrial Clusters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhu%2C+D">Dafeng Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+B">Bo Yang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Y">Yu Wu</a>, 
<a href="/search/eess?searchtype=author&query=Deng%2C+H">Haoran Deng</a>, 
<a href="/search/eess?searchtype=author&query=Dong%2C+Z">Zhaoyang Dong</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+K">Kai Ma</a>, 
<a href="/search/eess?searchtype=author&query=Guan%2C+X">Xinping Guan</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Smart Grid, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents a carbon-energy coupling management framework for an
industrial park, where the carbon flow model accompanying multi-energy flows is
adopted to track and suppress carbon emissions on the user side. To deal with
the quadratic constraint of gas flows, a bound tightening algorithm for
constraints relaxation is adopted. The synergies among the carbon capture,
energy storage, power-to-gas further consume renewable energy and reduce carbon
emissions. Aiming at carbon emissions disparities and supply-demand imbalances,
this paper proposes a carbon trading ladder reward and punishment mechanism and
an energy trading and scheduling method based on Lyapunov optimization and
matching game to maximize the long-term benefits of each industrial cluster
without knowing the prior information of random variables. Case studies show
that our proposed trading method can reduce overall costs and carbon emissions
while relieving energy pressure, which is important for Environmental, Social
and Governance (ESG).
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12797" title="Abstract">arXiv:2312.12797</a> [<a href="/pdf/2312.12797" title="Download PDF">pdf</a>, <a href="/ps/2312.12797" title="Download PostScript">ps</a>, <a href="/format/2312.12797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Join Sampling under Acyclic Degree Constraints and (Cyclic) Subgraph  Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ru Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+Y">Yufei Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Given a join with an acyclic set of degree constraints, we show how to draw a
uniformly random sample from the join result in $O(\mathit{polymat}/ \max \{1,
\mathrm{OUT} \})$ expected time after a preprocessing of $O(\mathrm{IN})$
expected time, where $\mathrm{IN}$, $\mathrm{OUT}$, and $\mathit{polymat}$ are
the join's input size, output size, and polymatroid bound, respectively. This
compares favorably with the state of the art (Deng et al.\ and Kim et al., both
in PODS'23), which states that a uniformly random sample can be drawn in
$\tilde{O}(\mathrm{AGM} / \max \{1, \mathrm{OUT}\})$ expected time after a
preprocessing phase of $\tilde{O}(\mathrm{IN})$ expected time, where
$\mathrm{AGM}$ is the join's AGM bound.
<br />We then utilize our techniques to tackle {\em directed subgraph sampling}.
Let $G = (V, E)$ be a directed data graph where each vertex has an out-degree
at most $\lambda$, and let $P$ be a directed pattern graph with $O(1)$
vertices. The objective is to uniformly sample an occurrence of $P$ in $G$. The
problem can be modeled as join sampling with input size $\mathrm{IN} =
\Theta(|E|)$ but, whenever $P$ contains cycles, the converted join has {\em
cyclic} degree constraints. We show that it is always possible to throw away
certain degree constraints such that (i) the remaining constraints are acyclic
and (ii) the new join has asymptotically the same polymatroid bound
$\mathit{polymat}$ as the old one. Combining this finding with our new join
sampling solution yields an algorithm to sample from the original (cyclic) join
(thereby yielding a uniformly random occurrence of $P$) in $O(\mathit{polymat}/
\max \{1, \mathrm{OUT}\})$ expected time after $O(|E|)$ expected-time
preprocessing. We also prove similar results for {\em undirected subgraph
sampling} and demonstrate how our techniques can be significantly simplified in
that scenario.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12803" title="Abstract">arXiv:2312.12803</a> [<a href="/pdf/2312.12803" title="Download PDF">pdf</a>, <a href="/format/2312.12803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Repairing Schemes for Tamo-Barg Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+H">Han Cai</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+Y">Ying Miao</a>, 
<a href="/search/cs?searchtype=author&query=Schwartz%2C+M">Moshe Schwartz</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiaohu Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we explore a practical system setting where a rack-aware
storage system consists of racks, each containing a few parity checks, referred
to as a rack-aware system with locality. To minimize cross-rack bandwidth in
this system, we organize the repair sets of locally repairable codes into racks
and investigate the problem of repairing erasures in locally repairable codes
beyond the code locality. We devise two repair schemes to reduce the repair
bandwidth for Tamo-Barg codes under the rack-aware model by setting each repair
set as a rack. We then establish a cut-set bound for locally repairable codes
under the rack-aware model with locality. Using this bound we show that our
second repair scheme is optimal. Furthermore, we consider the partial-repair
problem for locally repairable codes under the rack-aware model with locality,
and introduce both repair schemes and bounds for this scenario.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12804" title="Abstract">arXiv:2312.12804</a> [<a href="/pdf/2312.12804" title="Download PDF">pdf</a>, <a href="/format/2312.12804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-stages attention Breast cancer classification based on nonlinear  spiking neural P neurons with autapses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hong Peng</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiaohui Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+X">Xianzhong Long</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Breast cancer(BC) is a prevalent type of malignant tumor in women. Early
diagnosis and treatment are vital for enhancing the patients' survival rate.
Downsampling in deep networks may lead to loss of information, so for
compensating the detail and edge information and allowing convolutional neural
networks to pay more attention to seek the lesion region, we propose a
multi-stages attention architecture based on NSNP neurons with autapses. First,
unlike the single-scale attention acquisition methods of existing methods, we
set up spatial attention acquisition at each feature map scale of the
convolutional network to obtain an fusion global information on attention
guidance. Then we introduce a new type of NSNP variants called NSNP neurons
with autapses. Specifically, NSNP systems are modularized as feature encoders,
recoding the features extracted from convolutional neural network as well as
the fusion of attention information and preserve the key characteristic
elements in feature maps. This ensures the retention of valuable data while
gradually transforming high-dimensional complicated info into low-dimensional
ones. The proposed method is evaluated on the public dataset BreakHis at
various magnifications and classification tasks. It achieves a classification
accuracy of 96.32% at all magnification cases, outperforming state-of-the-art
methods. Ablation studies are also performed, verifying the proposed model's
efficacy. The source code is available at
XhuBobYoung/Breast-cancer-Classification.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12806" title="Abstract">arXiv:2312.12806</a> [<a href="/pdf/2312.12806" title="Download PDF">pdf</a>, <a href="/format/2312.12806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yan Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Linlin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Ye Wang</a>, 
<a href="/search/cs?searchtype=author&query=de+Melo%2C+G">Gerard de Melo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Liang He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The emergence of various medical large language models (LLMs) in the medical
domain has highlighted the need for unified evaluation standards, as manual
evaluation of LLMs proves to be time-consuming and labor-intensive. To address
this issue, we introduce MedBench, a comprehensive benchmark for the Chinese
medical domain, comprising 40,041 questions sourced from authentic examination
exercises and medical reports of diverse branches of medicine. In particular,
this benchmark is composed of four key components: the Chinese Medical
Licensing Examination, the Resident Standardization Training Examination, the
Doctor In-Charge Qualification Examination, and real-world clinic cases
encompassing examinations, diagnoses, and treatments. MedBench replicates the
educational progression and clinical practice experiences of doctors in
Mainland China, thereby establishing itself as a credible benchmark for
assessing the mastery of knowledge and reasoning abilities in medical language
learning models. We perform extensive experiments and conduct an in-depth
analysis from diverse perspectives, which culminate in the following findings:
(1) Chinese medical LLMs underperform on this benchmark, highlighting the need
for significant advances in clinical knowledge and diagnostic precision. (2)
Several general-domain LLMs surprisingly possess considerable medical
knowledge. These findings elucidate both the capabilities and limitations of
LLMs within the context of MedBench, with the ultimate goal of aiding the
medical research community.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12807" title="Abstract">arXiv:2312.12807</a> [<a href="/pdf/2312.12807" title="Download PDF">pdf</a>, <a href="/format/2312.12807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> All but One: Surgical Concept Erasing with Model Preservation in  Text-to-Image Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Seunghoo Hong</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Juhun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+S+S">Simon S. Woo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main paper with supplementary materials
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Text-to-Image models such as Stable Diffusion have shown impressive image
generation synthesis, thanks to the utilization of large-scale datasets.
However, these datasets may contain sexually explicit, copyrighted, or
undesirable content, which allows the model to directly generate them. Given
that retraining these large models on individual concept deletion requests is
infeasible, fine-tuning algorithms have been developed to tackle concept
erasing in diffusion models. While these algorithms yield good concept erasure,
they all present one of the following issues: 1) the corrupted feature space
yields synthesis of disintegrated objects, 2) the initially synthesized content
undergoes a divergence in both spatial structure and semantics in the generated
images, and 3) sub-optimal training updates heighten the model's susceptibility
to utility harm. These issues severely degrade the original utility of
generative models. In this work, we present a new approach that solves all of
these challenges. We take inspiration from the concept of classifier guidance
and propose a surgical update on the classifier guidance term while
constraining the drift of the unconditional score term. Furthermore, our
algorithm empowers the user to select an alternative to the erasing concept,
allowing for more controllability. Our experimental results show that our
algorithm not only erases the target concept effectively but also preserves the
model's generation capability.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12808" title="Abstract">arXiv:2312.12808</a> [<a href="/pdf/2312.12808" title="Download PDF">pdf</a>, <a href="/format/2312.12808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Consistency in Multimodal Dialogue System Using LLM with  Dialogue Scenario
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Onozeki%2C+H">Hiroki Onozeki</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zhiyang Qi</a>, 
<a href="/search/cs?searchtype=author&query=Akiyama%2C+K">Kazuma Akiyama</a>, 
<a href="/search/cs?searchtype=author&query=Asahara%2C+R">Ryutaro Asahara</a>, 
<a href="/search/cs?searchtype=author&query=Kaneko%2C+T">Takumasa Kaneko</a>, 
<a href="/search/cs?searchtype=author&query=Inaba%2C+M">Michimasa Inaba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is part of the proceedings of the Dialogue Robot Competition 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper describes our dialogue system submitted to Dialogue Robot
Competition 2023. The system's task is to help a user at a travel agency decide
on a plan for visiting two sightseeing spots in Kyoto City that satisfy the
user. Our dialogue system is flexible and stable and responds to user
requirements by controlling dialogue flow according to dialogue scenarios. We
also improved user satisfaction by introducing motion and speech control based
on system utterances and user situations. In the preliminary round, our system
was ranked fifth in the impression evaluation and sixth in the plan evaluation
among all 12 teams.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12809" title="Abstract">arXiv:2312.12809</a> [<a href="/pdf/2312.12809" title="Download PDF">pdf</a>, <a href="/format/2312.12809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gecko: Automated Feature Degradation for Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+K">Kapil Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Jyothi%2C+S+A">Sangeetha Abdu Jyothi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 supplemental pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Cloud resilience is crucial for cloud operators and the myriad of
applications that rely on the cloud. Today, we lack a mechanism that allows
cloud operators to gracefully degrade application performance in public clouds.
In this paper, we put forward a vision for automated feature degradation with a
three-pronged approach. First, we introduce the idea of diagonal scaling --
pruning an application's dependency graphs during capacity crunch scenarios --
to maximize the availability of critical services. Second, we propose the use
of simple and expressive Criticality Tags on microservices to convey an
application developer's resilience intent to the cloud provider without any
application modifications. Third, we design Gecko, an automated cloud
resilience management system that maximizes critical service availability of
applications while also taking into account operator objectives, thereby
improving the overall resilience of the infrastructure during failures. Using
extensive experiments, we show that the Gecko controller running atop
Kubernetes can maximize the overall resilience of applications and
infrastructure under a broad range of failure scenarios. We also demonstrate
that diagonal scaling with Gecko aligns well with microservice architecture
using experiments with a real-world application.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12811" title="Abstract">arXiv:2312.12811</a> [<a href="/pdf/2312.12811" title="Download PDF">pdf</a>, <a href="/format/2312.12811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph-Based Generalization of Galam Model: Convergence Time and  Influential Nodes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sining Li</a>, 
<a href="/search/cs?searchtype=author&query=Zehmakan%2C+A+N">Ahad N. Zehmakan</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Physics 2023, 5, 1094-1108
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study a graph-based generalization of the Galam opinion formation model.
Consider a simple connected graph which represents a social network. Each node
in the graph is colored either blue or white, which indicates a positive or
negative opinion on a new product or a topic. In each discrete-time round, all
nodes are assigned randomly to groups of different sizes, where the node(s) in
each group form a clique in the underlying graph. All the nodes simultaneously
update their color to the majority color in their group. If there is a tie,
each node in the group chooses one of the two colors uniformly at random.
Investigating the convergence time of the model, our experiments show that the
convergence time is a logarithm function of the number of nodes for a complete
graph and a quadratic function for a cycle graph. We also study the various
strategies for selecting a set of seed nodes to maximize the final cascade of
one of the two colors, motivated by viral marketing. We consider the algorithms
where the seed nodes are selected based on the graph structure (nodes'
centrality measures such as degree, betweenness, and closeness) and the
individual's characteristics (activeness and stubbornness). We provide a
comparison of such strategies by conducting experiments on different real-world
and synthetic networks.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12813" title="Abstract">arXiv:2312.12813</a> [<a href="/pdf/2312.12813" title="Download PDF">pdf</a>, <a href="/ps/2312.12813" title="Download PostScript">ps</a>, <a href="/format/2312.12813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Selecting Source Code Generation Tools Based on Bandit Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shima%2C+R">Ryoto Shima</a>, 
<a href="/search/cs?searchtype=author&query=Tsunoda%2C+M">Masateru Tsunoda</a>, 
<a href="/search/cs?searchtype=author&query=Murakami%2C+Y">Yukasa Murakami</a>, 
<a href="/search/cs?searchtype=author&query=Monden%2C+A">Akito Monden</a>, 
<a href="/search/cs?searchtype=author&query=Tahir%2C+A">Amjed Tahir</a>, 
<a href="/search/cs?searchtype=author&query=Bennin%2C+K+E">Kwabena Ebo Bennin</a>, 
<a href="/search/cs?searchtype=author&query=Toda%2C+K">Koji Toda</a>, 
<a href="/search/cs?searchtype=author&query=Nakasai%2C+K">Keitaro Nakasai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Background: Recently, code generation tools such as ChatGPT have drawn
attention to their performance. Generally, a prior analysis of their
performance is needed to select new code-generation tools from a list of
candidates. Without such analysis, there is a higher risk of selecting an
ineffective tool, negatively affecting software development productivity.
Additionally, conducting prior analysis of new code generation tools takes time
and effort. Aim: To use a new code generation tool without prior analysis but
with low risk, we propose to evaluate the new tools during software development
(i.e., online optimization). Method: We apply the bandit algorithm (BA)
approach to help select the best code-generation tool among candidates.
Developers evaluate whether the result of the tool is correct or not. When code
generation and evaluation are repeated, the evaluation results are saved. We
utilize the stored evaluation results to select the best tool based on the BA
approach. Our preliminary analysis evaluated five code generation tools with
164 code generation cases using BA. Result: The BA approach selected ChatGPT as
the best tool as the evaluation proceeded, and during the evaluation, the
average accuracy by the BA approach outperformed the second-best performing
tool. Our results reveal the feasibility and effectiveness of BA in assisting
the selection of best-performing code generation tools.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12815" title="Abstract">arXiv:2312.12815</a> [<a href="/pdf/2312.12815" title="Download PDF">pdf</a>, <a href="/format/2312.12815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OCTOPUS: Open-vocabulary Content Tracking and Object Placement Using  Semantic Understanding in Mixed Reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoffe%2C+L">Luke Yoffe</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Aditya Sharma</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B6llerer%2C+T">Tobias H&#xf6;llerer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE International Symposium on Mixed and Augmented Reality (ISMAR) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">One key challenge in augmented reality is the placement of virtual content in
natural locations. Existing automated techniques are only able to work with a
closed-vocabulary, fixed set of objects. In this paper, we introduce a new
open-vocabulary method for object placement. Our eight-stage pipeline leverages
recent advances in segmentation models, vision-language models, and LLMs to
place any virtual object in any AR camera frame or scene. In a preliminary user
study, we show that our method performs at least as well as human experts 57%
of the time.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12816" title="Abstract">arXiv:2312.12816</a> [<a href="/pdf/2312.12816" title="Download PDF">pdf</a>, <a href="/format/2312.12816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object-aware Adaptive-Positivity Learning for Audio-Visual Question  Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhangbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Dan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jinxing Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Meng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper focuses on the Audio-Visual Question Answering (AVQA) task that
aims to answer questions derived from untrimmed audible videos. To generate
accurate answers, an AVQA model is expected to find the most informative
audio-visual clues relevant to the given questions. In this paper, we propose
to explicitly consider fine-grained visual objects in video frames
(object-level clues) and explore the multi-modal relations(i.e., the object,
audio, and question) in terms of feature interaction and model optimization.
For the former, we present an end-to-end object-oriented network that adopts a
question-conditioned clue discovery module to concentrate audio/visual
modalities on respective keywords of the question and designs a
modality-conditioned clue collection module to highlight closely associated
audio segments or visual objects. For model optimization, we propose an
object-aware adaptive-positivity learning strategy that selects the highly
semantic-matched multi-modal pair as positivity. Specifically, we design two
object-aware contrastive loss functions to identify the highly relevant
question-object pairs and audio-object pairs, respectively. These selected
pairs are constrained to have larger similarity values than the mismatched
pairs. The positivity-selecting process is adaptive as the positivity pairs
selected in each video frame may be different. These two object-aware
objectives help the model understand which objects are exactly relevant to the
question and which are making sounds. Extensive experiments on the MUSIC-AVQA
dataset demonstrate the proposed method is effective in finding favorable
audio-visual clues and also achieves new state-of-the-art question-answering
performance.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12817" title="Abstract">arXiv:2312.12817</a> [<a href="/pdf/2312.12817" title="Download PDF">pdf</a>, <a href="/ps/2312.12817" title="Download PostScript">ps</a>, <a href="/format/2312.12817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Research on the Development of Blockchain-based Distributed Intelligent  Healthcare Industry -- A Policy Analysis Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yang Yue</a>, 
<a href="/search/cs?searchtype=author&query=Shyu%2C+J+Z">Joseph Z. Shyu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">As a pivotal innovation in digital infrastructure, blockchain ledger
technology catalyzes the development of nascent business paradigms and
applications globally. Utilizing Rothwell and Zegveld's taxonomy of twelve
innovation policy tools, this study offers a nuanced comparison of domestic
blockchain policies, dissecting supply, environment, and demand-driven policy
dimensions to distill prevailing strategic orientations towards blockchain
healthcare adoption. The findings indicate that blockchain technology has seen
rapid growth in the healthcare industry. However, a certain misalignment exists
between the corporate and policy layers in terms of supply and demand. While
companies focus more on technological applications, existing policies are
geared towards regulations and governance. Government emphasis lies on legal
supervision through environmental policies, aiming to guide the standardization
and regulation of blockchain technology. This maintains a balance between
encouraging innovation and market and legal regulatory order, thereby providing
a reference for the development of the distributed intelligent healthcare
industry in our country.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12819" title="Abstract">arXiv:2312.12819</a> [<a href="/pdf/2312.12819" title="Download PDF">pdf</a>, <a href="/format/2312.12819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Microservices Identification Method Based on Spectral Clustering for  Industrial Legacy Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+T">Teng Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+Y">Yinglei Teng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shijun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaxuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Sicong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures, accepted by IEEE Globecom2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The advent of Industrial Internet of Things (IIoT) has imposed more stringent
requirements on industrial software in terms of communication delay,
scalability, and maintainability. Microservice architecture (MSA), a novel
software architecture that has emerged from cloud computing and DevOps,
presents itself as the most promising solution due to its independently
deployable and loosely coupled nature. Currently, practitioners are inclined to
migrate industrial legacy systems to MSA, despite numerous challenges it
presents. In this paper, we propose an automated microservice decomposition
method for extracting microservice candidates based on spectral graph theory to
address the problems associated with manual extraction, which is
time-consuming, labor intensive, and highly subjective. The method is divided
into three steps. Firstly, static and dynamic analysis tools are employed to
extract dependency information of the legacy system. Subsequently, information
is transformed into a graph structure that captures inter-class structure and
performance relationships in legacy systems. Finally, graph-based clustering
algorithm is utilized to identify potential microservice candidates that
conform to the principles of high cohesion and low coupling. Comparative
experiments with state of-the-art methods demonstrate the significant
advantages of our proposed method in terms of performance metrics. Moreover,
Practice show that our method can yield favorable results even without the
involvement of domain experts.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12826" title="Abstract">arXiv:2312.12826</a> [<a href="/pdf/2312.12826" title="Download PDF">pdf</a>, <a href="/format/2312.12826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReCo-Diff: Explore Retinex-Based Condition Strategy in Diffusion Model  for Low-Light Image Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuhui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiwen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chongyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H+T">Heng Tao Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Low-light image enhancement (LLIE) has achieved promising performance by
employing conditional diffusion models. In this study, we propose ReCo-Diff, a
novel approach that incorporates Retinex-based prior as an additional
pre-processing condition to regulate the generating capabilities of the
diffusion model. ReCo-Diff first leverages a pre-trained decomposition network
to produce initial reflectance and illumination maps of the low-light image.
Then, an adjustment network is introduced to suppress the noise in the
reflectance map and brighten the illumination map, thus forming the learned
Retinex-based condition. The condition is integrated into a refinement network,
implementing Retinex-based conditional modules that offer sufficient guidance
at both feature- and image-levels. By treating Retinex theory as a condition,
ReCo-Diff presents a unique perspective for establishing an LLIE-specific
diffusion model. Extensive experiments validate the rationality and superiority
of our ReCo-Diff approach. The code will be made publicly available.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12828" title="Abstract">arXiv:2312.12828</a> [<a href="/pdf/2312.12828" title="Download PDF">pdf</a>, <a href="/format/2312.12828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TagCLIP: A Local-to-Global Framework to Enhance Open-Vocabulary  Multi-Label Classification of CLIP Without Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuqi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Minghao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaipeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hengjia Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingming Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+D">Dongqin Lv</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Binbin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haifeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Deng Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Contrastive Language-Image Pre-training (CLIP) has demonstrated impressive
capabilities in open-vocabulary classification. The class token in the image
encoder is trained to capture the global features to distinguish different text
descriptions supervised by contrastive loss, making it highly effective for
single-label classification. However, it shows poor performance on multi-label
datasets because the global feature tends to be dominated by the most prominent
class and the contrastive nature of softmax operation aggravates it. In this
study, we observe that the multi-label classification results heavily rely on
discriminative local features but are overlooked by CLIP. As a result, we
dissect the preservation of patch-wise spatial information in CLIP and proposed
a local-to-global framework to obtain image tags. It comprises three steps: (1)
patch-level classification to obtain coarse scores; (2) dual-masking attention
refinement (DMAR) module to refine the coarse scores; (3) class-wise
reidentification (CWR) module to remedy predictions from a global perspective.
This framework is solely based on frozen CLIP and significantly enhances its
multi-label classification performance on various benchmarks without
dataset-specific training. Besides, to comprehensively assess the quality and
practicality of generated tags, we extend their application to the downstream
task, i.e., weakly supervised semantic segmentation (WSSS) with generated tags
as image-level pseudo labels. Experiments demonstrate that this
classify-then-segment paradigm dramatically outperforms other annotation-free
segmentation methods and validates the effectiveness of generated tags. Our
code is available at https://github.com/linyq2117/TagCLIP.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12832" title="Abstract">arXiv:2312.12832</a> [<a href="/pdf/2312.12832" title="Download PDF">pdf</a>, <a href="/format/2312.12832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Turning Dust into Gold: Distilling Complex Reasoning Capabilities from  LLMs by Leveraging Negative Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+P">Peiwen Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+S">Shaoxiong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+B">Boyuan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Bin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinglin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Heda Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) have performed well on various reasoning tasks,
but their inaccessibility and numerous parameters hinder wide application in
practice. One promising way is distilling the reasoning ability from LLMs to
small models by the generated chain-of-thought reasoning paths. In some cases,
however, LLMs may produce incorrect reasoning chains, especially when facing
complex mathematical problems. Previous studies only transfer knowledge from
positive samples and drop the synthesized data with wrong answers. In this
work, we illustrate the merit of negative data and propose a model
specialization framework to distill LLMs with negative samples besides positive
ones. The framework consists of three progressive steps, covering from training
to inference stages, to absorb knowledge from negative data. We conduct
extensive experiments across arithmetic reasoning tasks to demonstrate the role
of negative data in distillation from LLM.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12835" title="Abstract">arXiv:2312.12835</a> [<a href="/pdf/2312.12835" title="Download PDF">pdf</a>, <a href="/ps/2312.12835" title="Download PostScript">ps</a>, <a href="/format/2312.12835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-Optimal Resilient Aggregation Rules for Distributed Learning Using  1-Center and 1-Mean Clustering with Outliers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+Y">Yuhao Yi</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+R">Ronghui You</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Changxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+J">Jiancheng Lv</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 4 figures. Accepted by the 38th Annual AAAI Conference on Artificial Intelligence (AAAI'24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Byzantine machine learning has garnered considerable attention in light of
the unpredictable faults that can occur in large-scale distributed learning
systems. The key to secure resilience against Byzantine machines in distributed
learning is resilient aggregation mechanisms. Although abundant resilient
aggregation rules have been proposed, they are designed in ad-hoc manners,
imposing extra barriers on comparing, analyzing, and improving the rules across
performance criteria. This paper studies near-optimal aggregation rules using
clustering in the presence of outliers. Our outlier-robust clustering approach
utilizes geometric properties of the update vectors provided by workers. Our
analysis show that constant approximations to the 1-center and 1-mean
clustering problems with outliers provide near-optimal resilient aggregators
for metric-based criteria, which have been proven to be crucial in the
homogeneous and heterogeneous cases respectively. In addition, we discuss two
contradicting types of attacks under which no single aggregation rule is
guaranteed to improve upon the naive average. Based on the discussion, we
propose a two-phase resilient aggregation framework. We run experiments for
image classification using a non-convex loss function. The proposed algorithms
outperform previously known aggregation rules by a large margin with both
homogeneous and heterogeneous data distributions among non-faulty workers. Code
and appendix are available at https://github.com/jerry907/AAAI24-RASHB.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12838" title="Abstract">arXiv:2312.12838</a> [<a href="/pdf/2312.12838" title="Download PDF">pdf</a>, <a href="/format/2312.12838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedA3I: Annotation Quality-Aware Aggregation for Federated Medical Image  Segmentation Against Heterogeneous Annotation Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+N">Nannan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhaobin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zengqiang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Li Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Federated learning (FL) has emerged as a promising paradigm for training
segmentation models on decentralized medical data, owing to its
privacy-preserving property. However, existing research overlooks the prevalent
annotation noise encountered in real-world medical datasets, which limits the
performance ceilings of FL. In this paper, we, for the first time, identify and
tackle this problem. For problem formulation, we propose a contour evolution
for modeling non-independent and identically distributed (Non-IID) noise across
pixels within each client and then extend it to the case of multi-source data
to form a heterogeneous noise model (\textit{i.e.}, Non-IID annotation noise
across clients). For robust learning from annotations with such two-level
Non-IID noise, we emphasize the importance of data quality in model
aggregation, allowing high-quality clients to have a greater impact on FL. To
achieve this, we propose \textbf{Fed}erated learning with \textbf{A}nnotation
qu\textbf{A}lity-aware \textbf{A}ggregat\textbf{I}on, named \textbf{FedA$^3$I},
by introducing a quality factor based on client-wise noise estimation.
Specifically, noise estimation at each client is accomplished through the
Gaussian mixture model and then incorporated into model aggregation in a
layer-wise manner to up-weight high-quality clients. Extensive experiments on
two real-world medical image segmentation datasets demonstrate the superior
performance of FedA$^3$I against the state-of-the-art approaches in dealing
with cross-client annotation noise. The code is available at
\color{blue}{https://github.com/wnn2000/FedAAAI}.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12839" title="Abstract">arXiv:2312.12839</a> [<a href="/pdf/2312.12839" title="Download PDF">pdf</a>, <a href="/format/2312.12839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing Machine Learning Algorithms by Union-Free Generic Depth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blocher%2C+H">Hannah Blocher</a>, 
<a href="/search/cs?searchtype=author&query=Schollmeyer%2C+G">Georg Schollmeyer</a>, 
<a href="/search/cs?searchtype=author&query=Nalenz%2C+M">Malte Nalenz</a>, 
<a href="/search/cs?searchtype=author&query=Jansen%2C+C">Christoph Jansen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2304.09872">arXiv:2304.09872</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We propose a framework for descriptively analyzing sets of partial orders
based on the concept of depth functions. Despite intensive studies in linear
and metric spaces, there is very little discussion on depth functions for
non-standard data types such as partial orders. We introduce an adaptation of
the well-known simplicial depth to the set of all partial orders, the
union-free generic (ufg) depth. Moreover, we utilize our ufg depth for a
comparison of machine learning algorithms based on multidimensional performance
measures. Concretely, we provide two examples of classifier comparisons on
samples of standard benchmark data sets. Our results demonstrate promisingly
the wide variety of different analysis approaches based on ufg methods.
Furthermore, the examples outline that our approach differs substantially from
existing benchmarking approaches, and thus adds a new perspective to the vivid
debate on classifier comparison.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12844" title="Abstract">arXiv:2312.12844</a> [<a href="/pdf/2312.12844" title="Download PDF">pdf</a>, <a href="/format/2312.12844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Discovery under Identifiable Heteroscedastic Noise Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+N">Naiyu Yin</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+T">Tian Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Q">Qiang Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
<p class="mathjax">Capturing the underlying structural causal relations represented by Directed
Acyclic Graphs (DAGs) has been a fundamental task in various AI disciplines.
Causal DAG learning via the continuous optimization framework has recently
achieved promising performance in terms of both accuracy and efficiency.
However, most methods make strong assumptions of homoscedastic noise, i.e.,
exogenous noises have equal variances across variables, observations, or even
both. The noises in real data usually violate both assumptions due to the
biases introduced by different data collection processes. To address the issue
of heteroscedastic noise, we introduce relaxed and implementable sufficient
conditions, proving the identifiability of a general class of SEM subject to
these conditions. Based on the identifiable general SEM, we propose a novel
formulation for DAG learning that accounts for the variation in noise variance
across variables and observations. We then propose an effective two-phase
iterative DAG learning algorithm to address the increasing optimization
difficulties and to learn a causal DAG from data with heteroscedastic variable
noise under varying variance. We show significant empirical gains of the
proposed approaches over state-of-the-art methods on both synthetic data and
real data.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12846" title="Abstract">arXiv:2312.12846</a> [<a href="/pdf/2312.12846" title="Download PDF">pdf</a>, <a href="/ps/2312.12846" title="Download PostScript">ps</a>, <a href="/format/2312.12846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $H^1$-analysis of H3N3-2\textbf{$_&#x3c3;$}-based difference method for  fractional hyperbolic equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Du%2C+R">Rui-lian Du</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+C">Changpin Li</a>, 
<a href="/search/math?searchtype=author&query=Sun%2C+Z">Zhi-zhong Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">A novel H3N3-2$_\sigma$ interpolation approximation for the Caputo fractional
derivative of order $\alpha\in(1,2)$ is derived in this paper, which improves
the popular L2C formula with (3-$\alpha$)-order accuracy. By an interpolation
technique, the second-order accuracy of the truncation error is skillfully
estimated. Based on this formula, a finite difference scheme with second-order
accuracy both in time and in space is constructed for the initial-boundary
value problem of the time fractional hyperbolic equation. It is well known that
the coefficient properties of discrete fractional derivatives are fundamental
to the numerical stability of time fractional differential models. We prove the
related properties of the coefficients of the H3N3-2$_\sigma$ approximate
formula. With these properties, the numerical stability and convergence of the
difference scheme is derived immediately by the energy method in the sense of
$H^1$-norm. Considering the weak regularity of the solution to the problem at
the starting time, a finite difference scheme on the graded meshes based on
H3N3-2$_\sigma$ formula is also presented. The numerical simulations are
performed to show the effectiveness of the derived finite difference schemes,
in which the fast algorithms are employed to speed up the numerical
computation.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12849" title="Abstract">arXiv:2312.12849</a> [<a href="/pdf/2312.12849" title="Download PDF">pdf</a>, <a href="/format/2312.12849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Divergences induced by dual subtractive and divisive normalizations of  exponential families and their convex deformations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nielsen%2C+F">Frank Nielsen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Exponential families are statistical models which are the workhorses in
statistics, information theory, and machine learning. An exponential family can
either be normalized subtractively by its cumulant function or equivalently
normalized divisively by its partition function. Both subtractive and divisive
normalizers are strictly convex and smooth functions inducing pairs of Bregman
and Jensen divergences. It is well-known that skewed Bhattacharryya distances
between probability densities of an exponential family amounts to skewed Jensen
divergences induced by the cumulant function between their corresponding
natural parameters, and in limit cases that the sided Kullback-Leibler
divergences amount to reverse-sided Bregman divergences. In this note, we first
show that the $\alpha$-divergences between unnormalized densities of an
exponential family amounts scaled $\alpha$-skewed Jensen divergences induced by
the partition function. We then show how comparative convexity with respect to
a pair of quasi-arithmetic means allows to deform convex functions and define
dually flat spaces with corresponding divergences when ordinary convexity is
preserved.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12850" title="Abstract">arXiv:2312.12850</a> [<a href="/pdf/2312.12850" title="Download PDF">pdf</a>, <a href="/ps/2312.12850" title="Download PostScript">ps</a>, <a href="/format/2312.12850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Stochastic Analysis of the Linguistic Provenance of English Place  Names
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dalvean%2C+M">Michael Dalvean</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In English place name analysis, meanings are often derived from the
resemblance of roots in place names to topographical features, proper names
and/or habitation terms in one of the languages that have had an influence on
English place names. The problem here is that it is sometimes difficult to
determine the base language to use to interpret the roots. The purpose of this
paper is to stochastically determine the resemblance between 18799 English
place names and 84685 place names from Ireland, Scotland, Wales, Denmark,
Norway, Sweden, France, Germany, the Netherlands and Ancient Rome. Each English
place name is ranked according to the extent to which it resembles place names
from the other countries, and this provides a basis for determining the likely
language to use to interpret the place name. A number of observations can be
made using the ranking provided. In particular, it is found that `Didlington'
is the most archetypically English place name in the English sample, and `Anna'
is the least. Furthermore, it is found that the place names in the non-English
datasets are most similar to Norwegian place names and least similar to Welsh
place names.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12852" title="Abstract">arXiv:2312.12852</a> [<a href="/pdf/2312.12852" title="Download PDF">pdf</a>, <a href="/format/2312.12852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Resources for Dutch Large Language Modelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vanroy%2C+B">Bram Vanroy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite the rapid expansion of types of large language models, there remains
a notable gap in models specifically designed for the Dutch language. This gap
is not only a shortage in terms of pretrained Dutch models but also in terms of
data, and benchmarks and leaderboards. This work provides a small step to
improve the situation. First, we introduce two fine-tuned variants of the Llama
2 13B model. We first fine-tuned Llama 2 using Dutch-specific web-crawled data
and subsequently refined this model further on multiple synthetic instruction
and chat datasets. These datasets as well as the model weights are made
available. In addition, we provide a leaderboard to keep track of the
performance of (Dutch) models on a number of generation tasks, and we include
results of a number of state-of-the-art models, including our own. Finally we
provide a critical conclusion on what we believe is needed to push forward
Dutch language models and the whole eco-system around the models.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12853" title="Abstract">arXiv:2312.12853</a> [<a href="/pdf/2312.12853" title="Download PDF">pdf</a>, <a href="/format/2312.12853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CORECODE: A Common Sense Annotated Dialogue Dataset with Benchmark Tasks  for Chinese Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+D">Dan Shi</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+C">Chaobin You</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiantao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Taihao Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+D">Deyi Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">As an indispensable ingredient of intelligence, commonsense reasoning is
crucial for large language models (LLMs) in real-world scenarios. In this
paper, we propose CORECODE, a dataset that contains abundant commonsense
knowledge manually annotated on dyadic dialogues, to evaluate the commonsense
reasoning and commonsense conflict detection capabilities of Chinese LLMs. We
categorize commonsense knowledge in everyday conversations into three
dimensions: entity, event, and social interaction. For easy and consistent
annotation, we standardize the form of commonsense knowledge annotation in
open-domain dialogues as "domain: slot = value". A total of 9 domains and 37
slots are defined to capture diverse commonsense knowledge. With these
pre-defined domains and slots, we collect 76,787 commonsense knowledge
annotations from 19,700 dialogues through crowdsourcing. To evaluate and
enhance the commonsense reasoning capability for LLMs on the curated dataset,
we establish a series of dialogue-level reasoning and detection tasks,
including commonsense knowledge filling, commonsense knowledge generation,
commonsense conflict phrase detection, domain identification, slot
identification, and event causal inference. A wide variety of existing
open-source Chinese LLMs are evaluated with these tasks on our dataset.
Experimental results demonstrate that these models are not competent to predict
CORECODE's plentiful reasoning content, and even ChatGPT could only achieve
0.275 and 0.084 accuracy on the domain identification and slot identification
tasks under the zero-shot setting. We release the data and codes of CORECODE at
https://github.com/danshi777/CORECODE to promote commonsense reasoning
evaluation and study of LLMs in the context of daily conversations.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12856" title="Abstract">arXiv:2312.12856</a> [<a href="/pdf/2312.12856" title="Download PDF">pdf</a>, <a href="/format/2312.12856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SkyScript: A Large and Semantically Diverse Vision-Language Dataset for  Remote Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhecheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Prabha%2C+R">Rajanie Prabha</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tianyuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Rajagopal%2C+R">Ram Rajagopal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Remote sensing imagery, despite its broad applications in helping achieve
Sustainable Development Goals and tackle climate change, has not yet benefited
from the recent advancements of versatile, task-agnostic vision language models
(VLMs). A key reason is that the large-scale, semantically diverse image-text
dataset required for developing VLMs is still absent for remote sensing images.
Unlike natural images, remote sensing images and their associated text
descriptions cannot be efficiently collected from the public Internet at scale.
In this work, we bridge this gap by using geo-coordinates to automatically
connect open, unlabeled remote sensing images with rich semantics covered in
OpenStreetMap, and thus construct SkyScript, a comprehensive vision-language
dataset for remote sensing images, comprising 2.6 million image-text pairs
covering 29K distinct semantic tags. With continual pre-training on this
dataset, we obtain a VLM that surpasses baseline models with a 6.2% average
accuracy gain in zero-shot scene classification across seven benchmark
datasets. It also demonstrates the ability of zero-shot transfer for
fine-grained object attribute classification and cross-modal retrieval. We hope
this dataset can support the advancement of VLMs for various multi-modal tasks
in remote sensing, such as open-vocabulary classification, retrieval,
captioning, and text-to-image synthesis.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12861" title="Abstract">arXiv:2312.12861</a> [<a href="/pdf/2312.12861" title="Download PDF">pdf</a>, <a href="/format/2312.12861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Multi-Agent Reinforcement Learning for Formation Control without  Individual Reference Targets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dawood%2C+M">Murad Dawood</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Sicong Pan</a>, 
<a href="/search/cs?searchtype=author&query=Dengler%2C+N">Nils Dengler</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Siqi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Schoellig%2C+A+P">Angela P. Schoellig</a>, 
<a href="/search/cs?searchtype=author&query=Bennewitz%2C+M">Maren Bennewitz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transaction on Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In recent years, formation control of unmanned vehicles has received
considerable interest, driven by the progress in autonomous systems and the
imperative for multiple vehicles to carry out diverse missions. In this paper,
we address the problem of behavior-based formation control of mobile robots,
where we use safe multi-agent reinforcement learning~(MARL) to ensure the
safety of the robots by eliminating all collisions during training and
execution. To ensure safety, we implemented distributed model predictive
control safety filters to override unsafe actions. We focus on achieving
behavior-based formation without having individual reference targets for the
robots, and instead use targets for the centroid of the formation. This
formulation facilitates the deployment of formation control on real robots and
improves the scalability of our approach to more robots. The task cannot be
addressed through optimization-based controllers without specific individual
reference targets for the robots and information about the relative locations
of each robot to the others. That is why, for our formulation we use MARL to
train the robots. Moreover, in order to account for the interactions between
the agents, we use attention-based critics to improve the training process. We
train the agents in simulation and later on demonstrate the resulting behavior
of our approach on real Turtlebot robots. We show that despite the agents
having very limited information, we can still safely achieve the desired
behavior.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12863" title="Abstract">arXiv:2312.12863</a> [<a href="/pdf/2312.12863" title="Download PDF">pdf</a>, <a href="/format/2312.12863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning While Providing Model as a Service: Joint Training  and Inference Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+P">Pengchao Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+Y">Yang Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jianwei Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE International Conference on Computer Communications (INFOCOM) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">While providing machine learning model as a service to process users'
inference requests, online applications can periodically upgrade the model
utilizing newly collected data. Federated learning (FL) is beneficial for
enabling the training of models across distributed clients while keeping the
data locally. However, existing work has overlooked the coexistence of model
training and inference under clients' limited resources. This paper focuses on
the joint optimization of model training and inference to maximize inference
performance at clients. Such an optimization faces several challenges. The
first challenge is to characterize the clients' inference performance when
clients may partially participate in FL. To resolve this challenge, we
introduce a new notion of age of model (AoM) to quantify client-side model
freshness, based on which we use FL's global model convergence error as an
approximate measure of inference performance. The second challenge is the tight
coupling among clients' decisions, including participation probability in FL,
model download probability, and service rates. Toward the challenges, we
propose an online problem approximation to reduce the problem complexity and
optimize the resources to balance the needs of model training and inference.
Experimental results demonstrate that the proposed algorithm improves the
average inference accuracy by up to 12%.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12865" title="Abstract">arXiv:2312.12865</a> [<a href="/pdf/2312.12865" title="Download PDF">pdf</a>, <a href="/format/2312.12865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RadEdit: stress-testing biomedical vision models via diffusion image  editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez-Garc%C3%ADa%2C+F">Fernando P&#xe9;rez-Garc&#xed;a</a>, 
<a href="/search/cs?searchtype=author&query=Bond-Taylor%2C+S">Sam Bond-Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Sanchez%2C+P+P">Pedro P. Sanchez</a>, 
<a href="/search/cs?searchtype=author&query=van+Breugel%2C+B">Boris van Breugel</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+D+C">Daniel C. Castro</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+H">Harshita Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Salvatelli%2C+V">Valentina Salvatelli</a>, 
<a href="/search/cs?searchtype=author&query=Wetscherek%2C+M+T+A">Maria T. A. Wetscherek</a>, 
<a href="/search/cs?searchtype=author&query=Richardson%2C+H">Hannah Richardson</a>, 
<a href="/search/cs?searchtype=author&query=Lungren%2C+M+P">Matthew P. Lungren</a>, 
<a href="/search/cs?searchtype=author&query=Nori%2C+A">Aditya Nori</a>, 
<a href="/search/cs?searchtype=author&query=Alvarez-Valle%2C+J">Javier Alvarez-Valle</a>, 
<a href="/search/cs?searchtype=author&query=Oktay%2C+O">Ozan Oktay</a>, 
<a href="/search/cs?searchtype=author&query=Ilse%2C+M">Maximilian Ilse</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Biomedical imaging datasets are often small and biased, meaning that
real-world performance of predictive models can be substantially lower than
expected from internal testing. This work proposes using generative image
editing to simulate dataset shifts and diagnose failure modes of biomedical
vision models; this can be used in advance of deployment to assess readiness,
potentially reducing cost and patient harm. Existing editing methods can
produce undesirable changes, with spurious correlations learned due to the
co-occurrence of disease and treatment interventions, limiting practical
applicability. To address this, we train a text-to-image diffusion model on
multiple chest X-ray datasets and introduce a new editing method RadEdit that
uses multiple masks, if present, to constrain changes and ensure consistency in
the edited images. We consider three types of dataset shifts: acquisition
shift, manifestation shift, and population shift, and demonstrate that our
approach can diagnose failures and quantify model robustness without additional
data collection, complementing more qualitative tools for explainable AI.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12867" title="Abstract">arXiv:2312.12867</a> [<a href="/pdf/2312.12867" title="Download PDF">pdf</a>, <a href="/format/2312.12867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Fairness-Aware Spectrum Auction for Enhanced Licensed Shared  Access in 6G Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Khadem%2C+M">Mina Khadem</a>, 
<a href="/search/eess?searchtype=author&query=Ansarifard%2C+M">Maryam Ansarifard</a>, 
<a href="/search/eess?searchtype=author&query=Mokari%2C+N">Nader Mokari</a>, 
<a href="/search/eess?searchtype=author&query=Javan%2C+M">Mohammadreza Javan</a>, 
<a href="/search/eess?searchtype=author&query=Saeedi%2C+H">Hamid Saeedi</a>, 
<a href="/search/eess?searchtype=author&query=Jorswieck%2C+E+A">Eduard A. Jorswieck</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">This article introduces a new approach to address the spectrum scarcity
challenge in 6G networks by implementing the enhanced licensed shared access
(ELSA) framework. Our proposed auction mechanism aims to ensure fairness in
spectrum allocation to mobile network operators (MNOs) through a novel weighted
auction called the fair Vickery-Clarke-Groves (FVCG) mechanism. Through
comparison with traditional methods, the study demonstrates that the proposed
auction method improves fairness significantly. We suggest using spectrum
sensing and integrating UAV-based networks to enhance efficiency of the LSA
system. This research employs two methods to solve the problem. We first
propose a novel greedy algorithm, named market share based weighted greedy
algorithm (MSWGA) to achieve better fairness compared to the traditional
auction methods and as the second approach, we exploit deep reinforcement
learning (DRL) algorithms, to optimize the auction policy and demonstrate its
superiority over other methods. Simulation results show that the deep
deterministic policy gradient (DDPG) method performs superior to soft actor
critic (SAC), MSWGA, and greedy methods. Moreover, a significant improvement is
observed in fairness index compared to the traditional greedy auction methods.
This improvement is as high as about 27% and 35% when deploying the MSWGA and
DDPG methods, respectively.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12868" title="Abstract">arXiv:2312.12868</a> [<a href="/pdf/2312.12868" title="Download PDF">pdf</a>, <a href="/format/2312.12868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Machines that Trust: AI Agents Learn to Trust in the Trust Game
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nobandegani%2C+A+S">Ardavan S. Nobandegani</a>, 
<a href="/search/cs?searchtype=author&query=Rish%2C+I">Irina Rish</a>, 
<a href="/search/cs?searchtype=author&query=Shultz%2C+T+R">Thomas R. Shultz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Widely considered a cornerstone of human morality, trust shapes many aspects
of human social interactions. In this work, we present a theoretical analysis
of the $\textit{trust game}$, the canonical task for studying trust in
behavioral and brain sciences, along with simulation results supporting our
analysis. Specifically, leveraging reinforcement learning (RL) to train our AI
agents, we systematically investigate learning trust under various
parameterizations of this task. Our theoretical analysis, corroborated by the
simulations results presented, provides a mathematical basis for the emergence
of trust in the trust game.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12869" title="Abstract">arXiv:2312.12869</a> [<a href="/pdf/2312.12869" title="Download PDF">pdf</a>, <a href="/format/2312.12869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameterized Projected Bellman Operator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vincent%2C+T">Th&#xe9;o Vincent</a>, 
<a href="/search/cs?searchtype=author&query=Metelli%2C+A+M">Alberto Maria Metelli</a>, 
<a href="/search/cs?searchtype=author&query=Belousov%2C+B">Boris Belousov</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Jan Peters</a>, 
<a href="/search/cs?searchtype=author&query=Restelli%2C+M">Marcello Restelli</a>, 
<a href="/search/cs?searchtype=author&query=D%27Eramo%2C+C">Carlo D&#x27;Eramo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the National Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Approximate value iteration~(AVI) is a family of algorithms for reinforcement
learning~(RL) that aims to obtain an approximation of the optimal value
function. Generally, AVI algorithms implement an iterated procedure where each
step consists of (i) an application of the Bellman operator and (ii) a
projection step into a considered function space. Notoriously, the Bellman
operator leverages transition samples, which strongly determine its behavior,
as uninformative samples can result in negligible updates or long detours,
whose detrimental effects are further exacerbated by the computationally
intensive projection step. To address these issues, we propose a novel
alternative approach based on learning an approximate version of the Bellman
operator rather than estimating it through samples as in AVI approaches. This
way, we are able to (i) generalize across transition samples and (ii) avoid the
computationally intensive projection step. For this reason, we call our novel
operator projected Bellman operator (PBO). We formulate an optimization problem
to learn PBO for generic sequential decision-making problems, and we
theoretically analyze its properties in two representative classes of RL
problems. Furthermore, we theoretically study our approach under the lens of
AVI and devise algorithmic implementations to learn PBO in offline and online
settings by leveraging neural network parameterizations. Finally, we
empirically showcase the benefits of PBO w.r.t. the regular Bellman operator on
several RL problems.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12870" title="Abstract">arXiv:2312.12870</a> [<a href="/pdf/2312.12870" title="Download PDF">pdf</a>, <a href="/format/2312.12870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Audio-Visual Conversational Graph: From an Egocentric-Exocentric  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+W">Wenqi Jia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Miao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ananthabhotla%2C+I">Ishwarya Ananthabhotla</a>, 
<a href="/search/cs?searchtype=author&query=Rehg%2C+J+M">James M. Rehg</a>, 
<a href="/search/cs?searchtype=author&query=Ithapu%2C+V+K">Vamsi Krishna Ithapu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Ruohan Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, the thriving development of research related to egocentric
videos has provided a unique perspective for the study of conversational
interactions, where both visual and audio signals play a crucial role. While
most prior work focus on learning about behaviors that directly involve the
camera wearer, we introduce the Ego-Exocentric Conversational Graph Prediction
problem, marking the first attempt to infer exocentric conversational
interactions from egocentric videos. We propose a unified multi-modal,
multi-task framework -- Audio-Visual Conversational Attention (Av-CONV), for
the joint prediction of conversation behaviors -- speaking and listening -- for
both the camera wearer as well as all other social partners present in the
egocentric video. Specifically, we customize the self-attention mechanism to
model the representations across-time, across-subjects, and across-modalities.
To validate our method, we conduct experiments on a challenging egocentric
video dataset that includes first-person perspective, multi-speaker, and
multi-conversation scenarios. Our results demonstrate the superior performance
of our method compared to a series of baselines. We also present detailed
ablation studies to assess the contribution of each component in our model.
Project page: https://vjwq.github.io/AV-CONV/.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12871" title="Abstract">arXiv:2312.12871</a> [<a href="/pdf/2312.12871" title="Download PDF">pdf</a>, <a href="/format/2312.12871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effect Size Estimation for Duration Recommendation in Online  Experiments: Leveraging Hierarchical Models and Objective Utility Approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+R">Runzhe Wan</a>, 
<a href="/search/cs?searchtype=author&query=McQueen%2C+J">James McQueen</a>, 
<a href="/search/cs?searchtype=author&query=Hains%2C+D">Doug Hains</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinxiang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+R">Rui Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">The selection of the assumed effect size (AES) critically determines the
duration of an experiment, and hence its accuracy and efficiency.
Traditionally, experimenters determine AES based on domain knowledge. However,
this method becomes impractical for online experimentation services managing
numerous experiments, and a more automated approach is hence of great demand.
We initiate the study of data-driven AES selection in for online
experimentation services by introducing two solutions. The first employs a
three-layer Gaussian Mixture Model considering the heteroskedasticity across
experiments, and it seeks to estimate the true expected effect size among
positive experiments. The second method, grounded in utility theory, aims to
determine the optimal effect size by striking a balance between the
experiment's cost and the precision of decision-making. Through comparisons
with baseline methods using both simulated and real data, we showcase the
superior performance of the proposed approaches.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12872" title="Abstract">arXiv:2312.12872</a> [<a href="/pdf/2312.12872" title="Download PDF">pdf</a>, <a href="/ps/2312.12872" title="Download PostScript">ps</a>, <a href="/format/2312.12872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integration and Performance Analysis of Artificial Intelligence and  Computer Vision Based on Deep Learning Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Liqiang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+C">Chang Che</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qunwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xinyu Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper focuses on the analysis of the application effectiveness of the
integration of deep learning and computer vision technologies. Deep learning
achieves a historic breakthrough by constructing hierarchical neural networks,
enabling end-to-end feature learning and semantic understanding of images. The
successful experiences in the field of computer vision provide strong support
for training deep learning algorithms. The tight integration of these two
fields has given rise to a new generation of advanced computer vision systems,
significantly surpassing traditional methods in tasks such as machine vision
image classification and object detection. In this paper, typical image
classification cases are combined to analyze the superior performance of deep
neural network models while also pointing out their limitations in
generalization and interpretability, proposing directions for future
improvements. Overall, the efficient integration and development trend of deep
learning with massive visual data will continue to drive technological
breakthroughs and application expansion in the field of computer vision, making
it possible to build truly intelligent machine vision systems. This deepening
fusion paradigm will powerfully promote unprecedented tasks and functions in
computer vision, providing stronger development momentum for related
disciplines and industries.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12874" title="Abstract">arXiv:2312.12874</a> [<a href="/pdf/2312.12874" title="Download PDF">pdf</a>, <a href="/format/2312.12874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep-Unfolding-Based Joint Activity and Data Detection for Grant-Free  Transmission in Cell-Free Communication Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Gangle Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Studer%2C+C">Christoph Studer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be presented at IEEE ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Massive grant-free transmission and cell-free wireless communication systems
have emerged as pivotal enablers for massive machine-type communication. This
paper proposes a deep-unfolding-based joint activity and data detection
(DU-JAD) algorithm for massive grant-free transmission in cell-free systems. We
first formulate a joint activity and data detection optimization problem, which
we solve approximately using forward-backward splitting (FBS). We then apply
deep unfolding to FBS to optimize algorithm parameters using machine learning.
In order to improve data detection (DD) performance, reduce algorithm
complexity, and enhance active user detection (AUD), we employ a momentum
strategy, an approximate posterior mean estimator, and a novel soft-output AUD
module, respectively. Simulation results confirm the efficacy of DU-JAD for AUD
and DD.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12877" title="Abstract">arXiv:2312.12877</a> [<a href="/pdf/2312.12877" title="Download PDF">pdf</a>, <a href="/format/2312.12877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relightable and Animatable Neural Avatars from Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Wenbin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chengwei Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yong%2C+J">Jun-Hai Yong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Feng Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Lightweight creation of 3D digital avatars is a highly desirable but
challenging task. With only sparse videos of a person under unknown
illumination, we propose a method to create relightable and animatable neural
avatars, which can be used to synthesize photorealistic images of humans under
novel viewpoints, body poses, and lighting. The key challenge here is to
disentangle the geometry, material of the clothed body, and lighting, which
becomes more difficult due to the complex geometry and shadow changes caused by
body motions. To solve this ill-posed problem, we propose novel techniques to
better model the geometry and shadow changes. For geometry change modeling, we
propose an invertible deformation field, which helps to solve the inverse
skinning problem and leads to better geometry quality. To model the spatial and
temporal varying shading cues, we propose a pose-aware part-wise light
visibility network to estimate light occlusion. Extensive experiments on
synthetic and real datasets show that our approach reconstructs high-quality
geometry and generates realistic shadows under different body poses. Code and
data are available at
\url{https://wenbin-lin.github.io/RelightableAvatar-page/}.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12878" title="Abstract">arXiv:2312.12878</a> [<a href="/pdf/2312.12878" title="Download PDF">pdf</a>, <a href="/format/2312.12878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rule-Extraction Methods From Feedforward Neural Networks: A Systematic  Literature Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mekkaoui%2C+S+E">Sara El Mekkaoui</a>, 
<a href="/search/cs?searchtype=author&query=Benabbou%2C+L">Loubna Benabbou</a>, 
<a href="/search/cs?searchtype=author&query=Berrado%2C+A">Abdelaziz Berrado</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Motivated by the interpretability question in ML models as a crucial element
for the successful deployment of AI systems, this paper focuses on rule
extraction as a means for neural networks interpretability. Through a
systematic literature review, different approaches for extracting rules from
feedforward neural networks, an important block in deep learning models, are
identified and explored. The findings reveal a range of methods developed for
over two decades, mostly suitable for shallow neural networks, with recent
developments to meet deep learning models' challenges. Rules offer a
transparent and intuitive means of explaining neural networks, making this
study a comprehensive introduction for researchers interested in the field.
While the study specifically addresses feedforward networks with supervised
learning and crisp rules, future work can extend to other network types,
machine learning methods, and fuzzy rule extraction.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12879" title="Abstract">arXiv:2312.12879</a> [<a href="/pdf/2312.12879" title="Download PDF">pdf</a>, <a href="/format/2312.12879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DynamiQS: Quantum Secure Authentication for Dynamic Charging of Electric  Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bianchi%2C+T">Tommaso Bianchi</a>, 
<a href="/search/cs?searchtype=author&query=Brighente%2C+A">Alessandro Brighente</a>, 
<a href="/search/cs?searchtype=author&query=Conti%2C+M">Mauro Conti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Dynamic Wireless Power Transfer (DWPT) is a novel technology that allows
charging an electric vehicle while driving thanks to a dedicated road
infrastructure. DWPT's capabilities in automatically establishing charging
sessions and billing without users' intervention make it prone to cybersecurity
attacks. Hence, security is essential in preventing fraud, impersonation, and
user tracking. To this aim, researchers proposed different solutions for
authenticating users. However, recent advancements in quantum computing
jeopardize classical public key cryptography, making currently existing
solutions in DWPT authentication nonviable. To avoid the resource burden
imposed by technology upgrades, it is essential to develop
post-quantum-resistant solutions. In this paper, we propose DynamiQS, the first
post-quantum secure authentication protocol for dynamic wireless charging.
DynamiQS is privacy-preserving and secure against attacks on the DWPT. We
leverage an Identity-Based Encryption with Lattices in the Ring Learning With
Error framework. Furthermore, we show the possibility of using DynamiQS in a
real environment, leveraging the results of cryptographic computation on real
constrained devices and simulations. DynamiQS reaches a total time cost of
around 281 ms, which is practicable in dynamic charging settings (car and
charging infrastructure).
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12882" title="Abstract">arXiv:2312.12882</a> [<a href="/pdf/2312.12882" title="Download PDF">pdf</a>, <a href="/format/2312.12882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BSL: Understanding and Improving Softmax Loss for Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Junkang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiawei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiancan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Wentao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jizhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICDE2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Loss functions steer the optimization direction of recommendation models and
are critical to model performance, but have received relatively little
attention in recent recommendation research. Among various losses, we find
Softmax loss (SL) stands out for not only achieving remarkable accuracy but
also better robustness and fairness. Nevertheless, the current literature lacks
a comprehensive explanation for the efficacy of SL. Toward addressing this
research gap, we conduct theoretical analyses on SL and uncover three insights:
1) Optimizing SL is equivalent to performing Distributionally Robust
Optimization (DRO) on the negative data, thereby learning against perturbations
on the negative distribution and yielding robustness to noisy negatives. 2)
Comparing with other loss functions, SL implicitly penalizes the prediction
variance, resulting in a smaller gap between predicted values and and thus
producing fairer results. Building on these insights, we further propose a
novel loss function Bilateral SoftMax Loss (BSL) that extends the advantage of
SL to both positive and negative sides. BSL augments SL by applying the same
Log-Expectation-Exp structure to positive examples as is used for negatives,
making the model robust to the noisy positives as well. Remarkably, BSL is
simple and easy-to-implement -- requiring just one additional line of code
compared to SL. Experiments on four real-world datasets and three
representative backbones demonstrate the effectiveness of our proposal. The
code is available at https://github.com/junkangwu/BSL
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12891" title="Abstract">arXiv:2312.12891</a> [<a href="/pdf/2312.12891" title="Download PDF">pdf</a>, <a href="/format/2312.12891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MinePlanner: A Benchmark for Long-Horizon Planning in Large Minecraft  Worlds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hill%2C+W">William Hill</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+I">Ireton Liu</a>, 
<a href="/search/cs?searchtype=author&query=De+Mello+Koch%2C+A">Anita De Mello Koch</a>, 
<a href="/search/cs?searchtype=author&query=Harvey%2C+D">Damion Harvey</a>, 
<a href="/search/cs?searchtype=author&query=Konidaris%2C+G">George Konidaris</a>, 
<a href="/search/cs?searchtype=author&query=James%2C+S">Steven James</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">We propose a new benchmark for planning tasks based on the Minecraft game.
Our benchmark contains 45 tasks overall, but also provides support for creating
both propositional and numeric instances of new Minecraft tasks automatically.
We benchmark numeric and propositional planning systems on these tasks, with
results demonstrating that state-of-the-art planners are currently incapable of
dealing with many of the challenges advanced by our new benchmark, such as
scaling to instances with thousands of objects. Based on these results, we
identify areas of improvement for future planners. Our framework is made
available at https://github.com/IretonLiu/mine-pddl/.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12902" title="Abstract">arXiv:2312.12902</a> [<a href="/pdf/2312.12902" title="Download PDF">pdf</a>, <a href="/format/2312.12902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DXP: Billing Data Preparation for Big Data Analytics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gagliardelli%2C+L">Luca Gagliardelli</a>, 
<a href="/search/cs?searchtype=author&query=Beneventano%2C+D">Domenico Beneventano</a>, 
<a href="/search/cs?searchtype=author&query=Esposito%2C+M">Marco Esposito</a>, 
<a href="/search/cs?searchtype=author&query=Zecchini%2C+L">Luca Zecchini</a>, 
<a href="/search/cs?searchtype=author&query=Simonini%2C+G">Giovanni Simonini</a>, 
<a href="/search/cs?searchtype=author&query=Bergamaschi%2C+S">Sonia Bergamaschi</a>, 
<a href="/search/cs?searchtype=author&query=Miselli%2C+F">Fabio Miselli</a>, 
<a href="/search/cs?searchtype=author&query=Miano%2C+G">Giuseppe Miano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">In this paper, we present the data preparation activities that we performed
for the Digital Experience Platform (DXP) project, commissioned and supervised
by Doxee S.p.A.. DXP manages the billing data of the users of different
companies operating in various sectors (electricity and gas, telephony, pay TV,
etc.). This data has to be processed to provide services to the users (e.g.,
interactive billing), but mainly to provide analytics to the companies (e.g.,
churn prediction or user segmentation). We focus on the design of the data
preparation pipeline, describing the challenges that we had to overcome in
order to get the billing data ready to perform analysis on it. We illustrate
the lessons learned by highlighting the key points that could be transferred to
similar projects. Moreover, we report some interesting results and
considerations derived from the preliminary analysis of the prepared data, also
pointing out some possible future directions for the ongoing project, spacing
from big data integration to privacy-preserving temporal record linkage.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12903" title="Abstract">arXiv:2312.12903</a> [<a href="/pdf/2312.12903" title="Download PDF">pdf</a>, <a href="/ps/2312.12903" title="Download PostScript">ps</a>, <a href="/format/2312.12903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Minimal Control Family of Dynamical Syetem for Universal Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Duan%2C+Y">Yifei Duan</a>, 
<a href="/search/eess?searchtype=author&query=Cai%2C+Y">Yongqiang Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Dynamical Systems (math.DS)

</div>
<p class="mathjax">The universal approximation property (UAP) of neural networks is a
fundamental characteristic of deep learning. It is widely recognized that a
composition of linear functions and non-linear functions, such as the rectified
linear unit (ReLU) activation function, can approximate continuous functions on
compact domains. In this paper, we extend this efficacy to the scenario of
dynamical systems with controls. We prove that the control family
$\mathcal{F}_1 = \mathcal{F}_0 \cup \{ \text{ReLU}(\cdot)\} $ is enough to
generate flow maps that can uniformly approximate diffeomorphisms of
$\mathbb{R}^d$ on any compact domain, where $\mathcal{F}_0 = \{x \mapsto Ax+b:
A\in \mathbb{R}^{d\times d}, b \in \mathbb{R}^d\}$ is the set of linear maps
and the dimension $d\ge2$. Since $\mathcal{F}_1$ contains only one nonlinear
function and $\mathcal{F}_0$ does not hold the UAP, we call $\mathcal{F}_1$ a
minimal control family for UAP. Based on this, some sufficient conditions, such
as the affine invariance, on the control family are established and discussed.
Our result reveals an underlying connection between the approximation power of
neural networks and control systems.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12904" title="Abstract">arXiv:2312.12904</a> [<a href="/pdf/2312.12904" title="Download PDF">pdf</a>, <a href="/format/2312.12904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PGN: A perturbation generation network against deep reinforcement  learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangjuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Feifan Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Q">Quan Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep reinforcement learning has advanced greatly and applied in many areas.
In this paper, we explore the vulnerability of deep reinforcement learning by
proposing a novel generative model for creating effective adversarial examples
to attack the agent. Our proposed model can achieve both targeted attacks and
untargeted attacks. Considering the specificity of deep reinforcement learning,
we propose the action consistency ratio as a measure of stealthiness, and a new
measurement index of effectiveness and stealthiness. Experiment results show
that our method can ensure the effectiveness and stealthiness of attack
compared with other algorithms. Moreover, our methods are considerably faster
and thus can achieve rapid and efficient verification of the vulnerability of
deep reinforcement learning.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12905" title="Abstract">arXiv:2312.12905</a> [<a href="/pdf/2312.12905" title="Download PDF">pdf</a>, <a href="/format/2312.12905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the distance to low-rank matrices in the maximum norm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Budzinskiy%2C+S">Stanislav Budzinskiy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
<p class="mathjax">Every sufficiently big matrix with small spectral norm has a nearby low-rank
matrix if the distance is measured in the maximum norm (Udell \&amp; Townsend, SIAM
J Math Data Sci, 2019). We use the Hanson--Wright inequality to improve the
estimate of the distance for matrices with incoherent column and row spaces. In
numerical experiments with several classes of matrices we study how well the
theoretical upper bound describes the approximation errors achieved with the
method of alternating projections.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12908" title="Abstract">arXiv:2312.12908</a> [<a href="/pdf/2312.12908" title="Download PDF">pdf</a>, <a href="/format/2312.12908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Common Optical Music Recognition Evaluation Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Torras%2C+P">Pau Torras</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+S">Sanket Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Forn%C3%A9s%2C+A">Alicia Forn&#xe9;s</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 4 figures, 3 tables, submitted (under review) for the International Journal in Document Analysis and Recognition
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The quality of Optical Music Recognition (OMR) systems is a rather difficult
magnitude to measure. There is no lingua franca shared among OMR datasets that
allows to compare systems' performance on equal grounds, since most of them are
specialised on certain approaches. As a result, most state-of-the-art works
currently report metrics that cannot be compared directly. In this paper we
identify the need of a common music representation language and propose the
Music Tree Notation (MTN) format, thanks to which the definition of standard
metrics is possible. This format represents music as a set of primitives that
group together into higher-abstraction nodes, a compromise between the
expression of fully graph-based and sequential notation formats. We have also
developed a specific set of OMR metrics and a typeset score dataset as a proof
of concept of this idea.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12910" title="Abstract">arXiv:2312.12910</a> [<a href="/pdf/2312.12910" title="Download PDF">pdf</a>, <a href="/ps/2312.12910" title="Download PostScript">ps</a>, <a href="/format/2312.12910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Scheduling the Task in Fog Computing Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ishaq%2C+F">Faiza Ishaq</a>, 
<a href="/search/cs?searchtype=author&query=Ashraf%2C+H">Humaira Ashraf</a>, 
<a href="/search/cs?searchtype=author&query=Jhanjhi%2C+N">Nz Jhanjhi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">With the rapid increase in the Internet of Things (IoT), the amount of data
produced and processed is also increased. Cloud Computing facilitates the
storage, processing, and analysis of data as needed. However, cloud computing
devices are located far away from the IoT devices. Fog computing has emerged as
a small cloud computing paradigm that is near to the edge devices and handles
the task very efficiently. Fog nodes have a small storage capability than the
cloud node but it is designed and deployed near to the edge device so that
request must be accessed efficiently and executes in time. In this survey paper
we have investigated and analysed the main challenges and issues raised in
scheduling the task in fog computing environment. To the best of our knowledge
there is no comprehensive survey paper on challenges in task scheduling of fog
computing paradigm. In this survey paper research is conducted from 2018 to
2021 and most of the paper selection is done from 2020-2021. Moreover, this
survey paper organizes the task scheduling approaches and technically plans the
identified challenges and issues. Based on the identified issues, we have
highlighted the future work directions in the field of task scheduling in fog
computing environment.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12913" title="Abstract">arXiv:2312.12913</a> [<a href="/pdf/2312.12913" title="Download PDF">pdf</a>, <a href="/format/2312.12913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Produce Once, Utilize Twice for Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qi Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Huiyuan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+C">Chengkan Lv</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhengtao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual anomaly detection aims at classifying and locating the regions that
deviate from the normal appearance. Embedding-based methods and
reconstruction-based methods are two main approaches for this task. However,
they are either not efficient or not precise enough for the industrial
detection. To deal with this problem, we derive POUTA (Produce Once Utilize
Twice for Anomaly detection), which improves both the accuracy and efficiency
by reusing the discriminant information potential in the reconstructive
network. We observe that the encoder and decoder representations of the
reconstructive network are able to stand for the features of the original and
reconstructed image respectively. And the discrepancies between the symmetric
reconstructive representations provides roughly accurate anomaly information.
To refine this information, a coarse-to-fine process is proposed in POUTA,
which calibrates the semantics of each discriminative layer by the high-level
representations and supervision loss. Equipped with the above modules, POUTA is
endowed with the ability to provide a more precise anomaly location than the
prior arts. Besides, the representation reusage also enables to exclude the
feature extraction process in the discriminative network, which reduces the
parameters and improves the efficiency. Extensive experiments show that, POUTA
is superior or comparable to the prior methods with even less cost.
Furthermore, POUTA also achieves better performance than the state-of-the-art
few-shot anomaly detection methods without any special design, showing that
POUTA has strong ability to learn representations inherent in the training
data.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12915" title="Abstract">arXiv:2312.12915</a> [<a href="/pdf/2312.12915" title="Download PDF">pdf</a>, <a href="/ps/2312.12915" title="Download PostScript">ps</a>, <a href="/format/2312.12915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survey on Multi-Document Summarization: Systematic Literature Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ihsan%2C+U">Uswa Ihsan</a>, 
<a href="/search/cs?searchtype=author&query=Ashraf%2C+H">Humaira Ashraf</a>, 
<a href="/search/cs?searchtype=author&query=Jhanjhi%2C+N">NZ Jhanjhi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">In this era of information technology, abundant information is available on
the internet in the form of web pages and documents on any given topic. Finding
the most relevant and informative content out of these huge number of
documents, without spending several hours of reading has become a very
challenging task. Various methods of multi-document summarization have been
developed to overcome this problem. The multi-document summarization methods
try to produce high-quality summaries of documents with low redundancy. This
study conducts a systematic literature review of existing methods for
multi-document summarization methods and provides an in-depth analysis of
performance achieved by these methods. The findings of the study show that more
effective methods are still required for getting higher accuracy of these
methods. The study also identifies some open challenges that can gain the
attention of future researchers of this domain.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12917" title="Abstract">arXiv:2312.12917</a> [<a href="/pdf/2312.12917" title="Download PDF">pdf</a>, <a href="/format/2312.12917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sign Language Production with Latent Motion Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+P">Pan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+T">Taiyi Peng</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yao Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qipeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WACV2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Sign Language Production (SLP) is the tough task of turning sign language
into sign videos. The main goal of SLP is to create these videos using a sign
gloss. In this research, we've developed a new method to make high-quality sign
videos without using human poses as a middle step. Our model works in two main
parts: first, it learns from a generator and the video's hidden features, and
next, it uses another model to understand the order of these hidden features.
To make this method even better for sign videos, we make several significant
improvements. (i) In the first stage, we take an improved 3D VQ-GAN to learn
downsampled latent representations. (ii) In the second stage, we introduce
sequence-to-sequence attention to better leverage conditional information.
(iii) The separated two-stage training discards the realistic visual semantic
of the latent codes in the second stage. To endow the latent sequences semantic
information, we extend the token-level autoregressive latent codes learning
with perceptual loss and reconstruction loss for the prior model with visual
perception. Compared with previous state-of-the-art approaches, our model
performs consistently better on two word-level sign language datasets, i.e.,
WLASL and NMFs-CSL.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12918" title="Abstract">arXiv:2312.12918</a> [<a href="/pdf/2312.12918" title="Download PDF">pdf</a>, <a href="/format/2312.12918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assaying on the Robustness of Zero-Shot Machine-Generated Text Detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi-Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+R">Rong Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures, AAAI 2024 Workshop on Responsible Language Models
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">To combat the potential misuse of Natural Language Generation (NLG)
technology, a variety of algorithms have been developed for the detection of
AI-generated texts. Traditionally, this task is treated as a binary
classification problem. Although supervised learning has demonstrated promising
results, acquiring labeled data for detection purposes poses real-world
challenges and the risk of overfitting. In an effort to address these issues,
we delve into the realm of zero-shot machine-generated text detection. Existing
zero-shot detectors, typically designed for specific tasks or topics, often
assume uniform testing scenarios, limiting their practicality. In our research,
we explore various advanced Large Language Models (LLMs) and their specialized
variants, contributing to this field in several ways. In empirical studies, we
uncover a significant correlation between topics and detection performance.
Secondly, we delve into the influence of topic shifts on zero-shot detectors.
These investigations shed light on the adaptability and robustness of these
detection methods across diverse topics.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12921" title="Abstract">arXiv:2312.12921</a> [<a href="/pdf/2312.12921" title="Download PDF">pdf</a>, <a href="/format/2312.12921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoupling Judgment and Decision Making: A Tale of Two Tails
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ba%5Cc%7Bs%7Dak">Ba&#x15f;ak</a> (Emre)
<a href="/search/cs?searchtype=author&query=Oral">Oral</a>, 
<a href="/search/cs?searchtype=author&query=Dragicevic%2C+P">Pierre Dragicevic</a>, 
<a href="/search/cs?searchtype=author&query=Telea%2C+A">Alexandru Telea</a>, 
<a href="/search/cs?searchtype=author&query=Dimara%2C+E">Evanthia Dimara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Is it true that if citizens understand hurricane probabilities, they will
make more rational decisions for evacuation? Finding answers to such questions
is not straightforward in the literature because the terms judgment and
decision making are often used interchangeably. This terminology conflation
leads to a lack of clarity on whether people make suboptimal decisions because
of inaccurate judgments of information conveyed in visualizations or because
they use alternative yet currently unknown heuristics. To decouple judgment
from decision making, we review relevant concepts from the literature and
present two preregistered experiments (N=601) to investigate if the task
(judgment vs. decision making), the scenario (sports vs. humanitarian), and the
visualization (quantile dotplots, density plots, probability bars) affect
accuracy. While experiment 1 was inconclusive, we found evidence for a
difference in experiment 2. Contrary to our expectations and previous research,
which found decisions less accurate than their direct-equivalent judgments, our
results pointed in the opposite direction. Our findings further revealed that
decisions were less vulnerable to status-quo bias, suggesting decision makers
may disfavor responses associated with inaction. We also found that both
scenario and visualization types can influence peoples judgments and decisions.
Although effect sizes are not large and results should be interpreted
carefully, we conclude that judgments cannot be safely used as proxy tasks for
decision making, and discuss implications for visualization research and
beyond.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12923" title="Abstract">arXiv:2312.12923</a> [<a href="/pdf/2312.12923" title="Download PDF">pdf</a>, <a href="/format/2312.12923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Data Minimization through Decentralized Data Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Battiston%2C+I">Ilaria Battiston</a>, 
<a href="/search/cs?searchtype=author&query=Boncz%2C+P">Peter Boncz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 1 figure
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> CEUR Workshop Proceedings 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">In this research project, we investigate an alternative to the standard
cloud-centralized data architecture. Specifically, we aim to leave part of the
application data under the control of the individual data owners in
decentralized personal data stores. Our primary goal is to increase data
minimization, i. e., enabling more sensitive personal data to be under the
control of its owners while providing a straightforward and efficient framework
to design architectures that allow applications to run and data to be analyzed.
To serve this purpose, the centralized part of the schema contains aggregating
views over this decentralized data. We propose to design a declarative language
that extends SQL, for architects to specify different kinds of tables and views
at the schema level, along with sensitive columns and their minimum granularity
level of their aggregations. Local updates need to be reflected in the
centralized views while ensuring privacy throughout intermediate calculations;
for this we pursue the integration of distributed materialized view maintenance
and multi-party computation (MPC) techniques. We finally aim to implement this
system, where the personal data stores could either live in mobile devices or
encrypted cloud storage, in order to evaluate its performance properties.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12924" title="Abstract">arXiv:2312.12924</a> [<a href="/pdf/2312.12924" title="Download PDF">pdf</a>, <a href="/format/2312.12924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Android dialogue system for customer service using prompt-based topic  control and compliments generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tamotsu%2C+M">Miyama Tamotsu</a>, 
<a href="/search/cs?searchtype=author&query=Shogo%2C+O">Okada Shogo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is part of the proceedings of the Dialogue Robot Competition 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This paper describes a dialogue system developed for the Dialogue Robot
Competition 2023 that achieves topic control for trip planning by inserting
text into prompts using the ChatGPT-API. We built a system that is capable of
generating compliments for the user based on recognition of the user's
appearance and creating travel plans by extracting the knowledge about the
user's preference from the history of the user's utterances. Complements and
planning based on preference are the elements required to maintain the quality
of customer service. A preliminary round was held at a travel agency's actual
store, where real customers experienced and evaluated the system. This system
was evaluated first in the preliminary round and participated in the final
round. The results of the preliminary round showed the effectiveness of the
proposed system.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12925" title="Abstract">arXiv:2312.12925</a> [<a href="/pdf/2312.12925" title="Download PDF">pdf</a>, <a href="/ps/2312.12925" title="Download PostScript">ps</a>, <a href="/format/2312.12925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Authentication Mechanism for Cluster based Vehicular Adhoc  Network (VANET): A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nasir%2C+R">Rabia Nasir</a>, 
<a href="/search/cs?searchtype=author&query=Ashraf%2C+H">Humaira Ashraf</a>, 
<a href="/search/cs?searchtype=author&query=Jhanjhi%2C+N">NZ Jhanjhi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Vehicular Ad Hoc Networks (VANETs) play a crucial role in Intelligent
Transportation Systems (ITS) by facilitating communication between vehicles and
infrastructure. This communication aims to enhance road safety, improve traffic
efficiency, and enhance passenger comfort. The secure and reliable exchange of
information is paramount to ensure the integrity and confidentiality of data,
while the authentication of vehicles and messages is essential to prevent
unauthorized access and malicious activities. This survey paper presents a
comprehensive analysis of existing authentication mechanisms proposed for
cluster-based VANETs. The strengths, weaknesses, and suitability of these
mechanisms for various scenarios are carefully examined. Additionally, the
integration of secure key management techniques is discussed to enhance the
overall authentication process. Cluster-based VANETs are formed by dividing the
network into smaller groups or clusters, with designated cluster heads
comprising one or more vehicles. Furthermore, this paper identifies gaps in the
existing literature through an exploration of previous surveys. Several schemes
based on different methods are critically evaluated, considering factors such
as throughput, detection rate, security, packet delivery ratio, and end-to-end
delay. To provide optimal solutions for authentication in cluster-based VANETs,
this paper highlights AI- and ML-based routing-based schemes. These approaches
leverage artificial intelligence and machine learning techniques to enhance
authentication within the cluster-based VANET network. Finally, this paper
explores the open research challenges that exist in the realm of authentication
for cluster-based Vehicular Adhoc Networks, shedding light on areas that
require further investigation and development.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12933" title="Abstract">arXiv:2312.12933</a> [<a href="/pdf/2312.12933" title="Download PDF">pdf</a>, <a href="/format/2312.12933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Testing for Text-to-Image Software
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+S">Siqi Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Recently, creative generative artificial intelligence software has emerged as
a pivotal assistant, enabling users to generate content and seek inspiration
rapidly. Text-to-image (T2I) software, being one of the most widely used among
them, is used to synthesize images with simple text input by engaging in a
cross-modal process. However, despite substantial advancements in several
fields, T2I software often encounters defects and erroneous, including omitting
focal entities, low image realism, and mismatched text-image information. The
cross-modal nature of T2I software makes it challenging for traditional testing
methods to detect defects. Lacking test oracles further increases the
complexity of testing. To address this deficiency, we propose ACTesting, an
Automated Cross-modal Testing Method of Text-to-Image software, the first
testing method designed specifically for T2I software. We construct test
samples based on entities and relationship triples following the fundamental
principle of maintaining consistency in the semantic information to overcome
the cross-modal matching challenges. To address the issue of testing oracle
scarcity, we first design the metamorphic relation for T2I software and
implement three types of mutation operators guided by adaptability density. In
the experiment, we conduct ACTesting on four widely-used T2I software. The
results show that ACTesting can generate error-revealing tests, reducing the
text-image consistency by up to 20% compared with the baseline. We also conduct
the ablation study that effectively showcases the efficacy of each mutation
operator, based on the proposed metamorphic relation. The results demonstrate
that ACTesting can identify abnormal behaviors of T2I software effectively.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12934" title="Abstract">arXiv:2312.12934</a> [<a href="/pdf/2312.12934" title="Download PDF">pdf</a>, <a href="/format/2312.12934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability of Graph Convolutional Neural Networks through the lens of  small perturbation analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Testa%2C+L">Lucia Testa</a>, 
<a href="/search/cs?searchtype=author&query=Battiloro%2C+C">Claudio Battiloro</a>, 
<a href="/search/cs?searchtype=author&query=Sardellitti%2C+S">Stefania Sardellitti</a>, 
<a href="/search/cs?searchtype=author&query=Barbarossa%2C+S">Sergio Barbarossa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Proc. of 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this work, we study the problem of stability of Graph Convolutional Neural
Networks (GCNs) under random small perturbations in the underlying graph
topology, i.e. under a limited number of insertions or deletions of edges. We
derive a novel bound on the expected difference between the outputs of
unperturbed and perturbed GCNs. The proposed bound explicitly depends on the
magnitude of the perturbation of the eigenpairs of the Laplacian matrix, and
the perturbation explicitly depends on which edges are inserted or deleted.
Then, we provide a quantitative characterization of the effect of perturbing
specific edges on the stability of the network. We leverage tools from small
perturbation analysis to express the bounds in closed, albeit approximate,
form, in order to enhance interpretability of the results, without the need to
compute any perturbed shift operator. Finally, we numerically evaluate the
effectiveness of the proposed bound.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12936" title="Abstract">arXiv:2312.12936</a> [<a href="/pdf/2312.12936" title="Download PDF">pdf</a>, <a href="/format/2312.12936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concept-based Explainable Artificial Intelligence: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poeta%2C+E">Eleonora Poeta</a>, 
<a href="/search/cs?searchtype=author&query=Ciravegna%2C+G">Gabriele Ciravegna</a>, 
<a href="/search/cs?searchtype=author&query=Pastor%2C+E">Eliana Pastor</a>, 
<a href="/search/cs?searchtype=author&query=Cerquitelli%2C+T">Tania Cerquitelli</a>, 
<a href="/search/cs?searchtype=author&query=Baralis%2C+E">Elena Baralis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">The field of explainable artificial intelligence emerged in response to the
growing need for more transparent and reliable models. However, using raw
features to provide explanations has been disputed in several works lately,
advocating for more user-understandable explanations. To address this issue, a
wide range of papers proposing Concept-based eXplainable Artificial
Intelligence (C-XAI) methods have arisen in recent years. Nevertheless, a
unified categorization and precise field definition are still missing. This
paper fills the gap by offering a thorough review of C-XAI approaches. We
define and identify different concepts and explanation types. We provide a
taxonomy identifying nine categories and propose guidelines for selecting a
suitable category based on the development context. Additionally, we report
common evaluation strategies including metrics, human evaluations and dataset
employed, aiming to assist the development of future methods. We believe this
survey will serve researchers, practitioners, and domain experts in
comprehending and advancing this innovative field.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12937" title="Abstract">arXiv:2312.12937</a> [<a href="/pdf/2312.12937" title="Download PDF">pdf</a>, <a href="/format/2312.12937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Loss Functions for Training Decision Trees with Noisy Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wilton%2C+J">Jonathan Wilton</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+N">Nan Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI Conference on Artificial Intelligence 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We consider training decision trees using noisily labeled data, focusing on
loss functions that can lead to robust learning algorithms. Our contributions
are threefold. First, we offer novel theoretical insights on the robustness of
many existing loss functions in the context of decision tree learning. We show
that some of the losses belong to a class of what we call conservative losses,
and the conservative losses lead to an early stopping behavior during training
and noise-tolerant predictions during testing. Second, we introduce a framework
for constructing robust loss functions, called distribution losses. These
losses apply percentile-based penalties based on an assumed margin
distribution, and they naturally allow adapting to different noise rates via a
robustness parameter. In particular, we introduce a new loss called the
negative exponential loss, which leads to an efficient greedy
impurity-reduction learning algorithm. Lastly, our experiments on multiple
datasets and noise settings validate our theoretical insight and the
effectiveness of our adaptive negative exponential loss.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12938" title="Abstract">arXiv:2312.12938</a> [<a href="/pdf/2312.12938" title="Download PDF">pdf</a>, <a href="/format/2312.12938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CARGO: Crypto-Assisted Differentially Private Triangle Counting without  Trusted Servers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Murakami%2C+T">Takao Murakami</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinfei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yoshikawa%2C+M">Masatoshi Yoshikawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICDE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Databases (cs.DB)

</div>
<p class="mathjax">Differentially private triangle counting in graphs is essential for analyzing
connection patterns and calculating clustering coefficients while protecting
sensitive individual information. Previous works have relied on either central
or local models to enforce differential privacy. However, a significant utility
gap exists between the central and local models of differentially private
triangle counting, depending on whether or not a trusted server is needed. In
particular, the central model provides a high accuracy but necessitates a
trusted server. The local model does not require a trusted server but suffers
from limited accuracy. Our paper introduces a crypto-assisted differentially
private triangle counting system, named CARGO, leveraging cryptographic
building blocks to improve the effectiveness of differentially private triangle
counting without assumption of trusted servers. It achieves high utility
similar to the central model but without the need for a trusted server like the
local model. CARGO consists of three main components. First, we introduce a
similarity-based projection method that reduces the global sensitivity while
preserving more triangles via triangle homogeneity. Second, we present a
triangle counting scheme based on the additive secret sharing that securely and
accurately computes the triangles while protecting sensitive information.
Third, we design a distributed perturbation algorithm that perturbs the
triangle count with minimal but sufficient noise. We also provide a
comprehensive theoretical and empirical analysis of our proposed methods.
Extensive experiments demonstrate that our CARGO significantly outperforms the
local model in terms of utility and achieves high-utility triangle counting
comparable to the central model.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12940" title="Abstract">arXiv:2312.12940</a> [<a href="/pdf/2312.12940" title="Download PDF">pdf</a>, <a href="/format/2312.12940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Energy Consumption of UAV Edge Computing in Non-Terrestrial  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Traspadini%2C+A">Alessandro Traspadini</a>, 
<a href="/search/cs?searchtype=author&query=Giordani%2C+M">Marco Giordani</a>, 
<a href="/search/cs?searchtype=author&query=Giambene%2C+G">Giovanni Giambene</a>, 
<a href="/search/cs?searchtype=author&query=De+Cola%2C+T">Tomaso De Cola</a>, 
<a href="/search/cs?searchtype=author&query=Zorzi%2C+M">Michele Zorzi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures, 1 table. This paper has been accepted for presentation at the 57th Asilomar Conference on Signals, Systems, and Computers. Copyright IEEE 2023. Please cite it as: A. Traspadini, M. Giordani, G. Giambene, T. De Cola, and M. Zorzi, "On the Energy Consumption of UAV Edge Computing in Non-Terrestrial Networks," 57th Asilomar Conference on Signals, Systems, and Computers, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">During the last few years, the use of Unmanned Aerial Vehicles (UAVs)
equipped with sensors and cameras has emerged as a cutting-edge technology to
provide services such as surveillance, infrastructure inspections, and target
acquisition. However, this approach requires UAVs to process data onboard,
mainly for person/object detection and recognition, which may pose significant
energy constraints as UAVs are battery-powered. A possible solution can be the
support of Non-Terrestrial Networks (NTNs) for edge computing. In particular,
UAVs can partially offload data (e.g., video acquisitions from onboard sensors)
to more powerful upstream High Altitude Platforms (HAPs) or satellites acting
as edge computing servers to increase the battery autonomy compared to local
processing, even though at the expense of some data transmission delays.
Accordingly, in this study we model the energy consumption of UAVs, HAPs, and
satellites considering the energy for data processing, offloading, and
hovering. Then, we investigate whether data offloading can improve the system
performance. Simulations demonstrate that edge computing can improve both UAV
autonomy and end-to-end delay compared to onboard processing in many
configurations.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12945" title="Abstract">arXiv:2312.12945</a> [<a href="/pdf/2312.12945" title="Download PDF">pdf</a>, <a href="/format/2312.12945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Misclassification excess risk bounds for 1-bit matrix completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
The <a href="/search/cs?searchtype=author&query=Mai%2C+T">Tien Mai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This study investigates the misclassification excess risk bound in the
context of 1-bit matrix completion, a significant problem in machine learning
involving the recovery of an unknown matrix from a limited subset of its
entries. Matrix completion has garnered considerable attention in the last two
decades due to its diverse applications across various fields. Unlike
conventional approaches that deal with real-valued samples, 1-bit matrix
completion is concerned with binary observations. While prior research has
predominantly focused on the estimation error of proposed estimators, our study
shifts attention to the prediction error. This paper offers theoretical
analysis regarding the prediction errors of two previous works utilizing the
logistic regression model: one employing a max-norm constrained minimization
and the other employing nuclear-norm penalization. Significantly, our findings
demonstrate that the latter achieves the minimax-optimal rate without the need
for an additional logarithmic term. These novel results contribute to a deeper
understanding of 1-bit matrix completion by shedding light on the predictive
performance of specific methodologies.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12946" title="Abstract">arXiv:2312.12946</a> [<a href="/pdf/2312.12946" title="Download PDF">pdf</a>, <a href="/format/2312.12946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Class Conditional Time Series Generation with Structured Noise Space GAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gholamrezaei%2C+H">Hamidreza Gholamrezaei</a>, 
<a href="/search/cs?searchtype=author&query=Koochali%2C+A">Alireza Koochali</a>, 
<a href="/search/cs?searchtype=author&query=Dengel%2C+A">Andreas Dengel</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S">Sheraz Ahmed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper introduces Structured Noise Space GAN (SNS-GAN), a novel approach
in the field of generative modeling specifically tailored for class-conditional
generation in both image and time series data. It addresses the challenge of
effectively integrating class labels into generative models without requiring
structural modifications to the network. The SNS-GAN method embeds class
conditions within the generator's noise space, simplifying the training process
and enhancing model versatility. The model's efficacy is demonstrated through
qualitative validations in the image domain and superior performance in time
series generation compared to baseline models. This research opens new avenues
for the application of GANs in various domains, including but not limited to
time series and image data generation.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12954" title="Abstract">arXiv:2312.12954</a> [<a href="/pdf/2312.12954" title="Download PDF">pdf</a>, <a href="/format/2312.12954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TADAP: Trajectory-Aided Drivable area Auto-labeling with Pre-trained  self-supervised features in winter driving conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alamikkotervo%2C+E">Eerik Alamikkotervo</a>, 
<a href="/search/cs?searchtype=author&query=Ojala%2C+R">Risto Ojala</a>, 
<a href="/search/cs?searchtype=author&query=Sepp%C3%A4nen%2C+A">Alvari Sepp&#xe4;nen</a>, 
<a href="/search/cs?searchtype=author&query=Tammi%2C+K">Kari Tammi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Detection of the drivable area in all conditions is crucial for autonomous
driving and advanced driver assistance systems. However, the amount of labeled
data in adverse driving conditions is limited, especially in winter, and
supervised methods generalize poorly to conditions outside the training
distribution. For easy adaption to all conditions, the need for human
annotation should be removed from the learning process. In this paper,
Trajectory-Aided Drivable area Auto-labeling with Pre-trained self-supervised
features (TADAP) is presented for automated annotation of the drivable area in
winter driving conditions. A sample of the drivable area is extracted based on
the trajectory estimate from the global navigation satellite system. Similarity
with the sample area is determined based on pre-trained self-supervised visual
features. Image areas similar to the sample area are considered to be drivable.
These TADAP labels were evaluated with a novel winter-driving dataset,
collected in varying driving scenes. A prediction model trained with the TADAP
labels achieved a +9.6 improvement in intersection over union compared to the
previous state-of-the-art of self-supervised drivable area detection.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12958" title="Abstract">arXiv:2312.12958</a> [<a href="/pdf/2312.12958" title="Download PDF">pdf</a>, <a href="/format/2312.12958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symbolic Security Verification of Mesh Commissioning Protocol in Thread  (extended version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Upadhyay%2C+P">Pankaj Upadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+S">Subodh Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+G">Guangdong Bai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Symbolic Computation (cs.SC)

</div>
<p class="mathjax">The Thread protocol (or simply Thread ) is a popular networking protocol for
the Internet of Things (IoT). It allows seamless integration of a set of
applications and protocols, hence reducing the risk of incompatibility among
different applications or user protocols. Thread has been deployed in many
popular smart home products by the majority of IoT manufacturers, such as Apple
TV, Apple HomePod mini, eero 6, Nest Hub, and Nest Wifi. Despite a few
empirical analyses on the security of Thread, there is still a lack of formal
analysis on this infrastructure of the booming IoT ecosystem. In this work, we
performed a formal symbolic analysis of the security properties of Thread. Our
main focus is on MeshCoP (Mesh Commissioning Protocol), the main subprotocol in
Thread for secure authentication and commissioning of new, untrusted devices
inside an existing Thread network. This case study presents the challenges and
proposed solutions in modeling MeshCoP. We use ProVerif, a symbolic
verification tool of {\pi}-calculus models, for verifying the security
properties of MeshCoP.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12961" title="Abstract">arXiv:2312.12961</a> [<a href="/pdf/2312.12961" title="Download PDF">pdf</a>, <a href="/format/2312.12961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Radar Fields: An Extension of Radiance Fields to SAR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ehret%2C+T">Thibaud Ehret</a>, 
<a href="/search/cs?searchtype=author&query=Mar%C3%AD%2C+R">Roger Mar&#xed;</a>, 
<a href="/search/cs?searchtype=author&query=Derksen%2C+D">Dawa Derksen</a>, 
<a href="/search/cs?searchtype=author&query=Gasnier%2C+N">Nicolas Gasnier</a>, 
<a href="/search/cs?searchtype=author&query=Facciolo%2C+G">Gabriele Facciolo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Radiance fields have been a major breakthrough in the field of inverse
rendering, novel view synthesis and 3D modeling of complex scenes from
multi-view image collections. Since their introduction, it was shown that they
could be extended to other modalities such as LiDAR, radio frequencies, X-ray
or ultrasound. In this paper, we show that, despite the important difference
between optical and synthetic aperture radar (SAR) image formation models, it
is possible to extend radiance fields to radar images thus presenting the first
"radar fields". This allows us to learn surface models using only collections
of radar images, similar to how regular radiance fields are learned and with
the same computational complexity on average. Thanks to similarities in how
both fields are defined, this work also shows a potential for hybrid methods
combining both optical and SAR images.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12962" title="Abstract">arXiv:2312.12962</a> [<a href="/pdf/2312.12962" title="Download PDF">pdf</a>, <a href="/ps/2312.12962" title="Download PostScript">ps</a>, <a href="/format/2312.12962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Points-Polynomials Incidence Theorem with Applications to Coding Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tamo%2C+I">Itzhak Tamo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">This paper focuses on incidences over finite fields, extending to higher
degrees a result by Vinh \cite{VINH20111177} on the number of point-line
incidences in the plane $\mathbb{F}^2$, where $\mathbb{F}$ is a finite field.
Specifically, we present a bound on the number of incidences between points and
polynomials of bounded degree in $\mathbb{F}^2$. Our approach employs a
singular value decomposition of the incidence matrix between points and
polynomials, coupled with an analysis of the related group algebras. This bound
is then applied to coding theory, specifically to the problem of average-radius
list decoding of Reed-Solomon (RS) codes. We demonstrate that RS codes of
certain lengths are average-radius list-decodable with a constant list size,
which is dependent on the code rate and the distance from the Johnson radius.
While a constant list size for list-decoding of RS codes in this regime was
previously established, its existence for the stronger notion of average-radius
list-decoding was not known to exist.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12964" title="Abstract">arXiv:2312.12964</a> [<a href="/pdf/2312.12964" title="Download PDF">pdf</a>, <a href="/format/2312.12964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Far- and Near-Field Channel Measurements and Characterization in the  Terahertz Band Using a Virtual Antenna Array
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiqin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Ziming Yu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+C">Chong Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Extremely large-scale antenna array (ELAA) technologies consisting of
ultra-massive multiple-input-multiple-output (UM-MIMO) or reconfigurable
intelligent surfaces (RISs), are emerging to meet the demand of wireless
systems in sixth-generation and beyond communications for enhanced coverage and
extreme data rates up to Terabits per second. For ELAA operating at Terahertz
(THz) frequencies, the Rayleigh distance expands, and users are likely to be
located in both far-field (FF) and near-field (NF) regions. On one hand, new
features like NF propagation and spatial non-stationarity need to be
characterized. On the other hand, the transition of properties near the FF and
NF boundary is worth exploring. In this paper, a complete experimental analysis
of far- and near-field channel characteristics using a THz virtual antenna
array is provided based on measurement of the multi-input-single-output channel
with the virtual uniform planar array (UPA) structure of at most 4096 elements.
In particular, non-linear phase change is observed in the NF, and the Rayleigh
criterion regarding the maximum phase error is verified. Then, a new
cross-field path loss model is proposed, which is compatible with both FF and
NF cases based on the UPA structure. Besides, multi-path fading is discovered
in both NF and FF regions.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12967" title="Abstract">arXiv:2312.12967</a> [<a href="/pdf/2312.12967" title="Download PDF">pdf</a>, <a href="/format/2312.12967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implementation of the Emulator-based Component Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Vladyka%2C+A">Anton Vladyka</a>, 
<a href="/search/math?searchtype=author&query=Eronen%2C+E+A">Eemeli A. Eronen</a>, 
<a href="/search/math?searchtype=author&query=Niskanen%2C+J">Johannes Niskanen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Software (cs.MS)

</div>
<p class="mathjax">We present a PyTorch-powered implementation of the emulator-based component
analysis used for ill-posed numerical non-linear inverse problems, where an
approximate emulator for the forward problem is known. This emulator may be a
numerical model, an interpolating function, or a fitting function such as a
neural network. With the help of the emulator and a data set, the method seeks
dimensionality reduction by projection in the variable space so that maximal
variance of the target (response) values of the data is covered. The obtained
basis set for projection in the variable space defines a subspace of the
greatest response for the outcome of the forward problem. The method allows for
the reconstruction of the coordinates in this subspace for an approximate
solution to the inverse problem. We present an example of using the code
provided as a Python class.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12970" title="Abstract">arXiv:2312.12970</a> [<a href="/pdf/2312.12970" title="Download PDF">pdf</a>, <a href="/format/2312.12970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> D3Former: Jointly Learning Repeatable Dense Detectors and  Feature-enhanced Descriptors via Saliency-guided Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Junjie Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengfei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Q">Qiujie Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Q">Qiong Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+S">Shiqing Xin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Caiming Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Establishing accurate and representative matches is a crucial step in
addressing the point cloud registration problem. A commonly employed approach
involves detecting keypoints with salient geometric features and subsequently
mapping these keypoints from one frame of the point cloud to another. However,
methods within this category are hampered by the repeatability of the sampled
keypoints. In this paper, we introduce a saliency-guided trans\textbf{former},
referred to as \textit{D3Former}, which entails the joint learning of
repeatable \textbf{D}ense \textbf{D}etectors and feature-enhanced
\textbf{D}escriptors. The model comprises a Feature Enhancement Descriptor
Learning (FEDL) module and a Repetitive Keypoints Detector Learning (RKDL)
module. The FEDL module utilizes a region attention mechanism to enhance
feature distinctiveness, while the RKDL module focuses on detecting repeatable
keypoints to enhance matching capabilities. Extensive experimental results on
challenging indoor and outdoor benchmarks demonstrate that our proposed method
consistently outperforms state-of-the-art point cloud matching methods.
Notably, tests on 3DLoMatch, even with a low overlap ratio, show that our
method consistently outperforms recently published approaches such as RoReg and
RoITr. For instance, with the number of extracted keypoints reduced to 250, the
registration recall scores for RoReg, RoITr, and our method are 64.3\%, 73.6\%,
and 76.5\%, respectively.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12972" title="Abstract">arXiv:2312.12972</a> [<a href="/pdf/2312.12972" title="Download PDF">pdf</a>, <a href="/format/2312.12972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Past to Future: Rethinking Eligibility Traces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+D">Dhawal Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Jordan%2C+S+M">Scott M. Jordan</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhari%2C+S">Shreyas Chaudhari</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+P+S">Philip S. Thomas</a>, 
<a href="/search/cs?searchtype=author&query=da+Silva%2C+B+C">Bruno Castro da Silva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in The 38th Annual AAAI Conference on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper, we introduce a fresh perspective on the challenges of credit
assignment and policy evaluation. First, we delve into the nuances of
eligibility traces and explore instances where their updates may result in
unexpected credit assignment to preceding states. From this investigation
emerges the concept of a novel value function, which we refer to as the
\emph{bidirectional value function}. Unlike traditional state value functions,
bidirectional value functions account for both future expected returns (rewards
anticipated from the current state onward) and past expected returns
(cumulative rewards from the episode's start to the present). We derive
principled update equations to learn this value function and, through
experimentation, demonstrate its efficacy in enhancing the process of policy
evaluation. In particular, our results indicate that the proposed learning
approach can, in certain challenging contexts, perform policy evaluation more
rapidly than TD($\lambda$) -- a method that learns forward value functions,
$v^\pi$, \emph{directly}. Overall, our findings present a new perspective on
eligibility traces and potential advantages associated with the novel value
function it inspires, especially for policy evaluation.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12973" title="Abstract">arXiv:2312.12973</a> [<a href="/pdf/2312.12973" title="Download PDF">pdf</a>, <a href="/format/2312.12973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Mean Field Load Balancing in Large Localized Queueing Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tahir%2C+A">Anam Tahir</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+K">Kai Cui</a>, 
<a href="/search/cs?searchtype=author&query=Koeppl%2C+H">Heinz Koeppl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Scalable load balancing algorithms are of great interest in cloud networks
and data centers, necessitating the use of tractable techniques to compute
optimal load balancing policies for good performance. However, most existing
scalable techniques, especially asymptotically scaling methods based on mean
field theory, have not been able to model large queueing networks with strong
locality. Meanwhile, general multi-agent reinforcement learning techniques can
be hard to scale and usually lack a theoretical foundation. In this work, we
address this challenge by leveraging recent advances in sparse mean field
theory to learn a near-optimal load balancing policy in sparsely connected
queueing networks in a tractable manner, which may be preferable to global
approaches in terms of communication overhead. Importantly, we obtain a general
load balancing framework for a large class of sparse bounded-degree topologies.
By formulating a novel mean field control problem in the context of graphs with
bounded degree, we reduce the otherwise difficult multi-agent problem to a
single-agent problem. Theoretically, the approach is justified by approximation
guarantees. Empirically, the proposed methodology performs well on several
realistic and scalable network topologies. Moreover, we compare it with a
number of well-known load balancing heuristics and with existing scalable
multi-agent reinforcement learning methods. Overall, we obtain a tractable
approach for load balancing in highly localized networks.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12977" title="Abstract">arXiv:2312.12977</a> [<a href="/pdf/2312.12977" title="Download PDF">pdf</a>, <a href="/format/2312.12977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Optimization of the Age of Information under Partial  Observability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tahir%2C+A">Anam Tahir</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+K">Kai Cui</a>, 
<a href="/search/cs?searchtype=author&query=Alt%2C+B">Bastian Alt</a>, 
<a href="/search/cs?searchtype=author&query=Rizk%2C+A">Amr Rizk</a>, 
<a href="/search/cs?searchtype=author&query=Koeppl%2C+H">Heinz Koeppl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">The significance of the freshness of sensor and control data at the receiver
side, often referred to as Age of Information (AoI), is fundamentally
constrained by contention for limited network resources. Evidently, network
congestion is detrimental for AoI, where this congestion is partly self-induced
by the sensor transmission process in addition to the contention from other
transmitting sensors. In this work, we devise a decentralized AoI-minimizing
transmission policy for a number of sensor agents sharing capacity-limited,
non-FIFO duplex channels that introduce random delays in communication with a
common receiver. By implementing the same policy, however with no explicit
inter-agent communication, the agents minimize the expected AoI in this
partially observable system. We cater to the partial observability due to
random channel delays by designing a bootstrap particle filter that
independently maintains a belief over the AoI of each agent. We also leverage
mean-field control approximations and reinforcement learning to derive scalable
and optimal solutions for minimizing the expected AoI collaboratively.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12981" title="Abstract">arXiv:2312.12981</a> [<a href="/pdf/2312.12981" title="Download PDF">pdf</a>, <a href="/format/2312.12981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hardness of linearly ordered 4-colouring of 3-colourable 3-uniform  hypergraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Filakovsk%C3%BD%2C+M">Marek Filakovsk&#xfd;</a>, 
<a href="/search/cs?searchtype=author&query=Nakajima%2C+T">Tamio-Vesa Nakajima</a>, 
<a href="/search/cs?searchtype=author&query=Opr%C5%A1al%2C+J">Jakub Opr&#x161;al</a>, 
<a href="/search/cs?searchtype=author&query=Tasinato%2C+G">Gianluca Tasinato</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+U">Uli Wagner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> full version of a paper accepted to STACS 2024 (Track A)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Algebraic Topology (math.AT); Combinatorics (math.CO)

</div>
<p class="mathjax">A linearly ordered (LO) $k$-colouring of a hypergraph is a colouring of its
vertices with colours $1, \dots, k$ such that each edge contains a unique
maximal colour. Deciding whether an input hypergraph admits LO $k$-colouring
with a fixed number of colours is NP-complete (and in the special case of
graphs, LO colouring coincides with the usual graph colouring).
<br />Here, we investigate the complexity of approximating the `linearly ordered
chromatic number' of a hypergraph. We prove that the following promise problem
is NP-complete: Given a 3-uniform hypergraph, distinguish between the case that
it is LO $3$-colourable, and the case that it is not even LO $4$-colourable. We
prove this result by a combination of algebraic, topological, and combinatorial
methods, building on and extending a topological approach for studying
approximate graph colouring introduced by Krokhin, Opr\v{s}al, Wrochna, and
\v{Z}ivn\'y (2023).
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12989" title="Abstract">arXiv:2312.12989</a> [<a href="/pdf/2312.12989" title="Download PDF">pdf</a>, <a href="/format/2312.12989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking and Analyzing In-context Learning, Fine-tuning and  Supervised Learning for Biomedical Knowledge Curation: a focused study on  chemical entities of biological interest
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Groves%2C+E">Emily Groves</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Minhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Abdulle%2C+Y">Yusuf Abdulle</a>, 
<a href="/search/cs?searchtype=author&query=Kunz%2C+H">Holger Kunz</a>, 
<a href="/search/cs?searchtype=author&query=Hoelscher-Obermaier%2C+J">Jason Hoelscher-Obermaier</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Ronin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Honghan Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 5 figures, 14 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Automated knowledge curation for biomedical ontologies is key to ensure that
they remain comprehensive, high-quality and up-to-date. In the era of
foundational language models, this study compares and analyzes three NLP
paradigms for curation tasks: in-context learning (ICL), fine-tuning (FT), and
supervised learning (ML). Using the Chemical Entities of Biological Interest
(ChEBI) database as a model ontology, three curation tasks were devised. For
ICL, three prompting strategies were employed with GPT-4, GPT-3.5, BioGPT.
PubmedBERT was chosen for the FT paradigm. For ML, six embedding models were
utilized for training Random Forest and Long-Short Term Memory models. Five
setups were designed to assess ML and FT model performance across different
data availability scenarios.Datasets for curation tasks included: task 1
(620,386), task 2 (611,430), and task 3 (617,381), maintaining a 50:50 positive
versus negative ratio. For ICL models, GPT-4 achieved best accuracy scores of
0.916, 0.766 and 0.874 for tasks 1-3 respectively. In a direct comparison, ML
(trained on ~260,000 triples) outperformed ICL in accuracy across all tasks.
(accuracy differences: +.11, +.22 and +.17). Fine-tuned PubmedBERT performed
similarly to leading ML models in tasks 1 &amp; 2 (F1 differences: -.014 and
+.002), but worse in task 3 (-.048). Simulations revealed performance declines
in both ML and FT models with smaller and higher imbalanced training data.
where ICL (particularly GPT-4) excelled in tasks 1 &amp; 3. GPT-4 excelled in tasks
1 and 3 with less than 6,000 triples, surpassing ML/FT. ICL underperformed
ML/FT in task 2.ICL-augmented foundation models can be good assistants for
knowledge curation with correct prompting, however, not making ML and FT
paradigms obsolete. The latter two require task-specific data to beat ICL. In
such cases, ML relies on small pretrained embeddings, minimizing computational
demands.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12995" title="Abstract">arXiv:2312.12995</a> [<a href="/pdf/2312.12995" title="Download PDF">pdf</a>, <a href="/format/2312.12995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aggregating Multiple Bio-Inspired Image Region Classifiers For Effective  And Lightweight Visual Place Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arcanjo%2C+B">Bruno Arcanjo</a>, 
<a href="/search/cs?searchtype=author&query=Ferrarini%2C+B">Bruno Ferrarini</a>, 
<a href="/search/cs?searchtype=author&query=Fasli%2C+M">Maria Fasli</a>, 
<a href="/search/cs?searchtype=author&query=Milford%2C+M">Michael Milford</a>, 
<a href="/search/cs?searchtype=author&query=McDonald-Maier%2C+K+D">Klaus D. McDonald-Maier</a>, 
<a href="/search/cs?searchtype=author&query=Ehsan%2C+S">Shoaib Ehsan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual place recognition (VPR) enables autonomous systems to localize
themselves within an environment using image information. While VPR techniques
built upon a Convolutional Neural Network (CNN) backbone dominate
state-of-the-art VPR performance, their high computational requirements make
them unsuitable for platforms equipped with low-end hardware. Recently, a
lightweight VPR system based on multiple bio-inspired classifiers, dubbed
DrosoNets, has been proposed, achieving great computational efficiency at the
cost of reduced absolute place retrieval performance. In this work, we propose
a novel multi-DrosoNet localization system, dubbed RegionDrosoNet, with
significantly improved VPR performance, while preserving a low-computational
profile. Our approach relies on specializing distinct groups of DrosoNets on
differently sliced partitions of the original image, increasing extrinsic model
differentiation. Furthermore, we introduce a novel voting module to combine the
outputs of all DrosoNets into the final place prediction which considers
multiple top refence candidates from each DrosoNet. RegionDrosoNet outperforms
other lightweight VPR techniques when dealing with both appearance changes and
viewpoint variations. Moreover, it competes with computationally expensive
methods on some benchmark datasets at a small fraction of their online
inference time.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12999" title="Abstract">arXiv:2312.12999</a> [<a href="/pdf/2312.12999" title="Download PDF">pdf</a>, <a href="/format/2312.12999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Mindset: An MBTI Exploration of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jiaxi Cui</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+L">Liuzhenghao Lv</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Jing Wen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jing Tang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">YongHong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Li Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present a novel approach for integrating Myers-Briggs Type Indicator
(MBTI) personality traits into large language models (LLMs), addressing the
challenges of personality consistency in personalized AI. Our method, "Machine
Mindset," involves a two-phase fine-tuning and Direct Preference Optimization
(DPO) to embed MBTI traits into LLMs. This approach ensures that models
internalize these traits, offering a stable and consistent personality profile.
We demonstrate the effectiveness of our models across various domains, showing
alignment between model performance and their respective MBTI traits. The paper
highlights significant contributions in the development of personality datasets
and a new training methodology for personality integration in LLMs, enhancing
the potential for personalized AI applications. We also open-sourced our model
and part of the data at \url{https://github.com/PKU-YuanGroup/Machine-Mindset}.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13000" title="Abstract">arXiv:2312.13000</a> [<a href="/pdf/2312.13000" title="Download PDF">pdf</a>, <a href="/format/2312.13000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerator-driven Data Arrangement to Minimize Transformers Run-time on  Multi-core Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amirshahi%2C+A">Alireza Amirshahi</a>, 
<a href="/search/cs?searchtype=author&query=Ansaloni%2C+G">Giovanni Ansaloni</a>, 
<a href="/search/cs?searchtype=author&query=Atienza%2C+D">David Atienza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The increasing complexity of transformer models in artificial intelligence
expands their computational costs, memory usage, and energy consumption.
Hardware acceleration tackles the ensuing challenges by designing processors
and accelerators tailored for transformer models, supporting their computation
hotspots with high efficiency. However, memory bandwidth can hinder
improvements in hardware accelerators. Against this backdrop, in this paper we
propose a novel memory arrangement strategy, governed by the hardware
accelerator's kernel size, which effectively minimizes off-chip data access.
This arrangement is particularly beneficial for end-to-end transformer model
inference, where most of the computation is based on general matrix
multiplication (GEMM) operations. Additionally, we address the overhead of
non-GEMM operations in transformer models within the scope of this memory data
arrangement. Our study explores the implementation and effectiveness of the
proposed accelerator-driven data arrangement approach in both single- and
multi-core systems. Our evaluation demonstrates that our approach can achieve
up to a 2.8x speed increase when executing inferences employing
state-of-the-art transformers.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13004" title="Abstract">arXiv:2312.13004</a> [<a href="/pdf/2312.13004" title="Download PDF">pdf</a>, <a href="/format/2312.13004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RIS-Aided Near-field Communications for 6G: Opportunities and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mu%2C+X">Xidong Mu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiaqi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hanzo%2C+L">Lajos Hanzo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures, this paper was accepted for publication in IEEE Vehicular Technology Magazine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Reconfigurable intelligent surface (RIS)-aided near-field communications is
investigated. First, the necessity of investigating RIS-aided near-field
communications and the advantages brought about by the unique
spherical-wave-based near-field propagation are discussed. Then, the family of
patch-array-based RISs and metasurface-based RISs are introduced along with
their respective near-field channel models. A pair of fundamental performance
limits of RIS-aided near-field communications, namely their power scaling law
and effective degrees-of-freedom, are analyzed for both patch-array-based and
metasurface-based RISs, which reveals the potential performance gains that can
be achieved. Furthermore, the associated near-field beam training and
beamforming design issues are studied, where a two-stage hierarchical beam
training approach and a low-complexity element-wise beamforming design are
proposed for RIS-aided near-field communications. Finally, a suite of open
research problems is highlighted for motivating future research.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13008" title="Abstract">arXiv:2312.13008</a> [<a href="/pdf/2312.13008" title="Download PDF">pdf</a>, <a href="/format/2312.13008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> No More Shortcuts: Realizing the Potential of Temporal Self-Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dave%2C+I+R">Ishan Rajendrakumar Dave</a>, 
<a href="/search/cs?searchtype=author&query=Jenni%2C+S">Simon Jenni</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+M">Mubarak Shah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 (Main Technical Track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Self-supervised approaches for video have shown impressive results in video
understanding tasks. However, unlike early works that leverage temporal
self-supervision, current state-of-the-art methods primarily rely on tasks from
the image domain (e.g., contrastive learning) that do not explicitly promote
the learning of temporal features. We identify two factors that limit existing
temporal self-supervision: 1) tasks are too simple, resulting in saturated
training performance, and 2) we uncover shortcuts based on local appearance
statistics that hinder the learning of high-level features. To address these
issues, we propose 1) a more challenging reformulation of temporal
self-supervision as frame-level (rather than clip-level) recognition tasks and
2) an effective augmentation strategy to mitigate shortcuts. Our model extends
a representation of single video frames, pre-trained through contrastive
learning, with a transformer that we train through temporal self-supervision.
We demonstrate experimentally that our more challenging frame-level task
formulations and the removal of shortcuts drastically improve the quality of
features learned through temporal self-supervision. The generalization
capability of our self-supervised video method is evidenced by its
state-of-the-art performance in a wide range of high-level semantic tasks,
including video retrieval, action classification, and video attribute
recognition (such as object and scene identification), as well as low-level
temporal correspondence tasks like video object segmentation and pose tracking.
Additionally, we show that the video representations learned through our method
exhibit increased robustness to the input perturbations.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13009" title="Abstract">arXiv:2312.13009</a> [<a href="/pdf/2312.13009" title="Download PDF">pdf</a>, <a href="/format/2312.13009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EMG-based Control Strategies of a Supernumerary Robotic Hand for the  Rehabilitation of Sub-Acute Stroke Patients: Proof of Concept
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gnocco%2C+M">Marina Gnocco</a>, 
<a href="/search/cs?searchtype=author&query=Catalano%2C+M+G">Manuel G. Catalano</a>, 
<a href="/search/cs?searchtype=author&query=Grioli%2C+G">Giorgio Grioli</a>, 
<a href="/search/cs?searchtype=author&query=Trompetto%2C+C">Carlo Trompetto</a>, 
<a href="/search/cs?searchtype=author&query=Bicchi%2C+A">Antonio Bicchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 International Conference on Rehabilitation Robotics (ICORR),
  Singapore, Singapore, 2023, pp. 1-6
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">One of the most frequent and severe aftermaths of a stroke is the loss of
upper limb functionality. Therapy started in the sub-acute phase proved more
effective, mainly when the patient participates actively. Recently, a novel set
of rehabilitation and support robotic devices, known as supernumerary robotic
limbs, have been introduced. This work investigates how a surface
electromyography (sEMG) based control strategy would improve their usability in
rehabilitation, limited so far by input interfaces requiring to subjects some
level of residual mobility. After briefly introducing the phenomena hindering
post-stroke sEMG and its use to control robotic hands, we describe a framework
to acquire and interpret muscle signals of the forearm extensors. We applied it
to drive a supernumerary robotic limb, the SoftHand-X, to provide Task-Specific
Training (TST) in patients with sub-acute stroke. We propose and describe two
algorithms to control the opening and closing of the robotic hand, with
different levels of user agency and therapist control. We experimentally tested
the feasibility of the proposed approach on four patients, followed by a
therapist, to check their ability to operate the hand. The promising
preliminary results indicate sEMG-based control as a viable solution to extend
TST to sub-acute post-stroke patients.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13010" title="Abstract">arXiv:2312.13010</a> [<a href="/pdf/2312.13010" title="Download PDF">pdf</a>, <a href="/format/2312.13010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AgentCoder: Multi-Agent-based Code Generation with Iterative Testing and  Optimisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Dong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bu%2C+Q">Qingwen Bu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J+M">Jie M.Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luck%2C+M">Michael Luck</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+H">Heming Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The advancement of natural language processing (NLP) has been significantly
boosted by the development of transformer-based large language models (LLMs).
These models have revolutionized NLP tasks, particularly in code generation,
aiding developers in creating software with enhanced efficiency. Despite their
advancements, challenges in balancing code snippet generation with effective
test case generation and execution persist. To address these issues, this paper
introduces Multi-Agent Assistant Code Generation (AgentCoder), a novel solution
comprising a multi-agent framework with specialized agents: the programmer
agent, the test designer agent, and the test executor agent. During the coding
procedure, the programmer agent will focus on the code generation and
refinement based on the test executor agent's feedback. The test designer agent
will generate test cases for the generated code, and the test executor agent
will run the code with the test cases and write the feedback to the programmer.
This collaborative system ensures robust code generation, surpassing the
limitations of single-agent models and traditional methodologies. Our extensive
experiments on 9 code generation models and 12 enhancement approaches showcase
AgentCoder's superior performance over existing code generation models and
prompt engineering techniques across various benchmarks. For example,
AgentCoder achieves 77.4% and 89.1% pass@1 in HumanEval-ET and MBPP-ET with
GPT-3.5, while SOTA baselines obtain only 69.5% and 63.0%.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13012" title="Abstract">arXiv:2312.13012</a> [<a href="/pdf/2312.13012" title="Download PDF">pdf</a>, <a href="/format/2312.13012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defining and executing temporal constraints for evaluating engineering  artifact compliance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ratiu%2C+C">Cosmina-Cristina Ratiu</a>, 
<a href="/search/cs?searchtype=author&query=Mayr-Dorn%2C+C">Christoph Mayr-Dorn</a>, 
<a href="/search/cs?searchtype=author&query=Egyed%2C+A">Alexander Egyed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Engineering processes for safety-critical systems describe the steps and
sequence that guide engineers from refining user requirements into executable
code, as well as producing the artifacts, traces, and evidence that the
resulting system is of high quality. Process compliance focuses on ensuring
that the actual engineering work is followed as closely as possible to the
described engineering processes. To this end, temporal constraints describe the
ideal sequence of steps. Checking these process constraints, however, is still
a daunting task that requires a lot of manual work and delivers feedback to
engineers only late in the process. In this paper, we present an automated
constraint checking approach that can incrementally check temporal constraints
across inter-related engineering artifacts upon every artifact change thereby
enabling timely feedback to engineers on process deviations. Temporal
constraints are expressed in the Object Constraint Language (OCL) extended with
operators from Linear Temporal Logic (LTL). We demonstrate the ability of our
approach to support a wide range of higher level temporal patterns. We further
show that for constraints in an industry-derived use case, the average
evaluation time for a single constraint takes around 0.2 milliseconds.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13015" title="Abstract">arXiv:2312.13015</a> [<a href="/pdf/2312.13015" title="Download PDF">pdf</a>, <a href="/format/2312.13015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VIBES: Vibro-Inertial Bionic Enhancement System in a Prosthetic Socket
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ivani%2C+A+S">Alessia Silvia Ivani</a>, 
<a href="/search/cs?searchtype=author&query=Barontini%2C+F">Federica Barontini</a>, 
<a href="/search/cs?searchtype=author&query=Catalano%2C+M+G">Manuel G. Catalano</a>, 
<a href="/search/cs?searchtype=author&query=Grioli%2C+G">Giorgio Grioli</a>, 
<a href="/search/cs?searchtype=author&query=Bianchi%2C+M">Matteo Bianchi</a>, 
<a href="/search/cs?searchtype=author&query=Bicchi%2C+A">Antonio Bicchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 8 figures, 2023 International Conference on Rehabilitation Robotics (ICORR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The use of vibrotactile feedback is of growing interest in the field of
prosthetics, but few devices fully integrate this technology in the prosthesis
to transmit high-frequency contact information (such as surface roughness and
first contact) arising from the interaction of the prosthetic device with
external items. This study describes a wearable vibrotactile system for
high-frequency tactile information embedded in the prosthetic socket. The
device consists of two compact planar vibrotactile actuators in direct contact
with the user's skin to transmit tactile cues. These stimuli are directly
related to the acceleration profiles recorded with two IMUS placed on the
distal phalanx of a soft under-actuated robotic prosthesis (SoftHand Pro). We
characterized the system from a psychophysical point of view with fifteen
able-bodied participants by computing participants' Just Noticeable Difference
(JND) related to the discrimination of vibrotactile cues delivered on the index
finger, which are associated with the exploration of different sandpapers.
Moreover, we performed a pilot experiment with one SoftHand Pro prosthesis user
by designing a task, i.e. Active Texture Identification, to investigate if our
feedback could enhance users' roughness discrimination. Results indicate that
the device can effectively convey contact and texture cues, which users can
readily detect and distinguish.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13016" title="Abstract">arXiv:2312.13016</a> [<a href="/pdf/2312.13016" title="Download PDF">pdf</a>, <a href="/format/2312.13016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffPortrait3D: Controllable Diffusion for Zero-Shot Portrait View  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuming Gu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongyi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">You Xie</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+G">Guoxian Song</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yichun Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+D">Di Chang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Lingjie Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present DiffPortrait3D, a conditional diffusion model that is capable of
synthesizing 3D-consistent photo-realistic novel views from as few as a single
in-the-wild portrait. Specifically, given a single RGB input, we aim to
synthesize plausible but consistent facial details rendered from novel camera
views with retained both identity and facial expression. In lieu of
time-consuming optimization and fine-tuning, our zero-shot method generalizes
well to arbitrary face portraits with unposed camera views, extreme facial
expressions, and diverse artistic depictions. At its core, we leverage the
generative prior of 2D diffusion models pre-trained on large-scale image
datasets as our rendering backbone, while the denoising is guided with
disentangled attentive control of appearance and camera pose. To achieve this,
we first inject the appearance context from the reference image into the
self-attention layers of the frozen UNets. The rendering view is then
manipulated with a novel conditional control module that interprets the camera
pose by watching a condition image of a crossed subject from the same view.
Furthermore, we insert a trainable cross-view attention module to enhance view
consistency, which is further strengthened with a novel 3D-aware noise
generation process during inference. We demonstrate state-of-the-art results
both qualitatively and quantitatively on our challenging in-the-wild and
multi-view benchmarks.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13027" title="Abstract">arXiv:2312.13027</a> [<a href="/pdf/2312.13027" title="Download PDF">pdf</a>, <a href="/format/2312.13027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Doubly Perturbed Task-Free Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+B+H">Byung Hyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+M">Min-hwan Oh</a>, 
<a href="/search/cs?searchtype=author&query=Chun%2C+S+Y">Se Young Chun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Task-free online continual learning (TF-CL) is a challenging problem where
the model incrementally learns tasks without explicit task information.
Although training with entire data from the past, present as well as future is
considered as the gold standard, naive approaches in TF-CL with the current
samples may be conflicted with learning with samples in the future, leading to
catastrophic forgetting and poor plasticity. Thus, a proactive consideration of
an unseen future sample in TF-CL becomes imperative. Motivated by this
intuition, we propose a novel TF-CL framework considering future samples and
show that injecting adversarial perturbations on both input data and
decision-making is effective. Then, we propose a novel method named Doubly
Perturbed Continual Learning (DPCL) to efficiently implement these input and
decision-making perturbations. Specifically, for input perturbation, we propose
an approximate perturbation method that injects noise into the input data as
well as the feature vector and then interpolates the two perturbed samples. For
decision-making process perturbation, we devise multiple stochastic
classifiers. We also investigate a memory management scheme and learning rate
scheduling reflecting our proposed double perturbations. We demonstrate that
our proposed method outperforms the state-of-the-art baseline methods by large
margins on various TF-CL benchmarks.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13031" title="Abstract">arXiv:2312.13031</a> [<a href="/pdf/2312.13031" title="Download PDF">pdf</a>, <a href="/format/2312.13031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A self-attention-based differentially private tabular GAN with high data  utility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zijian Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhihui Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Databases (cs.DB)

</div>
<p class="mathjax">Generative Adversarial Networks (GANs) have become a ubiquitous technology
for data generation, with their prowess in image generation being
well-established. However, their application in generating tabular data has
been less than ideal. Furthermore, attempting to incorporate differential
privacy technology into these frameworks has often resulted in a degradation of
data utility. To tackle these challenges, this paper introduces DP-SACTGAN, a
novel Conditional Generative Adversarial Network (CGAN) framework for
differentially private tabular data generation, aiming to surmount these
obstacles. Experimental findings demonstrate that DP-SACTGAN not only
accurately models the distribution of the original data but also effectively
satisfies the requirements of differential privacy.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13032" title="Abstract">arXiv:2312.13032</a> [<a href="/pdf/2312.13032" title="Download PDF">pdf</a>, <a href="/format/2312.13032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NodeMixup: Tackling Under-Reaching for Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Weigang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Z">Ziyu Guan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Long Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Graph Neural Networks (GNNs) have become mainstream methods for solving the
semi-supervised node classification problem. However, due to the uneven
location distribution of labeled nodes in the graph, labeled nodes are only
accessible to a small portion of unlabeled nodes, leading to the
\emph{under-reaching} issue. In this study, we firstly reveal under-reaching by
conducting an empirical investigation on various well-known graphs. Then, we
demonstrate that under-reaching results in unsatisfactory distribution
alignment between labeled and unlabeled nodes through systematic experimental
analysis, significantly degrading GNNs' performance. To tackle under-reaching
for GNNs, we propose an architecture-agnostic method dubbed NodeMixup. The
fundamental idea is to (1) increase the reachability of labeled nodes by
labeled-unlabeled pairs mixup, (2) leverage graph structures via fusing the
neighbor connections of intra-class node pairs to improve performance gains of
mixup, and (3) use neighbor label distribution similarity incorporating node
degrees to determine sampling weights for node mixup. Extensive experiments
demonstrate the efficacy of NodeMixup in assisting GNNs in handling
under-reaching. The source code is available at
\url{https://github.com/WeigangLu/NodeMixup}.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13033" title="Abstract">arXiv:2312.13033</a> [<a href="/pdf/2312.13033" title="Download PDF">pdf</a>, <a href="/format/2312.13033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable artificial intelligence approaches for brain-computer  interfaces: a review and design space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajpura%2C+P">Param Rajpura</a>, 
<a href="/search/cs?searchtype=author&query=Cecotti%2C+H">Hubert Cecotti</a>, 
<a href="/search/cs?searchtype=author&query=Meena%2C+Y+K">Yogesh Kumar Meena</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> draft submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This review paper provides an integrated perspective of Explainable
Artificial Intelligence techniques applied to Brain-Computer Interfaces. BCIs
use predictive models to interpret brain signals for various high-stake
applications. However, achieving explainability in these complex models is
challenging as it compromises accuracy. The field of XAI has emerged to address
the need for explainability across various stakeholders, but there is a lack of
an integrated perspective in XAI for BCI (XAI4BCI) literature. It is necessary
to differentiate key concepts like explainability, interpretability, and
understanding in this context and formulate a comprehensive framework. To
understand the need of XAI for BCI, we pose six key research questions for a
systematic review and meta-analysis, encompassing its purposes, applications,
usability, and technical feasibility. We employ the PRISMA methodology --
preferred reporting items for systematic reviews and meta-analyses to review
(n=1246) and analyze (n=84) studies published in 2015 and onwards for key
insights. The results highlight that current research primarily focuses on
interpretability for developers and researchers, aiming to justify outcomes and
enhance model performance. We discuss the unique approaches, advantages, and
limitations of XAI4BCI from the literature. We draw insights from philosophy,
psychology, and social sciences. We propose a design space for XAI4BCI,
considering the evolving need to visualize and investigate predictive model
outcomes customised for various stakeholders in the BCI development and
deployment lifecycle. This paper is the first to focus solely on reviewing
XAI4BCI research articles. This systematic review and meta-analysis findings
with the proposed design space prompt important discussions on establishing
standards for BCI explanations, highlighting current limitations, and guiding
the future of XAI in BCI.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13038" title="Abstract">arXiv:2312.13038</a> [<a href="/pdf/2312.13038" title="Download PDF">pdf</a>, <a href="/format/2312.13038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoXPCR: Automated Multi-Objective Model Selection for Time Series  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fischer%2C+R">Raphael Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Saadallah%2C+A">Amal Saadallah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Automated machine learning (AutoML) streamlines the creation of ML models.
While most methods select the "best" model based on predictive quality, it's
crucial to acknowledge other aspects, such as interpretability and resource
consumption. This holds particular importance in the context of deep neural
networks (DNNs), as these models are often perceived as computationally
intensive black boxes. In the challenging domain of time series forecasting,
DNNs achieve stunning results, but specialized approaches for automatically
selecting models are scarce. In this paper, we propose AutoXPCR - a novel
method for automated and explainable multi-objective model selection. Our
approach leverages meta-learning to estimate any model's performance along PCR
criteria, which encompass (P)redictive error, (C)omplexity, and (R)esource
demand. Explainability is addressed on multiple levels, as our interactive
framework can prioritize less complex models and provide by-product
explanations of recommendations. We demonstrate practical feasibility by
deploying AutoXPCR on over 1000 configurations across 114 data sets from
various domains. Our method clearly outperforms other model selection
approaches - on average, it only requires 20% of computation costs for
recommending models with 90% of the best-possible quality.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13040" title="Abstract">arXiv:2312.13040</a> [<a href="/pdf/2312.13040" title="Download PDF">pdf</a>, <a href="/format/2312.13040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval-augmented Multilingual Knowledge Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weixuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Haddow%2C+B">Barry Haddow</a>, 
<a href="/search/cs?searchtype=author&query=Birch%2C+A">Alexandra Birch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Knowledge represented in Large Language Models (LLMs) is quite often
incorrect and can also become obsolete over time. Updating knowledge via
fine-tuning is computationally resource-hungry and not reliable, and so
knowledge editing (KE) has developed as an effective and economical alternative
to inject new knowledge or to fix factual errors in LLMs. Although there has
been considerable interest in this area, current KE research exclusively
focuses on the monolingual setting, typically in English. However, what happens
if the new knowledge is supplied in one language, but we would like to query
the LLM in a different language? To address the problem of multilingual
knowledge editing, we propose Retrieval-augmented Multilingual Knowledge Editor
(ReMaKE) to update new knowledge in LLMs. ReMaKE can perform model-agnostic
knowledge editing in multilingual settings. ReMaKE concatenates the new
knowledge retrieved from a multilingual knowledge base with prompts. Our
experimental results show that ReMaKE outperforms baseline knowledge editing
methods by a significant margin and is the first KE method to work in a
multilingual setting. We provide our multilingual knowledge editing dataset
(MzsRE) in 12 languages, which along with code, and additional project
information is available at https://github.com/Vicky-Wil/ReMaKE.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13041" title="Abstract">arXiv:2312.13041</a> [<a href="/pdf/2312.13041" title="Download PDF">pdf</a>, <a href="/format/2312.13041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing SQL Injection Detection for High-Speed Data Centers: A Novel  Approach Using Cascaded NLP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tasdemir%2C+K">Kasim Tasdemir</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+R">Rafiullah Khan</a>, 
<a href="/search/cs?searchtype=author&query=Siddiqui%2C+F">Fahad Siddiqui</a>, 
<a href="/search/cs?searchtype=author&query=Sezer%2C+S">Sakir Sezer</a>, 
<a href="/search/cs?searchtype=author&query=Kurugollu%2C+F">Fatih Kurugollu</a>, 
<a href="/search/cs?searchtype=author&query=Yengec-Tasdemir%2C+S+B">Sena Busra Yengec-Tasdemir</a>, 
<a href="/search/cs?searchtype=author&query=Bolat%2C+A">Alperen Bolat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, The code is available at <a href="https://github.com/gdrlab/cascaded-sqli-detection">this https URL</a> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Detecting SQL Injection (SQLi) attacks is crucial for web-based data center
security, but it is challenging to balance accuracy and computational
efficiency, especially in high-speed networks. Traditional methods struggle
with this balance, while NLP-based approaches, although accurate, are
computationally intensive.
<br />We introduce a novel cascade SQLi detection method, blending classical and
transformer-based NLP models, achieving a 99.86% detection accuracy with
significantly lower computational demands-20 times faster than using
transformer-based models alone. Our approach is tested in a realistic setting
and compared with 35 other methods, including Machine Learning-based and
transformer models like BERT, on a dataset of over 30,000 SQL sentences.
<br />Our results show that this hybrid method effectively detects SQLi in
high-traffic environments, offering efficient and accurate protection against
SQLi vulnerabilities with computational efficiency. The code is available at
https://github.com/gdrlab/cascaded-sqli-detection .
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13045" title="Abstract">arXiv:2312.13045</a> [<a href="/pdf/2312.13045" title="Download PDF">pdf</a>, <a href="/ps/2312.13045" title="Download PostScript">ps</a>, <a href="/format/2312.13045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feasibility Conditions for Mobile LiFi
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ma%2C+S">Shuai Ma</a>, 
<a href="/search/eess?searchtype=author&query=Sheng%2C+H">Haihong Sheng</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+J">Junchang Sun</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Hang Li</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+X">Xiaodong Liu</a>, 
<a href="/search/eess?searchtype=author&query=Qiu%2C+C">Chen Qiu</a>, 
<a href="/search/eess?searchtype=author&query=Safari%2C+M">Majid Safari</a>, 
<a href="/search/eess?searchtype=author&query=Al-Dhahir%2C+N">Naofal Al-Dhahir</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Shiyin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Light fidelity (LiFi) is a potential key technology for future 6G networks.
However, its feasibility of supporting mobile communications has not been
fundamentally discussed. In this paper, we investigate the time-varying channel
characteristics of mobile LiFi based on measured mobile phone rotation and
movement data. Specifically, we define LiFi channel coherence time to evaluate
the correlation of the channel timing sequence. Then, we derive the expression
of LiFi transmission rate based on the m-pulse-amplitude-modulation (M-PAM).
The derived rate expression indicates that mobile LiFi communications is
feasible by using at least two photodiodes (PDs) with different orientations.
Further, we propose two channel estimation schemes, and propose a LiFi channel
tracking scheme to improve the communication performance. Finally, our
experimental results show that the channel coherence time is on the order of
tens of milliseconds, which indicates a relatively stable channel. In addition,
based on the measured data, better communication performance can be realized in
the multiple-input multiple-output (MIMO) scenario with a rate of 36Mbit/s,
compared to other scenarios. The results also show that the proposed channel
estimation and tracking schemes are effective in designing mobile LiFi systems.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13048" title="Abstract">arXiv:2312.13048</a> [<a href="/pdf/2312.13048" title="Download PDF">pdf</a>, <a href="/format/2312.13048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MIMO Integrated Sensing and Communication Exploiting Prior Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuowen Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted for possible journal publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we study a multiple-input multiple-output (MIMO) integrated
sensing and communication (ISAC) system where one multi-antenna base station
(BS) sends information to a user with multiple antennas in the downlink and
simultaneously senses the location parameter of a target based on its reflected
echo signals received back at the BS receive antennas. We focus on the case
where the location parameter to be sensed is unknown and random, for which the
prior distribution information is available for exploitation. First, we propose
to adopt the posterior Cram\'er-Rao bound (PCRB) as the sensing performance
metric with prior information, which quantifies a lower bound of the
mean-squared error (MSE). Since the PCRB is in a complicated form, we derive a
tight upper bound of it to draw more insights. Based on this, we analytically
show that by exploiting the prior distribution information, the PCRB is always
no larger than the CRB averaged over random location realizations without prior
information exploitation. Next, we formulate the transmit covariance matrix
optimization problem to minimize the sensing PCRB under a communication rate
constraint. We obtain the optimal solution and derive useful properties on its
rank. Then, by considering the derived PCRB upper bound as the objective
function, we propose a low-complexity suboptimal solution in semi-closed form.
Numerical results demonstrate the effectiveness of our proposed designs in MIMO
ISAC exploiting prior information.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13049" title="Abstract">arXiv:2312.13049</a> [<a href="/pdf/2312.13049" title="Download PDF">pdf</a>, <a href="/format/2312.13049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy norm error estimates and convergence analysis for a stabilized  Maxwell&#x27;s equations in conductive media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lindstr%C3%B6m%2C+E">Eric Lindstr&#xf6;m</a>, 
<a href="/search/math?searchtype=author&query=Beilina%2C+L">Larisa Beilina</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">The aim of this article is to investigate the well-posedness, stability and
convergence of solutions to the time-dependent Maxwell's equations for electric
field in conductive media in continuous and discrete settings. The situation we
consider would represent a physical problem where a subdomain is emerged in a
homogeneous medium, characterized by constant dielectric permittivity and
conductivity functions. It is well known that in these homogeneous regions the
solution to the Maxwell's equations also solves the wave equation which makes
calculations very efficient. In this way our problem can be considered as a
coupling problem for which we derive stability and convergence analysis. A
number of numerical examples validate theoretical convergence rates of the
proposed stabilized explicit finite element scheme.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13053" title="Abstract">arXiv:2312.13053</a> [<a href="/pdf/2312.13053" title="Download PDF">pdf</a>, <a href="/format/2312.13053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying Bias in Text-to-Image Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vice%2C+J">Jordan Vice</a>, 
<a href="/search/cs?searchtype=author&query=Akhtar%2C+N">Naveed Akhtar</a>, 
<a href="/search/cs?searchtype=author&query=Hartley%2C+R">Richard Hartley</a>, 
<a href="/search/cs?searchtype=author&query=Mian%2C+A">Ajmal Mian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> main manuscript = 9 pages, 6 tables, 4 figures. Supplementary material = 15 pages, 13 tables, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Bias in text-to-image (T2I) models can propagate unfair social
representations and may be used to aggressively market ideas or push
controversial agendas. Existing T2I model bias evaluation methods only focus on
social biases. We look beyond that and instead propose an evaluation
methodology to quantify general biases in T2I generative models, without any
preconceived notions. We assess four state-of-the-art T2I models and compare
their baseline bias characteristics to their respective variants (two for
each), where certain biases have been intentionally induced. We propose three
evaluation metrics to assess model biases including: (i) Distribution bias,
(ii) Jaccard hallucination and (iii) Generative miss-rate. We conduct two
evaluation studies, modelling biases under general, and task-oriented
conditions, using a marketing scenario as the domain for the latter. We also
quantify social biases to compare our findings to related works. Finally, our
methodology is transferred to evaluate captioned-image datasets and measure
their bias. Our approach is objective, domain-agnostic and consistently
measures different forms of T2I model biases. We have developed a web
application and practical implementation of what has been proposed in this
work, which is at https://huggingface.co/spaces/JVice/try-before-you-bias. A
video series with demonstrations is available at
https://www.youtube.com/channel/UCk-0xyUyT0MSd_hkp4jQt1Q
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13064" title="Abstract">arXiv:2312.13064</a> [<a href="/pdf/2312.13064" title="Download PDF">pdf</a>, <a href="/format/2312.13064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lampr: Boosting the Effectiveness of Language-Generic Program Reduction  via Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengxiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yongqiang Tian</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhenyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yiwen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+S+H">Shin Hwei Tan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chengnian Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 tables, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Program reduction is a prevalent technique to facilitate compilers' debugging
by automatically minimizing bug-triggering programs. Existing program reduction
techniques are either generic across languages (e.g., Perses and Vulcan) or
specifically customized for one certain language by employing language-specific
features, like C-Reduce. However, striking the balance between generality
across multiple programming languages and specificity to individual languages
in program reduction is yet to be explored.
<br />This paper proposes Lampr, the first technique utilizing LLMs to perform
language-specific program reduction for multiple languages. The core insight is
to utilize both the language-generic syntax level program reduction (e.g.,
Perses) and the language-specific semantic level program transformations
learned by LLMs. Alternately, language-generic program reducers efficiently
reduce programs into 1-tree-minimality, which is small enough to be manageable
for LLMs; LLMs effectively transform programs via the learned semantics to
expose new reduction opportunities for the language-generic program reducers to
further reduce the programs.
<br />Our extensive evaluation on 50 benchmarks across three languages (C, Rust,
and JavaScript) has highlighted Lampr's practicality and superiority over
Vulcan, the state-of-the-art language-generic program reducer. For
effectiveness, Lampr surpasses Vulcan by producing 24.93\%, 4.47\%, and 11.71\%
smaller programs on benchmarks in C, Rust and JavaScript. Moreover, Lampr and
Vulcan have demonstrated their potential to complement each other. By using
Vulcan on Lampr's output for C programs, we achieve program sizes comparable to
those reduced by C-Reduce. For efficiency, Lampr takes 10.77\%, 34.88\%,
36.96\% less time than Vulcan to finish all benchmarks in C, Rust and
JavaScript, separately.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13066" title="Abstract">arXiv:2312.13066</a> [<a href="/pdf/2312.13066" title="Download PDF">pdf</a>, <a href="/format/2312.13066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PPEA-Depth: Progressive Parameter-Efficient Adaptation for  Self-Supervised Monocular Depth Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yue-Jiang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuan-Chen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Ying-Tian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fang-Lue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Song-Hai Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Self-supervised monocular depth estimation is of significant importance with
applications spanning across autonomous driving and robotics. However, the
reliance on self-supervision introduces a strong static-scene assumption,
thereby posing challenges in achieving optimal performance in dynamic scenes,
which are prevalent in most real-world situations. To address these issues, we
propose PPEA-Depth, a Progressive Parameter-Efficient Adaptation approach to
transfer a pre-trained image model for self-supervised depth estimation. The
training comprises two sequential stages: an initial phase trained on a dataset
primarily composed of static scenes, succeeded by an expansion to more
intricate datasets involving dynamic scenes. To facilitate this process, we
design compact encoder and decoder adapters to enable parameter-efficient
tuning, allowing the network to adapt effectively. They not only uphold
generalized patterns from pre-trained image models but also retain knowledge
gained from the preceding phase into the subsequent one. Extensive experiments
demonstrate that PPEA-Depth achieves state-of-the-art performance on KITTI,
CityScapes and DDAD datasets.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13068" title="Abstract">arXiv:2312.13068</a> [<a href="/pdf/2312.13068" title="Download PDF">pdf</a>, <a href="/format/2312.13068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous-time Graph Representation with Sequential Survival Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Celikkanat%2C+A">Abdulkadir Celikkanat</a>, 
<a href="/search/cs?searchtype=author&query=Nakis%2C+N">Nikolaos Nakis</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%B8rup%2C+M">Morten M&#xf8;rup</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 38th Annual AAAI Conference on Artificial Intelligence (AAAI24), Vancouver, British Columbia, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Over the past two decades, there has been a tremendous increase in the growth
of representation learning methods for graphs, with numerous applications
across various fields, including bioinformatics, chemistry, and the social
sciences. However, current dynamic network approaches focus on discrete-time
networks or treat links in continuous-time networks as instantaneous events.
Therefore, these approaches have limitations in capturing the persistence or
absence of links that continuously emerge and disappear over time for
particular durations. To address this, we propose a novel stochastic process
relying on survival functions to model the durations of links and their
absences over time. This forms a generic new likelihood specification
explicitly accounting for intermittent edge-persistent networks, namely GraSSP:
Graph Representation with Sequential Survival Process. We apply the developed
framework to a recent continuous time dynamic latent distance model
characterizing network dynamics in terms of a sequence of piecewise linear
movements of nodes in latent space. We quantitatively assess the developed
framework in various downstream tasks, such as link prediction and network
completion, demonstrating that the developed modeling framework accounting for
link persistence and absence well tracks the intrinsic trajectories of nodes in
a latent space and captures the underlying characteristics of evolving network
structure.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13071" title="Abstract">arXiv:2312.13071</a> [<a href="/pdf/2312.13071" title="Download PDF">pdf</a>, <a href="/format/2312.13071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point Deformable Network with Enhanced Normal Embedding for Point Cloud  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xingyilang Yin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Liangchen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Nannan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinbo Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently MLP-based methods have shown strong performance in point cloud
analysis. Simple MLP architectures are able to learn geometric features in
local point groups yet fail to model long-range dependencies directly. In this
paper, we propose Point Deformable Network (PDNet), a concise MLP-based network
that can capture long-range relations with strong representation ability.
Specifically, we put forward Point Deformable Aggregation Module (PDAM) to
improve representation capability in both long-range dependency and adaptive
aggregation among points. For each query point, PDAM aggregates information
from deformable reference points rather than points in limited local areas. The
deformable reference points are generated data-dependent, and we initialize
them according to the input point positions. Additional offsets and modulation
scalars are learned on the whole point features, which shift the deformable
reference points to the regions of interest. We also suggest estimating the
normal vector for point clouds and applying Enhanced Normal Embedding (ENE) to
the geometric extractors to improve the representation ability of single-point.
Extensive experiments and ablation studies on various benchmarks demonstrate
the effectiveness and superiority of our PDNet.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13076" title="Abstract">arXiv:2312.13076</a> [<a href="/pdf/2312.13076" title="Download PDF">pdf</a>, <a href="/format/2312.13076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Integrate Digital Twin and Virtual Reality in Robotics Systems?  Design and Implementation for Providing Robotics Maintenance Services in Data  Centers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hanyi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In the context of Industry 4.0, the physical and digital worlds are closely
connected, and robots are widely used to achieve system automation. Digital
twin solutions have contributed significantly to the growth of Industry 4.0.
Combining various technologies is a trend that aims to improve system
performance. For example, digital twinning can be combined with virtual reality
in automated systems. This paper proposes a new concept to articulate this
combination, which has mainly been implemented in engineering research
projects. However, there are currently no guidelines, plans, or concepts to
articulate this combination. The concept will be implemented in data centers,
which are crucial for enabling virtual tasks in our daily lives. Due to the
COVID-19 pandemic, there has been a surge in demand for services such as
e-commerce and videoconferencing. Regular maintenance is necessary to ensure
uninterrupted and reliable services. Manual maintenance strategies may not be
sufficient to meet the current high demand, and innovative approaches are
needed to address the problem. This paper presents a novel approach to data
center maintenance: real-time monitoring by an autonomous robot. The robot is
integrated with digital twins of assets and a virtual reality interface that
allows human personnel to control it and respond to alarms. This methodology
enables faster, more cost-effective, and higher quality data center
maintenance. It has been validated in a real data centre and can be used for
intelligent monitoring and management through joint data sources. The method
has potential applications in other automated systems.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13081" title="Abstract">arXiv:2312.13081</a> [<a href="/pdf/2312.13081" title="Download PDF">pdf</a>, <a href="/format/2312.13081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BEVSeg2TP: Surround View Camera Bird&#x27;s-Eye-View Based Joint Vehicle  Segmentation and Ego Vehicle Trajectory Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+S">Sushil Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Arindam Das</a>, 
<a href="/search/cs?searchtype=author&query=Sistu%2C+G">Ganesh Sistu</a>, 
<a href="/search/cs?searchtype=author&query=Halton%2C+M">Mark Halton</a>, 
<a href="/search/cs?searchtype=author&query=Eising%2C+C">Ciar&#xe1;n Eising</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the International Conference on Computer Vision Theory and Applications (VISAPP) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Trajectory prediction is, naturally, a key task for vehicle autonomy. While
the number of traffic rules is limited, the combinations and uncertainties
associated with each agent's behaviour in real-world scenarios are nearly
impossible to encode. Consequently, there is a growing interest in
learning-based trajectory prediction. The proposed method in this paper
predicts trajectories by considering perception and trajectory prediction as a
unified system. In considering them as unified tasks, we show that there is the
potential to improve the performance of perception. To achieve these goals, we
present BEVSeg2TP - a surround-view camera bird's-eye-view-based joint vehicle
segmentation and ego vehicle trajectory prediction system for autonomous
vehicles. The proposed system uses a network trained on multiple camera views.
The images are transformed using several deep learning techniques to perform
semantic segmentation of objects, including other vehicles, in the scene. The
segmentation outputs are fused across the camera views to obtain a
comprehensive representation of the surrounding vehicles from the
bird's-eye-view perspective. The system further predicts the future trajectory
of the ego vehicle using a spatiotemporal probabilistic network (STPN) to
optimize trajectory prediction. This network leverages information from
encoder-decoder transformers and joint vehicle segmentation.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13084" title="Abstract">arXiv:2312.13084</a> [<a href="/pdf/2312.13084" title="Download PDF">pdf</a>, <a href="/format/2312.13084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pyreal: A Framework for Interpretable ML Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zytek%2C+A">Alexandra Zytek</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei-En Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dongyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Berti-Equille%2C+L">Laure Berti-Equille</a>, 
<a href="/search/cs?searchtype=author&query=Veeramachaneni%2C+K">Kalyan Veeramachaneni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC); Software Engineering (cs.SE)

</div>
<p class="mathjax">Users in many domains use machine learning (ML) predictions to help them make
decisions. Effective ML-based decision-making often requires explanations of ML
models and their predictions. While there are many algorithms that explain
models, generating explanations in a format that is comprehensible and useful
to decision-makers is a nontrivial task that can require extensive development
overhead. We developed Pyreal, a highly extensible system with a corresponding
Python implementation for generating a variety of interpretable ML
explanations. Pyreal converts data and explanations between the feature spaces
expected by the model, relevant explanation algorithms, and human users,
allowing users to generate interpretable explanations in a low-code manner. Our
studies demonstrate that Pyreal generates more useful explanations than
existing systems while remaining both easy-to-use and efficient.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13086" title="Abstract">arXiv:2312.13086</a> [<a href="/pdf/2312.13086" title="Download PDF">pdf</a>, <a href="/format/2312.13086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-sensory Anti-collision Design for Autonomous Nano-swarm  Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pourjabar%2C+M">Mahyar Pourjabar</a>, 
<a href="/search/cs?searchtype=author&query=Rusci%2C+M">Manuele Rusci</a>, 
<a href="/search/cs?searchtype=author&query=Bompani%2C+L">Luca Bompani</a>, 
<a href="/search/cs?searchtype=author&query=Lamberti%2C+L">Lorenzo Lamberti</a>, 
<a href="/search/cs?searchtype=author&query=Niculescu%2C+V">Vlad Niculescu</a>, 
<a href="/search/cs?searchtype=author&query=Palossi%2C+D">Daniele Palossi</a>, 
<a href="/search/cs?searchtype=author&query=Benini%2C+L">Luca Benini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This work presents a multi-sensory anti-collision system design to achieve
robust autonomous exploration capabilities for a swarm of 10 cm-side
nano-drones operating on object detection missions. We combine lightweight
single-beam laser ranging to avoid proximity collisions with a long-range
vision-based obstacle avoidance deep learning model (i.e., PULP-Dronet) and an
ultra-wide-band (UWB) based ranging module to prevent intra-swarm collisions.
An in-field study shows that our multisensory approach can prevent collisions
with static obstacles, improving the mission success rate from 20% to 80% in
cluttered environments w.r.t. a State-of-the-Art (SoA) baseline. At the same
time, the UWB-based sub-system shows a 92.8% success rate in preventing
collisions between drones of a four-agent fleet within a safety distance of 65
cm. On a SoA robotic platform extended by a GAP8 multi-core processor, the
PULP-Dronet runs interleaved with an objected detection task, which constraints
its execution at 1.6 frame/s. This throughput is sufficient for avoiding
obstacles with a probability of about 40% but shows a need for more capable
processors for the next-generation nano-drone swarms.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13090" title="Abstract">arXiv:2312.13090</a> [<a href="/pdf/2312.13090" title="Download PDF">pdf</a>, <a href="/format/2312.13090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perception Test 2023: A Summary of the First Challenge And Outcome
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heyward%2C+J">Joseph Heyward</a>, 
<a href="/search/cs?searchtype=author&query=Carreira%2C+J">Jo&#xe3;o Carreira</a>, 
<a href="/search/cs?searchtype=author&query=Damen%2C+D">Dima Damen</a>, 
<a href="/search/cs?searchtype=author&query=Zisserman%2C+A">Andrew Zisserman</a>, 
<a href="/search/cs?searchtype=author&query=P%C4%83tr%C4%83ucean%2C+V">Viorica P&#x103;tr&#x103;ucean</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The First Perception Test challenge was held as a half-day workshop alongside
the IEEE/CVF International Conference on Computer Vision (ICCV) 2023, with the
goal of benchmarking state-of-the-art video models on the recently proposed
Perception Test benchmark. The challenge had six tracks covering low-level and
high-level tasks, with both a language and non-language interface, across
video, audio, and text modalities, and covering: object tracking, point
tracking, temporal action localisation, temporal sound localisation,
multiple-choice video question-answering, and grounded video
question-answering. We summarise in this report the task descriptions, metrics,
baselines, and results.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13091" title="Abstract">arXiv:2312.13091</a> [<a href="/pdf/2312.13091" title="Download PDF">pdf</a>, <a href="/format/2312.13091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MoSAR: Monocular Semi-Supervised Model for Avatar Reconstruction using  Differentiable Shading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dib%2C+A">Abdallah Dib</a>, 
<a href="/search/cs?searchtype=author&query=Hafemann%2C+L+G">Luiz Gustavo Hafemann</a>, 
<a href="/search/cs?searchtype=author&query=Got%2C+E">Emeline Got</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+T">Trevor Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Fadaeinejad%2C+A">Amin Fadaeinejad</a>, 
<a href="/search/cs?searchtype=author&query=Cruz%2C+R+M+O">Rafael M. O. Cruz</a>, 
<a href="/search/cs?searchtype=author&query=Carbonneau%2C+M">Marc-Andre Carbonneau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://ubisoft-laforge.github.io/character/mosar/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Reconstructing an avatar from a portrait image has many applications in
multimedia, but remains a challenging research problem. Extracting reflectance
maps and geometry from one image is ill-posed: recovering geometry is a
one-to-many mapping problem and reflectance and light are difficult to
disentangle. Accurate geometry and reflectance can be captured under the
controlled conditions of a light stage, but it is costly to acquire large
datasets in this fashion. Moreover, training solely with this type of data
leads to poor generalization with in-the-wild images. This motivates the
introduction of MoSAR, a method for 3D avatar generation from monocular images.
We propose a semi-supervised training scheme that improves generalization by
learning from both light stage and in-the-wild datasets. This is achieved using
a novel differentiable shading formulation. We show that our approach
effectively disentangles the intrinsic face parameters, producing relightable
avatars. As a result, MoSAR estimates a richer set of skin reflectance maps,
and generates more realistic avatars than existing state-of-the-art methods. We
also introduce a new dataset, named FFHQ-UV-Intrinsics, the first public
dataset providing intrisic face attributes at scale (diffuse, specular, ambient
occlusion and translucency maps) for a total of 10k subjects. The project
website and the dataset are available on the following link:
https://ubisoftlaforge.github.io/character/mosar
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13094" title="Abstract">arXiv:2312.13094</a> [<a href="/pdf/2312.13094" title="Download PDF">pdf</a>, <a href="/format/2312.13094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated MPI code generation for scalable finite-difference solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bisbas%2C+G">George Bisbas</a>, 
<a href="/search/cs?searchtype=author&query=Nelson%2C+R">Rhodri Nelson</a>, 
<a href="/search/cs?searchtype=author&query=Louboutin%2C+M">Mathias Louboutin</a>, 
<a href="/search/cs?searchtype=author&query=Kelly%2C+P+H+J">Paul H.J. Kelly</a>, 
<a href="/search/cs?searchtype=author&query=Luporini%2C+F">Fabio Luporini</a>, 
<a href="/search/cs?searchtype=author&query=Gorman%2C+G">Gerard Gorman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 12 figures (18 pages with References and Appendix)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Mathematical Software (cs.MS); Performance (cs.PF)

</div>
<p class="mathjax">Partial differential equations (PDEs) are crucial in modelling diverse
phenomena across scientific disciplines, including seismic and medical imaging,
computational fluid dynamics, image processing, and neural networks. Solving
these PDEs on a large scale is an intricate and time-intensive process that
demands careful tuning. This paper introduces automated code-generation
techniques specifically tailored for distributed memory parallelism (DMP) to
solve explicit finite-difference (FD) stencils at scale, a fundamental
challenge in numerous scientific applications. These techniques are implemented
and integrated into the Devito DSL and compiler framework, a well-established
solution for automating the generation of FD solvers based on a high-level
symbolic math input. Users benefit from modelling simulations at a high-level
symbolic abstraction and effortlessly harnessing HPC-ready distributed-memory
parallelism without altering their source code. This results in drastic
reductions both in execution time and developer effort. While the contributions
of this work are implemented and integrated within the Devito framework, the
DMP concepts and the techniques applied are generally applicable to any FD
solvers. A comprehensive performance evaluation of Devito's DMP via MPI
demonstrates highly competitive weak and strong scaling on the Archer2
supercomputer, demonstrating the effectiveness of the proposed approach in
meeting the demands of large-scale scientific simulations.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13096" title="Abstract">arXiv:2312.13096</a> [<a href="/pdf/2312.13096" title="Download PDF">pdf</a>, <a href="/ps/2312.13096" title="Download PostScript">ps</a>, <a href="/format/2312.13096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In Generative AI we Trust: Can Chatbots Effectively Verify Political  Information?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuznetsova%2C+E">Elizaveta Kuznetsova</a>, 
<a href="/search/cs?searchtype=author&query=Makhortykh%2C+M">Mykola Makhortykh</a>, 
<a href="/search/cs?searchtype=author&query=Vziatysheva%2C+V">Victoria Vziatysheva</a>, 
<a href="/search/cs?searchtype=author&query=Stolze%2C+M">Martha Stolze</a>, 
<a href="/search/cs?searchtype=author&query=Baghumyan%2C+A">Ani Baghumyan</a>, 
<a href="/search/cs?searchtype=author&query=Urman%2C+A">Aleksandra Urman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">This article presents a comparative analysis of the ability of two large
language model (LLM)-based chatbots, ChatGPT and Bing Chat, recently rebranded
to Microsoft Copilot, to detect veracity of political information. We use AI
auditing methodology to investigate how chatbots evaluate true, false, and
borderline statements on five topics: COVID-19, Russian aggression against
Ukraine, the Holocaust, climate change, and LGBTQ+ related debates. We compare
how the chatbots perform in high- and low-resource languages by using prompts
in English, Russian, and Ukrainian. Furthermore, we explore the ability of
chatbots to evaluate statements according to political communication concepts
of disinformation, misinformation, and conspiracy theory, using
definition-oriented prompts. We also systematically test how such evaluations
are influenced by source bias which we model by attributing specific claims to
various political and social actors. The results show high performance of
ChatGPT for the baseline veracity evaluation task, with 72 percent of the cases
evaluated correctly on average across languages without pre-training. Bing Chat
performed worse with a 67 percent accuracy. We observe significant disparities
in how chatbots evaluate prompts in high- and low-resource languages and how
they adapt their evaluations to political communication concepts with ChatGPT
providing more nuanced outputs than Bing Chat. Finally, we find that for some
veracity detection-related tasks, the performance of chatbots varied depending
on the topic of the statement or the source to which it is attributed. These
findings highlight the potential of LLM-based chatbots in tackling different
forms of false information in online environments, but also points to the
substantial variation in terms of how such potential is realized due to
specific factors, such as language of the prompt or the topic.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13100" title="Abstract">arXiv:2312.13100</a> [<a href="/pdf/2312.13100" title="Download PDF">pdf</a>, <a href="/format/2312.13100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEER-ZSL: Semantic Encoder-Enhanced Representations for Generalized  Zero-Shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heyden%2C+W">William Heyden</a>, 
<a href="/search/cs?searchtype=author&query=Ullah%2C+H">Habib Ullah</a>, 
<a href="/search/cs?searchtype=author&query=Siddiqui%2C+M+S">M. Salman Siddiqui</a>, 
<a href="/search/cs?searchtype=author&query=Machot%2C+F+A">Fadi Al Machot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generalized Zero-Shot Learning (GZSL) recognizes unseen classes by
transferring knowledge from the seen classes, depending on the inherent
interactions between visual and semantic data. However, the discrepancy between
well-prepared training data and unpredictable real-world test scenarios remains
a significant challenge. This paper introduces a dual strategy to address the
generalization gap. Firstly, we incorporate semantic information through an
innovative encoder. This encoder effectively integrates class-specific semantic
information by targeting the performance disparity, enhancing the produced
features to enrich the semantic space for class-specific attributes. Secondly,
we refine our generative capabilities using a novel compositional loss
function. This approach generates discriminative classes, effectively
classifying both seen and unseen classes. In addition, we extend the
exploitation of the learned latent space by utilizing controlled semantic
inputs, ensuring the robustness of the model in varying environments. This
approach yields a model that outperforms the state-of-the-art models in terms
of both generalization and diverse settings, notably without requiring
hyperparameter tuning or domain-specific adaptations. We also propose a set of
novel evaluation metrics to provide a more detailed assessment of the
reliability and reproducibility of the results. The complete code is made
available on https://github.com/william-heyden/SEER-ZeroShotLearning/.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13102" title="Abstract">arXiv:2312.13102</a> [<a href="/pdf/2312.13102" title="Download PDF">pdf</a>, <a href="/format/2312.13102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpecNeRF: Gaussian Directional Encoding for Specular Reflections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Li Ma</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+V">Vasu Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Turki%2C+H">Haithem Turki</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Changil Kim</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chen Gao</a>, 
<a href="/search/cs?searchtype=author&query=Sander%2C+P">Pedro Sander</a>, 
<a href="/search/cs?searchtype=author&query=Zollh%C3%B6fer%2C+M">Michael Zollh&#xf6;fer</a>, 
<a href="/search/cs?searchtype=author&query=Richardt%2C+C">Christian Richardt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://limacv.github.io/SpecNeRF_web/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural radiance fields have achieved remarkable performance in modeling the
appearance of 3D scenes. However, existing approaches still struggle with the
view-dependent appearance of glossy surfaces, especially under complex lighting
of indoor environments. Unlike existing methods, which typically assume distant
lighting like an environment map, we propose a learnable Gaussian directional
encoding to better model the view-dependent effects under near-field lighting
conditions. Importantly, our new directional encoding captures the
spatially-varying nature of near-field lighting and emulates the behavior of
prefiltered environment maps. As a result, it enables the efficient evaluation
of preconvolved specular color at any 3D location with varying roughness
coefficients. We further introduce a data-driven geometry prior that helps
alleviate the shape radiance ambiguity in reflection modeling. We show that our
Gaussian directional encoding and geometry prior significantly improve the
modeling of challenging specular reflections in neural radiance fields, which
helps decompose appearance into more physically meaningful components.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13103" title="Abstract">arXiv:2312.13103</a> [<a href="/pdf/2312.13103" title="Download PDF">pdf</a>, <a href="/ps/2312.13103" title="Download PostScript">ps</a>, <a href="/format/2312.13103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Multimodal Large Language Models for Radiology Report  Error-checking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jinge Wu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yunsoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Keller%2C+E+C">Eva C. Keller</a>, 
<a href="/search/cs?searchtype=author&query=Chow%2C+J">Jamie Chow</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+A+P">Adam P. Levine</a>, 
<a href="/search/cs?searchtype=author&query=Pontikos%2C+N">Nikolas Pontikos</a>, 
<a href="/search/cs?searchtype=author&query=Ibrahim%2C+Z">Zina Ibrahim</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+P">Paul Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+M+C">Michelle C. Williams</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Honghan Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper proposes one of the first clinical applications of multimodal
large language models (LLMs) as an assistant for radiologists to check errors
in their reports. We created an evaluation dataset from two real-world
radiology datasets (MIMIC-CXR and IU-Xray), with 1,000 subsampled reports each.
A subset of original reports was modified to contain synthetic errors by
introducing various type of mistakes. The evaluation contained two difficulty
levels: SIMPLE for binary error-checking and COMPLEX for identifying error
types. LLaVA (Large Language and Visual Assistant) variant models, including
our instruction-tuned model, were used for the evaluation. Additionally, a
domain expert evaluation was conducted on a small test set. At the SIMPLE
level, the LLaVA v1.5 model outperformed other publicly available models.
Instruction tuning significantly enhanced performance by 47.4% and 25.4% on
MIMIC-CXR and IU-Xray data, respectively. The model also surpassed the domain
experts accuracy in the MIMIC-CXR dataset by 1.67%. Notably, among the subsets
(N=21) of the test set where a clinician did not achieve the correct
conclusion, the LLaVA ensemble mode correctly identified 71.4% of these cases.
This study marks a promising step toward utilizing multi-modal LLMs to enhance
diagnostic accuracy in radiology. The ensemble model demonstrated comparable
performance to clinicians, even capturing errors overlooked by humans.
Nevertheless, future work is needed to improve the model ability to identify
the types of inconsistency.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13104" title="Abstract">arXiv:2312.13104</a> [<a href="/pdf/2312.13104" title="Download PDF">pdf</a>, <a href="/format/2312.13104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Ego Vehicle Trajectory Prediction: The Graph Enhancement  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+S">Sushil Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Aryan Singh</a>, 
<a href="/search/cs?searchtype=author&query=Sistu%2C+G">Ganesh Sistu</a>, 
<a href="/search/cs?searchtype=author&query=Halton%2C+M">Mark Halton</a>, 
<a href="/search/cs?searchtype=author&query=Eising%2C+C">Ciar&#xe1;n Eising</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the Electronic Imagine Autonomous Vehicles and Machines (EI-AVM) Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Predicting the trajectory of an ego vehicle is a critical component of
autonomous driving systems. Current state-of-the-art methods typically rely on
Deep Neural Networks (DNNs) and sequential models to process front-view images
for future trajectory prediction. However, these approaches often struggle with
perspective issues affecting object features in the scene. To address this, we
advocate for the use of Bird's Eye View (BEV) perspectives, which offer unique
advantages in capturing spatial relationships and object homogeneity. In our
work, we leverage Graph Neural Networks (GNNs) and positional encoding to
represent objects in a BEV, achieving competitive performance compared to
traditional DNN-based methods. While the BEV-based approach loses some detailed
information inherent to front-view images, we balance this by enriching the BEV
data by representing it as a graph where relationships between the objects in a
scene are captured effectively.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13105" title="Abstract">arXiv:2312.13105</a> [<a href="/pdf/2312.13105" title="Download PDF">pdf</a>, <a href="/format/2312.13105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring ChatGPT for Toxicity Detection in GitHub
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Shyamal Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+P">Preetha Chatterjee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Fostering a collaborative and inclusive environment is crucial for the
sustained progress of open source development. However, the prevalence of
negative discourse, often manifested as toxic comments, poses significant
challenges to developer well-being and productivity. To identify such
negativity in project communications, especially within large projects,
automated toxicity detection models are necessary. To train these models
effectively, we need large software engineering-specific toxicity datasets.
However, such datasets are limited in availability and often exhibit imbalance
(e.g., only 6 in 1000 GitHub issues are toxic), posing challenges for training
effective toxicity detection models. To address this problem, we explore a
zero-shot LLM (ChatGPT) that is pre-trained on massive datasets but without
being fine-tuned specifically for the task of detecting toxicity in
software-related text. Our preliminary evaluation indicates that ChatGPT shows
promise in detecting toxicity in GitHub, and warrants further investigation. We
experimented with various prompts, including those designed for justifying
model outputs, thereby enhancing model interpretability and paving the way for
potential integration of ChatGPT-enabled toxicity detection into developer
communication channels.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13107" title="Abstract">arXiv:2312.13107</a> [<a href="/pdf/2312.13107" title="Download PDF">pdf</a>, <a href="/format/2312.13107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quick Order Fairness: Implementation and Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cachin%2C+C">Christian Cachin</a>, 
<a href="/search/cs?searchtype=author&query=Micic%2C+J">Jovana Micic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Decentralized finance revolutionizes traditional financial systems by
leveraging blockchain technology to reduce trust. However, some vulnerabilities
persist, notably front-running by malicious actors who exploit transaction
information to gain financial advantage. Consensus with a fair order aims at
preventing such attacks, and in particular, the differential order fairness
property addresses this problem and connects fair ordering to the validity of
consensus. The notion is implemented by the Quick Order-Fair Atomic Broadcast
(QOF) protocol (Cachin et al., FC '22). This paper revisits the QOF protocol
and describes a modular implementation that uses a generic consensus component.
Moreover, an empirical evaluation is performed to compare the performance of
QOF to a consensus protocol without fairness. Measurements show that the
increased complexity comes at a cost, throughput decreases by at most 5%, and
latency increases by roughly 50ms, using an emulated ideal network. This paper
contributes to a comprehensive understanding of practical aspects regarding
differential order fairness with the QOF protocol and also connects this with
similar fairness-imposing protocols like Themis and Pompe.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13108" title="Abstract">arXiv:2312.13108</a> [<a href="/pdf/2312.13108" title="Download PDF">pdf</a>, <a href="/format/2312.13108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ASSISTGUI: Task-Oriented Desktop Graphical User Interface Automation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+D">Difei Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+L">Lei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Z">Zechen Bai</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+M">Mingyu Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peiran Li</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+D">Dongxing Mao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qinchen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weichen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peiyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiangwu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hengxu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Luowei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Graphical User Interface (GUI) automation holds significant promise for
assisting users with complex tasks, thereby boosting human productivity.
Existing works leveraging Large Language Model (LLM) or LLM-based AI agents
have shown capabilities in automating tasks on Android and Web platforms.
However, these tasks are primarily aimed at simple device usage and
entertainment operations. This paper presents a novel benchmark, AssistGUI, to
evaluate whether models are capable of manipulating the mouse and keyboard on
the Windows platform in response to user-requested tasks. We carefully
collected a set of 100 tasks from nine widely-used software applications, such
as, After Effects and MS Word, each accompanied by the necessary project files
for better evaluation. Moreover, we propose an advanced Actor-Critic Embodied
Agent framework, which incorporates a sophisticated GUI parser driven by an
LLM-agent and an enhanced reasoning mechanism adept at handling lengthy
procedural tasks. Our experimental results reveal that our GUI Parser and
Reasoning mechanism outshine existing methods in performance. Nevertheless, the
potential remains substantial, with the best model attaining only a 46% success
rate on our benchmark. We conclude with a thorough analysis of the current
methods' limitations, setting the stage for future breakthroughs in this
domain.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13110" title="Abstract">arXiv:2312.13110</a> [<a href="/pdf/2312.13110" title="Download PDF">pdf</a>, <a href="/ps/2312.13110" title="Download PostScript">ps</a>, <a href="/format/2312.13110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-training of Molecular GNNs as Conditional Boltzmann Generator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koge%2C+D">Daiki Koge</a>, 
<a href="/search/cs?searchtype=author&query=Ono%2C+N">Naoaki Ono</a>, 
<a href="/search/cs?searchtype=author&query=Kanaya%2C+S">Shigehiko Kanaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages. Short paper submitted to AAAI workshop (AI2ASE) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Chemical Physics (physics.chem-ph); Biomolecules (q-bio.BM)

</div>
<p class="mathjax">Learning representations of molecular structures using deep learning is a
fundamental problem in molecular property prediction tasks. Molecules
inherently exist in the real world as three-dimensional structures;
furthermore, they are not static but in continuous motion in the 3D Euclidean
space, forming a potential energy surface. Therefore, it is desirable to
generate multiple conformations in advance and extract molecular
representations using a 4D-QSAR model that incorporates multiple conformations.
However, this approach is impractical for drug and material discovery tasks
because of the computational cost of obtaining multiple conformations. To
address this issue, we propose a pre-training method for molecular GNNs using
an existing dataset of molecular conformations to generate a latent vector
universal to multiple conformations from a 2D molecular graph. Our method,
called Boltzmann GNN, is formulated by maximizing the conditional marginal
likelihood of a conditional generative model for conformations generation. We
show that our model has a better prediction performance for molecular
properties than existing pre-training methods using molecular graphs and
three-dimensional molecular structures.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13114" title="Abstract">arXiv:2312.13114</a> [<a href="/pdf/2312.13114" title="Download PDF">pdf</a>, <a href="/format/2312.13114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Color Illusions from the Perspective of Computational  Color Constancy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ulucan%2C+O">Oguzhan Ulucan</a>, 
<a href="/search/cs?searchtype=author&query=Ulucan%2C+D">Diclehan Ulucan</a>, 
<a href="/search/cs?searchtype=author&query=Ebner%2C+M">Marc Ebner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is accepted at VISAPP 2024 as a long paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Color constancy and color illusion perception are two phenomena occurring in
the human visual system, which can help us reveal unknown mechanisms of human
perception. For decades computer vision scientists have developed numerous
color constancy methods, which estimate the reflectance of the surface by
discounting the illuminant. However, color illusions have not been analyzed in
detail in the field of computational color constancy, which we find surprising
since the relationship they share is significant and may let us design more
robust systems. We argue that any model that can reproduce our sensation on
color illusions should also be able to provide pixel-wise estimates of the
light source. In other words, we suggest that the analysis of color illusions
helps us to improve the performance of the existing global color constancy
methods, and enable them to provide pixel-wise estimates for scenes illuminated
by multiple light sources. In this study, we share the outcomes of our
investigation in which we take several color constancy methods and modify them
to reproduce the behavior of the human visual system on color illusions. Also,
we show that parameters purely extracted from illusions are able to improve the
performance of color constancy methods. A noteworthy outcome is that our
strategy based on the investigation of color illusions outperforms the
state-of-the-art methods that are specifically designed to transform global
color constancy algorithms into multi-illuminant algorithms.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13115" title="Abstract">arXiv:2312.13115</a> [<a href="/pdf/2312.13115" title="Download PDF">pdf</a>, <a href="/ps/2312.13115" title="Download PostScript">ps</a>, <a href="/format/2312.13115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Approach for RapidDevelopment Based on ChatGPT and Prompt  Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Youjia Li</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jianjun Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Code generation stands as a powerful technique in modern software
development, improving development efficiency, reducing errors, and fostering
standardization and consistency. Recently, ChatGPT has exhibited immense
potential in automatic code generation. However, existing researches on code
generation lack guidance for practical software development process. In this
study, we utilized ChatGPT to develop a web-based code generation platform
consisting of key components: User Interface, Prompt Builder and Backend
Service. Specifically, Prompt Builder dynamically generated comprehensive
prompts to enhance model generation performance. We conducted experiments on 2
datasets, evaluating the generated code through 8 widely used metrics.The
results demonstrate that (1) Our Prompt Builder is effective, resulting in a
65.06% improvement in EM, a 38.45% improvement in BLEU, a 15.70% improvement in
CodeBLEU, and a 50.64% improvement in Pass@1. (2) In real development
scenarios, 98.5% of test cases can be validated through manual validation,
highlighting the genuine assistance provided by the ChatGPT-based code
generation approach.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13116" title="Abstract">arXiv:2312.13116</a> [<a href="/pdf/2312.13116" title="Download PDF">pdf</a>, <a href="/format/2312.13116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VSR-Net: Vessel-like Structure Rehabilitation Network with Graph  Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Haili Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Huazhu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The morphologies of vessel-like structures, such as blood vessels and nerve
fibres, play significant roles in disease diagnosis, e.g., Parkinson's disease.
Deep network-based refinement segmentation methods have recently achieved
promising vessel-like structure segmentation results. There are still two
challenges: (1) existing methods have limitations in rehabilitating subsection
ruptures in segmented vessel-like structures; (2) they are often overconfident
in predicted segmentation results. To tackle these two challenges, this paper
attempts to leverage the potential of spatial interconnection relationships
among subsection ruptures from the structure rehabilitation perspective. Based
on this, we propose a novel Vessel-like Structure Rehabilitation Network
(VSR-Net) to rehabilitate subsection ruptures and improve the model calibration
based on coarse vessel-like structure segmentation results. VSR-Net first
constructs subsection rupture clusters with Curvilinear Clustering Module
(CCM). Then, the well-designed Curvilinear Merging Module (CMM) is applied to
rehabilitate the subsection ruptures to obtain the refined vessel-like
structures. Extensive experiments on five 2D/3D medical image datasets show
that VSR-Net significantly outperforms state-of-the-art (SOTA) refinement
segmentation methods with lower calibration error. Additionally, we provide
quantitative analysis to explain the morphological difference between the
rehabilitation results of VSR-Net and ground truth (GT), which is smaller than
SOTA methods and GT, demonstrating that our method better rehabilitates
vessel-like structures by restoring subsection ruptures.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13117" title="Abstract">arXiv:2312.13117</a> [<a href="/pdf/2312.13117" title="Download PDF">pdf</a>, <a href="/ps/2312.13117" title="Download PostScript">ps</a>, <a href="/format/2312.13117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallel Multi-step Spectral Indicator Method for Nonlinear Eigenvalue  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Xi%2C+Y">Yingxia Xi</a>, 
<a href="/search/math?searchtype=author&query=Sun%2C+J">Jiguang Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Consider nonlinear eigenvalue problems to compute all eigenvalues in a given
region on the complex plane. We propose a parallel multi-step spectral
indicator method with the contour integrals being the main ingredient. Step 1
(screening) divides the given region into subregion and compute an indicator
for each subregion. Then it decides candidate regions that contain eigenvalues.
Step 2 (computation) computes eigenvalues in each candidate region. Step 3
(validation) double checks each eigenvalue by substituting it back to the
system and computing the smallest eigenvalue. Each step is carried out in
parallel. Two examples are presented for demonstration.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13118" title="Abstract">arXiv:2312.13118</a> [<a href="/pdf/2312.13118" title="Download PDF">pdf</a>, <a href="/format/2312.13118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LRS: Enhancing Adversarial Transferability through Lipschitz Regularized  Surrogate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+T">Tie Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wunsch%2C+D+C">Donald C. Wunsch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The transferability of adversarial examples is of central importance to
transfer-based black-box adversarial attacks. Previous works for generating
transferable adversarial examples focus on attacking \emph{given} pretrained
surrogate models while the connections between surrogate models and adversarial
trasferability have been overlooked. In this paper, we propose {\em Lipschitz
Regularized Surrogate} (LRS) for transfer-based black-box attacks, a novel
approach that transforms surrogate models towards favorable adversarial
transferability. Using such transformed surrogate models, any existing
transfer-based black-box attack can run without any change, yet achieving much
better performance. Specifically, we impose Lipschitz regularization on the
loss landscape of surrogate models to enable a smoother and more controlled
optimization process for generating more transferable adversarial examples. In
addition, this paper also sheds light on the connection between the inner
properties of surrogate models and adversarial transferability, where three
factors are identified: smaller local Lipschitz constant, smoother loss
landscape, and stronger adversarial robustness. We evaluate our proposed LRS
approach by attacking state-of-the-art standard deep neural networks and
defense models. The results demonstrate significant improvement on the attack
success rates and transferability. Our code is available at
https://github.com/TrustAIoT/LRS.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13119" title="Abstract">arXiv:2312.13119</a> [<a href="/pdf/2312.13119" title="Download PDF">pdf</a>, <a href="/format/2312.13119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prometheus: Infrastructure Security Posture Analysis with AI-generated  Attack Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Katsis%2C+C">Charalampos Katsis</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+F">Fan Sang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiahao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Bertino%2C+E">Elisa Bertino</a>, 
<a href="/search/cs?searchtype=author&query=Kompella%2C+R+R">Ramana Rao Kompella</a>, 
<a href="/search/cs?searchtype=author&query=Kundu%2C+A">Ashish Kundu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">The rampant occurrence of cybersecurity breaches imposes substantial
limitations on the progress of network infrastructures, leading to compromised
data, financial losses, potential harm to individuals, and disruptions in
essential services. The current security landscape demands the urgent
development of a holistic security assessment solution that encompasses
vulnerability analysis and investigates the potential exploitation of these
vulnerabilities as attack paths. In this paper, we propose Prometheus, an
advanced system designed to provide a detailed analysis of the security posture
of computing infrastructures. Using user-provided information, such as device
details and software versions, Prometheus performs a comprehensive security
assessment. This assessment includes identifying associated vulnerabilities and
constructing potential attack graphs that adversaries can exploit. Furthermore,
Prometheus evaluates the exploitability of these attack paths and quantifies
the overall security posture through a scoring mechanism. The system takes a
holistic approach by analyzing security layers encompassing hardware, system,
network, and cryptography. Furthermore, Prometheus delves into the
interconnections between these layers, exploring how vulnerabilities in one
layer can be leveraged to exploit vulnerabilities in others. In this paper, we
present the end-to-end pipeline implemented in Prometheus, showcasing the
systematic approach adopted for conducting this thorough security analysis.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13126" title="Abstract">arXiv:2312.13126</a> [<a href="/pdf/2312.13126" title="Download PDF">pdf</a>, <a href="/ps/2312.13126" title="Download PostScript">ps</a>, <a href="/format/2312.13126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative agents in the streets: Exploring the use of Large Language  Models (LLMs) in collecting urban perceptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verma%2C+D">Deepank Verma</a>, 
<a href="/search/cs?searchtype=author&query=Mumm%2C+O">Olaf Mumm</a>, 
<a href="/search/cs?searchtype=author&query=Carlow%2C+V+M">Vanessa Miriam Carlow</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 Pages, 15 Figures, Submitted in a Journal for Peer review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Evaluating the surroundings to gain understanding, frame perspectives, and
anticipate behavioral reactions is an inherent human trait. However, these
continuous encounters are diverse and complex, posing challenges to their study
and experimentation. Researchers have been able to isolate environmental
features and study their effect on human perception and behavior. However, the
research attempts to replicate and study human behaviors with proxies, such as
by integrating virtual mediums and interviews, have been inconsistent. Large
language models (LLMs) have recently been unveiled as capable of contextual
understanding and semantic reasoning. These models have been trained on large
amounts of text and have evolved to mimic believable human behavior. This study
explores the current advancements in Generative agents powered by LLMs with the
help of perceptual experiments. The experiment employs Generative agents to
interact with the urban environments using street view images to plan their
journey toward specific goals. The agents are given virtual personalities,
which make them distinguishable. They are also provided a memory database to
store their thoughts and essential visual information and retrieve it when
needed to plan their movement. Since LLMs do not possess embodiment, nor have
access to the visual realm, and lack a sense of motion or direction, we
designed movement and visual modules that help agents gain an overall
understanding of surroundings. The agents are further employed to rate the
surroundings they encounter based on their perceived sense of safety and
liveliness. As these agents store details in their memory, we query the
findings to get details regarding their thought processes. Overall, this study
experiments with current AI developments and their potential in simulated human
behavior in urban environments.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13131" title="Abstract">arXiv:2312.13131</a> [<a href="/pdf/2312.13131" title="Download PDF">pdf</a>, <a href="/format/2312.13131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Compute Is Not All You Need for Adversarial Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Debenedetti%2C+E">Edoardo Debenedetti</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Zishen Wan</a>, 
<a href="/search/cs?searchtype=author&query=Andriushchenko%2C+M">Maksym Andriushchenko</a>, 
<a href="/search/cs?searchtype=author&query=Sehwag%2C+V">Vikash Sehwag</a>, 
<a href="/search/cs?searchtype=author&query=Bhardwaj%2C+K">Kshitij Bhardwaj</a>, 
<a href="/search/cs?searchtype=author&query=Kailkhura%2C+B">Bhavya Kailkhura</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The last six years have witnessed significant progress in adversarially
robust deep learning. As evidenced by the CIFAR-10 dataset category in
RobustBench benchmark, the accuracy under $\ell_\infty$ adversarial
perturbations improved from 44\% in \citet{Madry2018Towards} to 71\% in
\citet{peng2023robust}. Although impressive, existing state-of-the-art is still
far from satisfactory. It is further observed that best-performing models are
often very large models adversarially trained by industrial labs with
significant computational budgets. In this paper, we aim to understand: ``how
much longer can computing power drive adversarial robustness advances?" To
answer this question, we derive \emph{scaling laws for adversarial robustness}
which can be extrapolated in the future to provide an estimate of how much cost
we would need to pay to reach a desired level of robustness. We show that
increasing the FLOPs needed for adversarial training does not bring as much
advantage as it does for standard training in terms of performance
improvements. Moreover, we find that some of the top-performing techniques are
difficult to exactly reproduce, suggesting that they are not robust enough for
minor changes in the training setup. Our analysis also uncovers potentially
worthwhile directions to pursue in future research. Finally, we make our
benchmarking framework (built on top of \texttt{timm}~\citep{rw2019timm})
publicly available to facilitate future analysis in efficient robust deep
learning.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13132" title="Abstract">arXiv:2312.13132</a> [<a href="/pdf/2312.13132" title="Download PDF">pdf</a>, <a href="/format/2312.13132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the complexity of sabotage games for network security
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raju%2C+D">Dhananjay Raju</a>, 
<a href="/search/cs?searchtype=author&query=Bakirtzis%2C+G">Georgios Bakirtzis</a>, 
<a href="/search/cs?searchtype=author&query=Topcu%2C+U">Ufuk Topcu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Securing dynamic networks against adversarial actions is challenging because
of the need to anticipate and counter strategic disruptions by adversarial
entities within complex network structures. Traditional game-theoretic models,
while insightful, often fail to model the unpredictability and constraints of
real-world threat assessment scenarios. We refine sabotage games to reflect the
realistic limitations of the saboteur and the network operator. By transforming
sabotage games into reachability problems, our approach allows applying
existing computational solutions to model realistic restrictions on attackers
and defenders within the game. Modifying sabotage games into dynamic network
security problems successfully captures the nuanced interplay of strategy and
uncertainty in dynamic network security. Theoretically, we extend sabotage
games to model network security contexts and thoroughly explore if the
additional restrictions raise their computational complexity, often the
bottleneck of game theory in practical contexts. Practically, this research
sets the stage for actionable insights for developing robust defense mechanisms
by understanding what risks to mitigate in dynamically changing networks under
threat.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13139" title="Abstract">arXiv:2312.13139</a> [<a href="/pdf/2312.13139" title="Download PDF">pdf</a>, <a href="/format/2312.13139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unleashing Large-Scale Video Generative Pre-training for Visual Robot  Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hongtao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+Y">Ya Jing</a>, 
<a href="/search/cs?searchtype=author&query=Cheang%2C+C">Chilam Cheang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guangzeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiafeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinghang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Minghuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hang Li</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+T">Tao Kong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://GR1-Manipulation.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Generative pre-trained models have demonstrated remarkable effectiveness in
language and vision domains by learning useful representations. In this paper,
we extend the scope of this effectiveness by showing that visual robot
manipulation can significantly benefit from large-scale video generative
pre-training. We introduce GR-1, a straightforward GPT-style model designed for
multi-task language-conditioned visual robot manipulation. GR-1 takes as inputs
a language instruction, a sequence of observation images, and a sequence of
robot states. It predicts robot actions as well as future images in an
end-to-end manner. Thanks to a flexible design, GR-1 can be seamlessly
finetuned on robot data after pre-trained on a large-scale video dataset. We
perform extensive experiments on the challenging CALVIN benchmark and a real
robot. On CALVIN benchmark, our method outperforms state-of-the-art baseline
methods and improves the success rate from 88.9% to 94.9%. In the setting of
zero-shot unseen scene generalization, GR-1 improves the success rate from
53.3% to 85.4%. In real robot experiments, GR-1 also outperforms baseline
methods and shows strong potentials in generalization to unseen scenes and
objects. We provide inaugural evidence that a unified GPT-style transformer,
augmented with large-scale video generative pre-training, exhibits remarkable
generalization to multi-task visual robot manipulation. Project page:
https://GR1-Manipulation.github.io
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13141" title="Abstract">arXiv:2312.13141</a> [<a href="/pdf/2312.13141" title="Download PDF">pdf</a>, <a href="/format/2312.13141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augment on Manifold: Mixup Regularization with UMAP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=El-Laham%2C+Y">Yousef El-Laham</a>, 
<a href="/search/cs?searchtype=author&query=Fons%2C+E">Elizabeth Fons</a>, 
<a href="/search/cs?searchtype=author&query=Daudert%2C+D">Dillon Daudert</a>, 
<a href="/search/cs?searchtype=author&query=Vyetrenko%2C+S">Svitlana Vyetrenko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Data augmentation techniques play an important role in enhancing the
performance of deep learning models. Despite their proven benefits in computer
vision tasks, their application in the other domains remains limited. This
paper proposes a Mixup regularization scheme, referred to as UMAP Mixup,
designed for "on-manifold" automated data augmentation for deep learning
predictive models. The proposed approach ensures that the Mixup operations
result in synthesized samples that lie on the data manifold of the features and
labels by utilizing a dimensionality reduction technique known as uniform
manifold approximation and projection. Evaluations across diverse regression
tasks show that UMAP Mixup is competitive with or outperforms other Mixup
variants, show promise for its potential as an effective tool for enhancing the
generalization performance of deep learning models.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13143" title="Abstract">arXiv:2312.13143</a> [<a href="/pdf/2312.13143" title="Download PDF">pdf</a>, <a href="/format/2312.13143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Underwater Acoustic Signal Recognition Based on Salient Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Minghao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">With the rapid advancement of technology, the recognition of underwater
acoustic signals in complex environments has become increasingly crucial.
Currently, mainstream underwater acoustic signal recognition relies primarily
on time-frequency analysis to extract spectral features, finding widespread
applications in the field. However, existing recognition methods heavily depend
on expert systems, facing limitations such as restricted knowledge bases and
challenges in handling complex relationships. These limitations stem from the
complexity and maintenance difficulties associated with rules or inference
engines. Recognizing the potential advantages of deep learning in handling
intricate relationships, this paper proposes a method utilizing neural networks
for underwater acoustic signal recognition. The proposed approach involves
continual learning of features extracted from spectra for the classification of
underwater acoustic signals. Deep learning models can automatically learn
abstract features from data and continually adjust weights during training to
enhance classification performance.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13146" title="Abstract">arXiv:2312.13146</a> [<a href="/pdf/2312.13146" title="Download PDF">pdf</a>, <a href="/format/2312.13146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FLASH-TB: Integrating Arc-Flags and Trip-Based Public Transit Routing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gro%C3%9Fmann%2C+E">Ernestine Gro&#xdf;mann</a>, 
<a href="/search/cs?searchtype=author&query=Sauer%2C+J">Jonas Sauer</a>, 
<a href="/search/cs?searchtype=author&query=Schulz%2C+C">Christian Schulz</a>, 
<a href="/search/cs?searchtype=author&query=Steil%2C+P">Patrick Steil</a>, 
<a href="/search/cs?searchtype=author&query=Witt%2C+S">Sascha Witt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2302.07168">arXiv:2302.07168</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We present FLASH-TB, a journey planning algorithm for public transit networks
that combines Trip-Based Public Transit Routing (TB) with the Arc-Flags speedup
technique. The basic idea is simple: The network is partitioned into a
configurable number of cells. For each cell and each possible transfer between
two vehicles, the algorithm precomputes a flag that indicates whether the
transfer is required to reach the cell. During a query, only flagged transfers
are explored. Our algorithm improves upon previous attempts to apply Arc-Flags
to public transit networks, which saw limited success due to conflicting rules
for pruning the search space. We show that these rules can be reconciled while
still producing correct results. Because the number of cells is configurable,
FLASH-TB offers a tradeoff between query time and memory consumption. It is
significantly more space-efficient than existing techniques with a comparable
preprocessing time, which store generalized shortest-path trees: to match their
query performance, it requires up to two orders of magnitude less memory. The
fastest configuration of FLASH-TB achieves a speedup of more than two orders of
magnitude over TB, offering sub-millisecond query times even on large
countrywide networks.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13150" title="Abstract">arXiv:2312.13150</a> [<a href="/pdf/2312.13150" title="Download PDF">pdf</a>, <a href="/format/2312.13150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Splatter Image: Ultra-Fast Single-View 3D Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Szymanowicz%2C+S">Stanislaw Szymanowicz</a>, 
<a href="/search/cs?searchtype=author&query=Rupprecht%2C+C">Christian Rupprecht</a>, 
<a href="/search/cs?searchtype=author&query=Vedaldi%2C+A">Andrea Vedaldi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://szymanowiczs.github.io/splatter-image.html">this https URL</a> . Code: <a href="https://github.com/szymanowiczs/splatter-image">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce the Splatter Image, an ultra-fast approach for monocular 3D
object reconstruction which operates at 38 FPS. Splatter Image is based on
Gaussian Splatting, which has recently brought real-time rendering, fast
training, and excellent scaling to multi-view reconstruction. For the first
time, we apply Gaussian Splatting in a monocular reconstruction setting. Our
approach is learning-based, and, at test time, reconstruction only requires the
feed-forward evaluation of a neural network. The main innovation of Splatter
Image is the surprisingly straightforward design: it uses a 2D image-to-image
network to map the input image to one 3D Gaussian per pixel. The resulting
Gaussians thus have the form of an image, the Splatter Image. We further extend
the method to incorporate more than one image as input, which we do by adding
cross-view attention. Owning to the speed of the renderer (588 FPS), we can use
a single GPU for training while generating entire images at each iteration in
order to optimize perceptual metrics like LPIPS. On standard benchmarks, we
demonstrate not only fast reconstruction but also better results than recent
and much more expensive baselines in terms of PSNR, LPIPS, and other metrics.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13151" title="Abstract">arXiv:2312.13151</a> [<a href="/pdf/2312.13151" title="Download PDF">pdf</a>, <a href="/format/2312.13151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tuning the activation function to optimize the forecast horizon of a  reservoir computer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hurley%2C+L+A">Lauren A. Hurley</a>, 
<a href="/search/cs?searchtype=author&query=Restrepo%2C+J+G">Juan G. Restrepo</a>, 
<a href="/search/cs?searchtype=author&query=Shaheen%2C+S+E">Sean E. Shaheen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures, submitted to Journal of Physics Complexity
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Reservoir computing is a machine learning framework where the readouts from a
nonlinear system (the reservoir) are trained so that the output from the
reservoir, when forced with an input signal, reproduces a desired output
signal. A common implementation of reservoir computers is to use a recurrent
neural network as the reservoir. The design of this network can have
significant effects on the performance of the reservoir computer. In this paper
we study the effect of the node activation function on the ability of reservoir
computers to learn and predict chaotic time series. We find that the Forecast
Horizon (FH), the time during which the reservoir's predictions remain
accurate, can vary by an order of magnitude across a set of 16 activation
functions used in machine learning. By using different functions from this set,
and by modifying their parameters, we explore whether the entropy of node
activation levels or the curvature of the activation functions determine the
predictive ability of the reservoirs. We find that the FH is low when the
activation function is used in a region where it has low curvature, and a
positive correlation between curvature and FH. For the activation functions
studied we find that the largest FH generally occurs at intermediate levels of
the entropy of node activation levels. Our results show that the performance of
reservoir computers is very sensitive to the activation function shape.
Therefore, modifying this shape in hyperparameter optimization algorithms can
lead to improvements in reservoir computer performance.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13152" title="Abstract">arXiv:2312.13152</a> [<a href="/pdf/2312.13152" title="Download PDF">pdf</a>, <a href="/format/2312.13152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Stochastic Differential Equations with Change Points: A  Generative Adversarial Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhongchang Sun</a>, 
<a href="/search/cs?searchtype=author&query=El-Laham%2C+Y">Yousef El-Laham</a>, 
<a href="/search/cs?searchtype=author&query=Vyetrenko%2C+S">Svitlana Vyetrenko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Stochastic differential equations (SDEs) have been widely used to model real
world random phenomena. Existing works mainly focus on the case where the time
series is modeled by a single SDE, which might be restrictive for modeling time
series with distributional shift. In this work, we propose a change point
detection algorithm for time series modeled as neural SDEs. Given a time series
dataset, the proposed method jointly learns the unknown change points and the
parameters of distinct neural SDE models corresponding to each change point.
Specifically, the SDEs are learned under the framework of generative
adversarial networks (GANs) and the change points are detected based on the
output of the GAN discriminator in a forward pass. At each step of the proposed
algorithm, the change points and the SDE model parameters are updated in an
alternating fashion. Numerical results on both synthetic and real datasets are
provided to validate the performance of our algorithm in comparison to
classical change point detection benchmarks, standard GAN-based neural SDEs,
and other state-of-the-art deep generative models for time series data.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13155" title="Abstract">arXiv:2312.13155</a> [<a href="/pdf/2312.13155" title="Download PDF">pdf</a>, <a href="/format/2312.13155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gappy local conformal auto-encoders for heterogeneous data fusion: in  praise of rigidity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peterfreund%2C+E">Erez Peterfreund</a>, 
<a href="/search/cs?searchtype=author&query=Burak%2C+I">Iryna Burak</a>, 
<a href="/search/cs?searchtype=author&query=Lindenbaum%2C+O">Ofir Lindenbaum</a>, 
<a href="/search/cs?searchtype=author&query=Gimlett%2C+J">Jim Gimlett</a>, 
<a href="/search/cs?searchtype=author&query=Dietrich%2C+F">Felix Dietrich</a>, 
<a href="/search/cs?searchtype=author&query=Coifman%2C+R+R">Ronald R. Coifman</a>, 
<a href="/search/cs?searchtype=author&query=Kevrekidis%2C+I+G">Ioannis G. Kevrekidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Fusing measurements from multiple, heterogeneous, partial sources, observing
a common object or process, poses challenges due to the increasing availability
of numbers and types of sensors. In this work we propose, implement and
validate an end-to-end computational pipeline in the form of a
multiple-auto-encoder neural network architecture for this task. The inputs to
the pipeline are several sets of partial observations, and the result is a
globally consistent latent space, harmonizing (rigidifying, fusing) all
measurements. The key enabler is the availability of multiple slightly
perturbed measurements of each instance:, local measurement, "bursts", that
allows us to estimate the local distortion induced by each instrument. We
demonstrate the approach in a sequence of examples, starting with simple
two-dimensional data sets and proceeding to a Wi-Fi localization problem and to
the solution of a "dynamical puzzle" arising in spatio-temporal observations of
the solutions of Partial Differential Equations.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13156" title="Abstract">arXiv:2312.13156</a> [<a href="/pdf/2312.13156" title="Download PDF">pdf</a>, <a href="/format/2312.13156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AccidentGPT: Accident analysis and prevention from V2X Environmental  Perception with Multi-modal Large Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lening Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Han Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+P">Pinlong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+D">Daocheng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zhiyong Cui</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yilong Ren</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haiyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuesong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yinhai Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Traffic accidents, being a significant contributor to both human casualties
and property damage, have long been a focal point of research for many scholars
in the field of traffic safety. However, previous studies, whether focusing on
static environmental assessments or dynamic driving analyses, as well as
pre-accident predictions or post-accident rule analyses, have typically been
conducted in isolation. There has been a lack of an effective framework for
developing a comprehensive understanding and application of traffic safety. To
address this gap, this paper introduces AccidentGPT, a comprehensive accident
analysis and prevention multi-modal large model. AccidentGPT establishes a
multi-modal information interaction framework grounded in multi-sensor
perception, thereby enabling a holistic approach to accident analysis and
prevention in the field of traffic safety. Specifically, our capabilities can
be categorized as follows: for autonomous driving vehicles, we provide
comprehensive environmental perception and understanding to control the vehicle
and avoid collisions. For human-driven vehicles, we offer proactive long-range
safety warnings and blind-spot alerts while also providing safety driving
recommendations and behavioral norms through human-machine dialogue and
interaction. Additionally, for traffic police and management agencies, our
framework supports intelligent and real-time analysis of traffic safety,
encompassing pedestrian, vehicles, roads, and the environment through
collaborative perception from multiple vehicles and road testing devices. The
system is also capable of providing a thorough analysis of accident causes and
liability after vehicle collisions. Our framework stands as the first large
model to integrate comprehensive scene understanding into traffic safety
studies.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13161" title="Abstract">arXiv:2312.13161</a> [<a href="/pdf/2312.13161" title="Download PDF">pdf</a>, <a href="/ps/2312.13161" title="Download PostScript">ps</a>, <a href="/format/2312.13161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local space-preserving decompositions for the bubble transform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Falk%2C+R+S">Richard S. Falk</a>, 
<a href="/search/math?searchtype=author&query=Winther%2C+R">Ragnar Winther</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The bubble transform is a procedure to decompose differential forms, which
are piecewise smooth with respect to a given triangulation of the domain, into
a sum of local bubbles. In this paper, an improved version of a construction in
the setting of the de Rham complex previously proposed by the authors is
presented. The major improvement in the decomposition is that unlike the
previous results, in which the individual bubbles were rational functions with
the property that groups of local bubbles summed up to preserve piecewise
smoothness, the new decomposition is strictly space-preserving in the sense
that each local bubble preserves piecewise smoothness. An important property of
the transform is that the construction only depends on the given triangulation
of the domain and is independent of any finite element space. On the other
hand, all the standard piecewise polynomial spaces are invariant under the
transform. Other key properties of the transform are that it commutes with the
exterior derivative, is bounded in L^2, and satisfies the stable decomposition
property.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13162" title="Abstract">arXiv:2312.13162</a> [<a href="/pdf/2312.13162" title="Download PDF">pdf</a>, <a href="/format/2312.13162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brain-Inspired Visual Odometry: Balancing Speed and Interpretability  through a System of Systems Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tabrizi%2C+H+B">Habib Boloorchi Tabrizi</a>, 
<a href="/search/cs?searchtype=author&query=Crick%2C+C">Christopher Crick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://www.american-cse.org/csci2023">this https URL</a> is website of conference and conference name is CSCI2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this study, we address the critical challenge of balancing speed and
accuracy while maintaining interpretablity in visual odometry (VO) systems, a
pivotal aspect in the field of autonomous navigation and robotics. Traditional
VO systems often face a trade-off between computational speed and the precision
of pose estimation. To tackle this issue, we introduce an innovative system
that synergistically combines traditional VO methods with a specifically
tailored fully connected network (FCN). Our system is unique in its approach to
handle each degree of freedom independently within the FCN, placing a strong
emphasis on causal inference to enhance interpretability. This allows for a
detailed and accurate assessment of relative pose error (RPE) across various
degrees of freedom, providing a more comprehensive understanding of parameter
variations and movement dynamics in different environments. Notably, our system
demonstrates a remarkable improvement in processing speed without compromising
accuracy. In certain scenarios, it achieves up to a 5% reduction in Root Mean
Square Error (RMSE), showcasing its ability to effectively bridge the gap
between speed and accuracy that has long been a limitation in VO research. This
advancement represents a significant step forward in developing more efficient
and reliable VO systems, with wide-ranging applications in real-time navigation
and robotic systems.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13163" title="Abstract">arXiv:2312.13163</a> [<a href="/pdf/2312.13163" title="Download PDF">pdf</a>, <a href="/ps/2312.13163" title="Download PostScript">ps</a>, <a href="/format/2312.13163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse sampling recovery by greedy algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Temlyakov%2C+V">V. Temlyakov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2307.04161">arXiv:2307.04161</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Functional Analysis (math.FA)

</div>
<p class="mathjax">In this paper we analyze approximation and recovery properties with respect
to systems satisfying universal sampling discretization property and a special
incoherence property. We concentrate on recovery with the error measured in the
$L_p$ norm for $2\le p&lt;\infty$. We apply a powerful nonlinear approximation
method -- the Weak Chebyshev Greedy Algorithm (WCGA). We establish that the
WCGA based on good points for the $L_p$-universal discretization provides good
recovery in the $L_p$ norm for $2\le p&lt;\infty$. For our recovery algorithms we
obtain both the Lebesgue-type inequalities for individual functions and the
error bounds for special classes of multivariate functions.
<br />The main point of the paper is that we combine here two deep and powerful
techniques -- Lebesgue-type inequalities for the WCGA and theory of the
universal sampling dicretization -- in order to obtain new results in sampling
recovery.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13170" title="Abstract">arXiv:2312.13170</a> [<a href="/pdf/2312.13170" title="Download PDF">pdf</a>, <a href="/format/2312.13170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experiences Building an MLIR-based SYCL Compiler
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tiotto%2C+E">Ettore Tiotto</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+V">V&#xed;ctor P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Tsang%2C+W">Whitney Tsang</a>, 
<a href="/search/cs?searchtype=author&query=Sommer%2C+L">Lukas Sommer</a>, 
<a href="/search/cs?searchtype=author&query=Oppermann%2C+J">Julian Oppermann</a>, 
<a href="/search/cs?searchtype=author&query=Lom%C3%BCller%2C+V">Victor Lom&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Goli%2C+M">Mehdi Goli</a>, 
<a href="/search/cs?searchtype=author&query=Brodman%2C+J">James Brodman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures To be published in International Symposium on Code Generation and Optimization (CGO) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Performance (cs.PF)

</div>
<p class="mathjax">Similar to other programming models, compilers for SYCL, the open programming
model for heterogeneous computing based on C++, would benefit from access to
higher-level intermediate representations. The loss of high-level structure and
semantics caused by premature lowering to low-level intermediate
representations and the inability to reason about host and device code
simultaneously present major challenges for SYCL compilers. The MLIR compiler
framework, through its dialect mechanism, allows to model domain-specific,
high-level intermediate representations and provides the necessary facilities
to address these challenges. This work therefore describes practical experience
with the design and implementation of an MLIR-based SYCL compiler. By modeling
key elements of the SYCL programming model in host and device code in the MLIR
dialect framework, the presented approach enables the implementation of
powerful device code optimizations as well as analyses across host and device
code. Compared to two LLVM-based SYCL implementations, this yields speedups of
up to 4.3x on a collection of SYCL benchmark applications. Finally, this work
also discusses challenges encountered in the design and implementation and how
these could be addressed in the future.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13171" title="Abstract">arXiv:2312.13171</a> [<a href="/pdf/2312.13171" title="Download PDF">pdf</a>, <a href="/format/2312.13171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Programmable electrical coupling between stochastic magnetic tunnel  junctions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gibeault%2C+S">Sidra Gibeault</a>, 
<a href="/search/cs?searchtype=author&query=Adeyeye%2C+T+N">Temitayo N. Adeyeye</a>, 
<a href="/search/cs?searchtype=author&query=Pocher%2C+L+A">Liam A. Pocher</a>, 
<a href="/search/cs?searchtype=author&query=Lathrop%2C+D+P">Daniel P. Lathrop</a>, 
<a href="/search/cs?searchtype=author&query=Daniels%2C+M+W">Matthew W. Daniels</a>, 
<a href="/search/cs?searchtype=author&query=Stiles%2C+M+D">Mark D. Stiles</a>, 
<a href="/search/cs?searchtype=author&query=McClelland%2C+J+J">Jabez J. McClelland</a>, 
<a href="/search/cs?searchtype=author&query=Borders%2C+W+A">William A. Borders</a>, 
<a href="/search/cs?searchtype=author&query=Ryan%2C+J+T">Jason T. Ryan</a>, 
<a href="/search/cs?searchtype=author&query=Talatchian%2C+P">Philippe Talatchian</a>, 
<a href="/search/cs?searchtype=author&query=Ebels%2C+U">Ursula Ebels</a>, 
<a href="/search/cs?searchtype=author&query=Madhavan%2C+A">Advait Madhavan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
<p class="mathjax">Superparamagnetic tunnel junctions (SMTJs) are promising sources of
randomness for compact and energy efficient implementations of probabilistic
computing techniques. Augmenting an SMTJ with electronic circuits, to convert
the random telegraph fluctuations of its resistance state to stochastic digital
signals, gives a basic building block known as a probabilistic bit or $p$-bit.
Though scalable probabilistic computing methods connecting $p$-bits have been
proposed, practical implementations are limited by either minimal tunability or
energy inefficient microprocessors-in-the-loop. In this work, we experimentally
demonstrate the functionality of a scalable analog unit cell, namely a pair of
$p$-bits with programmable electrical coupling. This tunable coupling is
implemented with operational amplifier circuits that have a time constant of
approximately 1us, which is faster than the mean dwell times of the SMTJs over
most of the operating range. Programmability enables flexibility, allowing both
positive and negative couplings, as well as coupling devices with widely
varying device properties. These tunable coupling circuits can achieve the
whole range of correlations from $-1$ to $1$, for both devices with similar
timescales, and devices whose time scales vary by an order of magnitude. This
range of correlation allows such circuits to be used for scalable
implementations of simulated annealing with probabilistic computing.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13173" title="Abstract">arXiv:2312.13173</a> [<a href="/pdf/2312.13173" title="Download PDF">pdf</a>, <a href="/format/2312.13173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Fair Policies for Multi-stage Selection Problems from  Observational Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+Z">Zhuangzhuang Jia</a>, 
<a href="/search/cs?searchtype=author&query=Hanasusanto%2C+G+A">Grani A. Hanasusanto</a>, 
<a href="/search/cs?searchtype=author&query=Vayanos%2C+P">Phebe Vayanos</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weijun Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38th Annual AAAI Conference on Artificial Intelligence, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We consider the problem of learning fair policies for multi-stage selection
problems from observational data. This problem arises in several high-stakes
domains such as company hiring, loan approval, or bail decisions where outcomes
(e.g., career success, loan repayment, recidivism) are only observed for those
selected. We propose a multi-stage framework that can be augmented with various
fairness constraints, such as demographic parity or equal opportunity. This
problem is a highly intractable infinite chance-constrained program involving
the unknown joint distribution of covariates and outcomes. Motivated by the
potential impact of selection decisions on people's lives and livelihoods, we
propose to focus on interpretable linear selection rules. Leveraging tools from
causal inference and sample average approximation, we obtain an asymptotically
consistent solution to this selection problem by solving a mixed binary conic
optimization problem, which can be solved using standard off-the-shelf solvers.
We conduct extensive computational experiments on a variety of datasets adapted
from the UCI repository on which we show that our proposed approaches can
achieve an 11.6% improvement in precision and a 38% reduction in the measure of
unfairness compared to the existing selection policy.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13175" title="Abstract">arXiv:2312.13175</a> [<a href="/pdf/2312.13175" title="Download PDF">pdf</a>, <a href="/format/2312.13175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear moving horizon estimation for robust state and parameter  estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Schiller%2C+J+D">Julian D. Schiller</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%BCller%2C+M+A">Matthias A. M&#xfc;ller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">We propose a moving horizon estimation scheme to estimate the states and the
unknown constant parameters of general nonlinear uncertain discrete time
systems. The proposed framework and analysis explicitly do not involve the a
priori verification of a particular excitation condition for the parameters.
Instead, we use online information about the actual excitation of the
parameters at any time during operation and ensure that the regularization term
in the cost function is always automatically selected appropriately. This
ensures that the state and parameter estimation error is bounded for all times,
even if the parameters are never (or only rarely) excited during operation.
Additionally, the more often sufficient excitation is detected, the better
(i.e., smaller) the bound becomes. Robust exponential stability of the state
and parameter estimation error emerges under an additional uniform condition on
the maximum duration of insufficient excitation. The theoretical results are
illustrated by a numerical example.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13178" title="Abstract">arXiv:2312.13178</a> [<a href="/pdf/2312.13178" title="Download PDF">pdf</a>, <a href="/format/2312.13178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $\mathcal{O}(\log\log{n})$ Passes is Optimal for Semi-Streaming Maximal  Independent Set
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Assadi%2C+S">Sepehr Assadi</a>, 
<a href="/search/cs?searchtype=author&query=Konrad%2C+C">Christian Konrad</a>, 
<a href="/search/cs?searchtype=author&query=Naidu%2C+K+K">Kheeran K. Naidu</a>, 
<a href="/search/cs?searchtype=author&query=Sundaresan%2C+J">Janani Sundaresan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 60 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In the semi-streaming model for processing massive graphs, an algorithm makes
multiple passes over the edges of a given $n$-vertex graph and is tasked with
computing the solution to a problem using $O(n \cdot \text{polylog}(n))$ space.
Semi-streaming algorithms for Maximal Independent Set (MIS) that run in
$O(\log\log{n})$ passes have been known for almost a decade, however, the best
lower bounds can only rule out single-pass algorithms. We close this large gap
by proving that the current algorithms are optimal: Any semi-streaming
algorithm for finding an MIS with constant probability of success requires
$\Omega(\log\log{n})$ passes. This settles the complexity of this fundamental
problem in the semi-streaming model, and constitutes one of the first optimal
multi-pass lower bounds in this model.
<br />We establish our result by proving an optimal round vs communication tradeoff
for the (multi-party) communication complexity of MIS. The key ingredient of
this result is a new technique, called hierarchical embedding, for performing
round elimination: we show how to pack many but small hard $(r-1)$-round
instances of the problem into a single $r$-round instance, in a way that
enforces any $r$-round protocol to effectively solve all these $(r-1)$-round
instances also. These embeddings are obtained via a novel application of
results from extremal graph theory -- in particular dense graphs with many
disjoint unique shortest paths -- together with a newly designed graph product,
and are analyzed via information-theoretic tools such as direct-sum and message
compression arguments.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13179" title="Abstract">arXiv:2312.13179</a> [<a href="/pdf/2312.13179" title="Download PDF">pdf</a>, <a href="/format/2312.13179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextual Code Switching for Machine Translation using Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaji%2C+A">Arshad Kaji</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+M">Manan Shah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 1 figure, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have exerted a considerable impact on diverse
language-related tasks in recent years. Their demonstrated state-of-the-art
performance is achieved through methodologies such as zero-shot or few-shot
prompting. These models undergo training on extensive datasets that encompass
segments of the Internet and subsequently undergo fine-tuning tailored to
specific tasks. Notably, they exhibit proficiency in tasks such as translation,
summarization, question answering, and creative writing, even in the absence of
explicit training for those particular tasks. While they have shown substantial
improvement in the multilingual tasks their performance in the code switching,
especially for machine translation remains relatively uncharted. In this paper,
we present an extensive study on the code switching task specifically for the
machine translation task comparing multiple LLMs. Our results indicate that
despite the LLMs having promising results in the certain tasks, the models with
relatively lesser complexity outperform the multilingual large language models
in the machine translation task. We posit that the efficacy of multilingual
large language models in contextual code switching is constrained by their
training methodologies. In contrast, relatively smaller models, when trained
and fine-tuned on bespoke datasets, may yield superior results in comparison to
the majority of multilingual models.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13182" title="Abstract">arXiv:2312.13182</a> [<a href="/pdf/2312.13182" title="Download PDF">pdf</a>, <a href="/format/2312.13182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task-oriented Semantics-aware Communications for Robotic Waypoint  Transmission: the Value and Age of Information Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenchao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuanqing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yansha Deng</a>, 
<a href="/search/cs?searchtype=author&query=Aghvami%2C+A+H">A. Hamid Aghvami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The ultra-reliable and low-latency communication (URLLC) service of the
fifth-generation (5G) mobile communication network struggles to support safe
robot operation. Nowadays, the sixth-generation (6G) mobile communication
network is proposed to provide hyper-reliable and low-latency communication to
enable safer control for robots. However, current 5G/ 6G research mainly
focused on improving communication performance, while the robotics community
mostly assumed communication to be ideal. To jointly consider communication and
robotic control with a focus on the specific robotic task, we propose
task-oriented and semantics-aware communication in robotic control (TSRC) to
exploit the context of data and its importance in achieving the task at both
transmitter and receiver. At the transmitter, we propose a deep reinforcement
learning algorithm to generate optimal control and command (C&amp;C) data and a
proactive repetition scheme (DeepPro) to increase the successful transmission
probability. At the receiver, we design the value of information (VoI) and age
of information (AoI) based queue ordering mechanism (VA-QOM) to reorganize the
queue based on the semantic information extracted from the AoI and the VoI. The
simulation results validate that our proposed TSRC framework achieves a 91.5%
improvement in the mean square error compared to the traditional unmanned
aerial vehicle control framework.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13183" title="Abstract">arXiv:2312.13183</a> [<a href="/pdf/2312.13183" title="Download PDF">pdf</a>, <a href="/format/2312.13183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A framework for stable spectral methods in $d$-dimensional unit balls
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gao%2C+J">Jing Gao</a>, 
<a href="/search/math?searchtype=author&query=Iserles%2C+A">Arieh Iserles</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The subject of this paper is the design of efficient and stable spectral
methods for time-dependent partial differential equations in unit balls. We
commence by sketching the desired features of a spectral method, which is
defined by a choice of an orthonormal basis acting in the spatial domain. We
continue by considering in detail the choice of a $W$-function basis in a disc
in $\mathbb{R}^2$. This is a nontrivial issue because of a clash between two
objectives: skew symmetry of the differentiation matrix (which ensures inter
alia that the method is stable) and the correct behaviour at the origin. We
resolve it by representing the underlying space as an affine space and
splitting the underlying functions. This is generalised to any dimension $d
\geq 2$ in a natural manner and the paper is concluded with numerical examples
that demonstrate how our choice of basis attains the best outcome out of a
number of alternatives.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13189" title="Abstract">arXiv:2312.13189</a> [<a href="/pdf/2312.13189" title="Download PDF">pdf</a>, <a href="/ps/2312.13189" title="Download PostScript">ps</a>, <a href="/format/2312.13189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Memory Mappings Attack: On the (Mis)use of the ARM Cortex-M FPB  Unit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shan%2C+H">Haoqi Shan</a>, 
<a href="/search/cs?searchtype=author&query=Sullivan%2C+D">Dean Sullivan</a>, 
<a href="/search/cs?searchtype=author&query=Arias%2C+O">Orlando Arias</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by IEEE Asian Hardware Oriented Security and Trust Symposium (AsianHOST' 2023) and won Best Paper Award
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In recent years we have seen an explosion in the usage of low-cost, low-power
microcontrollers (MCUs) in embedded devices around us due to the popularity of
Internet of Things (IoT) devices. Although this is good from an economics
perspective, it has also been detrimental for security as microcontroller-based
systems are now a viable attack target. In response, researchers have developed
various protection mechanisms dedicated to improve security in these
resource-constrained embedded systems. We demonstrate in this paper these
defenses fall short when we leverage benign memory mapped design-for-debug
(DfD) structures added by MCU vendors in their products. In particular, we
utilize the Flash Patch and Breakpoint (FPB) unit present in the ARM Cortex-M
family to build new attack primitives which can be used to bypass common
defenses for embedded devices. Our work serves as a warning and a call in
balancing security and debug structures in modern microcontrollers.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13190" title="Abstract">arXiv:2312.13190</a> [<a href="/pdf/2312.13190" title="Download PDF">pdf</a>, <a href="/format/2312.13190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HeisenTrojans: They Are Not There Until They Are Triggered
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mavurapu%2C+A+R">Akshita Reddy Mavurapu</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+H">Haoqi Shan</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiaolong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Arias%2C+O">Orlando Arias</a>, 
<a href="/search/cs?searchtype=author&query=Sullivan%2C+D">Dean Sullivan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by IEEE Asian Hardware Oriented Security and Trust Symposium (AsianHOST' 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The hardware security community has made significant advances in detecting
Hardware Trojan vulnerabilities using software fuzzing-inspired automated
analysis. However, the Electronic Design Automation (EDA) code base itself
remains under-examined by the same techniques. Our experiments in fuzzing EDA
tools demonstrate that, indeed, they are prone to software bugs. As a
consequence, this paper unveils HeisenTrojan attacks, a new hardware attack
that does not generate harmful hardware, but rather, exploits software
vulnerabilities in the EDA tools themselves. A key feature of HeisenTrojan
attacks is that they are capable of deploying a malicious payload on the system
hosting the EDA tools without triggering verification tools because
HeisenTrojan attacks do not rely on superfluous or malicious hardware that
would otherwise be noticeable. The aim of a HeisenTrojan attack is to execute
arbitrary code on the system on which the vulnerable EDA tool is hosted,
thereby establishing a permanent presence and providing a beachhead for
intrusion into that system. Our analysis reveals 83% of the EDA tools analyzed
have exploitable bugs. In what follows, we demonstrate an end- to-end attack
and provide analysis on the existing capabilities of fuzzers to find
HeisenTrojan attacks in order to emphasize their practicality and the need to
secure EDA tools against them.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13193" title="Abstract">arXiv:2312.13193</a> [<a href="/pdf/2312.13193" title="Download PDF">pdf</a>, <a href="/ps/2312.13193" title="Download PostScript">ps</a>, <a href="/format/2312.13193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HCDIR: End-to-end Hate Context Detection, and Intensity Reduction model  for online comments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+N+K">Neeraj Kumar Singh</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+K">Koyel Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Mahapatra%2C+J">Joy Mahapatra</a>, 
<a href="/search/cs?searchtype=author&query=Garain%2C+U">Utpal Garain</a>, 
<a href="/search/cs?searchtype=author&query=Senapati%2C+A">Apurbalal Senapati</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Warning: This paper contains examples of the language that some people may
find offensive.
<br />Detecting and reducing hateful, abusive, offensive comments is a critical and
challenging task on social media. Moreover, few studies aim to mitigate the
intensity of hate speech. While studies have shown that context-level semantics
are crucial for detecting hateful comments, most of this research focuses on
English due to the ample datasets available. In contrast, low-resource
languages, like Indian languages, remain under-researched because of limited
datasets. Contrary to hate speech detection, hate intensity reduction remains
unexplored in high-resource and low-resource languages. In this paper, we
propose a novel end-to-end model, HCDIR, for Hate Context Detection, and Hate
Intensity Reduction in social media posts. First, we fine-tuned several
pre-trained language models to detect hateful comments to ascertain the
best-performing hateful comments detection model. Then, we identified the
contextual hateful words. Identification of such hateful words is justified
through the state-of-the-art explainable learning model, i.e., Integrated
Gradient (IG). Lastly, the Masked Language Modeling (MLM) model has been
employed to capture domain-specific nuances to reduce hate intensity. We masked
the 50\% hateful words of the comments identified as hateful and predicted the
alternative words for these masked terms to generate convincing sentences. An
optimal replacement for the original hate comments from the feasible sentences
is preferred. Extensive experiments have been conducted on several recent
datasets using automatic metric-based evaluation (BERTScore) and thorough human
evaluation. To enhance the faithfulness in human evaluation, we arranged a
group of three human annotators with varied expertise.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13201" title="Abstract">arXiv:2312.13201</a> [<a href="/pdf/2312.13201" title="Download PDF">pdf</a>, <a href="/format/2312.13201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Kemeny&#x27;s constant and stochastic complement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bini%2C+D+A">Dario Andrea Bini</a>, 
<a href="/search/math?searchtype=author&query=Durastante%2C+F">Fabio Durastante</a>, 
<a href="/search/math?searchtype=author&query=Kim%2C+S">Sooyeong Kim</a>, 
<a href="/search/math?searchtype=author&query=Meini%2C+B">Beatrice Meini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Given a stochastic matrix $P$ partitioned in four blocks $P_{ij}$, $i,j=1,2$,
Kemeny's constant $\kappa(P)$ is expressed in terms of Kemeny's constants of
the stochastic complements $P_1=P_{11}+P_{12}(I-P_{22})^{-1}P_{21}$, and
$P_2=P_{22}+P_{21}(I-P_{11})^{-1}P_{12}$. Specific cases concerning periodic
Markov chains and Kronecker products of stochastic matrices are investigated.
Bounds to Kemeny's constant of perturbed matrices are given. Relying on these
theoretical results, a divide-and-conquer algorithm for the efficient
computation of Kemeny's constant of graphs is designed. Numerical experiments
performed on real-world problems show the high efficiency and reliability of
this algorithm.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13202" title="Abstract">arXiv:2312.13202</a> [<a href="/pdf/2312.13202" title="Download PDF">pdf</a>, <a href="/format/2312.13202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multivariate rational approximation of functions with curves of  singularities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Boull%C3%A9%2C+N">Nicolas Boull&#xe9;</a>, 
<a href="/search/math?searchtype=author&query=Herremans%2C+A">Astrid Herremans</a>, 
<a href="/search/math?searchtype=author&query=Huybrechs%2C+D">Daan Huybrechs</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Functions with singularities are notoriously difficult to approximate with
conventional approximation schemes. In computational applications they are
often resolved with low-order piecewise polynomials, multilevel schemes or
other types of grading strategies. Rational functions are an exception to this
rule: for univariate functions with point singularities, such as branch points,
rational approximations exist with root-exponential convergence in the rational
degree. This is typically enabled by the clustering of poles near the
singularity. Both the theory and computational practice of rational functions
for function approximation have focused on the univariate case, with extensions
to two dimensions via identification with the complex plane. Multivariate
rational functions, i.e., quotients of polynomials of several variables, are
relatively unexplored in comparison. Yet, apart from a steep increase in
theoretical complexity, they also offer a wealth of opportunities. A first
observation is that singularities of multivariate rational functions may be
continuous curves of poles, rather than isolated ones. By generalizing the
clustering of poles from points to curves, we explore constructions of
multivariate rational approximations to functions with curves of singularities.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13203" title="Abstract">arXiv:2312.13203</a> [<a href="/pdf/2312.13203" title="Download PDF">pdf</a>, <a href="/format/2312.13203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RIShield: Enabling Electromagnetic Blackout in Radiation-Sensitive  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Encinas-Lago%2C+G">G. Encinas-Lago</a>, 
<a href="/search/cs?searchtype=author&query=Rossanese%2C+M">M. Rossanese</a>, 
<a href="/search/cs?searchtype=author&query=Sciancalepore%2C+V">V. Sciancalepore</a>, 
<a href="/search/cs?searchtype=author&query=Di+Renzo%2C+M">Marco Di Renzo</a>, 
<a href="/search/cs?searchtype=author&query=Costa-Perez%2C+X">Xavier Costa-Perez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Emerging Technologies (cs.ET); Signal Processing (eess.SP)

</div>
<p class="mathjax">Reconfigurable Intelligent Surfaces (RIS) have emerged as a disruptive
technology with the potential to revolutionize wireless communication systems.
In this paper, we present RIShield, a novel application of RIS technology
specifically designed for radiation-sensitive environments. The aim of RIShield
is to enable electromagnetic blackouts, preventing radiation leakage from
target areas. We propose a comprehensive framework for RIShield deployment,
considering the unique challenges and requirements of radiation-sensitive
environments. By strategically positioning RIS panels, we create an intelligent
shielding mechanism that selectively absorbs and reflects electromagnetic
waves, effectively blocking radiation transmission. To achieve optimal
performance, we model the corresponding channel and design a dynamic control
that adjusts the RIS configuration based on real-time radiation monitoring. By
leveraging the principles of reconfiguration and intelligent control, RIShield
ensures adaptive and efficient protection while minimizing signal degradation.
Through full-wave and ray-tracing simulations, we demonstrate the effectiveness
of RIShield in achieving significant electromagnetic attenuation. Our results
highlight the potential of RIS technology to address critical concerns in
radiation-sensitive environments, paving the way for safer and more secure
operations in industries such as healthcare, nuclear facilities, and defense.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13208" title="Abstract">arXiv:2312.13208</a> [<a href="/pdf/2312.13208" title="Download PDF">pdf</a>, <a href="/format/2312.13208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LlaMaVAE: Guiding Large Language Model Generation via Continuous Latent  Sentence Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Carvalho%2C+D+S">Danilo S. Carvalho</a>, 
<a href="/search/cs?searchtype=author&query=Pratt-Hartmann%2C+I">Ian Pratt-Hartmann</a>, 
<a href="/search/cs?searchtype=author&query=Freitas%2C+A">Andr&#xe9; Freitas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Deep generative neural networks, such as Variational AutoEncoders (VAEs),
offer an opportunity to better understand and control language models from the
perspective of sentence-level latent spaces. To combine the controllability of
VAE latent spaces with the state-of-the-art performance of recent large
language models (LLMs), we present in this work LlaMaVAE, which combines
expressive encoder and decoder models (sentenceT5 and LlaMA) with a VAE
architecture, aiming to provide better text generation control to LLMs. In
addition, to conditionally guide the VAE generation, we investigate a new
approach based on flow-based invertible neural networks (INNs) named Invertible
CVAE. Experimental results reveal that LlaMaVAE can outperform the previous
state-of-the-art VAE language model, Optimus, across various tasks, including
language modelling, semantic textual similarity and definition modelling.
Qualitative analysis on interpolation and traversal experiments also indicates
an increased degree of semantic clustering and geometric consistency, which
enables better generation control.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13211" title="Abstract">arXiv:2312.13211</a> [<a href="/pdf/2312.13211" title="Download PDF">pdf</a>, <a href="/format/2312.13211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DSFormer: Effective Compression of Text-Transformers by Dense-Sparse  Weight Factorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chand%2C+R">Rahul Chand</a>, 
<a href="/search/cs?searchtype=author&query=Prabhu%2C+Y">Yashoteja Prabhu</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+P">Pratyush Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 page main paper. 1 page appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With the tremendous success of large transformer models in natural language
understanding, down-sizing them for cost-effective deployments has become
critical. Recent studies have explored the low-rank weight factorization
techniques which are efficient to train, and apply out-of-the-box to any
transformer architecture. Unfortunately, the low-rank assumption tends to be
over-restrictive and hinders the expressiveness of the compressed model. This
paper proposes, DSFormer, a simple alternative factorization scheme which
expresses a target weight matrix as the product of a small dense and a
semi-structured sparse matrix. The resulting approximation is more faithful to
the weight distribution in transformers and therefore achieves a stronger
efficiency-accuracy trade-off. Another concern with existing factorizers is
their dependence on a task-unaware initialization step which degrades the
accuracy of the resulting model. DSFormer addresses this issue through a novel
Straight-Through Factorizer (STF) algorithm that jointly learns all the weight
factorizations to directly maximize the final task accuracy. Extensive
experiments on multiple natural language understanding benchmarks demonstrate
that DSFormer obtains up to 40% better compression than the state-of-the-art
low-rank factorizers, leading semi-structured sparsity baselines and popular
knowledge distillation approaches. Our approach is also orthogonal to
mainstream compressors and offers up to 50% additional compression when added
to popular distilled, layer-shared and quantized transformers. We empirically
evaluate the benefits of STF over conventional optimization practices.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13216" title="Abstract">arXiv:2312.13216</a> [<a href="/pdf/2312.13216" title="Download PDF">pdf</a>, <a href="/format/2312.13216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Semantic Correspondence with Viewpoint-Guided Spherical Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mariotti%2C+O">Octave Mariotti</a>, 
<a href="/search/cs?searchtype=author&query=Mac+Aodha%2C+O">Oisin Mac Aodha</a>, 
<a href="/search/cs?searchtype=author&query=Bilen%2C+H">Hakan Bilen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent progress in self-supervised representation learning has resulted in
models that are capable of extracting image features that are not only
effective at encoding image level, but also pixel-level, semantics. These
features have been shown to be effective for dense visual semantic
correspondence estimation, even outperforming fully-supervised methods.
Nevertheless, current self-supervised approaches still fail in the presence of
challenging image characteristics such as symmetries and repeated parts. To
address these limitations, we propose a new approach for semantic
correspondence estimation that supplements discriminative self-supervised
features with 3D understanding via a weak geometric spherical prior. Compared
to more involved 3D pipelines, our model only requires weak viewpoint
information, and the simplicity of our spherical representation enables us to
inject informative geometric priors into the model during training. We propose
a new evaluation metric that better accounts for repeated part and
symmetry-induced mistakes. We present results on the challenging SPair-71k
dataset, where we show that our approach demonstrates is capable of
distinguishing between symmetric views and repeated parts across many object
categories, and also demonstrate that we can generalize to unseen classes on
the AwA dataset.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13218" title="Abstract">arXiv:2312.13218</a> [<a href="/pdf/2312.13218" title="Download PDF">pdf</a>, <a href="/format/2312.13218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FiFAR: A Fraud Detection Dataset for Learning to Defer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alves%2C+J+V">Jean V. Alves</a>, 
<a href="/search/cs?searchtype=author&query=Leit%C3%A3o%2C+D">Diogo Leit&#xe3;o</a>, 
<a href="/search/cs?searchtype=author&query=Jesus%2C+S">S&#xe9;rgio Jesus</a>, 
<a href="/search/cs?searchtype=author&query=Sampaio%2C+M+O+P">Marco O. P. Sampaio</a>, 
<a href="/search/cs?searchtype=author&query=Saleiro%2C+P">Pedro Saleiro</a>, 
<a href="/search/cs?searchtype=author&query=Figueiredo%2C+M+A+T">M&#xe1;rio A. T. Figueiredo</a>, 
<a href="/search/cs?searchtype=author&query=Bizarro%2C+P">Pedro Bizarro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The public dataset and detailed synthetic expert information are available at: <a href="https://github.com/feedzai/fifar-dataset">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Public dataset limitations have significantly hindered the development and
benchmarking of learning to defer (L2D) algorithms, which aim to optimally
combine human and AI capabilities in hybrid decision-making systems. In such
systems, human availability and domain-specific concerns introduce
difficulties, while obtaining human predictions for training and evaluation is
costly. Financial fraud detection is a high-stakes setting where algorithms and
human experts often work in tandem; however, there are no publicly available
datasets for L2D concerning this important application of human-AI teaming. To
fill this gap in L2D research, we introduce the Financial Fraud Alert Review
Dataset (FiFAR), a synthetic bank account fraud detection dataset, containing
the predictions of a team of 50 highly complex and varied synthetic fraud
analysts, with varied bias and feature dependence. We also provide a realistic
definition of human work capacity constraints, an aspect of L2D systems that is
often overlooked, allowing for extensive testing of assignment systems under
real-world conditions. We use our dataset to develop a capacity-aware L2D
method and rejection learning approach under realistic data availability
conditions, and benchmark these baselines under an array of 300 distinct
testing scenarios. We believe that this dataset will serve as a pivotal
instrument in facilitating a systematic, rigorous, reproducible, and
transparent evaluation and comparison of L2D methods, thereby fostering the
development of more synergistic human-AI collaboration in decision-making
systems. The public dataset and detailed synthetic expert information are
available at: https://github.com/feedzai/fifar-dataset
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13219" title="Abstract">arXiv:2312.13219</a> [<a href="/pdf/2312.13219" title="Download PDF">pdf</a>, <a href="/format/2312.13219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Visual Task Learning for Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+W">Weiwei Gu</a>, 
<a href="/search/cs?searchtype=author&query=Sah%2C+A">Anant Sah</a>, 
<a href="/search/cs?searchtype=author&query=Gopalan%2C+N">Nakul Gopalan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of The 38th Annual AAAI Conference on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We present a framework for robots to learn novel visual concepts and tasks
via in-situ linguistic interactions with human users. Previous approaches have
either used large pre-trained visual models to infer novel objects zero-shot,
or added novel concepts along with their attributes and representations to a
concept hierarchy. We extend the approaches that focus on learning visual
concept hierarchies by enabling them to learn novel concepts and solve unseen
robotics tasks with them. To enable a visual concept learner to solve robotics
tasks one-shot, we developed two distinct techniques. Firstly, we propose a
novel approach, Hi-Viscont(HIerarchical VISual CONcept learner for Task), which
augments information of a novel concept to its parent nodes within a concept
hierarchy. This information propagation allows all concepts in a hierarchy to
update as novel concepts are taught in a continual learning setting. Secondly,
we represent a visual task as a scene graph with language annotations, allowing
us to create novel permutations of a demonstrated task zero-shot in-situ. We
present two sets of results. Firstly, we compare Hi-Viscont with the baseline
model (FALCON) on visual question answering(VQA) in three domains. While being
comparable to the baseline model on leaf level concepts, Hi-Viscont achieves an
improvement of over 9% on non-leaf concepts on average. We compare our model's
performance against the baseline FALCON model. Our framework achieves 33%
improvements in success rate metric, and 19% improvements in the object level
accuracy compared to the baseline model. With both of these results we
demonstrate the ability of our model to learn tasks and concepts in a continual
learning setting on the robot.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13223" title="Abstract">arXiv:2312.13223</a> [<a href="/pdf/2312.13223" title="Download PDF">pdf</a>, <a href="/format/2312.13223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StableKD: Breaking Inter-block Optimization Entanglement for Stable  Knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kao%2C+S">Shiu-hong Kao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jierun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+S+H+G">S.H. Gary Chan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Knowledge distillation (KD) has been recognized as an effective tool to
compress and accelerate models. However, current KD approaches generally suffer
from an accuracy drop and/or an excruciatingly long distillation process. In
this paper, we tackle the issue by first providing a new insight into a
phenomenon that we call the Inter-Block Optimization Entanglement (IBOE), which
makes the conventional end-to-end KD approaches unstable with noisy gradients.
We then propose StableKD, a novel KD framework that breaks the IBOE and
achieves more stable optimization. StableKD distinguishes itself through two
operations: Decomposition and Recomposition, where the former divides a pair of
teacher and student networks into several blocks for separate distillation, and
the latter progressively merges them back, evolving towards end-to-end
distillation. We conduct extensive experiments on CIFAR100, Imagewoof, and
ImageNet datasets with various teacher-student pairs. Compared to other KD
approaches, our simple yet effective StableKD greatly boosts the model accuracy
by 1% ~ 18%, speeds up the convergence up to 10 times, and outperforms them
with only 40% of the training data.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13225" title="Abstract">arXiv:2312.13225</a> [<a href="/pdf/2312.13225" title="Download PDF">pdf</a>, <a href="/format/2312.13225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated DevOps Pipeline Generation for Code Repositories using Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehta%2C+D">Deep Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Rawool%2C+K">Kartik Rawool</a>, 
<a href="/search/cs?searchtype=author&query=Gujar%2C+S">Subodh Gujar</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bowen Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Automating software development processes through the orchestration of GitHub
Action workflows has revolutionized the efficiency and agility of software
delivery pipelines. This paper presents a detailed investigation into the use
of Large Language Models (LLMs) specifically, GPT 3.5 and GPT 4 to generate and
evaluate GitHub Action workflows for DevOps tasks. Our methodology involves
data collection from public GitHub repositories, prompt engineering for LLM
utilization, and evaluation metrics encompassing exact match scores, BLEU
scores, and a novel DevOps Aware score. The research scrutinizes the
proficiency of GPT 3.5 and GPT 4 in generating GitHub workflows, while
assessing the influence of various prompt elements in constructing the most
efficient pipeline. Results indicate substantial advancements in GPT 4,
particularly in DevOps awareness and syntax correctness. The research
introduces a GitHub App built on Probot, empowering users to automate workflow
generation within GitHub ecosystem. This study contributes insights into the
evolving landscape of AI-driven automation in DevOps practices.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13228" title="Abstract">arXiv:2312.13228</a> [<a href="/pdf/2312.13228" title="Download PDF">pdf</a>, <a href="/format/2312.13228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarks for Retrospective Automated Driving System Crash Rate  Analysis Using Police-Reported Crash Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scanlon%2C+J+M">John M. Scanlon</a>, 
<a href="/search/cs?searchtype=author&query=Kusano%2C+K+D">Kristofer D. Kusano</a>, 
<a href="/search/cs?searchtype=author&query=Fraade-Blanar%2C+L+A">Laura A. Fraade-Blanar</a>, 
<a href="/search/cs?searchtype=author&query=McMurry%2C+T+L">Timothy L. McMurry</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yin-Hsiu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Victor%2C+T">Trent Victor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">With fully automated driving systems (ADS; SAE level 4) ride-hailing services
expanding in the US, we are now approaching an inflection point, where the
process of retrospectively evaluating ADS safety impact can start to yield
statistically credible conclusions. An ADS safety impact measurement requires a
comparison to a "benchmark" crash rate. This study aims to address, update, and
extend the existing literature by leveraging police-reported crashes to
generate human crash rates for multiple geographic areas with current ADS
deployments. All of the data leveraged is publicly accessible, and the
benchmark determination methodology is intended to be repeatable and
transparent. Generating a benchmark that is comparable to ADS crash data is
associated with certain challenges, including data selection, handling
underreporting and reporting thresholds, identifying the population of drivers
and vehicles to compare against, choosing an appropriate severity level to
assess, and matching crash and mileage exposure data. Consequently, we identify
essential steps when generating benchmarks, and present our analyses amongst a
backdrop of existing ADS benchmark literature. One analysis presented is the
usage of established underreporting correction methodology to publicly
available human driver police-reported data to improve comparability to
publicly available ADS crash data. We also identify important dependencies in
controlling for geographic region, road type, and vehicle type, and show how
failing to control for these features can bias results. This body of work aims
to contribute to the ability of the community - researchers, regulators,
industry, and experts - to reach consensus on how to estimate accurate
benchmarks.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13232" title="Abstract">arXiv:2312.13232</a> [<a href="/pdf/2312.13232" title="Download PDF">pdf</a>, <a href="/format/2312.13232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Best Response Policies in Dynamic Auctions via Deep  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thoma%2C+V">Vinzenz Thoma</a>, 
<a href="/search/cs?searchtype=author&query=Curry%2C+M">Michael Curry</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+N">Niao He</a>, 
<a href="/search/cs?searchtype=author&query=Seuken%2C+S">Sven Seuken</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Many real-world auctions are dynamic processes, in which bidders interact and
report information over multiple rounds with the auctioneer. The sequential
decision making aspect paired with imperfect information renders analyzing the
incentive properties of such auctions much more challenging than in the static
case. It is clear that bidders often have incentives for manipulation, but the
full scope of such strategies is not well-understood. We aim to develop a tool
for better understanding the incentive properties in dynamic auctions by using
reinforcement learning to learn the optimal strategic behavior for an auction
participant. We frame the decision problem as a Markov Decision Process, show
its relation to multi-task reinforcement learning and use a soft actor-critic
algorithm with experience relabeling to best-respond against several known
analytical equilibria as well as to find profitable deviations against
exploitable bidder strategies.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13234" title="Abstract">arXiv:2312.13234</a> [<a href="/pdf/2312.13234" title="Download PDF">pdf</a>, <a href="/format/2312.13234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Position Paper: Bridging the Gap Between Machine Learning and  Sensitivity Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scholbeck%2C+C+A">Christian A. Scholbeck</a>, 
<a href="/search/cs?searchtype=author&query=Moosbauer%2C+J">Julia Moosbauer</a>, 
<a href="/search/cs?searchtype=author&query=Casalicchio%2C+G">Giuseppe Casalicchio</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+H">Hoshin Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Bischl%2C+B">Bernd Bischl</a>, 
<a href="/search/cs?searchtype=author&query=Heumann%2C+C">Christian Heumann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We argue that interpretations of machine learning (ML) models or the
model-building process can bee seen as a form of sensitivity analysis (SA), a
general methodology used to explain complex systems in many fields such as
environmental modeling, engineering, or economics. We address both researchers
and practitioners, calling attention to the benefits of a unified SA-based view
of explanations in ML and the necessity to fully credit related work. We bridge
the gap between both fields by formally describing how (a) the ML process is a
system suitable for SA, (b) how existing ML interpretation methods relate to
this perspective, and (c) how other SA techniques could be applied to ML.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13236" title="Abstract">arXiv:2312.13236</a> [<a href="/pdf/2312.13236" title="Download PDF">pdf</a>, <a href="/format/2312.13236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Models With Learned Adaptive Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sahoo%2C+S+S">Subham Sekhar Sahoo</a>, 
<a href="/search/cs?searchtype=author&query=Gokaslan%2C+A">Aaron Gokaslan</a>, 
<a href="/search/cs?searchtype=author&query=De+Sa%2C+C">Chris De Sa</a>, 
<a href="/search/cs?searchtype=author&query=Kuleshov%2C+V">Volodymyr Kuleshov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Diffusion models have gained traction as powerful algorithms for synthesizing
high-quality images. Central to these algorithms is the diffusion process,
which maps data to noise according to equations inspired by thermodynamics and
can significantly impact performance. A widely held assumption is that the ELBO
objective of a diffusion model is invariant to the noise process (Kingma et
al.,2021). In this work, we dispel this assumption -- we propose multivariate
learned adaptive noise (MuLAN), a learned diffusion process that applies
Gaussian noise at different rates across an image. Our method consists of three
components -- a multivariate noise schedule, instance-conditional diffusion,
and auxiliary variables -- which ensure that the learning objective is no
longer invariant to the choice of the noise schedule as in previous works. Our
work is grounded in Bayesian inference and casts the learned diffusion process
as an approximate variational posterior that yields a tighter lower bound on
marginal likelihood. Empirically, MuLAN sets a new state-of-the-art in density
estimation on CIFAR-10 and ImageNet compared to classical diffusion. Code is
available at https://github.com/s-sahoo/MuLAN
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13240" title="Abstract">arXiv:2312.13240</a> [<a href="/pdf/2312.13240" title="Download PDF">pdf</a>, <a href="/format/2312.13240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Verification-Based Face Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rozner%2C+A">Amit Rozner</a>, 
<a href="/search/cs?searchtype=author&query=Battash%2C+B">Barak Battash</a>, 
<a href="/search/cs?searchtype=author&query=Lindenbaum%2C+O">Ofir Lindenbaum</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+L">Lior Wolf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We study the problem of performing face verification with an efficient neural
model $f$. The efficiency of $f$ stems from simplifying the face verification
problem from an embedding nearest neighbor search into a binary problem; each
user has its own neural network $f$. To allow information sharing between
different individuals in the training set, we do not train $f$ directly but
instead generate the model weights using a hypernetwork $h$. This leads to the
generation of a compact personalized model for face identification that can be
deployed on edge devices. Key to the method's success is a novel way of
generating hard negatives and carefully scheduling the training objectives. Our
model leads to a substantially small $f$ requiring only 23k parameters and 5M
floating point operations (FLOPS). We use six face verification datasets to
demonstrate that our method is on par or better than state-of-the-art models,
with a significantly reduced number of parameters and computational burden.
Furthermore, we perform an extensive ablation study to demonstrate the
importance of each element in our method.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13247" title="Abstract">arXiv:2312.13247</a> [<a href="/pdf/2312.13247" title="Download PDF">pdf</a>, <a href="/format/2312.13247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Neural Training via a Correlated Dynamics Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brokman%2C+J">Jonathan Brokman</a>, 
<a href="/search/cs?searchtype=author&query=Betser%2C+R">Roy Betser</a>, 
<a href="/search/cs?searchtype=author&query=Turjeman%2C+R">Rotem Turjeman</a>, 
<a href="/search/cs?searchtype=author&query=Berkov%2C+T">Tom Berkov</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+I">Ido Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Gilboa%2C+G">Guy Gilboa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Dynamical Systems (math.DS)

</div>
<p class="mathjax">As neural networks grow in scale, their training becomes both computationally
demanding and rich in dynamics. Amidst the flourishing interest in these
training dynamics, we present a novel observation: Parameters during training
exhibit intrinsic correlations over time. Capitalizing on this, we introduce
Correlation Mode Decomposition (CMD). This algorithm clusters the parameter
space into groups, termed modes, that display synchronized behavior across
epochs. This enables CMD to efficiently represent the training dynamics of
complex networks, like ResNets and Transformers, using only a few modes.
Moreover, test set generalization is enhanced. We introduce an efficient CMD
variant, designed to run concurrently with training. Our experiments indicate
that CMD surpasses the state-of-the-art method for compactly modeled dynamics
on image classification. Our modeling can improve training efficiency and lower
communication overhead, as shown by our preliminary experiments in the context
of federated learning.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13252" title="Abstract">arXiv:2312.13252</a> [<a href="/pdf/2312.13252" title="Download PDF">pdf</a>, <a href="/format/2312.13252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Metric Depth with a Field-of-View Conditioned Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saxena%2C+S">Saurabh Saxena</a>, 
<a href="/search/cs?searchtype=author&query=Hur%2C+J">Junhwa Hur</a>, 
<a href="/search/cs?searchtype=author&query=Herrmann%2C+C">Charles Herrmann</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Deqing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Fleet%2C+D+J">David J. Fleet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While methods for monocular depth estimation have made significant strides on
standard benchmarks, zero-shot metric depth estimation remains unsolved.
Challenges include the joint modeling of indoor and outdoor scenes, which often
exhibit significantly different distributions of RGB and depth, and the
depth-scale ambiguity due to unknown camera intrinsics. Recent work has
proposed specialized multi-head architectures for jointly modeling indoor and
outdoor scenes. In contrast, we advocate a generic, task-agnostic diffusion
model, with several advancements such as log-scale depth parameterization to
enable joint modeling of indoor and outdoor scenes, conditioning on the
field-of-view (FOV) to handle scale ambiguity and synthetically augmenting FOV
during training to generalize beyond the limited camera intrinsics in training
datasets. Furthermore, by employing a more diverse training mixture than is
common, and an efficient diffusion parameterization, our method, DMD (Diffusion
for Metric Depth) achieves a 25\% reduction in relative error (REL) on
zero-shot indoor and 33\% reduction on zero-shot outdoor datasets over the
current SOTA using only a small number of denoising steps. For an overview see
https://diffusion-vision.github.io/dmd
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13253" title="Abstract">arXiv:2312.13253</a> [<a href="/pdf/2312.13253" title="Download PDF">pdf</a>, <a href="/format/2312.13253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditional Image Generation with Pretrained Generative Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shrestha%2C+R">Rajesh Shrestha</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+B">Bowen Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, diffusion models have gained popularity for their ability to
generate higher-quality images in comparison to GAN models. However, like any
other large generative models, these models require a huge amount of data,
computational resources, and meticulous tuning for successful training. This
poses a significant challenge, rendering it infeasible for most individuals. As
a result, the research community has devised methods to leverage pre-trained
unconditional diffusion models with additional guidance for the purpose of
conditional image generative. These methods enable conditional image
generations on diverse inputs and, most importantly, circumvent the need for
training the diffusion model. In this paper, our objective is to reduce the
time-required and computational overhead introduced by the addition of guidance
in diffusion models -- while maintaining comparable image quality. We propose a
set of methods based on our empirical analysis, demonstrating a reduction in
computation time by approximately threefold.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13261" title="Abstract">arXiv:2312.13261</a> [<a href="/pdf/2312.13261" title="Download PDF">pdf</a>, <a href="/ps/2312.13261" title="Download PostScript">ps</a>, <a href="/format/2312.13261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error analysis for a non-conforming virtual element discretization of  the acoustic problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Amigo%2C+D">Danilo Amigo</a>, 
<a href="/search/math?searchtype=author&query=Lepe%2C+F">Felipe Lepe</a>, 
<a href="/search/math?searchtype=author&query=Rivera%2C+G">Gonzalo Rivera</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2310.07955">arXiv:2310.07955</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We introduce non conforming virtual elements to approximate the eigenvalues
and eigenfunctions of the two dimensional acoustic vibration problem. We focus
our attention on the pressure formulation of the acoustic vibration problem in
order to discretize it with a suitable non conforming virtual space for
$\mathrm{H}^1$. With the aid of the theory of non-compact operators we prove
convergence and spectral correctness of the method. To illustrate the
theoretical results, we report numerical tests on different polygonal meshes,
in order to show the accuracy of the method on the approximation of the
spectrum.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13264" title="Abstract">arXiv:2312.13264</a> [<a href="/pdf/2312.13264" title="Download PDF">pdf</a>, <a href="/format/2312.13264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> dIR -- Discrete Information Retrieval: Conversational Search over  Unstructured (and Structured) Data with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bertorello%2C+P+M+R">Pablo M. Rodriguez Bertorello</a>, 
<a href="/search/cs?searchtype=author&query=Laguerre%2C+J+R+J">Jean Rodmond Junior Laguerre</a> (Computer Science Department, Stanford University)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, Association for Computational Linguistics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Data is stored in both structured and unstructured form. Querying both, to
power natural language conversations, is a challenge. This paper introduces
dIR, Discrete Information Retrieval, providing a unified interface to query
both free text and structured knowledge. Specifically, a Large Language Model
(LLM) transforms text into expressive representation. After the text is
extracted into columnar form, it can then be queried via a text-to-SQL Semantic
Parser, with an LLM converting natural language into SQL. Where desired, such
conversation may be effected by a multi-step reasoning conversational agent. We
validate our approach via a proprietary question/answer data set, concluding
that dIR makes a whole new class of queries on free text possible when compared
to traditionally fine-tuned dense-embedding-model-based Information Retrieval
(IR) and SQL-based Knowledge Bases (KB). For sufficiently complex queries, dIR
can succeed where no other method stands a chance.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13265" title="Abstract">arXiv:2312.13265</a> [<a href="/pdf/2312.13265" title="Download PDF">pdf</a>, <a href="/format/2312.13265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClassLIE: Structure- and Illumination-Adaptive Classification for  Low-Light Image Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zixiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiting Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Vasilakos%2C+A+V">Athanasios V. Vasilakos</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Low-light images often suffer from limited visibility and multiple types of
degradation, rendering low-light image enhancement (LIE) a non-trivial task.
Some endeavors have been recently made to enhance low-light images using
convolutional neural networks (CNNs). However, they have low efficiency in
learning the structural information and diverse illumination levels at the
local regions of an image. Consequently, the enhanced results are affected by
unexpected artifacts, such as unbalanced exposure, blur, and color bias. To
this end, this paper proposes a novel framework, called ClassLIE, that combines
the potential of CNNs and transformers. It classifies and adaptively learns the
structural and illumination information from the low-light images in a holistic
and regional manner, thus showing better enhancement performance. Our framework
first employs a structure and illumination classification (SIC) module to learn
the degradation information adaptively. In SIC, we decompose an input image
into an illumination map and a reflectance map. A class prediction block is
then designed to classify the degradation information by calculating the
structure similarity scores on the reflectance map and mean square error on the
illumination map. As such, each input image can be divided into patches with
three enhancement difficulty levels. Then, a feature learning and fusion (FLF)
module is proposed to adaptively learn the feature information with CNNs for
different enhancement difficulty levels while learning the long-range
dependencies for the patches in a holistic manner. Experiments on five
benchmark datasets consistently show our ClassLIE achieves new state-of-the-art
performance, with 25.74 PSNR and 0.92 SSIM on the LOL dataset.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13270" title="Abstract">arXiv:2312.13270</a> [<a href="/pdf/2312.13270" title="Download PDF">pdf</a>, <a href="/ps/2312.13270" title="Download PostScript">ps</a>, <a href="/format/2312.13270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Milner&#x27;s Lambda-Calculus with Partial Substitutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kesner%2C+D">Delia Kesner</a>, 
<a href="/search/cs?searchtype=author&query=Conch%C3%BAir%2C+S+%C3%93">Shane &#xd3; Conch&#xfa;ir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">We study Milner's lambda-calculus with partial substitutions. Particularly,
we show confluence on terms and metaterms, preservation of \b{eta}-strong
normalisation and characterisation of strongly normalisable terms via an
intersection typing discipline. The results on terms transfer to Milner's
bigraphical model of the calculus. We relate Milner's calculus to calculi with
definitions, to calculi with explicit substitutions, and to MELL Proof-Nets.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13271" title="Abstract">arXiv:2312.13271</a> [<a href="/pdf/2312.13271" title="Download PDF">pdf</a>, <a href="/format/2312.13271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Repaint123: Fast and High-quality One Image to 3D Generation with  Progressive Controllable 2D Repainting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junwu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zhenyu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+Y">Yatian Pang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xinhua Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+P">Peng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yida Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wangbo Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+M">Munan Ning</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Li Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/junwuzhang19/repaint123">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent one image to 3D generation methods commonly adopt Score Distillation
Sampling (SDS). Despite the impressive results, there are multiple deficiencies
including multi-view inconsistency, over-saturated and over-smoothed textures,
as well as the slow generation speed. To address these deficiencies, we present
Repaint123 to alleviate multi-view bias as well as texture degradation and
speed up the generation process. The core idea is to combine the powerful image
generation capability of the 2D diffusion model and the texture alignment
ability of the repainting strategy for generating high-quality multi-view
images with consistency. We further propose visibility-aware adaptive
repainting strength for overlap regions to enhance the generated image quality
in the repainting process. The generated high-quality and multi-view consistent
images enable the use of simple Mean Square Error (MSE) loss for fast 3D
content generation. We conduct extensive experiments and show that our method
has a superior ability to generate high-quality 3D content with multi-view
consistency and fine textures in 2 minutes from scratch. Code is at
https://github.com/junwuzhang19/repaint123.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13272" title="Abstract">arXiv:2312.13272</a> [<a href="/pdf/2312.13272" title="Download PDF">pdf</a>, <a href="/format/2312.13272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Time-Relaxation Reduced Order Model for the Turbulent Channel Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tsai%2C+P">Ping-Hsuan Tsai</a> (1), 
<a href="/search/math?searchtype=author&query=Fischer%2C+P">Paul Fischer</a> (1 and 2), 
<a href="/search/math?searchtype=author&query=Iliescu%2C+T">Traian Iliescu</a> (3) ((1) Department of Computer Science, University of Illinois at Urbana-Champaign, (2) Department of Mechanical Science &amp; Engineering, University of Illinois at Urbana-Champaign, (3) Department of Mathematics, Virginia Polytechnic Institute and State University)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 46 pages, 19 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Reg-ROMs are stabilization strategies that leverage spatial filtering to
alleviate the spurious numerical oscillations generally displayed by the
classical G-ROM in under-resolved numerical simulations of turbulent flows. In
this paper, we propose a new Reg-ROM, the time-relaxation ROM (TR-ROM), which
filters the marginally resolved scales. We compare the new TR-ROM with the two
other Reg-ROMs in current use, i.e., the L-ROM and the EFR-ROM, in the
numerical simulation of the turbulent channel flow at $Re_{\tau} = 180$ and
$Re_{\tau} = 395$ in both the reproduction and the predictive regimes. For each
Reg-ROM, we investigate two different filters: (i) the differential filter
(DF), and (ii) a new higher-order algebraic filter (HOAF). In our numerical
investigation, we monitor the Reg-ROM performance for the ROM dimension, $N$,
and the filter order. We also perform sensitivity studies of the three Reg-ROMs
for the time interval, relaxation parameter, and filter radius. The numerical
results yield the following conclusions: (i) All three Reg-ROMs are
significantly more accurate than the G-ROM and (ii) more accurate than the ROM
projection, representing the best theoretical approximation of the training
data in the given ROM space. (iii) With the optimal parameter values, the
TR-ROM is more accurate than the other two Reg-ROMs in all tests. (iv) For most
$N$ values, DF yields the most accurate results for all three Reg-ROMs. (v) The
optimal parameters trained in the reproduction regime are also optimal for the
predictive regime for most $N$ values. (vi) All three Reg-ROMs are sensitive to
the filter radius and the filter order, and the EFR-ROM and the TR-ROM are
sensitive to the relaxation parameter. (vii) The optimal range for the filter
radius and the effect of relaxation parameter are similar for the two $\rm
Re_\tau$ values.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13274" title="Abstract">arXiv:2312.13274</a> [<a href="/pdf/2312.13274" title="Download PDF">pdf</a>, <a href="/format/2312.13274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoK: A Broad Comparative Evaluation of Software Debloating Tools
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brown%2C+M+D">Michael D. Brown</a>, 
<a href="/search/cs?searchtype=author&query=Meily%2C+A">Adam Meily</a>, 
<a href="/search/cs?searchtype=author&query=Fairservice%2C+B">Brian Fairservice</a>, 
<a href="/search/cs?searchtype=author&query=Sood%2C+A">Akshay Sood</a>, 
<a href="/search/cs?searchtype=author&query=Dorn%2C+J">Jonathan Dorn</a>, 
<a href="/search/cs?searchtype=author&query=Kilmer%2C+E">Eric Kilmer</a>, 
<a href="/search/cs?searchtype=author&query=Eytchison%2C+R">Ronald Eytchison</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 10 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR); Programming Languages (cs.PL)

</div>
<p class="mathjax">Software debloating tools seek to improve the program security and
performance by removing unnecessary code, called bloat. While many techniques
have been proposed, several barriers to their adoption have emerged. Namely,
debloating tools are highly specialized, making it difficult for adopters to
find the right type of tool for their needs. This is further hindered by a lack
of established metrics and comparative evaluations between tools. To close this
gap, we surveyed of 10 years of debloating literature and several tools
currently under commercial development to systematize the debloating
ecosystem's knowledge. We then conducted a broad comparative evaluation of 10
debloating tools to determine their relative strengths and weaknesses. Our
evaluation, conducted on a diverse set of 20 benchmark programs, measures tools
across 16 performance, security, correctness, and usability metrics.
<br />Our evaluation surfaces several concerning findings that contradict the
prevailing narrative in debloating literature. First, debloating tools lack the
required maturity to be used on real-world software, evidenced by a slim 21%
overall success rate for creating passable debloated versions of medium- and
high-complexity benchmarks. Second, debloating tools struggle to produce sound
and robust programs. Using our novel differential fuzzing tool, DIFFER, we
discovered that only 13% of our debloating attempts produced a sound and robust
debloated program. Finally, our results indicate that debloating tools
typically do not improve the performance or security posture of debloated
programs by a significant degree. We believe that our contributions in this
paper will help potential adopters better understand the landscape of tools and
will motivate future research and development of more capable debloating tools.
To this end, we have made our benchmark set, data, and custom tools publicly
available.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13277" title="Abstract">arXiv:2312.13277</a> [<a href="/pdf/2312.13277" title="Download PDF">pdf</a>, <a href="/format/2312.13277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning on 3D Neural Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramirez%2C+P+Z">Pierluigi Zama Ramirez</a>, 
<a href="/search/cs?searchtype=author&query=De+Luigi%2C+L">Luca De Luigi</a>, 
<a href="/search/cs?searchtype=author&query=Sirocchi%2C+D">Daniele Sirocchi</a>, 
<a href="/search/cs?searchtype=author&query=Cardace%2C+A">Adriano Cardace</a>, 
<a href="/search/cs?searchtype=author&query=Spezialetti%2C+R">Riccardo Spezialetti</a>, 
<a href="/search/cs?searchtype=author&query=Ballerini%2C+F">Francesco Ballerini</a>, 
<a href="/search/cs?searchtype=author&query=Salti%2C+S">Samuele Salti</a>, 
<a href="/search/cs?searchtype=author&query=Di+Stefano%2C+L">Luigi Di Stefano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of the paper "Deep Learning on Implicit Neural Representations of Shapes" that was presented at ICLR 2023. arXiv admin note: text overlap with <a href="/abs/2302.05438">arXiv:2302.05438</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, Neural Fields (NFs) have emerged as an effective tool for
encoding diverse continuous signals such as images, videos, audio, and 3D
shapes. When applied to 3D data, NFs offer a solution to the fragmentation and
limitations associated with prevalent discrete representations. However, given
that NFs are essentially neural networks, it remains unclear whether and how
they can be seamlessly integrated into deep learning pipelines for solving
downstream tasks. This paper addresses this research problem and introduces
nf2vec, a framework capable of generating a compact latent representation for
an input NF in a single inference pass. We demonstrate that nf2vec effectively
embeds 3D objects represented by the input NFs and showcase how the resulting
embeddings can be employed in deep learning pipelines to successfully address
various tasks, all while processing exclusively NFs. We test this framework on
several NFs used to represent 3D surfaces, such as unsigned/signed distance and
occupancy fields. Moreover, we demonstrate the effectiveness of our approach
with more complex NFs that encompass both geometry and appearance of 3D objects
such as neural radiance fields.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13279" title="Abstract">arXiv:2312.13279</a> [<a href="/pdf/2312.13279" title="Download PDF">pdf</a>, <a href="/format/2312.13279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stretch with Stretch: Physical Therapy Exercise Games Led by a Mobile  Manipulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lamsey%2C+M">Matthew Lamsey</a> (1), 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y+L">You Liang Tan</a> (1), 
<a href="/search/cs?searchtype=author&query=Wells%2C+M+D">Meredith D. Wells</a> (2), 
<a href="/search/cs?searchtype=author&query=Beatty%2C+M">Madeline Beatty</a> (1), 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zexuan Liu</a> (1), 
<a href="/search/cs?searchtype=author&query=Majumdar%2C+A">Arjun Majumdar</a> (1), 
<a href="/search/cs?searchtype=author&query=Washington%2C+K">Kendra Washington</a> (1), 
<a href="/search/cs?searchtype=author&query=Feldman%2C+J">Jerry Feldman</a> (3), 
<a href="/search/cs?searchtype=author&query=Kuppuswamy%2C+N">Naveen Kuppuswamy</a> (4), 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+E">Elizabeth Nguyen</a> (2 and 5), 
<a href="/search/cs?searchtype=author&query=Wallenstein%2C+A">Arielle Wallenstein</a> (2), 
<a href="/search/cs?searchtype=author&query=Hackney%2C+M+E">Madeleine E. Hackney</a> (2), 
<a href="/search/cs?searchtype=author&query=Kemp%2C+C+C">Charles C. Kemp</a> (1) ((1) The Institute for Robotics and Intelligent Machines at the Georgia Institute of Technology (GT), (2) Emory University School of Medicine, (3) The Parkinson&#x27;s Foundation, (4) Toyota Research Institute (TRI), (5) University of Texas Long School of Medicine)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Physical therapy (PT) is a key component of many rehabilitation regimens,
such as treatments for Parkinson's disease (PD). However, there are shortages
of physical therapists and adherence to self-guided PT is low. Robots have the
potential to support physical therapists and increase adherence to self-guided
PT, but prior robotic systems have been large and immobile, which can be a
barrier to use in homes and clinics. We present Stretch with Stretch (SWS), a
novel robotic system for leading stretching exercise games for older adults
with PD. SWS consists of a compact and lightweight mobile manipulator (Hello
Robot Stretch RE1) that visually and verbally guides users through PT
exercises. The robot's soft end effector serves as a target that users
repetitively reach towards and press with a hand, foot, or knee. For each
exercise, target locations are customized for the individual via a visually
estimated kinematic model, a haptically estimated range of motion, and the
person's exercise performance. The system includes sound effects and verbal
feedback from the robot to keep users engaged throughout a session and augment
physical exercise with cognitive exercise. We conducted a user study for which
people with PD (n=10) performed 6 exercises with the system. Participants
perceived the SWS to be useful and easy to use. They also reported mild to
moderate perceived exertion (RPE).
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13285" title="Abstract">arXiv:2312.13285</a> [<a href="/pdf/2312.13285" title="Download PDF">pdf</a>, <a href="/format/2312.13285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniSDF: Unifying Neural Representations for High-Fidelity 3D  Reconstruction of Complex Scenes with Reflections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fangjinhua Wang</a>, 
<a href="/search/cs?searchtype=author&query=Rakotosaona%2C+M">Marie-Julie Rakotosaona</a>, 
<a href="/search/cs?searchtype=author&query=Niemeyer%2C+M">Michael Niemeyer</a>, 
<a href="/search/cs?searchtype=author&query=Szeliski%2C+R">Richard Szeliski</a>, 
<a href="/search/cs?searchtype=author&query=Pollefeys%2C+M">Marc Pollefeys</a>, 
<a href="/search/cs?searchtype=author&query=Tombari%2C+F">Federico Tombari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://fangjinhuawang.github.io/UniSDF">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural 3D scene representations have shown great potential for 3D
reconstruction from 2D images. However, reconstructing real-world captures of
complex scenes still remains a challenge. Existing generic 3D reconstruction
methods often struggle to represent fine geometric details and do not
adequately model reflective surfaces of large-scale scenes. Techniques that
explicitly focus on reflective surfaces can model complex and detailed
reflections by exploiting better reflection parameterizations. However, we
observe that these methods are often not robust in real unbounded scenarios
where non-reflective as well as reflective components are present. In this
work, we propose UniSDF, a general purpose 3D reconstruction method that can
reconstruct large complex scenes with reflections. We investigate both
view-based as well as reflection-based color prediction parameterization
techniques and find that explicitly blending these representations in 3D space
enables reconstruction of surfaces that are more geometrically accurate,
especially for reflective surfaces. We further combine this representation with
a multi-resolution grid backbone that is trained in a coarse-to-fine manner,
enabling faster reconstructions than prior methods. Extensive experiments on
object-level datasets DTU, Shiny Blender as well as unbounded datasets Mip-NeRF
360 and Ref-NeRF real demonstrate that our method is able to robustly
reconstruct complex large-scale scenes with fine details and reflective
surfaces. Please see our project page at
https://fangjinhuawang.github.io/UniSDF.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13286" title="Abstract">arXiv:2312.13286</a> [<a href="/pdf/2312.13286" title="Download PDF">pdf</a>, <a href="/format/2312.13286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Multimodal Models are In-Context Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Quan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yufeng Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaosong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qiying Yu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhengxiong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yueze Wang</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+Y">Yongming Rao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingjing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tiejun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinlong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://baaivision.github.io/emu2">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The human ability to easily solve multimodal tasks in context (i.e., with
only a few demonstrations or simple instructions), is what current multimodal
systems have largely struggled to imitate. In this work, we demonstrate that
the task-agnostic in-context learning capabilities of large multimodal models
can be significantly enhanced by effective scaling-up. We introduce Emu2, a
generative multimodal model with 37 billion parameters, trained on large-scale
multimodal sequences with a unified autoregressive objective. Emu2 exhibits
strong multimodal in-context learning abilities, even emerging to solve tasks
that require on-the-fly reasoning, such as visual prompting and object-grounded
generation. The model sets a new record on multiple multimodal understanding
tasks in few-shot settings. When instruction-tuned to follow specific
instructions, Emu2 further achieves new state-of-the-art on challenging tasks
such as question answering benchmarks for large multimodal models and
open-ended subject-driven generation. These achievements demonstrate that Emu2
can serve as a base model and general-purpose interface for a wide range of
multimodal tasks. Code and models are publicly available to facilitate future
research.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Thu, 21 Dec 23</h3>
<dl>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12443" title="Abstract">arXiv:2312.12443</a> (cross-list from eess.SP) [<a href="/pdf/2312.12443" title="Download PDF">pdf</a>, <a href="/ps/2312.12443" title="Download PostScript">ps</a>, <a href="/format/2312.12443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Understanding of Driving Attributes through Quantitative  Assessment of Driver Cognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kakoti%2C+P">Pallabjyoti Kakoti</a>, 
<a href="/search/eess?searchtype=author&query=Kamti%2C+M+K">Mukesh Kumar Kamti</a>, 
<a href="/search/eess?searchtype=author&query=Iqbal%2C+R">Rauf Iqbal</a>, 
<a href="/search/eess?searchtype=author&query=Saikia%2C+E">Eeshankur Saikia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">This paper presents a novel approach for analysing EEG data from drivers in a
simulated driving test. We focused on the Hurst exponent, Shannon entropy, and
fractal dimension as markers of the nonlinear dynamics of the brain. The
results show significant trends: Shannon Entropy and Fractal Dimension exhibit
variations during driving condition transitions, whereas the Hurst exponent
reflects memory retention portraying learning patterns. These findings suggest
that the tools of Non-linear Dynamical (NLD) Theory as indicators of cognitive
state and driving memory changes for assessing driver performance and advancing
the understanding of non-linear dynamics of human cognition in the context of
driving and beyond. Our study reveals the potential of NLD tools to elucidate
brain state and system variances, enabling their integration into current Deep
Learning and Machine Learning models. This integration can extend beyond
driving applications and be harnessed for cognitive learning, thereby improving
overall productivity and accuracy levels.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12453" title="Abstract">arXiv:2312.12453</a> (cross-list from math.PR) [<a href="/pdf/2312.12453" title="Download PDF">pdf</a>, <a href="/format/2312.12453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overdrawing Urns using Categories of Signed Probabilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jacobs%2C+B">Bart Jacobs</a> (iHub, Radboud University Nijmegen), 
<a href="/search/math?searchtype=author&query=Stein%2C+D">Dario Stein</a> (iHub, Radboud University Nijmegen)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings ACT 2023, <a href="/abs/2312.08138">arXiv:2312.08138</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 397, 2023, pp. 172-189
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Machine Learning (cs.LG); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">A basic experiment in probability theory is drawing without replacement from
an urn filled with multiple balls of different colours. Clearly, it is
physically impossible to overdraw, that is, to draw more balls from the urn
than it contains. This paper demonstrates that overdrawing does make sense
mathematically, once we allow signed distributions with negative probabilities.
A new (conservative) extension of the familiar hypergeometric
('draw-and-delete') distribution is introduced that allows draws of arbitrary
sizes, including overdraws. The underlying theory makes use of the dual basis
functions of the Bernstein polynomials, which play a prominent role in computer
graphics. Negative probabilities are treated systematically in the framework of
categorical probability and the central role of datastructures such as
multisets and monads is emphasised.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12455" title="Abstract">arXiv:2312.12455</a> (cross-list from physics.ao-ph) [<a href="/pdf/2312.12455" title="Download PDF">pdf</a>, <a href="/format/2312.12455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FengWu-4DVar: Coupling the Data-driven Weather Forecasting Model with 4D  Variational Assimilation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Xiao%2C+Y">Yi Xiao</a>, 
<a href="/search/physics?searchtype=author&query=Bai%2C+L">Lei Bai</a>, 
<a href="/search/physics?searchtype=author&query=Xue%2C+W">Wei Xue</a>, 
<a href="/search/physics?searchtype=author&query=Chen%2C+K">Kang Chen</a>, 
<a href="/search/physics?searchtype=author&query=Han%2C+T">Tao Han</a>, 
<a href="/search/physics?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Weather forecasting is a crucial yet highly challenging task. With the
maturity of Artificial Intelligence (AI), the emergence of data-driven weather
forecasting models has opened up a new paradigm for the development of weather
forecasting systems. Despite the significant successes that have been achieved
(e.g., surpassing advanced traditional physical models for global medium-range
forecasting), existing data-driven weather forecasting models still rely on the
analysis fields generated by the traditional assimilation and forecasting
system, which hampers the significance of data-driven weather forecasting
models regarding both computational cost and forecasting accuracy. In this
work, we explore the possibility of coupling the data-driven weather
forecasting model with data assimilation by integrating the global AI weather
forecasting model, FengWu, with one of the most popular assimilation
algorithms, Four-Dimensional Variational (4DVar) assimilation, and develop an
AI-based cyclic weather forecasting system, FengWu-4DVar. FengWu-4DVar can
incorporate observational data into the data-driven weather forecasting model
and consider the temporal evolution of atmospheric dynamics to obtain accurate
analysis fields for making predictions in a cycling manner without the help of
physical models. Owning to the auto-differentiation ability of deep learning
models, FengWu-4DVar eliminates the need of developing the cumbersome adjoint
model, which is usually required in the traditional implementation of the 4DVar
algorithm. Experiments on the simulated observational dataset demonstrate that
FengWu-4DVar is capable of generating reasonable analysis fields for making
accurate and efficient iterative predictions.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12462" title="Abstract">arXiv:2312.12462</a> (cross-list from physics.ao-ph) [<a href="/pdf/2312.12462" title="Download PDF">pdf</a>, <a href="/format/2312.12462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards an End-to-End Artificial Intelligence Driven Global Weather  Forecasting System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Chen%2C+K">Kun Chen</a>, 
<a href="/search/physics?searchtype=author&query=Bai%2C+L">Lei Bai</a>, 
<a href="/search/physics?searchtype=author&query=Ling%2C+F">Fenghua Ling</a>, 
<a href="/search/physics?searchtype=author&query=Ye%2C+P">Peng Ye</a>, 
<a href="/search/physics?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/physics?searchtype=author&query=Chen%2C+K">Kang Chen</a>, 
<a href="/search/physics?searchtype=author&query=Han%2C+T">Tao Han</a>, 
<a href="/search/physics?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The weather forecasting system is important for science and society, and
significant achievements have been made in applying artificial intelligence
(AI) to medium-range weather forecasting. However, existing AI-based weather
forecasting models still rely on analysis or reanalysis products from the
traditional numerical weather prediction (NWP) systems as initial conditions
for making predictions, preventing them from being fully independent systems.
As a crucial component of an end-to-end global weather forecasting system, data
assimilation is vital in generating initial states for forecasting. In this
paper, we present an AI-based data assimilation model, i.e., Adas, for global
weather variables, which learns to generate the analysis from the background
and sparse observations. Different from existing assimilation methods, Adas
employs the gated convolution module to handle sparse observations and the
gated cross-attention module for capturing the interactions between
observations and background efficiently, which are guided by the confidence
matrix to represent the availability and quality of observations. Then, we
combine Adas with the advanced AI-based weather forecasting model (i.e.,
FengWu) and construct the first end-to-end AI-based global weather forecasting
system: FengWu-Adas. Experiments demonstrate that Adas can assimilate the
simulated global observations with the AI-generated background through a
one-year simulation and generate high-quality analysis stably in a cyclic
manner. Based on the generated analysis, FengWu-Adas exhibits skillful
performance and outperforms the Integrated Forecasting System (IFS) in weather
forecasting over seven days.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12476" title="Abstract">arXiv:2312.12476</a> (cross-list from physics.ao-ph) [<a href="/pdf/2312.12476" title="Download PDF">pdf</a>, <a href="/format/2312.12476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DSAF: A Dual-Stage Adaptive Framework for Numerical Weather Prediction  Downscaling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Liu%2C+P">Pengwei Liu</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+W">Wenwei Wang</a>, 
<a href="/search/physics?searchtype=author&query=Peng%2C+B">Bingqing Peng</a>, 
<a href="/search/physics?searchtype=author&query=Wu%2C+B">Binqing Wu</a>, 
<a href="/search/physics?searchtype=author&query=Sun%2C+L">Liang Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">While widely recognized as one of the most substantial weather forecasting
methodologies, Numerical Weather Prediction (NWP) usually suffers from
relatively coarse resolution and inevitable bias due to tempo-spatial
discretization, physical parametrization process, and computation limitation.
With the roaring growth of deep learning-based techniques, we propose the
Dual-Stage Adaptive Framework (DSAF), a novel framework to address regional NWP
downscaling and bias correction tasks. DSAF uniquely incorporates adaptive
elements in its design to ensure a flexible response to evolving weather
conditions. Specifically, NWP downscaling and correction are well-decoupled in
the framework and can be applied independently, which strategically guides the
optimization trajectory of the model. Utilizing a multi-task learning mechanism
and an uncertainty-weighted loss function, DSAF facilitates balanced training
across various weather factors. Additionally, our specifically designed
attention-centric learnable module effectively integrates geographic
information, proficiently managing complex interrelationships. Experimental
validation on the ECMWF operational forecast (HRES) and reanalysis (ERA5)
archive demonstrates DSAF's superior performance over existing state-of-the-art
models and shows substantial improvements when existing models are augmented
using our proposed modules. Code is publicly available at
https://github.com/pengwei07/DSAF.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12482" title="Abstract">arXiv:2312.12482</a> (cross-list from q-bio.QM) [<a href="/pdf/2312.12482" title="Download PDF">pdf</a>, <a href="/format/2312.12482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Horizons: Pioneering Pharmaceutical R&amp;D with Generative AI from lab  to the clinic -- an industry perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Doron%2C+G">Guy Doron</a>, 
<a href="/search/q-bio?searchtype=author&query=Genway%2C+S">Sam Genway</a>, 
<a href="/search/q-bio?searchtype=author&query=Roberts%2C+M">Mark Roberts</a>, 
<a href="/search/q-bio?searchtype=author&query=Jasti%2C+S">Sai Jasti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The rapid advance of generative AI is reshaping the strategic vision for R&amp;D
across industries. The unique challenges of pharmaceutical R&amp;D will see
applications of generative AI deliver value along the entire value chain from
early discovery to regulatory approval. This perspective reviews these
challenges and takes a three-horizon approach to explore the generative AI
applications already delivering impact, the disruptive opportunities which are
just around the corner, and the longer-term transformation which will shape the
future of the industry. Selected applications are reviewed for their potential
to drive increase productivity, accelerate timelines, improve the quality of
research, data and decision making, and support a sustainable future for the
industry. Recommendations are given for Pharma R&amp;D leaders developing a
generative AI strategy today which will lay the groundwork for getting real
value from the technology and safeguarding future growth. Generative AI is
today providing new, efficient routes to accessing and combining organisational
data to drive productivity. Next, this impact will reach clinical development,
enhancing the patient experience, driving operational efficiency, and unlocking
digital innovation to better tackle the future burden of disease. Looking to
the furthest horizon, rapid acquisition of rich multi-omics data, which capture
the 'language of life', in combination with next generation AI technologies
will allow organisations to close the loop around phases of the pipeline
through rapid, automated generation and testing of hypotheses from bench to
bedside. This provides a vision for the future of R&amp;D with sustainability at
the core, with reduced timescales and reduced dependency on resources, while
offering new hope to patients to treat the untreatable and ultimately cure
diseases.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12485" title="Abstract">arXiv:2312.12485</a> (cross-list from math.OC) [<a href="/pdf/2312.12485" title="Download PDF">pdf</a>, <a href="/ps/2312.12485" title="Download PostScript">ps</a>, <a href="/format/2312.12485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Deterministic Surrogates for Robust Convex QCQPs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Per%C5%A1ak%2C+E">Egon Per&#x161;ak</a>, 
<a href="/search/math?searchtype=author&query=Anjos%2C+M+F">Miguel F. Anjos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under submission at CPAIOR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Decision-focused learning is a promising development for contextual
optimisation. It enables us to train prediction models that reflect the
contextual sensitivity structure of the problem. However, there have been
limited attempts to extend this paradigm to robust optimisation. We propose a
double implicit layer model for training prediction models with respect to
robust decision loss in uncertain convex quadratically constrained quadratic
programs (QCQP). The first layer solves a deterministic version of the problem,
the second layer evaluates the worst case realisation for an uncertainty set
centred on the observation given the decisions obtained from the first layer.
This enables us to learn model parameterisations that lead to robust decisions
while only solving a simpler deterministic problem at test time. Additionally,
instead of having to solve a robust counterpart we solve two smaller and
potentially easier problems in training. The second layer (worst case problem)
can be seen as a regularisation approach for predict-and-optimise by fitting to
a neighbourhood of problems instead of just a point observation. We motivate
relaxations of the worst-case problem in cases of uncertainty sets that would
otherwise lead to trust region problems, and leverage various relaxations to
deal with uncertain constraints. Both layers are typically strictly convex in
this problem setting and thus have meaningful gradients almost everywhere. We
demonstrate an application of this model on simulated experiments. The method
is an effective regularisation tool for decision-focused learning for uncertain
convex QCQPs.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12536" title="Abstract">arXiv:2312.12536</a> (cross-list from physics.soc-ph) [<a href="/pdf/2312.12536" title="Download PDF">pdf</a>, <a href="/format/2312.12536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Stochastic Block Hypergraph model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Pister%2C+A">Alexis Pister</a>, 
<a href="/search/physics?searchtype=author&query=Barthelemy%2C+M">Marc Barthelemy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Statistical Mechanics (cond-mat.stat-mech); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">We propose a simple model for a hypergraph generalization of the stochastic
block model, using the clustering connection probability $P_{ij}$ between
communities $i$ and $j$, and integrating explicitly the hyperedge formation
process. Indeed, hyperedges are groups of nodes and we can expect that
different real-world networks correspond to different formation processes of
these groups and to different levels of homophily between nodes. We describe a
simple model where we can explicitly introduce the hyperedge formation process
and study its impact on the composition of hyperedges. We focus on the standard
case where $P_{ij}=p\delta_{ij}+q(1-\delta_{ij})$, and when $0\leq q\leq p$, we
show that the degree and hyperedge size distributions can be approximated by
binomials with effective parameters that depend on the number of communities
and on $q/p$. Also, the composition of hyperedges goes for $q=0$ from `pure'
hyperedges (comprising nodes belonging to the same community) to `mixed'
hyperedges that comprise nodes from different communities for $q=p$. We tested
various formation processes and our results suggest that when they depend on
the composition of the hyperedge, they tend to favor the dominant community and
lead to hyperedges with a smaller diversity. In contrast, for formation
processes that are independent from the hyperedge structure, we obtain
hyperedges comprising a larger diversity of communities. The advantages of the
model proposed here are its simplicity and flexibility that make it a good
candidate for testing community-related problems, from their detection to their
impact on various dynamics.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12587" title="Abstract">arXiv:2312.12587</a> (cross-list from eess.SP) [<a href="/pdf/2312.12587" title="Download PDF">pdf</a>, <a href="/format/2312.12587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Diagnostic Integrity Meets Efficiency: A Novel  Platform-Agnostic Architecture for Physiological Signal Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Vora%2C+N+R">Neel R Vora</a>, 
<a href="/search/eess?searchtype=author&query=Hajighasemi%2C+A">Amir Hajighasemi</a>, 
<a href="/search/eess?searchtype=author&query=Reynolds%2C+C+T">Cody T. Reynolds</a>, 
<a href="/search/eess?searchtype=author&query=Radmehr%2C+A">Amirmohammad Radmehr</a>, 
<a href="/search/eess?searchtype=author&query=Mohamed%2C+M">Mohamed Mohamed</a>, 
<a href="/search/eess?searchtype=author&query=Saurav%2C+J+R">Jillur Rahman Saurav</a>, 
<a href="/search/eess?searchtype=author&query=Aziz%2C+A">Abdul Aziz</a>, 
<a href="/search/eess?searchtype=author&query=Veerla%2C+J+P">Jai Prakash Veerla</a>, 
<a href="/search/eess?searchtype=author&query=Nasr%2C+M+S">Mohammad S Nasr</a>, 
<a href="/search/eess?searchtype=author&query=Lotspeich%2C+H">Hayden Lotspeich</a>, 
<a href="/search/eess?searchtype=author&query=Guttikonda%2C+P+S">Partha Sai Guttikonda</a>, 
<a href="/search/eess?searchtype=author&query=Pham%2C+T">Thuong Pham</a>, 
<a href="/search/eess?searchtype=author&query=Darji%2C+A">Aarti Darji</a>, 
<a href="/search/eess?searchtype=author&query=Malidarreh%2C+P+B">Parisa Boodaghi Malidarreh</a>, 
<a href="/search/eess?searchtype=author&query=Shang%2C+H+H">Helen H Shang</a>, 
<a href="/search/eess?searchtype=author&query=Harvey%2C+J">Jay Harvey</a>, 
<a href="/search/eess?searchtype=author&query=Ding%2C+K">Kan Ding</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+P">Phuc Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Luber%2C+J+M">Jacob M Luber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Tissues and Organs (q-bio.TO)

</div>
<p class="mathjax">Head-based signals such as EEG, EMG, EOG, and ECG collected by wearable
systems will play a pivotal role in clinical diagnosis, monitoring, and
treatment of important brain disorder diseases.
<br />However, the real-time transmission of the significant corpus physiological
signals over extended periods consumes substantial power and time, limiting the
viability of battery-dependent physiological monitoring wearables.
<br />This paper presents a novel deep-learning framework employing a variational
autoencoder (VAE) for physiological signal compression to reduce wearables'
computational complexity and energy consumption.
<br />Our approach achieves an impressive compression ratio of 1:293 specifically
for spectrogram data, surpassing state-of-the-art compression techniques such
as JPEG2000, H.264, Direct Cosine Transform (DCT), and Huffman Encoding, which
do not excel in handling physiological signals.
<br />We validate the efficacy of the compressed algorithms using collected
physiological signals from real patients in the Hospital and deploy the
solution on commonly used embedded AI chips (i.e., ARM Cortex V8 and Jetson
Nano). The proposed framework achieves a 91{\%} seizure detection accuracy
using XGBoost, confirming the approach's reliability, practicality, and
scalability.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12599" title="Abstract">arXiv:2312.12599</a> (cross-list from eess.IV) [<a href="/pdf/2312.12599" title="Download PDF">pdf</a>, <a href="/format/2312.12599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Segmentation of Colonoscopy Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yao%2C+H">Heming Yao</a>, 
<a href="/search/eess?searchtype=author&query=L%C3%BCscher%2C+J">J&#xe9;r&#xf4;me L&#xfc;scher</a>, 
<a href="/search/eess?searchtype=author&query=Becker%2C+B+G">Benjamin Gutierrez Becker</a>, 
<a href="/search/eess?searchtype=author&query=Ar%C3%BAs-Pous%2C+J">Josep Ar&#xfa;s-Pous</a>, 
<a href="/search/eess?searchtype=author&query=Biancalani%2C+T">Tommaso Biancalani</a>, 
<a href="/search/eess?searchtype=author&query=Bigorgne%2C+A">Amelie Bigorgne</a>, 
<a href="/search/eess?searchtype=author&query=Richmond%2C+D">David Richmond</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Colonoscopy plays a crucial role in the diagnosis and prognosis of various
gastrointestinal diseases. Due to the challenges of collecting large-scale
high-quality ground truth annotations for colonoscopy images, and more
generally medical images, we explore using self-supervised features from vision
transformers in three challenging tasks for colonoscopy images. Our results
indicate that image-level features learned from DINO models achieve image
classification performance comparable to fully supervised models, and
patch-level features contain rich semantic information for object detection.
Furthermore, we demonstrate that self-supervised features combined with
unsupervised segmentation can be used to discover multiple clinically relevant
structures in a fully unsupervised manner, demonstrating the tremendous
potential of applying these methods in medical image analysis.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12610" title="Abstract">arXiv:2312.12610</a> (cross-list from physics.plasm-ph) [<a href="/pdf/2312.12610" title="Download PDF">pdf</a>, <a href="/format/2312.12610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing predictive capabilities in fusion burning plasmas through  surrogate-based optimization in core transport solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Rodriguez-Fernandez%2C+P">P. Rodriguez-Fernandez</a>, 
<a href="/search/physics?searchtype=author&query=Howard%2C+N+T">N.T. Howard</a>, 
<a href="/search/physics?searchtype=author&query=Saltzman%2C+A">A. Saltzman</a>, 
<a href="/search/physics?searchtype=author&query=Kantamneni%2C+S">S. Kantamneni</a>, 
<a href="/search/physics?searchtype=author&query=Candy%2C+J">J. Candy</a>, 
<a href="/search/physics?searchtype=author&query=Holland%2C+C">C. Holland</a>, 
<a href="/search/physics?searchtype=author&query=Balandat%2C+M">M. Balandat</a>, 
<a href="/search/physics?searchtype=author&query=Ament%2C+S">S. Ament</a>, 
<a href="/search/physics?searchtype=author&query=White%2C+A+E">A.E. White</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Plasma Physics (physics.plasm-ph)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">This work presents the PORTALS framework, which leverages surrogate modeling
and optimization techniques to enable the prediction of core plasma profiles
and performance with nonlinear gyrokinetic simulations at significantly reduced
cost, with no loss of accuracy. The efficiency of PORTALS is benchmarked
against standard methods, and its full potential is demonstrated on a unique,
simultaneous 5-channel (electron temperature, ion temperature, electron
density, impurity density and angular rotation) prediction of steady-state
profiles in a DIII-D ITER Similar Shape plasma with GPU-accelerated, nonlinear
CGYRO. This paper also provides general guidelines for accurate performance
predictions in burning plasmas and the impact of transport modeling in fusion
pilot plants studies.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12612" title="Abstract">arXiv:2312.12612</a> (cross-list from econ.TH) [<a href="/pdf/2312.12612" title="Download PDF">pdf</a>, <a href="/format/2312.12612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Control Barrier Functions for Economics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=van+Wijk%2C+D">David van Wijk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Control barrier functions (CBFs) and safety-critical control have seen a
rapid increase in popularity in recent years, predominantly applied to systems
in aerospace, robotics and neural network controllers. Control barrier
functions can provide a computationally efficient method to monitor arbitrary
primary controllers and enforce state constraints to ensure overall system
safety. One area that has yet to take advantage of the benefits offered by CBFs
is the field of finance and economics. This manuscript re-introduces three
applications of traditional control to economics, and develops and implements
CBFs for such problems. We consider the problem of optimal advertising for the
deterministic and stochastic case and Merton's portfolio optimization problem.
Numerical simulations are used to demonstrate the effectiveness of using
traditional control solutions in tandem with CBFs and stochastic CBFs to solve
such problems in the presence of state constraints.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12616" title="Abstract">arXiv:2312.12616</a> (cross-list from stat.ML) [<a href="/pdf/2312.12616" title="Download PDF">pdf</a>, <a href="/format/2312.12616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Variational Sequential Monte Carlo
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Mastrototaro%2C+A">Alessandro Mastrototaro</a>, 
<a href="/search/stat?searchtype=author&query=Olsson%2C+J">Jimmy Olsson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Being the most classical generative model for serial data, state-space models
(SSM) are fundamental in AI and statistical machine learning. In SSM, any form
of parameter learning or latent state inference typically involves the
computation of complex latent-state posteriors. In this work, we build upon the
variational sequential Monte Carlo (VSMC) method, which provides
computationally efficient and accurate model parameter estimation and Bayesian
latent-state inference by combining particle methods and variational inference.
While standard VSMC operates in the offline mode, by re-processing repeatedly a
given batch of data, we distribute the approximation of the gradient of the
VSMC surrogate ELBO in time using stochastic approximation, allowing for online
learning in the presence of streams of data. This results in an algorithm,
online VSMC, that is capable of performing efficiently, entirely on-the-fly,
both parameter estimation and particle proposal adaptation. In addition, we
provide rigorous theoretical results describing the algorithm's convergence
properties as the number of data tends to infinity as well as numerical
illustrations of its excellent convergence properties and usefulness also in
batch-processing settings.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12618" title="Abstract">arXiv:2312.12618</a> (cross-list from math.CO) [<a href="/pdf/2312.12618" title="Download PDF">pdf</a>, <a href="/format/2312.12618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automating Weight Function Generation in Graph Pebbling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Flocco%2C+D">Dominic Flocco</a>, 
<a href="/search/math?searchtype=author&query=Pulaj%2C+J">Jonad Pulaj</a>, 
<a href="/search/math?searchtype=author&query=Yerger%2C+C">Carl Yerger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Graph pebbling is a combinatorial game played on an undirected graph with an
initial configuration of pebbles. A pebbling move consists of removing two
pebbles from one vertex and placing one pebble on an adjacent vertex. The
pebbling number of a graph is the smallest number of pebbles necessary such
that, given any initial configuration of pebbles, at least one pebble can be
moved to a specified root vertex. Recent lines of inquiry apply computational
techniques to pebbling bound generation and improvement.
<br />Along these lines, we present a computational framework that produces a set
of tree strategy weight functions that are capable of proving pebbling number
upper bounds on a connected graph. Our mixed-integer linear programming
approach automates the generation of large sets of such functions and provides
verifiable certificates of pebbling number upper bounds. The framework is
capable of producing verifiable pebbling bounds on any connected graph,
regardless of its structure or pebbling properties. We apply the model to the
4th weak Bruhat to prove $\pi(B_4) \leq 66$ and to the Lemke square graph to
produce a set of certificates that verify $\pi(L x L) \leq 96$.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12625" title="Abstract">arXiv:2312.12625</a> (cross-list from eess.SP) [<a href="/pdf/2312.12625" title="Download PDF">pdf</a>, <a href="/format/2312.12625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calibrating Wireless Ray Tracing for Digital Twinning using Local Phase  Error Estimates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ruah%2C+C">Clement Ruah</a>, 
<a href="/search/eess?searchtype=author&query=Simeone%2C+O">Osvaldo Simeone</a>, 
<a href="/search/eess?searchtype=author&query=Hoydis%2C+J">Jakob Hoydis</a>, 
<a href="/search/eess?searchtype=author&query=Al-Hashimi%2C+B">Bashir Al-Hashimi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Embodying the principle of simulation intelligence, digital twin (DT) systems
construct and maintain a high-fidelity virtual model of a physical system. This
paper focuses on ray tracing (RT), which is widely seen as an enabling
technology for DTs of the radio access network (RAN) segment of next-generation
disaggregated wireless systems. RT makes it possible to simulate channel
conditions, enabling data augmentation and prediction-based transmission.
However, the effectiveness of RT hinges on the adaptation of the
electromagnetic properties assumed by the RT to actual channel conditions, a
process known as calibration. The main challenge of RT calibration is the fact
that small discrepancies in the geometric model fed to the RT software hinder
the accuracy of the predicted phases of the simulated propagation paths.
Existing solutions to this problem either rely on the channel power profile,
hence disregarding phase information, or they operate on the channel responses
by assuming the simulated phases to be sufficiently accurate for calibration.
This paper proposes a novel channel response-based scheme that, unlike the
state of the art, estimates and compensates for the phase errors in the
RT-generated channel responses. The proposed approach builds on the variational
expectation maximization algorithm with a flexible choice of the prior
phase-error distribution that bridges between a deterministic model with no
phase errors and a stochastic model with uniform phase errors. The algorithm is
computationally efficient, and is demonstrated, by leveraging the open-source
differentiable RT software available within the Sionna library, to outperform
existing methods in terms of the accuracy of RT predictions.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12630" title="Abstract">arXiv:2312.12630</a> (cross-list from math.DS) [<a href="/pdf/2312.12630" title="Download PDF">pdf</a>, <a href="/format/2312.12630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven discovery with Limited Data Acquisition for fluid flow  across cylinder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Singh%2C+D+H">Dr. Himanshu Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 Pages, 16 Figures, JULIA Coding Result for Dynamic Mode Decomposition, Part of this work selected for 42nd Annual Dynamic Days 2024 Conference (January 8 to 10) at University of California, Davis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Machine Learning (cs.LG); Complex Variables (math.CV); Functional Analysis (math.FA); Spectral Theory (math.SP)

</div>
<p class="mathjax">One of the central challenge for extracting governing principles of dynamical
system via Dynamic Mode Decomposition (DMD) is about the limit data
availability or formally called as Limited Data Acquisition in the present
paper. In the interest of discovering the governing principles for a dynamical
system with limited data acquisition, we provide a variant of Kernelized
Extended DMD (KeDMD) based on the Koopman operator which employ the notion of
Gaussian random matrix to recover the dominant Koopman modes for the standard
fluid flow across cylinder experiment. It turns out that the traditional kernel
function, Gaussian Radial Basis Function Kernel, unfortunately, is not able to
generate the desired Koopman modes in the scenario of executing KeDMD with
limited data acquisition. However, the Laplacian Kernel Function successfully
generates the desired Koopman modes when limited data is provided in terms of
data-set snapshot for the aforementioned experiment and this manuscripts serves
the purpose of reporting these exciting experimental insights. This paper also
explores the functionality of the Koopman operator when it interacts with the
reproducing kernel Hilbert space (RKHS) that arises from the normalized
probability Lebesgue measure
$d\mu_{\sigma,1,\mathbb{C}^n}(z)=(2\pi\sigma^2)^{-n}\exp\left(-\frac{\|z\|_2}{\sigma}\right)dV(z)$
when it is embedded in $L^2-$sense for the holomorphic functions over
$\mathbb{C}^n$, in the aim of determining the Koopman modes for fluid flow
across cylinder experiment. We explore the operator-theoretic characterizations
of the Koopman operator on the RKHS generated by the normalized Laplacian
measure $d\mu_{\sigma,1,\mathbb{C}^n}(z)$ in the $L^2-$sense. In doing so, we
provide the compactification &amp; closable characterization of Koopman operator
over the RKHS generated by the normalized Laplacian measure in the $L^2-$sense.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12641" title="Abstract">arXiv:2312.12641</a> (cross-list from stat.ME) [<a href="/pdf/2312.12641" title="Download PDF">pdf</a>, <a href="/format/2312.12641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matching via Distance Profiles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hur%2C+Y">YoonHaeng Hur</a>, 
<a href="/search/stat?searchtype=author&query=Khoo%2C+Y">Yuehaw Khoo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">In this paper, we introduce and study matching methods based on distance
profiles. For the matching of point clouds, the proposed method is easily
implementable by solving a linear program, circumventing the computational
obstacles of quadratic matching. Also, we propose and analyze a flexible way to
execute location-to-location matching using distance profiles. Moreover, we
provide a statistical estimation error analysis in the context of
location-to-location matching using empirical process theory. Furthermore, we
apply our method to a certain model and show its noise stability by
characterizing conditions on the noise level for the matching to be successful.
Lastly, we demonstrate the performance of the proposed method and compare it
with some existing methods using synthetic and real data.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12644" title="Abstract">arXiv:2312.12644</a> (cross-list from eess.IV) [<a href="/pdf/2312.12644" title="Download PDF">pdf</a>, <a href="/format/2312.12644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rotational Augmented Noise2Inverse for Low-dose Computed Tomography  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+H">Hang Xu</a>, 
<a href="/search/eess?searchtype=author&query=Perelli%2C+A">Alessandro Perelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 12 figures, accepted manuscript in IEEE Transactions on Radiation and Plasma Medical Sciences
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">In this work, we present a novel self-supervised method for Low Dose Computed
Tomography (LDCT) reconstruction. Reducing the radiation dose to patients
during a CT scan is a crucial challenge since the quality of the reconstruction
highly degrades because of low photons or limited measurements. Supervised deep
learning methods have shown the ability to remove noise in images but require
accurate ground truth which can be obtained only by performing additional
high-radiation CT scans. Therefore, we propose a novel self-supervised
framework for LDCT, in which ground truth is not required for training the
convolutional neural network (CNN). Based on the Noise2Inverse (N2I) method, we
enforce in the training loss the equivariant property of rotation
transformation, which is induced by the CT imaging system, to improve the
quality of the CT image in a lower dose. Numerical and experimental results
show that the reconstruction accuracy of N2I with sparse views is degrading
while the proposed rotational augmented Noise2Inverse (RAN2I) method keeps
better image quality over a different range of sampling angles. Finally, the
quantitative results demonstrate that RAN2I achieves higher image quality
compared to N2I, and experimental results of RAN2I on real projection data show
comparable performance to supervised learning.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12649" title="Abstract">arXiv:2312.12649</a> (cross-list from eess.IV) [<a href="/pdf/2312.12649" title="Download PDF">pdf</a>, <a href="/format/2312.12649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Surf-CDM: Score-Based Surface Cold-Diffusion Model For Medical Image  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zaman%2C+F+A">Fahim Ahmed Zaman</a>, 
<a href="/search/eess?searchtype=author&query=Jacob%2C+M">Mathews Jacob</a>, 
<a href="/search/eess?searchtype=author&query=Chang%2C+A">Amanda Chang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+K">Kan Liu</a>, 
<a href="/search/eess?searchtype=author&query=Sonka%2C+M">Milan Sonka</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+X">Xiaodong Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Diffusion models have shown impressive performance for image generation,
often times outperforming other generative models. Since their introduction,
researchers have extended the powerful noise-to-image denoising pipeline to
discriminative tasks, including image segmentation. In this work we propose a
conditional score-based generative modeling framework for medical image
segmentation which relies on a parametric surface representation for the
segmentation masks. The surface re-parameterization allows the direct
application of standard diffusion theory, as opposed to when the mask is
represented as a binary mask. Moreover, we adapted an extended variant of the
diffusion technique known as the "cold-diffusion" where the diffusion model can
be constructed with deterministic perturbations instead of Gaussian noise,
which facilitates significantly faster convergence in the reverse diffusion. We
evaluated our method on the segmentation of the left ventricle from 65
transthoracic echocardiogram videos (2230 echo image frames) and compared its
performance to the most popular and widely used image segmentation models. Our
proposed model not only outperformed the compared methods in terms of
segmentation accuracy, but also showed potential in estimating segmentation
uncertainties for further downstream analyses due to its inherent generative
nature.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12653" title="Abstract">arXiv:2312.12653</a> (cross-list from eess.IV) [<a href="/pdf/2312.12653" title="Download PDF">pdf</a>, <a href="/format/2312.12653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diagnosis Of Takotsubo Syndrome By Robust Feature Selection From The  Complex Latent Space Of DL-based Segmentation Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zaman%2C+F+A">Fahim Ahmed Zaman</a>, 
<a href="/search/eess?searchtype=author&query=Alam%2C+W">Wahidul Alam</a>, 
<a href="/search/eess?searchtype=author&query=Roy%2C+T+K">Tarun Kanti Roy</a>, 
<a href="/search/eess?searchtype=author&query=Chang%2C+A">Amanda Chang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+K">Kan Liu</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+X">Xiaodong Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Researchers have shown significant correlations among segmented objects in
various medical imaging modalities and disease related pathologies. Several
studies showed that using hand crafted features for disease prediction neglects
the immense possibility to use latent features from deep learning (DL) models
which may reduce the overall accuracy of differential diagnosis. However,
directly using classification or segmentation models on medical to learn latent
features opt out robust feature selection and may lead to overfitting. To fill
this gap, we propose a novel feature selection technique using the latent space
of a segmentation model that can aid diagnosis. We evaluated our method in
differentiating a rare cardiac disease: Takotsubo Syndrome (TTS) from the ST
elevation myocardial infarction (STEMI) using echocardiogram videos (echo). TTS
can mimic clinical features of STEMI in echo and extremely hard to distinguish.
Our approach shows promising results in differential diagnosis of TTS with 82%
diagnosis accuracy beating the previous state-of-the-art (SOTA) approach.
Moreover, the robust feature selection technique using LASSO algorithm shows
great potential in reducing the redundant features and creates a robust
pipeline for short- and long-term disease prognoses in the downstream analysis.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12678" title="Abstract">arXiv:2312.12678</a> (cross-list from q-bio.QM) [<a href="/pdf/2312.12678" title="Download PDF">pdf</a>, <a href="/format/2312.12678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Discovery for fMRI data: Challenges, Solutions, and a Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Rawls%2C+E">Eric Rawls</a>, 
<a href="/search/q-bio?searchtype=author&query=Andrews%2C+B">Bryan Andrews</a>, 
<a href="/search/q-bio?searchtype=author&query=Lim%2C+K">Kelvin Lim</a>, 
<a href="/search/q-bio?searchtype=author&query=Kummerfeld%2C+E">Erich Kummerfeld</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">Designing studies that apply causal discovery requires navigating many
researcher degrees of freedom. This complexity is exacerbated when the study
involves fMRI data. In this paper we (i) describe nine challenges that occur
when applying causal discovery to fMRI data, (ii) discuss the space of
decisions that need to be made, (iii) review how a recent case study made those
decisions, (iv) and identify existing gaps that could potentially be solved by
the development of new methods. Overall, causal discovery is a promising
approach for analyzing fMRI data, and multiple successful applications have
indicated that it is superior to traditional fMRI functional connectivity
methods, but current causal discovery methods for fMRI leave room for
improvement.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12685" title="Abstract">arXiv:2312.12685</a> (cross-list from math.AG) [<a href="/pdf/2312.12685" title="Download PDF">pdf</a>, <a href="/format/2312.12685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using monodromy to recover symmetries of polynomial systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Duff%2C+T">Timothy Duff</a>, 
<a href="/search/math?searchtype=author&query=Korotynskiy%2C+V">Viktor Korotynskiy</a>, 
<a href="/search/math?searchtype=author&query=Pajdla%2C+T">Tomas Pajdla</a>, 
<a href="/search/math?searchtype=author&query=Regan%2C+M">Margaret Regan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended journal version of conference paper published at ISSAC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Geometry (math.AG)</span>; Mathematical Software (cs.MS)

</div>
<p class="mathjax">Galois/monodromy groups attached to parametric systems of polynomial
equations provide a method for detecting the existence of symmetries in
solution sets. Beyond the question of existence, one would like to compute
formulas for these symmetries, towards the eventual goal of solving the systems
more efficiently. We describe and implement one possible approach to this task
using numerical homotopy continuation and multivariate rational function
interpolation. We describe additional methods that detect and exploit a priori
unknown quasi-homogeneous structure in symmetries. These methods extend the
range of interpolation to larger examples, including applications with
nonlinear symmetries drawn from vision and robotics.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12700" title="Abstract">arXiv:2312.12700</a> (cross-list from econ.TH) [<a href="/pdf/2312.12700" title="Download PDF">pdf</a>, <a href="/format/2312.12700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance rating in chess, tennis, and other contexts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Ismail%2C+M+S">Mehmet S. Ismail</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">In this note, I introduce Estimated Performance Rating (PR$^e$), a novel
system for evaluating player performance in sports and games. PR$^e$ addresses
a key limitation of the Tournament Performance Rating (TPR) system, which is
undefined for zero or perfect scores in a series of games. PR$^e$ is defined as
the rating that solves an optimization problem related to scoring probability,
making it applicable for any performance level. The main theorem establishes
that the PR$^e$ of a player is equivalent to the TPR whenever the latter is
defined. I then apply this system to historically significant win-streaks in
association football, tennis, and chess. Beyond sports, PR$^e$ has broad
applicability in domains where Elo ratings are used, from college rankings to
the evaluation of large language models.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12715" title="Abstract">arXiv:2312.12715</a> (cross-list from stat.ML) [<a href="/pdf/2312.12715" title="Download PDF">pdf</a>, <a href="/format/2312.12715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Performance Maximizing Ensembles with Explainability Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Pisztora%2C+V">Vincent Pisztora</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+J">Jia Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper we propose a method for the optimal allocation of observations
between an intrinsically explainable glass box model and a black box model. An
optimal allocation being defined as one which, for any given explainability
level (i.e. the proportion of observations for which the explainable model is
the prediction function), maximizes the performance of the ensemble on the
underlying task, and maximizes performance of the explainable model on the
observations allocated to it, subject to the maximal ensemble performance
condition. The proposed method is shown to produce such explainability optimal
allocations on a benchmark suite of tabular datasets across a variety of
explainable and black box model types. These learned allocations are found to
consistently maintain ensemble performance at very high explainability levels
(explaining $74\%$ of observations on average), and in some cases even
outperforming both the component explainable and black box models while
improving explainability.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12764" title="Abstract">arXiv:2312.12764</a> (cross-list from eess.AS) [<a href="/pdf/2312.12764" title="Download PDF">pdf</a>, <a href="/ps/2312.12764" title="Download PostScript">ps</a>, <a href="/format/2312.12764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lattice Rescoring Based on Large Ensemble of Complementary Neural  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ogawa%2C+A">Atsunori Ogawa</a>, 
<a href="/search/eess?searchtype=author&query=Tawara%2C+N">Naohiro Tawara</a>, 
<a href="/search/eess?searchtype=author&query=Delcroix%2C+M">Marc Delcroix</a>, 
<a href="/search/eess?searchtype=author&query=Araki%2C+S">Shoko Araki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)

</div>
<p class="mathjax">We investigate the effectiveness of using a large ensemble of advanced neural
language models (NLMs) for lattice rescoring on automatic speech recognition
(ASR) hypotheses. Previous studies have reported the effectiveness of combining
a small number of NLMs. In contrast, in this study, we combine up to eight
NLMs, i.e., forward/backward long short-term memory/Transformer-LMs that are
trained with two different random initialization seeds. We combine these NLMs
through iterative lattice generation. Since these NLMs work complementarily
with each other, by combining them one by one at each rescoring iteration,
language scores attached to given lattice arcs can be gradually refined.
Consequently, errors of the ASR hypotheses can be gradually reduced. We also
investigate the effectiveness of carrying over contextual information (previous
rescoring results) across a lattice sequence of a long speech such as a lecture
speech. In experiments using a lecture speech corpus, by combining the eight
NLMs and using context carry-over, we obtained a 24.4% relative word error rate
reduction from the ASR 1-best baseline. For further comparison, we performed
simultaneous (i.e., non-iterative) NLM combination and 100-best rescoring using
the large ensemble of NLMs, which confirmed the advantage of lattice rescoring
with iterative NLM combination.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12783" title="Abstract">arXiv:2312.12783</a> (cross-list from eess.AS) [<a href="/pdf/2312.12783" title="Download PDF">pdf</a>, <a href="/format/2312.12783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable Distillation: Regularizing Continued Pre-training for  Low-Resource Automatic Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Seth%2C+A">Ashish Seth</a>, 
<a href="/search/eess?searchtype=author&query=Ghosh%2C+S">Sreyan Ghosh</a>, 
<a href="/search/eess?searchtype=author&query=Umesh%2C+S">S. Umesh</a>, 
<a href="/search/eess?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024. Code: <a href="https://github.com/cs20s030/stable_distillation">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Sound (cs.SD)

</div>
<p class="mathjax">Continued self-supervised (SSL) pre-training for adapting existing SSL models
to the target domain has shown to be extremely effective for low-resource
Automatic Speech Recognition (ASR). This paper proposes Stable Distillation, a
simple and novel approach for SSL-based continued pre-training that boosts ASR
performance in the target domain where both labeled and unlabeled data are
limited. Stable Distillation employs self-distillation as regularization for
continued pre-training, alleviating the over-fitting issue, a common problem
continued pre-training faces when the source and target domains differ.
Specifically, first, we perform vanilla continued pre-training on an initial
SSL pre-trained model on the target domain ASR dataset and call it the teacher.
Next, we take the same initial pre-trained model as a student to perform
continued pre-training while enforcing its hidden representations to be close
to that of the teacher (via MSE loss). This student is then used for downstream
ASR fine-tuning on the target dataset. In practice, Stable Distillation
outperforms all our baselines by 0.8 - 7 WER when evaluated in various
experimental settings.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12789" title="Abstract">arXiv:2312.12789</a> (cross-list from eess.IV) [<a href="/pdf/2312.12789" title="Download PDF">pdf</a>, <a href="/format/2312.12789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SLP-Net:An efficient lightweight network for segmentation of skin  lesions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+B">Bo Yang</a>, 
<a href="/search/eess?searchtype=author&query=Peng%2C+H">Hong Peng</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+C">Chenggang Guo</a>, 
<a href="/search/eess?searchtype=author&query=Luo%2C+X">Xiaohui Luo</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/eess?searchtype=author&query=Long%2C+X">Xianzhong Long</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Prompt treatment for melanoma is crucial. To assist physicians in identifying
lesion areas precisely in a quick manner, we propose a novel skin lesion
segmentation technique namely SLP-Net, an ultra-lightweight segmentation
network based on the spiking neural P(SNP) systems type mechanism. Most
existing convolutional neural networks achieve high segmentation accuracy while
neglecting the high hardware cost. SLP-Net, on the contrary, has a very small
number of parameters and a high computation speed. We design a lightweight
multi-scale feature extractor without the usual encoder-decoder structure.
Rather than a decoder, a feature adaptation module is designed to replace it
and implement multi-scale information decoding. Experiments at the ISIC2018
challenge demonstrate that the proposed model has the highest Acc and DSC among
the state-of-the-art methods, while experiments on the PH2 dataset also
demonstrate a favorable generalization ability. Finally, we compare the
computational complexity as well as the computational speed of the models in
experiments, where SLP-Net has the highest overall superiority
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12810" title="Abstract">arXiv:2312.12810</a> (cross-list from eess.AS) [<a href="/pdf/2312.12810" title="Download PDF">pdf</a>, <a href="/format/2312.12810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unconstrained Dysfluency Modeling for Dysfluent Speech Transcription and  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lian%2C+J">Jiachen Lian</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+C">Carly Feng</a>, 
<a href="/search/eess?searchtype=author&query=Farooqi%2C+N">Naasir Farooqi</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Steve Li</a>, 
<a href="/search/eess?searchtype=author&query=Kashyap%2C+A">Anshul Kashyap</a>, 
<a href="/search/eess?searchtype=author&query=Cho%2C+C+J">Cheol Jun Cho</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+P">Peter Wu</a>, 
<a href="/search/eess?searchtype=author&query=Netzorg%2C+R">Robbie Netzorg</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+T">Tingle Li</a>, 
<a href="/search/eess?searchtype=author&query=Anumanchipalli%2C+G+K">Gopala Krishna Anumanchipalli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 ASRU
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Dysfluent speech modeling requires time-accurate and silence-aware
transcription at both the word-level and phonetic-level. However, current
research in dysfluency modeling primarily focuses on either transcription or
detection, and the performance of each aspect remains limited. In this work, we
present an unconstrained dysfluency modeling (UDM) approach that addresses both
transcription and detection in an automatic and hierarchical manner. UDM
eliminates the need for extensive manual annotation by providing a
comprehensive solution. Furthermore, we introduce a simulated dysfluent dataset
called VCTK++ to enhance the capabilities of UDM in phonetic transcription. Our
experimental results demonstrate the effectiveness and robustness of our
proposed methods in both transcription and detection tasks.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12821" title="Abstract">arXiv:2312.12821</a> (cross-list from eess.AS) [<a href="/pdf/2312.12821" title="Download PDF">pdf</a>, <a href="/format/2312.12821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CST-former: Transformer with Channel-Spectro-Temporal Attention for  Sound Event Localization and Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shul%2C+Y">Yusun Shul</a>, 
<a href="/search/eess?searchtype=author&query=Choi%2C+J">Jung-Woo Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Sound event localization and detection (SELD) is a task for the
classification of sound events and the localization of direction of arrival
(DoA) utilizing multichannel acoustic signals. Prior studies employ spectral
and channel information as the embedding for temporal attention. However, this
usage limits the deep neural network from extracting meaningful features from
the spectral or spatial domains. Therefore, our investigation in this paper
presents a novel framework termed the Channel-Spectro-Temporal Transformer
(CST-former) that bolsters SELD performance through the independent application
of attention mechanisms to distinct domains. The CST-former architecture
employs distinct attention mechanisms to independently process channel,
spectral, and temporal information. In addition, we propose an unfolded local
embedding (ULE) technique for channel attention (CA) to generate informative
embedding vectors including local spectral and temporal information. Empirical
validation through experimentation on the 2022 and 2023 DCASE Challenge task3
datasets affirms the efficacy of employing attention mechanisms separated
across each domain and the benefit of ULE, in enhancing SELD performance.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12824" title="Abstract">arXiv:2312.12824</a> (cross-list from eess.IV) [<a href="/pdf/2312.12824" title="Download PDF">pdf</a>, <a href="/format/2312.12824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedSODA: Federated Cross-assessment and Dynamic Aggregation for  Histopathology Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yuan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Qi%2C+Y">Yaolei Qi</a>, 
<a href="/search/eess?searchtype=author&query=Qi%2C+X">Xiaoming Qi</a>, 
<a href="/search/eess?searchtype=author&query=Senhadji%2C+L">Lotfi Senhadji</a>, 
<a href="/search/eess?searchtype=author&query=Wei%2C+Y">Yongyue Wei</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+F">Feng Chen</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+G">Guanyu Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Federated learning (FL) for histopathology image segmentation involving
multiple medical sites plays a crucial role in advancing the field of accurate
disease diagnosis and treatment. However, it is still a task of great
challenges due to the sample imbalance across clients and large data
heterogeneity from disparate organs, variable segmentation tasks, and diverse
distribution. Thus, we propose a novel FL approach for histopathology nuclei
and tissue segmentation, FedSODA, via synthetic-driven cross-assessment
operation (SO) and dynamic stratified-layer aggregation (DA). Our SO constructs
a cross-assessment strategy to connect clients and mitigate the representation
bias under sample imbalance. Our DA utilizes layer-wise interaction and dynamic
aggregation to diminish heterogeneity and enhance generalization. The
effectiveness of our FedSODA has been evaluated on the most extensive
histopathology image segmentation dataset from 7 independent datasets. The code
is available at https://github.com/yuanzhang7/FedSODA.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12833" title="Abstract">arXiv:2312.12833</a> (cross-list from eess.IV) [<a href="/pdf/2312.12833" title="Download PDF">pdf</a>, <a href="/format/2312.12833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Exhaustive Correlation for Spectral Super-Resolution: Where  Unified Spatial-Spectral Attention Meets Mutual Linear Dependence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Hongyuan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+L">Lizhi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+J">Jiang Xu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+C">Chang Chen</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+X">Xue Hu</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+F">Fenglong Song</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+Y">Youliang Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Spectral super-resolution from the easily obtainable RGB image to
hyperspectral image (HSI) has drawn increasing interest in the field of
computational photography. The crucial aspect of spectral super-resolution lies
in exploiting the correlation within HSIs. However, two types of bottlenecks in
existing Transformers limit performance improvement and practical applications.
First, existing Transformers often separately emphasize either spatial-wise or
spectral-wise correlation, disrupting the 3D features of HSI and hindering the
exploitation of unified spatial-spectral correlation. Second, the existing
self-attention mechanism learns the correlation between pairs of tokens and
captures the full-rank correlation matrix, leading to its inability to
establish mutual linear dependence among multiple tokens. To address these
issues, we propose a novel Exhaustive Correlation Transformer (ECT) for
spectral super-resolution. First, we propose a Spectral-wise Discontinuous 3D
(SD3D) splitting strategy, which models unified spatial-spectral correlation by
simultaneously utilizing spatial-wise continuous splitting and spectral-wise
discontinuous splitting. Second, we propose a Dynamic Low-Rank Mapping (DLRM)
model, which captures mutual linear dependence among multiple tokens through a
dynamically calculated low-rank dependence map. By integrating unified
spatial-spectral attention with mutual linear dependence, our ECT can establish
exhaustive correlation within HSI. The experimental results on both simulated
and real data indicate that our method achieves state-of-the-art performance.
Codes and pretrained models will be available later.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12848" title="Abstract">arXiv:2312.12848</a> (cross-list from quant-ph) [<a href="/pdf/2312.12848" title="Download PDF">pdf</a>, <a href="/format/2312.12848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Annealing for Computer Vision Minimization Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Heidari%2C+S">Shahrokh Heidari</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dinneen%2C+M+J">Michael J. Dinneen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Delmas%2C+P">Patrice Delmas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Computer Vision (CV) labelling algorithms play a pivotal role in the domain
of low-level vision. For decades, it has been known that these problems can be
elegantly formulated as discrete energy minimization problems derived from
probabilistic graphical models (such as Markov Random Fields). Despite recent
advances in inference algorithms (such as graph-cut and message-passing
algorithms), the resulting energy minimization problems are generally viewed as
intractable. The emergence of quantum computations, which offer the potential
for faster solutions to certain problems than classical methods, has led to an
increased interest in utilizing quantum properties to overcome intractable
problems. Recently, there has also been a growing interest in Quantum Computer
Vision (QCV), with the hope of providing a credible alternative or assistant to
deep learning solutions in the field. This study investigates a new Quantum
Annealing based inference algorithm for CV discrete energy minimization
problems. Our contribution is focused on Stereo Matching as a significant CV
labeling problem. As a proof of concept, we also use a hybrid quantum-classical
solver provided by D-Wave System to compare our results with the best classical
inference algorithms in the literature.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12876" title="Abstract">arXiv:2312.12876</a> (cross-list from eess.IV) [<a href="/pdf/2312.12876" title="Download PDF">pdf</a>, <a href="/ps/2312.12876" title="Download PostScript">ps</a>, <a href="/format/2312.12876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COVID-19 Diagnosis: ULGFBP-ResNet51 approach on the CT and the Chest  X-ray Images Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Esmaeili%2C+V">Vida Esmaeili</a>, 
<a href="/search/eess?searchtype=author&query=Feghhi%2C+M+M">Mahmood Mohassel Feghhi</a>, 
<a href="/search/eess?searchtype=author&query=Shahdi%2C+S+O">Seyed Omid Shahdi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 8 figures, submitted for possible journal publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The contagious and pandemic COVID-19 disease is currently considered as the
main health concern and posed widespread panic across human-beings. It affects
the human respiratory tract and lungs intensely. So that it has imposed
significant threats for premature death. Although, its early diagnosis can play
a vital role in revival phase, the radiography tests with the manual
intervention are a time-consuming process. Time is also limited for such manual
inspecting of numerous patients in the hospitals. Thus, the necessity of
automatic diagnosis on the chest X-ray or the CT images with a high efficient
performance is urgent. Toward this end, we propose a novel method, named as the
ULGFBP-ResNet51 to tackle with the COVID-19 diagnosis in the images. In fact,
this method includes Uniform Local Binary Pattern (ULBP), Gabor Filter (GF),
and ResNet51. According to our results, this method could offer superior
performance in comparison with the other methods, and attain maximum accuracy.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12880" title="Abstract">arXiv:2312.12880</a> (cross-list from eess.IV) [<a href="/pdf/2312.12880" title="Download PDF">pdf</a>, <a href="/format/2312.12880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing the Segment Anything Model on radiology data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=de+Almeida%2C+J+G">Jos&#xe9; Guilherme de Almeida</a>, 
<a href="/search/eess?searchtype=author&query=Rodrigues%2C+N+M">Nuno M. Rodrigues</a>, 
<a href="/search/eess?searchtype=author&query=Silva%2C+S">Sara Silva</a>, 
<a href="/search/eess?searchtype=author&query=Papanikolaou%2C+N">Nickolas Papanikolaou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning models trained with large amounts of data have become a recent
and effective approach to predictive problem solving -- these have become known
as "foundation models" as they can be used as fundamental tools for other
applications. While the paramount examples of image classification (earlier)
and large language models (more recently) led the way, the Segment Anything
Model (SAM) was recently proposed and stands as the first foundation model for
image segmentation, trained on over 10 million images and with recourse to over
1 billion masks. However, the question remains -- what are the limits of this
foundation? Given that magnetic resonance imaging (MRI) stands as an important
method of diagnosis, we sought to understand whether SAM could be used for a
few tasks of zero-shot segmentation using MRI data. Particularly, we wanted to
know if selecting masks from the pool of SAM predictions could lead to good
segmentations.
<br />Here, we provide a critical assessment of the performance of SAM on magnetic
resonance imaging data. We show that, while acceptable in a very limited set of
cases, the overall trend implies that these models are insufficient for MRI
segmentation across the whole volume, but can provide good segmentations in a
few, specific slices. More importantly, we note that while foundation models
trained on natural images are set to become key aspects of predictive
modelling, they may prove ineffective when used on other imaging modalities.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12881" title="Abstract">arXiv:2312.12881</a> (cross-list from physics.soc-ph) [<a href="/pdf/2312.12881" title="Download PDF">pdf</a>, <a href="/format/2312.12881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Big Tech influence over AI research revisited: memetic analysis of  attribution of ideas to affiliation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Gizi%C5%84ski%2C+S">Stanis&#x142;aw Gizi&#x144;ski</a>, 
<a href="/search/physics?searchtype=author&query=Kaczy%C5%84ska%2C+P">Paulina Kaczy&#x144;ska</a>, 
<a href="/search/physics?searchtype=author&query=Ruczy%C5%84ski%2C+H">Hubert Ruczy&#x144;ski</a>, 
<a href="/search/physics?searchtype=author&query=Wi%C5%9Bnios%2C+E">Emilia Wi&#x15b;nios</a>, 
<a href="/search/physics?searchtype=author&query=Pieli%C5%84ski%2C+B">Bartosz Pieli&#x144;ski</a>, 
<a href="/search/physics?searchtype=author&query=Biecek%2C+P">Przemys&#x142;aw Biecek</a>, 
<a href="/search/physics?searchtype=author&query=Sienkiewicz%2C+J">Julian Sienkiewicz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Computation and Language (cs.CL); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">There exists a growing discourse around the domination of Big Tech on the
landscape of artificial intelligence (AI) research, yet our comprehension of
this phenomenon remains cursory. This paper aims to broaden and deepen our
understanding of Big Tech's reach and power within AI research. It highlights
the dominance not merely in terms of sheer publication volume but rather in the
propagation of new ideas or \textit{memes}. Current studies often oversimplify
the concept of influence to the share of affiliations in academic papers,
typically sourced from limited databases such as arXiv or specific academic
conferences.
<br />The main goal of this paper is to unravel the specific nuances of such
influence, determining which AI ideas are predominantly driven by Big Tech
entities. By employing network and memetic analysis on AI-oriented paper
abstracts and their citation network, we are able to grasp a deeper insight
into this phenomenon. By utilizing two databases: OpenAlex and S2ORC, we are
able to perform such analysis on a much bigger scale than previous attempts.
<br />Our findings suggest, that while Big Tech-affiliated papers are
disproportionately more cited in some areas, the most cited papers are those
affiliated with both Big Tech and Academia. Focusing on the most contagious
memes, their attribution to specific affiliation groups (Big Tech, Academia,
mixed affiliation) seems to be equally distributed between those three groups.
This suggests that the notion of Big Tech domination over AI research is
oversimplified in the discourse.
<br />Ultimately, this more nuanced understanding of Big Tech's and Academia's
influence could inform a more symbiotic alliance between these stakeholders
which would better serve the dual goals of societal welfare and the scientific
integrity of AI research.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12909" title="Abstract">arXiv:2312.12909</a> (cross-list from eess.SP) [<a href="/pdf/2312.12909" title="Download PDF">pdf</a>, <a href="/ps/2312.12909" title="Download PostScript">ps</a>, <a href="/format/2312.12909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-efficient Spiking Neural Network Equalization for IM/DD Systems  with Optimized Neural Encoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=von+Bank%2C+A">Alexander von Bank</a>, 
<a href="/search/eess?searchtype=author&query=Edelmann%2C+E">Eike-Manuel Edelmann</a>, 
<a href="/search/eess?searchtype=author&query=Schmalen%2C+L">Laurent Schmalen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at OFC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">We propose an energy-efficient equalizer for IM/DD systems based on spiking
neural networks. We optimize a neural spike encoding that boosts the
equalizer's performance while decreasing energy consumption.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12919" title="Abstract">arXiv:2312.12919</a> (cross-list from math.CO) [<a href="/pdf/2312.12919" title="Download PDF">pdf</a>, <a href="/format/2312.12919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coloring Grids Avoiding Bicolored Paths
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Keskinkilic%2C+D">Derman Keskinkilic</a>, 
<a href="/search/math?searchtype=author&query=Ozkahya%2C+L">Lale Ozkahya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">The vertex-coloring problem on graphs avoiding bicolored members of a family
of subgraphs has been widely studied. Most well-known examples are star
coloring and acyclic coloring of graphs (Gr\"unbaum, 1973) where bicolored
copies of $P_4$ and cycles are not allowed, respectively. In this paper, we
study a variation of this problem, by considering vertex coloring on grids
forbidding bicolored paths. We let $P_k$-chromatic number of a graph be the
minimum number of colors needed to color the vertex set properly avoiding a
bicolored $P_k.$ We show that in any 3-coloring of the cartesian product of
paths, $P_{k-2}\square P_{k-2}$, there is a bicolored $P_k.$ With our result,
the problem of finding the $P_k$-chromatic number of product of two paths
(2-dimensional grid) is settled for all $k.$
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12960" title="Abstract">arXiv:2312.12960</a> (cross-list from math.CO) [<a href="/pdf/2312.12960" title="Download PDF">pdf</a>, <a href="/ps/2312.12960" title="Download PostScript">ps</a>, <a href="/format/2312.12960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximizing Matching Cuts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Le%2C+V+B">Van Bang Le</a>, 
<a href="/search/math?searchtype=author&query=Lucke%2C+F">Felicia Lucke</a>, 
<a href="/search/math?searchtype=author&query=Paulusma%2C+D">Dani&#xeb;l Paulusma</a>, 
<a href="/search/math?searchtype=author&query=Ries%2C+B">Bernard Ries</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Complexity (cs.CC); Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">A matching cut in a graph G is an edge cut of G that is also a matching. This
short survey gives an overview of old and new results and open problems for
Maximum Matching Cut, which is to determine the size of a largest matching cut
in a graph. We also compare this problem with the related problems Matching
Cut, Minimum Matching Cut, and Perfect Matching Cut, which are to determine if
a graph has a matching cut; the size of a smallest matching cut in a graph; and
if a graph has a matching cut that is a perfect matching, respectively.
Moreover, we discuss a relationship between Maximum Matching Cut and Max Cut,
which is to determine the size of a largest edge cut in a graph, as well as a
relationship between Minimum Matching Cut and Min Cut, which is to determine
the size of a smallest edge cut in a graph.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12990" title="Abstract">arXiv:2312.12990</a> (cross-list from eess.IV) [<a href="/pdf/2312.12990" title="Download PDF">pdf</a>, <a href="/format/2312.12990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-task Learning To Improve Semantic Segmentation Of CBCT Scans Using  Image Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tschuchnig%2C+M+E">Maximilian Ernst Tschuchnig</a>, 
<a href="/search/eess?searchtype=author&query=Coste-Marin%2C+J">Julia Coste-Marin</a>, 
<a href="/search/eess?searchtype=author&query=Steininger%2C+P">Philipp Steininger</a>, 
<a href="/search/eess?searchtype=author&query=Gadermayr%2C+M">Michael Gadermayr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at German Conference on Medical Image Computing (BVM) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Semantic segmentation is a crucial task in medical image processing,
essential for segmenting organs or lesions such as tumors. In this study we aim
to improve automated segmentation in CBCTs through multi-task learning. To
evaluate effects on different volume qualities, a CBCT dataset is synthesised
from the CT Liver Tumor Segmentation Benchmark (LiTS) dataset. To improve
segmentation, two approaches are investigated. First, we perform multi-task
learning to add morphology based regularization through a volume reconstruction
task. Second, we use this reconstruction task to reconstruct the best quality
CBCT (most similar to the original CT), facilitating denoising effects. We
explore both holistic and patch-based approaches. Our findings reveal that,
especially using a patch-based approach, multi-task learning improves
segmentation in most cases and that these results can further be improved by
our denoising approach.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13013" title="Abstract">arXiv:2312.13013</a> (cross-list from eess.SP) [<a href="/pdf/2312.13013" title="Download PDF">pdf</a>, <a href="/ps/2312.13013" title="Download PostScript">ps</a>, <a href="/format/2312.13013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User-Assisted Networked Sensing in OFDM Cellular Network with Erroneous  Anchor Position Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Guo%2C+X">Xianzhen Guo</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+Q">Qin Shi</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+L">Liang Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+S">Shuowen Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In the sixth-generation (6G) integrated sensing and communication (ISAC)
cellular network, base stations (BSs) can collaborate with each other to reap
not only the cooperative communication gain, but also the networked sensing
gain. In contrast to cooperative communication where both line-of-sight (LOS)
paths and non-line-of-sight (NLOS) paths are useful, networked sensing mainly
relies on the LOS paths. However, in practice, the number of BSs possessing LOS
paths to a target can be small, leading to marginal networked sensing gain.
Because the density of user equipments (UEs) is much larger than that of the
BSs, this paper considers a UE-assisted networked sensing architecture, where a
BS transmits communication signals in the downlink, while the UEs that receive
the echo signals scattered by a target can cooperate with the BS to localize
it. Under this scheme, however, the positions of the UEs are estimated by
Global Positioning System (GPS) and subject to unknown errors. If some UEs with
significantly erroneous position information are used as anchors, the
localization performance can be severely degraded. Based on the outlier
detection technique, this paper proposes an efficient method to select a subset
of UEs with accurate position information as anchors for localizing the target.
Numerical results show that our scheme can select good UEs as anchors with very
high probability, indicating that networked sensing can be realized in practice
with the aid of UEs.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13026" title="Abstract">arXiv:2312.13026</a> (cross-list from eess.AS) [<a href="/pdf/2312.13026" title="Download PDF">pdf</a>, <a href="/format/2312.13026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FusDom: Combining In-Domain and Out-of-Domain Knowledge for Continuous  Self-Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Seth%2C+A">Ashish Seth</a>, 
<a href="/search/eess?searchtype=author&query=Ghosh%2C+S">Sreyan Ghosh</a>, 
<a href="/search/eess?searchtype=author&query=Umesh%2C+S">S. Umesh</a>, 
<a href="/search/eess?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICASSP 2024. Code: <a href="https://github.com/cs20s030/fusdom">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Sound (cs.SD)

</div>
<p class="mathjax">Continued pre-training (CP) offers multiple advantages, like target domain
adaptation and the potential to exploit the continuous stream of unlabeled data
available online. However, continued pre-training on out-of-domain
distributions often leads to catastrophic forgetting of previously acquired
knowledge, leading to sub-optimal ASR performance. This paper presents FusDom,
a simple and novel methodology for SSL-based continued pre-training. FusDom
learns speech representations that are robust and adaptive yet not forgetful of
concepts seen in the past. Instead of solving the SSL pre-text task on the
output representations of a single model, FusDom leverages two identical
pre-trained SSL models, a teacher and a student, with a modified pre-training
head to solve the CP SSL pre-text task. This head employs a cross-attention
mechanism between the representations of both models while only the student
receives gradient updates and the teacher does not. Finally, the student is
fine-tuned for ASR. In practice, FusDom outperforms all our baselines across
settings significantly, with WER improvements in the range of 0.2 WER - 7.3 WER
in the target domain while retaining the performance in the earlier domain.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13034" title="Abstract">arXiv:2312.13034</a> (cross-list from nlin.CG) [<a href="/pdf/2312.13034" title="Download PDF">pdf</a>, <a href="/format/2312.13034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modelling reliability of reversible circuits with 2D second-order  cellular automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/nlin?searchtype=author&query=Vlasov%2C+A+Y">Alexander Yu. Vlasov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> LaTeX 12pt, 32 pages, 21 illustrations (with graphical abstract)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cellular Automata and Lattice Gases (nlin.CG)</span>; Discrete Mathematics (cs.DM); Mathematical Physics (math-ph)

</div>
<p class="mathjax">The cellular automata is a widely known model of reversible computations. The
family of reversible second-order cellular automata considered in this work is
appropriate both for construction of logic gates and analysis of damage
distribution. The quantities such as formal dimension of damage patterns can be
used only for rough estimation of consequences of particular faults and
numerical experiments are provided for illustration of some subtleties. Such
analysis demonstrates high sensitivity to errors from defects, lack of
synchronization and too short intervals between signals.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13035" title="Abstract">arXiv:2312.13035</a> (cross-list from eess.SP) [<a href="/pdf/2312.13035" title="Download PDF">pdf</a>, <a href="/format/2312.13035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 1D-CNN Optimization for Non-contact Respiration Pattern Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Islam%2C+M+Z">Md Zobaer Islam</a>, 
<a href="/search/eess?searchtype=author&query=Yen%2C+G">Gary Yen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures, to be submitted to IEEE conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this study, we present a deep learning-based approach for time-series
respiration data classification. The dataset contains regular breathing
patterns as well as various forms of abnormal breathing, obtained through
non-contact incoherent light-wave sensing (LWS) technology. Given the
one-dimensional (1D) nature of the data, we employed a 1D convolutional neural
network (1D-CNN) for classification purposes. Genetic algorithm was employed to
optimize the 1D-CNN architecture to maximize classification accuracy.
Addressing the computational complexity associated with training the 1D-CNN
across multiple generations, we implemented transfer learning from a
pre-trained model. This approach significantly reduced the computational time
required for training, thereby enhancing the efficiency of the optimization
process. This study contributes valuable insights into the potential
applications of deep learning methodologies for enhancing respiratory anomaly
detection through precise and efficient respiration classification.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13127" title="Abstract">arXiv:2312.13127</a> (cross-list from eess.IV) [<a href="/pdf/2312.13127" title="Download PDF">pdf</a>, <a href="/format/2312.13127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pixel-to-Abundance Translation: Conditional Generative Adversarial  Networks Based on Patch Transformer for Hyperspectral Unmixing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+L">Li Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xiaohua Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+L">Longfei Li</a>, 
<a href="/search/eess?searchtype=author&query=Meng%2C+H">Hongyun Meng</a>, 
<a href="/search/eess?searchtype=author&query=Cao%2C+X">Xianghai Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Spectral unmixing is a significant challenge in hyperspectral image
processing. Existing unmixing methods utilize prior knowledge about the
abundance distribution to solve the regularization optimization problem, where
the difficulty lies in choosing appropriate prior knowledge and solving the
complex regularization optimization problem. To solve these problems, we
propose a hyperspectral conditional generative adversarial network (HyperGAN)
method as a generic unmixing framework, based on the following assumption: the
unmixing process from pixel to abundance can be regarded as a transformation of
two modalities with an internal specific relationship. The proposed HyperGAN is
composed of a generator and discriminator, the former completes the modal
conversion from mixed hyperspectral pixel patch to the abundance of
corresponding endmember of the central pixel and the latter is used to
distinguish whether the distribution and structure of generated abundance are
the same as the true ones. We propose hyperspectral image (HSI) Patch
Transformer as the main component of the generator, which utilize adaptive
attention score to capture the internal pixels correlation of the HSI patch and
leverage the spatial-spectral information in a fine-grained way to achieve
optimization of the unmixing process. Experiments on synthetic data and real
hyperspectral data achieve impressive results compared to state-of-the-art
competitors.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13130" title="Abstract">arXiv:2312.13130</a> (cross-list from stat.ML) [<a href="/pdf/2312.13130" title="Download PDF">pdf</a>, <a href="/ps/2312.13130" title="Download PostScript">ps</a>, <a href="/format/2312.13130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distribution-Dependent Rates for Multi-Distribution Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hanashiro%2C+R">Rafael Hanashiro</a>, 
<a href="/search/stat?searchtype=author&query=Jaillet%2C+P">Patrick Jaillet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">To address the needs of modeling uncertainty in sensitive machine learning
applications, the setup of distributionally robust optimization (DRO) seeks
good performance uniformly across a variety of tasks. The recent
multi-distribution learning (MDL) framework tackles this objective in a dynamic
interaction with the environment, where the learner has sampling access to each
target distribution. Drawing inspiration from the field of pure-exploration
multi-armed bandits, we provide distribution-dependent guarantees in the MDL
regime, that scale with suboptimality gaps and result in superior dependence on
the sample size when compared to the existing distribution-independent
analyses. We investigate two non-adaptive strategies, uniform and non-uniform
exploration, and present non-asymptotic regret bounds using novel tools from
empirical process theory. Furthermore, we devise an adaptive optimistic
algorithm, LCB-DR, that showcases enhanced dependence on the gaps, mirroring
the contrast between uniform and optimistic allocation in the multi-armed
bandit literature.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13136" title="Abstract">arXiv:2312.13136</a> (cross-list from physics.chem-ph) [<a href="/pdf/2312.13136" title="Download PDF">pdf</a>, <a href="/format/2312.13136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Molecular Hypergraph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Chen%2C+J">Junwu Chen</a>, 
<a href="/search/physics?searchtype=author&query=Schwaller%2C+P">Philippe Schwaller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Graph neural networks (GNNs) have demonstrated promising performance across
various chemistry-related tasks. However, conventional graphs only model the
pairwise connectivity in molecules, failing to adequately represent
higher-order connections like multi-center bonds and conjugated structures. To
tackle this challenge, we introduce molecular hypergraphs and propose Molecular
Hypergraph Neural Networks (MHNN) to predict the optoelectronic properties of
organic semiconductors, where hyperedges represent conjugated structures. A
general algorithm is designed for irregular high-order connections, which can
efficiently operate on molecular hypergraphs with hyperedges of various orders.
The results show that MHNN outperforms all baseline models on most tasks of
OPV, OCELOTv1 and PCQM4Mv2 datasets. Notably, MHNN achieves this without any 3D
geometric information, surpassing the baseline model that utilizes atom
positions. Moreover, MHNN achieves better performance than pretrained GNNs
under limited training data, underscoring its excellent data efficiency. This
work provides a new strategy for more general molecular representations and
property prediction tasks related to high-order connections.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13185" title="Abstract">arXiv:2312.13185</a> (cross-list from quant-ph) [<a href="/pdf/2312.13185" title="Download PDF">pdf</a>, <a href="/format/2312.13185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measurement-based quantum computation from Clifford quantum cellular  automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Nautrup%2C+H+P">Hendrik Poulsen Nautrup</a>, 
<a href="/search/quant-ph?searchtype=author&query=Briegel%2C+H+J">Hans J. Briegel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Strongly Correlated Electrons (cond-mat.str-el); Emerging Technologies (cs.ET); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Measurement-based quantum computation (MBQC) is a paradigm for quantum
computation where computation is driven by local measurements on a suitably
entangled resource state. In this work we show that MBQC is related to a model
of quantum computation based on Clifford quantum cellular automata (CQCA).
Specifically, we show that certain MBQCs can be directly constructed from CQCAs
which yields a simple and intuitive circuit model representation of MBQC in
terms of quantum computation based on CQCA. We apply this description to
construct various MBQC-based Ans\"atze for parameterized quantum circuits,
demonstrating that the different Ans\"atze may lead to significantly different
performances on different learning tasks. In this way, MBQC yields a family of
Hardware-efficient Ans\"atze that may be adapted to specific problem settings
and is particularly well suited for architectures with translationally
invariant gates such as neutral atoms.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13212" title="Abstract">arXiv:2312.13212</a> (cross-list from physics.ao-ph) [<a href="/pdf/2312.13212" title="Download PDF">pdf</a>, <a href="/format/2312.13212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A 3D super-resolution of wind fields via physics-informed pixel-wise  self-attention generative adversarial network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kurihana%2C+T">Takuya Kurihana</a>, 
<a href="/search/physics?searchtype=author&query=Yeo%2C+K">Kyongmin Yeo</a>, 
<a href="/search/physics?searchtype=author&query=Szwarcman%2C+D">Daniela Szwarcman</a>, 
<a href="/search/physics?searchtype=author&query=Elmegreen%2C+B">Bruce Elmegreen</a>, 
<a href="/search/physics?searchtype=author&query=Mukkavilli%2C+K">Karthik Mukkavilli</a>, 
<a href="/search/physics?searchtype=author&query=Schmude%2C+J">Johannes Schmude</a>, 
<a href="/search/physics?searchtype=author&query=Klein%2C+L">Levente Klein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, NeurIPS 2023 Workshop: Tackling Climate Change with Machine Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">To mitigate global warming, greenhouse gas sources need to be resolved at a
high spatial resolution and monitored in time to ensure the reduction and
ultimately elimination of the pollution source. However, the complexity of
computation in resolving high-resolution wind fields left the simulations
impractical to test different time lengths and model configurations. This study
presents a preliminary development of a physics-informed super-resolution (SR)
generative adversarial network (GAN) that super-resolves the three-dimensional
(3D) low-resolution wind fields by upscaling x9 times. We develop a pixel-wise
self-attention (PWA) module that learns 3D weather dynamics via a
self-attention computation followed by a 2D convolution. We also employ a loss
term that regularizes the self-attention map during pretraining, capturing the
vertical convection process from input wind data. The new PWA SR-GAN shows the
high-fidelity super-resolved 3D wind data, learns a wind structure at the
high-frequency domain, and reduces the computational cost of a high-resolution
wind simulation by x89.7 times.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13220" title="Abstract">arXiv:2312.13220</a> (cross-list from eess.IV) [<a href="/pdf/2312.13220" title="Download PDF">pdf</a>, <a href="/format/2312.13220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SISMIK for brain MRI: Deep-learning-based motion estimation and  model-based motion correction in k-space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dabrowski%2C+O">Oscar Dabrowski</a> (1 and 2), 
<a href="/search/eess?searchtype=author&query=Falcone%2C+J">Jean-Luc Falcone</a> (1), 
<a href="/search/eess?searchtype=author&query=Klauser%2C+A">Antoine Klauser</a> (2 and 3), 
<a href="/search/eess?searchtype=author&query=Songeon%2C+J">Julien Songeon</a> (2 and 3), 
<a href="/search/eess?searchtype=author&query=Kocher%2C+M">Michel Kocher</a> (4), 
<a href="/search/eess?searchtype=author&query=Chopard%2C+B">Bastien Chopard</a> (1), 
<a href="/search/eess?searchtype=author&query=Lazeyras%2C+F">Fran&#xe7;ois Lazeyras</a> (2 and 3), 
<a href="/search/eess?searchtype=author&query=Courvoisier%2C+S">S&#xe9;bastien Courvoisier</a> (2 and 3) ((1) Computer Science Department, Faculty of Science, University of Geneva, Switzerland, (2) Department of Radiology and Medical Informatics, Faculty of Medicine, University of Geneva, Switzerland, (3) CIBM Center for Biomedical Imaging, MRI HUG-UNIGE, Geneva, Switzerland, (4) EPFL Biomedical Imaging Group (BIG), Lausanne, Switzerland)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">MRI, a widespread non-invasive medical imaging modality, is highly sensitive
to patient motion. Despite many attempts over the years, motion correction
remains a difficult problem and there is no general method applicable to all
situations. We propose a retrospective method for motion quantification and
correction to tackle the problem of in-plane rigid-body motion, apt for
classical 2D Spin-Echo scans of the brain, which are regularly used in clinical
practice. Due to the sequential acquisition of k-space, motion artifacts are
well localized. The method leverages the power of deep neural networks to
estimate motion parameters in k-space and uses a model-based approach to
restore degraded images to avoid ''hallucinations''. Notable advantages are its
ability to estimate motion occurring in high spatial frequencies without the
need of a motion-free reference. The proposed method operates on the whole
k-space dynamic range and is moderately affected by the lower SNR of higher
harmonics. As a proof of concept, we provide models trained using supervised
learning on 600k motion simulations based on motion-free scans of 43 different
subjects. Generalization performance was tested with simulations as well as
in-vivo. Qualitative and quantitative evaluations are presented for motion
parameter estimations and image reconstruction. Experimental results show that
our approach is able to obtain good generalization performance on simulated
data and in-vivo acquisitions.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13250" title="Abstract">arXiv:2312.13250</a> (cross-list from quant-ph) [<a href="/pdf/2312.13250" title="Download PDF">pdf</a>, <a href="/format/2312.13250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The role of data embedding in equivariant quantum convolutional neural  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Das%2C+S">Sreetama Das</a>, 
<a href="/search/quant-ph?searchtype=author&query=Martina%2C+S">Stefano Martina</a>, 
<a href="/search/quant-ph?searchtype=author&query=Caruso%2C+F">Filippo Caruso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computer Vision and Pattern Recognition (cs.CV); Emerging Technologies (cs.ET); Machine Learning (cs.LG)

</div>
<p class="mathjax">Geometric deep learning refers to the scenario in which the symmetries of a
dataset are used to constrain the parameter space of a neural network and thus,
improve their trainability and generalization. Recently this idea has been
incorporated into the field of quantum machine learning, which has given rise
to equivariant quantum neural networks (EQNNs). In this work, we investigate
the role of classical-to-quantum embedding on the performance of equivariant
quantum convolutional neural networks (EQCNNs) for the classification of
images. We discuss the connection between the data embedding method and the
resulting representation of a symmetry group and analyze how changing
representation affects the expressibility of an EQCNN. We numerically compare
the classification accuracy of EQCNNs with three different basis-permuted
amplitude embeddings to the one obtained from a non-equivariant quantum
convolutional neural network (QCNN). Our results show that all the EQCNNs
achieve higher classification accuracy than the non-equivariant QCNN for small
numbers of training iterations, while for large iterations this improvement
crucially depends on the used embedding. It is expected that the results of
this work can be useful to the community for a better understanding of the
importance of data embedding choice in the context of geometric quantum machine
learning.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13259" title="Abstract">arXiv:2312.13259</a> (cross-list from stat.ML) [<a href="/pdf/2312.13259" title="Download PDF">pdf</a>, <a href="/ps/2312.13259" title="Download PostScript">ps</a>, <a href="/format/2312.13259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A note on regularised NTK dynamics with an application to PAC-Bayesian  training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Clerico%2C+E">Eugenio Clerico</a>, 
<a href="/search/stat?searchtype=author&query=Guedj%2C+B">Benjamin Guedj</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We establish explicit dynamics for neural networks whose training objective
has a regularising term that constrains the parameters to remain close to their
initial value. This keeps the network in a lazy training regime, where the
dynamics can be linearised around the initialisation. The standard neural
tangent kernel (NTK) governs the evolution during the training in the
infinite-width limit, although the regularisation yields an additional term
appears in the differential equation describing the dynamics. This setting
provides an appropriate framework to study the evolution of wide networks
trained to optimise generalisation objectives such as PAC-Bayes bounds, and
hence potentially contribute to a deeper theoretical understanding of such
networks.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13284" title="Abstract">arXiv:2312.13284</a> (cross-list from math.AP) [<a href="/pdf/2312.13284" title="Download PDF">pdf</a>, <a href="/format/2312.13284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A structure preserving discretization for the  Derrida-Lebowitz-Speer-Spohn equation based on diffusive transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Matthes%2C+D">Daniel Matthes</a>, 
<a href="/search/math?searchtype=author&query=Rott%2C+E">Eva-Maria Rott</a>, 
<a href="/search/math?searchtype=author&query=Savar%C3%A9%2C+G">Giuseppe Savar&#xe9;</a>, 
<a href="/search/math?searchtype=author&query=Schlichting%2C+A">Andr&#xe9; Schlichting</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 2 figures. Comments welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We propose a spatial discretization of the fourth-order nonlinear DLSS
equation on the circle. Our choice of discretization is motivated by a novel
gradient flow formulation with respect to a metric that generalizes martingale
transport. The discrete dynamics inherits this gradient flow structure, and in
addition further properties, such as an alternative gradient flow formulation
in the Wasserstein distance, contractivity in the Hellinger distance, and
monotonicity of several Lypunov functionals. Our main result is the convergence
in the limit of vanishing mesh size. The proof relies an a discrete version of
a nonlinear functional inequality between integral expressions involving second
order derivatives.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Thu, 21 Dec 23</h3>
<dl>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2001.04235" title="Abstract">arXiv:2001.04235</a> (replaced) [<a href="/pdf/2001.04235" title="Download PDF">pdf</a>, <a href="/format/2001.04235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Notes on Theory of Distributed Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aspnes%2C+J">James Aspnes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated for Fall 2023 semester
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.07066" title="Abstract">arXiv:2103.07066</a> (replaced) [<a href="/pdf/2103.07066" title="Download PDF">pdf</a>, <a href="/format/2103.07066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Subgroups with Significant Treatment Effects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Spiess%2C+J">Jann Spiess</a>, 
<a href="/search/econ?searchtype=author&query=Syrgkanis%2C+V">Vasilis Syrgkanis</a>, 
<a href="/search/econ?searchtype=author&query=Wang%2C+V+Y">Victor Yaneng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics (econ.EM)</span>; Machine Learning (cs.LG); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.07930" title="Abstract">arXiv:2103.07930</a> (replaced) [<a href="/pdf/2103.07930" title="Download PDF">pdf</a>, <a href="/ps/2103.07930" title="Download PostScript">ps</a>, <a href="/format/2103.07930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ideal-theoretic Explanation of Capacity-achieving Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhandari%2C+S">Siddharth Bhandari</a>, 
<a href="/search/cs?searchtype=author&query=Harsha%2C+P">Prahladh Harsha</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+M">Mrinal Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Sudan%2C+M">Madhu Sudan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc. 25th RANDOM, vol 207 of LipiCS pages 56:1--56:21, 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.06033" title="Abstract">arXiv:2104.06033</a> (replaced) [<a href="/pdf/2104.06033" title="Download PDF">pdf</a>, <a href="/format/2104.06033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Not All Requirements Prioritization Criteria Are Equal at All Times: A  Quantitative Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Svensson%2C+R+B">Richard Berntsson Svensson</a>, 
<a href="/search/cs?searchtype=author&query=Torkar%2C+R">Richard Torkar</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Systems and Software, Volume 209, March 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.07669" title="Abstract">arXiv:2105.07669</a> (replaced) [<a href="/pdf/2105.07669" title="Download PDF">pdf</a>, <a href="/format/2105.07669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Achievable Rates of Line Networks with Generalized Batched Network  Coding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shenghao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yanyan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiheng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was presented in part at ISIT 2019 and 2020, and is accepted by a JSAC special issue
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.10293" title="Abstract">arXiv:2105.10293</a> (replaced) [<a href="/pdf/2105.10293" title="Download PDF">pdf</a>, <a href="/format/2105.10293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decision Questions for Probabilistic Automata on Small Alphabets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bell%2C+P+C">Paul C. Bell</a>, 
<a href="/search/cs?searchtype=author&query=Semukhin%2C+P">Pavel Semukhin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.00721" title="Abstract">arXiv:2108.00721</a> (replaced) [<a href="/pdf/2108.00721" title="Download PDF">pdf</a>, <a href="/format/2108.00721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantitatively Nonblocking Supervisory Control of Discrete-Event Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+R">Renyuan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jiahao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zenghui Wang</a>, 
<a href="/search/eess?searchtype=author&query=Cai%2C+K">Kai Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.12524" title="Abstract">arXiv:2109.12524</a> (replaced) [<a href="/pdf/2109.12524" title="Download PDF">pdf</a>, <a href="/ps/2109.12524" title="Download PostScript">ps</a>, <a href="/format/2109.12524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A parallel-in-time preconditioner for Crank-Nicolson discretization of a  parabolic optimal control problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lin%2C+X">Xue-Lei Lin</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+S">Shu-Lin Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.02473" title="Abstract">arXiv:2110.02473</a> (replaced) [<a href="/pdf/2110.02473" title="Download PDF">pdf</a>, <a href="/format/2110.02473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Power of Contrast for Feature Learning: A Theoretical Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+W">Wenlong Ji</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhun Deng</a>, 
<a href="/search/cs?searchtype=author&query=Nakada%2C+R">Ryumei Nakada</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">James Zou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Linjun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 78 pages, accepted by JMLR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.00350" title="Abstract">arXiv:2201.00350</a> (replaced) [<a href="/pdf/2201.00350" title="Download PDF">pdf</a>, <a href="/format/2201.00350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Interpretability of LSTM Models for Predicting Oil Company Stocks:  Impact of Correlated Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Firouzjaee%2C+J+T">Javad T. Firouzjaee</a>, 
<a href="/search/q-fin?searchtype=author&query=Khaliliyan%2C+P">Pouriya Khaliliyan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 figures, 13 tables, accepted for publication in International Journal of Energy Research
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.09169" title="Abstract">arXiv:2201.09169</a> (replaced) [<a href="/pdf/2201.09169" title="Download PDF">pdf</a>, <a href="/format/2201.09169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rich Action-semantic Consistent Knowledge for Early Action Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoli Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jianqin Yin</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Di Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huaping Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE TIP,15pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.02249" title="Abstract">arXiv:2202.02249</a> (replaced) [<a href="/pdf/2202.02249" title="Download PDF">pdf</a>, <a href="/format/2202.02249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Functional Mixtures-of-Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chamroukhi%2C+F">Fa&#xef;cel Chamroukhi</a>, 
<a href="/search/stat?searchtype=author&query=Pham%2C+N+T">Nhat Thien Pham</a>, 
<a href="/search/stat?searchtype=author&query=Hoang%2C+V+H">Van H&#xe0; Hoang</a>, 
<a href="/search/stat?searchtype=author&query=McLachlan%2C+G+J">Geoffrey J. McLachlan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Computation (stat.CO); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.02980" title="Abstract">arXiv:2202.02980</a> (replaced) [<a href="/pdf/2202.02980" title="Download PDF">pdf</a>, <a href="/format/2202.02980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Object Detection from Images for Autonomous Driving: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xinzhu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Simonelli%2C+A">Andrea Simonelli</a>, 
<a href="/search/cs?searchtype=author&query=Ricci%2C+E">Elisa Ricci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by T-PAMI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.06152" title="Abstract">arXiv:2202.06152</a> (replaced) [<a href="/pdf/2202.06152" title="Download PDF">pdf</a>, <a href="/format/2202.06152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of Dual-Based PID Controllers through Convolutional Mirror  Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Balseiro%2C+S+R">Santiago R. Balseiro</a>, 
<a href="/search/math?searchtype=author&query=Lu%2C+H">Haihao Lu</a>, 
<a href="/search/math?searchtype=author&query=Mirrokni%2C+V">Vahab Mirrokni</a>, 
<a href="/search/math?searchtype=author&query=Sivan%2C+B">Balasubramanian Sivan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.04575" title="Abstract">arXiv:2203.04575</a> (replaced) [<a href="/pdf/2203.04575" title="Download PDF">pdf</a>, <a href="/format/2203.04575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometric Aspects of Data-Processing of Markov Chains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wolfer%2C+G">Geoffrey Wolfer</a>, 
<a href="/search/math?searchtype=author&query=Watanabe%2C+S">Shun Watanabe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Information Theory (cs.IT); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.12303" title="Abstract">arXiv:2204.12303</a> (replaced) [<a href="/pdf/2204.12303" title="Download PDF">pdf</a>, <a href="/format/2204.12303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On converses to the polynomial method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Bri%C3%ABt%2C+J">Jop Bri&#xeb;t</a>, 
<a href="/search/quant-ph?searchtype=author&query=Guti%C3%A9rrez%2C+F+E">Francisco Escudero Guti&#xe9;rrez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages. No changes. This work was largely subsumed by another with one extra author (<a href="/abs/2212.08559">arXiv:2212.08559</a>)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> TQC'22 Proceedings, LIPICS Vol. 232 (6), 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.15834" title="Abstract">arXiv:2205.15834</a> (replaced) [<a href="/pdf/2205.15834" title="Download PDF">pdf</a>, <a href="/format/2205.15834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attribution-based Explanations that Provide Recourse Cannot be Robust
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Fokkema%2C+H">Hidde Fokkema</a>, 
<a href="/search/stat?searchtype=author&query=de+Heide%2C+R">Rianne de Heide</a>, 
<a href="/search/stat?searchtype=author&query=van+Erven%2C+T">Tim van Erven</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.07207" title="Abstract">arXiv:2206.07207</a> (replaced) [<a href="/pdf/2206.07207" title="Download PDF">pdf</a>, <a href="/format/2206.07207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Grounding: Extracting Fine-Grained Event Hierarchies Across  Modalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ayyubi%2C+H+A">Hammad A. Ayyubi</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+C">Christopher Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Chum%2C+L">Lovish Chum</a>, 
<a href="/search/cs?searchtype=author&query=Lokesh%2C+R">Rahul Lokesh</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Long Chen</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yulei Niu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xudong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xuande Feng</a>, 
<a href="/search/cs?searchtype=author&query=Koo%2C+J">Jaywon Koo</a>, 
<a href="/search/cs?searchtype=author&query=Ray%2C+S">Sounak Ray</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+S">Shih-Fu Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.08615" title="Abstract">arXiv:2206.08615</a> (replaced) [<a href="/pdf/2206.08615" title="Download PDF">pdf</a>, <a href="/format/2206.08615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Number of Regions of Piecewise Linear Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goujon%2C+A">Alexis Goujon</a>, 
<a href="/search/cs?searchtype=author&query=Etemadi%2C+A">Arian Etemadi</a>, 
<a href="/search/cs?searchtype=author&query=Unser%2C+M">Michael Unser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Combinatorics (math.CO); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.00283" title="Abstract">arXiv:2207.00283</a> (replaced) [<a href="/pdf/2207.00283" title="Download PDF">pdf</a>, <a href="/format/2207.00283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Lattice Quantum Field Theories with Equivariant Continuous  Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-lat?searchtype=author&query=Gerdes%2C+M">Mathis Gerdes</a>, 
<a href="/search/hep-lat?searchtype=author&query=de+Haan%2C+P">Pim de Haan</a>, 
<a href="/search/hep-lat?searchtype=author&query=Rainone%2C+C">Corrado Rainone</a>, 
<a href="/search/hep-lat?searchtype=author&query=Bondesan%2C+R">Roberto Bondesan</a>, 
<a href="/search/hep-lat?searchtype=author&query=Cheng%2C+M+C+N">Miranda C. N. Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 9 figures, 1 table; slightly expanded published version, added 2 figures and 2 sections to appendix
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SciPost Phys. 15, 238 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Lattice (hep-lat)</span>; Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG); High Energy Physics - Theory (hep-th)

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.06867" title="Abstract">arXiv:2208.06867</a> (replaced) [<a href="/pdf/2208.06867" title="Download PDF">pdf</a>, <a href="/format/2208.06867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Limit Consistency of Lattice Boltzmann Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Simonis%2C+S">Stephan Simonis</a>, 
<a href="/search/math?searchtype=author&query=Krause%2C+M+J">Mathias J. Krause</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.11429" title="Abstract">arXiv:2208.11429</a> (replaced) [<a href="/pdf/2208.11429" title="Download PDF">pdf</a>, <a href="/format/2208.11429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of the Driving Performance and User Acceptance of a  Predictive Eco-Driving Assistance System for Electric Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chada%2C+S+K">Sai Krishna Chada</a>, 
<a href="/search/eess?searchtype=author&query=G%C3%B6rges%2C+D">Daniel G&#xf6;rges</a>, 
<a href="/search/eess?searchtype=author&query=Ebert%2C+A">Achim Ebert</a>, 
<a href="/search/eess?searchtype=author&query=Teutsch%2C+R">Roman Teutsch</a>, 
<a href="/search/eess?searchtype=author&query=Subramanya%2C+S+P">Shreevatsa Puttige Subramanya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Transportation Research Part C: Emerging Technologies Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.02154" title="Abstract">arXiv:2209.02154</a> (replaced) [<a href="/e-print/2209.02154" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random Initialization Solves Shapley&#x27;s Fictitious Play Counterexample
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ganzfried%2C+S">Sam Ganzfried</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Superceded by <a href="/abs/2001.11165">arXiv:2001.11165</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.04587" title="Abstract">arXiv:2209.04587</a> (replaced) [<a href="/pdf/2209.04587" title="Download PDF">pdf</a>, <a href="/format/2209.04587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multipoint-BAX: A New Approach for Efficiently Tuning Particle  Accelerator Emittance via Virtual Objectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Miskovich%2C+S+A">Sara A. Miskovich</a>, 
<a href="/search/physics?searchtype=author&query=Neiswanger%2C+W">Willie Neiswanger</a>, 
<a href="/search/physics?searchtype=author&query=Colocho%2C+W">William Colocho</a>, 
<a href="/search/physics?searchtype=author&query=Emma%2C+C">Claudio Emma</a>, 
<a href="/search/physics?searchtype=author&query=Garrahan%2C+J">Jacqueline Garrahan</a>, 
<a href="/search/physics?searchtype=author&query=Maxwell%2C+T">Timothy Maxwell</a>, 
<a href="/search/physics?searchtype=author&query=Mayes%2C+C">Christopher Mayes</a>, 
<a href="/search/physics?searchtype=author&query=Ermon%2C+S">Stefano Ermon</a>, 
<a href="/search/physics?searchtype=author&query=Edelen%2C+A">Auralee Edelen</a>, 
<a href="/search/physics?searchtype=author&query=Ratner%2C+D">Daniel Ratner</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Machine Learning: Science and Technology, Dec. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Accelerator Physics (physics.acc-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.11144" title="Abstract">arXiv:2209.11144</a> (replaced) [<a href="/pdf/2209.11144" title="Download PDF">pdf</a>, <a href="/format/2209.11144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic and effective discovery of quantum kernels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Incudini%2C+M">Massimiliano Incudini</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bosco%2C+D+L">Daniele Lizzio Bosco</a>, 
<a href="/search/quant-ph?searchtype=author&query=Martini%2C+F">Francesco Martini</a>, 
<a href="/search/quant-ph?searchtype=author&query=Grossi%2C+M">Michele Grossi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Serra%2C+G">Giuseppe Serra</a>, 
<a href="/search/quant-ph?searchtype=author&query=Di+Pierro%2C+A">Alessandra Di Pierro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.14719" title="Abstract">arXiv:2209.14719</a> (replaced) [<a href="/pdf/2209.14719" title="Download PDF">pdf</a>, <a href="/format/2209.14719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In Search of Projectively Equivariant Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%B6kman%2C+G">Georg B&#xf6;kman</a>, 
<a href="/search/cs?searchtype=author&query=Flinth%2C+A">Axel Flinth</a>, 
<a href="/search/cs?searchtype=author&query=Kahl%2C+F">Fredrik Kahl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v3: Another significant rewrite. Accepted for publication in TMLR. v2: Significant rewrite. The title has been changed: "neural network" -&amp;gt; "network". More general description of projectively equivariant linear layers, with new proposed architectures, and a completely new accompanying experiment section, as a result
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.03087" title="Abstract">arXiv:2210.03087</a> (replaced) [<a href="/pdf/2210.03087" title="Download PDF">pdf</a>, <a href="/format/2210.03087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterative Vision-and-Language Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krantz%2C+J">Jacob Krantz</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Shurjo Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Corso%2C+J">Jason Corso</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+P">Peter Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Stefan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Thomason%2C+J">Jesse Thomason</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.07085" title="Abstract">arXiv:2210.07085</a> (replaced) [<a href="/pdf/2210.07085" title="Download PDF">pdf</a>, <a href="/format/2210.07085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Uniform Certification in QBF
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chew%2C+L">Leroy Chew</a>, 
<a href="/search/cs?searchtype=author&query=Slivovsky%2C+F">Friedrich Slivovsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.15563" title="Abstract">arXiv:2210.15563</a> (replaced) [<a href="/pdf/2210.15563" title="Download PDF">pdf</a>, <a href="/format/2210.15563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Transformer Distillation for Audio-Visual Synchronization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuanjun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haibin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chung-Che Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hung-yi Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+J+R">Jyh-Shing Roger Jang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Retrieval (cs.IR); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.15642" title="Abstract">arXiv:2210.15642</a> (replaced) [<a href="/pdf/2210.15642" title="Download PDF">pdf</a>, <a href="/format/2210.15642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Existential Definability over the Subword Ordering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baumann%2C+P">Pascal Baumann</a>, 
<a href="/search/cs?searchtype=author&query=Ganardi%2C+M">Moses Ganardi</a>, 
<a href="/search/cs?searchtype=author&query=Thinniyam%2C+R+S">Ramanathan S. Thinniyam</a>, 
<a href="/search/cs?searchtype=author&query=Zetzsche%2C+G">Georg Zetzsche</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.15657" title="Abstract">arXiv:2210.15657</a> (replaced) [<a href="/e-print/2210.15657" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting fake accounts through Generative Adversarial Network in online  social media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bordbar%2C+J">Jinus Bordbar</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadrezaie%2C+M">Mohammadreza Mohammadrezaie</a>, 
<a href="/search/cs?searchtype=author&query=Ardalan%2C+S">Saman Ardalan</a>, 
<a href="/search/cs?searchtype=author&query=Shiri%2C+M+E">Mohammad Ebrahim Shiri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> needed more investigation on final results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.06624" title="Abstract">arXiv:2211.06624</a> (replaced) [<a href="/pdf/2211.06624" title="Download PDF">pdf</a>, <a href="/ps/2211.06624" title="Download PostScript">ps</a>, <a href="/format/2211.06624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regularized Barzilai-Borwein method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=An%2C+C">Congpei An</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+X">Xin Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.10525" title="Abstract">arXiv:2211.10525</a> (replaced) [<a href="/pdf/2211.10525" title="Download PDF">pdf</a>, <a href="/format/2211.10525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Uncalibrated Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gupta%2C+S">Sidharth Gupta</a>, 
<a href="/search/eess?searchtype=author&query=Kothari%2C+K">Konik Kothari</a>, 
<a href="/search/eess?searchtype=author&query=Debarnot%2C+V">Valentin Debarnot</a>, 
<a href="/search/eess?searchtype=author&query=Dokmani%C4%87%2C+I">Ivan Dokmani&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01039" title="Abstract">arXiv:2212.01039</a> (replaced) [<a href="/pdf/2212.01039" title="Download PDF">pdf</a>, <a href="/format/2212.01039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoftCorrect: Error Correction with Soft Detection for Automatic Speech  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leng%2C+Y">Yichong Leng</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kaitao Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang-Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+T">Tao Qin</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+E">Edward Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tie-Yan Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01071" title="Abstract">arXiv:2212.01071</a> (replaced) [<a href="/e-print/2212.01071" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fake detection in imbalance dataset by Semi-supervised learning with GAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bordbar%2C+J">Jinus Bordbar</a>, 
<a href="/search/cs?searchtype=author&query=Ardalan%2C+S">Saman Ardalan</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadrezaie%2C+M">Mohammadreza Mohammadrezaie</a>, 
<a href="/search/cs?searchtype=author&query=Ghasemi%2C+Z">Zahra Ghasemi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> needed more investigation o final results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.04155" title="Abstract">arXiv:2212.04155</a> (replaced) [<a href="/pdf/2212.04155" title="Download PDF">pdf</a>, <a href="/format/2212.04155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Graph Representations for Critical View of Safety Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Murali%2C+A">Aditya Murali</a>, 
<a href="/search/cs?searchtype=author&query=Alapatt%2C+D">Deepak Alapatt</a>, 
<a href="/search/cs?searchtype=author&query=Mascagni%2C+P">Pietro Mascagni</a>, 
<a href="/search/cs?searchtype=author&query=Vardazaryan%2C+A">Armine Vardazaryan</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+A">Alain Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Okamoto%2C+N">Nariaki Okamoto</a>, 
<a href="/search/cs?searchtype=author&query=Mutter%2C+D">Didier Mutter</a>, 
<a href="/search/cs?searchtype=author&query=Padoy%2C+N">Nicolas Padoy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.05908" title="Abstract">arXiv:2212.05908</a> (replaced) [<a href="/pdf/2212.05908" title="Download PDF">pdf</a>, <a href="/format/2212.05908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instance-Conditional Timescales of Decay for Non-Stationary Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+N">Nishant Jain</a>, 
<a href="/search/cs?searchtype=author&query=Shenoy%2C+P">Pradeep Shenoy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.06370" title="Abstract">arXiv:2212.06370</a> (replaced) [<a href="/pdf/2212.06370" title="Download PDF">pdf</a>, <a href="/format/2212.06370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual Accuracy-Quality-Driven Neural Network for Prediction Interval  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morales%2C+G">Giorgio Morales</a>, 
<a href="/search/cs?searchtype=author&query=Sheppard%2C+J+W">John W. Sheppard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the IEEE Transactions on Neural Networks and Learning Systems
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> G. Morales and J. W. Sheppard, "Dual Accuracy-Quality-Driven
  Neural Network for Prediction Interval Generation," in IEEE Transactions on
  Neural Networks and Learning Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03713" title="Abstract">arXiv:2301.03713</a> (replaced) [<a href="/pdf/2301.03713" title="Download PDF">pdf</a>, <a href="/format/2301.03713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-contact Respiratory Anomaly Detection using Infrared Light-wave  Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Islam%2C+M+Z">Md Zobaer Islam</a>, 
<a href="/search/eess?searchtype=author&query=Martin%2C+B">Brenden Martin</a>, 
<a href="/search/eess?searchtype=author&query=Gotcher%2C+C">Carly Gotcher</a>, 
<a href="/search/eess?searchtype=author&query=Martinez%2C+T">Tyler Martinez</a>, 
<a href="/search/eess?searchtype=author&query=O%27Hara%2C+J+F">John F. O&#x27;Hara</a>, 
<a href="/search/eess?searchtype=author&query=Ekin%2C+S">Sabit Ekin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 15 figures excluding photos of authors, submitted to IEEE Transactions on Human-machine Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.05540" title="Abstract">arXiv:2301.05540</a> (replaced) [<a href="/pdf/2301.05540" title="Download PDF">pdf</a>, <a href="/ps/2301.05540" title="Download PostScript">ps</a>, <a href="/format/2301.05540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving PDEs with Incomplete Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Binev%2C+P">Peter Binev</a>, 
<a href="/search/math?searchtype=author&query=Bonito%2C+A">Andrea Bonito</a>, 
<a href="/search/math?searchtype=author&query=Cohen%2C+A">Albert Cohen</a>, 
<a href="/search/math?searchtype=author&query=Dahmen%2C+W">Wolfgang Dahmen</a>, 
<a href="/search/math?searchtype=author&query=DeVore%2C+R">Ronald DeVore</a>, 
<a href="/search/math?searchtype=author&query=Petrova%2C+G">Guergana Petrova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12523" title="Abstract">arXiv:2301.12523</a> (replaced) [<a href="/pdf/2301.12523" title="Download PDF">pdf</a>, <a href="/ps/2301.12523" title="Download PostScript">ps</a>, <a href="/format/2301.12523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Subspace Subcodes in the Rank Metric
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ndiaye%2C+O">Ousmane Ndiaye</a>, 
<a href="/search/cs?searchtype=author&query=Kidoudou%2C+P+A">Peter Arnaud Kidoudou</a>, 
<a href="/search/cs?searchtype=author&query=Kalachi%2C+H+T">Herv&#xe9; Tale Kalachi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13779" title="Abstract">arXiv:2301.13779</a> (replaced) [<a href="/pdf/2301.13779" title="Download PDF">pdf</a>, <a href="/format/2301.13779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FLAME: A small language model for spreadsheet formulas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joshi%2C+H">Harshit Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Ebenezer%2C+A">Abishai Ebenezer</a>, 
<a href="/search/cs?searchtype=author&query=Cambronero%2C+J">Jos&#xe9; Cambronero</a>, 
<a href="/search/cs?searchtype=author&query=Gulwani%2C+S">Sumit Gulwani</a>, 
<a href="/search/cs?searchtype=author&query=Kanade%2C+A">Aditya Kanade</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+V">Vu Le</a>, 
<a href="/search/cs?searchtype=author&query=Radi%C4%8Dek%2C+I">Ivan Radi&#x10d;ek</a>, 
<a href="/search/cs?searchtype=author&query=Verbruggen%2C+G">Gust Verbruggen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01686" title="Abstract">arXiv:2302.01686</a> (replaced) [<a href="/pdf/2302.01686" title="Download PDF">pdf</a>, <a href="/format/2302.01686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Augmented Reality Approach to Interact with Visualizations of  Industrial Process Tomography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuchong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xuan%2C+Y">Yueming Xuan</a>, 
<a href="/search/cs?searchtype=author&query=Yadav%2C+R">Rahul Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Omrani%2C+A">Adel Omrani</a>, 
<a href="/search/cs?searchtype=author&query=Fjeld%2C+M">Morten Fjeld</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In IFIP Conference on Human-Computer Interaction 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IFIP Conference on Human-Computer Interaction 2023 Aug 28 vol
  14143 (pp. 123-144)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02270" title="Abstract">arXiv:2302.02270</a> (replaced) [<a href="/pdf/2302.02270" title="Download PDF">pdf</a>, <a href="/ps/2302.02270" title="Download PostScript">ps</a>, <a href="/format/2302.02270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regret-Guaranteed Safe Switching with Minimum Cost: LQR Setting with  Unknown Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chekan%2C+J+A">Jafar Abbaszadeh Chekan</a>, 
<a href="/search/eess?searchtype=author&query=Langbort%2C+C">Cedric Langbort</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02515" title="Abstract">arXiv:2302.02515</a> (replaced) [<a href="/pdf/2302.02515" title="Download PDF">pdf</a>, <a href="/format/2302.02515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning for Time Series Classification and Extrinsic Regression: A  Current Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Foumani%2C+N+M">Navid Mohammadi Foumani</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+L">Lynn Miller</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C+W">Chang Wei Tan</a>, 
<a href="/search/cs?searchtype=author&query=Webb%2C+G+I">Geoffrey I. Webb</a>, 
<a href="/search/cs?searchtype=author&query=Forestier%2C+G">Germain Forestier</a>, 
<a href="/search/cs?searchtype=author&query=Salehi%2C+M">Mahsa Salehi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13005" title="Abstract">arXiv:2302.13005</a> (replaced) [<a href="/pdf/2302.13005" title="Download PDF">pdf</a>, <a href="/format/2302.13005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accurate Gaussian-Process-based Distance Fields with applications to  Echolocation and Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gentil%2C+C+L">Cedric Le Gentil</a>, 
<a href="/search/cs?searchtype=author&query=Ouabi%2C+O">Othmane-Latif Ouabi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Pradalier%2C+C">Cedric Pradalier</a>, 
<a href="/search/cs?searchtype=author&query=Vidal-Calleja%2C+T">Teresa Vidal-Calleja</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00196" title="Abstract">arXiv:2303.00196</a> (replaced) [<a href="/pdf/2303.00196" title="Download PDF">pdf</a>, <a href="/format/2303.00196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformed Low-Rank Parameterization Can Help Robust Generalization for  Tensor Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Andong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chao Li</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+M">Mingyuan Bai</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Guoxu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qibin Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 51 pages, presented on NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01125" title="Abstract">arXiv:2303.01125</a> (replaced) [<a href="/pdf/2303.01125" title="Download PDF">pdf</a>, <a href="/format/2303.01125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distilling Multi-Level X-vector Knowledge for Small-footprint Speaker  Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuechen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sahidullah%2C+M">Md Sahidullah</a>, 
<a href="/search/cs?searchtype=author&query=Kinnunen%2C+T">Tomi Kinnunen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Data &amp; Knowledge Engineering at Dec. 2023. Copyright may be transferred without notice
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02367" title="Abstract">arXiv:2303.02367</a> (replaced) [<a href="/pdf/2303.02367" title="Download PDF">pdf</a>, <a href="/format/2303.02367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perirobot space representation for HRI: measuring and designing  collaborative workspace coverage by diverse sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rozlivek%2C+J">Jakub Rozlivek</a>, 
<a href="/search/cs?searchtype=author&query=Svarny%2C+P">Petr Svarny</a>, 
<a href="/search/cs?searchtype=author&query=Hoffmann%2C+M">Matej Hoffmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 12 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05122" title="Abstract">arXiv:2303.05122</a> (replaced) [<a href="/pdf/2303.05122" title="Download PDF">pdf</a>, <a href="/format/2303.05122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M-Tuning: Prompt Tuning with Mitigated Label Bias in Open-Set Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+N">Ning Liao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaopeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+M">Min Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qi Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05221" title="Abstract">arXiv:2303.05221</a> (replaced) [<a href="/pdf/2303.05221" title="Download PDF">pdf</a>, <a href="/format/2303.05221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEAM: An Integrated Activation-Coupled Model of Sentence Processing and  Eye Movements in Reading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Rabe%2C+M+M">Maximilian M. Rabe</a>, 
<a href="/search/q-bio?searchtype=author&query=Paape%2C+D">Dario Paape</a>, 
<a href="/search/q-bio?searchtype=author&query=Mertzen%2C+D">Daniela Mertzen</a>, 
<a href="/search/q-bio?searchtype=author&query=Vasishth%2C+S">Shravan Vasishth</a>, 
<a href="/search/q-bio?searchtype=author&query=Engbert%2C+R">Ralf Engbert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06854" title="Abstract">arXiv:2303.06854</a> (replaced) [<a href="/pdf/2303.06854" title="Download PDF">pdf</a>, <a href="/format/2303.06854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Contrastive Language-Image Pre-training against Data Poisoning  and Backdoor Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenhan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jingdong Gao</a>, 
<a href="/search/cs?searchtype=author&query=Mirzasoleiman%2C+B">Baharan Mirzasoleiman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09429" title="Abstract">arXiv:2303.09429</a> (replaced) [<a href="/pdf/2303.09429" title="Download PDF">pdf</a>, <a href="/format/2303.09429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Roaming and Quality Assessment for Composed Image Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Levy%2C+M">Matan Levy</a>, 
<a href="/search/cs?searchtype=author&query=Ben-Ari%2C+R">Rami Ben-Ari</a>, 
<a href="/search/cs?searchtype=author&query=Darshan%2C+N">Nir Darshan</a>, 
<a href="/search/cs?searchtype=author&query=Lischinski%2C+D">Dani Lischinski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera Ready version for AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11048" title="Abstract">arXiv:2303.11048</a> (replaced) [<a href="/pdf/2303.11048" title="Download PDF">pdf</a>, <a href="/format/2303.11048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SGFormer: Semantic Graph Transformer for Point Cloud-based 3D Scene  Graph Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lv%2C+C">Changsheng Lv</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+M">Mengshi Qi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xia Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhengyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Huadong Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in Thirty-Eighth AAAI Conference on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11938" title="Abstract">arXiv:2303.11938</a> (replaced) [<a href="/pdf/2303.11938" title="Download PDF">pdf</a>, <a href="/format/2303.11938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D-CLFusion: Fast Text-to-3D Rendering with Contrastive Latent Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yu-Jhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Ji Hou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bichen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xiaoliang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Pumarola%2C+A">Albert Pumarola</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peizhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Vajda%2C+P">Peter Vajda</a>, 
<a href="/search/cs?searchtype=author&query=Kitani%2C+K">Kris Kitani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12332" title="Abstract">arXiv:2303.12332</a> (replaced) [<a href="/pdf/2303.12332" title="Download PDF">pdf</a>, <a href="/format/2303.12332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly-Supervised Temporal Action Localization by Inferring Salient  Snippet-Feature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yun%2C+W">Wulian Yun</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+M">Mengshi Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chuanming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Huadong Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12484" title="Abstract">arXiv:2303.12484</a> (replaced) [<a href="/pdf/2303.12484" title="Download PDF">pdf</a>, <a href="/format/2303.12484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Label-Efficient Deep Learning in Medical Image Analysis: Challenges and  Future Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Cheng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhengrui Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Luyang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Update Few-shot Methods
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15119" title="Abstract">arXiv:2303.15119</a> (replaced) [<a href="/pdf/2303.15119" title="Download PDF">pdf</a>, <a href="/format/2303.15119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PoPeC: PAoI-Centric Task Offloading with Priority over Unreliable  Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiao%2C+N">Nan Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+S">Sheng Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongmin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Ju Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15413" title="Abstract">arXiv:2303.15413</a> (replaced) [<a href="/pdf/2303.15413" title="Download PDF">pdf</a>, <a href="/format/2303.15413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Debiasing Scores and Prompts of 2D Diffusion for View-consistent  Text-to-3D Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Susung Hong</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+D">Donghoon Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungryong Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023. Project Page: <a href="https://susunghong.github.io/Debiased-Score-Distillation-Sampling/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16521" title="Abstract">arXiv:2303.16521</a> (replaced) [<a href="/pdf/2303.16521" title="Download PDF">pdf</a>, <a href="/format/2303.16521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hard Regularization to Prevent Deep Online Clustering Collapse without  Data Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahon%2C+L">Louis Mahon</a>, 
<a href="/search/cs?searchtype=author&query=Lukasiewicz%2C+T">Thomas Lukasiewicz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16567" title="Abstract">arXiv:2303.16567</a> (replaced) [<a href="/pdf/2303.16567" title="Download PDF">pdf</a>, <a href="/format/2303.16567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient and Reconfigurable Optimal Planning in Large-Scale Systems  Using Hierarchical Finite State Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Stefansson%2C+E">Elis Stefansson</a>, 
<a href="/search/eess?searchtype=author&query=Johansson%2C+K+H">Karl H. Johansson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CDC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17908" title="Abstract">arXiv:2303.17908</a> (replaced) [<a href="/pdf/2303.17908" title="Download PDF">pdf</a>, <a href="/format/2303.17908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trade-offs in Fine-tuned Diffusion Models Between Accuracy and  Interpretability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dombrowski%2C+M">Mischa Dombrowski</a>, 
<a href="/search/cs?searchtype=author&query=Reynaud%2C+H">Hadrien Reynaud</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+J+P">Johanna P. M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Baugh%2C+M">Matthew Baugh</a>, 
<a href="/search/cs?searchtype=author&query=Kainz%2C+B">Bernhard Kainz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01246" title="Abstract">arXiv:2304.01246</a> (replaced) [<a href="/pdf/2304.01246" title="Download PDF">pdf</a>, <a href="/format/2304.01246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safety Analysis in the Era of Large Language Models: A Case Study of  STPA using ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yi Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xingyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Khastgir%2C+S">Siddartha Khastgir</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaowei Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01644" title="Abstract">arXiv:2304.01644</a> (replaced) [<a href="/pdf/2304.01644" title="Download PDF">pdf</a>, <a href="/format/2304.01644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Repeated Fair Allocation of Indivisible Items
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Igarashi%2C+A">Ayumi Igarashi</a>, 
<a href="/search/cs?searchtype=author&query=Lackner%2C+M">Martin Lackner</a>, 
<a href="/search/cs?searchtype=author&query=Nardi%2C+O">Oliviero Nardi</a>, 
<a href="/search/cs?searchtype=author&query=Novaro%2C+A">Arianna Novaro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages. Extended version of accepted AAAI-24 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02150" title="Abstract">arXiv:2304.02150</a> (replaced) [<a href="/pdf/2304.02150" title="Download PDF">pdf</a>, <a href="/format/2304.02150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Re-Evaluating LiDAR Scene Flow for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chodosh%2C+N">Nathaniel Chodosh</a>, 
<a href="/search/cs?searchtype=author&query=Ramanan%2C+D">Deva Ramanan</a>, 
<a href="/search/cs?searchtype=author&query=Lucey%2C+S">Simon Lucey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03483" title="Abstract">arXiv:2304.03483</a> (replaced) [<a href="/pdf/2304.03483" title="Download PDF">pdf</a>, <a href="/format/2304.03483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RED-PSM: Regularization by Denoising of Partially Separable Models for  Dynamic Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Iskender%2C+B">Berk Iskender</a>, 
<a href="/search/eess?searchtype=author&query=Klasky%2C+M+L">Marc L. Klasky</a>, 
<a href="/search/eess?searchtype=author&query=Bresler%2C+Y">Yoram Bresler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03693" title="Abstract">arXiv:2304.03693</a> (replaced) [<a href="/pdf/2304.03693" title="Download PDF">pdf</a>, <a href="/format/2304.03693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-Agnostic Gender Debiased Image Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hirota%2C+Y">Yusuke Hirota</a>, 
<a href="/search/cs?searchtype=author&query=Nakashima%2C+Y">Yuta Nakashima</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+N">Noa Garcia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03898" title="Abstract">arXiv:2304.03898</a> (replaced) [<a href="/pdf/2304.03898" title="Download PDF">pdf</a>, <a href="/format/2304.03898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Short Text Matching Model Enhanced with Knowledge via Contrastive  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruiqiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Q">Qiqiang Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+M">Mengmeng Cui</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+H">Hanjie Mai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shaohua Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiangzheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yanlong Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages,2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04353" title="Abstract">arXiv:2304.04353</a> (replaced) [<a href="/pdf/2304.04353" title="Download PDF">pdf</a>, <a href="/format/2304.04353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exponentially Improved Efficient and Accurate Machine Learning for  Quantum Many-body States with Provable Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Che%2C+Y">Yanming Che</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gneiting%2C+C">Clemens Gneiting</a>, 
<a href="/search/quant-ph?searchtype=author&query=Nori%2C+F">Franco Nori</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 + 13 pages, 2 + 1 figures; With supplemental material (SM). Improved presentation to highlight our new findings; Added numerical demonstration with a quantum XY model; Added Sec. II in the SM
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06385" title="Abstract">arXiv:2304.06385</a> (replaced) [<a href="/pdf/2304.06385" title="Download PDF">pdf</a>, <a href="/format/2304.06385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TransHP: Image Classification with Hierarchical Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yifan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023; Released code
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09679" title="Abstract">arXiv:2304.09679</a> (replaced) [<a href="/pdf/2304.09679" title="Download PDF">pdf</a>, <a href="/format/2304.09679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse graphs without long induced paths
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Defrain%2C+O">Oscar Defrain</a>, 
<a href="/search/math?searchtype=author&query=Raymond%2C+J">Jean-Florent Raymond</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13096" title="Abstract">arXiv:2304.13096</a> (replaced) [<a href="/pdf/2304.13096" title="Download PDF">pdf</a>, <a href="/format/2304.13096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time Autonomous Glider Navigation Software
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Ruochu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+M">Mengxue Hou</a>, 
<a href="/search/cs?searchtype=author&query=Lembke%2C+C">Chad Lembke</a>, 
<a href="/search/cs?searchtype=author&query=Edwards%2C+C">Catherine Edwards</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fumin Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> OCEANS 2023 Limerick
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13646" title="Abstract">arXiv:2304.13646</a> (replaced) [<a href="/pdf/2304.13646" title="Download PDF">pdf</a>, <a href="/format/2304.13646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven Piecewise Affine Decision Rules for Stochastic Programming  with Covariate Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+Y">Yiyang Zhang</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+J">Junyi Liu</a>, 
<a href="/search/math?searchtype=author&query=Zhao%2C+X">Xiaobo Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00054" title="Abstract">arXiv:2305.00054</a> (replaced) [<a href="/pdf/2305.00054" title="Download PDF">pdf</a>, <a href="/format/2305.00054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LAVA: Data Valuation without Pre-Specified Learning Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Just%2C+H+A">Hoang Anh Just</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+F">Feiyang Kang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J+T">Jiachen T. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yi Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+M">Myeongseob Ko</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Ming Jin</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+R">Ruoxi Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2023 Spotlight Latest Updated Version: 2023/12/19
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00766" title="Abstract">arXiv:2305.00766</a> (replaced) [<a href="/pdf/2305.00766" title="Download PDF">pdf</a>, <a href="/format/2305.00766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Montsalvat: Intel SGX Shielding for GraalVM Native Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuhala%2C+P">Peterson Yuhala</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%A9n%C3%A9trey%2C+J">J&#xe4;mes M&#xe9;n&#xe9;trey</a>, 
<a href="/search/cs?searchtype=author&query=Felber%2C+P">Pascal Felber</a>, 
<a href="/search/cs?searchtype=author&query=Schiavoni%2C+V">Valerio Schiavoni</a>, 
<a href="/search/cs?searchtype=author&query=Tchana%2C+A">Alain Tchana</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+G">Ga&#xeb;l Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Guiroux%2C+H">Hugo Guiroux</a>, 
<a href="/search/cs?searchtype=author&query=Lozi%2C+J">Jean-Pierre Lozi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, Proceedings of the 22nd International Middleware Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04214" title="Abstract">arXiv:2305.04214</a> (replaced) [<a href="/pdf/2305.04214" title="Download PDF">pdf</a>, <a href="/format/2305.04214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PiML Toolbox for Interpretable Machine Learning Model Development and  Diagnostics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sudjianto%2C+A">Agus Sudjianto</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Aijun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zebin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yu Su</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+N">Ningzhou Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05418" title="Abstract">arXiv:2305.05418</a> (replaced) [<a href="/pdf/2305.05418" title="Download PDF">pdf</a>, <a href="/format/2305.05418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring Rule-based LTLf Process Specifications: A Probabilistic  Data-driven Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cecconi%2C+A">Alessio Cecconi</a>, 
<a href="/search/cs?searchtype=author&query=Barbaro%2C+L">Luca Barbaro</a>, 
<a href="/search/cs?searchtype=author&query=Di+Ciccio%2C+C">Claudio Di Ciccio</a>, 
<a href="/search/cs?searchtype=author&query=Senderovich%2C+A">Arik Senderovich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10701" title="Abstract">arXiv:2305.10701</a> (replaced) [<a href="/pdf/2305.10701" title="Download PDF">pdf</a>, <a href="/format/2305.10701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalization as a Shortcut for Few-Shot Backdoor Attack against  Text-to-Image Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yihao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Juefei-Xu%2C+F">Felix Juefei-Xu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yutong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+M">Ming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianlin Li</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+G">Geguang Pu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11662" title="Abstract">arXiv:2305.11662</a> (replaced) [<a href="/pdf/2305.11662" title="Download PDF">pdf</a>, <a href="/format/2305.11662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Separating form and meaning: Using self-consistency to quantify task  understanding across multiple senses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ohmer%2C+X">Xenia Ohmer</a>, 
<a href="/search/cs?searchtype=author&query=Bruni%2C+E">Elia Bruni</a>, 
<a href="/search/cs?searchtype=author&query=Hupkes%2C+D">Dieuwke Hupkes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12038" title="Abstract">arXiv:2305.12038</a> (replaced) [<a href="/pdf/2305.12038" title="Download PDF">pdf</a>, <a href="/ps/2305.12038" title="Download PostScript">ps</a>, <a href="/format/2305.12038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stabilized finite element methods for the time-spectral  convection-diffusion equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Esmaily%2C+M">Mahdi Esmaily</a>, 
<a href="/search/math?searchtype=author&query=Jia%2C+D">Dongjie Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> *Correspondence: me399@cornell.edu
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12554" title="Abstract">arXiv:2305.12554</a> (replaced) [<a href="/pdf/2305.12554" title="Download PDF">pdf</a>, <a href="/format/2305.12554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Consistent Stochastic Human Motion Prediction via Motion  Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiarui Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhary%2C+G">Girish Chowdhary</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15163" title="Abstract">arXiv:2305.15163</a> (replaced) [<a href="/pdf/2305.15163" title="Download PDF">pdf</a>, <a href="/format/2305.15163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A fast and accurate domain-decomposition nonlinear manifold reduced  order model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Diaz%2C+A+N">Alejandro N. Diaz</a>, 
<a href="/search/math?searchtype=author&query=Choi%2C+Y">Youngsoo Choi</a>, 
<a href="/search/math?searchtype=author&query=Heinkenschloss%2C+M">Matthias Heinkenschloss</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15296" title="Abstract">arXiv:2305.15296</a> (replaced) [<a href="/pdf/2305.15296" title="Download PDF">pdf</a>, <a href="/format/2305.15296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultiFusion: Fusing Pre-Trained Models for Multi-Lingual, Multi-Modal  Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bellagente%2C+M">Marco Bellagente</a>, 
<a href="/search/cs?searchtype=author&query=Brack%2C+M">Manuel Brack</a>, 
<a href="/search/cs?searchtype=author&query=Teufel%2C+H">Hannah Teufel</a>, 
<a href="/search/cs?searchtype=author&query=Friedrich%2C+F">Felix Friedrich</a>, 
<a href="/search/cs?searchtype=author&query=Deiseroth%2C+B">Bj&#xf6;rn Deiseroth</a>, 
<a href="/search/cs?searchtype=author&query=Eichenberg%2C+C">Constantin Eichenberg</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+A">Andrew Dai</a>, 
<a href="/search/cs?searchtype=author&query=Baldock%2C+R">Robert Baldock</a>, 
<a href="/search/cs?searchtype=author&query=Nanda%2C+S">Souradeep Nanda</a>, 
<a href="/search/cs?searchtype=author&query=Oostermeijer%2C+K">Koen Oostermeijer</a>, 
<a href="/search/cs?searchtype=author&query=Cruz-Salinas%2C+A+F">Andres Felipe Cruz-Salinas</a>, 
<a href="/search/cs?searchtype=author&query=Schramowski%2C+P">Patrick Schramowski</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+K">Kristian Kersting</a>, 
<a href="/search/cs?searchtype=author&query=Weinbach%2C+S">Samuel Weinbach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of Advances in Neural Information Processing Systems: Annual Conference on Neural Information Processing Systems (NeurIPS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15685" title="Abstract">arXiv:2305.15685</a> (replaced) [<a href="/pdf/2305.15685" title="Download PDF">pdf</a>, <a href="/format/2305.15685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RewriteLM: An Instruction-Tuned Large Language Model for Text Rewriting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shu%2C+L">Lei Shu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Liangchen Luo</a>, 
<a href="/search/cs?searchtype=author&query=Hoskere%2C+J">Jayakumar Hoskere</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yinxiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+S">Simon Tong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jindong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+L">Lei Meng</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16172" title="Abstract">arXiv:2305.16172</a> (replaced) [<a href="/pdf/2305.16172" title="Download PDF">pdf</a>, <a href="/format/2305.16172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked and Permuted Implicit Context Learning for Scene Text Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaomeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Z">Zhi Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Dongbao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yu Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16307" title="Abstract">arXiv:2305.16307</a> (replaced) [<a href="/pdf/2305.16307" title="Download PDF">pdf</a>, <a href="/ps/2305.16307" title="Download PostScript">ps</a>, <a href="/format/2305.16307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IndicTrans2: Towards High-Quality and Accessible Machine Translation  Models for all 22 Scheduled Indian Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gala%2C+J">Jay Gala</a>, 
<a href="/search/cs?searchtype=author&query=Chitale%2C+P+A">Pranjal A. Chitale</a>, 
<a href="/search/cs?searchtype=author&query=AK%2C+R">Raghavan AK</a>, 
<a href="/search/cs?searchtype=author&query=Gumma%2C+V">Varun Gumma</a>, 
<a href="/search/cs?searchtype=author&query=Doddapaneni%2C+S">Sumanth Doddapaneni</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Aswanth Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Nawale%2C+J">Janki Nawale</a>, 
<a href="/search/cs?searchtype=author&query=Sujatha%2C+A">Anupama Sujatha</a>, 
<a href="/search/cs?searchtype=author&query=Puduppully%2C+R">Ratish Puduppully</a>, 
<a href="/search/cs?searchtype=author&query=Raghavan%2C+V">Vivek Raghavan</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+P">Pratyush Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Khapra%2C+M+M">Mitesh M. Khapra</a>, 
<a href="/search/cs?searchtype=author&query=Dabre%2C+R">Raj Dabre</a>, 
<a href="/search/cs?searchtype=author&query=Kunchukuttan%2C+A">Anoop Kunchukuttan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at TMLR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17239" title="Abstract">arXiv:2305.17239</a> (replaced) [<a href="/pdf/2305.17239" title="Download PDF">pdf</a>, <a href="/format/2305.17239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Irreducibility of Recombination Markov Chains in the Triangular Lattice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cannon%2C+S">Sarah Cannon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 81 pages, 37 figures. 10-page conference version published in SIAM Conference on Applied and Computational Discrete Algorithms, 2023 (ACDA23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Computational Geometry (cs.CG); Data Structures and Algorithms (cs.DS); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17330" title="Abstract">arXiv:2305.17330</a> (replaced) [<a href="/pdf/2305.17330" title="Download PDF">pdf</a>, <a href="/format/2305.17330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MADiff: Offline Multi-agent Learning with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhengbang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Minghuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+L">Liyuan Mao</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+B">Bingyi Kang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Minkai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ermon%2C+S">Stefano Ermon</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 10 figures, 6 tables. The first two authors contributed equally to the work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17965" title="Abstract">arXiv:2305.17965</a> (replaced) [<a href="/pdf/2305.17965" title="Download PDF">pdf</a>, <a href="/format/2305.17965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the Generalizability of Trajectory Prediction Models with  Frenet-Based Domain Normalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+L">Luyao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zikang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianping Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was published in 2023 IEEE International Conference on Robotics and Automation (ICRA). New version updated with links to the source code of the Frenet+ strategy
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01266" title="Abstract">arXiv:2306.01266</a> (replaced) [<a href="/pdf/2306.01266" title="Download PDF">pdf</a>, <a href="/format/2306.01266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self Contrastive Learning for Session-based Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhengxiang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lipani%2C+A">Aldo Lipani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ECIR 2024 (Full Paper) Camera-ready Version. Code is available at <a href="https://github.com/ZhengxiangShi/SelfContrastiveLearningRecSys">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01335" title="Abstract">arXiv:2306.01335</a> (replaced) [<a href="/pdf/2306.01335" title="Download PDF">pdf</a>, <a href="/format/2306.01335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invertible residual networks in the context of regularization theory for  linear inverse problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Arndt%2C+C">Clemens Arndt</a>, 
<a href="/search/math?searchtype=author&query=Denker%2C+A">Alexander Denker</a>, 
<a href="/search/math?searchtype=author&query=Dittmer%2C+S">S&#xf6;ren Dittmer</a>, 
<a href="/search/math?searchtype=author&query=Heilenk%C3%B6tter%2C+N">Nick Heilenk&#xf6;tter</a>, 
<a href="/search/math?searchtype=author&query=Iske%2C+M">Meira Iske</a>, 
<a href="/search/math?searchtype=author&query=Kluth%2C+T">Tobias Kluth</a>, 
<a href="/search/math?searchtype=author&query=Maass%2C+P">Peter Maass</a>, 
<a href="/search/math?searchtype=author&query=Nickel%2C+J">Judith Nickel</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Inverse Problems 39 125018 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02630" title="Abstract">arXiv:2306.02630</a> (replaced) [<a href="/pdf/2306.02630" title="Download PDF">pdf</a>, <a href="/format/2306.02630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Covariance Adaptive Best Arm Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Saad%2C+E+M">El Mehdi Saad</a> (CentraleSup&#xe9;l&#xe9;c), 
<a href="/search/stat?searchtype=author&query=Blanchard%2C+G">Gilles Blanchard</a> (LMO, DATASHAPE), 
<a href="/search/stat?searchtype=author&query=Verzelen%2C+N">Nicolas Verzelen</a> (MISTEA)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> New version with some minor corrections
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neurips 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03373" title="Abstract">arXiv:2306.03373</a> (replaced) [<a href="/pdf/2306.03373" title="Download PDF">pdf</a>, <a href="/format/2306.03373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CiT-Net: Convolutional Neural Networks Hand in Hand with Vision  Transformers for Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lei%2C+T">Tao Lei</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+R">Rui Sun</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xuan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yingbo Wang</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+X">Xi He</a>, 
<a href="/search/eess?searchtype=author&query=Nandi%2C+A">Asoke Nandi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures, 3 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The 32nd International Joint Conference on Artificial
  Intelligence, IJCAI2023, MACAO
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03410" title="Abstract">arXiv:2306.03410</a> (replaced) [<a href="/pdf/2306.03410" title="Download PDF">pdf</a>, <a href="/format/2306.03410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Simulate Tree-Branch Dynamics for Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jacob%2C+J">Jayadeep Jacob</a>, 
<a href="/search/cs?searchtype=author&query=Bandyopadhyay%2C+T">Tirthankar Bandyopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+J">Jason Williams</a>, 
<a href="/search/cs?searchtype=author&query=Borges%2C+P">Paulo Borges</a>, 
<a href="/search/cs?searchtype=author&query=Ramos%2C+F">Fabio Ramos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03625" title="Abstract">arXiv:2306.03625</a> (replaced) [<a href="/pdf/2306.03625" title="Download PDF">pdf</a>, <a href="/format/2306.03625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair and Robust Estimation of Heterogeneous Treatment Effects for Policy  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kim%2C+K">Kwangho Kim</a>, 
<a href="/search/stat?searchtype=author&query=Zubizarreta%2C+J+R">Jos&#xe9; R. Zubizarreta</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 40 th International Conference on Machine
  Learning, Honolulu, Hawaii, USA. PMLR 202, 16997--17014, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04086" title="Abstract">arXiv:2306.04086</a> (replaced) [<a href="/pdf/2306.04086" title="Download PDF">pdf</a>, <a href="/format/2306.04086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TEC-Net: Vision Transformer Embrace Convolutional Neural Networks for  Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sun%2C+R">Rui Sun</a>, 
<a href="/search/eess?searchtype=author&query=Lei%2C+T">Tao Lei</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+W">Weichuan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wan%2C+Y">Yong Wan</a>, 
<a href="/search/eess?searchtype=author&query=Xia%2C+Y">Yong Xia</a>, 
<a href="/search/eess?searchtype=author&query=Nandi%2C+A+K">Asoke K. Nandi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2306.03373">arXiv:2306.03373</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04164" title="Abstract">arXiv:2306.04164</a> (replaced) [<a href="/pdf/2306.04164" title="Download PDF">pdf</a>, <a href="/format/2306.04164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Multi-AP Coordination Approaches over Emerging WLANs: Future  Directions and Open Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verma%2C+S">Shikhar Verma</a>, 
<a href="/search/cs?searchtype=author&query=Rodrigues%2C+T+K">Tiago Koketsu Rodrigues</a>, 
<a href="/search/cs?searchtype=author&query=Kawamoto%2C+Y">Yuichi Kawamoto</a>, 
<a href="/search/cs?searchtype=author&query=Fouda%2C+M+M">Mostafa M. Fouda</a>, 
<a href="/search/cs?searchtype=author&query=Kato%2C+N">Nei Kato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The reason for the replacement of the previous version of the paper is due to a change in the author's list. As a result, a new version has been created, which serves as the final draft version before acceptance. This updated version contains all the latest changes and improvements made to the paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04733" title="Abstract">arXiv:2306.04733</a> (replaced) [<a href="/pdf/2306.04733" title="Download PDF">pdf</a>, <a href="/format/2306.04733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Epidemic spreading in group-structured populations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Patwardhan%2C+S">Siddharth Patwardhan</a>, 
<a href="/search/physics?searchtype=author&query=Rao%2C+V+K">Varun K. Rao</a>, 
<a href="/search/physics?searchtype=author&query=Fortunato%2C+S">Santo Fortunato</a>, 
<a href="/search/physics?searchtype=author&query=Radicchi%2C+F">Filippo Radicchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures + Supplemental Material
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Phys. Rev. X 13, 041054 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04886" title="Abstract">arXiv:2306.04886</a> (replaced) [<a href="/pdf/2306.04886" title="Download PDF">pdf</a>, <a href="/format/2306.04886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-task Bioassay Pre-training for Protein-ligand Binding Affinity  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Yan%2C+J">Jiaxian Yan</a>, 
<a href="/search/q-bio?searchtype=author&query=Ye%2C+Z">Zhaofeng Ye</a>, 
<a href="/search/q-bio?searchtype=author&query=Yang%2C+Z">Ziyi Yang</a>, 
<a href="/search/q-bio?searchtype=author&query=Lu%2C+C">Chengqiang Lu</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+S">Shengyu Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Qiu%2C+J">Jiezhong Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06041" title="Abstract">arXiv:2306.06041</a> (replaced) [<a href="/pdf/2306.06041" title="Download PDF">pdf</a>, <a href="/format/2306.06041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Graph Dynamics Prior for Relational Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Liming Pan</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Cheng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Dokmani%C4%87%2C+I">Ivan Dokmani&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07547" title="Abstract">arXiv:2306.07547</a> (replaced) [<a href="/pdf/2306.07547" title="Download PDF">pdf</a>, <a href="/format/2306.07547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniCATS: A Unified Context-Aware Text-to-Speech Framework with  Contextual VQ-Diffusion and Vocoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+C">Chenpeng Du</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yiwei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+F">Feiyu Shen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhijun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zheng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kai Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09564" title="Abstract">arXiv:2306.09564</a> (replaced) [<a href="/pdf/2306.09564" title="Download PDF">pdf</a>, <a href="/ps/2306.09564" title="Download PostScript">ps</a>, <a href="/format/2306.09564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed Fair Division: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shengxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xinhang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+M">Mashbat Suzuki</a>, 
<a href="/search/cs?searchtype=author&query=Walsh%2C+T">Toby Walsh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the 38th AAAI Conference on Artificial Intelligence (AAAI), Senior Member Presentation Track, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10982" title="Abstract">arXiv:2306.10982</a> (replaced) [<a href="/pdf/2306.10982" title="Download PDF">pdf</a>, <a href="/format/2306.10982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Over-the-Air Federated Learning Over MIMO Fading  Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jia Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y+A">Ying-Jun Angela Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been accepted by the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11698" title="Abstract">arXiv:2306.11698</a> (replaced) [<a href="/pdf/2306.11698" title="Download PDF">pdf</a>, <a href="/format/2306.11698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Boxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weixin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+H">Hengzhi Pei</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Chulin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+M">Mintong Kang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenhui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chejian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zidi Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Dutta%2C+R">Ritik Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Schaeffer%2C+R">Rylan Schaeffer</a>, 
<a href="/search/cs?searchtype=author&query=Truong%2C+S+T">Sang T. Truong</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+S">Simran Arora</a>, 
<a href="/search/cs?searchtype=author&query=Mazeika%2C+M">Mantas Mazeika</a>, 
<a href="/search/cs?searchtype=author&query=Hendrycks%2C+D">Dan Hendrycks</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zinan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Koyejo%2C+S">Sanmi Koyejo</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dawn Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Outstanding Paper (Datasets and Benchmarks Track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12028" title="Abstract">arXiv:2306.12028</a> (replaced) [<a href="/pdf/2306.12028" title="Download PDF">pdf</a>, <a href="/format/2306.12028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Sapper: A LLM-Empowered Production Tool for Building AI Chains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jieshan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhenchang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Qinghua Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 5 figures, accepted to TOSEM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13628" title="Abstract">arXiv:2306.13628</a> (replaced) [<a href="/pdf/2306.13628" title="Download PDF">pdf</a>, <a href="/ps/2306.13628" title="Download PostScript">ps</a>, <a href="/format/2306.13628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Construction of polynomial particular solutions of linear  constant-coefficient partial differential equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Anderson%2C+T+G">Thomas G. Anderson</a>, 
<a href="/search/math?searchtype=author&query=Bonnet%2C+M">Marc Bonnet</a>, 
<a href="/search/math?searchtype=author&query=Faria%2C+L+M">Luiz M. Faria</a>, 
<a href="/search/math?searchtype=author&query=P%C3%A9rez-Arancibia%2C+C">Carlos P&#xe9;rez-Arancibia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14932" title="Abstract">arXiv:2306.14932</a> (replaced) [<a href="/pdf/2306.14932" title="Download PDF">pdf</a>, <a href="/ps/2306.14932" title="Download PostScript">ps</a>, <a href="/format/2306.14932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GloptiNets: Scalable Non-Convex Optimization with Certificates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Beugnot%2C+G">Gaspard Beugnot</a> (PSL, DI-ENS), 
<a href="/search/math?searchtype=author&query=Mairal%2C+J">Julien Mairal</a>, 
<a href="/search/math?searchtype=author&query=Rudi%2C+A">Alessandro Rudi</a> (PSL, DI-ENS)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Edit affiliations and acknowledgments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16307" title="Abstract">arXiv:2306.16307</a> (replaced) [<a href="/pdf/2306.16307" title="Download PDF">pdf</a>, <a href="/format/2306.16307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing Deep Learning Package Supply Chains in PyPI: Domains,  Clusters, and Disengagement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+K">Kai Gao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Runzhi He</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+B">Bing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Minghui Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint of paper accepted by ACM Transactions on Software Engineering and Methodology (TOSEM)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02273" title="Abstract">arXiv:2307.02273</a> (replaced) [<a href="/pdf/2307.02273" title="Download PDF">pdf</a>, <a href="/format/2307.02273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Hierarchical Priors and Adaptive Spatial Resolution for Efficient  Neural Image Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghorbel%2C+A">Ahmed Ghorbel</a>, 
<a href="/search/cs?searchtype=author&query=Hamidouche%2C+W">Wassim Hamidouche</a>, 
<a href="/search/cs?searchtype=author&query=Morin%2C+L">Luce Morin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05209" title="Abstract">arXiv:2307.05209</a> (replaced) [<a href="/pdf/2307.05209" title="Download PDF">pdf</a>, <a href="/format/2307.05209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextual Pre-Planning on Reward Machine Abstractions for Enhanced  Transfer in Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azran%2C+G">Guy Azran</a>, 
<a href="/search/cs?searchtype=author&query=Danesh%2C+M+H">Mohamad H. Danesh</a>, 
<a href="/search/cs?searchtype=author&query=Albrecht%2C+S+V">Stefano V. Albrecht</a>, 
<a href="/search/cs?searchtype=author&query=Keren%2C+S">Sarah Keren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 38th AAAI Conference on Artificial Intelligence (AAAI), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07063" title="Abstract">arXiv:2307.07063</a> (replaced) [<a href="/pdf/2307.07063" title="Download PDF">pdf</a>, <a href="/format/2307.07063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bootstrapping Vision-Language Learning with Decoupled Language  Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jian%2C+Y">Yiren Jian</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chongyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Vosoughi%2C+S">Soroush Vosoughi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023 (spotlight). The code is available at <a href="https://github.com/yiren-jian/BLIText">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09298" title="Abstract">arXiv:2307.09298</a> (replaced) [<a href="/pdf/2307.09298" title="Download PDF">pdf</a>, <a href="/ps/2307.09298" title="Download PostScript">ps</a>, <a href="/format/2307.09298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subfield subcodes of projective Reed-Muller codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gimenez%2C+P">Philippe Gimenez</a>, 
<a href="/search/cs?searchtype=author&query=Ruano%2C+D">Diego Ruano</a>, 
<a href="/search/cs?searchtype=author&query=San-Jos%C3%A9%2C+R">Rodrigo San-Jos&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Commutative Algebra (math.AC)

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11575" title="Abstract">arXiv:2307.11575</a> (replaced) [<a href="/pdf/2307.11575" title="Download PDF">pdf</a>, <a href="/ps/2307.11575" title="Download PostScript">ps</a>, <a href="/format/2307.11575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The connection between the spread of misinformation, time of day, and  individual user activity patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stockinger%2C+E">Elisabeth Stockinger</a>, 
<a href="/search/cs?searchtype=author&query=Gallotti%2C+R">Riccardo Gallotti</a>, 
<a href="/search/cs?searchtype=author&query=Hausladen%2C+C+I">Carina I. Hausladen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12976" title="Abstract">arXiv:2307.12976</a> (replaced) [<a href="/pdf/2307.12976" title="Download PDF">pdf</a>, <a href="/format/2307.12976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Ripple Effects of Knowledge Editing in Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cohen%2C+R">Roi Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Biran%2C+E">Eden Biran</a>, 
<a href="/search/cs?searchtype=author&query=Yoran%2C+O">Ori Yoran</a>, 
<a href="/search/cs?searchtype=author&query=Globerson%2C+A">Amir Globerson</a>, 
<a href="/search/cs?searchtype=author&query=Geva%2C+M">Mor Geva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Transactions of the Association for Computational Linguistics (TACL), 2024. Author's final version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13986" title="Abstract">arXiv:2307.13986</a> (replaced) [<a href="/pdf/2307.13986" title="Download PDF">pdf</a>, <a href="/format/2307.13986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Representation-Enhanced Sampling for Bayesian Active Learning in  Musculoskeletal Segmentation of Lower Extremities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+G">Ganping Li</a>, 
<a href="/search/eess?searchtype=author&query=Otake%2C+Y">Yoshito Otake</a>, 
<a href="/search/eess?searchtype=author&query=Soufi%2C+M">Mazen Soufi</a>, 
<a href="/search/eess?searchtype=author&query=Taniguchi%2C+M">Masashi Taniguchi</a>, 
<a href="/search/eess?searchtype=author&query=Yagi%2C+M">Masahide Yagi</a>, 
<a href="/search/eess?searchtype=author&query=Ichihashi%2C+N">Noriaki Ichihashi</a>, 
<a href="/search/eess?searchtype=author&query=Uemura%2C+K">Keisuke Uemura</a>, 
<a href="/search/eess?searchtype=author&query=Takao%2C+M">Masaki Takao</a>, 
<a href="/search/eess?searchtype=author&query=Sugano%2C+N">Nobuhiko Sugano</a>, 
<a href="/search/eess?searchtype=author&query=Sato%2C+Y">Yoshinobu Sato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15409" title="Abstract">arXiv:2307.15409</a> (replaced) [<a href="/pdf/2307.15409" title="Download PDF">pdf</a>, <a href="/format/2307.15409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-aware Unsupervised Multi-Object Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Sheng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Z">Zhihang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Ze Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+R">Rongxin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jieping Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by International Conference on Computer Vision (ICCV) 2023. Code is available at <a href="https://github.com/alibaba/u2mot/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15490" title="Abstract">arXiv:2307.15490</a> (replaced) [<a href="/pdf/2307.15490" title="Download PDF">pdf</a>, <a href="/format/2307.15490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unleashing the Potential of Stage-Wise Decision-Making in Scheduling of  Graph-Structured Tasks over Mobile Vehicular Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liwang%2C+M">Minghui Liwang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+B">Bingshuo Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhanxi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yuhan Su</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jian Jin</a>, 
<a href="/search/cs?searchtype=author&query=Hosseinalipour%2C+S">Seyyedali Hosseinalipour</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xianbin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Huaiyu Dai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Networking and Internet Architecture (cs.NI); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16092" title="Abstract">arXiv:2307.16092</a> (replaced) [<a href="/pdf/2307.16092" title="Download PDF">pdf</a>, <a href="/ps/2307.16092" title="Download PostScript">ps</a>, <a href="/format/2307.16092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Transportation Improves Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eliasof%2C+M">Moshe Eliasof</a>, 
<a href="/search/cs?searchtype=author&query=Haber%2C+E">Eldad Haber</a>, 
<a href="/search/cs?searchtype=author&query=Treister%2C+E">Eran Treister</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16597" title="Abstract">arXiv:2307.16597</a> (replaced) [<a href="/pdf/2307.16597" title="Download PDF">pdf</a>, <a href="/format/2307.16597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Errors Dynamics in Affine Group Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xinghan Li</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jianqi Chen</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Han Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wei%2C+J">Jieqiang Wei</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+J">Junfeng Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8pages,1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02052" title="Abstract">arXiv:2308.02052</a> (replaced) [<a href="/pdf/2308.02052" title="Download PDF">pdf</a>, <a href="/format/2308.02052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PyPartMC: A Pythonic interface to a particle-resolved, Monte Carlo  aerosol simulation framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%27Aquino%2C+Z">Zachary D&#x27;Aquino</a>, 
<a href="/search/cs?searchtype=author&query=Arabas%2C+S">Sylwester Arabas</a>, 
<a href="/search/cs?searchtype=author&query=Curtis%2C+J">Jeffrey Curtis</a>, 
<a href="/search/cs?searchtype=author&query=Vaishnav%2C+A">Akshunna Vaishnav</a>, 
<a href="/search/cs?searchtype=author&query=Riemer%2C+N">Nicole Riemer</a>, 
<a href="/search/cs?searchtype=author&query=West%2C+M">Matthew West</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Software (cs.MS)</span>; Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03108" title="Abstract">arXiv:2308.03108</a> (replaced) [<a href="/pdf/2308.03108" title="Download PDF">pdf</a>, <a href="/format/2308.03108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAAM: Stealthy Adversarial Attack on Monocular Depth Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guesmi%2C+A">Amira Guesmi</a>, 
<a href="/search/cs?searchtype=author&query=Hanif%2C+M+A">Muhammad Abdullah Hanif</a>, 
<a href="/search/cs?searchtype=author&query=Ouni%2C+B">Bassem Ouni</a>, 
<a href="/search/cs?searchtype=author&query=Shafique%2C+M">Muhammad Shafique</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03109" title="Abstract">arXiv:2308.03109</a> (replaced) [<a href="/pdf/2308.03109" title="Download PDF">pdf</a>, <a href="/format/2308.03109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lost in Translation: A Study of Bugs Introduced by Large Language Models  while Translating Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+R">Rangeet Pan</a>, 
<a href="/search/cs?searchtype=author&query=Ibrahimzada%2C+A+R">Ali Reza Ibrahimzada</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+R">Rahul Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Sankar%2C+D">Divya Sankar</a>, 
<a href="/search/cs?searchtype=author&query=Wassi%2C+L+P">Lambert Pouguem Wassi</a>, 
<a href="/search/cs?searchtype=author&query=Merler%2C+M">Michele Merler</a>, 
<a href="/search/cs?searchtype=author&query=Sobolev%2C+B">Boris Sobolev</a>, 
<a href="/search/cs?searchtype=author&query=Pavuluri%2C+R">Raju Pavuluri</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+S">Saurabh Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Jabbarvand%2C+R">Reyhaneh Jabbarvand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in ICSE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08198" title="Abstract">arXiv:2308.08198</a> (replaced) [<a href="/pdf/2308.08198" title="Download PDF">pdf</a>, <a href="/format/2308.08198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeSCo: Towards Generalizable and Scalable Deep Subgraph Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+T">Tianyu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+C">Chiyue Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+R">Rex Ying</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages main text, 2 pages references, 11 pages appendix; open source at <a href="https://github.com/fuvty/DeSCo">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> WSDM'24, March 4-8, 2024, Merida, Mexico
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08511" title="Abstract">arXiv:2308.08511</a> (replaced) [<a href="/pdf/2308.08511" title="Download PDF">pdf</a>, <a href="/format/2308.08511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-and-a-half Order Score-based Model for Solving 3D Ill-posed Inverse  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zirong Li</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yanyang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jianjia Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+W">Weiwen Wu</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+H">Hengyong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 13 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computers in Biology and Medicine Volume 168, January 2024, 107819
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08658" title="Abstract">arXiv:2308.08658</a> (replaced) [<a href="/pdf/2308.08658" title="Download PDF">pdf</a>, <a href="/ps/2308.08658" title="Download PostScript">ps</a>, <a href="/format/2308.08658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Data-Theoretic Approach to Identifying Violent Facial Expressions in  Social Crime Contexts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paul%2C+A+K">Arindam Kumar Paul</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08742" title="Abstract">arXiv:2308.08742</a> (replaced) [<a href="/pdf/2308.08742" title="Download PDF">pdf</a>, <a href="/format/2308.08742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PMET: Precise Model Editing in a Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaopeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shasha Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shezheng Song</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jie Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09156" title="Abstract">arXiv:2308.09156</a> (replaced) [<a href="/pdf/2308.09156" title="Download PDF">pdf</a>, <a href="/format/2308.09156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing Information Seeking Events in Health-Related Social  Discourse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharif%2C+O">Omar Sharif</a>, 
<a href="/search/cs?searchtype=author&query=Basak%2C+M">Madhusudan Basak</a>, 
<a href="/search/cs?searchtype=author&query=Parvin%2C+T">Tanzia Parvin</a>, 
<a href="/search/cs?searchtype=author&query=Scharfstein%2C+A">Ava Scharfstein</a>, 
<a href="/search/cs?searchtype=author&query=Bradham%2C+A">Alphonso Bradham</a>, 
<a href="/search/cs?searchtype=author&query=Borodovsky%2C+J+T">Jacob T. Borodovsky</a>, 
<a href="/search/cs?searchtype=author&query=Lord%2C+S+E">Sarah E. Lord</a>, 
<a href="/search/cs?searchtype=author&query=Preum%2C+S+M">Sarah M. Preum</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI-2024. 9 pages, 6 tables, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10079" title="Abstract">arXiv:2308.10079</a> (replaced) [<a href="/pdf/2308.10079" title="Download PDF">pdf</a>, <a href="/format/2308.10079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MeDM: Mediating Image Diffusion Models for Video-to-Video Translation  with Temporal Correspondence Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+E">Ernie Chu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tzuhsuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shuo-Yen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jun-Cheng Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a conference paper in AAAI 2024. Project page: <a href="https://medm2023.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10542" title="Abstract">arXiv:2308.10542</a> (replaced) [<a href="/pdf/2308.10542" title="Download PDF">pdf</a>, <a href="/format/2308.10542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Weakly Convex Regularizers for Convergent Image-Reconstruction  Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Goujon%2C+A">Alexis Goujon</a>, 
<a href="/search/eess?searchtype=author&query=Neumayer%2C+S">Sebastian Neumayer</a>, 
<a href="/search/eess?searchtype=author&query=Unser%2C+M">Michael Unser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12535" title="Abstract">arXiv:2308.12535</a> (replaced) [<a href="/pdf/2308.12535" title="Download PDF">pdf</a>, <a href="/format/2308.12535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCP: Spherical-Coordinate-based Learned Point Cloud Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+A">Ao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Linxin Song</a>, 
<a href="/search/cs?searchtype=author&query=Nonaka%2C+K">Keisuke Nonaka</a>, 
<a href="/search/cs?searchtype=author&query=Unno%2C+K">Kyohei Unno</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Heming Sun</a>, 
<a href="/search/cs?searchtype=author&query=Goto%2C+M">Masayuki Goto</a>, 
<a href="/search/cs?searchtype=author&query=Katto%2C+J">Jiro Katto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13198" title="Abstract">arXiv:2308.13198</a> (replaced) [<a href="/pdf/2308.13198" title="Download PDF">pdf</a>, <a href="/format/2308.13198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Journey to the Center of the Knowledge Neurons: Discoveries of  Language-Independent Knowledge Neurons and Degenerate Knowledge Neurons
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+P">Pengfei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yubo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the 38th AAAI Conference on Artificial Intelligence (AAAI 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13380" title="Abstract">arXiv:2308.13380</a> (replaced) [<a href="/pdf/2308.13380" title="Download PDF">pdf</a>, <a href="/format/2308.13380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From system models to class models: An in-context learning paradigm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Forgione%2C+M">Marco Forgione</a>, 
<a href="/search/eess?searchtype=author&query=Pura%2C+F">Filippo Pura</a>, 
<a href="/search/eess?searchtype=author&query=Piga%2C+D">Dario Piga</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13739" title="Abstract">arXiv:2308.13739</a> (replaced) [<a href="/pdf/2308.13739" title="Download PDF">pdf</a>, <a href="/format/2308.13739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Devignet: High-Resolution Vignetting Removal via a Dual Aggregated  Fusion Transformer With Adaptive Channel Expansion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Shenghong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuhang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weiwen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zinuo Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pun%2C+C">Chi-Man Pun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI Conference on Artificial Intelligence 2024 (AAAI 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14078" title="Abstract">arXiv:2308.14078</a> (replaced) [<a href="/pdf/2308.14078" title="Download PDF">pdf</a>, <a href="/format/2308.14078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse3D: Distilling Multiview-Consistent Diffusion for Object  Reconstruction from Sparse Views
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+Z">Zi-Xin Zou</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+W">Weihao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yan-Pei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shi-Sheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Song-Hai Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14606" title="Abstract">arXiv:2308.14606</a> (replaced) [<a href="/pdf/2308.14606" title="Download PDF">pdf</a>, <a href="/format/2308.14606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Tradeoff between Privacy Preservation and Byzantine-Robustness in  Decentralized Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Haoxiang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Heng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+Q">Qing Ling</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15637" title="Abstract">arXiv:2308.15637</a> (replaced) [<a href="/pdf/2308.15637" title="Download PDF">pdf</a>, <a href="/format/2308.15637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Managing Software Provenance to Enhance Reproducibility in Computational  Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhruv%2C+A">Akash Dhruv</a>, 
<a href="/search/cs?searchtype=author&query=Dubey%2C+A">Anshu Dubey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01431" title="Abstract">arXiv:2309.01431</a> (replaced) [<a href="/pdf/2309.01431" title="Download PDF">pdf</a>, <a href="/format/2309.01431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Large Language Models in Retrieval-Augmented Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiawei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hongyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xianpei Han</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Le Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02033" title="Abstract">arXiv:2309.02033</a> (replaced) [<a href="/pdf/2309.02033" title="Download PDF">pdf</a>, <a href="/format/2309.02033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Juicer: A One-Stop Data Processing System for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Daoyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yilun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhijian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hesen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xuchen Pan</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+C">Ce Ge</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+D">Dawei Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yuexiang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhaoyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jinyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+B">Bolin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 Pages, 10 figures, 9 tables. The system, data recipes, and demos are continuously maintained at <a href="https://github.com/alibaba/data-juicer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Databases (cs.DB); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08023" title="Abstract">arXiv:2309.08023</a> (replaced) [<a href="/pdf/2309.08023" title="Download PDF">pdf</a>, <a href="/format/2309.08023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> USM-SCD: Multilingual Speaker Change Detection Based on Large Pretrained  Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhao%2C+G">Guanlong Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yongqiang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Pelecanos%2C+J">Jason Pelecanos</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Liao%2C+H">Hank Liao</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yiling Huang</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+H">Han Lu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Q">Quan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09128" title="Abstract">arXiv:2309.09128</a> (replaced) [<a href="/pdf/2309.09128" title="Download PDF">pdf</a>, <a href="/format/2309.09128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChainForge: A Visual Toolkit for Prompt Engineering and LLM Hypothesis  Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arawjo%2C+I">Ian Arawjo</a>, 
<a href="/search/cs?searchtype=author&query=Swoopes%2C+C">Chelse Swoopes</a>, 
<a href="/search/cs?searchtype=author&query=Vaithilingam%2C+P">Priyan Vaithilingam</a>, 
<a href="/search/cs?searchtype=author&query=Wattenberg%2C+M">Martin Wattenberg</a>, 
<a href="/search/cs?searchtype=author&query=Glassman%2C+E">Elena Glassman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 7 figures, in submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10689" title="Abstract">arXiv:2309.10689</a> (replaced) [<a href="/pdf/2309.10689" title="Download PDF">pdf</a>, <a href="/format/2309.10689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReShader: View-Dependent Highlights for Single Image View-Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paliwal%2C+A">Avinash Paliwal</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+B">Brandon Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Tsarov%2C+A">Andrii Tsarov</a>, 
<a href="/search/cs?searchtype=author&query=Kalantari%2C+N+K">Nima Khademi Kalantari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGGRAPH Asia 2023. Project page at <a href="https://people.engr.tamu.edu/nimak/Papers/SIGAsia2023_Reshader/index.html">this https URL</a> and video at <a href="https://www.youtube.com/watch?v=XW-tl48D3Ok">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM Transactions on Graphics (ToG) 42,6 (2023) 1-9
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13059" title="Abstract">arXiv:2309.13059</a> (replaced) [<a href="/pdf/2309.13059" title="Download PDF">pdf</a>, <a href="/format/2309.13059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Traditional Teaching: The Potential of Large Language Models and  Chatbots in Graduate Engineering Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abedi%2C+M">Mahyar Abedi</a>, 
<a href="/search/cs?searchtype=author&query=Alshybani%2C+I">Ibrahem Alshybani</a>, 
<a href="/search/cs?searchtype=author&query=Shahadat%2C+M+R+B">Muhammad Rubayat Bin Shahadat</a>, 
<a href="/search/cs?searchtype=author&query=Murillo%2C+M+S">Michael S. Murillo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages, 18 figures, preprint for PLOS ONE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15312" title="Abstract">arXiv:2309.15312</a> (replaced) [<a href="/pdf/2309.15312" title="Download PDF">pdf</a>, <a href="/format/2309.15312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAPTree: Beating &quot;Optimal&quot; Decision Trees with Bayesian Decision Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sullivan%2C+C">Colin Sullivan</a>, 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+M">Mo Tiwari</a>, 
<a href="/search/cs?searchtype=author&query=Thrun%2C+S">Sebastian Thrun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17255" title="Abstract">arXiv:2309.17255</a> (replaced) [<a href="/pdf/2309.17255" title="Download PDF">pdf</a>, <a href="/format/2309.17255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Graphs for the Life Sciences: Recent Developments, Challenges  and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaoyan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Hastings%2C+J">Janna Hastings</a>, 
<a href="/search/cs?searchtype=author&query=Jim%C3%A9nez-Ruiz%2C+E">Ernesto Jim&#xe9;nez-Ruiz</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+V">Vanessa L&#xf3;pez</a>, 
<a href="/search/cs?searchtype=author&query=Monnin%2C+P">Pierre Monnin</a>, 
<a href="/search/cs?searchtype=author&query=Pesquita%2C+C">Catia Pesquita</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0koda%2C+P">Petr &#x160;koda</a>, 
<a href="/search/cs?searchtype=author&query=Tamma%2C+V">Valentina Tamma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 1 figure, camera-ready version, accepted for Transactions on Graph Data and Knowledge (TGDK)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00340" title="Abstract">arXiv:2310.00340</a> (replaced) [<a href="/pdf/2310.00340" title="Download PDF">pdf</a>, <a href="/ps/2310.00340" title="Download PostScript">ps</a>, <a href="/format/2310.00340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regulating Dark Patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brenncke%2C+M">Martin Brenncke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> forthcoming in Notre Dame Journal of International &amp; Comparative Law
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01685" title="Abstract">arXiv:2310.01685</a> (replaced) [<a href="/pdf/2310.01685" title="Download PDF">pdf</a>, <a href="/format/2310.01685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Framework for Interpretability in Machine Learning for Medical Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+A+Q">Alan Q. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Karaman%2C+B+K">Batuhan K. Karaman</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Heejong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Rosenthal%2C+J">Jacob Rosenthal</a>, 
<a href="/search/cs?searchtype=author&query=Saluja%2C+R">Rachit Saluja</a>, 
<a href="/search/cs?searchtype=author&query=Young%2C+S+I">Sean I. Young</a>, 
<a href="/search/cs?searchtype=author&query=Sabuncu%2C+M+R">Mert R. Sabuncu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02152" title="Abstract">arXiv:2310.02152</a> (replaced) [<a href="/pdf/2310.02152" title="Download PDF">pdf</a>, <a href="/format/2310.02152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Neural Network-based EEG Classification: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Klepl%2C+D">Dominik Klepl</a>, 
<a href="/search/q-bio?searchtype=author&query=Wu%2C+M">Min Wu</a>, 
<a href="/search/q-bio?searchtype=author&query=He%2C+F">Fei He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03560" title="Abstract">arXiv:2310.03560</a> (replaced) [<a href="/pdf/2310.03560" title="Download PDF">pdf</a>, <a href="/format/2310.03560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Redefining Digital Health Interfaces with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Imrie%2C+F">Fergus Imrie</a>, 
<a href="/search/cs?searchtype=author&query=Rauba%2C+P">Paulius Rauba</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Schaar%2C+M">Mihaela van der Schaar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04469" title="Abstract">arXiv:2310.04469</a> (replaced) [<a href="/pdf/2310.04469" title="Download PDF">pdf</a>, <a href="/format/2310.04469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taming Binarized Neural Networks and Mixed-Integer Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aspman%2C+J">Johannes Aspman</a>, 
<a href="/search/cs?searchtype=author&query=Korpas%2C+G">Georgios Korpas</a>, 
<a href="/search/cs?searchtype=author&query=Marecek%2C+J">Jakub Marecek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the AAAI Conference on Artificial Intelligence,
  2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06958" title="Abstract">arXiv:2310.06958</a> (replaced) [<a href="/pdf/2310.06958" title="Download PDF">pdf</a>, <a href="/format/2310.06958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing the robustness of modern no-reference image- and video-quality  metrics to adversarial attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Antsiferova%2C+A">Anastasia Antsiferova</a>, 
<a href="/search/cs?searchtype=author&query=Abud%2C+K">Khaled Abud</a>, 
<a href="/search/cs?searchtype=author&query=Gushchin%2C+A">Aleksandr Gushchin</a>, 
<a href="/search/cs?searchtype=author&query=Shumitskaya%2C+E">Ekaterina Shumitskaya</a>, 
<a href="/search/cs?searchtype=author&query=Lavrushkin%2C+S">Sergey Lavrushkin</a>, 
<a href="/search/cs?searchtype=author&query=Vatolin%2C+D">Dmitriy Vatolin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Multimedia (cs.MM); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07811" title="Abstract">arXiv:2310.07811</a> (replaced) [<a href="/pdf/2310.07811" title="Download PDF">pdf</a>, <a href="/ps/2310.07811" title="Download PostScript">ps</a>, <a href="/format/2310.07811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online RL in Linearly $q^&#x3c0;$-Realizable MDPs Is as Easy as in Linear  MDPs If You Learn What to Ignore
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weisz%2C+G">Gell&#xe9;rt Weisz</a>, 
<a href="/search/cs?searchtype=author&query=Gy%C3%B6rgy%2C+A">Andr&#xe1;s Gy&#xf6;rgy</a>, 
<a href="/search/cs?searchtype=author&query=Szepesv%C3%A1ri%2C+C">Csaba Szepesv&#xe1;ri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09688" title="Abstract">arXiv:2310.09688</a> (replaced) [<a href="/pdf/2310.09688" title="Download PDF">pdf</a>, <a href="/format/2310.09688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recursively-Constrained Partially Observable Markov Decision Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ho%2C+Q+H">Qi Heng Ho</a>, 
<a href="/search/cs?searchtype=author&query=Becker%2C+T">Tyler Becker</a>, 
<a href="/search/cs?searchtype=author&query=Kraske%2C+B">Benjamin Kraske</a>, 
<a href="/search/cs?searchtype=author&query=Laouar%2C+Z">Zakariya Laouar</a>, 
<a href="/search/cs?searchtype=author&query=Feather%2C+M+S">Martin S. Feather</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+F">Federico Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Lahijanian%2C+M">Morteza Lahijanian</a>, 
<a href="/search/cs?searchtype=author&query=Sunberg%2C+Z+N">Zachary N. Sunberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14747" title="Abstract">arXiv:2310.14747</a> (replaced) [<a href="/pdf/2310.14747" title="Download PDF">pdf</a>, <a href="/format/2310.14747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MCC-KD: Multi-CoT Consistent Knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongzhan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Siyue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+X">Xiaojun Quan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+M">Ming Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Ji Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ENMLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14884" title="Abstract">arXiv:2310.14884</a> (replaced) [<a href="/pdf/2310.14884" title="Download PDF">pdf</a>, <a href="/format/2310.14884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Budgeted Embedding Table For Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yunke Qu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q+V+H">Quoc Viet Hung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongzhi Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WSDM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14958" title="Abstract">arXiv:2310.14958</a> (replaced) [<a href="/pdf/2310.14958" title="Download PDF">pdf</a>, <a href="/format/2310.14958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Real-World Image De-Weathering with Imperfect Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaohui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhilu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaohe Wu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chaoyu Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaotao Wang</a>, 
<a href="/search/cs?searchtype=author&query=LEI%2C+L">LEI LEI</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+W">Wangmeng Zuo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15494" title="Abstract">arXiv:2310.15494</a> (replaced) [<a href="/pdf/2310.15494" title="Download PDF">pdf</a>, <a href="/format/2310.15494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TRAMS: Training-free Memory Selection for Long-range Language Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haofei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cunxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+W">Wei Bi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15582" title="Abstract">arXiv:2310.15582</a> (replaced) [<a href="/pdf/2310.15582" title="Download PDF">pdf</a>, <a href="/format/2310.15582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SecV: Secure Code Partitioning via Multi-Language Secure Values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuhala%2C+P">Peterson Yuhala</a>, 
<a href="/search/cs?searchtype=author&query=Felber%2C+P">Pascal Felber</a>, 
<a href="/search/cs?searchtype=author&query=Guiroux%2C+H">Hugo Guiroux</a>, 
<a href="/search/cs?searchtype=author&query=Lozi%2C+J">Jean-Pierre Lozi</a>, 
<a href="/search/cs?searchtype=author&query=Tchana%2C+A">Alain Tchana</a>, 
<a href="/search/cs?searchtype=author&query=Schiavoni%2C+V">Valerio Schiavoni</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+G">Ga&#xeb;l Thomas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16999" title="Abstract">arXiv:2310.16999</a> (replaced) [<a href="/pdf/2310.16999" title="Download PDF">pdf</a>, <a href="/format/2310.16999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trust, but Verify: Robust Image Segmentation using Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zaman%2C+F+A">Fahim Ahmed Zaman</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaodong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weiyu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sonka%2C+M">Milan Sonka</a>, 
<a href="/search/cs?searchtype=author&query=Mudumbai%2C+R">Raghuraman Mudumbai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 Pages, 8 Figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19459" title="Abstract">arXiv:2310.19459</a> (replaced) [<a href="/pdf/2310.19459" title="Download PDF">pdf</a>, <a href="/format/2310.19459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Security Challenges for Cloud or Fog Computing-Based AI Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pakmehr%2C+A">Amir Pakmehr</a>, 
<a href="/search/cs?searchtype=author&query=A%C3%9Fmuth%2C+A">Andreas A&#xdf;muth</a>, 
<a href="/search/cs?searchtype=author&query=Neumann%2C+C+P">Christoph P. Neumann</a>, 
<a href="/search/cs?searchtype=author&query=Pirkl%2C+G">Gerald Pirkl</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc of the 14th International Conference on Cloud Computing,
  GRIDs, and Virtualization (Cloud Computing 2023), Nice, France, June 2023,
  pp. 21-29, ISSN 2308-4294
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19461" title="Abstract">arXiv:2310.19461</a> (replaced) [<a href="/pdf/2310.19461" title="Download PDF">pdf</a>, <a href="/format/2310.19461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FoodFresh: Multi-Chain Design for an Inter-Institutional Food Supply  Chain Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stangl%2C+P">Philipp Stangl</a>, 
<a href="/search/cs?searchtype=author&query=Neumann%2C+C+P">Christoph P. Neumann</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc of the 14th International Conference on Cloud Computing,
  GRIDs, and Virtualization (Cloud Computing 2023), Nice, France, June 2023,
  pp. 41-46, ISSN 2308-4294
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02554" title="Abstract">arXiv:2311.02554</a> (replaced) [<a href="/pdf/2311.02554" title="Download PDF">pdf</a>, <a href="/format/2311.02554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pilot-Based Key Distribution and Encryption for Secure Coherent Passive  Optical Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haide Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Ji Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Qingxin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+J">Jianrui Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yongqing Liao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Changyuan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhaohui Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been submitted to the Journal of Lightwave Technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03351" title="Abstract">arXiv:2311.03351</a> (replaced) [<a href="/pdf/2311.03351" title="Download PDF">pdf</a>, <a href="/format/2311.03351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uni-O4: Unifying Online and Offline Deep Reinforcement Learning with  Multi-Step On-Policy Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+K">Kun Lei</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhengmao He</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chenhao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+K">Kaizhe Hu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huazhe Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our website: <a href="https://lei-kun.github.io/uni-o4/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04207" title="Abstract">arXiv:2311.04207</a> (replaced) [<a href="/pdf/2311.04207" title="Download PDF">pdf</a>, <a href="/format/2311.04207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Hashing via Householder Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schwengber%2C+L+R">Lucas R. Schwengber</a>, 
<a href="/search/cs?searchtype=author&query=Resende%2C+L">Lucas Resende</a>, 
<a href="/search/cs?searchtype=author&query=Orenstein%2C+P">Paulo Orenstein</a>, 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+R+I">Roberto I. Oliveira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04590" title="Abstract">arXiv:2311.04590</a> (replaced) [<a href="/pdf/2311.04590" title="Download PDF">pdf</a>, <a href="/format/2311.04590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Cross-Domain Sequential Recommendation under Open-World  Assumptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wujiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qitian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Runzhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ha%2C+M">Mingming Ha</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Q">Qiongxu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Linxun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bing Han</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06875" title="Abstract">arXiv:2311.06875</a> (replaced) [<a href="/pdf/2311.06875" title="Download PDF">pdf</a>, <a href="/ps/2311.06875" title="Download PostScript">ps</a>, <a href="/format/2311.06875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modularity of nearly complete graphs and bipartite graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=McDiarmid%2C+C">Colin McDiarmid</a>, 
<a href="/search/math?searchtype=author&query=Skerman%2C+F">Fiona Skerman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08206" title="Abstract">arXiv:2311.08206</a> (replaced) [<a href="/pdf/2311.08206" title="Download PDF">pdf</a>, <a href="/ps/2311.08206" title="Download PostScript">ps</a>, <a href="/format/2311.08206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-Centric Autonomous Systems With LLMs for User Command Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Ci Li</a>, 
<a href="/search/cs?searchtype=author&query=Marta%2C+D+S">Daniel Sim&#xf5;es Marta</a>, 
<a href="/search/cs?searchtype=author&query=Batool%2C+N">Nazre Batool</a>, 
<a href="/search/cs?searchtype=author&query=Folkesson%2C+J">John Folkesson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) Workshops, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08925" title="Abstract">arXiv:2311.08925</a> (replaced) [<a href="/pdf/2311.08925" title="Download PDF">pdf</a>, <a href="/format/2311.08925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Octal Annular Ring-Shaped Planar Monopole Antenna For WiFi And  Unlicensed Ultra Wideband Frequency Range Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mangal%2C+J">Jai Mangal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 8 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10197" title="Abstract">arXiv:2311.10197</a> (replaced) [<a href="/pdf/2311.10197" title="Download PDF">pdf</a>, <a href="/format/2311.10197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> You Cannot Escape Me: Detecting Evasions of SIEM Rules in Enterprise  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uetz%2C+R">Rafael Uetz</a>, 
<a href="/search/cs?searchtype=author&query=Herzog%2C+M">Marco Herzog</a>, 
<a href="/search/cs?searchtype=author&query=Hackl%C3%A4nder%2C+L">Louis Hackl&#xe4;nder</a>, 
<a href="/search/cs?searchtype=author&query=Schwarz%2C+S">Simon Schwarz</a>, 
<a href="/search/cs?searchtype=author&query=Henze%2C+M">Martin Henze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in Proceedings of the 33rd USENIX Security Symposium (USENIX Security 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11296" title="Abstract">arXiv:2311.11296</a> (replaced) [<a href="/pdf/2311.11296" title="Download PDF">pdf</a>, <a href="/format/2311.11296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Approximation Algorithms for Minimizing the Total Weighted  Completion Time of Coflows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chi-Yeh Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11383" title="Abstract">arXiv:2311.11383</a> (replaced) [<a href="/pdf/2311.11383" title="Download PDF">pdf</a>, <a href="/format/2311.11383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Emerging Applications of Diffusion Probabilistic Models in  MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yuheng Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+H">Hanxi Liao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shiqi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yimin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Huazhu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+H">Haikun Qi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12420" title="Abstract">arXiv:2311.12420</a> (replaced) [<a href="/pdf/2311.12420" title="Download PDF">pdf</a>, <a href="/format/2311.12420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Far Have We Gone in Vulnerability Detection Using Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zeyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuchen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13073" title="Abstract">arXiv:2311.13073</a> (replaced) [<a href="/pdf/2311.13073" title="Download PDF">pdf</a>, <a href="/format/2311.13073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FusionFrames: Efficient Architectural Aspects for Text-to-Video  Generation Pipeline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arkhipkin%2C+V">Vladimir Arkhipkin</a>, 
<a href="/search/cs?searchtype=author&query=Shaheen%2C+Z">Zein Shaheen</a>, 
<a href="/search/cs?searchtype=author&query=Vasilev%2C+V">Viacheslav Vasilev</a>, 
<a href="/search/cs?searchtype=author&query=Dakhova%2C+E">Elizaveta Dakhova</a>, 
<a href="/search/cs?searchtype=author&query=Kuznetsov%2C+A">Andrey Kuznetsov</a>, 
<a href="/search/cs?searchtype=author&query=Dimitrov%2C+D">Denis Dimitrov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://ai-forever.github.io/kandinsky-video/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14521" title="Abstract">arXiv:2311.14521</a> (replaced) [<a href="/pdf/2311.14521" title="Download PDF">pdf</a>, <a href="/format/2311.14521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GaussianEditor: Swift and Controllable 3D Editing with Gaussian  Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiwen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zilong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Feng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaofeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yikai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhongang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huaping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guosheng Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://buaacyw.github.io/gaussian-editor/">this https URL</a> Code: <a href="https://github.com/buaacyw/GaussianEditor">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15803" title="Abstract">arXiv:2311.15803</a> (replaced) [<a href="/pdf/2311.15803" title="Download PDF">pdf</a>, <a href="/format/2311.15803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SOAC: Spatio-Temporal Overlap-Aware Multi-Sensor Calibration using  Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herau%2C+Q">Quentin Herau</a>, 
<a href="/search/cs?searchtype=author&query=Piasco%2C+N">Nathan Piasco</a>, 
<a href="/search/cs?searchtype=author&query=Bennehar%2C+M">Moussab Bennehar</a>, 
<a href="/search/cs?searchtype=author&query=Rold%C3%A3o%2C+L">Luis Rold&#xe3;o</a>, 
<a href="/search/cs?searchtype=author&query=Tsishkou%2C+D">Dzmitry Tsishkou</a>, 
<a href="/search/cs?searchtype=author&query=Migniot%2C+C">Cyrille Migniot</a>, 
<a href="/search/cs?searchtype=author&query=Vasseur%2C+P">Pascal Vasseur</a>, 
<a href="/search/cs?searchtype=author&query=Demonceaux%2C+C">C&#xe9;dric Demonceaux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper + Supplementary, under review. Project page: <a href="https://qherau.github.io/SOAC/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15917" title="Abstract">arXiv:2311.15917</a> (replaced) [<a href="/pdf/2311.15917" title="Download PDF">pdf</a>, <a href="/format/2311.15917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Graph Convolution Meets Double Attention: Online Privacy Disclosure  Detection with Multi-Label Text Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zhanbo Liang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jie Guo</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+W">Weidong Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shujun Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The manuscript is accepted by Data Mining and Knowledge Discovery(ECML PKDD Journal track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16135" title="Abstract">arXiv:2311.16135</a> (replaced) [<a href="/pdf/2311.16135" title="Download PDF">pdf</a>, <a href="/format/2311.16135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Use of Deep Neural Networks for Uncertain Stress Functions with  Extensions to Impact Mechanics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Blum%2C+G">Garrett Blum</a>, 
<a href="/search/cond-mat?searchtype=author&query=Doris%2C+R">Ryan Doris</a>, 
<a href="/search/cond-mat?searchtype=author&query=Klabjan%2C+D">Diego Klabjan</a>, 
<a href="/search/cond-mat?searchtype=author&query=Espinosa%2C+H">Horacio Espinosa</a>, 
<a href="/search/cond-mat?searchtype=author&query=Szalkowski%2C+R">Ron Szalkowski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Index Terms: Stress, Uncertainty, Impact Mechanics, Deep Learning, Neural Network. 10 pages, 9 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16716" title="Abstract">arXiv:2311.16716</a> (replaced) [<a href="/pdf/2311.16716" title="Download PDF">pdf</a>, <a href="/format/2311.16716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphPro: Graph Pre-training and Prompt Learning for Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuhao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Lianghao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+D">Da Luo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kangyi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16984" title="Abstract">arXiv:2311.16984</a> (replaced) [<a href="/pdf/2311.16984" title="Download PDF">pdf</a>, <a href="/format/2311.16984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedECA: A Federated External Control Arm Method for Causal Inference  with Time-To-Event Data in Distributed Settings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Terrail%2C+J+O+d">Jean Ogier du Terrail</a>, 
<a href="/search/stat?searchtype=author&query=Klopfenstein%2C+Q">Quentin Klopfenstein</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+H">Honghao Li</a>, 
<a href="/search/stat?searchtype=author&query=Mayer%2C+I">Imke Mayer</a>, 
<a href="/search/stat?searchtype=author&query=Loiseau%2C+N">Nicolas Loiseau</a>, 
<a href="/search/stat?searchtype=author&query=Hallal%2C+M">Mohammad Hallal</a>, 
<a href="/search/stat?searchtype=author&query=Balazard%2C+F">F&#xe9;lix Balazard</a>, 
<a href="/search/stat?searchtype=author&query=Andreux%2C+M">Mathieu Andreux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> code available at: <a href="https://github.com/owkin/fedeca">this https URL</a>, fixed some typos, figures and acknowledgments in v2
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00626" title="Abstract">arXiv:2312.00626</a> (replaced) [<a href="/pdf/2312.00626" title="Download PDF">pdf</a>, <a href="/format/2312.00626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forecasting Trends in Food Security: a Reservoir Computing Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herteux%2C+J">Joschka Herteux</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%A4th%2C+C">Christoph R&#xe4;th</a>, 
<a href="/search/cs?searchtype=author&query=Baha%2C+A">Amine Baha</a>, 
<a href="/search/cs?searchtype=author&query=Martini%2C+G">Giulia Martini</a>, 
<a href="/search/cs?searchtype=author&query=Piovani%2C+D">Duccio Piovani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 11 figures, typo in acknowledgements corrected
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Physics and Society (physics.soc-ph); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02464" title="Abstract">arXiv:2312.02464</a> (replaced) [<a href="/pdf/2312.02464" title="Download PDF">pdf</a>, <a href="/format/2312.02464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAM-Assisted Remote Sensing Imagery Semantic Segmentation with Object  and Boundary Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xianping Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qianqian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xingyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaokang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pun%2C+M">Man-On Pun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Bo Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02542" title="Abstract">arXiv:2312.02542</a> (replaced) [<a href="/pdf/2312.02542" title="Download PDF">pdf</a>, <a href="/format/2312.02542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fortress: Securing IoT Peripherals with Trusted Execution Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuhala%2C+P">Peterson Yuhala</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%A9n%C3%A9trey%2C+J">J&#xe4;mes M&#xe9;n&#xe9;trey</a>, 
<a href="/search/cs?searchtype=author&query=Felber%2C+P">Pascal Felber</a>, 
<a href="/search/cs?searchtype=author&query=Pasin%2C+M">Marcelo Pasin</a>, 
<a href="/search/cs?searchtype=author&query=Schiavoni%2C+V">Valerio Schiavoni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02916" title="Abstract">arXiv:2312.02916</a> (replaced) [<a href="/pdf/2312.02916" title="Download PDF">pdf</a>, <a href="/format/2312.02916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MIND: Multi-Task Incremental Network Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bonato%2C+J">Jacopo Bonato</a>, 
<a href="/search/cs?searchtype=author&query=Pelosin%2C+F">Francesco Pelosin</a>, 
<a href="/search/cs?searchtype=author&query=Sabetta%2C+L">Luigi Sabetta</a>, 
<a href="/search/cs?searchtype=author&query=Nicolosi%2C+A">Alessandro Nicolosi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 38th AAAI Conference on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03393" title="Abstract">arXiv:2312.03393</a> (replaced) [<a href="/pdf/2312.03393" title="Download PDF">pdf</a>, <a href="/format/2312.03393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PS$^3$: Precise Patch Presence Test based on Semantic Symbolic Signature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Q">Qi Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shanping Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03719" title="Abstract">arXiv:2312.03719</a> (replaced) [<a href="/pdf/2312.03719" title="Download PDF">pdf</a>, <a href="/ps/2312.03719" title="Download PostScript">ps</a>, <a href="/format/2312.03719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing AI Chatbots Performance in Comprehensive Standardized Test  Preparation; A Case Study with GRE
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abu-Haifa%2C+M">Mohammad Abu-Haifa</a>, 
<a href="/search/cs?searchtype=author&query=Etawi%2C+B">Bara&#x27;a Etawi</a>, 
<a href="/search/cs?searchtype=author&query=Alkhatatbeh%2C+H">Huthaifa Alkhatatbeh</a>, 
<a href="/search/cs?searchtype=author&query=Ababneh%2C+A">Ayman Ababneh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 Pages, 6 figures, and 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03795" title="Abstract">arXiv:2312.03795</a> (replaced) [<a href="/pdf/2312.03795" title="Download PDF">pdf</a>, <a href="/format/2312.03795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnimatableDreamer: Text-Guided Non-rigid 3D Model Generation and  Reconstruction with Canonical Score Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinzhou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yikai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Junliang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhengyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Fuchun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Pengkun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Ling Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+K">Kai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xintong Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bin He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://animatabledreamer.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03807" title="Abstract">arXiv:2312.03807</a> (replaced) [<a href="/pdf/2312.03807" title="Download PDF">pdf</a>, <a href="/format/2312.03807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Achieving ${O}(&#x3b5;^{-1.5})$ Complexity in Hessian/Jacobian-free  Stochastic Bilevel Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yang%2C+Y">Yifan Yang</a>, 
<a href="/search/math?searchtype=author&query=Xiao%2C+P">Peiyao Xiao</a>, 
<a href="/search/math?searchtype=author&query=Ji%2C+K">Kaiyi Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04273" title="Abstract">arXiv:2312.04273</a> (replaced) [<a href="/pdf/2312.04273" title="Download PDF">pdf</a>, <a href="/format/2312.04273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invariant Random Forest: Tree-Based Model Solution for OOD  Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yufan Liao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xing Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI Conference on Artificial Intelligence, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04728" title="Abstract">arXiv:2312.04728</a> (replaced) [<a href="/pdf/2312.04728" title="Download PDF">pdf</a>, <a href="/format/2312.04728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taming Subnet-Drift in D2D-Enabled Fog Learning: A Hierarchical Gradient  Tracking Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Evan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Brinton%2C+C+G">Christopher G. Brinton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted for publication in the proceedings of 2024 IEEE International Conference on Computer Communications (INFOCOM)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04810" title="Abstract">arXiv:2312.04810</a> (replaced) [<a href="/pdf/2312.04810" title="Download PDF">pdf</a>, <a href="/format/2312.04810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RS-Corrector: Correcting the Racial Stereotypes in Latent Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yue Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Y">Yueming Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Tianxiang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Bo Peng</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jing Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 15 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04875" title="Abstract">arXiv:2312.04875</a> (replaced) [<a href="/pdf/2312.04875" title="Download PDF">pdf</a>, <a href="/format/2312.04875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MVDD: Multi-View Depth Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qiangeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+F">Feitong Tan</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+M">Menglei Chai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shichen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+R">Rohit Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Fanello%2C+S">Sean Fanello</a>, 
<a href="/search/cs?searchtype=author&query=Kadambi%2C+A">Achuta Kadambi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yinda Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05614" title="Abstract">arXiv:2312.05614</a> (replaced) [<a href="/pdf/2312.05614" title="Download PDF">pdf</a>, <a href="/format/2312.05614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer as Linear Expansion of Learngene
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shiyu Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Miaosen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruiming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haokun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+X">Xin Geng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06022" title="Abstract">arXiv:2312.06022</a> (replaced) [<a href="/pdf/2312.06022" title="Download PDF">pdf</a>, <a href="/format/2312.06022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Representation Bias for Data Distillation in Abstractive Text  Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atri%2C+Y+K">Yash Kumar Atri</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+V">Vikram Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+T">Tanmoy Chakraborty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06106" title="Abstract">arXiv:2312.06106</a> (replaced) [<a href="/pdf/2312.06106" title="Download PDF">pdf</a>, <a href="/format/2312.06106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AUGCAL: Improving Sim2Real Adaptation by Uncertainty Calibration on  Augmented Synthetic Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chattopadhyay%2C+P">Prithvijit Chattopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+B">Bharat Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Ecsedi%2C+B">Boglarka Ecsedi</a>, 
<a href="/search/cs?searchtype=author&query=Prabhu%2C+V">Viraj Prabhu</a>, 
<a href="/search/cs?searchtype=author&query=Hoffman%2C+J">Judy Hoffman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06914" title="Abstract">arXiv:2312.06914</a> (replaced) [<a href="/pdf/2312.06914" title="Download PDF">pdf</a>, <a href="/format/2312.06914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Novel Object Recognition and Spontaneous Location Recognition  Machine Learning Analysis Techniques in Alzheimer&#x27;s Mice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bafana%2C+S">Soham Bafana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 Pages. All code used in this research can be found at <a href="https://github.com/bafanaS/DLC-Object-Recognition-Analysis.git">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07392" title="Abstract">arXiv:2312.07392</a> (replaced) [<a href="/pdf/2312.07392" title="Download PDF">pdf</a>, <a href="/format/2312.07392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReRoGCRL: Representation-based Robustness in Goal-Conditioned  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xiangyu Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Sihao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaxu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+M">Meng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xingyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaowei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+W">Wenjie Ruan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted in AAAI24 (<a href="https://aaai.org/aaai-conference/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07879" title="Abstract">arXiv:2312.07879</a> (replaced) [<a href="/pdf/2312.07879" title="Download PDF">pdf</a>, <a href="/format/2312.07879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoIE: Chain-of-Instruct Editing for Multi-Attribute Face Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenduo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo-Wen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07937" title="Abstract">arXiv:2312.07937</a> (replaced) [<a href="/pdf/2312.07937" title="Download PDF">pdf</a>, <a href="/format/2312.07937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BOTH2Hands: Inferring 3D Hands from Both Text Prompts and Body Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenqian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Molin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuxuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Juze Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jingyi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingya Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08174" title="Abstract">arXiv:2312.08174</a> (replaced) [<a href="/pdf/2312.08174" title="Download PDF">pdf</a>, <a href="/format/2312.08174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Double Machine Learning for Static Panel Models with Fixed Effects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Clarke%2C+P">Paul Clarke</a>, 
<a href="/search/econ?searchtype=author&query=Polselli%2C+A">Annalivia Polselli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 5 tables, 5 figure, 2 appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics (econ.EM)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08288" title="Abstract">arXiv:2312.08288</a> (replaced) [<a href="/pdf/2312.08288" title="Download PDF">pdf</a>, <a href="/format/2312.08288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Sample Synthesis-based Debiasing of Classifier in Limited Data  Setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arora%2C+P">Piyush Arora</a>, 
<a href="/search/cs?searchtype=author&query=Mazumder%2C+P">Pratik Mazumder</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08403" title="Abstract">arXiv:2312.08403</a> (replaced) [<a href="/pdf/2312.08403" title="Download PDF">pdf</a>, <a href="/format/2312.08403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Earthfarseer: Versatile Spatio-Temporal Dynamical Systems Modeling in  One Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuxuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhengyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+W">Wei Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kun Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08410" title="Abstract">arXiv:2312.08410</a> (replaced) [<a href="/pdf/2312.08410" title="Download PDF">pdf</a>, <a href="/format/2312.08410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Approximation Property of Random Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neufeld%2C+A">Ariel Neufeld</a>, 
<a href="/search/cs?searchtype=author&query=Schmocker%2C+P">Philipp Schmocker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 64 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Probability (math.PR); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08488" title="Abstract">arXiv:2312.08488</a> (replaced) [<a href="/pdf/2312.08488" title="Download PDF">pdf</a>, <a href="/format/2312.08488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PnP for Two-Dimensional Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Joshua Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 figures. Improved testing figures from version 1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08866" title="Abstract">arXiv:2312.08866</a> (replaced) [<a href="/pdf/2312.08866" title="Download PDF">pdf</a>, <a href="/format/2312.08866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MCANet: Medical Image Segmentation with Multi-Scale Cross-Axis Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shao%2C+H">Hao Shao</a>, 
<a href="/search/eess?searchtype=author&query=Zeng%2C+Q">Quansheng Zeng</a>, 
<a href="/search/eess?searchtype=author&query=Hou%2C+Q">Qibin Hou</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+J">Jufeng Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09085" title="Abstract">arXiv:2312.09085</a> (replaced) [<a href="/pdf/2312.09085" title="Download PDF">pdf</a>, <a href="/format/2312.09085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Earth is Flat because...: Investigating LLMs&#x27; Belief towards  Misinformation via Persuasive Conversation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Rongwu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B+S">Brian S. Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shujian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Weiyan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhixuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+H">Han Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09513" title="Abstract">arXiv:2312.09513</a> (replaced) [<a href="/pdf/2312.09513" title="Download PDF">pdf</a>, <a href="/format/2312.09513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CGS-Mask: Making Time Series Predictions Intuitive for All
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+F">Feng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yifei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Cheng Song</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yufei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zomaya%2C+A+Y">Albert Y. Zomaya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09787" title="Abstract">arXiv:2312.09787</a> (replaced) [<a href="/pdf/2312.09787" title="Download PDF">pdf</a>, <a href="/format/2312.09787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-informed Neural Network Estimation of Material Properties in  Soft Tissue Nonlinear Biomechanical Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caforio%2C+F">Federica Caforio</a>, 
<a href="/search/cs?searchtype=author&query=Regazzoni%2C+F">Francesco Regazzoni</a>, 
<a href="/search/cs?searchtype=author&query=Pagani%2C+S">Stefano Pagani</a>, 
<a href="/search/cs?searchtype=author&query=Karabelas%2C+E">Elias Karabelas</a>, 
<a href="/search/cs?searchtype=author&query=Augustin%2C+C">Christoph Augustin</a>, 
<a href="/search/cs?searchtype=author&query=Haase%2C+G">Gundolf Haase</a>, 
<a href="/search/cs?searchtype=author&query=Plank%2C+G">Gernot Plank</a>, 
<a href="/search/cs?searchtype=author&query=Quarteroni%2C+A">Alfio Quarteroni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Biological Physics (physics.bio-ph); Medical Physics (physics.med-ph)

</div>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10080" title="Abstract">arXiv:2312.10080</a> (replaced) [<a href="/pdf/2312.10080" title="Download PDF">pdf</a>, <a href="/ps/2312.10080" title="Download PostScript">ps</a>, <a href="/format/2312.10080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> No prejudice! Fair Federated Graph Neural Networks for Personalized  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+N">Nimesh Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Sirohi%2C+A+K">Anuj Kumar Sirohi</a>, 
<a href="/search/cs?searchtype=author&query=Jayadeva">Jayadeva</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sandeep Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear as a full paper in AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10461" title="Abstract">arXiv:2312.10461</a> (replaced) [<a href="/pdf/2312.10461" title="Download PDF">pdf</a>, <a href="/format/2312.10461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking the Up-Sampling Operations in CNN-based Generative Network  for Generalizable Deepfake Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Chuangchuang Tan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Shikui Wei</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+G">Guanghua Gu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Ping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yunchao Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10469" title="Abstract">arXiv:2312.10469</a> (replaced) [<a href="/pdf/2312.10469" title="Download PDF">pdf</a>, <a href="/format/2312.10469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One step closer to unbiased aleatoric uncertainty estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Ziwen Ma</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Subhro Das</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+T">Tsui-Wei Weng</a>, 
<a href="/search/cs?searchtype=author&query=Megretski%2C+A">Alexandre Megretski</a>, 
<a href="/search/cs?searchtype=author&query=Daniel%2C+L">Luca Daniel</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+L+M">Lam M. Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10589" title="Abstract">arXiv:2312.10589</a> (replaced) [<a href="/pdf/2312.10589" title="Download PDF">pdf</a>, <a href="/format/2312.10589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NN-Steiner: A Mixed Neural-algorithmic Approach for the Rectilinear  Steiner Minimum Tree Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kahng%2C+A+B">Andrew B. Kahng</a>, 
<a href="/search/cs?searchtype=author&query=Nerem%2C+R+R">Robert R. Nerem</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yusu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chien-Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is the complete version with appendix of the paper accepted in AAAI'24 with the same title
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10743" title="Abstract">arXiv:2312.10743</a> (replaced) [<a href="/pdf/2312.10743" title="Download PDF">pdf</a>, <a href="/format/2312.10743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Framework for Multi-Domain CTR Prediction via Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+Z">Zichuan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chuhan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yichao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+K">Kuicai Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Mengchen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Huifeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruiming Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Still being revised
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10885" title="Abstract">arXiv:2312.10885</a> (replaced) [<a href="/e-print/2312.10885" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A novel diffusion recommendation algorithm based on multi-scale cnn and  residual lstm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yong Niu</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+X">Xing Xing</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Z">Zhichun Jia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruidi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+M">Mindong Xin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper needs to be further modified, including the ablation experiment, model framework and other information in Chapter 5. There are some inaccuracies in the presentation of this paper. Two datasets are used instead of three, and there are many inaccuracies in the presentation, which need to be further corrected
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11017" title="Abstract">arXiv:2312.11017</a> (replaced) [<a href="/pdf/2312.11017" title="Download PDF">pdf</a>, <a href="/ps/2312.11017" title="Download PostScript">ps</a>, <a href="/format/2312.11017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information Inequalities via Ideas from Additive Combinatorics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lau%2C+C+W">Chin Wa Lau</a>, 
<a href="/search/cs?searchtype=author&query=Nair%2C+C">Chandra Nair</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, The authors were made aware that some of the results had been obtained earlier. The revised version acknowledges and references this work. A conference version of this was published in the proceeding of IEEE ISIT 2023. s
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Combinatorics (math.CO); Number Theory (math.NT)

</div>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11057" title="Abstract">arXiv:2312.11057</a> (replaced) [<a href="/pdf/2312.11057" title="Download PDF">pdf</a>, <a href="/format/2312.11057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DataElixir: Purifying Poisoned Dataset to Mitigate Backdoor Attacks via  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiachen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+P">Peizhuo Lv</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yibing Lan</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+G">Guozhu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Hualong Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11143" title="Abstract">arXiv:2312.11143</a> (replaced) [<a href="/pdf/2312.11143" title="Download PDF">pdf</a>, <a href="/format/2312.11143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Domain-Independent Heuristics for Grounded and Lifted Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+D+Z">Dillon Z. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Thi%C3%A9baux%2C+S">Sylvie Thi&#xe9;baux</a>, 
<a href="/search/cs?searchtype=author&query=Trevizan%2C+F">Felipe Trevizan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of AAAI 2024 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11193" title="Abstract">arXiv:2312.11193</a> (replaced) [<a href="/pdf/2312.11193" title="Download PDF">pdf</a>, <a href="/ps/2312.11193" title="Download PostScript">ps</a>, <a href="/format/2312.11193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Paraphrasing The Original Text&quot; Makes High Accuracy Long-Context QA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yijiong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Chinese version of this paper can be downloaded from (<a href="https://cloud.tsinghua.edu.cn/d/5894ec4442e54a6aac96/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11276" title="Abstract">arXiv:2312.11276</a> (replaced) [<a href="/pdf/2312.11276" title="Download PDF">pdf</a>, <a href="/format/2312.11276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Generalization for Multi-label Text Classification: A  Data-Augmentation Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chai%2C+Y">Yuyang Chai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiahui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fei Li</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+D">Donghong Ji</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+C">Chong Teng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11404" title="Abstract">arXiv:2312.11404</a> (replaced) [<a href="/pdf/2312.11404" title="Download PDF">pdf</a>, <a href="/ps/2312.11404" title="Download PostScript">ps</a>, <a href="/format/2312.11404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An information-theoretic proof of the Shannon-Hagelbarger theorem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anantharam%2C+V">Venkat Anantharam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11489" title="Abstract">arXiv:2312.11489</a> (replaced) [<a href="/pdf/2312.11489" title="Download PDF">pdf</a>, <a href="/format/2312.11489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agglomerative Federated Learning: Empowering Larger Model Training via  End-Edge-Cloud Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Sheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Min Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+B">Bo Gao</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Q">Quyang Pan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tianliu He</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xuefeng Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE International Conference on Computer Communications (INFOCOM), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11517" title="Abstract">arXiv:2312.11517</a> (replaced) [<a href="/pdf/2312.11517" title="Download PDF">pdf</a>, <a href="/format/2312.11517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unlocking Musculoskeletal Disorder Risk Factors: NLP-Based  Classification and Mode-Based Ranking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jahin%2C+M+A">Md Abrar Jahin</a>, 
<a href="/search/cs?searchtype=author&query=Talapatra%2C+S">Subrata Talapatra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11534" title="Abstract">arXiv:2312.11534</a> (replaced) [<a href="/pdf/2312.11534" title="Download PDF">pdf</a>, <a href="/ps/2312.11534" title="Download PostScript">ps</a>, <a href="/format/2312.11534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Differentially Private and Lazy Online Convex Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+N">Naman Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Kale%2C+S">Satyen Kale</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+K">Karan Singh</a>, 
<a href="/search/cs?searchtype=author&query=Thakurta%2C+A+G">Abhradeep Guha Thakurta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11562" title="Abstract">arXiv:2312.11562</a> (replaced) [<a href="/pdf/2312.11562" title="Download PDF">pdf</a>, <a href="/format/2312.11562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Reasoning with Foundation Models: Concepts, Methodologies,  and Outlook
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiankai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chuanyang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+E">Enze Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+R">Ruihang Chu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jianing Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiaqi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Mingyu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+M">Mengzhe Geng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junsong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhangyue Yin</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiaozhe Ren</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junxian He</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Wu Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xihui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yu Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Ming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Heng%2C+P+A">Pheng Ann Heng</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jifeng Dai</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingdong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yike Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 Figures, 159 Pages, 740 References, Project Page <a href="https://github.com/reasoning-survey/Awesome-Reasoning-Foundation-Models">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11675" title="Abstract">arXiv:2312.11675</a> (replaced) [<a href="/pdf/2312.11675" title="Download PDF">pdf</a>, <a href="/format/2312.11675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PRP Rebooted: Advancing the State of the Art in FOND Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muise%2C+C">Christian Muise</a>, 
<a href="/search/cs?searchtype=author&query=McIlraith%2C+S+A">Sheila A. McIlraith</a>, 
<a href="/search/cs?searchtype=author&query=Beck%2C+J+C">J. Christopher Beck</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures, AAAI conference paper Update: Fixed abstract and typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11681" title="Abstract">arXiv:2312.11681</a> (replaced) [<a href="/pdf/2312.11681" title="Download PDF">pdf</a>, <a href="/format/2312.11681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing LLM Chains by Adapting Techniques from Crowdsourcing Workflows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grunde-McLaughlin%2C+M">Madeleine Grunde-McLaughlin</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+M+S">Michelle S. Lam</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+R">Ranjay Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Weld%2C+D+S">Daniel S. Weld</a>, 
<a href="/search/cs?searchtype=author&query=Heer%2C+J">Jeffrey Heer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11740" title="Abstract">arXiv:2312.11740</a> (replaced) [<a href="/pdf/2312.11740" title="Download PDF">pdf</a>, <a href="/format/2312.11740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Composable Design of Multiphase Fluid Dynamics Solvers in Flash-X
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhruv%2C+A">Akash Dhruv</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11831" title="Abstract">arXiv:2312.11831</a> (replaced) [<a href="/pdf/2312.11831" title="Download PDF">pdf</a>, <a href="/format/2312.11831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Locally-Minimal Probabilistic Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Izza%2C+Y">Yacine Izza</a>, 
<a href="/search/cs?searchtype=author&query=Meel%2C+K+S">Kuldeep S. Meel</a>, 
<a href="/search/cs?searchtype=author&query=Marques-Silva%2C+J">Joao Marques-Silva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11841" title="Abstract">arXiv:2312.11841</a> (replaced) [<a href="/pdf/2312.11841" title="Download PDF">pdf</a>, <a href="/format/2312.11841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MixRT: Mixed Neural Representations For Real-Time NeRF Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chaojian Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bichen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Vajda%2C+P">Peter Vajda</a>, 
<a href="/search/cs?searchtype=author&query=Yingyan">Yingyan</a> (Celine)Lin
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 3DV'24. Project Page: <a href="https://licj15.github.io/MixRT/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11953" title="Abstract">arXiv:2312.11953</a> (replaced) [<a href="/pdf/2312.11953" title="Download PDF">pdf</a>, <a href="/ps/2312.11953" title="Download PostScript">ps</a>, <a href="/format/2312.11953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Competition among Pairwise Lottery Contests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+X">Xiaotie Deng</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+H">Hangxin Gan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Ningyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weian Li</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Q">Qi Qi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 38th Annual AAAI Conference on Artificial Intelligence (AAAI 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11985" title="Abstract">arXiv:2312.11985</a> (replaced) [<a href="/pdf/2312.11985" title="Download PDF">pdf</a>, <a href="/format/2312.11985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Climate Change from Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hongyin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+P">Prayag Tiwari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12010" title="Abstract">arXiv:2312.12010</a> (replaced) [<a href="/pdf/2312.12010" title="Download PDF">pdf</a>, <a href="/format/2312.12010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Outlier detection using flexible categorisation and interrogative  agendas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boersma%2C+M">Marcel Boersma</a>, 
<a href="/search/cs?searchtype=author&query=Manoorkar%2C+K">Krishna Manoorkar</a>, 
<a href="/search/cs?searchtype=author&query=Palmigiano%2C+A">Alessandra Palmigiano</a>, 
<a href="/search/cs?searchtype=author&query=Panettiere%2C+M">Mattia Panettiere</a>, 
<a href="/search/cs?searchtype=author&query=Tzimoulis%2C+A">Apostolos Tzimoulis</a>, 
<a href="/search/cs?searchtype=author&query=Wijnberg%2C+N">Nachoem Wijnberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12036" title="Abstract">arXiv:2312.12036</a> (replaced) [<a href="/pdf/2312.12036" title="Download PDF">pdf</a>, <a href="/format/2312.12036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LHManip: A Dataset for Long-Horizon Language-Grounded Manipulation Tasks  in Cluttered Tabletop Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ceola%2C+F">Federico Ceola</a>, 
<a href="/search/cs?searchtype=author&query=Natale%2C+L">Lorenzo Natale</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%BCnderhauf%2C+N">Niko S&#xfc;nderhauf</a>, 
<a href="/search/cs?searchtype=author&query=Rana%2C+K">Krishan Rana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IJRR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12037" title="Abstract">arXiv:2312.12037</a> (replaced) [<a href="/pdf/2312.12037" title="Download PDF">pdf</a>, <a href="/format/2312.12037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Founder-GPT: Self-play to evaluate the Founder-Idea fit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+S">Sichao Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Ihlamur%2C+Y">Yigit Ihlamur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12096" title="Abstract">arXiv:2312.12096</a> (replaced) [<a href="/pdf/2312.12096" title="Download PDF">pdf</a>, <a href="/format/2312.12096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DLCA-Recon: Dynamic Loose Clothing Avatar Reconstruction from Monocular  Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Chunjie Luo</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+F">Fei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yusen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+E">Enxu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chunxia Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12143" title="Abstract">arXiv:2312.12143</a> (replaced) [<a href="/pdf/2312.12143" title="Download PDF">pdf</a>, <a href="/format/2312.12143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating Human Vision Perception in Vision Transformers for  Classifying Waste Items
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+A+K">Akshat Kishore Shrivastava</a>, 
<a href="/search/cs?searchtype=author&query=Gandhi%2C+T+K">Tapan Kumar Gandhi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12145" title="Abstract">arXiv:2312.12145</a> (replaced) [<a href="/pdf/2312.12145" title="Download PDF">pdf</a>, <a href="/format/2312.12145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OVD-Explorer: Optimism Should Not Be the Sole Pursuit of Exploration in  Noisy Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jianye Hao</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+C">Chenjia Bai</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Junjie Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Piao%2C+H">Haiyin Piao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yang Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024, with appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12183" title="Abstract">arXiv:2312.12183</a> (replaced) [<a href="/pdf/2312.12183" title="Download PDF">pdf</a>, <a href="/format/2312.12183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Poincar&#xe9; Differential Privacy for Hierarchy-Aware Graph Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yuecen Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Haonan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xingcheng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qingyun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xianxian Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chunming Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12263" title="Abstract">arXiv:2312.12263</a> (replaced) [<a href="/pdf/2312.12263" title="Download PDF">pdf</a>, <a href="/format/2312.12263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedDiv: Collaborative Noise Filtering for Federated Learning with Noisy  Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jichang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hui Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Z">Zicheng Liao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yizhou Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in AAAI-2024; correct minor typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12288" title="Abstract">arXiv:2312.12288</a> (replaced) [<a href="/pdf/2312.12288" title="Download PDF">pdf</a>, <a href="/ps/2312.12288" title="Download PostScript">ps</a>, <a href="/format/2312.12288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Qutrit Codes from Pure and Bordered Multidimensional Circulant  Construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seneviratne%2C+P">Padmapani Seneviratne</a>, 
<a href="/search/cs?searchtype=author&query=Cuff%2C+H">Hannah Cuff</a>, 
<a href="/search/cs?searchtype=author&query=Koletsos%2C+A">Alexandra Koletsos</a>, 
<a href="/search/cs?searchtype=author&query=Seekamp%2C+K">Kerry Seekamp</a>, 
<a href="/search/cs?searchtype=author&query=Thananopavarn%2C+A">Adrian Thananopavarn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12340" title="Abstract">arXiv:2312.12340</a> (replaced) [<a href="/pdf/2312.12340" title="Download PDF">pdf</a>, <a href="/format/2312.12340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Geometric Fracture Assembly via Co-creation Space among  Assemblers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruiyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaxiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zexi Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chao Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12430" title="Abstract">arXiv:2312.12430</a> (replaced) [<a href="/pdf/2312.12430" title="Download PDF">pdf</a>, <a href="/format/2312.12430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Title Reranker for Fast and Improved Knowledge-Intense NLP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Ziyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+H">Heyi Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+D">Daqian Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jize Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yuxiang Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12436" title="Abstract">arXiv:2312.12436</a> (replaced) [<a href="/pdf/2312.12436" title="Download PDF">pdf</a>, <a href="/format/2312.12436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Challenger to GPT-4V? Early Explorations of Gemini in Visual Expertise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Chaoyou Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Renrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yubo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhengye Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Longtian Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+G">Gaoxiang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yunhang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengdan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peixian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sirui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shaohui Lin</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Deqiang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Di Yin</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Peng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Ke Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xing Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Total 120 pages. See our project at <a href="https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multimedia (cs.MM)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item338">Cross-lists</a></li>
<li><a href="#item390">Replacements</a></li>
</ul>
<small>[ total of 630 entries:  <b>1-630</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2312">2312</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
