<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Mon  4 Dec 23  to  Tue  5 Dec 23, announced Wed,  6 Dec 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item365">Cross-lists</a></li>
<li><a href="#item408">Replacements</a></li>
</ul>
<small>[ total of 627 entries:  <b>1-627</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Wed,  6 Dec 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02159" title="Abstract">arXiv:2312.02159</a> [<a href="/pdf/2312.02159" title="Download PDF">pdf</a>, <a href="/format/2312.02159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral Temporal Graph Neural Network for massive MIMO CSI Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mourya%2C+S">Sharan Mourya</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+P">Pavan Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Amuru%2C+S">SaiDhiraj Amuru</a>, 
<a href="/search/cs?searchtype=author&query=Kuchi%2C+K+K">Kiran Kumar Kuchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">In the realm of 5G communication systems, the accuracy of Channel State
Information (CSI) prediction is vital for optimizing performance. This letter
introduces a pioneering approach: the Spectral-Temporal Graph Neural Network
(STEM GNN), which fuses spatial relationships and temporal dynamics of the
wireless channel using the Graph Fourier Transform. We compare the STEM GNN
approach with conventional Recurrent Neural Network (RNN) and Long Short-Term
Memory (LSTM) models for CSI prediction. Our findings reveal a significant
enhancement in overall communication system performance through STEM GNNs. For
instance, in one scenario, STEM GNN achieves a sum rate of 5.009 bps/Hz which
is $11.9\%$ higher than that of LSTM and $35\%$ higher than that of RNN. The
spectral-temporal analysis capabilities of STEM GNNs capture intricate patterns
often overlooked by traditional models, offering improvements in beamforming,
interference mitigation, and ultra-reliable low-latency communication (URLLC).
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02160" title="Abstract">arXiv:2312.02160</a> [<a href="/pdf/2312.02160" title="Download PDF">pdf</a>, <a href="/ps/2312.02160" title="Download PostScript">ps</a>, <a href="/format/2312.02160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coding for the unsourced A-channel with erasures: the linked loop code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W+W">William W. Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Ebert%2C+J+R">Jamison R. Ebert</a>, 
<a href="/search/cs?searchtype=author&query=Rini%2C+S">Stefano Rini</a>, 
<a href="/search/cs?searchtype=author&query=Chamberland%2C+J">Jean-Francois Chamberland</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, to be published in the 31st European Signal Processing Conference, EUSIPCO 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">The A-channel is a noiseless multiple access channel in which users
simultaneously transmit Q-ary symbols and the receiver observes the set of
transmitted symbols, but not their multiplicities. An A-channel is said to be
unsourced if, additionally, users transmissions are encoded across time using a
common codebook and decoding of the transmitted messages is done without regard
to the identities of the active users. An interesting variant of the unsourced
A-channel is the unsourced A-channel with erasures (UACE), in which transmitted
symbols are erased with a given independent and identically distributed
probability. In this paper, we focus on designing a code that enables a list of
transmitted codewords to be recovered despite the erasures of some of the
transmitted symbols. To this end, we propose the linked-loop code (LLC), which
uses parity bits to link each symbol to the previous M symbols in a tail-biting
manner, i.e., the first symbols of the transmission are linked to the last
ones. The decoding process occurs in two phases: the first phase decodes the
codewords that do not suffer from any erasures, and the second phase attempts
to recover the erased symbols using the available parities. We compare the
performance of the LLC over the UACE with other codes in the literature and
argue for the effectiveness of the construction. Our motivation for studying
the UACE comes from its relevance in machine-type communication and coded
compressed sensing.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02161" title="Abstract">arXiv:2312.02161</a> [<a href="/pdf/2312.02161" title="Download PDF">pdf</a>, <a href="/format/2312.02161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient LDPC Decoding using Physical Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vengalam%2C+U+K+R">Uday Kumar Reddy Vengalam</a>, 
<a href="/search/cs?searchtype=author&query=Hahn%2C+A">Andrew Hahn</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yongchao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Anshujit Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Michael Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Due to 5G deployment, there is significant interest in LDPC decoding. While
much research is devoted on efficient hardwiring of algorithms based on Belief
Propagation (BP), it has been shown that LDPC decoding can be formulated as a
combinatorial optimization problem, which could benefit from significant
acceleration of physical computation mechanisms such as Ising machines. This
approach has so far resulted in poor performance. This paper shows that the
reason is not fundamental but suboptimal hardware and formulation. A
co-designed Ising machine-based system can improve speed by 3 orders of
magnitude. As a result, a physical computation approach can outperform
hardwiring state-of-the-art algorithms. In this paper, we show such an
augmented Ising machine that is 4.4$\times$ more energy efficient than the
state of the art in the literature.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02163" title="Abstract">arXiv:2312.02163</a> [<a href="/pdf/2312.02163" title="Download PDF">pdf</a>, <a href="/format/2312.02163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cooperation Based Joint Active and Passive Sensing with Asynchronous  Transceivers for Perceptive Mobile Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wangjun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhiqing Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shaoshi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhiyong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Ping Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Performance (cs.PF); Signal Processing (eess.SP)

</div>
<p class="mathjax">Perceptive mobile network (PMN) is an emerging concept for next-generation
wireless networks capable of conducting integrated sensing and communication
(ISAC). A major challenge for realizing high performance sensing in PMNs is how
to deal with spatially separated asynchronous transceivers. Asynchronicity
results in timing offsets (TOs) and carrier frequency offsets (CFOs), which
further cause ambiguity in ranging and velocity sensing. Most existing
algorithms mitigate TOs and CFOs based on the line-of-sight (LOS) propagation
path between sensing transceivers. However, LOS paths may not exist in
realistic scenarios. In this paper, we propose a cooperation based joint active
and passive sensing scheme for the non-LOS (NLOS) scenarios having asynchronous
transceivers. This scheme relies on the cross-correlation cooperative sensing
(CCCS) algorithm, which regards active sensing as a reference and mitigates TOs
and CFOs by correlating active and passive sensing information. Another major
challenge for realizing high performance sensing in PMNs is how to realize high
accuracy angle-of-arrival (AoA) estimation with low complexity.
Correspondingly, we propose a low complexity AoA algorithm based on cooperative
sensing, which comprises coarse AoA estimation and fine AoA estimation.
Analytical and numerical simulation results verify the performance advantages
of the proposed CCCS algorithm and the low complexity AoA estimation algorithm.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02164" title="Abstract">arXiv:2312.02164</a> [<a href="/pdf/2312.02164" title="Download PDF">pdf</a>, <a href="/format/2312.02164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Driver Safety Reward with Cooperative Platooning using Blockchain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rachamalla%2C+S">Sruthi Rachamalla</a>, 
<a href="/search/cs?searchtype=author&query=Hexmoor%2C+H">Henry Hexmoor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Cooperative driving (or Platooning) focuses on improving the safety and
efficiency by connecting two or more vehicles on a road by vehicular
communication protocols. The leader is crucial as it manages the platoon,
establishes communication between cars, and perform platoon maneuvers. In this
paper, we proposed a driver incentive model which encourages platooning on
roads leading to driver safety. As, the leader of platoon have multiple
responsibilities than followers, our model rewards more incentives to leader
than followers. These incentives will be rewarded as crypto tokens. This
digital monetization method for both leaders and followers of a platoon is
accomplished by secure transactions using blockchain.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02167" title="Abstract">arXiv:2312.02167</a> [<a href="/pdf/2312.02167" title="Download PDF">pdf</a>, <a href="/format/2312.02167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Quantification in Machine Learning Based Segmentation: A  Post-Hoc Approach for Left Ventricle Volume Estimation in MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Terhag%2C+F">F. Terhag</a>, 
<a href="/search/cs?searchtype=author&query=Knechtges%2C+P">P. Knechtges</a>, 
<a href="/search/cs?searchtype=author&query=Basermann%2C+A">A. Basermann</a>, 
<a href="/search/cs?searchtype=author&query=Tempone%2C+R">R. Tempone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">Recent studies have confirmed cardiovascular diseases remain responsible for
highest death toll amongst non-communicable diseases. Accurate left ventricular
(LV) volume estimation is critical for valid diagnosis and management of
various cardiovascular conditions, but poses significant challenge due to
inherent uncertainties associated with segmentation algorithms in magnetic
resonance imaging (MRI). Recent machine learning advancements, particularly
U-Net-like convolutional networks, have facilitated automated segmentation for
medical images, but struggles under certain pathologies and/or different
scanner vendors and imaging protocols. This study proposes a novel methodology
for post-hoc uncertainty estimation in LV volume prediction using It\^{o}
stochastic differential equations (SDEs) to model path-wise behavior for the
prediction error. The model describes the area of the left ventricle along the
heart's long axis. The method is agnostic to the underlying segmentation
algorithm, facilitating its use with various existing and future segmentation
technologies. The proposed approach provides a mechanism for quantifying
uncertainty, enabling medical professionals to intervene for unreliable
predictions. This is of utmost importance in critical applications such as
medical diagnosis, where prediction accuracy and reliability can directly
impact patient outcomes. The method is also robust to dataset changes, enabling
application for medical centers with limited access to labeled data. Our
findings highlight the proposed uncertainty estimation methodology's potential
to enhance automated segmentation robustness and generalizability, paving the
way for more reliable and accurate LV volume estimation in clinical settings as
well as opening new avenues for uncertainty quantification in biomedical image
segmentation, providing promising directions for future research.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02168" title="Abstract">arXiv:2312.02168</a> [<a href="/pdf/2312.02168" title="Download PDF">pdf</a>, <a href="/format/2312.02168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The SVHN Dataset Is Deceptive for Probabilistic Generative Models Due to  a Distribution Mismatch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T+Z">Tim Z. Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zenn%2C+J">Johannes Zenn</a>, 
<a href="/search/cs?searchtype=author&query=Bamler%2C+R">Robert Bamler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023 Workshop on Distribution Shifts; 4 pages + appendix; proposed data set at <a href="https://jzenn.github.io/svhn-remix/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">The Street View House Numbers (SVHN) dataset is a popular benchmark dataset
in deep learning. Originally designed for digit classification tasks, the SVHN
dataset has been widely used as a benchmark for various other tasks including
generative modeling. However, with this work, we aim to warn the community
about an issue of the SVHN dataset as a benchmark for generative modeling
tasks: we discover that the official split into training set and test set of
the SVHN dataset are not drawn from the same distribution. We empirically show
that this distribution mismatch has little impact on the classification task
(which may explain why this issue has not been detected before), but it
severely affects the evaluation of probabilistic generative models, such as
Variational Autoencoders and diffusion models. As a workaround, we propose to
mix and re-split the official training and test set when SVHN is used for tasks
other than classification. We publish a new split and the indices we used to
create it at https://jzenn.github.io/svhn-remix/ .
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02170" title="Abstract">arXiv:2312.02170</a> [<a href="/pdf/2312.02170" title="Download PDF">pdf</a>, <a href="/format/2312.02170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiple Reference Signals Collaborative Sensing for Integrated Sensing  and Communication System Towards 5G-A and 6G
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhiqing Wei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fengyun Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haotian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Huici Wu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kaifeng Han</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhiyong Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Integrated sensing and communication (ISAC) is considered as the potential
key technology of the future mobile communication systems. The signal design is
fundamental for the ISAC system. The reference signals in mobile communication
systems have good detection performance, which is worth further research.
Existing studies applied the single reference signal to radar sensing. In this
paper, a multiple reference signals collaborative sensing scheme is designed.
Specifically, we jointly apply channel state information reference signal
(CSI-RS), positioning reference signal (PRS) and demodulation reference signal
(DMRS) in radar sensing, which improve the performance of radar sensing via
obtaining continuous time-frequency resource mapping. Cr\'amer-Rao lower bound
(CRLB) of the joint reference signal for distance and velocity estimation is
derived. The impacts of carrier frequency and subcarrier spacing on the
performance of distance and velocity estimation are revealed. The results of
simulation experiments show that compared with the single reference signal
sensing scheme, the multiple reference signals collaborative sensing scheme
effectively improves the sensing accuracy. Moreover, because of the
discontinuous OFDM symbols, the accuracy of velocity estimation could be
further improved via compressed sensing (CS). This paper has verified that
multiple reference signals, instead of single reference signal, have much more
superior performance on radar sensing, which is a practical and efficient
approach in designing ISAC signal.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02171" title="Abstract">arXiv:2312.02171</a> [<a href="/pdf/2312.02171" title="Download PDF">pdf</a>, <a href="/ps/2312.02171" title="Download PostScript">ps</a>, <a href="/format/2312.02171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LpiCT: A logic security analysis framework for protocols
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fusheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinhui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanbing Li</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+M">Mingtao Ni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12pades,7figuers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">The pi calculus is a basic theory of mobile communication based on the notion
of interaction, which, aimed at analyzing and modelling the behaviors of
communication process in communicating and mobile systems, is widely applied to
the security analysis of cryptographic protocol's design and implementation.
But the pi calculus does not provide perfect logic security analysis, so the
logic flaws in the design and the implementation of a cryptographic protocol
can not be discovered in time. The aim is to analyze whether there are logic
flaws in the design and the implementation of a cryptographic protocol, so as
to ensure the security of the cryptographic protocol when it is encoded into a
software and implemented. This paper introduces logic rules and proofs, binary
tree and the KMP algorithm, and proposes a new extension the pi calculus
theory, a logic security analysis framework and an algorithm. This paper
presents the logic security proof and analysis of TLS1.3 protocol's
interactional implementation process. Empirical results show that the new
extension theory, the logic security analysis framework and the algorithm can
effectively analyze whether there are logic flaws in the design and the
implementation of a cryptographic protocol. The security of cryptographic
protocols depends not only on cryptographic primitives, but also on the coding
of cryptographic protocols and the environment in which they are implemented.
The security analysis framework of cryptographic protocol implementation
proposed in this paper can ensure the security of protocol implementation.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02172" title="Abstract">arXiv:2312.02172</a> [<a href="/pdf/2312.02172" title="Download PDF">pdf</a>, <a href="/format/2312.02172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mercury: A modeling, simulation, and optimization framework for data  stream-oriented IoT applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=C%C3%A1rdenas%2C+R">Rom&#xe1;n C&#xe1;rdenas</a>, 
<a href="/search/cs?searchtype=author&query=Arroba%2C+P">Patricia Arroba</a>, 
<a href="/search/cs?searchtype=author&query=Blanco%2C+R">Roberto Blanco</a>, 
<a href="/search/cs?searchtype=author&query=Malag%C3%B3n%2C+P">Pedro Malag&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Risco-Mart%C3%ADn%2C+J+L">Jos&#xe9; L. Risco-Mart&#xed;n</a>, 
<a href="/search/cs?searchtype=author&query=Moya%2C+J+M">Jos&#xe9; M. Moya</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Simulation Modelling Practice and Theory, 101, 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The Internet of Things is transforming our society by monitoring users and
infrastructures' behavior to enable new services that will improve life quality
and resource management. These applications require a vast amount of localized
information to be processed in real-time so, the deployment of new fog
computing infrastructures that bring computing closer to the data sources is a
major concern. In this context, we present Mercury, a Modeling, Simulation, and
Optimization (M&amp;S&amp;O) framework to analyze the dimensioning and the dynamic
operation of real-time fog computing scenarios. Our research proposes a
location-aware solution that supports data stream analytics applications
including FaaS-based computation offloading. Mercury implements a detailed
structural and behavioral simulation model, providing fine-grained simulation
outputs, and is described using the Discrete Event System Specification (DEVS)
mathematical formalism, helping to validate the model's implementation.
Finally, we present a case study using real traces from a driver assistance
scenario, offering a detailed comparison with other state-of-the-art
simulators.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02173" title="Abstract">arXiv:2312.02173</a> [<a href="/pdf/2312.02173" title="Download PDF">pdf</a>, <a href="/format/2312.02173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TailorMe: Self-Supervised Learning of an Anatomically Constrained  Volumetric Human Shape Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wenninger%2C+S">Stephan Wenninger</a>, 
<a href="/search/cs?searchtype=author&query=Kemper%2C+F">Fabian Kemper</a>, 
<a href="/search/cs?searchtype=author&query=Schwanecke%2C+U">Ulrich Schwanecke</a>, 
<a href="/search/cs?searchtype=author&query=Botsch%2C+M">Mario Botsch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Human shape spaces have been extensively studied, as they are a core element
of human shape and pose inference tasks. Classic methods for creating a human
shape model register a surface template mesh to a database of 3D scans and use
dimensionality reduction techniques, such as Principal Component Analysis, to
learn a compact representation. While these shape models enable global shape
modifications by correlating anthropometric measurements with the learned
subspace, they only provide limited localized shape control. We instead
register a volumetric anatomical template, consisting of skeleton bones and
soft tissue, to the surface scans of the CAESAR database. We further enlarge
our training data to the full Cartesian product of all skeletons and all soft
tissues using physically plausible volumetric deformation transfer. This data
is then used to learn an anatomically constrained volumetric human shape model
in a self-supervised fashion. The resulting TailorMe model enables shape
sampling, localized shape manipulation, and fast inference from given surface
scans.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02175" title="Abstract">arXiv:2312.02175</a> [<a href="/pdf/2312.02175" title="Download PDF">pdf</a>, <a href="/format/2312.02175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wavefront Transformation-based Near-field Channel Prediction for  Extremely Large Antenna Array with Mobility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weidong Li</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Haifan Yin</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Ziao Qin</a>, 
<a href="/search/cs?searchtype=author&query=Debbah%2C+M">Merouane Debbah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">This paper addresses the mobility problem in extremely large antenna array
(ELAA) communication systems. In order to account for the performance loss
caused by the spherical wavefront of ELAA in the mobility scenario, we propose
a wavefront transformation-based matrix pencil (WTMP) channel prediction
method. In particular, we design a matrix to transform the spherical wavefront
into a new wavefront, which is closer to the plane wave. We also design a
time-frequency projection matrix to capture the time-varying path delay due to
user movement. Furthermore, we adopt the matrix pencil (MP) method to estimate
channel parameters. Our proposed WTMP method can mitigate the effect of
near-field radiation when predicting future channels. Theoretical analysis
shows that the designed matrix is asymptotically determined by the distance
between the base station (BS) antenna array and the scatterers or the user when
the number of BS antennas is large enough. For an ELAA communication system in
the mobility scenario, we prove that the prediction error converges to zero
with the increasing number of BS antennas. Simulation results demonstrate that
our designed transform matrix efficiently mitigates the near-field effect, and
that our proposed WTMP method can overcome the ELAA mobility challenge and
approach the performance in stationary setting.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02176" title="Abstract">arXiv:2312.02176</a> [<a href="/pdf/2312.02176" title="Download PDF">pdf</a>, <a href="/format/2312.02176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Channel Scheduling for IoT Access with Spatial Correlation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raghuwanshi%2C+P">Prasoon Raghuwanshi</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+O+L+A">Onel Luis Alcaraz L&#xf3;pez</a>, 
<a href="/search/cs?searchtype=author&query=Popovski%2C+P">Petar Popovski</a>, 
<a href="/search/cs?searchtype=author&query=Latva-aho%2C+M">Matti Latva-aho</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP); Probability (math.PR)

</div>
<p class="mathjax">Spatially correlated device activation is a typical feature of the Internet
of Things (IoT). This motivates the development of channel scheduling (CS)
methods that mitigate device collisions efficiently in such scenarios, which
constitutes the scope of this work. Specifically, we present a quadratic
program (QP) formulation for the CS problem considering the joint activation
probabilities among devices. This formulation allows the devices to
stochastically select the transmit channels, thus, leading to a soft-clustering
approach. We prove that the optimal QP solution can only be attained when it is
transformed into a hard-clustering problem, leading to a pure integer QP, which
we transform into a pure integer linear program (PILP). We leverage the
branch-and-cut (B&amp;C) algorithm to solve PILP optimally. Due to the high
computational cost of B&amp;C, we resort to some sub-optimal clustering methods
with low computational costs to tackle the clustering problem in CS. Our
findings demonstrate that the CS strategy, sourced from B&amp;C, significantly
outperforms those derived from sub-optimal clustering methods, even amidst
increased device correlation.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02177" title="Abstract">arXiv:2312.02177</a> [<a href="/pdf/2312.02177" title="Download PDF">pdf</a>, <a href="/ps/2312.02177" title="Download PostScript">ps</a>, <a href="/format/2312.02177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entropy generating function for past lifetime and its properties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S.%2C+S">Smitha S.</a>, 
<a href="/search/cs?searchtype=author&query=Kattumannil%2C+S+K">Sudheesh K Kattumannil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Statistics Theory (math.ST); Methodology (stat.ME)

</div>
<p class="mathjax">The past entropy is considered as an uncertainty measure for the past
lifetime distribution. Generating function approach to entropy become popular
in recent time as it generate several well-known entropy measures. In this
paper, we introduce the past entropy-generating function. We study certain
properties of this measure. It is shown that the past entropy-generating
function uniquely determines the distribution. Further, we present
characterizations for some lifetime models using the relationship between
reliability concepts and the past entropy-generating function.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02179" title="Abstract">arXiv:2312.02179</a> [<a href="/pdf/2312.02179" title="Download PDF">pdf</a>, <a href="/format/2312.02179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training Chain-of-Thought via Latent-Variable Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phan%2C+D">Du Phan</a>, 
<a href="/search/cs?searchtype=author&query=Hoffman%2C+M+D">Matthew D. Hoffman</a>, 
<a href="/search/cs?searchtype=author&query=Dohan%2C+D">David Dohan</a>, 
<a href="/search/cs?searchtype=author&query=Douglas%2C+S">Sholto Douglas</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T+A">Tuan Anh Le</a>, 
<a href="/search/cs?searchtype=author&query=Parisi%2C+A">Aaron Parisi</a>, 
<a href="/search/cs?searchtype=author&query=Sountsov%2C+P">Pavel Sountsov</a>, 
<a href="/search/cs?searchtype=author&query=Sutton%2C+C">Charles Sutton</a>, 
<a href="/search/cs?searchtype=author&query=Vikram%2C+S">Sharad Vikram</a>, 
<a href="/search/cs?searchtype=author&query=Saurous%2C+R+A">Rif A. Saurous</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models (LLMs) solve problems more accurately and interpretably
when instructed to work out the answer step by step using a
``chain-of-thought'' (CoT) prompt. One can also improve LLMs' performance on a
specific task by supervised fine-tuning, i.e., by using gradient ascent on some
tunable parameters to maximize the average log-likelihood of correct answers
from a labeled training set. Naively combining CoT with supervised tuning
requires supervision not just of the correct answers, but also of detailed
rationales that lead to those answers; these rationales are expensive to
produce by hand. Instead, we propose a fine-tuning strategy that tries to
maximize the \emph{marginal} log-likelihood of generating a correct answer
using CoT prompting, approximately averaging over all possible rationales. The
core challenge is sampling from the posterior over rationales conditioned on
the correct answer; we address it using a simple Markov-chain Monte Carlo
(MCMC) expectation-maximization (EM) algorithm inspired by the self-taught
reasoner (STaR), memoized wake-sleep, Markovian score climbing, and persistent
contrastive divergence. This algorithm also admits a novel control-variate
technique that drives the variance of our gradient estimates to zero as the
model improves. Applying our technique to GSM8K and the tasks in BIG-Bench
Hard, we find that this MCMC-EM fine-tuning technique typically improves the
model's accuracy on held-out examples more than STaR or prompt-tuning with or
without CoT.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02181" title="Abstract">arXiv:2312.02181</a> [<a href="/pdf/2312.02181" title="Download PDF">pdf</a>, <a href="/ps/2312.02181" title="Download PostScript">ps</a>, <a href="/format/2312.02181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Generative-AI can be Effectively used in Government Chatbots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zeteng Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); General Economics (econ.GN)

</div>
<p class="mathjax">With the rapid development of artificial intelligence and breakthroughs in
machine learning and natural language processing, intelligent
question-answering robots have become widely used in government affairs. This
paper conducts a horizontal comparison between Guangdong Province's government
chatbots, ChatGPT, and Wenxin Ernie, two large language models, to analyze the
strengths and weaknesses of existing government chatbots and AIGC technology.
The study finds significant differences between government chatbots and large
language models. China's government chatbots are still in an exploratory stage
and have a gap to close to achieve "intelligence." To explore the future
direction of government chatbots more deeply, this research proposes targeted
optimization paths to help generative AI be effectively applied in government
chatbot conversations.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02182" title="Abstract">arXiv:2312.02182</a> [<a href="/pdf/2312.02182" title="Download PDF">pdf</a>, <a href="/ps/2312.02182" title="Download PostScript">ps</a>, <a href="/format/2312.02182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adam-like Algorithm with Smooth Clipping Attains Global Minima: Analysis  Based on Ergodicity of Functional SDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+K">Keisuke Suzuki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Probability (math.PR)

</div>
<p class="mathjax">In this paper, we prove that an Adam-type algorithm with smooth clipping
approaches the global minimizer of the regularized non-convex loss function.
Adding smooth clipping and taking the state space as the set of all
trajectories, we can apply the ergodic theory of Markov semigroups for this
algorithm and investigate its asymptotic behavior. The ergodic theory we
establish in this paper reduces the problem of evaluating the convergence,
generalization error and discretization error of this algorithm to the problem
of evaluating the difference between two functional stochastic differential
equations (SDEs) with different drift coefficients. As a result of our
analysis, we have shown that this algorithm minimizes the the regularized
non-convex loss function with errors of the form $n^{-1/2}$, $\eta^{1/4}$,
$\beta^{-1} \log (\beta + 1)$ and $e^{- c t}$. Here, $c$ is a constant and $n$,
$\eta$, $\beta$ and $t$ denote the size of the training dataset, learning rate,
inverse temperature and time, respectively.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02184" title="Abstract">arXiv:2312.02184</a> [<a href="/pdf/2312.02184" title="Download PDF">pdf</a>, <a href="/format/2312.02184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Channel-Feedback-Free Transmission for Downlink FD-RAN: A Radio Map  based Complex-valued Precoding Network Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiwei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiacheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zeyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yuhang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Haibo Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xuemin">Xuemin</a> (Sherman)
<a href="/search/cs?searchtype=author&query=Shen">Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">As the demand for high-quality services proliferates, an innovative network
architecture, the fully-decoupled RAN (FD-RAN), has emerged for more flexible
spectrum resource utilization and lower network costs. However, with the
decoupling of uplink base stations and downlink base stations in FD-RAN, the
traditional transmission mechanism, which relies on real-time channel feedback,
is not suitable as the receiver is not able to feedback accurate and timely
channel state information to the transmitter. This paper proposes a novel
transmission scheme without relying on physical layer channel feedback.
Specifically, we design a radio map based complex-valued precoding
network~(RMCPNet) model, which outputs the base station precoding based on user
location. RMCPNet comprises multiple subnets, with each subnet responsible for
extracting unique modal features from diverse input modalities. Furthermore,
the multi-modal embeddings derived from these distinct subnets are integrated
within the information fusion layer, culminating in a unified representation.
We also develop a specific RMCPNet training algorithm that employs the negative
spectral efficiency as the loss function. We evaluate the performance of the
proposed scheme on the public DeepMIMO dataset and show that RMCPNet can
achieve 16\% and 76\% performance improvements over the conventional
real-valued neural network and statistical codebook approach, respectively.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02185" title="Abstract">arXiv:2312.02185</a> [<a href="/pdf/2312.02185" title="Download PDF">pdf</a>, <a href="/format/2312.02185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Virtual Fusion with Contrastive Learning for Single Sensor-based  Activity Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D">Duc-Anh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+C">Cuong Pham</a>, 
<a href="/search/cs?searchtype=author&query=Le-Khac%2C+N">Nhien-An Le-Khac</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Various types of sensors can be used for Human Activity Recognition (HAR),
and each of them has different strengths and weaknesses. Sometimes a single
sensor cannot fully observe the user's motions from its perspective, which
causes wrong predictions. While sensor fusion provides more information for
HAR, it comes with many inherent drawbacks like user privacy and acceptance,
costly set-up, operation, and maintenance. To deal with this problem, we
propose Virtual Fusion - a new method that takes advantage of unlabeled data
from multiple time-synchronized sensors during training, but only needs one
sensor for inference. Contrastive learning is adopted to exploit the
correlation among sensors. Virtual Fusion gives significantly better accuracy
than training with the same single sensor, and in some cases, it even surpasses
actual fusion using multiple sensors at test time. We also extend this method
to a more general version called Actual Fusion within Virtual Fusion (AFVF),
which uses a subset of training sensors during inference. Our method achieves
state-of-the-art accuracy and F1-score on UCI-HAR and PAMAP2 benchmark
datasets. Implementation is available upon request.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02186" title="Abstract">arXiv:2312.02186</a> [<a href="/pdf/2312.02186" title="Download PDF">pdf</a>, <a href="/format/2312.02186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying Spurious Correlations using Counterfactual Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cohen%2C+J+P">Joseph Paul Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Blankemeier%2C+L">Louis Blankemeier</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhari%2C+A">Akshay Chaudhari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Models driven by spurious correlations often yield poor generalization
performance. We propose the counterfactual alignment method to detect and
explore spurious correlations of black box classifiers. Counterfactual images
generated with respect to one classifier can be input into other classifiers to
see if they also induce changes in the outputs of these classifiers. The
relationship between these responses can be quantified and used to identify
specific instances where a spurious correlation exists as well as compute
aggregate statistics over a dataset. Our work demonstrates the ability to
detect spurious correlations in face attribute classifiers. This is validated
by observing intuitive trends in a face attribute classifier as well as
fabricating spurious correlations and detecting their presence, both visually
and quantitatively. Further, utilizing the CF alignment method, we demonstrate
that we can rectify spurious correlations identified in classifiers.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02188" title="Abstract">arXiv:2312.02188</a> [<a href="/pdf/2312.02188" title="Download PDF">pdf</a>, <a href="/format/2312.02188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video Summarization: Towards Entity-Aware Captions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ayyubi%2C+H+A">Hammad A. Ayyubi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Nagrani%2C+A">Arsha Nagrani</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xudong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingda Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Arnab%2C+A">Anurag Arnab</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+F">Feng Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yukun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jialu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+S">Shih-Fu Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multimedia (cs.MM)

</div>
<p class="mathjax">Existing popular video captioning benchmarks and models deal with generic
captions devoid of specific person, place or organization named entities. In
contrast, news videos present a challenging setting where the caption requires
such named entities for meaningful summarization. As such, we propose the task
of summarizing news video directly to entity-aware captions. We also release a
large-scale dataset, VIEWS (VIdeo NEWS), to support research on this task.
Further, we propose a method that augments visual information from videos with
context retrieved from external world knowledge to generate entity-aware
captions. We demonstrate the effectiveness of our approach on three video
captioning models. We also show that our approach generalizes to existing news
image captions dataset. With all the extensive experiments and insights, we
believe we establish a solid basis for future research on this challenging
task.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02189" title="Abstract">arXiv:2312.02189</a> [<a href="/pdf/2312.02189" title="Download PDF">pdf</a>, <a href="/format/2312.02189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StableDreamer: Taming Noisy Score Distillation Sampling for Text-to-3D
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+P">Pengsheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+H">Hans Hao</a>, 
<a href="/search/cs?searchtype=author&query=Caccavale%2C+A">Adam Caccavale</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhongzheng Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Edward Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Q">Qi Shan</a>, 
<a href="/search/cs?searchtype=author&query=Sankar%2C+A">Aditya Sankar</a>, 
<a href="/search/cs?searchtype=author&query=Schwing%2C+A+G">Alexander G. Schwing</a>, 
<a href="/search/cs?searchtype=author&query=Colburn%2C+A">Alex Colburn</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+F">Fangchang Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the realm of text-to-3D generation, utilizing 2D diffusion models through
score distillation sampling (SDS) frequently leads to issues such as blurred
appearances and multi-faced geometry, primarily due to the intrinsically noisy
nature of the SDS loss. Our analysis identifies the core of these challenges as
the interaction among noise levels in the 2D diffusion process, the
architecture of the diffusion network, and the 3D model representation. To
overcome these limitations, we present StableDreamer, a methodology
incorporating three advances. First, inspired by InstructNeRF2NeRF, we
formalize the equivalence of the SDS generative prior and a simple supervised
L2 reconstruction loss. This finding provides a novel tool to debug SDS, which
we use to show the impact of time-annealing noise levels on reducing
multi-faced geometries. Second, our analysis shows that while image-space
diffusion contributes to geometric precision, latent-space diffusion is crucial
for vivid color rendition. Based on this observation, StableDreamer introduces
a two-stage training strategy that effectively combines these aspects,
resulting in high-fidelity 3D models. Third, we adopt an anisotropic 3D
Gaussians representation, replacing Neural Radiance Fields (NeRFs), to enhance
the overall quality, reduce memory usage during training, and accelerate
rendering speeds, and better capture semi-transparent objects. StableDreamer
reduces multi-face geometries, generates fine details, and converges stably.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02190" title="Abstract">arXiv:2312.02190</a> [<a href="/pdf/2312.02190" title="Download PDF">pdf</a>, <a href="/format/2312.02190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Handles: Enabling 3D Edits for Diffusion Models by Lifting  Activations to 3D
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pandey%2C+K">Karran Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Guerrero%2C+P">Paul Guerrero</a>, 
<a href="/search/cs?searchtype=author&query=Gadelha%2C+M">Matheus Gadelha</a>, 
<a href="/search/cs?searchtype=author&query=Hold-Geoffroy%2C+Y">Yannick Hold-Geoffroy</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+K">Karan Singh</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+N">Niloy Mitra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Diffusion Handles is a novel approach to enabling 3D object edits on
diffusion images. We accomplish these edits using existing pre-trained
diffusion models, and 2D image depth estimation, without any fine-tuning or 3D
object retrieval. The edited results remain plausible, photo-real, and preserve
object identity. Diffusion Handles address a critically missing facet of
generative image based creative design, and significantly advance the
state-of-the-art in generative image editing. Our key insight is to lift
diffusion activations for an object to 3D using a proxy depth, 3D-transform the
depth and associated activations, and project them back to image space. The
diffusion process applied to the manipulated activations with identity control,
produces plausible edited images showing complex 3D occlusion and lighting
effects. We evaluate Diffusion Handles: quantitatively, on a large synthetic
data benchmark; and qualitatively by a user study, showing our output to be
more plausible, and better than prior art at both, 3D editing and identity
control.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02191" title="Abstract">arXiv:2312.02191</a> [<a href="/pdf/2312.02191" title="Download PDF">pdf</a>, <a href="/format/2312.02191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Tuning for Zero-shot Compositional Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lingyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+T">Ting Hua</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yilin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hongxia Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Open World Compositional Zero-Shot Learning (OW-CZSL) is known to be an
extremely challenging task, which aims to recognize unseen compositions formed
from seen attributes and objects without any prior assumption of the output
space. In order to achieve this goal, a model has to be "smart" and
"knowledgeable". To be smart, a model should be good at reasoning the
interactions between attributes and objects from the seen compositions. While
"knowledgeable" means the model owns "common sense" to the open world that can
"foresee" some features of the unseen compositions. Most previous work focuses
on the "smart" part, while few of them provided an effective solution to
achieve the "knowledgeable" goal. In this paper, we proposed a framework named
Multi-Modal Prompt Tuning (MMPT) to inherit the "knowledgeable" property from
the large pre-trained vision-language model. Extensive experiments show that
our proposed MMPT obtains new state-of-the-art results in OW-CZSL task. On the
UT-Zappos dataset, MMPT pushes the AUC score to $29.8$, while the previous best
score is $26.5$. On the more challenging MIT-States dataset, the AUC score of
MMPT is 1.5 times better than the current state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02192" title="Abstract">arXiv:2312.02192</a> [<a href="/pdf/2312.02192" title="Download PDF">pdf</a>, <a href="/format/2312.02192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiverseDream: Diverse Text-to-3D Synthesis with Augmented Text Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+U+D">Uy Dieu Tran</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+M">Minh Luu</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+P">Phong Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Heikkila%2C+J">Janne Heikkila</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+K">Khoi Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+B">Binh-Son Hua</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-to-3D synthesis has recently emerged as a new approach to sampling 3D
models by adopting pretrained text-to-image models as guiding visual priors. An
intriguing but underexplored problem with existing text-to-3D methods is that
3D models obtained from the sampling-by-optimization procedure tend to have
mode collapses, and hence poor diversity in their results. In this paper, we
provide an analysis and identify potential causes of such a limited diversity,
and then devise a new method that considers the joint generation of different
3D models from the same text prompt, where we propose to use augmented text
prompts via textual inversion of reference images to diversify the joint
generation. We show that our method leads to improved diversity in text-to-3D
synthesis qualitatively and quantitatively.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02194" title="Abstract">arXiv:2312.02194</a> [<a href="/pdf/2312.02194" title="Download PDF">pdf</a>, <a href="/format/2312.02194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local Masking Meets Progressive Freezing: Crafting Efficient Vision  Transformers for Self-Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Topcuoglu%2C+U+M">Utku Mert Topcuoglu</a>, 
<a href="/search/cs?searchtype=author&query=Akag%C3%BCnd%C3%BCz%2C+E">Erdem Akag&#xfc;nd&#xfc;z</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we present an innovative approach to self-supervised learning
for Vision Transformers (ViTs), integrating local masked image modeling with
progressive layer freezing. This method focuses on enhancing the efficiency and
speed of initial layer training in ViTs. By systematically freezing specific
layers at strategic points during training, we reduce computational demands
while maintaining or improving learning capabilities. Our approach employs a
novel multi-scale reconstruction process that fosters efficient learning in
initial layers and enhances semantic comprehension across scales. The results
demonstrate a substantial reduction in training time (~12.5\%) with a minimal
impact on model accuracy (decrease in top-1 accuracy by 0.6\%). Our method
achieves top-1 and top-5 accuracies of 82.6\% and 96.2\%, respectively,
underscoring its potential in scenarios where computational resources and time
are critical. This work marks an advancement in the field of self-supervised
learning for computer vision. The implementation of our approach is available
at our project's GitHub repository: github.com/utkutpcgl/ViTFreeze.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02195" title="Abstract">arXiv:2312.02195</a> [<a href="/pdf/2312.02195" title="Download PDF">pdf</a>, <a href="/ps/2312.02195" title="Download PostScript">ps</a>, <a href="/format/2312.02195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cancer Subtype Identification through Integrating Inter and Intra  Dataset Relationships in Multi-Omics Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peelen%2C+M">Mark Peelen</a>, 
<a href="/search/cs?searchtype=author&query=Bagheriye%2C+L">Leila Bagheriye</a>, 
<a href="/search/cs?searchtype=author&query=Kwisthout%2C+J">Johan Kwisthout</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Genomics (q-bio.GN); Applications (stat.AP)

</div>
<p class="mathjax">The integration of multi-omics data has emerged as a promising approach for
gaining comprehensive insights into complex diseases such as cancer. This paper
proposes a novel approach to identify cancer subtypes through the integration
of multi-omics data for clustering. The proposed method, named LIDAF utilises
affinity matrices based on linear relationships between and within different
omics datasets (Linear Inter and Intra Dataset Affinity Fusion (LIDAF)).
Canonical Correlation Analysis is in this paper employed to create distance
matrices based on Euclidean distances between canonical variates. The distance
matrices are converted to affinity matrices and those are fused in a three-step
process. The proposed LIDAF addresses the limitations of the existing method
resulting in improvement of clustering performance as measured by the Adjusted
Rand Index and the Normalized Mutual Information score. Moreover, our proposed
LIDAF approach demonstrates a notable enhancement in 50% of the log10 rank
p-values obtained from Cox survival analysis, surpassing the performance of the
best reported method, highlighting its potential of identifying distinct cancer
subtypes.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02196" title="Abstract">arXiv:2312.02196</a> [<a href="/pdf/2312.02196" title="Download PDF">pdf</a>, <a href="/format/2312.02196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Inertial Poser (DynaIP): Part-Based Motion Dynamics Learning for  Enhanced Human Pose Estimation with Sparse Inertial Sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Songpengcheng Xia</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+L">Lei Chu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiarui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+L">Ling Pei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper introduces a novel human pose estimation approach using sparse
inertial sensors, addressing the shortcomings of previous methods reliant on
synthetic data. It leverages a diverse array of real inertial motion capture
data from different skeleton formats to improve motion diversity and model
generalization. This method features two innovative components: a
pseudo-velocity regression model for dynamic motion capture with inertial
sensors, and a part-based model dividing the body and sensor data into three
regions, each focusing on their unique characteristics. The approach
demonstrates superior performance over state-of-the-art models across five
public datasets, notably reducing pose error by 19\% on the DIP-IMU dataset,
thus representing a significant improvement in inertial sensor-based human pose
estimation. We will make the implementation of our model available for public
use.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02197" title="Abstract">arXiv:2312.02197</a> [<a href="/pdf/2312.02197" title="Download PDF">pdf</a>, <a href="/format/2312.02197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Diffusion Priors for All-in-One Image Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gou%2C+Y">Yuanbiao Gou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haiyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boyun Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xinyan Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xi Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">All-in-one aims to solve various tasks of image restoration in a single
model. To this end, we present a feasible way of exploiting the image priors
captured by the pretrained diffusion model, through addressing the two
challenges, i.e., degradation modeling and diffusion guidance. The former aims
to simulate the process of the clean image degenerated by certain degradations,
and the latter aims at guiding the diffusion model to generate the
corresponding clean image. With the motivations, we propose a zero-shot
framework for all-in-one image restoration, termed ZeroAIR, which alternatively
performs the test-time degradation modeling (TDM) and the three-stage diffusion
guidance (TDG) at each timestep of the reverse sampling. To be specific, TDM
exploits the diffusion priors to learn a degradation model from a given
degraded image, and TDG divides the timesteps into three stages for taking full
advantage of the varying diffusion priors. Thanks to their degradation-agnostic
property, the all-in-one image restoration could be achieved in a zero-shot way
by ZeroAIR. Through extensive experiments, we show that our ZeroAIR achieves
comparable even better performance than those task-specific methods. The code
will be available on Github.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02199" title="Abstract">arXiv:2312.02199</a> [<a href="/pdf/2312.02199" title="Download PDF">pdf</a>, <a href="/format/2312.02199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> USat: A Unified Self-Supervised Encoder for Multi-Sensor Satellite  Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Irvin%2C+J">Jeremy Irvin</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+L">Lucas Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Joanne Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yuntao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Nashold%2C+L">Langston Nashold</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Benjamin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+A+Y">Andrew Y. Ng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Image and Video Processing (eess.IV); Applications (stat.AP)

</div>
<p class="mathjax">Large, self-supervised vision models have led to substantial advancements for
automatically interpreting natural images. Recent works have begun tailoring
these methods to remote sensing data which has rich structure with
multi-sensor, multi-spectral, and temporal information providing massive
amounts of self-labeled data that can be used for self-supervised pre-training.
In this work, we develop a new encoder architecture called USat that can input
multi-spectral data from multiple sensors for self-supervised pre-training.
USat is a vision transformer with modified patch projection layers and
positional encodings to model spectral bands with varying spatial scales from
multiple sensors. We integrate USat into a Masked Autoencoder (MAE)
self-supervised pre-training procedure and find that a pre-trained USat
outperforms state-of-the-art self-supervised MAE models trained on remote
sensing data on multiple remote sensing benchmark datasets (up to 8%) and leads
to improvements in low data regimes (up to 7%). Code and pre-trained weights
are available at https://github.com/stanfordmlgroup/USat .
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02200" title="Abstract">arXiv:2312.02200</a> [<a href="/pdf/2312.02200" title="Download PDF">pdf</a>, <a href="/format/2312.02200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Study of Automated Mislabel Detection in Real World Vision  Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srikanth%2C+M">Maya Srikanth</a>, 
<a href="/search/cs?searchtype=author&query=Irvin%2C+J">Jeremy Irvin</a>, 
<a href="/search/cs?searchtype=author&query=Hill%2C+B+W">Brian Wesley Hill</a>, 
<a href="/search/cs?searchtype=author&query=Godoy%2C+F">Felipe Godoy</a>, 
<a href="/search/cs?searchtype=author&query=Sabane%2C+I">Ishan Sabane</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+A+Y">Andrew Y. Ng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Applications (stat.AP)

</div>
<p class="mathjax">Major advancements in computer vision can primarily be attributed to the use
of labeled datasets. However, acquiring labels for datasets often results in
errors which can harm model performance. Recent works have proposed methods to
automatically identify mislabeled images, but developing strategies to
effectively implement them in real world datasets has been sparsely explored.
Towards improved data-centric methods for cleaning real world vision datasets,
we first conduct more than 200 experiments carefully benchmarking recently
developed automated mislabel detection methods on multiple datasets under a
variety of synthetic and real noise settings with varying noise levels. We
compare these methods to a Simple and Efficient Mislabel Detector (SEMD) that
we craft, and find that SEMD performs similarly to or outperforms prior
mislabel detection approaches. We then apply SEMD to multiple real world
computer vision datasets and test how dataset size, mislabel removal strategy,
and mislabel removal amount further affect model performance after retraining
on the cleaned data. With careful design of the approach, we find that mislabel
removal leads per-class performance improvements of up to 8% of a retrained
classifier in smaller data regimes.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02201" title="Abstract">arXiv:2312.02201</a> [<a href="/pdf/2312.02201" title="Download PDF">pdf</a>, <a href="/format/2312.02201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ImageDream: Image-Prompt Multi-view Diffusion for 3D Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yichun Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project page: <a href="https://Image-Dream.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce "ImageDream," an innovative image-prompt, multi-view diffusion
model for 3D object generation. ImageDream stands out for its ability to
produce 3D models of higher quality compared to existing state-of-the-art,
image-conditioned methods. Our approach utilizes a canonical camera
coordination for the objects in images, improving visual geometry accuracy. The
model is designed with various levels of control at each block inside the
diffusion model based on the input image, where global control shapes the
overall object layout and local control fine-tunes the image details. The
effectiveness of ImageDream is demonstrated through extensive evaluations using
a standard prompt list. For more information, visit our project page at
https://Image-Dream.github.io.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02202" title="Abstract">arXiv:2312.02202</a> [<a href="/pdf/2312.02202" title="Download PDF">pdf</a>, <a href="/format/2312.02202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Volumetric Rendering with Baked Quadrature Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+G">Gopal Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Rebain%2C+D">Daniel Rebain</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+K+M">Kwang Moo Yi</a>, 
<a href="/search/cs?searchtype=author&query=Tagliasacchi%2C+A">Andrea Tagliasacchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We propose a novel Neural Radiance Field (NeRF) representation for non-opaque
scenes that allows fast inference by utilizing textured polygons. Despite the
high-quality novel view rendering that NeRF provides, a critical limitation is
that it relies on volume rendering that can be computationally expensive and
does not utilize the advancements in modern graphics hardware. Existing methods
for this problem fall short when it comes to modelling volumetric effects as
they rely purely on surface rendering. We thus propose to model the scene with
polygons, which can then be used to obtain the quadrature points required to
model volumetric effects, and also their opacity and colour from the texture.
To obtain such polygonal mesh, we train a specialized field whose
zero-crossings would correspond to the quadrature points when volume rendering,
and perform marching cubes on this field. We then rasterize the polygons and
utilize the fragment shaders to obtain the final colour image. Our method
allows rendering on various devices and easy integration with existing graphics
frameworks while keeping the benefits of volume rendering alive.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02204" title="Abstract">arXiv:2312.02204</a> [<a href="/pdf/2312.02204" title="Download PDF">pdf</a>, <a href="/format/2312.02204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can We Learn Communication-Efficient Optimizers?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joseph%2C+C">Charles-&#xc9;tienne Joseph</a>, 
<a href="/search/cs?searchtype=author&query=Th%C3%A9rien%2C+B">Benjamin Th&#xe9;rien</a>, 
<a href="/search/cs?searchtype=author&query=Moudgil%2C+A">Abhinav Moudgil</a>, 
<a href="/search/cs?searchtype=author&query=Knyazev%2C+B">Boris Knyazev</a>, 
<a href="/search/cs?searchtype=author&query=Belilovsky%2C+E">Eugene Belilovsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Communication-efficient variants of SGD, specifically local SGD, have
received a great deal of interest in recent years. These approaches compute
multiple gradient steps locally, that is on each worker, before averaging model
parameters, helping relieve the critical communication bottleneck in
distributed deep learning training. Although many variants of these approaches
have been proposed, they can sometimes lag behind state-of-the-art adaptive
optimizers for deep learning. In this work, we investigate if the recent
progress in the emerging area of learned optimizers can potentially close this
gap while remaining communication-efficient. Specifically, we meta-learn how to
perform global updates given an update from local SGD iterations. Our results
demonstrate that learned optimizers can substantially outperform local SGD and
its sophisticated variants while maintaining their communication efficiency.
Learned optimizers can even generalize to unseen and much larger datasets and
architectures, including ImageNet and ViTs, and to unseen modalities such as
language modeling. We therefore demonstrate the potential of learned optimizers
for improving communication-efficient distributed learning.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02205" title="Abstract">arXiv:2312.02205</a> [<a href="/pdf/2312.02205" title="Download PDF">pdf</a>, <a href="/format/2312.02205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangling the Effects of Data Augmentation and Format Transform in  Self-Supervised Learning of Image Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalibhat%2C+N">Neha Kalibhat</a>, 
<a href="/search/cs?searchtype=author&query=Morningstar%2C+W">Warren Morningstar</a>, 
<a href="/search/cs?searchtype=author&query=Bijamov%2C+A">Alex Bijamov</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Luyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Singhal%2C+K">Karan Singhal</a>, 
<a href="/search/cs?searchtype=author&query=Mansfield%2C+P">Philip Mansfield</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Self-Supervised Learning (SSL) enables training performant models using
limited labeled data. One of the pillars underlying vision SSL is the use of
data augmentations/perturbations of the input which do not significantly alter
its semantic content. For audio and other temporal signals, augmentations are
commonly used alongside format transforms such as Fourier transforms or wavelet
transforms. Unlike augmentations, format transforms do not change the
information contained in the data; rather, they express the same information in
different coordinates. In this paper, we study the effects of format transforms
and augmentations both separately and together on vision SSL. We define
augmentations in frequency space called Fourier Domain Augmentations (FDA) and
show that training SSL models on a combination of these and image augmentations
can improve the downstream classification accuracy by up to 1.3% on
ImageNet-1K. We also show improvements against SSL baselines in few-shot and
transfer learning setups using FDA. Surprisingly, we also observe that format
transforms can improve the quality of learned representations even without
augmentations; however, the combination of the two techniques yields better
quality.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02206" title="Abstract">arXiv:2312.02206</a> [<a href="/pdf/2312.02206" title="Download PDF">pdf</a>, <a href="/format/2312.02206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Axiomatic Preference Modeling for Longform Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rosset%2C+C">Corby Rosset</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+G">Guoqing Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Dibia%2C+V">Victor Dibia</a>, 
<a href="/search/cs?searchtype=author&query=Awadallah%2C+A">Ahmed Awadallah</a>, 
<a href="/search/cs?searchtype=author&query=Bennett%2C+P">Paul Bennett</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The remarkable abilities of large language models (LLMs) like GPT-4 partially
stem from post-training processes like Reinforcement Learning from Human
Feedback (RLHF) involving human preferences encoded in a reward model. However,
these reward models (RMs) often lack direct knowledge of why, or under what
principles, the preferences annotations were made. In this study, we identify
principles that guide RMs to better align with human preferences, and then
develop an axiomatic framework to generate a rich variety of preference signals
to uphold them. We use these axiomatic signals to train a model for scoring
answers to longform questions. Our approach yields a Preference Model with only
about 220M parameters that agrees with gold human-annotated preference labels
more often than GPT-4. The contributions of this work include: training a
standalone preference model that can score human- and LLM-generated answers on
the same scale; developing an axiomatic framework for generating training data
pairs tailored to certain principles; and showing that a small amount of
axiomatic signals can help small models outperform GPT-4 in preference scoring.
We release our model on huggingface:
https://huggingface.co/corbyrosset/axiomatic_preference_model
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02207" title="Abstract">arXiv:2312.02207</a> [<a href="/pdf/2312.02207" title="Download PDF">pdf</a>, <a href="/format/2312.02207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TranSegPGD: Improving Transferability of Adversarial Examples on  Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiaojun Jia</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jindong Gu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yihao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+S">Simeng Qin</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xiaochun Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Transferability of adversarial examples on image classification has been
systematically explored, which generates adversarial examples in black-box
mode. However, the transferability of adversarial examples on semantic
segmentation has been largely overlooked. In this paper, we propose an
effective two-stage adversarial attack strategy to improve the transferability
of adversarial examples on semantic segmentation, dubbed TranSegPGD.
Specifically, at the first stage, every pixel in an input image is divided into
different branches based on its adversarial property. Different branches are
assigned different weights for optimization to improve the adversarial
performance of all pixels.We assign high weights to the loss of the
hard-to-attack pixels to misclassify all pixels. At the second stage, the
pixels are divided into different branches based on their transferable property
which is dependent on Kullback-Leibler divergence. Different branches are
assigned different weights for optimization to improve the transferability of
the adversarial examples. We assign high weights to the loss of the
high-transferability pixels to improve the transferability of adversarial
examples. Extensive experiments with various segmentation models are conducted
on PASCAL VOC 2012 and Cityscapes datasets to demonstrate the effectiveness of
the proposed method. The proposed adversarial attack method can achieve
state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02208" title="Abstract">arXiv:2312.02208</a> [<a href="/pdf/2312.02208" title="Download PDF">pdf</a>, <a href="/format/2312.02208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Data-efficient Framework for Robotics Large-scale LiDAR Scene Parsing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kangcheng Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Robotics and Automation (ICRA) 2022, 6 Figures. arXiv admin note: substantial text overlap with <a href="/abs/2312.01262">arXiv:2312.01262</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Existing state-of-the-art 3D point clouds understanding methods only perform
well in a fully supervised manner. To the best of our knowledge, there exists
no unified framework which simultaneously solves the downstream high-level
understanding tasks, especially when labels are extremely limited. This work
presents a general and simple framework to tackle point clouds understanding
when labels are limited. We propose a novel unsupervised region expansion based
clustering method for generating clusters. More importantly, we innovatively
propose to learn to merge the over-divided clusters based on the local
low-level geometric property similarities and the learned high-level feature
similarities supervised by weak labels. Hence, the true weak labels guide
pseudo labels merging taking both geometric and semantic feature correlations
into consideration. Finally, the self-supervised reconstruction and data
augmentation optimization modules are proposed to guide the propagation of
labels among semantically similar points within a scene. Experimental Results
demonstrate that our framework has the best performance among the three most
important weakly supervised point clouds understanding tasks including semantic
segmentation, instance segmentation, and object detection even when limited
points are labeled, under the data-efficient settings for the large-scale 3D
semantic scene parsing. The developed techniques have postentials to be applied
to downstream tasks for better representations in robotic manipulation and
robotic autonomous navigation. Codes and models are publicly available at:
https://github.com/KangchengLiu.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02209" title="Abstract">arXiv:2312.02209</a> [<a href="/pdf/2312.02209" title="Download PDF">pdf</a>, <a href="/format/2312.02209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AttriHuman-3D: Editable 3D Human Avatar Generation with Attribute  Decomposition and Indexing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaosheng He</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhongang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Si Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guosheng Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Editable 3D-aware generation, which supports user-interacted editing, has
witnessed rapid development recently. However, existing editable 3D GANs either
fail to achieve high-accuracy local editing or suffer from huge computational
costs. We propose AttriHuman-3D, an editable 3D human generation model, which
address the aforementioned problems with attribute decomposition and indexing.
The core idea of the proposed model is to generate all attributes (e.g. human
body, hair, clothes and so on) in an overall attribute space with six feature
planes, which are then decomposed and manipulated with different attribute
indexes. To precisely extract features of different attributes from the
generated feature planes, we propose a novel attribute indexing method as well
as an orthogonal projection regularization to enhance the disentanglement. We
also introduce a hyper-latent training strategy and an attribute-specific
sampling strategy to avoid style entanglement and misleading punishment from
the discriminator. Our method allows users to interactively edit selected
attributes in the generated 3D human avatars while keeping others fixed. Both
qualitative and quantitative experiments demonstrate that our model provides a
strong disentanglement between different attributes, allows fine-grained image
editing and generates high-quality 3D human avatars.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02210" title="Abstract">arXiv:2312.02210</a> [<a href="/pdf/2312.02210" title="Download PDF">pdf</a>, <a href="/format/2312.02210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Precision Mixed-Computation Models for Inference on Edge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azizi%2C+S">Seyedarmin Azizi</a>, 
<a href="/search/cs?searchtype=author&query=Nazemi%2C+M">Mahdi Nazemi</a>, 
<a href="/search/cs?searchtype=author&query=Kamal%2C+M">Mehdi Kamal</a>, 
<a href="/search/cs?searchtype=author&query=Pedram%2C+M">Massoud Pedram</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents a mixed-computation neural network processing approach
for edge applications that incorporates low-precision (low-width) Posit and
low-precision fixed point (FixP) number systems. This mixed-computation
approach employs 4-bit Posit (Posit4), which has higher precision around zero,
for representing weights with high sensitivity, while it uses 4-bit FixP
(FixP4) for representing other weights. A heuristic for analyzing the
importance and the quantization error of the weights is presented to assign the
proper number system to different weights. Additionally, a gradient
approximation for Posit representation is introduced to improve the quality of
weight updates in the backpropagation process. Due to the high energy
consumption of the fully Posit-based computations, neural network operations
are carried out in FixP or Posit/FixP. An efficient hardware implementation of
a MAC operation with a first Posit operand and FixP for a second operand and
accumulator is presented. The efficacy of the proposed low-precision
mixed-computation approach is extensively assessed on vision and language
models. The results show that, on average, the accuracy of the
mixed-computation is about 1.5% higher than that of FixP with a cost of 0.19%
energy overhead.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02212" title="Abstract">arXiv:2312.02212</a> [<a href="/pdf/2312.02212" title="Download PDF">pdf</a>, <a href="/format/2312.02212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Portrait Diffusion: Training-free Face Stylization with  Chain-of-Painting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huaibo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Chao Jin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ran He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Face stylization refers to the transformation of a face into a specific
portrait style. However, current methods require the use of example-based
adaptation approaches to fine-tune pre-trained generative models so that they
demand lots of time and storage space and fail to achieve detailed style
transformation. This paper proposes a training-free face stylization framework,
named Portrait Diffusion. This framework leverages off-the-shelf text-to-image
diffusion models, eliminating the need for fine-tuning specific examples.
Specifically, the content and style images are first inverted into latent
codes. Then, during image reconstruction using the corresponding latent code,
the content and style features in the attention space are delicately blended
through a modified self-attention operation called Style Attention Control.
Additionally, a Chain-of-Painting method is proposed for the gradual redrawing
of unsatisfactory areas from rough adjustments to fine-tuning. Extensive
experiments validate the effectiveness of our Portrait Diffusion method and
demonstrate the superiority of Chain-of-Painting in achieving precise face
stylization. Code will be released at
\url{https://github.com/liujin112/PortraitDiffusion}.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02213" title="Abstract">arXiv:2312.02213</a> [<a href="/pdf/2312.02213" title="Download PDF">pdf</a>, <a href="/format/2312.02213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JarviX: A LLM No code Platform for Tabular Data Analysis and  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shang-Ching Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">ShengKun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Wenqi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Hsiung%2C+C">Chung-Wei Hsiung</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+Y">Yi-Chen Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yu-Ping Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Sian-Hong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+T">Tsungyao Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianwei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB); Applications (stat.AP)

</div>
<p class="mathjax">In this study, we introduce JarviX, a sophisticated data analytics framework.
JarviX is designed to employ Large Language Models (LLMs) to facilitate an
automated guide and execute high-precision data analyzes on tabular datasets.
This framework emphasizes the significance of varying column types,
capitalizing on state-of-the-art LLMs to generate concise data insight
summaries, propose relevant analysis inquiries, visualize data effectively, and
provide comprehensive explanations for results drawn from an extensive data
analysis pipeline. Moreover, JarviX incorporates an automated machine learning
(AutoML) pipeline for predictive modeling. This integration forms a
comprehensive and automated optimization cycle, which proves particularly
advantageous for optimizing machine configuration. The efficacy and
adaptability of JarviX are substantiated through a series of practical use case
studies.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02214" title="Abstract">arXiv:2312.02214</a> [<a href="/pdf/2312.02214" title="Download PDF">pdf</a>, <a href="/format/2312.02214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlashAvatar: High-Fidelity Digital Avatar Rendering at 300FPS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiang%2C+J">Jun Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yudong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Juyong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://ustc3dv.github.io/FlashAvatar/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We propose FlashAvatar, a novel and lightweight 3D animatable avatar
representation that could reconstruct a digital avatar from a short monocular
video sequence in minutes and render high-fidelity photo-realistic images at
300FPS on a consumer-grade GPU. To achieve this, we maintain a uniform 3D
Gaussian field embedded in the surface of a parametric face model and learn
extra spatial offset to model non-surface regions and subtle facial details.
While full use of geometric priors can capture high-frequency facial details
and preserve exaggerated expressions, proper initialization can help reduce the
number of Gaussians, thus enabling super-fast rendering speed. Extensive
experimental results demonstrate that FlashAvatar outperforms existing works
regarding visual quality and personalized details and is almost an order of
magnitude faster in rendering speed. Project page:
https://ustc3dv.github.io/FlashAvatar/
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02216" title="Abstract">arXiv:2312.02216</a> [<a href="/pdf/2312.02216" title="Download PDF">pdf</a>, <a href="/format/2312.02216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DragVideo: Interactive Drag-style Video Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yufan Deng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruida Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+Y">Yu-Wing Tai</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chi-Keung Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Editing visual content on videos remains a formidable challenge with two main
issues: 1) direct and easy user control to produce 2) natural editing results
without unsightly distortion and artifacts after changing shape, expression and
layout. Inspired by DragGAN, a recent image-based drag-style editing technique,
we address above issues by proposing DragVideo, where a similar drag-style user
interaction is adopted to edit video content while maintaining temporal
consistency. Empowered by recent diffusion models as in DragDiffusion,
DragVideo contains the novel Drag-on-Video U-Net (DoVe) editing method, which
optimizes diffused video latents generated by video U-Net to achieve the
desired control. Specifically, we use Sample-specific LoRA fine-tuning and
Mutual Self-Attention control to ensure faithful reconstruction of video from
the DoVe method. We also present a series of testing examples for drag-style
video editing and conduct extensive experiments across a wide array of
challenging editing tasks, such as motion editing, skeleton editing, etc,
underscoring DragVideo's versatility and generality. Our codes including the
DragVideo web user interface will be released.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02218" title="Abstract">arXiv:2312.02218</a> [<a href="/pdf/2312.02218" title="Download PDF">pdf</a>, <a href="/format/2312.02218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WavePlanes: A compact Wavelet representation for Dynamic Neural Radiance  Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azzarelli%2C+A">Adrian Azzarelli</a>, 
<a href="/search/cs?searchtype=author&query=Anantrasirichai%2C+N">Nantheera Anantrasirichai</a>, 
<a href="/search/cs?searchtype=author&query=Bull%2C+D+R">David R Bull</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Dynamic Neural Radiance Fields (Dynamic NeRF) enhance NeRF technology to
model moving scenes. However, they are resource intensive and challenging to
compress. To address this issue, this paper presents WavePlanes, a fast and
more compact explicit model. We propose a multi-scale space and space-time
feature plane representation using N-level 2-D wavelet coefficients. The
inverse discrete wavelet transform reconstructs N feature signals at varying
detail, which are linearly decoded to approximate the color and density of
volumes in a 4-D grid. Exploiting the sparsity of wavelet coefficients, we
compress a Hash Map containing only non-zero coefficients and their locations
on each plane. This results in a compressed model size of ~12 MB. Compared with
state-of-the-art plane-based models, WavePlanes is up to 15x smaller, less
computationally demanding and achieves comparable results in as little as one
hour of training - without requiring custom CUDA code or high performance
computing resources. Additionally, we propose new feature fusion schemes that
work as well as previously proposed schemes while providing greater
interpretability. Our code is available at:
https://github.com/azzarelli/waveplanes/
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02219" title="Abstract">arXiv:2312.02219</a> [<a href="/pdf/2312.02219" title="Download PDF">pdf</a>, <a href="/format/2312.02219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Behind the Magic, MERLIM: Multi-modal Evaluation Benchmark for Large  Image-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Villa%2C+A">Andr&#xe9;s Villa</a>, 
<a href="/search/cs?searchtype=author&query=Alc%C3%A1zar%2C+J+C+L">Juan Carlos Le&#xf3;n Alc&#xe1;zar</a>, 
<a href="/search/cs?searchtype=author&query=Soto%2C+A">Alvaro Soto</a>, 
<a href="/search/cs?searchtype=author&query=Ghanem%2C+B">Bernard Ghanem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large Vision and Language Models have enabled significant advances in fully
supervised and zero-shot vision tasks. These large pre-trained architectures
serve as the baseline to what is currently known as Instruction Tuning Large
Vision and Language models (IT-LVLMs). IT-LVLMs are general-purpose multi-modal
assistants whose responses are modulated by natural language instructions and
arbitrary visual data. Despite this versatility, IT-LVLM effectiveness in
fundamental computer vision problems remains unclear, primarily due to the
absence of a standardized evaluation benchmark. This paper introduces a
Multi-modal Evaluation Benchmark named MERLIM, a scalable test-bed to assess
the performance of IT-LVLMs on fundamental computer vision tasks. MERLIM
contains over 279K image-question pairs, and has a strong focus on detecting
cross-modal "hallucination" events in IT-LVLMs, where the language output
refers to visual concepts that lack any effective grounding in the image. Our
results show that state-of-the-art IT-LVMLs are still limited at identifying
fine-grained visual concepts, object hallucinations are common across tasks,
and their results are strongly biased by small variations in the input query,
even if the queries have the very same semantics. Our findings also suggest
that these models have weak visual groundings but they can still make adequate
guesses by global visual patterns or textual biases contained in the LLM
component.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02220" title="Abstract">arXiv:2312.02220</a> [<a href="/pdf/2312.02220" title="Download PDF">pdf</a>, <a href="/format/2312.02220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QuantAttack: Exploiting Dynamic Quantization to Attack Vision  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baras%2C+A">Amit Baras</a>, 
<a href="/search/cs?searchtype=author&query=Zolfi%2C+A">Alon Zolfi</a>, 
<a href="/search/cs?searchtype=author&query=Elovici%2C+Y">Yuval Elovici</a>, 
<a href="/search/cs?searchtype=author&query=Shabtai%2C+A">Asaf Shabtai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, there has been a significant trend in deep neural networks
(DNNs), particularly transformer-based models, of developing ever-larger and
more capable models. While they demonstrate state-of-the-art performance, their
growing scale requires increased computational resources (e.g., GPUs with
greater memory capacity). To address this problem, quantization techniques
(i.e., low-bit-precision representation and matrix multiplication) have been
proposed. Most quantization techniques employ a static strategy in which the
model parameters are quantized, either during training or inference, without
considering the test-time sample. In contrast, dynamic quantization techniques,
which have become increasingly popular, adapt during inference based on the
input provided, while maintaining full-precision performance. However, their
dynamic behavior and average-case performance assumption makes them vulnerable
to a novel threat vector -- adversarial attacks that target the model's
efficiency and availability. In this paper, we present QuantAttack, a novel
attack that targets the availability of quantized models, slowing down the
inference, and increasing memory usage and energy consumption. We show that
carefully crafted adversarial examples, which are designed to exhaust the
resources of the operating system, can trigger worst-case performance. In our
experiments, we demonstrate the effectiveness of our attack on vision
transformers on a wide range of tasks, both uni-modal and multi-modal. We also
examine the effect of different attack variants (e.g., a universal
perturbation) and the transferability between different models.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02221" title="Abstract">arXiv:2312.02221</a> [<a href="/pdf/2312.02221" title="Download PDF">pdf</a>, <a href="/format/2312.02221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Slice3D: Multi-Slice, Occlusion-Revealing, Single View 3D Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yizhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lira%2C+W">Wallace Lira</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mahdavi-Amiri%2C+A">Ali Mahdavi-Amiri</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="https://yizhiwang96.github.io/Slice3D/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We introduce multi-slice reasoning, a new notion for single-view 3D
reconstruction which challenges the current and prevailing belief that
multi-view synthesis is the most natural conduit between single-view and 3D.
Our key observation is that object slicing is more advantageous than altering
views to reveal occluded structures. Specifically, slicing is more
occlusion-revealing since it can peel through any occluders without
obstruction. In the limit, i.e., with infinitely many slices, it is guaranteed
to unveil all hidden object parts. We realize our idea by developing Slice3D, a
novel method for single-view 3D reconstruction which first predicts multi-slice
images from a single RGB image and then integrates the slices into a 3D model
using a coordinate-based transformer network for signed distance prediction.
The slice images can be regressed or generated, both through a U-Net based
network. For the former, we inject a learnable slice indicator code to
designate each decoded image into a spatial slice location, while the slice
generator is a denoising diffusion model operating on the entirety of slice
images stacked on the input channels. We conduct extensive evaluation against
state-of-the-art alternatives to demonstrate superiority of our method,
especially in recovering complex and severely occluded shape structures, amid
ambiguities. All Slice3D results were produced by networks trained on a single
Nvidia A40 GPU, with an inference time less than 20 seconds.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02222" title="Abstract">arXiv:2312.02222</a> [<a href="/pdf/2312.02222" title="Download PDF">pdf</a>, <a href="/format/2312.02222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InvertAvatar: Incremental GAN Inversion for Generalized Head Avatars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiaochen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jingxiang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lizhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yebin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While high fidelity and efficiency are central to the creation of digital
head avatars, recent methods relying on 2D or 3D generative models often
experience limitations such as shape distortion, expression inaccuracy, and
identity flickering. Additionally, existing one-shot inversion techniques fail
to fully leverage multiple input images for detailed feature extraction. We
propose a novel framework, \textbf{Incremental 3D GAN Inversion}, that enhances
avatar reconstruction performance using an algorithm designed to increase the
fidelity from multiple frames, resulting in improved reconstruction quality
proportional to frame count. Our method introduces a unique animatable 3D GAN
prior with two crucial modifications for enhanced expression controllability
alongside an innovative neural texture encoder that categorizes texture feature
spaces based on UV parameterization. Differentiating from traditional
techniques, our architecture emphasizes pixel-aligned image-to-image
translation, mitigating the need to learn correspondences between observation
and canonical spaces. Furthermore, we incorporate ConvGRU-based recurrent
networks for temporal data aggregation from multiple frames, boosting geometry
and texture detail reconstruction. The proposed paradigm demonstrates
state-of-the-art performance on one-shot and few-shot avatar animation tasks.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02224" title="Abstract">arXiv:2312.02224</a> [<a href="/pdf/2312.02224" title="Download PDF">pdf</a>, <a href="/format/2312.02224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tracing Hyperparameter Dependencies for Model Parsing via Learnable  Graph Pooling Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Asnani%2C+V">Vishal Asnani</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sijia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoming Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 15 figures, 17 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Model Parsing defines the research task of predicting hyperparameters of the
generative model (GM), given a generated image as input. Since a diverse set of
hyperparameters is jointly employed by the generative model, and dependencies
often exist among them, it is crucial to learn these hyperparameter
dependencies for the improved model parsing performance. To explore such
important dependencies, we propose a novel model parsing method called
Learnable Graph Pooling Network (LGPN). Specifically, we transform model
parsing into a graph node classification task, using graph nodes and edges to
represent hyperparameters and their dependencies, respectively. Furthermore,
LGPN incorporates a learnable pooling-unpooling mechanism tailored to model
parsing, which adaptively learns hyperparameter dependencies of GMs used to
generate the input image. We also extend our proposed method to CNN-generated
image detection and coordinate attacks detection. Empirically, we achieve
state-of-the-art results in model parsing and its extended applications,
showing the effectiveness of our method. Our source code are available.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02226" title="Abstract">arXiv:2312.02226</a> [<a href="/pdf/2312.02226" title="Download PDF">pdf</a>, <a href="/format/2312.02226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Action-conditioned Prompts for Open-vocabulary Video Action  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+C">Chengyou Jia</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+M">Minnan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiaojun Chang</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+Z">Zhuohang Dang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+M">Mingfei Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengmeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+G">Guang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+S">Sizhe Dang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingdong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Exploring open-vocabulary video action recognition is a promising venture,
which aims to recognize previously unseen actions within any arbitrary set of
categories. Existing methods typically adapt pretrained image-text models to
the video domain, capitalizing on their inherent strengths in generalization. A
common thread among such methods is the augmentation of visual embeddings with
temporal information to improve the recognition of seen actions. Yet, they
compromise with standard less-informative action descriptions, thus faltering
when confronted with novel actions. Drawing inspiration from human cognitive
processes, we argue that augmenting text embeddings with human prior knowledge
is pivotal for open-vocabulary video action recognition. To realize this, we
innovatively blend video models with Large Language Models (LLMs) to devise
Action-conditioned Prompts. Specifically, we harness the knowledge in LLMs to
produce a set of descriptive sentences that contain distinctive features for
identifying given actions. Building upon this foundation, we further introduce
a multi-modal action knowledge alignment mechanism to align concepts in video
and textual knowledge encapsulated within the prompts. Extensive experiments on
various video benchmarks, including zero-shot, few-shot, and base-to-novel
generalization settings, demonstrate that our method not only sets new SOTA
performance but also possesses excellent interpretability.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02227" title="Abstract">arXiv:2312.02227</a> [<a href="/pdf/2312.02227" title="Download PDF">pdf</a>, <a href="/format/2312.02227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Multimodal Sentiment Analysis: Supervised Angular Margin-based  Contrastive Learning for Enhanced Fusion Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+C">Cong-Duy Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thong Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+D+A">Duc Anh Vu</a>, 
<a href="/search/cs?searchtype=author&query=Tuan%2C+L+A">Luu Anh Tuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The effectiveness of a model is heavily reliant on the quality of the fusion
representation of multiple modalities in multimodal sentiment analysis.
Moreover, each modality is extracted from raw input and integrated with the
rest to construct a multimodal representation. Although previous methods have
proposed multimodal representations and achieved promising results, most of
them focus on forming positive and negative pairs, neglecting the variation in
sentiment scores within the same class. Additionally, they fail to capture the
significance of unimodal representations in the fusion vector. To address these
limitations, we introduce a framework called Supervised Angular-based
Contrastive Learning for Multimodal Sentiment Analysis. This framework aims to
enhance discrimination and generalizability of the multimodal representation
and overcome biases in the fusion vector's modality. Our experimental results,
along with visualizations on two widely used datasets, demonstrate the
effectiveness of our approach.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02228" title="Abstract">arXiv:2312.02228</a> [<a href="/pdf/2312.02228" title="Download PDF">pdf</a>, <a href="/format/2312.02228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PixelLM: Pixel Reasoning with Large Multimodal Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhongwei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhicheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yunchao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+D">Dongmei Fu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiashi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xiaojie Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and models will be released at: <a href="https://pixellm.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While large multimodal models (LMMs) have achieved remarkable progress,
generating pixel-level masks for image reasoning tasks involving multiple
open-world targets remains a challenge. To bridge this gap, we introduce
PixelLM, an effective and efficient LMM for pixel-level reasoning and
understanding. Central to PixelLM is a novel, lightweight pixel decoder and a
comprehensive segmentation codebook. The decoder efficiently produces masks
from the hidden embeddings of the codebook tokens, which encode detailed
target-relevant information. With this design, PixelLM harmonizes with the
structure of popular LMMs and avoids the need for additional costly
segmentation models. Furthermore, we propose a target refinement loss to
enhance the model's ability to differentiate between multiple targets, leading
to substantially improved mask quality. To advance research in this area, we
construct MUSE, a high-quality multi-target reasoning segmentation benchmark.
PixelLM excels across various pixel-level image reasoning and understanding
tasks, outperforming well-established methods in multiple benchmarks, including
MUSE, single- and multi-referring segmentation. Comprehensive ablations confirm
the efficacy of each proposed component. All code, models, and datasets will be
publicly available.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02229" title="Abstract">arXiv:2312.02229</a> [<a href="/pdf/2312.02229" title="Download PDF">pdf</a>, <a href="/format/2312.02229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthetic Data Generation Techniques for Developing AI-based Speech  Assessments for Parkinson&#x27;s Disease (A Comparative Study)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parsapoor%2C+M">Mahboobeh Parsapoor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6, 5 Tables, 5 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Changes in speech and language are among the first signs of Parkinson's
disease (PD). Thus, clinicians have tried to identify individuals with PD from
their voices for years. Doctors can leverage AI-based speech assessments to
spot PD thanks to advancements in artificial intelligence (AI). Such AI systems
can be developed using machine learning classifiers that have been trained
using individuals' voices. Although several studies have shown reasonable
results in developing such AI systems, these systems would need more data
samples to achieve promising performance. This paper explores using deep
learning-based data generation techniques on the accuracy of machine learning
classifiers that are the core of such systems.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02230" title="Abstract">arXiv:2312.02230</a> [<a href="/pdf/2312.02230" title="Download PDF">pdf</a>, <a href="/format/2312.02230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple and Scalable Representation for Graph Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jang%2C+Y">Yunhui Jang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seul Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+S">Sungsoo Ahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, there has been a surge of interest in employing neural networks for
graph generation, a fundamental statistical learning problem with critical
applications like molecule design and community analysis. However, most
approaches encounter significant limitations when generating large-scale
graphs. This is due to their requirement to output the full adjacency matrices
whose size grows quadratically with the number of nodes. In response to this
challenge, we introduce a new, simple, and scalable graph representation named
gap encoded edge list (GEEL) that has a small representation size that aligns
with the number of edges. In addition, GEEL significantly reduces the
vocabulary size by incorporating the gap encoding and bandwidth restriction
schemes. GEEL can be autoregressively generated with the incorporation of node
positional encoding, and we further extend GEEL to deal with attributed graphs
by designing a new grammar. Our findings reveal that the adoption of this
compact representation not only enhances scalability but also bolsters
performance by simplifying the graph generation process. We conduct a
comprehensive evaluation across ten non-attributed and two molecular graph
generation tasks, demonstrating the effectiveness of GEEL.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02231" title="Abstract">arXiv:2312.02231</a> [<a href="/pdf/2312.02231" title="Download PDF">pdf</a>, <a href="/format/2312.02231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quality Diversity in the Amorphous Fortress (QD-AF): Evolving for  Complexity in 0-Player Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Earle%2C+S">Sam Earle</a>, 
<a href="/search/cs?searchtype=author&query=Charity%2C+M">M Charity</a>, 
<a href="/search/cs?searchtype=author&query=Rajesh%2C+D">Dipika Rajesh</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+M">Mayu Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Togelius%2C+J">Julian Togelius</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 7 figures, ALOE workship at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">We explore the generation of diverse environments using the Amorphous
Fortress (AF) simulation framework. AF defines a set of Finite State Machine
(FSM) nodes and edges that can be recombined to control the behavior of agents
in the `fortress' grid-world. The behaviors and conditions of the agents within
the framework are designed to capture the common building blocks of multi-agent
artificial life and reinforcement learning environments. Using quality
diversity evolutionary search, we generate diverse sets of environments. These
environments exhibit certain types of complexity according to measures of
agents' FSM architectures and activations, and collective behaviors. Our
approach, Quality Diversity in Amorphous Fortress (QD-AF) generates families of
0-player games akin to simplistic ecological models, and we identify the
emergence of both competitive and co-operative multi-agent and multi-species
survival dynamics. We argue that these generated worlds can collectively serve
as training and testing grounds for learning algorithms.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02232" title="Abstract">arXiv:2312.02232</a> [<a href="/pdf/2312.02232" title="Download PDF">pdf</a>, <a href="/format/2312.02232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HumanNeRF-SE: A Simple yet Effective Approach to Animate HumanNeRF with  Diverse Poses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Caoyuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu-Lun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhixiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinchen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zheng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present HumanNeRF-SE, which can synthesize diverse novel pose images with
simple input. Previous HumanNeRF studies require large neural networks to fit
the human appearance and prior knowledge. Subsequent methods build upon this
approach with some improvements. Instead, we reconstruct this approach,
combining explicit and implicit human representations with both general and
specific mapping processes. Our key insight is that explicit shape can filter
the information used to fit implicit representation, and frozen general mapping
combined with point-specific mapping can effectively avoid overfitting and
improve pose generalization performance. Our explicit and implicit human
represent combination architecture is extremely effective. This is reflected in
our model's ability to synthesize images under arbitrary poses with few-shot
input and increase the speed of synthesizing images by 15 times through a
reduction in computational complexity without using any existing acceleration
modules. Compared to the state-of-the-art HumanNeRF studies, HumanNeRF-SE
achieves better performance with fewer learnable parameters and less training
time (see Figure 1).
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02233" title="Abstract">arXiv:2312.02233</a> [<a href="/pdf/2312.02233" title="Download PDF">pdf</a>, <a href="/format/2312.02233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MedXChat: Bridging CXR Modalities with a Unified Multimodal Large Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Ling Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhanyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Luping Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite the success of Large Language Models (LLMs) in general image tasks, a
gap persists in the medical field for a multimodal large model adept at
handling the nuanced diversity of medical images. Addressing this, we propose
MedXChat, a unified multimodal large model designed for seamless interactions
between medical assistants and users. MedXChat encompasses three key
functionalities: CXR(Chest X-ray)-to-Report generation, CXR-based visual
question-answering (VQA), and Text-to-CXR synthesis. Our contributions are as
follows. Firstly, our model showcases exceptional cross-task adaptability,
displaying adeptness across all three defined tasks and outperforming the
benchmark models on the MIMIC dataset in medical multimodal applications.
Secondly, we introduce an innovative Text-to-CXR synthesis approach that
utilizes instruction-following capabilities within the Stable Diffusion (SD)
architecture. This technique integrates smoothly with the existing model
framework, requiring no extra parameters, thereby maintaining the SD's
generative strength while also bestowing upon it the capacity to render
fine-grained medical images with high fidelity. Comprehensive experiments
validate MedXChat's synergistic enhancement across all tasks. Our instruction
data and model will be open-sourced.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02235" title="Abstract">arXiv:2312.02235</a> [<a href="/pdf/2312.02235" title="Download PDF">pdf</a>, <a href="/format/2312.02235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GenEM: Physics-Informed Generative Cryo-Electron Microscopy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiakai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qihe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Wenyuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xuming He</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhijie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jingyi Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the past decade, deep conditional generative models have revolutionized
the generation of realistic images, extending their application from
entertainment to scientific domains. Single-particle cryo-electron microscopy
(cryo-EM) is crucial in resolving near-atomic resolution 3D structures of
proteins, such as the SARS-COV-2 spike protein. To achieve high-resolution
reconstruction, AI models for particle picking and pose estimation have been
adopted. However, their performance is still limited as they lack high-quality
annotated datasets. To address this, we introduce physics-informed generative
cryo-electron microscopy (GenEM), which for the first time integrates
physical-based cryo-EM simulation with a generative unpaired noise translation
to generate physically correct synthetic cryo-EM datasets with realistic
noises. Initially, GenEM simulates the cryo-EM imaging process based on a
virtual specimen. To generate realistic noises, we leverage an unpaired noise
translation via contrastive learning with a novel mask-guided sampling scheme.
Extensive experiments show that GenEM is capable of generating realistic
cryo-EM images. The generated dataset can further enhance particle picking and
pose estimation models, eventually improving the reconstruction resolution. We
will release our code and annotated synthetic datasets.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02236" title="Abstract">arXiv:2312.02236</a> [<a href="/pdf/2312.02236" title="Download PDF">pdf</a>, <a href="/format/2312.02236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Adversarial Training with Neural Tangent Kernel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanlin Li</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+H">Han Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Shangwei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Adversarial training (AT) is an important and attractive topic in deep
learning security, exhibiting mysteries and odd properties. Recent studies of
neural network training dynamics based on Neural Tangent Kernel (NTK) make it
possible to reacquaint AT and deeply analyze its properties. In this paper, we
perform an in-depth investigation of AT process and properties with NTK, such
as NTK evolution. We uncover three new findings that are missed in previous
works. First, we disclose the impact of data normalization on AT and the
importance of unbiased estimators in batch normalization layers. Second, we
experimentally explore the kernel dynamics and propose more time-saving AT
methods. Third, we study the spectrum feature inside the kernel to address the
catastrophic overfitting problem. To the best of our knowledge, it is the first
work leveraging the observations of kernel dynamics to improve existing AT
methods.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02237" title="Abstract">arXiv:2312.02237</a> [<a href="/pdf/2312.02237" title="Download PDF">pdf</a>, <a href="/format/2312.02237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Singular Regularization with Information Bottleneck Improves Model&#x27;s  Adversarial Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanlin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+N">Naishan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Man Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Adversarial examples are one of the most severe threats to deep learning
models. Numerous works have been proposed to study and defend adversarial
examples. However, these works lack analysis of adversarial information or
perturbation, which cannot reveal the mystery of adversarial examples and lose
proper interpretation. In this paper, we aim to fill this gap by studying
adversarial information as unstructured noise, which does not have a clear
pattern. Specifically, we provide some empirical studies with singular value
decomposition, by decomposing images into several matrices, to analyze
adversarial information for different attacks. Based on the analysis, we
propose a new module to regularize adversarial information and combine
information bottleneck theory, which is proposed to theoretically restrict
intermediate representations. Therefore, our method is interpretable. Moreover,
the fashion of our design is a novel principle that is general and unified.
Equipped with our new module, we evaluate two popular model structures on two
mainstream datasets with various adversarial attacks. The results indicate that
the improvement in robust accuracy is significant. On the other hand, we prove
that our method is efficient with only a few additional parameters and able to
be explained under regional faithfulness analysis.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02238" title="Abstract">arXiv:2312.02238</a> [<a href="/pdf/2312.02238" title="Download PDF">pdf</a>, <a href="/format/2312.02238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> X-Adapter: Adding Universal Compatibility of Plugins for Upgraded  Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ran%2C+L">Lingmin Ran</a>, 
<a href="/search/cs?searchtype=author&query=Cun%2C+X">Xiaodong Cun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">JiaWei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zijie%2C+S">Song Zijie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xintao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Keppo%2C+J">Jussi Keppo</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://showlab.github.io/X-Adapter/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
<p class="mathjax">We introduce X-Adapter, a universal upgrader to enable the pretrained
plug-and-play modules (e.g., ControlNet, LoRA) to work directly with the
upgraded text-to-image diffusion model (e.g., SDXL) without further retraining.
We achieve this goal by training an additional network to control the frozen
upgraded model with the new text-image data pairs. In detail, X-Adapter keeps a
frozen copy of the old model to preserve the connectors of different plugins.
Additionally, X-Adapter adds trainable mapping layers that bridge the decoders
from models of different versions for feature remapping. The remapped features
will be used as guidance for the upgraded model. To enhance the guidance
ability of X-Adapter, we employ a null-text training strategy for the upgraded
model. After training, we also introduce a two-stage denoising strategy to
align the initial latents of X-Adapter and the upgraded model. Thanks to our
strategies, X-Adapter demonstrates universal compatibility with various plugins
and also enables plugins of different versions to work together, thereby
expanding the functionalities of diffusion community. To verify the
effectiveness of the proposed method, we conduct extensive experiments and the
results show that X-Adapter may facilitate wider application in the upgraded
foundational diffusion model.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02239" title="Abstract">arXiv:2312.02239</a> [<a href="/pdf/2312.02239" title="Download PDF">pdf</a>, <a href="/format/2312.02239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-based Deep Learning for Beam Prediction based on a Channel Chart
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yassine%2C+T">Taha Yassine</a> (IETR, INSA Rennes), 
<a href="/search/cs?searchtype=author&query=Chatelier%2C+B">Baptiste Chatelier</a> (IETR, MERCE-France, INSA Rennes), 
<a href="/search/cs?searchtype=author&query=Corlay%2C+V">Vincent Corlay</a> (MERCE-France), 
<a href="/search/cs?searchtype=author&query=Crussi%C3%A8re%2C+M">Matthieu Crussi&#xe8;re</a> (IETR, INSA Rennes), 
<a href="/search/cs?searchtype=author&query=Paquelet%2C+S">Stephane Paquelet</a>, 
<a href="/search/cs?searchtype=author&query=Tirkkonen%2C+O">Olav Tirkkonen</a>, 
<a href="/search/cs?searchtype=author&query=Magoarou%2C+L+L">Luc Le Magoarou</a> (INSA Rennes, IETR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Channel charting builds a map of the radio environment in an unsupervised
way. The obtained chart locations can be seen as low-dimensional compressed
versions of channel state information that can be used for a wide variety of
applications, including beam prediction. In non-standalone or cell-free
systems, chart locations computed at a given base station can be transmitted to
several other base stations (possibly operating at different frequency bands)
for them to predict which beams to use. This potentially yields a dramatic
reduction of the overhead due to channel estimation or beam management, since
only the base station performing charting requires channel state information,
the others directly predicting the beam from the chart location. In this paper,
advanced model-based neural network architectures are proposed for both channel
charting and beam prediction. The proposed methods are assessed on realistic
synthetic channels, yielding promising results.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02240" title="Abstract">arXiv:2312.02240</a> [<a href="/pdf/2312.02240" title="Download PDF">pdf</a>, <a href="/format/2312.02240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Learning-Based Spectral Knowledge Distillation for  Multi-Modality and Missing Modality Scenarios in Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sikdar%2C+A">Aniruddh Sikdar</a>, 
<a href="/search/cs?searchtype=author&query=Teotia%2C+J">Jayant Teotia</a>, 
<a href="/search/cs?searchtype=author&query=Sundaram%2C+S">Suresh Sundaram</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Improving the performance of semantic segmentation models using multispectral
information is crucial, especially for environments with low-light and adverse
conditions. Multi-modal fusion techniques pursue either the learning of
cross-modality features to generate a fused image or engage in knowledge
distillation but address multimodal and missing modality scenarios as distinct
issues, which is not an optimal approach for multi-sensor models. To address
this, a novel multi-modal fusion approach called CSK-Net is proposed, which
uses a contrastive learning-based spectral knowledge distillation technique
along with an automatic mixed feature exchange mechanism for semantic
segmentation in optical (EO) and infrared (IR) images. The distillation scheme
extracts detailed textures from the optical images and distills them into the
optical branch of CSK-Net. The model encoder consists of shared convolution
weights with separate batch norm (BN) layers for both modalities, to capture
the multi-spectral information from different modalities of the same objects. A
Novel Gated Spectral Unit (GSU) and mixed feature exchange strategy are
proposed to increase the correlation of modality-shared information and
decrease the modality-specific information during the distillation process.
Comprehensive experiments show that CSK-Net surpasses state-of-the-art models
in multi-modal tasks and for missing modalities when exclusively utilizing IR
data for inference across three public benchmarking datasets. For missing
modality scenarios, the performance increase is achieved without additional
computational costs compared to the baseline segmentation models.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02243" title="Abstract">arXiv:2312.02243</a> [<a href="/pdf/2312.02243" title="Download PDF">pdf</a>, <a href="/format/2312.02243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlowHON: Representing Flow Fields Using Higher-Order Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Nan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhihong Li</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+J">Jun Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be submitted to TVCG
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Flow fields are often partitioned into data blocks for massively parallel
computation and analysis based on blockwise relationships. However, most of the
previous techniques only consider the first-order dependencies among blocks,
which is insufficient in describing complex flow patterns. In this work, we
present FlowHON, an approach to construct higher-order networks (HONs) from
flow fields. FlowHON captures the inherent higher-order dependencies in flow
fields as nodes and estimates the transitions among them as edges. We formulate
the HON construction as an optimization problem with three linear
transformations. The first two layers correspond to the node generation and the
third one corresponds to edge estimation. Our formulation allows the node
generation and edge estimation to be solved in a unified framework. With
FlowHON, the rich set of traditional graph algorithms can be applied without
any modification to analyze flow fields, while leveraging the higher-order
information to understand the inherent structure and manage flow data for
efficiency. We demonstrate the effectiveness of FlowHON using a series of
downstream tasks, including estimating the density of particles during tracing,
partitioning flow fields for data management, and understanding flow fields
using the node-link diagram representation of networks.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02244" title="Abstract">arXiv:2312.02244</a> [<a href="/pdf/2312.02244" title="Download PDF">pdf</a>, <a href="/format/2312.02244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometrically-driven Aggregation for Zero-shot 3D Point Cloud  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mei%2C+G">Guofeng Mei</a>, 
<a href="/search/cs?searchtype=author&query=Riz%2C+L">Luigi Riz</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Poiesi%2C+F">Fabio Poiesi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Zero-shot, point cloud, 2D Vision-Language Models, geometric structure, training-free
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Zero-shot 3D point cloud understanding can be achieved via 2D Vision-Language
Models (VLMs). Existing strategies directly map Vision-Language Models from 2D
pixels of rendered or captured views to 3D points, overlooking the inherent and
expressible point cloud geometric structure. Geometrically similar or close
regions can be exploited for bolstering point cloud understanding as they are
likely to share semantic information. To this end, we introduce the first
training-free aggregation technique that leverages the point cloud's 3D
geometric structure to improve the quality of the transferred Vision-Language
Models. Our approach operates iteratively, performing local-to-global
aggregation based on geometric and semantic point-level reasoning. We benchmark
our approach on three downstream tasks, including classification, part
segmentation, and semantic segmentation, with a variety of datasets
representing both synthetic/real-world, and indoor/outdoor scenarios. Our
approach achieves new state-of-the-art results in all benchmarks. We will
release the source code publicly.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02246" title="Abstract">arXiv:2312.02246</a> [<a href="/pdf/2312.02246" title="Download PDF">pdf</a>, <a href="/format/2312.02246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditional Variational Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=della+Maggiora%2C+G">Gabriel della Maggiora</a>, 
<a href="/search/cs?searchtype=author&query=Croquevielle%2C+L+A">Luis Alberto Croquevielle</a>, 
<a href="/search/cs?searchtype=author&query=Desphande%2C+N">Nikita Desphande</a>, 
<a href="/search/cs?searchtype=author&query=Horsley%2C+H">Harry Horsley</a>, 
<a href="/search/cs?searchtype=author&query=Heinis%2C+T">Thomas Heinis</a>, 
<a href="/search/cs?searchtype=author&query=Yakimovich%2C+A">Artur Yakimovich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Denoising Diffusion Probabilistic Models, Inverse Problems, Generative Models, Super Resolution, Phase Quantification, Variational Methods
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Inverse problems aim to determine parameters from observations, a crucial
task in engineering and science. Lately, generative models, especially
diffusion models, have gained popularity in this area for their ability to
produce realistic solutions and their good mathematical properties. Despite
their success, an important drawback of diffusion models is their sensitivity
to the choice of variance schedule, which controls the dynamics of the
diffusion process. Fine-tuning this schedule for specific applications is
crucial but time-costly and does not guarantee an optimal result. We propose a
novel approach for learning the schedule as part of the training process. Our
method supports probabilistic conditioning on data, provides high-quality
solutions, and is flexible, proving able to adapt to different applications
with minimum overhead. This approach is tested in two unrelated inverse
problems: super-resolution microscopy and quantitative phase imaging, yielding
comparable or superior results to previous methods and fine-tuned diffusion
models. We conclude that fine-tuning the schedule by experimentation should be
avoided because it can be learned during training in a stable way that yields
better results.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02247" title="Abstract">arXiv:2312.02247</a> [<a href="/pdf/2312.02247" title="Download PDF">pdf</a>, <a href="/format/2312.02247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Active Learning for Target Domain Generalisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caramalau%2C+R">Razvan Caramalau</a>, 
<a href="/search/cs?searchtype=author&query=Bhattarai%2C+B">Binod Bhattarai</a>, 
<a href="/search/cs?searchtype=author&query=Stoyanov%2C+D">Danail Stoyanov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this paper, we introduce Active Learning framework in Federated Learning
for Target Domain Generalisation, harnessing the strength from both learning
paradigms. Our framework, FEDALV, composed of Active Learning (AL) and
Federated Domain Generalisation (FDG), enables generalisation of an image
classification model trained from limited source domain client's data without
sharing images to an unseen target domain. To this end, our FDG, FEDA, consists
of two optimisation updates during training, one at the client and another at
the server level. For the client, the introduced losses aim to reduce feature
complexity and condition alignment, while in the server, the regularisation
limits free energy biases between source and target obtained by the global
model. The remaining component of FEDAL is AL with variable budgets, which
queries the server to retrieve and sample the most informative local data for
the targeted client. We performed multiple experiments on FDG w/ and w/o AL and
compared with both conventional FDG baselines and Federated Active Learning
baselines. Our extensive quantitative experiments demonstrate the superiority
of our method in accuracy and efficiency compared to the multiple contemporary
methods. FEDALV manages to obtain the performance of the full training target
accuracy while sampling as little as 5% of the source client's data.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02249" title="Abstract">arXiv:2312.02249</a> [<a href="/pdf/2312.02249" title="Download PDF">pdf</a>, <a href="/format/2312.02249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recursive Visual Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+J">Jiaxin Ge</a>, 
<a href="/search/cs?searchtype=author&query=Subramanian%2C+S">Sanjay Subramanian</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Baifeng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Herzig%2C+R">Roei Herzig</a>, 
<a href="/search/cs?searchtype=author&query=Darrell%2C+T">Trevor Darrell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Visual Programming (VP) has emerged as a powerful framework for Visual
Question Answering (VQA). By generating and executing bespoke code for each
question, these methods demonstrate impressive compositional and reasoning
capabilities, especially in few-shot and zero-shot scenarios. However, existing
VP methods generate all code in a single function, resulting in code that is
suboptimal in terms of both accuracy and interpretability. Inspired by human
coding practices, we propose Recursive Visual Programming (RVP), which
simplifies generated routines, provides more efficient problem solving, and can
manage more complex data structures. RVP is inspired by human coding practices
and approaches VQA tasks with an iterative recursive code generation approach,
allowing decomposition of complicated problems into smaller parts. Notably, RVP
is capable of dynamic type assignment, i.e., as the system recursively
generates a new piece of code, it autonomously determines the appropriate
return type and crafts the requisite code to generate that output. We show
RVP's efficacy through extensive experiments on benchmarks including VSR, COVR,
GQA, and NextQA, underscoring the value of adopting human-like recursive and
modular programming techniques for solving VQA tasks through coding.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02251" title="Abstract">arXiv:2312.02251</a> [<a href="/pdf/2312.02251" title="Download PDF">pdf</a>, <a href="/format/2312.02251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Tuning Language Models for Context-Specific SQL Query Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rebei%2C+A">Amine Rebei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">The ability to generate SQL queries from natural language has significant
implications for making data accessible to non-specialists. This paper presents
a novel approach to fine-tuning open-source large language models (LLMs) for
the task of transforming natural language into SQL queries within the retail
domain. We introduce models specialized in generating SQL queries, trained on
synthetic datasets tailored to the Snowflake SQL and GoogleSQL dialects. Our
methodology involves generating a context-specific dataset using GPT-4, then
fine-tuning three open-source LLMs(Starcoder Plus, Code-Llama, and Mistral)
employing the LoRa technique to optimize for resource constraints. The
fine-tuned models demonstrate superior performance in zero-shot settings
compared to the baseline GPT-4, with Code-Llama achieving the highest accuracy
rates, at 81.58% for Snowflake SQL and 82.66% for GoogleSQL. These results
underscore the effectiveness of fine-tuning LLMs on domain-specific tasks and
suggest a promising direction for enhancing the accessibility of relational
databases through natural language interfaces.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02252" title="Abstract">arXiv:2312.02252</a> [<a href="/pdf/2312.02252" title="Download PDF">pdf</a>, <a href="/format/2312.02252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models as Consistent Story Visualizers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xiaoqian Shen</a>, 
<a href="/search/cs?searchtype=author&query=Elhoseiny%2C+M">Mohamed Elhoseiny</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://storygpt-v.s3.amazonaws.com/index.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent generative models have demonstrated impressive capabilities in
generating realistic and visually pleasing images grounded on textual prompts.
Nevertheless, a significant challenge remains in applying these models for the
more intricate task of story visualization. Since it requires resolving
pronouns (he, she, they) in the frame descriptions, i.e., anaphora resolution,
and ensuring consistent characters and background synthesis across frames. Yet,
the emerging Large Language Model (LLM) showcases robust reasoning abilities to
navigate through ambiguous references and process extensive sequences.
Therefore, we introduce \textbf{StoryGPT-V}, which leverages the merits of the
latent diffusion (LDM) and LLM to produce images with consistent and
high-quality characters grounded on given story descriptions. First, we train a
character-aware LDM, which takes character-augmented semantic embedding as
input and includes the supervision of the cross-attention map using character
segmentation masks, aiming to enhance character generation accuracy and
faithfulness. In the second stage, we enable an alignment between the output of
LLM and the character-augmented embedding residing in the input space of the
first-stage model. This harnesses the reasoning ability of LLM to address
ambiguous references and the comprehension capability to memorize the context.
We conduct comprehensive experiments on two visual story visualization
benchmarks. Our model reports superior quantitative results and consistently
generates accurate characters of remarkable quality with low memory
consumption. Our code will be made publicly available.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02253" title="Abstract">arXiv:2312.02253</a> [<a href="/pdf/2312.02253" title="Download PDF">pdf</a>, <a href="/format/2312.02253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diversify, Don&#x27;t Fine-Tune: Scaling Up Visual Recognition Training with  Synthetic Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhuoran Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chenchen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Culatana%2C+S">Sean Culatana</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamoorthi%2C+R">Raghuraman Krishnamoorthi</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+F">Fanyi Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y+J">Yong Jae Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advances in generative deep learning have enabled the creation of
high-quality synthetic images in text-to-image generation. Prior work shows
that fine-tuning a pretrained diffusion model on ImageNet and generating
synthetic training images from the finetuned model can enhance an ImageNet
classifier's performance. However, performance degrades as synthetic images
outnumber real ones. In this paper, we explore whether generative fine-tuning
is essential for this improvement and whether it is possible to further scale
up training using more synthetic data. We present a new framework leveraging
off-the-shelf generative models to generate synthetic training images,
addressing multiple challenges: class name ambiguity, lack of diversity in
naive prompts, and domain shifts. Specifically, we leverage large language
models (LLMs) and CLIP to resolve class name ambiguity. To diversify images, we
propose contextualized diversification (CD) and stylized diversification (SD)
methods, also prompted by LLMs. Finally, to mitigate domain shifts, we leverage
domain adaptation techniques with auxiliary batch normalization for synthetic
images. Our framework consistently enhances recognition model performance with
more synthetic data, up to 6x of original ImageNet size showcasing the
potential of synthetic data for improved recognition models and strong
out-of-domain generalization.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02254" title="Abstract">arXiv:2312.02254</a> [<a href="/pdf/2312.02254" title="Download PDF">pdf</a>, <a href="/ps/2312.02254" title="Download PostScript">ps</a>, <a href="/format/2312.02254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Innovations in Agricultural Forecasting: A Multivariate Regression Study  on Global Crop Yield Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+I">Ishaan Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Ayalasomayajula%2C+S">Samyutha Ayalasomayajula</a>, 
<a href="/search/cs?searchtype=author&query=Shashidhara%2C+Y">Yashas Shashidhara</a>, 
<a href="/search/cs?searchtype=author&query=Kataria%2C+A">Anish Kataria</a>, 
<a href="/search/cs?searchtype=author&query=Shashidhara%2C+S">Shreyas Shashidhara</a>, 
<a href="/search/cs?searchtype=author&query=Kataria%2C+K">Krishita Kataria</a>, 
<a href="/search/cs?searchtype=author&query=Undurti%2C+A">Aditya Undurti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures, 1 table, Guided by Dr. Aditya Undurti
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The prediction of crop yields internationally is a crucial objective in
agricultural research. Thus, this study implements 6 regression models (Linear,
Tree, Gradient Descent, Gradient Boosting, K- Nearest Neighbors, and Random
Forest) to predict crop yields in 196 countries. Given 4 key training
parameters, pesticides (tonnes), rainfall (mm), temperature (Celsius), and
yield (hg/ha), it was found that our Random Forest Regression model achieved a
determination coefficient (r^2) of 0.94, with a margin of error (ME) of .03.
The models were trained and tested using the Food and Agricultural Organization
of the United Nations data, along with the World Bank Climate Change Data
Catalog. Furthermore, each parameter was analyzed to understand how varying
factors could impact overall yield. We used unconventional models, contrary to
generally used Deep Learning (DL) and Machine Learning (ML) models, combined
with recently collected data to implement a unique approach in our research.
Existing scholarship would benefit from understanding the most optimal model
for agricultural research, specifically using the United Nations data.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02255" title="Abstract">arXiv:2312.02255</a> [<a href="/pdf/2312.02255" title="Download PDF">pdf</a>, <a href="/format/2312.02255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Re-Nerfing: Enforcing Geometric Constraints on Neural Radiance Fields  through Novel Views Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tristram%2C+F">Felix Tristram</a>, 
<a href="/search/cs?searchtype=author&query=Gasperini%2C+S">Stefano Gasperini</a>, 
<a href="/search/cs?searchtype=author&query=Tombari%2C+F">Federico Tombari</a>, 
<a href="/search/cs?searchtype=author&query=Navab%2C+N">Nassir Navab</a>, 
<a href="/search/cs?searchtype=author&query=Busam%2C+B">Benjamin Busam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code will be released upon acceptance
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Neural Radiance Fields (NeRFs) have shown remarkable novel view synthesis
capabilities even in large-scale, unbounded scenes, albeit requiring hundreds
of views or introducing artifacts in sparser settings. Their optimization
suffers from shape-radiance ambiguities wherever only a small visual overlap is
available. This leads to erroneous scene geometry and artifacts. In this paper,
we propose Re-Nerfing, a simple and general multi-stage approach that leverages
NeRF's own view synthesis to address these limitations. With Re-Nerfing, we
increase the scene's coverage and enhance the geometric consistency of novel
views as follows: First, we train a NeRF with the available views. Then, we use
the optimized NeRF to synthesize pseudo-views next to the original ones to
simulate a stereo or trifocal setup. Finally, we train a second NeRF with both
original and pseudo views while enforcing structural, epipolar constraints via
the newly synthesized images. Extensive experiments on the mip-NeRF 360 dataset
show the effectiveness of Re-Nerfing across denser and sparser input scenarios,
bringing improvements to the state-of-the-art Zip-NeRF, even when trained with
all views.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02256" title="Abstract">arXiv:2312.02256</a> [<a href="/pdf/2312.02256" title="Download PDF">pdf</a>, <a href="/format/2312.02256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EMDM: Efficient Motion Diffusion Model for Fast, High-Quality Motion  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wenyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Z">Zhiyang Dou</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zeyu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Z">Zhouyingcheng Liao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingbo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Komura%2C+T">Taku Komura</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingjie Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://frank-zy-dou.github.io/projects/EMDM/index.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">We introduce Efficient Motion Diffusion Model (EMDM) for fast and
high-quality human motion generation. Although previous motion diffusion models
have shown impressive results, they struggle to achieve fast generation while
maintaining high-quality human motions. Motion latent diffusion has been
proposed for efficient motion generation. However, effectively learning a
latent space can be non-trivial in such a two-stage manner. Meanwhile,
accelerating motion sampling by increasing the step size, e.g., DDIM, typically
leads to a decline in motion quality due to the inapproximation of complex data
distributions when naively increasing the step size. In this paper, we propose
EMDM that allows for much fewer sample steps for fast motion generation by
modeling the complex denoising distribution during multiple sampling steps.
Specifically, we develop a Conditional Denoising Diffusion GAN to capture
multimodal data distributions conditioned on both control signals, i.e.,
textual description and denoising time step. By modeling the complex data
distribution, a larger sampling step size and fewer steps are achieved during
motion synthesis, significantly accelerating the generation process. To
effectively capture the human dynamics and reduce undesired artifacts, we
employ motion geometric loss during network training, which improves the motion
quality and training efficiency. As a result, EMDM achieves a remarkable
speed-up at the generation stage while maintaining high-quality motion
generation in terms of fidelity and diversity.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02284" title="Abstract">arXiv:2312.02284</a> [<a href="/pdf/2312.02284" title="Download PDF">pdf</a>, <a href="/format/2312.02284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PatchFusion: An End-to-End Tile-Based Framework for High-Resolution  Monocular Metric Depth Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Bhat%2C+S+F">Shariq Farooq Bhat</a>, 
<a href="/search/cs?searchtype=author&query=Wonka%2C+P">Peter Wonka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Single image depth estimation is a foundational task in computer vision and
generative modeling. However, prevailing depth estimation models grapple with
accommodating the increasing resolutions commonplace in today's consumer
cameras and devices. Existing high-resolution strategies show promise, but they
often face limitations, ranging from error propagation to the loss of
high-frequency details. We present PatchFusion, a novel tile-based framework
with three key components to improve the current state of the art: (1) A
patch-wise fusion network that fuses a globally-consistent coarse prediction
with finer, inconsistent tiled predictions via high-level feature guidance, (2)
A Global-to-Local (G2L) module that adds vital context to the fusion network,
discarding the need for patch selection heuristics, and (3) A Consistency-Aware
Training (CAT) and Inference (CAI) approach, emphasizing patch overlap
consistency and thereby eradicating the necessity for post-processing.
Experiments on UnrealStereo4K, MVS-Synth, and Middleburry 2014 demonstrate that
our framework can generate high-resolution depth maps with intricate details.
PatchFusion is independent of the base model for depth estimation. Notably, our
framework built on top of SOTA ZoeDepth brings improvements for a total of
17.3% and 29.4% in terms of the root mean squared error (RMSE) on
UnrealStereo4K and MVS-Synth, respectively.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02290" title="Abstract">arXiv:2312.02290</a> [<a href="/pdf/2312.02290" title="Download PDF">pdf</a>, <a href="/format/2312.02290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> You Can Run but not Hide: Improving Gait Recognition with Intrinsic  Occlusion Type Awareness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Ayush Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Chellappa%2C+R">Rama Chellappa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been accepted to WACV 2024 as an Oral paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While gait recognition has seen many advances in recent years, the occlusion
problem has largely been ignored. This problem is especially important for gait
recognition from uncontrolled outdoor sequences at range - since any small
obstruction can affect the recognition system. Most current methods assume the
availability of complete body information while extracting the gait features.
When parts of the body are occluded, these methods may hallucinate and output a
corrupted gait signature as they try to look for body parts which are not
present in the input at all. To address this, we exploit the learned occlusion
type while extracting identity features from videos. Thus, in this work, we
propose an occlusion aware gait recognition method which can be used to model
intrinsic occlusion awareness into potentially any state-of-the-art gait
recognition method. Our experiments on the challenging GREW and BRIAR datasets
show that networks enhanced with this occlusion awareness perform better at
recognition tasks than their counterparts trained on similar occlusions.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02296" title="Abstract">arXiv:2312.02296</a> [<a href="/pdf/2312.02296" title="Download PDF">pdf</a>, <a href="/format/2312.02296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMs Accelerate Annotation for Medical Information Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goel%2C+A">Akshay Goel</a>, 
<a href="/search/cs?searchtype=author&query=Gueta%2C+A">Almog Gueta</a>, 
<a href="/search/cs?searchtype=author&query=Gilon%2C+O">Omry Gilon</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Erell%2C+S">Sofia Erell</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+L+H">Lan Huong Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+X">Xiaohong Hao</a>, 
<a href="/search/cs?searchtype=author&query=Jaber%2C+B">Bolous Jaber</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+S">Shashir Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Kartha%2C+R">Rupesh Kartha</a>, 
<a href="/search/cs?searchtype=author&query=Steiner%2C+J">Jean Steiner</a>, 
<a href="/search/cs?searchtype=author&query=Laish%2C+I">Itay Laish</a>, 
<a href="/search/cs?searchtype=author&query=Feder%2C+A">Amir Feder</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in proceedings of the Machine Learning for Health (ML4H) Symposium 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The unstructured nature of clinical notes within electronic health records
often conceals vital patient-related information, making it challenging to
access or interpret. To uncover this hidden information, specialized Natural
Language Processing (NLP) models are required. However, training these models
necessitates large amounts of labeled data, a process that is both
time-consuming and costly when relying solely on human experts for annotation.
In this paper, we propose an approach that combines Large Language Models
(LLMs) with human expertise to create an efficient method for generating ground
truth labels for medical text annotation. By utilizing LLMs in conjunction with
human annotators, we significantly reduce the human annotation burden, enabling
the rapid creation of labeled datasets. We rigorously evaluate our method on a
medical information extraction task, demonstrating that our approach not only
substantially cuts down on human intervention but also maintains high accuracy.
The results highlight the potential of using LLMs to improve the utilization of
unstructured clinical data, allowing for the swift deployment of tailored NLP
solutions in healthcare.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02299" title="Abstract">arXiv:2312.02299</a> [<a href="/pdf/2312.02299" title="Download PDF">pdf</a>, <a href="/ps/2312.02299" title="Download PostScript">ps</a>, <a href="/format/2312.02299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cotton Yield Prediction Using Random Forest
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mitra%2C+A">Alakananda Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Beegum%2C+S">Sahila Beegum</a>, 
<a href="/search/cs?searchtype=author&query=Fleisher%2C+D">David Fleisher</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+V+R">Vangimalla R. Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wenguang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ray%2C+C">Chittaranjan Ray</a>, 
<a href="/search/cs?searchtype=author&query=Timlin%2C+D">Dennis Timlin</a>, 
<a href="/search/cs?searchtype=author&query=Malakar%2C+A">Arindam Malakar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Applications (stat.AP)

</div>
<p class="mathjax">The cotton industry in the United States is committed to sustainable
production practices that minimize water, land, and energy use while improving
soil health and cotton output. Climate-smart agricultural technologies are
being developed to boost yields while decreasing operating expenses. Crop yield
prediction, on the other hand, is difficult because of the complex and
nonlinear impacts of cultivar, soil type, management, pest and disease,
climate, and weather patterns on crops. To solve this issue, we employ machine
learning (ML) to forecast production while considering climate change, soil
diversity, cultivar, and inorganic nitrogen levels. From the 1980s to the
1990s, field data were gathered across the southern cotton belt of the United
States. To capture the most current effects of climate change over the previous
six years, a second data source was produced using the process-based crop
model, GOSSYM. We concentrated our efforts on three distinct areas inside each
of the three southern states: Texas, Mississippi, and Georgia. To simplify the
amount of computations, accumulated heat units (AHU) for each set of
experimental data were employed as an analogy to use time-series weather data.
The Random Forest Regressor yielded a 97.75% accuracy rate, with a root mean
square error of 55.05 kg/ha and an R2 of around 0.98. These findings
demonstrate how an ML technique may be developed and applied as a reliable and
easy-to-use model to support the cotton climate-smart initiative.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02300" title="Abstract">arXiv:2312.02300</a> [<a href="/pdf/2312.02300" title="Download PDF">pdf</a>, <a href="/ps/2312.02300" title="Download PostScript">ps</a>, <a href="/format/2312.02300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconsideration on evaluation of machine learning models in continuous  monitoring using wearables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Cheng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhicheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Rudin%2C+C">Cynthia Rudin</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+R">Ran Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Nahab%2C+F+B">Fadi B Nahab</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiao Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper explores the challenges in evaluating machine learning (ML) models
for continuous health monitoring using wearable devices beyond conventional
metrics. We state the complexities posed by real-world variability, disease
dynamics, user-specific characteristics, and the prevalence of false
notifications, necessitating novel evaluation strategies. Drawing insights from
large-scale heart studies, the paper offers a comprehensive guideline for
robust ML model evaluation on continuous health monitoring.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02308" title="Abstract">arXiv:2312.02308</a> [<a href="/pdf/2312.02308" title="Download PDF">pdf</a>, <a href="/format/2312.02308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdsorbRL: Deep Multi-Objective Reinforcement Learning for Inverse  Catalysts Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lacombe%2C+R">Romain Lacombe</a>, 
<a href="/search/cs?searchtype=author&query=Hendren%2C+L">Lucas Hendren</a>, 
<a href="/search/cs?searchtype=author&query=El-Awady%2C+K">Khalid El-Awady</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37th Conference on Neural Information Processing Systems (NeurIPS 2023), AI for Accelerated Materials Design Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Chemical Physics (physics.chem-ph)

</div>
<p class="mathjax">A central challenge of the clean energy transition is the development of
catalysts for low-emissions technologies. Recent advances in Machine Learning
for quantum chemistry drastically accelerate the computation of catalytic
activity descriptors such as adsorption energies. Here we introduce AdsorbRL, a
Deep Reinforcement Learning agent aiming to identify potential catalysts given
a multi-objective binding energy target, trained using offline learning on the
Open Catalyst 2020 and Materials Project data sets. We experiment with Deep
Q-Network agents to traverse the space of all ~160,000 possible unary, binary
and ternary compounds of 55 chemical elements, with very sparse rewards based
on adsorption energy known for only between 2,000 and 3,000 catalysts per
adsorbate. To constrain the actions space, we introduce Random Edge Traversal
and train a single-objective DQN agent on the known states subgraph, which we
find strengthens target binding energy by an average of 4.1 eV. We extend this
approach to multi-objective, goal-conditioned learning, and train a DQN agent
to identify materials with the highest (respectively lowest) adsorption
energies for multiple simultaneous target adsorbates. We experiment with
Objective Sub-Sampling, a novel training scheme aimed at encouraging
exploration in the multi-objective setup, and demonstrate simultaneous
adsorption energy improvement across all target adsorbates, by an average of
0.8 eV. Overall, our results suggest strong potential for Deep Reinforcement
Learning applied to the inverse catalysts design problem.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02309" title="Abstract">arXiv:2312.02309</a> [<a href="/pdf/2312.02309" title="Download PDF">pdf</a>, <a href="/format/2312.02309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training Reinforcement Learning Agents and Humans With  Difficulty-Conditioned Generators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tio%2C+S">Sidney Tio</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+J">Jimmy Ho</a>, 
<a href="/search/cs?searchtype=author&query=Varakantham%2C+P">Pradeep Varakantham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">We adapt Parameterized Environment Response Model (PERM), a method for
training both Reinforcement Learning (RL) Agents and human learners in
parameterized environments by directly modeling difficulty and ability.
Inspired by Item Response Theory (IRT), PERM aligns environment difficulty with
individual ability, creating a Zone of Proximal Development-based curriculum.
Remarkably, PERM operates without real-time RL updates and allows for offline
training, ensuring its adaptability across diverse students. We present a
two-stage training process that capitalizes on PERM's adaptability, and
demonstrate its effectiveness in training RL agents and humans in an empirical
study.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02310" title="Abstract">arXiv:2312.02310</a> [<a href="/pdf/2312.02310" title="Download PDF">pdf</a>, <a href="/format/2312.02310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VaQuitA: Enhancing Alignment in LLM-Assisted Video Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yizhou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruiyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoliang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+U">Uttaran Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yun Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Gang Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advancements in language-model-based video understanding have been
progressing at a remarkable pace, spurred by the introduction of Large Language
Models (LLMs). However, the focus of prior research has been predominantly on
devising a projection layer that maps video features to tokens, an approach
that is both rudimentary and inefficient. In our study, we introduce a
cutting-edge framework, VaQuitA, designed to refine the synergy between video
and textual information. At the data level, instead of sampling frames
uniformly, we implement a sampling method guided by CLIP-score rankings, which
enables a more aligned selection of frames with the given question. At the
feature level, we integrate a trainable Video Perceiver alongside a
Visual-Query Transformer (abbreviated as VQ-Former), which bolsters the
interplay between the input question and the video features. We also discover
that incorporating a simple prompt, "Please be critical", into the LLM input
can substantially enhance its video comprehension capabilities. Our
experimental results indicate that VaQuitA consistently sets a new benchmark
for zero-shot video question-answering tasks and is adept at producing
high-quality, multi-turn video dialogues with users.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02312" title="Abstract">arXiv:2312.02312</a> [<a href="/pdf/2312.02312" title="Download PDF">pdf</a>, <a href="/format/2312.02312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Encoders for Data-Efficient Imitation Learning in Modern Video  Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sch%C3%A4fer%2C+L">Lukas Sch&#xe4;fer</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+L">Logan Jones</a>, 
<a href="/search/cs?searchtype=author&query=Kanervisto%2C+A">Anssi Kanervisto</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yuhan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Rashid%2C+T">Tabish Rashid</a>, 
<a href="/search/cs?searchtype=author&query=Georgescu%2C+R">Raluca Georgescu</a>, 
<a href="/search/cs?searchtype=author&query=Bignell%2C+D">Dave Bignell</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+S">Siddhartha Sen</a>, 
<a href="/search/cs?searchtype=author&query=Gavito%2C+A+T">Andrea Trevi&#xf1;o Gavito</a>, 
<a href="/search/cs?searchtype=author&query=Devlin%2C+S">Sam Devlin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Video games have served as useful benchmarks for the decision making
community, but going beyond Atari games towards training agents in modern games
has been prohibitively expensive for the vast majority of the research
community. Recent progress in the research, development and open release of
large vision models has the potential to amortize some of these costs across
the community. However, it is currently unclear which of these models have
learnt representations that retain information critical for sequential decision
making. Towards enabling wider participation in the research of gameplaying
agents in modern games, we present a systematic study of imitation learning
with publicly available visual encoders compared to the typical, task-specific,
end-to-end training approach in Minecraft, Minecraft Dungeons and
Counter-Strike: Global Offensive.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02313" title="Abstract">arXiv:2312.02313</a> [<a href="/pdf/2312.02313" title="Download PDF">pdf</a>, <a href="/format/2312.02313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coverage Explorer: Coverage-guided Test Generation for Cyber Physical  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sheikhi%2C+S">Sanaz Sheikhi</a>, 
<a href="/search/cs?searchtype=author&query=Bak%2C+S">Stanley Bak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Given the safety-critical functions of autonomous cyber-physical systems
(CPS) across diverse domains, testing these systems is essential. While
conventional software and hardware testing methodologies offer partial
insights, they frequently do not provide adequate coverage in a CPS. In this
study, we introduce a testing framework designed to systematically formulate
test cases, effectively exploring the state space of CPS. This framework
introduces a coverage-centric sampling technique, coupled with a cluster-based
methodology for training a surrogate model. The framework then uses model
predictive control within the surrogate model to generates test cases tailored
to CPS specifications. To evaluate the efficacy of the framework, we applied it
on several benchmarks, spanning from a kinematic car to systems like an
unmanned aircraft collision avoidance system (ACAS XU) and automatic
transmission system. Comparative analyses were conducted against alternative
test generation strategies, including randomized testing, as well as
falsification using S-TaLiRo.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02314" title="Abstract">arXiv:2312.02314</a> [<a href="/pdf/2312.02314" title="Download PDF">pdf</a>, <a href="/format/2312.02314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-tuning pre-trained extractive QA models for clinical document  parsing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Ashwyn Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Feldman%2C+D+I">David I. Feldman</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Aneesh Jain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Electronic health records (EHRs) contain a vast amount of high-dimensional
multi-modal data that can accurately represent a patient's medical history.
Unfortunately, most of this data is either unstructured or semi-structured,
rendering it unsuitable for real-time and retrospective analyses. A remote
patient monitoring (RPM) program for Heart Failure (HF) patients needs to have
access to clinical markers like EF (Ejection Fraction) or LVEF (Left
Ventricular Ejection Fraction) in order to ascertain eligibility and
appropriateness for the program. This paper explains a system that can parse
echocardiogram reports and verify EF values. This system helps identify
eligible HF patients who can be enrolled in such a program. At the heart of
this system is a pre-trained extractive QA transformer model that is fine-tuned
on custom-labeled data. The methods used to prepare such a model for deployment
are illustrated by running experiments on a public clinical dataset like
MIMIC-IV-Note. The pipeline can be used to generalize solutions to similar
problems in a low-resource setting. We found that the system saved over 1500
hours for our clinicians over 12 months by automating the task at scale.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02317" title="Abstract">arXiv:2312.02317</a> [<a href="/pdf/2312.02317" title="Download PDF">pdf</a>, <a href="/format/2312.02317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GNN2R: Weakly-Supervised Rationale-Providing Question Answering over  Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Rossetto%2C+L">Luca Rossetto</a>, 
<a href="/search/cs?searchtype=author&query=Cochez%2C+M">Michael Cochez</a>, 
<a href="/search/cs?searchtype=author&query=Bernstein%2C+A">Abraham Bernstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Most current methods for multi-hop question answering (QA) over knowledge
graphs (KGs) only provide final conclusive answers without explanations, such
as a set of KG entities that is difficult for normal users to review and
comprehend. This issue severely limits the application of KG-based QA in
real-world scenarios. However, it is non-trivial to solve due to two
challenges: First, annotations of reasoning chains of multi-hop questions,
which could serve as supervision for explanation generation, are usually
lacking. Second, it is difficult to maintain high efficiency when explicit KG
triples need to be retrieved to generate explanations. In this paper, we
propose a novel Graph Neural Network-based Two-Step Reasoning model (GNN2R) to
solve this issue. GNN2R can provide both final answers and reasoning subgraphs
as a rationale behind final answers efficiently with only weak supervision that
is available through question-final answer pairs. We extensively evaluated
GNN2R with detailed analyses in experiments. The results demonstrate that, in
terms of effectiveness, efficiency, and quality of generated explanations,
GNN2R outperforms existing state-of-the-art methods that are applicable to this
task. Our code and pre-trained models are available at
https://github.com/ruijie-wang-uzh/GNN2R.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02320" title="Abstract">arXiv:2312.02320</a> [<a href="/pdf/2312.02320" title="Download PDF">pdf</a>, <a href="/ps/2312.02320" title="Download PostScript">ps</a>, <a href="/format/2312.02320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cable Slack Detection for Arresting Gear Application using Machine  Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goodman%2C+A">Ari Goodman</a>, 
<a href="/search/cs?searchtype=author&query=Shevach%2C+G">Glenn Shevach</a>, 
<a href="/search/cs?searchtype=author&query=Zabriskie%2C+S">Sean Zabriskie</a>, 
<a href="/search/cs?searchtype=author&query=Thajudeen%2C+D+C">Dr. Chris Thajudeen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 9 figures, Published in the Proceedings of the ASNE 2023 Technology, Systems &amp; Ships Symposium. Reproduced with permission from the American Society of Naval Engineers. NAVAIR Public Release 2023-31 Distribution Statement A - "Approved for public release; distribution is unlimited"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The cable-based arrestment systems are integral to the launch and recovery of
aircraft onboard carriers and on expeditionary land-based installations. These
modern arrestment systems rely on various mechanisms to absorb energy from an
aircraft during an arrestment cycle to bring the aircraft to a full stop. One
of the primary components of this system is the cable interface to the engine.
The formation of slack in the cable at this interface can result in reduced
efficiency and drives maintenance efforts to remove the slack prior to
continued operations. In this paper, a machine vision based slack detection
system is presented. A situational awareness camera is utilized to collect
video data of the cable interface region, machine vision algorithms are applied
to reduce noise, remove background clutter, focus on regions of interest, and
detect changes in the image representative of slack formations. Some algorithms
employed in this system include bilateral image filters, least squares
polynomial fit, Canny Edge Detection, K-Means clustering, Gaussian
Mixture-based Background/Foreground Segmentation for background subtraction,
Hough Circle Transforms, and Hough line Transforms. The resulting detections
are filtered and highlighted to create an indication to the shipboard operator
of the presence of slack and a need for a maintenance action. A user interface
was designed to provide operators with an easy method to redefine regions of
interest and adjust the methods to specific locations. The algorithms were
validated on shipboard footage and were able to accurately identify slack with
minimal false positives.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02327" title="Abstract">arXiv:2312.02327</a> [<a href="/pdf/2312.02327" title="Download PDF">pdf</a>, <a href="/format/2312.02327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FLea: Improving federated learning on scarce and label-skewed data via  privacy-preserving feature augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+T">Tong Xia</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+A">Abhirup Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Mascolo%2C+C">Cecilia Mascolo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Learning a global model by abstracting the knowledge, distributed across
multiple clients, without aggregating the raw data is the primary goal of
Federated Learning (FL). Typically, this works in rounds alternating between
parallel local training at several clients, followed by model aggregation at a
server. We found that existing FL methods under-perform when local datasets are
small and present severe label skew as these lead to over-fitting and local
model bias. This is a realistic setting in many real-world applications. To
address the problem, we propose \textit{FLea}, a unified framework that tackles
over-fitting and local bias by encouraging clients to exchange
privacy-protected features to aid local training. The features refer to
activations from an intermediate layer of the model, which are obfuscated
before being shared with other clients to protect sensitive information in the
data. \textit{FLea} leverages a novel way of combining local and shared
features as augmentations to enhance local model learning. Our extensive
experiments demonstrate that \textit{FLea} outperforms the start-of-the-art FL
methods, sharing only model parameters, by up to $17.6\%$, and FL methods that
share data augmentations by up to $6.3\%$, while reducing the privacy
vulnerability associated with shared data augmentations.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02328" title="Abstract">arXiv:2312.02328</a> [<a href="/pdf/2312.02328" title="Download PDF">pdf</a>, <a href="/format/2312.02328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Modal MPPI and Active Inference for Reactive Task and Motion  Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuezhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pezzato%2C+C">Corrado Pezzato</a>, 
<a href="/search/cs?searchtype=author&query=Trevisan%2C+E">Elia Trevisan</a>, 
<a href="/search/cs?searchtype=author&query=Salmi%2C+C">Chadi Salmi</a>, 
<a href="/search/cs?searchtype=author&query=Corbato%2C+C+H">Carlos Hern&#xe1;ndez Corbato</a>, 
<a href="/search/cs?searchtype=author&query=Alonso-Mora%2C+J">Javier Alonso-Mora</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to RA-L. Experiments' videos are available at <a href="https://sites.google.com/view/m3p2i-aip">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Task and Motion Planning (TAMP) has made strides in complex manipulation
tasks, yet the execution robustness of the planned solutions remains
overlooked. In this work, we propose a method for reactive TAMP to cope with
runtime uncertainties and disturbances. We combine an Active Inference planner
(AIP) for adaptive high-level action selection and a novel Multi-Modal Model
Predictive Path Integral controller (M3P2I) for low-level control. This results
in a scheme that simultaneously adapts both high-level actions and low-level
motions. The AIP generates alternative symbolic plans, each linked to a cost
function for M3P2I. The latter employs a physics simulator for diverse
trajectory rollouts, deriving optimal control by weighing the different samples
according to their cost. This idea enables blending different robot skills for
fluid and reactive plan execution, accommodating plan adjustments at both the
high and low levels to cope, for instance, with dynamic obstacles or
disturbances that invalidate the current plan. We have tested our approach in
simulations and real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02331" title="Abstract">arXiv:2312.02331</a> [<a href="/pdf/2312.02331" title="Download PDF">pdf</a>, <a href="/ps/2312.02331" title="Download PostScript">ps</a>, <a href="/format/2312.02331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Topic-Guided Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Carolina Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Vafa%2C+K">Keyon Vafa</a>, 
<a href="/search/cs?searchtype=author&query=Blei%2C+D+M">David M. Blei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Transactions on Machine Learning Research (TMLR) (12/2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">A recent line of work in natural language processing has aimed to combine
language models and topic models. These topic-guided language models augment
neural language models with topic models, unsupervised learning methods that
can discover document-level patterns of word use. This paper compares the
effectiveness of these methods in a standardized setting. We study four
topic-guided language models and two baselines, evaluating the held-out
predictive performance of each model on four corpora. Surprisingly, we find
that none of these methods outperform a standard LSTM language model baseline,
and most fail to learn good topics. Further, we train a probe of the neural
language model that shows that the baseline's hidden states already encode
topic information. We make public all code used for this study.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02332" title="Abstract">arXiv:2312.02332</a> [<a href="/pdf/2312.02332" title="Download PDF">pdf</a>, <a href="/ps/2312.02332" title="Download PostScript">ps</a>, <a href="/format/2312.02332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Connected Components in Linear Work and Near-Optimal Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farhadi%2C+A">Alireza Farhadi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S+C">S. Cliff Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+E">Elaine Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Computing the connected components of a graph is a fundamental problem in
algorithmic graph theory. A major question in this area is whether we can
compute connected components in $o(\log n)$ parallel time. Recent works showed
an affirmative answer in the Massively Parallel Computation (MPC) model for a
wide class of graphs. Specifically, Behnezhad et al. (FOCS'19) showed that
connected components can be computed in $O(\log d + \log \log n)$ rounds in the
MPC model. More recently, Liu et al. (SPAA'20) showed that the same result can
be achieved in the standard PRAM model but their result incurs $\Theta((m+n)
\cdot (\log d + \log \log n))$ work which is sub-optimal.
<br />In this paper, we show that for graphs that contain \emph{well-connected}
components, we can compute connected components on a PRAM in sub-logarithmic
parallel time with \emph{optimal}, i.e., $O(m+n)$ total work. Specifically, our
algorithm achieves $O(\log(1/\lambda) + \log \log n)$ parallel time with high
probability, where $\lambda$ is the minimum spectral gap of any connected
component in the input graph. The algorithm requires no prior knowledge on
$\lambda$.
<br />Additionally, based on the \textsc{2-Cycle} Conjecture we provide a time
lower bound of $\Omega(\log(1/\lambda))$ for solving connected components on a
PRAM with $O(m+n)$ total memory when $\lambda \le (1/\log n)^c$, giving
conditional optimality to the running time of our algorithm as a parameter of
$\lambda$.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02334" title="Abstract">arXiv:2312.02334</a> [<a href="/pdf/2312.02334" title="Download PDF">pdf</a>, <a href="/format/2312.02334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Evaluation Framework for Mapping News Headlines to Event Classes in a  Knowledge Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mbouadeu%2C+S+F">Steve Fonin Mbouadeu</a>, 
<a href="/search/cs?searchtype=author&query=Lorenzo%2C+M">Martin Lorenzo</a>, 
<a href="/search/cs?searchtype=author&query=Barker%2C+K">Ken Barker</a>, 
<a href="/search/cs?searchtype=author&query=Hassanzadeh%2C+O">Oktie Hassanzadeh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at CASE 2023 @ RANLP <a href="https://aclanthology.org/2023.case-1.6/">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 6th Workshop on Challenges and Applications of
  Automated Extraction of Socio-political Events from Text (CASE 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Mapping ongoing news headlines to event-related classes in a rich knowledge
base can be an important component in a knowledge-based event analysis and
forecasting solution. In this paper, we present a methodology for creating a
benchmark dataset of news headlines mapped to event classes in Wikidata, and
resources for the evaluation of methods that perform the mapping. We use the
dataset to study two classes of unsupervised methods for this task: 1)
adaptations of classic entity linking methods, and 2) methods that treat the
problem as a zero-shot text classification problem. For the first approach, we
evaluate off-the-shelf entity linking systems. For the second approach, we
explore a) pre-trained natural language inference (NLI) models, and b)
pre-trained large generative language models. We present the results of our
evaluation, lessons learned, and directions for future work. The dataset and
scripts for evaluation are made publicly available.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02337" title="Abstract">arXiv:2312.02337</a> [<a href="/pdf/2312.02337" title="Download PDF">pdf</a>, <a href="/format/2312.02337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring Distributional Shifts in Text: The Advantage of Language  Model-Based Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+G">Gyandev Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Rastegarpanah%2C+B">Bashir Rastegarpanah</a>, 
<a href="/search/cs?searchtype=author&query=Iyer%2C+A">Amalendu Iyer</a>, 
<a href="/search/cs?searchtype=author&query=Rubin%2C+J">Joshua Rubin</a>, 
<a href="/search/cs?searchtype=author&query=Kenthapadi%2C+K">Krishnaram Kenthapadi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">An essential part of monitoring machine learning models in production is
measuring input and output data drift. In this paper, we present a system for
measuring distributional shifts in natural language data and highlight and
investigate the potential advantage of using large language models (LLMs) for
this problem. Recent advancements in LLMs and their successful adoption in
different domains indicate their effectiveness in capturing semantic
relationships for solving various natural language processing problems. The
power of LLMs comes largely from the encodings (embeddings) generated in the
hidden layers of the corresponding neural network. First we propose a
clustering-based algorithm for measuring distributional shifts in text data by
exploiting such embeddings. Then we study the effectiveness of our approach
when applied to text embeddings generated by both LLMs and classical embedding
algorithms. Our experiments show that general-purpose LLM-based embeddings
provide a high sensitivity to data drift compared to other embedding methods.
We propose drift sensitivity as an important evaluation metric to consider when
comparing language models. Finally, we present insights and lessons learned
from deploying our framework as part of the Fiddler ML Monitoring platform over
a period of 18 months.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02338" title="Abstract">arXiv:2312.02338</a> [<a href="/pdf/2312.02338" title="Download PDF">pdf</a>, <a href="/format/2312.02338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Contrastive Compositional Benchmark for Text-to-Image Synthesis: A  Study with Unified Text-to-Image Fidelity Metrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiangru Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+P">Penglei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhixu Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yanghua Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jun Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 14 figures, 11 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
<p class="mathjax">Text-to-image (T2I) synthesis has recently achieved significant advancements.
However, challenges remain in the model's compositionality, which is the
ability to create new combinations from known components. We introduce
Winoground-T2I, a benchmark designed to evaluate the compositionality of T2I
models. This benchmark includes 11K complex, high-quality contrastive sentence
pairs spanning 20 categories. These contrastive sentence pairs with subtle
differences enable fine-grained evaluations of T2I synthesis models.
Additionally, to address the inconsistency across different metrics, we propose
a strategy that evaluates the reliability of various metrics by using
comparative sentence pairs. We use Winoground-T2I with a dual objective: to
evaluate the performance of T2I models and the metrics used for their
evaluation. Finally, we provide insights into the strengths and weaknesses of
these metrics and the capabilities of current T2I models in tackling challenges
across a range of complex compositional categories. Our benchmark is publicly
available at https://github.com/zhuxiangru/Winoground-T2I .
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02339" title="Abstract">arXiv:2312.02339</a> [<a href="/pdf/2312.02339" title="Download PDF">pdf</a>, <a href="/format/2312.02339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expressive Sign Equivariant Networks for Spectral Geometric Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lim%2C+D">Derek Lim</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+J">Joshua Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Jegelka%2C+S">Stefanie Jegelka</a>, 
<a href="/search/cs?searchtype=author&query=Maron%2C+H">Haggai Maron</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Spotlight
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Recent work has shown the utility of developing machine learning models that
respect the structure and symmetries of eigenvectors. These works promote sign
invariance, since for any eigenvector v the negation -v is also an eigenvector.
However, we show that sign invariance is theoretically limited for tasks such
as building orthogonally equivariant models and learning node positional
encodings for link prediction in graphs. In this work, we demonstrate the
benefits of sign equivariance for these tasks. To obtain these benefits, we
develop novel sign equivariant neural network architectures. Our models are
based on a new analytic characterization of sign equivariant polynomials and
thus inherit provable expressiveness properties. Controlled synthetic
experiments show that our networks can achieve the theoretically predicted
benefits of sign equivariant models. Code is available at
https://github.com/cptq/Sign-Equivariant-Nets.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02344" title="Abstract">arXiv:2312.02344</a> [<a href="/pdf/2312.02344" title="Download PDF">pdf</a>, <a href="/format/2312.02344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STEREOFOG -- Computational DeFogging via Image-to-Image Translation on a  real-world Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pollak%2C+A">Anton Pollak</a>, 
<a href="/search/cs?searchtype=author&query=Menon%2C+R">Rajesh Menon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures, for associated dataset and Supplement file, see <a href="https://github.com/apoll2000/stereofog">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Image-to-Image translation (I2I) is a subtype of Machine Learning (ML) that
has tremendous potential in applications where two domains of images and the
need for translation between the two exist, such as the removal of fog. For
example, this could be useful for autonomous vehicles, which currently struggle
with adverse weather conditions like fog. However, datasets for I2I tasks are
not abundant and typically hard to acquire. Here, we introduce STEREOFOG, a
dataset comprised of $10,067$ paired fogged and clear images, captured using a
custom-built device, with the purpose of exploring I2I's potential in this
domain. It is the only real-world dataset of this kind to the best of our
knowledge. Furthermore, we apply and optimize the pix2pix I2I ML framework to
this dataset. With the final model achieving an average Complex
Wavelet-Structural Similarity (CW-SSIM) score of $0.76$, we prove the
technique's suitability for the problem.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02345" title="Abstract">arXiv:2312.02345</a> [<a href="/pdf/2312.02345" title="Download PDF">pdf</a>, <a href="/format/2312.02345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIPDrawX: Primitive-based Explanations for Text Guided Sketch Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mathur%2C+N">Nityanand Mathur</a>, 
<a href="/search/cs?searchtype=author&query=Marjit%2C+S">Shyam Marjit</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhuri%2C+A">Abhra Chaudhuri</a>, 
<a href="/search/cs?searchtype=author&query=Dutta%2C+A">Anjan Dutta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the goal of understanding the visual concepts that CLIP associates with
text prompts, we show that the latent space of CLIP can be visualized solely in
terms of linear transformations on simple geometric primitives like circles and
straight lines. Although existing approaches achieve this by
sketch-synthesis-through-optimization, they do so on the space of B\'ezier
curves, which exhibit a wastefully large set of structures that they can evolve
into, as most of them are non-essential for generating meaningful sketches. We
present CLIPDrawX, an algorithm that provides significantly better
visualizations for CLIP text embeddings, using only simple primitive shapes
like straight lines and circles. This constrains the set of possible outputs to
linear transformations on these primitives, thereby exhibiting an inherently
simpler mathematical form. The synthesis process of CLIPDrawX can be tracked
end-to-end, with each visual concept being explained exclusively in terms of
primitives. Implementation will be released upon acceptance. Project Page:
$\href{https://clipdrawx.github.io/}{\text{https://clipdrawx.github.io/}}$.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02348" title="Abstract">arXiv:2312.02348</a> [<a href="/pdf/2312.02348" title="Download PDF">pdf</a>, <a href="/format/2312.02348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UCCA: A Verified Architecture for Compartmentalization of Untrusted Code  Sections in Resource-Constrained Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tyler%2C+L">Liam Tyler</a>, 
<a href="/search/cs?searchtype=author&query=De+Oliveira+Nunes%2C+I">Ivan De Oliveira Nunes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Micro-controller units (MCUs) implement the de facto interface between the
physical and digital worlds. As a consequence, they appear in a variety of
sensing/actuation applications, from smart personal spaces to complex
industrial control systems and safety-critical medical equipment. While many of
these devices perform safety- and time-critical tasks, they often lack support
for security features compatible with their importance to overall system
functions. This lack of architectural support leaves them vulnerable to
run-time attacks that can remotely alter their intended behavior, with
potentially catastrophic consequences. In particular, we note that MCU software
often includes untrusted third-party libraries (some of them closed-source)
that are blindly used within MCU programs, without proper isolation from the
rest of the system. In turn, a single vulnerability (or intentional backdoor)
in one such third-party software can often compromise the entire MCU software
state.
<br />In this paper, we tackle this problem by proposing, demonstrating security,
and formally verifying the implementation of UCCA: an Untrusted Code
Compartment Architecture. UCCA provides flexible hardware-enforced isolation of
untrusted code sections (e.g., third-party software modules) in
resource-constrained and time-critical MCUs. To demonstrate UCCA's
practicality, we implement an open-source version of the design on a real
resource-constrained MCU: the well-known TI MSP430. Our evaluation shows that
UCCA incurs little overhead and is affordable even to lowest-end MCUs,
requiring significantly less overhead and assumptions than prior related work.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02350" title="Abstract">arXiv:2312.02350</a> [<a href="/pdf/2312.02350" title="Download PDF">pdf</a>, <a href="/format/2312.02350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calibrated Uncertainties for Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amini-Naieni%2C+N">Niki Amini-Naieni</a>, 
<a href="/search/cs?searchtype=author&query=Jakab%2C+T">Tomas Jakab</a>, 
<a href="/search/cs?searchtype=author&query=Vedaldi%2C+A">Andrea Vedaldi</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+R">Ronald Clark</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural Radiance Fields have achieved remarkable results for novel view
synthesis but still lack a crucial component: precise measurement of
uncertainty in their predictions. Probabilistic NeRF methods have tried to
address this, but their output probabilities are not typically accurately
calibrated, and therefore do not capture the true confidence levels of the
model. Calibration is a particularly challenging problem in the sparse-view
setting, where additional held-out data is unavailable for fitting a calibrator
that generalizes to the test distribution. In this paper, we introduce the
first method for obtaining calibrated uncertainties from NeRF models. Our
method is based on a robust and efficient metric to calculate per-pixel
uncertainties from the predictive posterior distribution. We propose two
techniques that eliminate the need for held-out data. The first, based on patch
sampling, involves training two NeRF models for each scene. The second is a
novel meta-calibrator that only requires the training of one NeRF model. Our
proposed approach for obtaining calibrated uncertainties achieves
state-of-the-art uncertainty in the sparse-view setting while maintaining image
quality. We further demonstrate our method's effectiveness in applications such
as view enhancement and next-best view selection.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02352" title="Abstract">arXiv:2312.02352</a> [<a href="/pdf/2312.02352" title="Download PDF">pdf</a>, <a href="/format/2312.02352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Working Backwards: Learning to Place by Picking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Limoyo%2C+O">Oliver Limoyo</a>, 
<a href="/search/cs?searchtype=author&query=Konar%2C+A">Abhisek Konar</a>, 
<a href="/search/cs?searchtype=author&query=Ablett%2C+T">Trevor Ablett</a>, 
<a href="/search/cs?searchtype=author&query=Kelly%2C+J">Jonathan Kelly</a>, 
<a href="/search/cs?searchtype=author&query=Hogan%2C+F+R">Francois R. Hogan</a>, 
<a href="/search/cs?searchtype=author&query=Dudek%2C+G">Gregory Dudek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present Learning to Place by Picking (LPP), a method capable of
autonomously collecting demonstrations for a family of placing tasks in which
objects must be manipulated to specific locations. With LPP, we approach the
learning of robotic object placement policies by reversing the grasping process
and exploiting the inherent symmetry of the pick and place problems.
Specifically, we obtain placing demonstrations from a set of grasp sequences of
objects that are initially located at their target placement locations. Our
system is capable of collecting hundreds of demonstrations without human
intervention by using a combination of tactile sensing and compliant control
for grasps. We train a policy directly from visual observations through
behaviour cloning, using the autonomously-collected demonstrations. By doing
so, the policy can generalize to object placement scenarios outside of the
training environment without privileged information (e.g., placing a plate
picked up from a table and not at the original placement location). We validate
our approach on home robotic scenarios that include dishwasher loading and
table setting. Our approach yields robotic placing policies that outperform
policies trained with kinesthetic teaching, both in terms of performance and
data efficiency, while requiring no human supervision.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02353" title="Abstract">arXiv:2312.02353</a> [<a href="/pdf/2312.02353" title="Download PDF">pdf</a>, <a href="/format/2312.02353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient 2D Graph SLAM for Sparse Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hanzhi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zichao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sihang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Samira Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Simultaneous localization and mapping (SLAM) plays a vital role in mapping
unknown spaces and aiding autonomous navigation. Virtually all state-of-the-art
solutions today for 2D SLAM are designed for dense and accurate sensors such as
laser range-finders (LiDARs). However, these sensors are not suitable for
resource-limited nano robots, which become increasingly capable and ubiquitous
nowadays, and these robots tend to mount economical and low-power sensors that
can only provide sparse and noisy measurements. This introduces a challenging
problem called SLAM with sparse sensing. This work addresses the problem by
adopting the form of the state-of-the-art graph-based SLAM pipeline with a
novel frontend and an improvement for loop closing in the backend, both of
which are designed to work with sparse and uncertain range data. Experiments
show that the maps constructed by our algorithm have superior quality compared
to prior works on sparse sensing. Furthermore, our method is capable of running
in real-time on a modern PC with an average processing time of 1/100th the
input interval time.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02355" title="Abstract">arXiv:2312.02355</a> [<a href="/pdf/2312.02355" title="Download PDF">pdf</a>, <a href="/format/2312.02355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When is Offline Policy Selection Sample Efficient for Reinforcement  Learning?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+V">Vincent Liu</a>, 
<a href="/search/cs?searchtype=author&query=Nagarajan%2C+P">Prabhat Nagarajan</a>, 
<a href="/search/cs?searchtype=author&query=Patterson%2C+A">Andrew Patterson</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+M">Martha White</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Offline reinforcement learning algorithms often require careful
hyperparameter tuning. Consequently, before deployment, we need to select
amongst a set of candidate policies. As yet, however, there is little
understanding about the fundamental limits of this offline policy selection
(OPS) problem. In this work we aim to provide clarity on when sample efficient
OPS is possible, primarily by connecting OPS to off-policy policy evaluation
(OPE) and Bellman error (BE) estimation. We first show a hardness result, that
in the worst case, OPS is just as hard as OPE, by proving a reduction of OPE to
OPS. As a result, no OPS method can be more sample efficient than OPE in the
worst case. We then propose a BE method for OPS, called Identifiable BE
Selection (IBES), that has a straightforward method for selecting its own
hyperparameters. We highlight that using IBES for OPS generally has more
requirements than OPE methods, but if satisfied, can be more sample efficient.
We conclude with an empirical study comparing OPE and IBES, and by showing the
difficulty of OPS on an offline Atari benchmark dataset.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02358" title="Abstract">arXiv:2312.02358</a> [<a href="/pdf/2312.02358" title="Download PDF">pdf</a>, <a href="/format/2312.02358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Peer attention enhances student learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Songlin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+D">Dongyin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ru Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Human visual attention is susceptible to social influences. In education,
peer effects impact student learning, but their precise role in modulating
attention remains unclear. Our experiment (N=311) demonstrates that displaying
peer visual attention regions when students watch online course videos enhances
their focus and engagement. However, students retain adaptability in following
peer attention cues. Overall, guided peer attention improves learning
experiences and outcomes. These findings elucidate how peer visual attention
shapes students' gaze patterns, deepening understanding of peer influence on
learning. They also offer insights into designing adaptive online learning
interventions leveraging peer attention modelling to optimize student
attentiveness and success.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02359" title="Abstract">arXiv:2312.02359</a> [<a href="/pdf/2312.02359" title="Download PDF">pdf</a>, <a href="/ps/2312.02359" title="Download PostScript">ps</a>, <a href="/format/2312.02359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quest Complete: the Holy Grail of Gradual Security
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Siek%2C+J+G">Jeremy G. Siek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Languages with gradual information-flow control combine static and dynamic
techniques to prevent security leaks. Gradual languages should satisfy the
gradual guarantee: programs that only differ in the precision of their type
annotations should behave the same modulo cast errors. Unfortunately, Toro et
al. [2018] identify a tension between the gradual guarantee and information
security; they were unable to satisfy both properties in the language
$\mathrm{GSL}_\mathsf{Ref}$ and had to settle for only satisfying
information-flow security. Azevedo de Amorim et al. [2020] show that by
sacrificing type-guided classification, one obtains a language that satisfies
both noninterference and the gradual guarantee. Bichhawat et al. [2021] show
that both properties can be satisfied by sacrificing the no-sensitive-upgrade
mechanism, replacing it with a static analysis.
<br />In this paper we present a language design, $\lambda_{\mathtt{IFC}}^\star$,
that satisfies both noninterference and the gradual guarantee without making
any sacrifices. We keep the type-guided classification of
$\mathrm{GSL}_\mathsf{Ref}$ and use the standard no-sensitive-upgrade mechanism
to prevent implicit flows through mutable references. The key to the design of
$\lambda_{\mathtt{IFC}}^\star$ is to walk back the unusual decision in
$\mathrm{GSL}_\mathsf{Ref}$ to include the unknown label $\star$ among the
runtime security labels. We mechanize the definition of
$\lambda_{\mathtt{IFC}}^\star$ in Agda and prove the gradual guarantee. On the
technical side, the semantics of $\lambda_{\mathtt{IFC}}^\star$ is the first
gradual information-flow control language to be specified using coercion
calculi (a la Henglein), thereby expanding the coercion-based theory of gradual
typing.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02362" title="Abstract">arXiv:2312.02362</a> [<a href="/pdf/2312.02362" title="Download PDF">pdf</a>, <a href="/format/2312.02362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PointNeRF++: A multi-scale, point-based Neural Radiance Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weiwei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Trulls%2C+E">Eduard Trulls</a>, 
<a href="/search/cs?searchtype=author&query=Tseng%2C+Y">Yang-Che Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Sambandam%2C+S">Sneha Sambandam</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+G">Gopal Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Tagliasacchi%2C+A">Andrea Tagliasacchi</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+K+M">Kwang Moo Yi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Point clouds offer an attractive source of information to complement images
in neural scene representations, especially when few images are available.
Neural rendering methods based on point clouds do exist, but they do not
perform well when the point cloud quality is low -- e.g., sparse or incomplete,
which is often the case with real-world data. We overcome these problems with a
simple representation that aggregates point clouds at multiple scale levels
with sparse voxel grids at different resolutions. To deal with point cloud
sparsity, we average across multiple scale levels -- but only among those that
are valid, i.e., that have enough neighboring points in proximity to the ray of
a pixel. To help model areas without points, we add a global voxel at the
coarsest scale, thus unifying "classical" and point-based NeRF formulations. We
validate our method on the NeRF Synthetic, ScanNet, and KITTI-360 datasets,
outperforming the state of the art by a significant margin.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02363" title="Abstract">arXiv:2312.02363</a> [<a href="/pdf/2312.02363" title="Download PDF">pdf</a>, <a href="/ps/2312.02363" title="Download PostScript">ps</a>, <a href="/format/2312.02363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> General Numerical Framework to Derive Structure Preserving Reduced Order  Models for Thermodynamically Consistent Reversible-Irreversible PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+Z">Zengyan Zhang</a>, 
<a href="/search/math?searchtype=author&query=Zhao%2C+J">Jia Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we propose a general numerical framework to derive
structure-preserving reduced order models for thermodynamically consistent
PDEs. Our numerical framework has two primary features: (a) a systematic way to
extract reduced order models for thermodynamically consistent PDE systems while
maintaining their inherent thermodynamic principles and (b) a strategic process
to devise accurate, efficient, and structure-preserving numerical algorithms to
solve the forehead reduced-order models. The platform's generality extends to
various PDE systems governed by embedded thermodynamic laws. The proposed
numerical platform is unique from several perspectives. First, it utilizes the
generalized Onsager principle to transform the thermodynamically consistent PDE
system into an equivalent one, where the transformed system's free energy
adopts a quadratic form of the state variables. This transformation is named
energy quadratization (EQ). Through EQ, we gain a novel perspective on deriving
reduced order models. The reduced order models derived through our method
continue to uphold the energy dissipation law. Secondly, our proposed numerical
approach automatically provides numerical algorithms to discretize the reduced
order models. The proposed algorithms are always linear, easy to implement and
solve, and uniquely solvable. Furthermore, these algorithms inherently ensure
the thermodynamic laws. In essence, our platform offers a distinctive approach
to derive structure-preserving reduced-order models for a wide range of PDE
systems abiding by thermodynamic principles.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02364" title="Abstract">arXiv:2312.02364</a> [<a href="/pdf/2312.02364" title="Download PDF">pdf</a>, <a href="/format/2312.02364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Class-Discriminative Attention Maps for Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brocki%2C+L">Lennart Brocki</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+N+C">Neo Christopher Chung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Interpretability methods are critical components for examining and exploring
deep neural networks (DNN), as well as increasing our understanding of and
trust in them. Vision transformers (ViT), which can be trained to
state-of-the-art performance with a self-supervised learning (SSL) training
method, provide built-in attention maps (AM). While AMs can provide
high-quality semantic segmentation of input images, they do not account for any
signal coming from a downstream classifier. We introduce class-discriminative
attention maps (CDAM), a novel post-hoc explanation method that is highly
sensitive to the target class. Our method essentially scales attention scores
by how relevant the corresponding tokens are for the predictions of a
classifier head. Alternative to classifier outputs, CDAM can also explain a
user-defined concept by targeting similarity measures in the latent space of
the ViT. This allows for explanations of arbitrary concepts, defined by the
user through a few sample images. We investigate the operating characteristics
of CDAM in comparison with relevance propagation (RP) and token ablation maps
(TAM), an alternative to pixel occlusion methods. CDAM is highly
class-discriminative and semantically relevant, while providing implicit
regularization of relevance scores.
<br />PyTorch implementation: \url{https://github.com/lenbrocki/CDAM}
<br />Web live demo: \url{https://cdam.informatism.com/}
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02366" title="Abstract">arXiv:2312.02366</a> [<a href="/pdf/2312.02366" title="Download PDF">pdf</a>, <a href="/format/2312.02366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards General Purpose Vision Foundation Models for Medical Image  Analysis: An Experimental Study of DINOv2 on Radiology Benchmarks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baharoon%2C+M">Mohammed Baharoon</a>, 
<a href="/search/cs?searchtype=author&query=Qureshi%2C+W">Waseem Qureshi</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+J">Jiahong Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yanwu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Phol%2C+K">Kilian Phol</a>, 
<a href="/search/cs?searchtype=author&query=Aljouie%2C+A">Abdulrhman Aljouie</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wei Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The integration of deep learning systems into the medical domain has been
hindered by the resource-intensive process of data annotation and the inability
of these systems to generalize to different data distributions. Foundation
models, which are models pre-trained on large datasets, have emerged as a
solution to reduce reliance on annotated data and enhance model
generalizability and robustness. DINOv2, an open-source foundation model
pre-trained with self-supervised learning on 142 million curated natural
images, excels in extracting general-purpose visual representations, exhibiting
promising capabilities across various vision tasks. Nevertheless, a critical
question remains unanswered regarding DINOv2's adaptability to radiological
imaging, and the clarity on whether its features are sufficiently general to
benefit radiology image analysis is yet to be established. Therefore, this
study comprehensively evaluates DINOv2 for radiology, conducting over 100
experiments across diverse modalities (X-ray, CT, and MRI). Tasks include
disease classification and organ segmentation on both 2D and 3D images,
evaluated under different settings like kNN, few-shot learning, linear-probing,
end-to-end fine-tuning, and parameter-efficient fine-tuning, to measure the
effectiveness and generalizability of the DINOv2 feature embeddings.
Comparative analyses with established medical image analysis models, U-Net and
TransUnet for segmentation, and CNN and ViT models pre-trained via supervised,
weakly supervised, and self-supervised learning for classification, reveal
DINOv2's superior performance in segmentation tasks and competitive results in
disease classification. The findings contribute insights to potential avenues
for optimizing pre-training strategies for medical imaging and enhancing the
broader understanding of DINOv2's role in bridging the gap between natural and
radiological image analysis.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02368" title="Abstract">arXiv:2312.02368</a> [<a href="/pdf/2312.02368" title="Download PDF">pdf</a>, <a href="/format/2312.02368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RINAS: Training with Dataset Shuffling Can Be General and Fast
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+T">Tianle Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiechen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xindi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Q">Qiang Su</a>, 
<a href="/search/cs?searchtype=author&query=Fox%2C+G">Geoffrey Fox</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG); Performance (cs.PF)

</div>
<p class="mathjax">Deep learning datasets are expanding at an unprecedented pace, creating new
challenges for data processing in model training pipelines. A crucial aspect of
these pipelines is dataset shuffling, which significantly improves unbiased
learning and convergence accuracy by adhering to the principles of random
sampling. However, loading shuffled data for large datasets incurs significant
overhead in the deep learning pipeline and severely impacts the end-to-end
training throughput. To mitigate this, current deep learning systems often
resort to partial dataset shuffling, sacrificing global randomness to maintain
acceptable training throughput on large datasets, still leaving global
shuffling efficiency issues not fully explored.
<br />In this work, we present RINAS, a data loading framework that systematically
addresses the performance bottleneck of loading global shuffled datasets. Our
key contribution is to offer an intra-batch unordered data fetching approach,
which unleashes unexplored parallelism of data loading. We implement RINAS
under the PyTorch framework for common dataset libraries HuggingFace and
TorchVision. Our experimental results show that RINAS improves the throughput
of general language model training and vision model training by up to 59% and
89%, respectively.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02376" title="Abstract">arXiv:2312.02376</a> [<a href="/pdf/2312.02376" title="Download PDF">pdf</a>, <a href="/format/2312.02376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Fourier Transform periodic interpolation method for superposition  sums in a periodic unit cell
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ai%2C+F">Fangzhou Ai</a>, 
<a href="/search/math?searchtype=author&query=Lomakin%2C+V">Vitaliy Lomakin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">We propose a Fast Fourier Transform based Periodic Interpolation Method
(FFT-PIM), a flexible and computationally efficient approach for computing the
scalar potential given by a superposition sum in a unit cell of an infinitely
periodic array. Under the same umbrella, FFT-PIM allows computing the potential
for 1D, 2D, and 3D periodicities for dynamic and static problems, including
problems with and without a periodic phase shift. The computational complexity
of the FFT-PIM is of $O(N \log N)$ for $N$ spatially coinciding sources and
observer points. The FFT-PIM uses rapidly converging series representations of
the Green's function serving as a kernel in the superposition sum. Based on
these representations, the FFT-PIM splits the potential into its near-zone
component, which includes a small number of images surrounding the unit cell of
interest, and far-zone component, which includes the rest of an infinite number
of images. The far-zone component is evaluated by projecting the non-uniform
sources onto a sparse uniform grid, performing superposition sums on this
sparse grid, and interpolating the potential from the uniform grid to the
non-uniform observation points. The near-zone component is evaluated using an
FFT-based method, which is adapted to efficiently handle non-uniform
source-observer distributions within the periodic unit cell. The FFT-PIM can be
used for a broad range of applications, such as periodic problems involving
integral equations in computational electromagnetic and acoustic, micromagnetic
solvers, and density functional theory solvers.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02380" title="Abstract">arXiv:2312.02380</a> [<a href="/pdf/2312.02380" title="Download PDF">pdf</a>, <a href="/format/2312.02380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FaultFormer: Transformer-based Prediction of Bearing Faults
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A">Anthony Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Farimani%2C+A+B">Amir Barati Farimani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The growth of deep learning in the past decade has motivated important
applications to smart manufacturing and machine health monitoring. In
particular, vibration data offers a rich and reliable source to provide
meaningful insights into machine health and predictive maintenance. In this
work, we present a Transformer based framework for analyzing vibration signals
to predict different types of bearing faults (FaultFormer). In particular, we
process signal data using data augmentations and extract their Fourier modes to
train a transformer encoder to achieve state of the art accuracies. The
attention mechanism as well as model outputs were analyzed to confirm the
transformer's ability to automatically extract features within signals and
learn both global and local relationships to make classifications. Lastly, two
pretraining strategies were proposed to pave the way for large, generalizable
transformers that could adapt to new data, situations, or machinery on the
production floor.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02382" title="Abstract">arXiv:2312.02382</a> [<a href="/pdf/2312.02382" title="Download PDF">pdf</a>, <a href="/format/2312.02382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Evaluation Metrics Capture Quality Degradation due to LLM  Watermarking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+K">Karanpartap Singh</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">James Zou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With the increasing use of large-language models (LLMs) like ChatGPT,
watermarking has emerged as a promising approach for tracing machine-generated
content. However, research on LLM watermarking often relies on simple
perplexity or diversity-based measures to assess the quality of watermarked
text, which can mask important limitations in watermarking. Here we introduce
two new easy-to-use methods for evaluating watermarking algorithms for LLMs: 1)
evaluation by LLM-judger with specific guidelines; and 2) binary classification
on text embeddings to distinguish between watermarked and unwatermarked text.
We apply these methods to characterize the effectiveness of current
watermarking techniques. Our experiments, conducted across various datasets,
reveal that current watermarking methods are detectable by even simple
classifiers, challenging the notion of watermarking subtlety. We also found,
through the LLM judger, that watermarking impacts text quality, especially in
degrading the coherence and depth of the response. Our findings underscore the
trade-off between watermark robustness and text quality and highlight the
importance of having more informative metrics to assess watermarking quality.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02384" title="Abstract">arXiv:2312.02384</a> [<a href="/pdf/2312.02384" title="Download PDF">pdf</a>, <a href="/format/2312.02384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Akhiezer iteration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ballew%2C+C">Cade Ballew</a>, 
<a href="/search/math?searchtype=author&query=Trogdon%2C+T">Thomas Trogdon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Complex Variables (math.CV)

</div>
<p class="mathjax">We develop the Akhiezer iteration, a generalization of the classical
Chebyshev iteration, for the inner product-free, iterative solution of
indefinite linear systems using orthogonal polynomials for measures supported
on multiple, disjoint intervals. The iteration applies to shifted linear solves
and can then be used for efficient matrix function approximation. Using the
asymptotics of orthogonal polynomials, error bounds are provided. A key
component in the efficiency of the method is the ability to compute the first
$k$ orthogonal polynomial recurrence coefficients and the first $k$ weighted
Stieltjes transforms of these orthogonal polynomials in $\mathrm{O}(k)$
complexity using a numerical Riemann--Hilbert approach. For a special class of
orthogonal polynomials, the Akhiezer polynomials, the method can be sped up
significantly, with the greatest speedup occurring in the two interval case
where important formulae of Akhiezer are employed and the Riemann--Hilbert
approach is bypassed.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02387" title="Abstract">arXiv:2312.02387</a> [<a href="/pdf/2312.02387" title="Download PDF">pdf</a>, <a href="/format/2312.02387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dissecting Medical Referral Mechanisms in Health Services: Role of  Physician Professional Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Brito+Duarte%2C+R">Regina de Brito Duarte</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Q">Qiwei Han</a>, 
<a href="/search/cs?searchtype=author&query=Soares%2C+C">Claudia Soares</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 9 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Medical referrals between primary care physicians (PC) and specialist care
(SC) physicians profoundly impact patient care regarding quality, satisfaction,
and cost. This paper investigates the influence of professional networks among
medical doctors on referring patients from PC to SC. Using five-year
consultation data from a Portuguese private health provider, we conducted
exploratory data analysis and constructed both professional and referral
networks among physicians. We then apply Graph Neural Network (GNN) models to
learn latent representations of the referral network. Our analysis supports the
hypothesis that doctors' professional social connections can predict medical
referrals, potentially enhancing collaboration within organizations and
improving healthcare services. This research contributes to dissecting the
underlying mechanisms in primary-specialty referrals, thereby providing
valuable insights for enhancing patient care and effective healthcare
management.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02390" title="Abstract">arXiv:2312.02390</a> [<a href="/pdf/2312.02390" title="Download PDF">pdf</a>, <a href="/format/2312.02390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Robots&#x27; Facial Emotional Expressions on Light Physical  Exercises
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdulazeem%2C+N">Nourhan Abdulazeem</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yue Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">To address the global challenge of population aging, our goal is to enhance
successful aging through the introduction of robots capable of assisting in
daily physical activities and promoting light exercises, which would enhance
the cognitive and physical well-being of older adults. Previous studies have
shown that facial expressions can increase engagement when interacting with
robots. This study aims to investigate how older adults perceive and interact
with a robot capable of displaying facial emotions while performing a physical
exercise task together. We employed a collaborative robotic arm with a flat
panel screen to encourage physical exercise across three different facial
emotion conditions. We ran the experiment with older adults aged between 66 and
88. Our findings suggest that individuals perceive robots exhibiting facial
expressions as less competent than those without such expressions.
Additionally, the presence of facial expressions does not appear to
significantly impact participants' levels of engagement, unlike other
state-of-the-art studies. This observation is likely linked to our study's
emphasis on collaborative physical human-robot interaction (pHRI) applications,
as opposed to socially oriented pHRI applications. Additionally, we foresee a
requirement for more suitable non-verbal social behavior to effectively enhance
participants' engagement levels.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02392" title="Abstract">arXiv:2312.02392</a> [<a href="/pdf/2312.02392" title="Download PDF">pdf</a>, <a href="/format/2312.02392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instance Space Analysis of Search-Based Software Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neelofar%2C+N">Neelofar Neelofar</a>, 
<a href="/search/cs?searchtype=author&query=Smith-Miles%2C+K">Kate Smith-Miles</a>, 
<a href="/search/cs?searchtype=author&query=Munoz%2C+M+A">Mario Andres Munoz</a>, 
<a href="/search/cs?searchtype=author&query=Aleti%2C+A">Aldeida Aleti</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Software Engineering, 49(4), 2642-2660 (2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Search-based software testing (SBST) is now a mature area, with numerous
techniques developed to tackle the challenging task of software testing. SBST
techniques have shown promising results and have been successfully applied in
the industry to automatically generate test cases for large and complex
software systems. Their effectiveness, however, is problem-dependent. In this
paper, we revisit the problem of objective performance evaluation of SBST
techniques considering recent methodological advances -- in the form of
Instance Space Analysis (ISA) -- enabling the strengths and weaknesses of SBST
techniques to be visualized and assessed across the broadest possible space of
problem instances (software classes) from common benchmark datasets. We
identify features of SBST problems that explain why a particular instance is
hard for an SBST technique, reveal areas of hard and easy problems in the
instance space of existing benchmark datasets, and identify the strengths and
weaknesses of state-of-the-art SBST techniques. In addition, we examine the
diversity and quality of common benchmark datasets used in experimental
evaluations.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02393" title="Abstract">arXiv:2312.02393</a> [<a href="/pdf/2312.02393" title="Download PDF">pdf</a>, <a href="/format/2312.02393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lecture Notes on Computerized Tomography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Beckmann%2C+M">Matthias Beckmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Lecture notes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">These lecture notes give an introduction to the mathematics of computer(ized)
tomography (CT). Treated are the imaging principle of X-ray tomography, the
Radon transform as mathematical model for the measurement process and its
properties, the ill-posedness of the underlying mathematical reconstruction
problem and classical reconstruction techniques. The required background from
Fourier analysis is also briefly summarized.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02396" title="Abstract">arXiv:2312.02396</a> [<a href="/pdf/2312.02396" title="Download PDF">pdf</a>, <a href="/format/2312.02396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Change Detection for Space Habitats Using 3D Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santos%2C+J">Jamie Santos</a>, 
<a href="/search/cs?searchtype=author&query=Dinkel%2C+H">Holly Dinkel</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+J">Julia Di</a>, 
<a href="/search/cs?searchtype=author&query=Borges%2C+P+V+K">Paulo V.K. Borges</a>, 
<a href="/search/cs?searchtype=author&query=Moreira%2C+M">Marina Moreira</a>, 
<a href="/search/cs?searchtype=author&query=Alexandrov%2C+O">Oleg Alexandrov</a>, 
<a href="/search/cs?searchtype=author&query=Coltin%2C+B">Brian Coltin</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+T">Trey Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures, Manuscript will be presented at the AIAA SciTech Forum in Orlando, FL, USA, 8 - 12 January 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">This work presents an algorithm for scene change detection from point clouds
to enable autonomous robotic caretaking in future space habitats. Autonomous
robotic systems will help maintain future deep-space habitats, such as the
Gateway space station, which will be uncrewed for extended periods. Existing
scene analysis software used on the International Space Station (ISS) relies on
manually-labeled images for detecting changes. In contrast, the algorithm
presented in this work uses raw, unlabeled point clouds as inputs. The
algorithm first applies modified Expectation-Maximization Gaussian Mixture
Model (GMM) clustering to two input point clouds. It then performs change
detection by comparing the GMMs using the Earth Mover's Distance. The algorithm
is validated quantitatively and qualitatively using a test dataset collected by
an Astrobee robot in the NASA Ames Granite Lab comprising single frame depth
images taken directly by Astrobee and full-scene reconstructed maps built with
RGB-D and pose data from Astrobee. The runtimes of the approach are also
analyzed in depth. The source code is publicly released to promote further
development.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02400" title="Abstract">arXiv:2312.02400</a> [<a href="/pdf/2312.02400" title="Download PDF">pdf</a>, <a href="/format/2312.02400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auto DP-SGD: Dual Improvements of Privacy and Accuracy via Automatic  Clipping Threshold and Noise Multiplier Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chilukoti%2C+S+V">Sai Venkatesh Chilukoti</a>, 
<a href="/search/cs?searchtype=author&query=Hossen%2C+M+I">Md Imran Hossen</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+L">Liqun Shan</a>, 
<a href="/search/cs?searchtype=author&query=Tida%2C+V+S">Vijay Srinivas Tida</a>, 
<a href="/search/cs?searchtype=author&query=Hei%2C+X">Xiai Hei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages single column, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">DP-SGD has emerged as a popular method to protect personally identifiable
information in deep learning applications. Unfortunately, DP-SGD's per-sample
gradient clipping and uniform noise addition during training can significantly
degrade model utility. To enhance the model's utility, researchers proposed
various adaptive DP-SGD methods. However, we examine and discover that these
techniques result in greater privacy leakage or lower accuracy than the
traditional DP-SGD method, or a lack of evaluation on a complex data set such
as CIFAR100. To address these limitations, we propose an Auto DP-SGD. Our
method automates clipping threshold estimation based on the DL model's gradient
norm and scales the gradients of each training sample without losing gradient
information. This helps to improve the algorithm's utility while using a less
privacy budget. To further improve accuracy, we introduce automatic noise
multiplier decay mechanisms to decrease the noise multiplier after every epoch.
Finally, we develop closed-form mathematical expressions using tCDP accountant
for automatic noise multiplier and automatic clipping threshold estimation.
Through extensive experimentation, we demonstrate that Auto DP-SGD outperforms
existing SOTA DP-SGD methods in privacy and accuracy on various benchmark
datasets. We also show that privacy can be improved by lowering the scale
factor and using learning rate schedulers without significantly reducing
accuracy. Specifically, Auto DP-SGD, when used with a step noise multiplier,
improves accuracy by 3.20, 1.57, 6.73, and 1.42 for the MNIST, CIFAR10,
CIFAR100, and AG News Corpus datasets, respectively. Furthermore, it obtains a
substantial reduction in the privacy budget of 94.9, 79.16, 67.36, and 53.37
for the corresponding data sets.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02403" title="Abstract">arXiv:2312.02403</a> [<a href="/pdf/2312.02403" title="Download PDF">pdf</a>, <a href="/format/2312.02403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Neural Operator Enabled Concurrent Multitask Design for  Multifunctional Metamaterials under Heterogeneous Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Doksoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Multifunctional metamaterials (MMM) bear promise as next-generation material
platforms supporting miniaturization and customization. Despite many
proof-of-concept demonstrations and the proliferation of deep learning assisted
design, grand challenges of inverse design for MMM, especially those involving
heterogeneous fields possibly subject to either mutual meta-atom coupling or
long-range interactions, remain largely under-explored. To this end, we present
a data-driven design framework, which streamlines the inverse design of MMMs
involving heterogeneous fields. A core enabler is implicit Fourier neural
operator (IFNO), which predicts heterogeneous fields distributed across a
metamaterial array, thus in general at odds with homogenization assumptions, in
a parameter-/sample-efficient fashion. Additionally, we propose a standard
formulation of inverse problem covering a broad class of MMMs, and
gradient-based multitask concurrent optimization identifying a set of
Pareto-optimal architecture-stimulus (A-S) pairs. Fourier multiclass blending
is proposed to synthesize inter-class meta-atoms anchored on a set of geometric
motifs, while enjoying training-free dimension reduction and built-it
reconstruction. Interlocking the three pillars, the framework is validated for
light-bylight programmable plasmonic nanoantenna, whose design involves vast
space jointly spanned by quasi-freeform supercells, maneuverable incident phase
distributions, and conflicting figure-of-merits involving on-demand
localization patterns. Accommodating all the challenges without a-priori
simplifications, our framework could propel future advancements of MMM.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02405" title="Abstract">arXiv:2312.02405</a> [<a href="/pdf/2312.02405" title="Download PDF">pdf</a>, <a href="/format/2312.02405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BEDD: The MineRL BASALT Evaluation and Demonstrations Dataset for  Training and Benchmarking Agents that Solve Fuzzy Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Milani%2C+S">Stephanie Milani</a>, 
<a href="/search/cs?searchtype=author&query=Kanervisto%2C+A">Anssi Kanervisto</a>, 
<a href="/search/cs?searchtype=author&query=Ramanauskas%2C+K">Karolis Ramanauskas</a>, 
<a href="/search/cs?searchtype=author&query=Schulhoff%2C+S">Sander Schulhoff</a>, 
<a href="/search/cs?searchtype=author&query=Houghton%2C+B">Brandon Houghton</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+R">Rohin Shah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Datasets and Benchmarks Oral. Dataset links are available on Github: <a href="https://github.com/minerllabs/basalt-benchmark">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The MineRL BASALT competition has served to catalyze advances in learning
from human feedback through four hard-to-specify tasks in Minecraft, such as
create and photograph a waterfall. Given the completion of two years of BASALT
competitions, we offer to the community a formalized benchmark through the
BASALT Evaluation and Demonstrations Dataset (BEDD), which serves as a resource
for algorithm development and performance assessment. BEDD consists of a
collection of 26 million image-action pairs from nearly 14,000 videos of human
players completing the BASALT tasks in Minecraft. It also includes over 3,000
dense pairwise human evaluations of human and algorithmic agents. These
comparisons serve as a fixed, preliminary leaderboard for evaluating
newly-developed algorithms. To enable this comparison, we present a streamlined
codebase for benchmarking new algorithms against the leaderboard. In addition
to presenting these datasets, we conduct a detailed analysis of the data from
both datasets to guide algorithm development and evaluation. The released code
and data are available at https://github.com/minerllabs/basalt-benchmark .
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02406" title="Abstract">arXiv:2312.02406</a> [<a href="/pdf/2312.02406" title="Download PDF">pdf</a>, <a href="/format/2312.02406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Online Data Mixing For Language Model Pre-Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Albalak%2C+A">Alon Albalak</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Liangming Pan</a>, 
<a href="/search/cs?searchtype=author&query=Raffel%2C+C">Colin Raffel</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W+Y">William Yang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The data used to pretrain large language models has a decisive impact on a
model's downstream performance, which has led to a large body of work on data
selection methods that aim to automatically determine the most suitable data to
use for pretraining. Existing data selection methods suffer from slow and
computationally expensive processes, a problem amplified by the increasing size
of models and of pretraining datasets. Data mixing, on the other hand, reduces
the complexity of data selection by grouping data points together and
determining sampling probabilities across entire groups. However, data mixing
proportions are typically fixed before training and therefore cannot adapt to
changing training dynamics. To address these limitations, we develop an
efficient algorithm for Online Data Mixing (ODM) that combines elements from
both data selection and data mixing. Based on multi-armed bandit algorithms,
our online approach optimizes the data mixing proportions during training.
Remarkably, our method trains a model that reaches the final perplexity of the
next best method with 19\% fewer training iterations, and improves performance
on the 5-shot MMLU benchmark by 1.9% relative accuracy, while adding negligible
wall-clock time during pretraining.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02407" title="Abstract">arXiv:2312.02407</a> [<a href="/pdf/2312.02407" title="Download PDF">pdf</a>, <a href="/format/2312.02407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Clustering using Hyperdimensional Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+L">Lulu Ge</a>, 
<a href="/search/cs?searchtype=author&query=Parhi%2C+K+K">Keshab K. Parhi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Databases (cs.DB); Symbolic Computation (cs.SC)

</div>
<p class="mathjax">This paper addresses the clustering of data in the hyperdimensional computing
(HDC) domain. In prior work, an HDC-based clustering framework, referred to as
HDCluster, has been proposed. However, the performance of the existing
HDCluster is not robust. The performance of HDCluster is degraded as the
hypervectors for the clusters are chosen at random during the initialization
step. To overcome this bottleneck, we assign the initial cluster hypervectors
by exploring the similarity of the encoded data, referred to as \textit{query}
hypervectors. Intra-cluster hypervectors have a higher similarity than
inter-cluster hypervectors. Harnessing the similarity results among query
hypervectors, this paper proposes four HDC-based clustering algorithms:
similarity-based k-means, equal bin-width histogram, equal bin-height
histogram, and similarity-based affinity propagation. Experimental results
illustrate that: (i) Compared to the existing HDCluster, our proposed HDC-based
clustering algorithms can achieve better accuracy, more robust performance,
fewer iterations, and less execution time. Similarity-based affinity
propagation outperforms the other three HDC-based clustering algorithms on
eight datasets by 2~38% in clustering accuracy. (ii) Even for one-pass
clustering, i.e., without any iterative update of the cluster hypervectors, our
proposed algorithms can provide more robust clustering accuracy than HDCluster.
(iii) Over eight datasets, five out of eight can achieve higher or comparable
accuracy when projected onto the hyperdimensional space. Traditional clustering
is more desirable than HDC when the number of clusters, $k$, is large.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02409" title="Abstract">arXiv:2312.02409</a> [<a href="/pdf/2312.02409" title="Download PDF">pdf</a>, <a href="/format/2312.02409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MGTR: Multi-Granular Transformer for Motion Prediction with LiDAR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gan%2C+Y">Yiqian Gan</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+H">Hao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yizhe Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Ethan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhe Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xin Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+L">Lingting Ge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Motion prediction has been an essential component of autonomous driving
systems since it handles highly uncertain and complex scenarios involving
moving agents of different types. In this paper, we propose a Multi-Granular
TRansformer (MGTR) framework, an encoder-decoder network that exploits context
features in different granularities for different kinds of traffic agents. To
further enhance MGTR's capabilities, we leverage LiDAR point cloud data by
incorporating LiDAR semantic features from an off-the-shelf LiDAR feature
extractor. We evaluate MGTR on Waymo Open Dataset motion prediction benchmark
and show that the proposed method achieved state-of-the-art performance,
ranking 1st on its leaderboard
(https://waymo.com/open/challenges/2023/motion-prediction/).
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02412" title="Abstract">arXiv:2312.02412</a> [<a href="/pdf/2312.02412" title="Download PDF">pdf</a>, <a href="/ps/2312.02412" title="Download PostScript">ps</a>, <a href="/format/2312.02412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Turing Incomputable Coloring Function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fiske%2C+M+S">Michael Stephen Fiske</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Logic in Computer Science (cs.LO); Combinatorics (math.CO); Logic (math.LO)

</div>
<p class="mathjax">This paper describes a sequence of natural numbers that grows faster than any
Turing computable function. This sequence is generated from a version of the
tiling problem, called a coloring system. In our proof that generates the
sequence, we use the notions of a chain and an unbounded sequence property,
which resemble the methods of point set topology. From this sequence, we define
a Turing incomputable coloring function.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02415" title="Abstract">arXiv:2312.02415</a> [<a href="/pdf/2312.02415" title="Download PDF">pdf</a>, <a href="/format/2312.02415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Almost Exact Recovery in Gossip Opinion Dynamics over Stochastic Block  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xing%2C+Y">Yu Xing</a>, 
<a href="/search/eess?searchtype=author&query=Johansson%2C+K+H">Karl H. Johansson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">We study community detection based on state observations from gossip opinion
dynamics over stochastic block models (SBM). It is assumed that a network is
generated from a two-community SBM where each agent has a community label and
each edge exists with probability depending on its endpoints' labels. A gossip
process then evolves over the sampled network. We propose two algorithms to
detect the communities out of a single trajectory of the process. It is shown
that, when the influence of stubborn agents is small and the link probability
within communities is large, an algorithm based on clustering transient agent
states can achieve almost exact recovery of the communities. That is, the
algorithm can recover all but a vanishing part of community labels with high
probability. In contrast, when the influence of stubborn agents is large,
another algorithm based on clustering time average of agent states can achieve
almost exact recovery. Numerical experiments are given for illustration of the
two algorithms and the theoretical results of the paper.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02416" title="Abstract">arXiv:2312.02416</a> [<a href="/pdf/2312.02416" title="Download PDF">pdf</a>, <a href="/format/2312.02416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Fast and Stable Federated Learning: Confronting Heterogeneity  via Knowledge Anchor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinqian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jihua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Q">Qinghai Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in ACM MM23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Federated learning encounters a critical challenge of data heterogeneity,
adversely affecting the performance and convergence of the federated model.
Various approaches have been proposed to address this issue, yet their
effectiveness is still limited. Recent studies have revealed that the federated
model suffers severe forgetting in local training, leading to global forgetting
and performance degradation. Although the analysis provides valuable insights,
a comprehensive understanding of the vulnerable classes and their impact
factors is yet to be established. In this paper, we aim to bridge this gap by
systematically analyzing the forgetting degree of each class during local
training across different communication rounds. Our observations are: (1) Both
missing and non-dominant classes suffer similar severe forgetting during local
training, while dominant classes show improvement in performance. (2) When
dynamically reducing the sample size of a dominant class, catastrophic
forgetting occurs abruptly when the proportion of its samples is below a
certain threshold, indicating that the local model struggles to leverage a few
samples of a specific class effectively to prevent forgetting. Motivated by
these findings, we propose a novel and straightforward algorithm called
Federated Knowledge Anchor (FedKA). Assuming that all clients have a single
shared sample for each class, the knowledge anchor is constructed before each
local training stage by extracting shared samples for missing classes and
randomly selecting one sample per class for non-dominant classes. The knowledge
anchor is then utilized to correct the gradient of each mini-batch towards the
direction of preserving the knowledge of the missing and non-dominant classes.
Extensive experimental results demonstrate that our proposed FedKA achieves
fast and stable convergence, significantly improving accuracy on popular
benchmarks.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02418" title="Abstract">arXiv:2312.02418</a> [<a href="/pdf/2312.02418" title="Download PDF">pdf</a>, <a href="/format/2312.02418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoding Data Quality via Synthetic Corruptions: Embedding-guided  Pruning of Code Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A+K">Aaditya K. Singh</a>, 
<a href="/search/cs?searchtype=author&query=Elhoushi%2C+M">Mostafa Elhoushi</a>, 
<a href="/search/cs?searchtype=author&query=Mahmoud%2C+A">Anas Mahmoud</a>, 
<a href="/search/cs?searchtype=author&query=Tirumala%2C+K">Kushal Tirumala</a>, 
<a href="/search/cs?searchtype=author&query=Gloeckle%2C+F">Fabian Gloeckle</a>, 
<a href="/search/cs?searchtype=author&query=Rozi%C3%A8re%2C+B">Baptiste Rozi&#xe8;re</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Carole-Jean Wu</a>, 
<a href="/search/cs?searchtype=author&query=Morcos%2C+A+S">Ari S. Morcos</a>, 
<a href="/search/cs?searchtype=author&query=Ardalani%2C+N">Newsha Ardalani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures, Oral Presentation at 3rd Workshop on Efficient Natural Language and Speech Processing (ENLSP-III), NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Code datasets, often collected from diverse and uncontrolled sources such as
GitHub, potentially suffer from quality issues, thereby affecting the
performance and training efficiency of Large Language Models (LLMs) optimized
for code generation. Previous studies demonstrated the benefit of using
embedding spaces for data pruning, but they mainly focused on duplicate removal
or increasing variety, and in other modalities, such as images. Our work
focuses on using embeddings to identify and remove "low-quality" code data.
First, we explore features of "low-quality" code in embedding space, through
the use of synthetic corruptions. Armed with this knowledge, we devise novel
pruning metrics that operate in embedding space to identify and remove
low-quality entries in the Stack dataset. We demonstrate the benefits of this
synthetic corruption informed pruning (SCIP) approach on the well-established
HumanEval and MBPP benchmarks, outperforming existing embedding-based methods.
Importantly, we achieve up to a 3% performance improvement over no pruning,
thereby showing the promise of insights from synthetic corruptions for data
pruning.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02419" title="Abstract">arXiv:2312.02419</a> [<a href="/pdf/2312.02419" title="Download PDF">pdf</a>, <a href="/format/2312.02419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Demonstrations are Generalizable Knowledge for Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guangyan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+T">Te Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianxing Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zicai Peng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+M">Mengxiao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Meiling Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yufeng Yue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Learning from human demonstrations is an emerging trend for designing
intelligent robotic systems. However, previous methods typically regard videos
as instructions, simply dividing them into action sequences for robotic
repetition, which poses obstacles to generalization to diverse tasks or object
instances. In this paper, we propose a different perspective, considering human
demonstration videos not as mere instructions, but as a source of knowledge for
robots. Motivated by this perspective and the remarkable comprehension and
generalization capabilities exhibited by large language models (LLMs), we
propose DigKnow, a method that DIstills Generalizable KNOWledge with a
hierarchical structure. Specifically, DigKnow begins by converting human
demonstration video frames into observation knowledge. This knowledge is then
subjected to analysis to extract human action knowledge and further distilled
into pattern knowledge compassing task and object instances, resulting in the
acquisition of generalizable knowledge with a hierarchical structure. In
settings with different tasks or object instances, DigKnow retrieves relevant
knowledge for the current task and object instances. Subsequently, the
LLM-based planner conducts planning based on the retrieved knowledge, and the
policy executes actions in line with the plan to achieve the designated task.
Utilizing the retrieved knowledge, we validate and rectify planning and
execution outcomes, resulting in a substantial enhancement of the success rate.
Experimental results across a range of tasks and scenes demonstrate the
effectiveness of this approach in facilitating real-world robots to accomplish
tasks with the knowledge derived from human demonstrations.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02420" title="Abstract">arXiv:2312.02420</a> [<a href="/pdf/2312.02420" title="Download PDF">pdf</a>, <a href="/format/2312.02420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Granularity-adjusted Pixel-level Semantic Annotation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kundu%2C+R">Rohit Kundu</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+S">Sudipta Paul</a>, 
<a href="/search/cs?searchtype=author&query=Lal%2C+R">Rohit Lal</a>, 
<a href="/search/cs?searchtype=author&query=Roy-Chowdhury%2C+A+K">Amit K. Roy-Chowdhury</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advancements in computer vision predominantly rely on learning-based
systems, leveraging annotations as the driving force to develop specialized
models. However, annotating pixel-level information, particularly in semantic
segmentation, presents a challenging and labor-intensive task, prompting the
need for autonomous processes. In this work, we propose GranSAM which
distinguishes itself by providing semantic segmentation at the user-defined
granularity level on unlabeled data without the need for any manual
supervision, offering a unique contribution in the realm of semantic mask
annotation method. Specifically, we propose an approach to enable the Segment
Anything Model (SAM) with semantic recognition capability to generate
pixel-level annotations for images without any manual supervision. For this, we
accumulate semantic information from synthetic images generated by the Stable
Diffusion model or web crawled images and employ this data to learn a mapping
function between SAM mask embeddings and object class labels. As a result, SAM,
enabled with granularity-adjusted mask recognition, can be used for pixel-level
semantic annotation purposes. We conducted experiments on the PASCAL VOC 2012
and COCO-80 datasets and observed a +17.95% and +5.17% increase in mIoU,
respectively, compared to existing state-of-the-art methods when evaluated
under our problem setting.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02424" title="Abstract">arXiv:2312.02424</a> [<a href="/pdf/2312.02424" title="Download PDF">pdf</a>, <a href="/format/2312.02424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GNSS Odometry: Precise Trajectory Estimation Based on Carrier Phase  Cycle Slip Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+T">Taro Suzuki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in IEEE Robotics and Automation Letters (RA-L) and presented at the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2022
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters (RA-L), vol. 7, no. 3, pp.
  7319-7326, July 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper proposes a highly accurate trajectory estimation method for
outdoor mobile robots using global navigation satellite system (GNSS) time
differences of carrier phase (TDCP) measurements. By using GNSS TDCP, the
relative 3D position can be estimated with millimeter precision. However, when
a phenomenon called cycle slip occurs, wherein the carrier phase measurement
jumps and becomes discontinuous, it is impossible to accurately estimate the
relative position using TDCP. Although previous studies have eliminated the
effect of cycle slip using a robust optimization technique, it was difficult to
completely eliminate the effect of outliers. In this paper, we propose a method
to detect GNSS carrier phase cycle slip, estimate the amount of cycle slip, and
modify the observed TDCP to calculate the relative position using the factor
graph optimization framework. The estimated relative position acts as a loop
closure in graph optimization and contributes to the reduction in the
integration error of the relative position. Experiments with an unmanned aerial
vehicle showed that by modifying the cycle slip using the proposed method, the
vehicle trajectory could be estimated with an accuracy of 5 to 30 cm using only
a single GNSS receiver, without using any other external data or sensors.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02428" title="Abstract">arXiv:2312.02428</a> [<a href="/pdf/2312.02428" title="Download PDF">pdf</a>, <a href="/format/2312.02428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FreestyleRet: Retrieving Images from Style-Diversified Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+C">Curise Jia</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+P">Peng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zesen Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kehan Li</a>, 
<a href="/search/cs?searchtype=author&query=Sui%2C+J">Jialu Sui</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Li Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Image Retrieval aims to retrieve corresponding images based on a given query.
In application scenarios, users intend to express their retrieval intent
through various query styles. However, current retrieval tasks predominantly
focus on text-query retrieval exploration, leading to limited retrieval query
options and potential ambiguity or bias in user intention. In this paper, we
propose the Style-Diversified Query-Based Image Retrieval task, which enables
retrieval based on various query styles. To facilitate the novel setting, we
propose the first Diverse-Style Retrieval dataset, encompassing diverse query
styles including text, sketch, low-resolution, and art. We also propose a
light-weighted style-diversified retrieval framework. For various query style
inputs, we apply the Gram Matrix to extract the query's textural features and
cluster them into a style space with style-specific bases. Then we employ the
style-init prompt tuning module to enable the visual encoder to comprehend the
texture and style information of the query. Experiments demonstrate that our
model, employing the style-init prompt tuning strategy, outperforms existing
retrieval models on the style-diversified retrieval task. Moreover,
style-diversified queries~(sketch+text, art+text, etc) can be simultaneously
retrieved in our model. The auxiliary information from other queries enhances
the retrieval performance within the respective query.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02429" title="Abstract">arXiv:2312.02429</a> [<a href="/pdf/2312.02429" title="Download PDF">pdf</a>, <a href="/format/2312.02429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PEFA: Parameter-Free Adapters for Large-scale Embedding-based Retrieval  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+W">Wei-Cheng Chang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jyun-Yu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Al-Darabsah%2C+M">Mutasem Al-Darabsah</a>, 
<a href="/search/cs?searchtype=author&query=Teo%2C+C+H">Choon Hui Teo</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+C">Cho-Jui Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hsiang-Fu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Vishwanathan%2C+S+V+N">S.V.N. Vishwanathan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accept by WSDM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Embedding-based Retrieval Models (ERMs) have emerged as a promising framework
for large-scale text retrieval problems due to powerful large language models.
Nevertheless, fine-tuning ERMs to reach state-of-the-art results can be
expensive due to the extreme scale of data as well as the complexity of
multi-stages pipelines (e.g., pre-training, fine-tuning, distillation). In this
work, we propose the PEFA framework, namely ParamEter-Free Adapters, for fast
tuning of ERMs without any backward pass in the optimization. At index building
stage, PEFA equips the ERM with a non-parametric k-nearest neighbor (kNN)
component. At inference stage, PEFA performs a convex combination of two
scoring functions, one from the ERM and the other from the kNN. Based on the
neighborhood definition, PEFA framework induces two realizations, namely
PEFA-XL (i.e., extra large) using double ANN indices and PEFA-XS (i.e., extra
small) using a single ANN index. Empirically, PEFA achieves significant
improvement on two retrieval applications. For document retrieval, regarding
Recall@100 metric, PEFA improves not only pre-trained ERMs on Trivia-QA by an
average of 13.2%, but also fine-tuned ERMs on NQ-320K by an average of 5.5%,
respectively. For product search, PEFA improves the Recall@100 of the
fine-tuned ERMs by an average of 5.3% and 14.5%, for PEFA-XS and PEFA-XL,
respectively. Our code is available at https://github.com/
amzn/pecos/tree/mainline/examples/pefa-wsdm24
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02431" title="Abstract">arXiv:2312.02431</a> [<a href="/pdf/2312.02431" title="Download PDF">pdf</a>, <a href="/format/2312.02431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visually Grounded Language Learning: a review of language games,  datasets, tasks, and models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suglia%2C+A">Alessandro Suglia</a>, 
<a href="/search/cs?searchtype=author&query=Konstas%2C+I">Ioannis Konstas</a>, 
<a href="/search/cs?searchtype=author&query=Lemon%2C+O">Oliver Lemon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint for JAIR before copyediting
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In recent years, several machine learning models have been proposed. They are
trained with a language modelling objective on large-scale text-only data. With
such pretraining, they can achieve impressive results on many Natural Language
Understanding and Generation tasks. However, many facets of meaning cannot be
learned by ``listening to the radio" only. In the literature, many
Vision+Language (V+L) tasks have been defined with the aim of creating models
that can ground symbols in the visual modality. In this work, we provide a
systematic literature review of several tasks and models proposed in the V+L
field. We rely on Wittgenstein's idea of `language games' to categorise such
tasks into 3 different families: 1) discriminative games, 2) generative games,
and 3) interactive games. Our analysis of the literature provides evidence that
future work should be focusing on interactive games where communication in
Natural Language is important to resolve ambiguities about object referents and
action plans and that physical embodiment is essential to understand the
semantics of situations and events. Overall, these represent key requirements
for developing grounded meanings in neural models.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02432" title="Abstract">arXiv:2312.02432</a> [<a href="/pdf/2312.02432" title="Download PDF">pdf</a>, <a href="/format/2312.02432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orthogonal Adaptation for Modular Customization of Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Po%2C+R">Ryan Po</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guandao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Aberman%2C+K">Kfir Aberman</a>, 
<a href="/search/cs?searchtype=author&query=Wetzstein%2C+G">Gordon Wetzstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://ryanpo.com/ortha/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Customization techniques for text-to-image models have paved the way for a
wide range of previously unattainable applications, enabling the generation of
specific concepts across diverse contexts and styles. While existing methods
facilitate high-fidelity customization for individual concepts or a limited,
pre-defined set of them, they fall short of achieving scalability, where a
single model can seamlessly render countless concepts. In this paper, we
address a new problem called Modular Customization, with the goal of
efficiently merging customized models that were fine-tuned independently for
individual concepts. This allows the merged model to jointly synthesize
concepts in one image without compromising fidelity or incurring any additional
computational costs.
<br />To address this problem, we introduce Orthogonal Adaptation, a method
designed to encourage the customized models, which do not have access to each
other during fine-tuning, to have orthogonal residual weights. This ensures
that during inference time, the customized models can be summed with minimal
interference.
<br />Our proposed method is both simple and versatile, applicable to nearly all
optimizable weights in the model architecture. Through an extensive set of
quantitative and qualitative evaluations, our method consistently outperforms
relevant baselines in terms of efficiency and identity preservation,
demonstrating a significant leap toward scalable customization of diffusion
models.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02433" title="Abstract">arXiv:2312.02433</a> [<a href="/pdf/2312.02433" title="Download PDF">pdf</a>, <a href="/format/2312.02433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lenna: Language Enhanced Reasoning Detection Assistant
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Fei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Ailing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+X">Xiangxiang Chu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the fast-paced development of multimodal large language models (MLLMs),
we can now converse with AI systems in natural languages to understand images.
However, the reasoning power and world knowledge embedded in the large language
models have been much less investigated and exploited for image perception
tasks. In this paper, we propose Lenna, a language-enhanced reasoning detection
assistant, which utilizes the robust multimodal feature representation of
MLLMs, while preserving location information for detection. This is achieved by
incorporating an additional &lt;DET&gt; token in the MLLM vocabulary that is free of
explicit semantic context but serves as a prompt for the detector to identify
the corresponding position. To evaluate the reasoning capability of Lenna, we
construct a ReasonDet dataset to measure its performance on reasoning-based
detection. Remarkably, Lenna demonstrates outstanding performance on ReasonDet
and comes with significantly low training costs. It also incurs minimal
transferring overhead when extended to other tasks. Our code and model will be
available at https://git.io/Lenna.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02434" title="Abstract">arXiv:2312.02434</a> [<a href="/pdf/2312.02434" title="Download PDF">pdf</a>, <a href="/format/2312.02434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FINER: Flexible spectral-bias tuning in Implicit NEural Representation  by Variable-periodic Activation Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jingde Fu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+W">Weibing Deng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yanwen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xun Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Implicit Neural Representation (INR), which utilizes a neural network to map
coordinate inputs to corresponding attributes, is causing a revolution in the
field of signal processing. However, current INR techniques suffer from a
restricted capability to tune their supported frequency set, resulting in
imperfect performance when representing complex signals with multiple
frequencies. We have identified that this frequency-related problem can be
greatly alleviated by introducing variable-periodic activation functions, for
which we propose FINER. By initializing the bias of the neural network within
different ranges, sub-functions with various frequencies in the
variable-periodic function are selected for activation. Consequently, the
supported frequency set of FINER can be flexibly tuned, leading to improved
performance in signal representation. We demonstrate the capabilities of FINER
in the contexts of 2D image fitting, 3D signed distance field representation,
and 5D neural radiance fields optimization, and we show that it outperforms
existing INRs.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02435" title="Abstract">arXiv:2312.02435</a> [<a href="/pdf/2312.02435" title="Download PDF">pdf</a>, <a href="/format/2312.02435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Average-Case Dimensionality Reduction in $\ell_1$: Tree Ising Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Charikar%2C+M">Moses Charikar</a>, 
<a href="/search/cs?searchtype=author&query=Compton%2C+S">Spencer Compton</a>, 
<a href="/search/cs?searchtype=author&query=Pabbaraju%2C+C">Chirag Pabbaraju</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Given an arbitrary set of high dimensional points in $\ell_1$, there are
known negative results that preclude the possibility of mapping them to a low
dimensional $\ell_1$ space while preserving distances with small multiplicative
distortion. This is in stark contrast with dimension reduction in Euclidean
space ($\ell_2$) where such mappings are always possible. While the first
non-trivial lower bounds for $\ell_1$ dimension reduction were established
almost 20 years ago, there has been minimal progress in understanding what sets
of points in $\ell_1$ are conducive to a low-dimensional mapping.
<br />In this work, we shift the focus from the worst-case setting and initiate the
study of a characterization of $\ell_1$ metrics that are conducive to dimension
reduction in $\ell_1$. Our characterization focuses on metrics that are defined
by the disagreement of binary variables over a probability distribution -- any
$\ell_1$ metric can be represented in this form. We show that, for
configurations of $n$ points in $\ell_1$ obtained from tree Ising models, we
can reduce dimension to $\mathrm{polylog}(n)$ with constant distortion. In
doing so, we develop technical tools for embedding capped metrics (also known
as truncated metrics) which have been studied because of their applications in
computer vision, and are objects of independent interest in metric geometry.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02436" title="Abstract">arXiv:2312.02436</a> [<a href="/pdf/2312.02436" title="Download PDF">pdf</a>, <a href="/format/2312.02436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MUFFIN: Curating Multi-Faceted Instructions for Improving  Instruction-Following
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lou%2C+R">Renze Lou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jian Xie</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuxuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+J">Janice Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hanzi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yu Su</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+W">Wenpeng Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Website: <a href="https://renzelou.github.io/Muffin/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the realm of large language models (LLMs), enhancing instruction-following
capability often involves curating expansive training data. This is achieved
through two primary schemes: i) Scaling-Inputs: Amplifying (input, output)
pairs per task instruction, aiming for better instruction adherence. ii)
Scaling Input-Free Tasks: Enlarging tasks, each composed of an (instruction,
output) pair (without requiring a separate input anymore). However, LLMs under
Scaling-Inputs tend to be overly sensitive to inputs, leading to
misinterpretation or non-compliance with instructions. Conversely, Scaling
Input-Free Tasks demands a substantial number of tasks but is less effective in
instruction following when dealing with instances in Scaling-Inputs. This work
introduces MUFFIN, a new scheme of instruction-following dataset curation.
Specifically, we automatically Scale Tasks per Input by diversifying these
tasks with various input facets. Experimental results across four zero-shot
benchmarks, spanning both Scaling-Inputs and Scaling Input-Free Tasks schemes,
reveal that LLMs, at various scales, trained on MUFFIN generally demonstrate
superior instruction-following capabilities compared to those trained on the
two aforementioned schemes.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02437" title="Abstract">arXiv:2312.02437</a> [<a href="/pdf/2312.02437" title="Download PDF">pdf</a>, <a href="/ps/2312.02437" title="Download PostScript">ps</a>, <a href="/format/2312.02437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GDN: A Stacking Network Used for Skin Cancer Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jingmin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Haoyang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziqian Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ICSPS 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Skin cancer, the primary type of cancer that can be identified by visual
recognition, requires an automatic identification system that can accurately
classify different types of lesions. This paper presents GoogLe-Dense Network
(GDN), which is an image-classification model to identify two types of skin
cancer, Basal Cell Carcinoma, and Melanoma. GDN uses stacking of different
networks to enhance the model performance. Specifically, GDN consists of two
sequential levels in its structure. The first level performs basic
classification tasks accomplished by GoogLeNet and DenseNet, which are trained
in parallel to enhance efficiency. To avoid low accuracy and long training
time, the second level takes the output of the GoogLeNet and DenseNet as the
input for a logistic regression model. We compare our method with four baseline
networks including ResNet, VGGNet, DenseNet, and GoogLeNet on the dataset, in
which GoogLeNet and DenseNet significantly outperform ResNet and VGGNet. In the
second level, different stacking methods such as perceptron, logistic
regression, SVM, decision trees and K-neighbor are studied in which Logistic
Regression shows the best prediction result among all. The results prove that
GDN, compared to a single network structure, has higher accuracy in optimizing
skin cancer detection.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02438" title="Abstract">arXiv:2312.02438</a> [<a href="/pdf/2312.02438" title="Download PDF">pdf</a>, <a href="/format/2312.02438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Instrument Design for Indirect Experiments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chandak%2C+Y">Yash Chandak</a>, 
<a href="/search/cs?searchtype=author&query=Shankar%2C+S">Shiv Shankar</a>, 
<a href="/search/cs?searchtype=author&query=Syrgkanis%2C+V">Vasilis Syrgkanis</a>, 
<a href="/search/cs?searchtype=author&query=Brunskill%2C+E">Emma Brunskill</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Indirect experiments provide a valuable framework for estimating treatment
effects in situations where conducting randomized control trials (RCTs) is
impractical or unethical. Unlike RCTs, indirect experiments estimate treatment
effects by leveraging (conditional) instrumental variables, enabling estimation
through encouragement and recommendation rather than strict treatment
assignment. However, the sample efficiency of such estimators depends not only
on the inherent variability in outcomes but also on the varying compliance
levels of users with the instrumental variables and the choice of estimator
being used, especially when dealing with numerous instrumental variables. While
adaptive experiment design has a rich literature for direct experiments, in
this paper we take the initial steps towards enhancing sample efficiency for
indirect experiments by adaptively designing a data collection policy over
instrumental variables. Our main contribution is a practical computational
procedure that utilizes influence functions to search for an optimal data
collection policy, minimizing the mean-squared error of the desired
(non-linear) estimator. Through experiments conducted in various domains
inspired by real-world applications, we showcase how our method can
significantly improve the sample efficiency of indirect experiments.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02439" title="Abstract">arXiv:2312.02439</a> [<a href="/pdf/2312.02439" title="Download PDF">pdf</a>, <a href="/format/2312.02439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Let&#x27;s Think Outside the Box: Exploring Leap-of-Thought in Large Language  Models with Creative Humor Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+S">Shanshan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhongzhan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shanghua Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+W">Wushao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Liang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zitnik%2C+M">Marinka Zitnik</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pan Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Chain-of-Thought (CoT) guides large language models (LLMs) to reason
step-by-step, and can motivate their logical reasoning ability. While effective
for logical tasks, CoT is not conducive to creative problem-solving which often
requires out-of-box thoughts and is crucial for innovation advancements. In
this paper, we explore the Leap-of-Thought (LoT) abilities within LLMs -- a
non-sequential, creative paradigm involving strong associations and knowledge
leaps. To this end, we study LLMs on the popular Oogiri game which needs
participants to have good creativity and strong associative thinking for
responding unexpectedly and humorously to the given image, text, or both, and
thus is suitable for LoT study. Then to investigate LLMs' LoT ability in the
Oogiri game, we first build a multimodal and multilingual Oogiri-GO dataset
which contains over 130,000 samples from the Oogiri game, and observe the
insufficient LoT ability or failures of most existing LLMs on the Oogiri game.
Accordingly, we introduce a creative Leap-of-Thought (CLoT) paradigm to improve
LLM's LoT ability. CLoT first formulates the Oogiri-GO dataset into
LoT-oriented instruction tuning data to train pretrained LLM for achieving
certain LoT humor generation and discrimination abilities. Then CLoT designs an
explorative self-refinement that encourages the LLM to generate more creative
LoT data via exploring parallels between seemingly unrelated concepts and
selects high-quality data to train itself for self-refinement. CLoT not only
excels in humor generation in the Oogiri game but also boosts creative
abilities in various tasks like cloud guessing game and divergent association
task. These findings advance our understanding and offer a pathway to improve
LLMs' creative capacities for innovative applications across domains. The
dataset, code, and models will be released online.
https://github.com/sail-sg/CLoT.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02441" title="Abstract">arXiv:2312.02441</a> [<a href="/pdf/2312.02441" title="Download PDF">pdf</a>, <a href="/format/2312.02441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MedDM:LLM-executable clinical guidance tree for clinical decision-making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Binbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+T">Tianxin Meng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xiaoming Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+J">Jie Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+T">Tong Ruan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">It is becoming increasingly emphasis on the importance of LLM participating
in clinical diagnosis decision-making. However, the low specialization refers
to that current medical LLMs can not provide specific medical advice, which are
more like a medical Q\&amp;A. And there is no suitable clinical guidance tree data
set that can be used directly with LLM. To address this issue, we first propose
LLM-executavle clinical guidance tree(CGT), which can be directly used by large
language models, and construct medical diagnostic decision-making dataset
(MedDM), from flowcharts in clinical practice guidelines. We propose an
approach to screen flowcharts from medical literature, followed by their
identification and conversion into standardized diagnostic decision trees.
Constructed a knowledge base with 1202 decision trees, which came from 5000
medical literature and covered 12 hospital departments, including internal
medicine, surgery, psychiatry, and over 500 diseases.Moreover, we propose a
method for reasoning on LLM-executable CGT and a Patient-LLM multi-turn
dialogue framework.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02443" title="Abstract">arXiv:2312.02443</a> [<a href="/pdf/2312.02443" title="Download PDF">pdf</a>, <a href="/format/2312.02443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E4SRec: An Elegant Effective Efficient Extensible Solution of Large  Language Models for Sequential Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinhang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+C">Chunxiao Xing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The recent advancements in Large Language Models (LLMs) have sparked interest
in harnessing their potential within recommender systems. Since LLMs are
designed for natural language tasks, existing recommendation approaches have
predominantly transformed recommendation tasks into open-domain natural
language generation tasks. However, this approach necessitates items to possess
rich semantic information, often generates out-of-range results, and suffers
from notably low efficiency and limited extensibility. Furthermore, practical
ID-based recommendation strategies, reliant on a huge number of unique
identities (IDs) to represent users and items, have gained prominence in
real-world recommender systems due to their effectiveness and efficiency.
Nevertheless, the incapacity of LLMs to model IDs presents a formidable
challenge when seeking to leverage LLMs for personalized recommendations. In
this paper, we introduce an Elegant Effective Efficient Extensible solution for
large language models for Sequential Recommendation (E4SRec), which seamlessly
integrates LLMs with traditional recommender systems that exclusively utilize
IDs to represent items. Specifically, E4SRec takes ID sequences as inputs,
ensuring that the generated outputs fall within the candidate lists.
Furthermore, E4SRec possesses the capability to generate the entire ranking
list in a single forward process, and demands only a minimal set of pluggable
parameters, which are trained for each dataset while keeping the entire LLM
frozen. We substantiate the effectiveness, efficiency, and extensibility of our
proposed E4SRec through comprehensive experiments conducted on four widely-used
real-world datasets. The implementation code is accessible at
https://github.com/HestiaSky/E4SRec/.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02445" title="Abstract">arXiv:2312.02445</a> [<a href="/pdf/2312.02445" title="Download PDF">pdf</a>, <a href="/format/2312.02445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLaRA: Aligning Large Language Models with Sequential Recommenders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+J">Jiayi Liao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sihang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhengyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiancan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yancheng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiangnan He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Sequential recommendation aims to predict the subsequent items matching user
preference based on her/his historical interactions. With the development of
Large Language Models (LLMs), there is growing interest in exploring the
potential of LLMs for sequential recommendation by framing it as a language
modeling task. Prior works represent items in the textual prompts using either
ID indexing or text indexing and feed the prompts into LLMs, but falling short
of either encapsulating comprehensive world knowledge or exhibiting sufficient
sequential understanding. To harness the complementary strengths of traditional
recommenders (which encode user behavioral knowledge) and LLMs (which possess
world knowledge about items), we propose LLaRA -- a Large Language and
Recommendation Assistant framework. Specifically, LLaRA represents items in
LLM's input prompts using a novel hybrid approach that integrates ID-based item
embeddings from traditional recommenders with textual item features. Viewing
the ``sequential behavior of the user'' as a new modality in recommendation, we
employ an adapter to bridge the modality gap between ID embeddings of the
traditional recommenders and the input space of LLMs. Furthermore, instead of
directly exposing the hybrid prompt to LLMs, we apply a curriculum learning
approach to gradually ramp up training complexity. We first warm up the LLM
with text-only prompting, which aligns more naturally with the LLM's language
modeling capabilities. Thereafter, we progressively transition to hybrid
prompting, training the adapter to incorporate behavioral knowledge from the
traditional sequential recommender into the LLM. Extensive experiments
demonstrate the efficacy of LLaRA framework. Our code and data are available at
https://github.com/ljy0ustc/LLaRA .
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02448" title="Abstract">arXiv:2312.02448</a> [<a href="/pdf/2312.02448" title="Download PDF">pdf</a>, <a href="/format/2312.02448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Relative RTK-GNSS: GNSS Loop Closure in Pose Graph Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+T">Taro Suzuki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in IEEE Robotics and Automation Letters (RA-L) and presented at the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2020
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters (RA-L), vol. 5, no. 3, pp.
  4735-4742, July 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">A pose-graph-based optimization technique is widely used to estimate robot
poses using various sensor measurements from devices such as laser scanners and
cameras. The global navigation satellite system (GNSS) has recently been used
to estimate the absolute 3D position of outdoor mobile robots. However, since
the accuracy of GNSS single-point positioning is only a few meters, the GNSS is
not used for the loop closure of a pose graph. The main purpose of this study
is to generate a loop closure of a pose graph using a time-relative real-time
kinematic GNSS (TR-RTK-GNSS) technique. The proposed TR-RTK-GNSS technique uses
time-differential carrier phase positioning, which is based on
carrier-phase-based differential GNSS with a single GNSS receiver. Unlike a
conventional RTK-GNSS, we can directly compute the robot's relative position
using only a stand-alone GNSS receiver. The initial pose graph is generated
from the accumulated velocity computed from GNSS Doppler measurements. To
reduce the accumulated error of velocity, we use the TR-RTK-GNSS technique for
the loop closure in the graph-based optimization framework. The kinematic
positioning tests were performed using an unmanned aerial vehicle to confirm
the effectiveness of the proposed technique. From the tests, we can estimate
the vehicle's trajectory with approximately 3 cm accuracy using only a
stand-alone GNSS receiver.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02456" title="Abstract">arXiv:2312.02456</a> [<a href="/pdf/2312.02456" title="Download PDF">pdf</a>, <a href="/format/2312.02456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Watermarking for Neural Radiation Fields by Invertible Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wenquan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+W">Weina Dong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+K">Ke Niu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">To protect the copyright of the 3D scene represented by the neural radiation
field, the embedding and extraction of the neural radiation field watermark are
considered as a pair of inverse problems of image transformations. A scheme for
protecting the copyright of the neural radiation field is proposed using
invertible neural network watermarking, which utilizes watermarking techniques
for 2D images to achieve the protection of the 3D scene. The scheme embeds the
watermark in the training image of the neural radiation field through the
forward process in the invertible network and extracts the watermark from the
image rendered by the neural radiation field using the inverse process to
realize the copyright protection of both the neural radiation field and the 3D
scene. Since the rendering process of the neural radiation field can cause the
loss of watermark information, the scheme incorporates an image quality
enhancement module, which utilizes a neural network to recover the rendered
image and then extracts the watermark. The scheme embeds a watermark in each
training image to train the neural radiation field and enables the extraction
of watermark information from multiple viewpoints. Simulation experimental
results demonstrate the effectiveness of the method.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02462" title="Abstract">arXiv:2312.02462</a> [<a href="/pdf/2312.02462" title="Download PDF">pdf</a>, <a href="/ps/2312.02462" title="Download PostScript">ps</a>, <a href="/format/2312.02462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dimensionality Reduction and Dynamical Mode Recognition of Circular  Arrays of Flame Oscillators Using Deep Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weiming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 10 figures, research paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Oscillatory combustion in aero engines and modern gas turbines often has
significant adverse effects on their operation, and accurately recognizing
various oscillation modes is the prerequisite for understanding and controlling
combustion instability. However, the high-dimensional spatial-temporal data of
a complex combustion system typically poses considerable challenges to the
dynamical mode recognition. Based on a two-layer bidirectional long short-term
memory variational autoencoder (Bi-LSTM-VAE) dimensionality reduction model and
a two-dimensional Wasserstein distance-based classifier (WDC), this study
proposes a promising method (Bi-LSTM-VAE-WDC) for recognizing dynamical modes
in oscillatory combustion systems. Specifically, the Bi-LSTM-VAE dimension
reduction model was introduced to reduce the high-dimensional spatial-temporal
data of the combustion system to a low-dimensional phase space; Gaussian kernel
density estimates (GKDE) were computed based on the distribution of phase
points in a grid; two-dimensional WD values were calculated from the GKDE maps
to recognize the oscillation modes. The time-series data used in this study
were obtained from numerical simulations of circular arrays of laminar flame
oscillators. The results show that the novel Bi-LSTM-VAE method can produce a
non-overlapping distribution of phase points, indicating an effective
unsupervised mode recognition and classification. Furthermore, the present
method exhibits a more prominent performance than VAE and PCA (principal
component analysis) for distinguishing dynamical modes in complex flame
systems, implying its potential in studying turbulent combustion.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02464" title="Abstract">arXiv:2312.02464</a> [<a href="/pdf/2312.02464" title="Download PDF">pdf</a>, <a href="/format/2312.02464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAM-Assisted Remote Sensing Imagery Semantic Segmentation with Object  and Boundary Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xianping Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qianqian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xingyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaokang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pun%2C+M">Man-On Pun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Bo Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semantic segmentation of remote sensing imagery plays a pivotal role in
extracting precise information for diverse down-stream applications. Recent
development of the Segment Anything Model (SAM), an advanced general-purpose
segmentation model, has revolutionized this field, presenting new avenues for
accurate and efficient segmentation. However, SAM is limited to generating
segmentation results without class information. Consequently, the utilization
of such a powerful general vision model for semantic segmentation in remote
sensing images has become a focal point of research. In this paper, we present
a streamlined framework aimed at leveraging the raw output of SAM by exploiting
two novel concepts called SAM-Generated Object (SGO) and SAM-Generated Boundary
(SGB). More specifically, we propose a novel object loss and further introduce
a boundary loss as augmentative components to aid in model optimization in a
general semantic segmentation framework. Taking into account the content
characteristics of SGO, we introduce the concept of object consistency to
leverage segmented regions lacking semantic information. By imposing
constraints on the consistency of predicted values within objects, the object
loss aims to enhance semantic segmentation performance. Furthermore, the
boundary loss capitalizes on the distinctive features of SGB by directing the
model's attention to the boundary information of the object. Experimental
results on two well-known datasets, namely ISPRS Vaihingen and LoveDA Urban,
demonstrate the effectiveness of our proposed method. The source code for this
work will be accessible at https://github.com/sstary/SSRS.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02467" title="Abstract">arXiv:2312.02467</a> [<a href="/pdf/2312.02467" title="Download PDF">pdf</a>, <a href="/format/2312.02467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object Importance Estimation using Counterfactual Reasoning for  Intelligent Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+P">Pranay Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+A">Abhijat Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Admoni%2C+H">Henny Admoni</a>, 
<a href="/search/cs?searchtype=author&query=Held%2C+D">David Held</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The ability to identify important objects in a complex and dynamic driving
environment is essential for autonomous driving agents to make safe and
efficient driving decisions. It also helps assistive driving systems decide
when to alert drivers. We tackle object importance estimation in a data-driven
fashion and introduce HOIST - Human-annotated Object Importance in Simulated
Traffic. HOIST contains driving scenarios with human-annotated importance
labels for vehicles and pedestrians. We additionally propose a novel approach
that relies on counterfactual reasoning to estimate an object's importance. We
generate counterfactual scenarios by modifying the motion of objects and
ascribe importance based on how the modifications affect the ego vehicle's
driving. Our approach outperforms strong baselines for the task of object
importance estimation on HOIST. We also perform ablation studies to justify our
design choices and show the significance of the different components of our
proposed approach.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02468" title="Abstract">arXiv:2312.02468</a> [<a href="/pdf/2312.02468" title="Download PDF">pdf</a>, <a href="/format/2312.02468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Terrain-Based UAV Deployment: Providing Coverage for Outdoor Users
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lou%2C+Z">Zhengying Lou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Belmekki%2C+B+E+Y">Baha Eddine Youcef Belmekki</a>, 
<a href="/search/cs?searchtype=author&query=Kishk%2C+M+A">Mustafa A. Kishk</a>, 
<a href="/search/cs?searchtype=author&query=Alouini%2C+M">Mohamed-Slim Alouini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Deploying unmanned aerial vehicle (UAV) networks to provide coverage for
outdoor users has attracted great attention during the last decade. However,
outdoor coverage is challenging due to the high mobility of crowds and the
diverse terrain configurations causing building blockage. Most studies use
stochastic channel models to characterize the impact of building blockage on
user performance and do not take into account terrain information. On the other
hand, real-time search methods use terrain information, but they are only
practical when a single UAV serves a single user.In this paper, we put forward
two methods to avoid building blockage in a multi-user system by collecting
prior terrain information and using real-time search.We proposed four
algorithms related to the combinations of the above methods and their
performances are evaluated and compared in different scenarios.By adjusting the
height of the UAV based on terrain information collected before networking, the
performance is significantly enhanced compared to the one when no terrain
information is available.The algorithm based on real-time search further
improves the coverage performance by avoiding the shadow of buildings. During
the execution of the real-time search algorithm, the search distance is reduced
using the collected terrain information.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02469" title="Abstract">arXiv:2312.02469</a> [<a href="/pdf/2312.02469" title="Download PDF">pdf</a>, <a href="/format/2312.02469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Energy-based Model via Dual-MCMC Teaching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jiali Cui</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+T">Tian Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Computation (stat.CO)

</div>
<p class="mathjax">This paper studies the fundamental learning problem of the energy-based model
(EBM). Learning the EBM can be achieved using the maximum likelihood estimation
(MLE), which typically involves the Markov Chain Monte Carlo (MCMC) sampling,
such as the Langevin dynamics. However, the noise-initialized Langevin dynamics
can be challenging in practice and hard to mix. This motivates the exploration
of joint training with the generator model where the generator model serves as
a complementary model to bypass MCMC sampling. However, such a method can be
less accurate than the MCMC and result in biased EBM learning. While the
generator can also serve as an initializer model for better MCMC sampling, its
learning can be biased since it only matches the EBM and has no access to
empirical training examples. Such biased generator learning may limit the
potential of learning the EBM. To address this issue, we present a joint
learning framework that interweaves the maximum likelihood learning algorithm
for both the EBM and the complementary generator model. In particular, the
generator model is learned by MLE to match both the EBM and the empirical data
distribution, making it a more informative initializer for MCMC sampling of
EBM. Learning generator with observed examples typically requires inference of
the generator posterior. To ensure accurate and efficient inference, we adopt
the MCMC posterior sampling and introduce a complementary inference model to
initialize such latent MCMC sampling. We show that three separate models can be
seamlessly integrated into our joint framework through two (dual-) MCMC
teaching, enabling effective and efficient EBM learning.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02470" title="Abstract">arXiv:2312.02470</a> [<a href="/pdf/2312.02470" title="Download PDF">pdf</a>, <a href="/format/2312.02470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generator Born from Classifier
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+R">Runpeng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinchao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this paper, we make a bold attempt toward an ambitious task: given a
pre-trained classifier, we aim to reconstruct an image generator, without
relying on any data samples. From a black-box perspective, this challenge seems
intractable, since it inevitably involves identifying the inverse function for
a classifier, which is, by nature, an information extraction process. As such,
we resort to leveraging the knowledge encapsulated within the parameters of the
neural network. Grounded on the theory of Maximum-Margin Bias of gradient
descent, we propose a novel learning paradigm, in which the generator is
trained to ensure that the convergence conditions of the network parameters are
satisfied over the generated distribution of the samples. Empirical validation
from various image generation tasks substantiates the efficacy of our strategy.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02471" title="Abstract">arXiv:2312.02471</a> [<a href="/pdf/2312.02471" title="Download PDF">pdf</a>, <a href="/format/2312.02471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Congestion-aware Distributed Task Offloading in Wireless Multi-hop  Networks Using Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhongyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Perazzone%2C+J">Jake Perazzone</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+G">Gunjan Verma</a>, 
<a href="/search/cs?searchtype=author&query=Segarra%2C+S">Santiago Segarra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures, submitted to IEEE ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Computational offloading has become an enabling component for edge
intelligence in mobile and smart devices. Existing offloading schemes mainly
focus on mobile devices and servers, while ignoring the potential network
congestion caused by tasks from multiple mobile devices, especially in wireless
multi-hop networks. To fill this gap, we propose a low-overhead,
congestion-aware distributed task offloading scheme by augmenting a distributed
greedy framework with graph-based machine learning. In simulated wireless
multi-hop networks with 20-110 nodes and a resource allocation scheme based on
shortest path routing and contention-based link scheduling, our approach is
demonstrated to be effective in reducing congestion or unstable queues under
the context-agnostic baseline, while improving the execution latency over local
computing.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02473" title="Abstract">arXiv:2312.02473</a> [<a href="/pdf/2312.02473" title="Download PDF">pdf</a>, <a href="/format/2312.02473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeutronStream: A Dynamic GNN Training Framework with Sliding Window for  Graph Streams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaoyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+D">Dechao Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiange Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Z">Zhenbo Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuecang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Junhua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yu Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Ge Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Existing Graph Neural Network (GNN) training frameworks have been designed to
help developers easily create performant GNN implementations. However, most
existing GNN frameworks assume that the input graphs are static, but ignore
that most real-world graphs are constantly evolving. Though many dynamic GNN
models have emerged to learn from evolving graphs, the training process of
these dynamic GNNs is dramatically different from traditional GNNs in that it
captures both the spatial and temporal dependencies of graph updates. This
poses new challenges for designing dynamic GNN training frameworks. First, the
traditional batched training method fails to capture real-time structural
evolution information. Second, the time-dependent nature makes parallel
training hard to design. Third, it lacks system supports for users to
efficiently implement dynamic GNNs. In this paper, we present NeutronStream, a
framework for training dynamic GNN models. NeutronStream abstracts the input
dynamic graph into a chronologically updated stream of events and processes the
stream with an optimized sliding window to incrementally capture the
spatial-temporal dependencies of events. Furthermore, NeutronStream provides a
parallel execution engine to tackle the sequential event processing challenge
to achieve high performance. NeutronStream also integrates a built-in graph
storage structure that supports dynamic updates and provides a set of
easy-to-use APIs that allow users to express their dynamic GNNs. Our
experimental results demonstrate that, compared to state-of-the-art dynamic GNN
implementations, NeutronStream achieves speedups ranging from 1.48X to 5.87X
and an average accuracy improvement of 3.97%.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02476" title="Abstract">arXiv:2312.02476</a> [<a href="/pdf/2312.02476" title="Download PDF">pdf</a>, <a href="/format/2312.02476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Higher-order FEM and CIP-FEM for Helmholtz equation with high wave  number and perfectly matched layer truncation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+Y">Yonglin Li</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+H">Haijun Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The high-frequency Helmholtz equation on the entire space is truncated into a
bounded domain using the perfectly matched layer (PML) technique and
subsequently, discretized by the higher-order finite element method (FEM) and
the continuous interior penalty finite element method (CIP-FEM). By formulating
an elliptic problem involving a linear combination of a finite number of
eigenfunctions related to the PML differential operator, a wave-number-explicit
decomposition lemma is proved for the PML problem, which implies that the PML
solution can be decomposed into a non-oscillating elliptic part and an
oscillating but analytic part. The preasymptotic error estimates in the energy
norm for both the $p$-th order CIP-FEM and FEM are proved to be $C_1(kh)^p +
C_2k(kh)^{2p} +C_3 E^{\rm PML}$ under the mesh condition that $k^{2p+1}h^{2p}$
is sufficiently small, where $k$ is the wave number, $h$ is the mesh size, and
$E^{\rm PML}$ is the PML truncation error which is exponentially small. In
particular, the dependences of coefficients $C_j~(j=1,2)$ on the source $f$ are
improved. Numerical experiments are presented to validate the theoretical
findings, illustrating that the higher-order CIP-FEM can greatly reduce the
pollution errors.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02478" title="Abstract">arXiv:2312.02478</a> [<a href="/pdf/2312.02478" title="Download PDF">pdf</a>, <a href="/format/2312.02478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RL-Based Cargo-UAV Trajectory Planning and Cell Association for Minimum  Handoffs, Disconnectivity, and Energy Consumption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cherif%2C+N">Nesrine Cherif</a>, 
<a href="/search/eess?searchtype=author&query=Jaafar%2C+W">Wael Jaafar</a>, 
<a href="/search/eess?searchtype=author&query=Yanikomeroglu%2C+H">Halim Yanikomeroglu</a>, 
<a href="/search/eess?searchtype=author&query=Yongacoglu%2C+A">Abbas Yongacoglu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Unmanned aerial vehicle (UAV) is a promising technology for last-mile cargo
delivery. However, the limited on-board battery capacity, cellular
unreliability, and frequent handoffs in the airspace are the main obstacles to
unleash its full potential. Given that existing cellular networks were
primarily designed to service ground users, re-utilizing the same architecture
for highly mobile aerial users, e.g., cargo-UAVs, is deemed challenging.
Indeed, to ensure a safe delivery using cargo-UAVs, it is crucial to utilize
the available energy efficiently, while guaranteeing reliable connectivity for
command-and-control and avoiding frequent handoff. To achieve this goal, we
propose a novel approach for joint cargo-UAV trajectory planning and cell
association. Specifically, we formulate the cargo-UAV mission as a
multi-objective problem aiming to 1) minimize energy consumption, 2) reduce
handoff events, and 3) guarantee cellular reliability along the trajectory. We
leverage reinforcement learning (RL) to jointly optimize the cargo-UAV's
trajectory and cell association. Simulation results demonstrate a performance
improvement of our proposed method, in terms of handoffs, disconnectivity, and
energy consumption, compared to benchmarks.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02480" title="Abstract">arXiv:2312.02480</a> [<a href="/pdf/2312.02480" title="Download PDF">pdf</a>, <a href="/format/2312.02480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Point-based Inverse Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chung%2C+H">Hoon-Gyu Chung</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Seokjun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Baek%2C+S">Seung-Hwan Baek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present differentiable point-based inverse rendering, DPIR, an
analysis-by-synthesis method that processes images captured under diverse
illuminations to estimate shape and spatially-varying BRDF. To this end, we
adopt point-based rendering, eliminating the need for multiple samplings per
ray, typical of volumetric rendering, thus significantly enhancing the speed of
inverse rendering. To realize this idea, we devise a hybrid point-volumetric
representation for geometry and a regularized basis-BRDF representation for
reflectance. The hybrid geometric representation enables fast rendering through
point-based splatting while retaining the geometric details and stability
inherent to SDF-based representations. The regularized basis-BRDF mitigates the
ill-posedness of inverse rendering stemming from limited light-view angular
samples. We also propose an efficient shadow detection method using point-based
shadow map rendering. Our extensive evaluations demonstrate that DPIR
outperforms prior works in terms of reconstruction accuracy, computational
efficiency, and memory footprint. Furthermore, our explicit point-based
representation and rendering enables intuitive geometry and reflectance
editing. The code will be publicly available.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02481" title="Abstract">arXiv:2312.02481</a> [<a href="/pdf/2312.02481" title="Download PDF">pdf</a>, <a href="/format/2312.02481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Holistically Detect Bridges from Large-Size VHR Remote  Sensing Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yansheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Junwei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yihua Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jin-Gang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+S">Song Bai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 11 figures, 6 tables; due to the limitation "The abstract field cannot be longer than 1,920 characters", the abstract appearing here is slightly shorter than that in the PDF file
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Bridge detection in remote sensing images (RSIs) plays a crucial role in
various applications, but it poses unique challenges compared to the detection
of other objects. In RSIs, bridges exhibit considerable variations in terms of
their spatial scales and aspect ratios. Therefore, to ensure the visibility and
integrity of bridges, it is essential to perform holistic bridge detection in
large-size very-high-resolution (VHR) RSIs. However, the lack of datasets with
large-size VHR RSIs limits the deep learning algorithms' performance on bridge
detection. Due to the limitation of GPU memory in tackling large-size images,
deep learning-based object detection methods commonly adopt the cropping
strategy, which inevitably results in label fragmentation and discontinuous
prediction. To ameliorate the scarcity of datasets, this paper proposes a
large-scale dataset named GLH-Bridge comprising 6,000 VHR RSIs sampled from
diverse geographic locations across the globe. These images encompass a wide
range of sizes, varying from 2,048*2,048 to 16,38*16,384 pixels, and
collectively feature 59,737 bridges. Furthermore, we present an efficient
network for holistic bridge detection (HBD-Net) in large-size RSIs. The HBD-Net
presents a separate detector-based feature fusion (SDFF) architecture and is
optimized via a shape-sensitive sample re-weighting (SSRW) strategy. Based on
the proposed GLH-Bridge dataset, we establish a bridge detection benchmark
including the OBB and HBB tasks, and validate the effectiveness of the proposed
HBD-Net. Additionally, cross-dataset generalization experiments on two publicly
available datasets illustrate the strong generalization capability of the
GLH-Bridge dataset.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02483" title="Abstract">arXiv:2312.02483</a> [<a href="/pdf/2312.02483" title="Download PDF">pdf</a>, <a href="/format/2312.02483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EtC: Temporal Boundary Expand then Clarify for Weakly Supervised Video  Grounding with Multimodal Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guozhang Li</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+X">Xinpeng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+D">De Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jie Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Nannan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinbo Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Early weakly supervised video grounding (WSVG) methods often struggle with
incomplete boundary detection due to the absence of temporal boundary
annotations. To bridge the gap between video-level and boundary-level
annotation, explicit-supervision methods, i.e., generating pseudo-temporal
boundaries for training, have achieved great success. However, data
augmentations in these methods might disrupt critical temporal information,
yielding poor pseudo boundaries. In this paper, we propose a new perspective
that maintains the integrity of the original temporal content while introducing
more valuable information for expanding the incomplete boundaries. To this end,
we propose EtC (Expand then Clarify), first use the additional information to
expand the initial incomplete pseudo boundaries, and subsequently refine these
expanded ones to achieve precise boundaries. Motivated by video continuity,
i.e., visual similarity across adjacent frames, we use powerful multimodal
large language models (MLLMs) to annotate each frame within initial pseudo
boundaries, yielding more comprehensive descriptions for expanded boundaries.
To further clarify the noise of expanded boundaries, we combine mutual learning
with a tailored proposal-level contrastive objective to use a learnable
approach to harmonize a balance between incomplete yet clean (initial) and
comprehensive yet noisy (expanded) boundaries for more precise ones.
Experiments demonstrate the superiority of our method on two challenging WSVG
datasets.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02485" title="Abstract">arXiv:2312.02485</a> [<a href="/pdf/2312.02485" title="Download PDF">pdf</a>, <a href="/ps/2312.02485" title="Download PostScript">ps</a>, <a href="/format/2312.02485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust UAV Position and Attitude Estimation using Multiple GNSS  Receivers for Laser-based 3D Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+T">Taro Suzuki</a>, 
<a href="/search/cs?searchtype=author&query=Inoue%2C+D">Daichi Inoue</a>, 
<a href="/search/cs?searchtype=author&query=Amano%2C+Y">Yoshiharu Amano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2019
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2019 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS), Macau, China, 2019, pp. 4402-4408
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Small-sized unmanned aerial vehicles (UAVs) have been widely investigated for
use in a variety of applications such as remote sensing and aerial surveying.
Direct three-dimensional (3D) mapping using a small-sized UAV equipped with a
laser scanner is required for numerous remote sensing applications. In direct
3D mapping, the precise information about the position and attitude of the UAV
is necessary for constructing 3D maps. In this study, we propose a novel and
robust technique for estimating the position and attitude of small-sized UAVs
by employing multiple low-cost and light-weight global navigation satellite
system (GNSS) antennas/receivers. Using the "redundancy" of multiple GNSS
receivers, we enhance the performance of real-time kinematic (RTK)-GNSS by
employing single-frequency GNSS receivers. This method consists of two
approaches: hybrid GNSS fix solutions and consistency examination of the GNSS
signal strength. The fix rate of RTK-GNSS using single-frequency GNSS receivers
can be highly enhanced to combine multiple RTK-GNSS to fix solutions in the
multiple antennas. In addition, positioning accuracy and fix rate can be
further enhanced to detect multipath signals by using multiple GNSS antennas.
In this study, we developed a prototype UAV that is equipped with six GNSS
antennas/receivers. From the static test results, we conclude that the proposed
technique can enhance the accuracy of the position and attitude estimation in
multipath environments. From the flight test, the proposed system could
generate a 3D map with an accuracy of 5 cm.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02488" title="Abstract">arXiv:2312.02488</a> [<a href="/pdf/2312.02488" title="Download PDF">pdf</a>, <a href="/format/2312.02488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-Aware Shared Autonomy System with Hierarchical Conservative  Skill Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taewoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Donghyung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+M">Minsu Jang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jaehong Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA 2024 and currently under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Shared autonomy imitation learning, in which robots share workspace with
humans for learning, enables correct actions in unvisited states and the
effective resolution of compounding errors through expert's corrections.
However, it demands continuous human attention and supervision to lead the
demonstrations, without considering the risks associated with human judgment
errors and delayed interventions. This can potentially lead to high levels of
fatigue for the demonstrator and the additional errors. In this work, we
propose an uncertainty-aware shared autonomy system that enables the robot to
infer conservative task skills considering environmental uncertainties and
learning from expert demonstrations and corrections. To enhance generalization
and scalability, we introduce a hierarchical structure-based skill uncertainty
inference framework operating at more abstract levels. We apply this to robot
motion to promote a more stable interaction. Although shared autonomy systems
have demonstrated high-level results in recent research and play a critical
role, specific system design details have remained elusive. This paper provides
a detailed design proposal for a shared autonomy system considering various
robot configurations. Furthermore, we experimentally demonstrate the system's
capability to learn operational skills, even in dynamic environments with
interference, through pouring and pick-and-place tasks. Our code will be
released soon.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02490" title="Abstract">arXiv:2312.02490</a> [<a href="/pdf/2312.02490" title="Download PDF">pdf</a>, <a href="/format/2312.02490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained Twin Variational Auto-Encoder for Intrusion Detection in IoT  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dinh%2C+P+V">Phai Vu Dinh</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q+U">Quang Uy Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+D+T">Dinh Thai Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+N">Diep N. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+S+P">Son Pham Bao</a>, 
<a href="/search/cs?searchtype=author&query=Dutkiewicz%2C+E">Eryk Dutkiewicz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Intrusion detection systems (IDSs) play a critical role in protecting
billions of IoT devices from malicious attacks. However, the IDSs for IoT
devices face inherent challenges of IoT systems, including the heterogeneity of
IoT data/devices, the high dimensionality of training data, and the imbalanced
data. Moreover, the deployment of IDSs on IoT systems is challenging, and
sometimes impossible, due to the limited resources such as memory/storage and
computing capability of typical IoT devices. To tackle these challenges, this
article proposes a novel deep neural network/architecture called Constrained
Twin Variational Auto-Encoder (CTVAE) that can feed classifiers of IDSs with
more separable/distinguishable and lower-dimensional representation data.
Additionally, in comparison to the state-of-the-art neural networks used in
IDSs, CTVAE requires less memory/storage and computing power, hence making it
more suitable for IoT IDS systems. Extensive experiments with the 11 most
popular IoT botnet datasets show that CTVAE can boost around 1% in terms of
accuracy and Fscore in detection attack compared to the state-of-the-art
machine learning and representation learning methods, whilst the running time
for attack detection is lower than 2E-6 seconds and the model size is lower
than 1 MB. We also further investigate various characteristics of CTVAE in the
latent space and in the reconstruction representation to demonstrate its
efficacy compared with current well-known methods.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02491" title="Abstract">arXiv:2312.02491</a> [<a href="/pdf/2312.02491" title="Download PDF">pdf</a>, <a href="/ps/2312.02491" title="Download PostScript">ps</a>, <a href="/format/2312.02491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pseudo Replay-based Class Continual Learning for Online New Category  Anomaly Detection in Additive Manufacturing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhangyue Shi</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+T">Tianxin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chenang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuxuan Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">The incorporation of advanced sensors and machine learning techniques has
enabled modern manufacturing enterprises to perform data-driven in-situ quality
monitoring based on the sensor data collected in manufacturing processes.
However, one critical challenge is that newly presented defect category may
manifest as the manufacturing process continues, resulting in monitoring
performance deterioration of previously trained machine learning models. Hence,
there is an increasing need for empowering machine learning model to learn
continually. Among all continual learning methods, memory-based continual
learning has the best performance but faces the constraints of data storage
capacity. To address this issue, this paper develops a novel pseudo
replay-based continual learning by integrating class incremental learning and
oversampling-based data generation. Without storing all the data, the developed
framework could generate high-quality data representing previous classes to
train machine learning model incrementally when new category anomaly occurs. In
addition, it could even enhance the monitoring performance since it also
effectively improves the data quality. The effectiveness of the proposed
framework is validated in an additive manufacturing process, which leverages
supervised classification problem for anomaly detection. The experimental
results show that the developed method is very promising in detecting novel
anomaly while maintaining a good performance on the previous task and brings up
more flexibility in model architecture.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02493" title="Abstract">arXiv:2312.02493</a> [<a href="/pdf/2312.02493" title="Download PDF">pdf</a>, <a href="/format/2312.02493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flexible Communication for Optimal Distributed Learning over  Unpredictable Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tyagi%2C+S">Sahil Tyagi</a>, 
<a href="/search/cs?searchtype=author&query=Swany%2C+M">Martin Swany</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE International Conference on Big Data (BigData)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Gradient compression alleviates expensive communication in distributed deep
learning by sending fewer values and its corresponding indices, typically via
Allgather (AG). Training with high compression ratio (CR) achieves high
accuracy like DenseSGD, but has lower parallel scaling due to high
communication cost (i.e., parallel efficiency). Using lower CRs improves
parallel efficiency by lowering synchronization cost, but degrades model
accuracy as well (statistical efficiency). Further, speedup attained with
different models and CRs also varies with network latency, effective bandwidth
and collective op used for aggregation. In many cases, collectives like
Allreduce (AR) have lower cost than AG to exchange the same amount of data. In
this paper, we propose an AR-compatible Topk compressor that is
bandwidth-optimal and thus performs better than AG in certain network
configurations. We develop a flexible communication strategy that switches
between AG and AR based on which collective is optimal in the current settings,
and model the pareto-relationship between parallel and statistical efficiency
as a multi-objective optimization (MOO) problem to dynamically adjust CR and
accelerate training while still converging to high accuracy.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02496" title="Abstract">arXiv:2312.02496</a> [<a href="/pdf/2312.02496" title="Download PDF">pdf</a>, <a href="/ps/2312.02496" title="Download PostScript">ps</a>, <a href="/format/2312.02496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MKA: A Scalable Medical Knowledge Assisted Mechanism for Generative  Models on Medical Conversation Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+K">Ke Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Sifan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiayi Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Using natural language processing (NLP) technologies to develop medical
chatbots makes the diagnosis of the patient more convenient and efficient,
which is a typical application in healthcare AI. Because of its importance,
lots of research have been come out. Recently, the neural generative models
have shown their impressive ability as the core of chatbot, while it cannot
scale well when directly applied to medical conversation due to the lack of
medical-specific knowledge. To address the limitation, a scalable Medical
Knowledge Assisted mechanism, MKA, is proposed in this paper. The mechanism
aims to assist general neural generative models to achieve better performance
on the medical conversation task. The medical-specific knowledge graph is
designed within the mechanism, which contains 6 types of medical-related
information, including department, drug, check, symptom, disease, food.
Besides, the specific token concatenation policy is defined to effectively
inject medical information into the input data. Evaluation of our method is
carried out on two typical medical datasets, MedDG and MedDialog-CN. The
evaluation results demonstrate that models combined with our mechanism
outperform original methods in multiple automatic evaluation metrics. Besides,
MKA-Bert-GPT achieves state-of-the-art performance. The open-sourced codes are
public:
https://github.com/LIANGKE23/Knowledge_Assisted_Medical_Dialogue_Generation_Mechanism
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02498" title="Abstract">arXiv:2312.02498</a> [<a href="/pdf/2312.02498" title="Download PDF">pdf</a>, <a href="/format/2312.02498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provable Reinforcement Learning for Networked Control Systems with  Stochastic Packet Disordering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xue%2C+W">Wenqian Xue</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+Y">Yi Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Lewis%2C+F+L">Frank L. Lewis</a>, 
<a href="/search/eess?searchtype=author&query=Lian%2C+B">Bosen Lian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper formulates a stochastic optimal control problem for linear
networked control systems featuring stochastic packet disordering with a unique
stabilizing solution certified. The problem is solved by proposing
reinforcement learning algorithms. A measurement method is first presented to
deal with PD and calculate the newest control input. The NCSs with stochastic
PD are modeled as stochastic NCSs. Then, given a cost function, a modified
algebraic Riccati equation is derived within the formulation. We propose
offline policy iteration and value iteration algorithms to solve the MARE
associated with provable convergence. These two algorithms require knowledge of
NCS dynamics and PD probabilities. To release that, we further design online
model-free off-policy and Q-learning algorithms with an online estimation
method for PD probability. Both model-free algorithms solve the optimal control
problem using real-time system states, control inputs, and PD probability
estimates. Simulation results verify the proposed formulation and algorithms at
last.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02501" title="Abstract">arXiv:2312.02501</a> [<a href="/pdf/2312.02501" title="Download PDF">pdf</a>, <a href="/format/2312.02501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inspecting Model Fairness in Ultrasound Segmentation Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zikang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+F">Fenghe Tang</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+Q">Quan Quan</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jianrui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+C">Chunping Ning</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S+K">S. Kevin Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ISBI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the rapid expansion of machine learning and deep learning (DL),
researchers are increasingly employing learning-based algorithms to alleviate
diagnostic challenges across diverse medical tasks and applications. While
advancements in diagnostic precision are notable, some researchers have
identified a concerning trend: their models exhibit biased performance across
subgroups characterized by different sensitive attributes. This bias not only
infringes upon the rights of patients but also has the potential to lead to
life-altering consequences. In this paper, we inspect a series of DL
segmentation models using two ultrasound datasets, aiming to assess the
presence of model unfairness in these specific tasks. Our findings reveal that
even state-of-the-art DL algorithms demonstrate unfair behavior in ultrasound
segmentation tasks. These results serve as a crucial warning, underscoring the
necessity for careful model evaluation before their deployment in real-world
scenarios. Such assessments are imperative to ensure ethical considerations and
mitigate the risk of adverse impacts on patient outcomes.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02503" title="Abstract">arXiv:2312.02503</a> [<a href="/pdf/2312.02503" title="Download PDF">pdf</a>, <a href="/format/2312.02503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAVE: Protagonist Diversification with Structure Agnostic Video Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yeji Song</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+W">Wonsik Shin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Junsoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jeesoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kwak%2C+N">Nojun Kwak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="https://ldynx.github.io/SAVE/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Driven by the upsurge progress in text-to-image (T2I) generation models,
text-to-video (T2V) generation has experienced a significant advance as well.
Accordingly, tasks such as modifying the object or changing the style in a
video have been possible. However, previous works usually work well on trivial
and consistent shapes, and easily collapse on a difficult target that has a
largely different body shape from the original one. In this paper, we spot the
bias problem in the existing video editing method that restricts the range of
choices for the new protagonist and attempt to address this issue using the
conventional image-level personalization method. We adopt motion
personalization that isolates the motion from a single source video and then
modifies the protagonist accordingly. To deal with the natural discrepancy
between image and video, we propose a motion word with an inflated textual
embedding to properly represent the motion in a source video. We also regulate
the motion word to attend to proper motion-related areas by introducing a novel
pseudo optical flow, efficiently computed from the pre-calculated attention
maps. Finally, we decouple the motion from the appearance of the source video
with an additional pseudo word. Extensive experiments demonstrate the editing
capability of our method, taking a step toward more diverse and extensive video
editing.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02505" title="Abstract">arXiv:2312.02505</a> [<a href="/pdf/2312.02505" title="Download PDF">pdf</a>, <a href="/format/2312.02505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating eVTOL Network Performance and Fleet Dynamics through  Simulation-Based Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Onat%2C+E+B">Emin Burak Onat</a>, 
<a href="/search/cs?searchtype=author&query=Bulusu%2C+V">Vishwanath Bulusu</a>, 
<a href="/search/cs?searchtype=author&query=Chakrabarty%2C+A">Anjan Chakrabarty</a>, 
<a href="/search/cs?searchtype=author&query=Hansen%2C+M">Mark Hansen</a>, 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+R">Raja Sengupta</a>, 
<a href="/search/cs?searchtype=author&query=Sridar%2C+B">Banavar Sridar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AIAA SciTech Forum 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Urban Air Mobility (UAM) represents a promising solution for future
transportation. In this study, we introduce VertiSim, an advanced event-driven
simulator developed to evaluate e-VTOL transportation networks. Uniquely,
VertiSim simultaneously models passenger, aircraft, and energy flows,
reflecting the interrelated complexities of UAM systems. We utilized VertiSim
to assess 19 operational scenarios serving a daily demand for 2,834 passengers
with varying fleet sizes and vertiport distances. The study aims to support
stakeholders in making informed decisions about fleet size, network design, and
infrastructure development by understanding tradeoffs in passenger delay time,
operational costs, and fleet utilization. Our simulations, guided by a
heuristic dispatch and charge policy, indicate that fleet size significantly
influences passenger delay and energy consumption within UAM networks. We find
that increasing the fleet size can reduce average passenger delays, but this
comes at the cost of higher operational expenses due to an increase in the
number of repositioning flights. Additionally, our analysis highlights how
vertiport distances impact fleet utilization: longer distances result in
reduced total idle time and increased cruise and charge times, leading to more
efficient fleet utilization but also longer passenger delays. These findings
are important for UAM network planning, especially in balancing fleet size with
vertiport capacity and operational costs. Simulator demo is available at:
https://tinyurl.com/vertisim-vis
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02509" title="Abstract">arXiv:2312.02509</a> [<a href="/pdf/2312.02509" title="Download PDF">pdf</a>, <a href="/ps/2312.02509" title="Download PostScript">ps</a>, <a href="/format/2312.02509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When PETs misbehave: A Contextual Integrity analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balsa%2C+E">Ero Balsa</a>, 
<a href="/search/cs?searchtype=author&query=Shvartzshnaider%2C+Y">Yan Shvartzshnaider</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY); Information Theory (cs.IT)

</div>
<p class="mathjax">Privacy enhancing technologies, or PETs, have been hailed as a promising
means to protect privacy without compromising on the functionality of digital
services. At the same time, and partly because they may encode a narrow
conceptualization of privacy as confidentiality that is popular among
policymakers, engineers and the public, PETs risk being co-opted to promote
privacy-invasive practices. In this paper, we resort to the theory of
Contextual Integrity to explain how privacy technologies may be misused to
erode privacy. To illustrate, we consider three PETs and scenarios: anonymous
credentials for age verification, client-side scanning for illegal content
detection, and homomorphic encryption for machine learning model training.
Using the theory of Contextual Integrity, we reason about the notion of privacy
that these PETs encode, and show that CI enables us to identify and reason
about the limitations of PETs and their misuse, and which may ultimately lead
to privacy violations.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02510" title="Abstract">arXiv:2312.02510</a> [<a href="/pdf/2312.02510" title="Download PDF">pdf</a>, <a href="/format/2312.02510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimation of articulated angle in six-wheeled dump trucks using  multiple GNSS receivers for autonomous driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+T">Taro Suzuki</a>, 
<a href="/search/cs?searchtype=author&query=Ohno%2C+K">Kazunori Ohno</a>, 
<a href="/search/cs?searchtype=author&query=Kojima%2C+S">Syotaro Kojima</a>, 
<a href="/search/cs?searchtype=author&query=Miyamoto%2C+N">Naoto Miyamoto</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+T">Takahiro Suzuki</a>, 
<a href="/search/cs?searchtype=author&query=Komatsu%2C+T">Tomohiro Komatsu</a>, 
<a href="/search/cs?searchtype=author&query=Shibata%2C+Y">Yukinori Shibata</a>, 
<a href="/search/cs?searchtype=author&query=Asano%2C+K">Kimitaka Asano</a>, 
<a href="/search/cs?searchtype=author&query=Nagatani%2C+K">Keiji Nagatani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an electronic version of an article published in ADVANCED ROBOTICS, 35:23, 1376-1387, 2021. ADVANCED ROBOTICS is available online at: www.tandfonline.com/Article DOI; 10.1080/01691864.2019.1619622
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Advanced Robotics, 35:23, 1376-1387, 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Due to the declining birthrate and aging population, the shortage of labor in
the construction industry has become a serious problem, and increasing
attention has been paid to automation of construction equipment. We focus on
the automatic operation of articulated six-wheel dump trucks at construction
sites. For the automatic operation of the dump trucks, it is important to
estimate the position and the articulated angle of the dump trucks with high
accuracy. In this study, we propose a method for estimating the state of a dump
truck by using four global navigation satellite systems (GNSSs) installed on an
articulated dump truck and a graph optimization method that utilizes the
redundancy of multiple GNSSs. By adding real-time kinematic (RTK)-GNSS
constraints and geometric constraints between the four antennas, the proposed
method can robustly estimate the position and articulation angle even in
environments where GNSS satellites are partially blocked. As a result of
evaluating the accuracy of the proposed method through field tests, it was
confirmed that the articulated angle could be estimated with an accuracy of
0.1$^\circ$ in an open-sky environment and 0.7$^\circ$ in a mountainous area
simulating an elevation angle of 45$^\circ$ where GNSS satellites are blocked.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02512" title="Abstract">arXiv:2312.02512</a> [<a href="/pdf/2312.02512" title="Download PDF">pdf</a>, <a href="/format/2312.02512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AV2AV: Direct Audio-Visual Speech to Audio-Visual Speech Translation  with Unified Audio-Visual Speech Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jeongsoo Choi</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S+J">Se Jin Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ro%2C+Y+M">Yong Man Ro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This paper proposes a novel direct Audio-Visual Speech to Audio-Visual Speech
Translation (AV2AV) framework, where the input and output of the system are
multimodal (i.e., audio and visual speech). With the proposed AV2AV, two key
advantages can be brought: 1) We can perform real-like conversations with
individuals worldwide in a virtual meeting by utilizing our own primary
languages. In contrast to Speech-to-Speech Translation (A2A), which solely
translates between audio modalities, the proposed AV2AV directly translates
between audio-visual speech. This capability enhances the dialogue experience
by presenting synchronized lip movements along with the translated speech. 2)
We can improve the robustness of the spoken language translation system. By
employing the complementary information of audio-visual speech, the system can
effectively translate spoken language even in the presence of acoustic noise,
showcasing robust performance. To mitigate the problem of the absence of a
parallel AV2AV translation dataset, we propose to train our spoken language
translation system with the audio-only dataset of A2A. This is done by learning
unified audio-visual speech representations through self-supervised learning in
advance to train the translation system. Moreover, we propose an AV-Renderer
that can generate raw audio and video in parallel. It is designed with
zero-shot speaker modeling, thus the speaker in source audio-visual speech can
be maintained at the target translated audio-visual speech. The effectiveness
of AV2AV is evaluated with extensive experiments in a many-to-many language
translation setting. The demo page is available on
https://choijeongsoo.github.io/av2av.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02514" title="Abstract">arXiv:2312.02514</a> [<a href="/pdf/2312.02514" title="Download PDF">pdf</a>, <a href="/ps/2312.02514" title="Download PostScript">ps</a>, <a href="/format/2312.02514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Skipping Scheme for Gate-hiding Garbled Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Ke Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In classic settings of garbled circuits, each gate type is leaked to improve
both space and speed optimization. Zahur et al. have shown in EUROCRYPT 2015
that a typical linear garbling scheme requires at least two $\lambda$-bit
elements per gate with a security parameter of $\lambda$, which limits their
efficiency. In contrast to typical garbled circuits, gate-hiding garbled
circuits have the potential to drastically reduce time costs, although they
have been underappreciated.
<br />We propose the first skipping scheme for gate-hiding garbled circuits to
enhance the efficiency of evaluation by observing prime implicants. Our scheme
introduces skip gates to eliminate the need to calculate the entire circuit,
enabling unnecessary execution paths to be avoided. We also introduce two
variants of our scheme that balance security with parallelism. A proof of
hybrid security that combines simulation-based and symmetry-based security in
semi-honest scenarios is presented to demonstrate its security under
gate-hiding conditions. Our scheme will inspire new directions to improve the
general garbling scheme and lead to more practical ones.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02515" title="Abstract">arXiv:2312.02515</a> [<a href="/pdf/2312.02515" title="Download PDF">pdf</a>, <a href="/format/2312.02515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ASPEN: High-Throughput LoRA Fine-Tuning of Large Language Models with a  Single GPU
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zhengmao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dengchun Li</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jingqi Tian</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+T">Tingfeng Lan</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+J">Jie Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+L">Lei Duan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hui Lu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yexi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Sha%2C+J">Jian Sha</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Ke Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+M">Mingjie Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Transformer-based large language models (LLMs) have demonstrated outstanding
performance across diverse domains, particularly when fine-turned for specific
domains. Recent studies suggest that the resources required for fine-tuning
LLMs can be economized through parameter-efficient methods such as Low-Rank
Adaptation (LoRA). While LoRA effectively reduces computational burdens and
resource demands, it currently supports only a single-job fine-tuning setup.
<br />In this paper, we present ASPEN, a high-throughput framework for fine-tuning
LLMs. ASPEN efficiently trains multiple jobs on a single GPU using the LoRA
method, leveraging shared pre-trained model and adaptive scheduling. ASPEN is
compatible with transformer-based language models like LLaMA and ChatGLM, etc.
Experiments show that ASPEN saves 53% of GPU memory when training multiple
LLaMA-7B models on NVIDIA A100 80GB GPU and boosts training throughput by about
17% compared to existing methods when training with various pre-trained models
on different GPUs. The adaptive scheduling algorithm reduces turnaround time by
24%, end-to-end training latency by 12%, prioritizing jobs and preventing
out-of-memory issues.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02517" title="Abstract">arXiv:2312.02517</a> [<a href="/pdf/2312.02517" title="Download PDF">pdf</a>, <a href="/format/2312.02517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simplifying Neural Network Training Under Class Imbalance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shwartz-Ziv%2C+R">Ravid Shwartz-Ziv</a>, 
<a href="/search/cs?searchtype=author&query=Goldblum%2C+M">Micah Goldblum</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y+L">Yucen Lily Li</a>, 
<a href="/search/cs?searchtype=author&query=Bruss%2C+C+B">C. Bayan Bruss</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+A+G">Andrew Gordon Wilson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. Code available at <a href="https://github.com/ravidziv/SimplifyingImbalancedTraining">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Real-world datasets are often highly class-imbalanced, which can adversely
impact the performance of deep learning models. The majority of research on
training neural networks under class imbalance has focused on specialized loss
functions, sampling techniques, or two-stage training procedures. Notably, we
demonstrate that simply tuning existing components of standard deep learning
pipelines, such as the batch size, data augmentation, optimizer, and label
smoothing, can achieve state-of-the-art performance without any such
specialized class imbalance methods. We also provide key prescriptions and
considerations for training under class imbalance, and an understanding of why
imbalance methods succeed or fail.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02519" title="Abstract">arXiv:2312.02519</a> [<a href="/pdf/2312.02519" title="Download PDF">pdf</a>, <a href="/format/2312.02519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Creative Agents: Empowering Agents with Imagination for Creative Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+P">Penglin Cai</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yuhui Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Haoqi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zongqing Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors contribute equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We study building embodied agents for open-ended creative tasks. While
existing methods build instruction-following agents that can perform diverse
open-ended tasks, none of them demonstrates creativity -- the ability to give
novel and diverse task solutions implicit in the language instructions. This
limitation comes from their inability to convert abstract language instructions
into concrete task goals in the environment and perform long-horizon planning
for such complicated goals. Given the observation that humans perform creative
tasks with the help of imagination, we propose a class of solutions for
creative agents, where the controller is enhanced with an imaginator that
generates detailed imaginations of task outcomes conditioned on language
instructions. We introduce several approaches to implementing the components of
creative agents. We implement the imaginator with either a large language model
for textual imagination or a diffusion model for visual imagination. The
controller can either be a behavior-cloning policy learned from data or a
pre-trained foundation model generating executable codes in the environment. We
benchmark creative tasks with the challenging open-world game Minecraft, where
the agents are asked to create diverse buildings given free-form language
instructions. In addition, we propose novel evaluation metrics for open-ended
creative tasks utilizing GPT-4V, which holds many advantages over existing
metrics. We perform a detailed experimental analysis of creative agents,
showing that creative agents are the first AI agents accomplishing diverse
building creation in the survival mode of Minecraft. Our benchmark and models
are open-source for future research on creative agents
(https://github.com/PKU-RL/Creative-Agents).
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02520" title="Abstract">arXiv:2312.02520</a> [<a href="/pdf/2312.02520" title="Download PDF">pdf</a>, <a href="/format/2312.02520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards More Unified In-context Visual Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sheng%2C+D">Dianmo Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dongdong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhentao Tan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qiankun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+Q">Qi Chu</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+J">Jianmin Bao</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+T">Tao Gong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shengwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+N">Nenghai Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The rapid advancement of large language models (LLMs) has accelerated the
emergence of in-context learning (ICL) as a cutting-edge approach in the
natural language processing domain. Recently, ICL has been employed in visual
understanding tasks, such as semantic segmentation and image captioning,
yielding promising results. However, existing visual ICL framework can not
enable producing content across multiple modalities, which limits their
potential usage scenarios. To address this issue, we present a new ICL
framework for visual understanding with multi-modal output enabled. First, we
quantize and embed both text and visual prompt into a unified representational
space, structured as interleaved in-context sequences. Then a decoder-only
sparse transformer architecture is employed to perform generative modeling on
them, facilitating in-context learning. Thanks to this design, the model is
capable of handling in-context vision understanding tasks with multimodal
output in a unified pipeline. Experimental results demonstrate that our model
achieves competitive performance compared with specialized models and previous
ICL baselines. Overall, our research takes a further step toward unified
multimodal in-context learning.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02521" title="Abstract">arXiv:2312.02521</a> [<a href="/pdf/2312.02521" title="Download PDF">pdf</a>, <a href="/format/2312.02521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieving Conditions from Reference Images for Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Haoran Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jieren Deng</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhihong Pan</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Hao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhari%2C+P">Pratik Chaudhari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent diffusion-based subject driven generative methods have enabled image
generations with good fidelity for specific objects or human portraits.
However, to achieve better versatility for applications, we argue that not only
improved datasets and evaluations are desired, but also more careful methods to
retrieve only relevant information from conditional images are anticipated. To
this end, we propose an anime figures dataset RetriBooru-V1, with enhanced
identity and clothing labels. We state new tasks enabled by this dataset, and
introduce a new diversity metric to measure success in completing these tasks,
quantifying the flexibility of image generations. We establish an RAG-inspired
baseline method, designed to retrieve precise conditional information from
reference images. Then, we compare with current methods on existing task to
demonstrate the capability of the proposed method. Finally, we provide baseline
experiment results on new tasks, and conduct ablation studies on the possible
structural choices.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02522" title="Abstract">arXiv:2312.02522</a> [<a href="/pdf/2312.02522" title="Download PDF">pdf</a>, <a href="/format/2312.02522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MASP: Scalable GNN-based Planning for Multi-Agent Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinting Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiayu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Huazhong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE RA-L
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">We investigate the problem of decentralized multi-agent navigation tasks,
where multiple agents need to reach initially unassigned targets in a limited
time. Classical planning-based methods suffer from expensive computation
overhead at each step and offer limited expressiveness for complex cooperation
strategies. In contrast, reinforcement learning (RL) has recently become a
popular paradigm for addressing this issue. However, RL struggles with low data
efficiency and cooperation when directly exploring (nearly) optimal policies in
the large search space, especially with an increased agent number (e.g., 10+
agents) or in complex environments (e.g., 3D simulators). In this paper, we
propose Multi-Agent Scalable GNN-based P lanner (MASP), a goal-conditioned
hierarchical planner for navigation tasks with a substantial number of agents.
MASP adopts a hierarchical framework to divide a large search space into
multiple smaller spaces, thereby reducing the space complexity and accelerating
training convergence. We also leverage graph neural networks (GNN) to model the
interaction between agents and goals, improving goal achievement. Besides, to
enhance generalization capabilities in scenarios with unseen team sizes, we
divide agents into multiple groups, each with a previously trained number of
agents. The results demonstrate that MASP outperforms classical planning-based
competitors and RL baselines, achieving a nearly 100% success rate with minimal
training data in both multi-agent particle environments (MPE) with 50 agents
and a quadrotor 3-dimensional environment (OmniDrones) with 20 agents.
Furthermore, the learned policy showcases zero-shot generalization across
unseen team sizes.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02528" title="Abstract">arXiv:2312.02528</a> [<a href="/pdf/2312.02528" title="Download PDF">pdf</a>, <a href="/format/2312.02528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Automatic Power Battery Detection: New Challenge, Benchmark  Dataset and Baseline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiaoqi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+Y">Youwei Pang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lihe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hanqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+J">Jiaming Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Huchuan Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We conduct a comprehensive study on a new task named power battery detection
(PBD), which aims to localize the dense cathode and anode plates endpoints from
X-ray images to evaluate the quality of power batteries. Existing manufacturers
usually rely on human eye observation to complete PBD, which makes it difficult
to balance the accuracy and efficiency of detection. To address this issue and
drive more attention into this meaningful task, we first elaborately collect a
dataset, called X-ray PBD, which has $1,500$ diverse X-ray images selected from
thousands of power batteries of $5$ manufacturers, with $7$ different visual
interference. Then, we propose a novel segmentation-based solution for PBD,
termed multi-dimensional collaborative network (MDCNet). With the help of line
and counting predictors, the representation of the point segmentation branch
can be improved at both semantic and detail aspects. Besides, we design an
effective distance-adaptive mask generation strategy, which can alleviate the
visual challenge caused by the inconsistent distribution density of plates to
provide MDCNet with stable supervision. Without any bells and whistles, our
segmentation-based MDCNet consistently outperforms various other corner
detection, crowd counting and general/tiny object detection-based solutions,
making it a strong baseline that can help facilitate future research in PBD.
Finally, we share some potential difficulties and works for future researches.
The source code and datasets will be publicly available at
\href{<a href="http://www.gy3000.company/x3000%e5%bc%80%e6%94%be%e5%b9%b3%e5%8f%b0">this http URL</a>}{X-ray
PBD}.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02530" title="Abstract">arXiv:2312.02530</a> [<a href="/pdf/2312.02530" title="Download PDF">pdf</a>, <a href="/format/2312.02530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MEMTO: Memory-guided Transformer for Multivariate Time Series Anomaly  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Junho Song</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Keonwoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+J">Jeonglyul Oh</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+S">Sungzoon Cho</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Detecting anomalies in real-world multivariate time series data is
challenging due to complex temporal dependencies and inter-variable
correlations. Recently, reconstruction-based deep models have been widely used
to solve the problem. However, these methods still suffer from an
over-generalization issue and fail to deliver consistently high performance. To
address this issue, we propose the MEMTO, a memory-guided Transformer using a
reconstruction-based approach. It is designed to incorporate a novel memory
module that can learn the degree to which each memory item should be updated in
response to the input data. To stabilize the training procedure, we use a
two-phase training paradigm which involves using K-means clustering for
initializing memory items. Additionally, we introduce a bi-dimensional
deviation-based detection criterion that calculates anomaly scores considering
both input space and latent space. We evaluate our proposed method on five
real-world datasets from diverse domains, and it achieves an average anomaly
detection F1-score of 95.74%, significantly outperforming the previous
state-of-the-art methods. We also conduct extensive experiments to empirically
validate the effectiveness of our proposed model's key components.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02531" title="Abstract">arXiv:2312.02531</a> [<a href="/pdf/2312.02531" title="Download PDF">pdf</a>, <a href="/format/2312.02531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PolyFit: A Peg-in-hole Assembly Framework for Unseen Polygon Shapes via  Sim-to-real Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+G">Geonhyup Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Joosoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Noh%2C+S">Sangjun Noh</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+M">Minhwan Ko</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kangmin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kyoobin Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The study addresses the foundational and challenging task of peg-in-hole
assembly in robotics, where misalignments caused by sensor inaccuracies and
mechanical errors often result in insertion failures or jamming. This research
introduces PolyFit, representing a paradigm shift by transitioning from a
reinforcement learning approach to a supervised learning methodology. PolyFit
is a Force/Torque (F/T)-based supervised learning framework designed for 5-DoF
peg-in-hole assembly. It utilizes F/T data for accurate extrinsic pose
estimation and adjusts the peg pose to rectify misalignments. Extensive
training in a simulated environment involves a dataset encompassing a diverse
range of peg-hole shapes, extrinsic poses, and their corresponding contact F/T
readings. To enhance extrinsic pose estimation, a multi-point contact strategy
is integrated into the model input, recognizing that identical F/T readings can
indicate different poses. The study proposes a sim-to-real adaptation method
for real-world application, using a sim-real paired dataset to enable effective
generalization to complex and unseen polygon shapes. PolyFit achieves
impressive peg-in-hole success rates of 97.3% and 96.3% for seen and unseen
shapes in simulations, respectively. Real-world evaluations further demonstrate
substantial success rates of 86.7% and 85.0%, highlighting the robustness and
adaptability of the proposed method.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02532" title="Abstract">arXiv:2312.02532</a> [<a href="/pdf/2312.02532" title="Download PDF">pdf</a>, <a href="/format/2312.02532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DRAFT: Dense Retrieval Augmented Few-shot Topic classifier Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Keonwoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Younggun Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">With the growing volume of diverse information, the demand for classifying
arbitrary topics has become increasingly critical. To address this challenge,
we introduce DRAFT, a simple framework designed to train a classifier for
few-shot topic classification. DRAFT uses a few examples of a specific topic as
queries to construct Customized dataset with a dense retriever model.
Multi-query retrieval (MQR) algorithm, which effectively handles multiple
queries related to a specific topic, is applied to construct the Customized
dataset. Subsequently, we fine-tune a classifier using the Customized dataset
to identify the topic. To demonstrate the efficacy of our proposed approach, we
conduct evaluations on both widely used classification benchmark datasets and
manually constructed datasets with 291 diverse topics, which simulate diverse
contents encountered in real-world applications. DRAFT shows competitive or
superior performance compared to baselines that use in-context learning, such
as GPT-3 175B and InstructGPT 175B, on few-shot topic classification tasks
despite having 177 times fewer parameters, demonstrating its effectiveness.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02535" title="Abstract">arXiv:2312.02535</a> [<a href="/pdf/2312.02535" title="Download PDF">pdf</a>, <a href="/format/2312.02535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Open-set Gesture Recognition via Feature Activation Enhancement  and Orthogonal Prototype Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+C">Can Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chengfeng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+C">Crystal Cai</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+S">Suncheng Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+H">Hualiang Ni</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+D">Dahong Qian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Gesture recognition is a foundational task in human-machine interaction
(HMI). While there has been significant progress in gesture recognition based
on surface electromyography (sEMG), accurate recognition of predefined gestures
only within a closed set is still inadequate in practice. It is essential to
effectively discern and reject unknown gestures of disinterest in a robust
system. Numerous methods based on prototype learning (PL) have been proposed to
tackle this open set recognition (OSR) problem. However, they do not fully
explore the inherent distinctions between known and unknown classes. In this
paper, we propose a more effective PL method leveraging two novel and inherent
distinctions, feature activation level and projection inconsistency.
Specifically, the Feature Activation Enhancement Mechanism (FAEM) widens the
gap in feature activation values between known and unknown classes.
Furthermore, we introduce Orthogonal Prototype Learning (OPL) to construct
multiple perspectives. OPL acts to project a sample from orthogonal directions
to maximize the distinction between its two projections, where unknown samples
will be projected near the clusters of different known classes while known
samples still maintain intra-class similarity. Our proposed method
simultaneously achieves accurate closed-set classification for predefined
gestures and effective rejection for unknown gestures. Extensive experiments
demonstrate its efficacy and superiority in open-set gesture recognition based
on sEMG.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02538" title="Abstract">arXiv:2312.02538</a> [<a href="/pdf/2312.02538" title="Download PDF">pdf</a>, <a href="/format/2312.02538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-Granularity-Aware Aspect Learning Model for Multi-Aspect Dense  Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaojie Sun</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+K">Keping Bi</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiafeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sihui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qishen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhongyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guannan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WSDM2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Dense retrieval methods have been mostly focused on unstructured text and
less attention has been drawn to structured data with various aspects, e.g.,
products with aspects such as category and brand. Recent work has proposed two
approaches to incorporate the aspect information into item representations for
effective retrieval by predicting the values associated with the item aspects.
Despite their efficacy, they treat the values as isolated classes (e.g., "Smart
Homes", "Home, Garden &amp; Tools", and "Beauty &amp; Health") and ignore their
fine-grained semantic relation. Furthermore, they either enforce the learning
of aspects into the CLS token, which could confuse it from its designated use
for representing the entire content semantics, or learn extra aspect embeddings
only with the value prediction objective, which could be insufficient
especially when there are no annotated values for an item aspect. Aware of
these limitations, we propose a MUlti-granulaRity-aware Aspect Learning model
(MURAL) for multi-aspect dense retrieval. It leverages aspect information
across various granularities to capture both coarse and fine-grained semantic
relations between values. Moreover, MURAL incorporates separate aspect
embeddings as input to transformer encoders so that the masked language model
objective can assist implicit aspect learning even without aspect-value
annotations. Extensive experiments on two real-world datasets of products and
mini-programs show that MURAL outperforms state-of-the-art baselines
significantly.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02542" title="Abstract">arXiv:2312.02542</a> [<a href="/pdf/2312.02542" title="Download PDF">pdf</a>, <a href="/format/2312.02542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fortress: Securing IoT Peripherals with Trusted Execution Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuhala%2C+P">Peterson Yuhala</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%A9n%C3%A9trey%2C+J">J&#xe4;mes M&#xe9;n&#xe9;trey</a>, 
<a href="/search/cs?searchtype=author&query=Felber%2C+P">Pascal Felber</a>, 
<a href="/search/cs?searchtype=author&query=Pasin%2C+M">Marcelo Pasin</a>, 
<a href="/search/cs?searchtype=author&query=Schiavoni%2C+V">Valerio Schiavoni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">With the increasing popularity of Internet of Things (IoT) devices, securing
sensitive user data has emerged as a major challenge. These devices often
collect confidential information, such as audio and visual data, through
peripheral inputs like microphones and cameras. Such sensitive information is
then exposed to potential threats, either from malicious software with
high-level access rights or transmitted (sometimes inadvertently) to untrusted
cloud services. In this paper, we propose a generic design to enhance the
privacy in IoT-based systems by isolating peripheral I/O memory regions in a
secure kernel space of a trusted execution environment (TEE). Only a minimal
set of peripheral driver code, resident within the secure kernel, can access
this protected memory area.
<br />This design effectively restricts any unauthorised access by system software,
including the operating system and hypervisor. The sensitive peripheral data is
then securely transferred to a user-space TEE, where obfuscation mechanisms can
be applied before it is relayed to third parties, e.g., the cloud. To validate
our architectural approach, we provide a proof-of-concept implementation of our
design by securing an audio peripheral based on inter-IC sound (I2S), a serial
bus to interconnect audio devices. The experimental results show that our
design offers a robust security solution with an acceptable computational
overhead.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02545" title="Abstract">arXiv:2312.02545</a> [<a href="/pdf/2312.02545" title="Download PDF">pdf</a>, <a href="/format/2312.02545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Information Bottleneck for Remote Sensing Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shou%2C+Y">Yuntao Shou</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+W">Wei Ai</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+T">Tao Meng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Remote sensing segmentation has a wide range of applications in environmental
protection, and urban change detection, etc. Despite the success of deep
learning-based remote sensing segmentation methods (e.g., CNN and Transformer),
they are not flexible enough to model irregular objects. In addition, existing
graph contrastive learning methods usually adopt the way of maximizing mutual
information to keep the node representations consistent between different graph
views, which may cause the model to learn task-independent redundant
information. To tackle the above problems, this paper treats images as graph
structures and introduces a simple contrastive vision GNN (SC-ViG) architecture
for remote sensing segmentation. Specifically, we construct a node-masked and
edge-masked graph view to obtain an optimal graph structure representation,
which can adaptively learn whether to mask nodes and edges. Furthermore, this
paper innovatively introduces information bottleneck theory into graph
contrastive learning to maximize task-related information while minimizing
task-independent redundant information. Finally, we replace the convolutional
module in UNet with the SC-ViG module to complete the segmentation and
classification tasks of remote sensing images. Extensive experiments on
publicly available real datasets demonstrate that our method outperforms
state-of-the-art remote sensing image segmentation methods.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02546" title="Abstract">arXiv:2312.02546</a> [<a href="/pdf/2312.02546" title="Download PDF">pdf</a>, <a href="/format/2312.02546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Vision Therapy: Multimodal Large Language Models Can Enhance  Visual Robustness via Denoising In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhuo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yinpeng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hang Su</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shibao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tongliang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 19 figures, and 13 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Although vision models such as Contrastive Language-Image Pre-Training (CLIP)
show impressive generalization performance, their zero-shot robustness is still
limited under Out-of-Distribution (OOD) scenarios without fine-tuning. Instead
of undesirably providing human supervision as commonly done, it is possible to
take advantage of Multi-modal Large Language Models (MLLMs) that hold powerful
visual understanding abilities. However, MLLMs are shown to struggle with
vision problems due to the incompatibility of tasks, thus hindering their
utilization. In this paper, we propose to effectively leverage MLLMs to conduct
Machine Vision Therapy which aims to rectify the noisy predictions from vision
models. By fine-tuning with the denoised labels, the learning model performance
can be boosted in an unsupervised manner. To solve the incompatibility issue,
we propose a novel Denoising In-Context Learning (DICL) strategy to align
vision tasks with MLLMs. Concretely, by estimating a transition matrix that
captures the probability of one class being confused with another, an
instruction containing a correct exemplar and an erroneous one from the most
probable noisy class can be constructed. Such an instruction can help any MLLMs
with ICL ability to detect and rectify incorrect predictions of vision models.
Through extensive experiments on ImageNet, WILDS, DomainBed, and other OOD
datasets, we carefully validate the quantitative and qualitative effectiveness
of our method. Our code is available at
https://github.com/tmllab/Machine_Vision_Therapy.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02547" title="Abstract">arXiv:2312.02547</a> [<a href="/pdf/2312.02547" title="Download PDF">pdf</a>, <a href="/format/2312.02547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Optimal Consistency-Robustness Trade-Off for Learning-Augmented  Multi-Option Ski Rental
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shin%2C+Y">Yongho Shin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Changyeol Lee</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+H">Hyung-Chan An</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)

</div>
<p class="mathjax">The learning-augmented multi-option ski rental problem generalizes the
classical ski rental problem in two ways: the algorithm is provided with a
prediction on the number of days we can ski, and the ski rental options now
come with a variety of rental periods and prices to choose from, unlike the
classical two-option setting. Subsequent to the initial study of the
multi-option ski rental problem (without learning augmentation) due to Zhang,
Poon, and Xu, significant progress has been made for this problem recently in
particular. The problem is very well understood when we relinquish one of the
two generalizations -- for the learning-augmented classical ski rental problem,
algorithms giving best-possible trade-off between consistency and robustness
exist; for the multi-option ski rental problem without learning augmentation,
deterministic/randomized algorithms giving the best-possible competitiveness
have been found. However, in presence of both generalizations, there remained a
huge gap between the algorithmic and impossibility results. In fact, for
randomized algorithms, we did not have any nontrivial lower bounds on the
consistency-robustness trade-off before.
<br />This paper bridges this gap for both deterministic and randomized algorithms.
For deterministic algorithms, we present a best-possible algorithm that
completely matches the known lower bound. For randomized algorithms, we show
the first nontrivial lower bound on the consistency-robustness trade-off, and
also present an improved randomized algorithm. Our algorithm matches our lower
bound on robustness within a factor of e/2 when the consistency is at most
1.086.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02548" title="Abstract">arXiv:2312.02548</a> [<a href="/pdf/2312.02548" title="Download PDF">pdf</a>, <a href="/format/2312.02548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GeNIe: Generative Hard Negative Images Through Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koohpayegani%2C+S+A">Soroush Abbasi Koohpayegani</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Anuj Singh</a>, 
<a href="/search/cs?searchtype=author&query=Navaneet%2C+K+L">K L Navaneet</a>, 
<a href="/search/cs?searchtype=author&query=Jamali-Rad%2C+H">Hadi Jamali-Rad</a>, 
<a href="/search/cs?searchtype=author&query=Pirsiavash%2C+H">Hamed Pirsiavash</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our code is available <a href="https://github.com/UCDvision/GeNIe">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Data augmentation is crucial in training deep models, preventing them from
overfitting to limited data. Common data augmentation methods are effective,
but recent advancements in generative AI, such as diffusion models for image
generation, enable more sophisticated augmentation techniques that produce data
resembling natural images. We recognize that augmented samples closer to the
ideal decision boundary of a classifier are particularly effective and
efficient in guiding the learning process. We introduce GeNIe which leverages a
diffusion model conditioned on a text prompt to merge contrasting data points
(an image from the source category and a text prompt from the target category)
to generate challenging samples for the target category. Inspired by recent
image editing methods, we limit the number of diffusion iterations and the
amount of noise. This ensures that the generated image retains low-level and
contextual features from the source image, potentially conflicting with the
target category. Our extensive experiments, in few-shot and also long-tail
distribution settings, demonstrate the effectiveness of our novel augmentation
method, especially benefiting categories with a limited number of examples.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02549" title="Abstract">arXiv:2312.02549</a> [<a href="/pdf/2312.02549" title="Download PDF">pdf</a>, <a href="/format/2312.02549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DemaFormer: Damped Exponential Moving Average Transformer with  Energy-Based Modeling for Temporal Language Grounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thong Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaobao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xinshuai Dong</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+C">Cong-Duy Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+S">See-Kiong Ng</a>, 
<a href="/search/cs?searchtype=author&query=Tuan%2C+L+A">Luu Anh Tuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023 (Findings)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Temporal Language Grounding seeks to localize video moments that semantically
correspond to a natural language query. Recent advances employ the attention
mechanism to learn the relations between video moments and the text query.
However, naive attention might not be able to appropriately capture such
relations, resulting in ineffective distributions where target video moments
are difficult to separate from the remaining ones. To resolve the issue, we
propose an energy-based model framework to explicitly learn moment-query
distributions. Moreover, we propose DemaFormer, a novel Transformer-based
architecture that utilizes exponential moving average with a learnable damping
factor to effectively encode moment-query inputs. Comprehensive experiments on
four public temporal language grounding datasets showcase the superiority of
our methods over the state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02550" title="Abstract">arXiv:2312.02550</a> [<a href="/pdf/2312.02550" title="Download PDF">pdf</a>, <a href="/format/2312.02550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An empirical study of next-basket recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Zhufeng Shao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shoujin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wenpeng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xueping Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Next Basket Recommender Systems (NBRs) function to recommend the subsequent
shopping baskets for users through the modeling of their preferences derived
from purchase history, typically manifested as a sequence of historical
baskets. Given their widespread applicability in the E-commerce industry,
investigations into NBRs have garnered increased attention in recent years.
Despite the proliferation of diverse NBR methodologies, a substantial challenge
lies in the absence of a systematic and unified evaluation framework across
these methodologies. Various studies frequently appraise NBR approaches using
disparate datasets and diverse experimental settings, impeding a fair and
effective comparative assessment of methodological performance. To bridge this
gap, this study undertakes a systematic empirical inquiry into NBRs, reviewing
seminal works within the domain and scrutinizing their respective merits and
drawbacks. Subsequently, we implement designated NBR algorithms on uniform
datasets, employing consistent experimental configurations, and assess their
performances via identical metrics. This methodological rigor establishes a
cohesive framework for the impartial evaluation of diverse NBR approaches. It
is anticipated that this study will furnish a robust foundation and serve as a
pivotal reference for forthcoming research endeavors in this dynamic field.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02554" title="Abstract">arXiv:2312.02554</a> [<a href="/pdf/2312.02554" title="Download PDF">pdf</a>, <a href="/format/2312.02554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ULMA: Unified Language Model Alignment with Demonstration and Point-wise  Human Preference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+T">Tianchi Cai</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xierui Song</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jiyan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+F">Fei Teng</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinjie Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guannan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Language model alignment is a cutting-edge technique in large language model
training to align the model output to user's intent, e.g., being helpful and
harmless. Recent alignment framework consists of two steps: supervised
fine-tuning with demonstration data and preference learning with human
preference data. Previous preference learning methods, such as RLHF and DPO,
mainly focus on pair-wise preference data. However, in many real-world
scenarios where human feedbacks are intrinsically point-wise, these methods
will suffer from information loss or even fail. To fill this gap, in this
paper, we first develop a preference learning method called point-wise DPO to
tackle point-wise preference data. Further revelation on the connection between
supervised fine-tuning and point-wise preference learning enables us to develop
a unified framework for both human demonstration and point-wise preference
data, which sheds new light on the construction of preference dataset.
Extensive experiments on point-wise datasets with binary or continuous labels
demonstrate the superior performance and efficiency of our proposed methods. A
new dataset with high-quality demonstration samples on harmlessness is
constructed and made publicly available.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02556" title="Abstract">arXiv:2312.02556</a> [<a href="/pdf/2312.02556" title="Download PDF">pdf</a>, <a href="/ps/2312.02556" title="Download PostScript">ps</a>, <a href="/format/2312.02556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Blockchain-based Remote Management Systems for Patients with  Movement Disorders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Behara%2C+B">Behnaz Behara</a>, 
<a href="/search/eess?searchtype=author&query=Delrobaei%2C+M">Mehdi Delrobaei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the 31th International Conference on Electrical Engineering (ICEE), Tehran, Iran, May 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Secure storage and sharing of patients' medical data over the Internet are
part of the challenges for emerging healthcare systems. The use of blockchain
technology in medical Internet of things systems can be considered a safe and
novel solution to overcome such challenges. Patients with movement disorders
require multi-disciplinary management and must continuously receive medical
care from a specialist. Due to the increasing costs of face-to-face treatment,
especially during the pandemic, patients would highly benefit from remote
monitoring and management. The proposed work presents a model for
blockchain-based remote management systems for patients with movement
disorders, especially those with Parkinson's disease. The model ensures a high
level of integrity and decreases the security risks of medical data sharing.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02557" title="Abstract">arXiv:2312.02557</a> [<a href="/pdf/2312.02557" title="Download PDF">pdf</a>, <a href="/format/2312.02557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BOgen: Generating Part-Level 3D Designs Based on User Intention  Inference through Bayesian Optimization and Variational Autoencoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S+W">Seung Won Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jiin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Hyun%2C+K+H">Kyung Hoon Hyun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Advancements in generative artificial intelligence (AI) have introduced
various AI models capable of producing impressive visual design outputs.
However, when it comes to AI models in the design process, prioritizing outputs
that align with designers' needs over mere visual craftsmanship becomes even
more crucial. Furthermore, designers often intricately combine parts of various
designs to create novel designs. The ability to generate designs that align
with the designers' intentions at the part level is pivotal for assisting
designers. Hence, we introduced BOgen, which empowers designers to proactively
generate and explore part-level designs through Bayesian optimization and
variational autoencoders, thereby enhancing their overall user experience. We
assessed BOgen's performance using a study involving 30 designers. The results
revealed that, compared to the baseline, BOgen fulfilled the designer
requirements for part recommendations and design exploration space guidance.
BOgen assists designers in navigation and development, offering valuable design
suggestions and fosters proactive design exploration and creation.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02561" title="Abstract">arXiv:2312.02561</a> [<a href="/pdf/2312.02561" title="Download PDF">pdf</a>, <a href="/format/2312.02561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DanZero+: Dominating the GuanDan Game through Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Youpeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yudong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wengang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Houqiang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2210.17087">arXiv:2210.17087</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The utilization of artificial intelligence (AI) in card games has been a
well-explored subject within AI research for an extensive period. Recent
advancements have propelled AI programs to showcase expertise in intricate card
games such as Mahjong, DouDizhu, and Texas Hold'em. In this work, we aim to
develop an AI program for an exceptionally complex and popular card game called
GuanDan. This game involves four players engaging in both competitive and
cooperative play throughout a long process to upgrade their level, posing great
challenges for AI due to its expansive state and action space, long episode
length, and complex rules. Employing reinforcement learning techniques,
specifically Deep Monte Carlo (DMC), and a distributed training framework, we
first put forward an AI program named DanZero for this game. Evaluation against
baseline AI programs based on heuristic rules highlights the outstanding
performance of our bot. Besides, in order to further enhance the AI's
capabilities, we apply policy-based reinforcement learning algorithm to
GuanDan. To address the challenges arising from the huge action space, which
will significantly impact the performance of policy-based algorithms, we adopt
the pre-trained model to facilitate the training process and the achieved AI
program manages to achieve a superior performance.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02566" title="Abstract">arXiv:2312.02566</a> [<a href="/pdf/2312.02566" title="Download PDF">pdf</a>, <a href="/format/2312.02566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structured World Representations in Maze-Solving Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ivanitskiy%2C+M+I">Michael Igorevich Ivanitskiy</a>, 
<a href="/search/cs?searchtype=author&query=Spies%2C+A+F">Alex F. Spies</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%A4uker%2C+T">Tilman R&#xe4;uker</a>, 
<a href="/search/cs?searchtype=author&query=Corlouer%2C+G">Guillaume Corlouer</a>, 
<a href="/search/cs?searchtype=author&query=Mathwin%2C+C">Chris Mathwin</a>, 
<a href="/search/cs?searchtype=author&query=Quirke%2C+L">Lucia Quirke</a>, 
<a href="/search/cs?searchtype=author&query=Rager%2C+C">Can Rager</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+R">Rusheb Shah</a>, 
<a href="/search/cs?searchtype=author&query=Valentine%2C+D">Dan Valentine</a>, 
<a href="/search/cs?searchtype=author&query=Behn%2C+C+D">Cecilia Diniz Behn</a>, 
<a href="/search/cs?searchtype=author&query=Inoue%2C+K">Katsumi Inoue</a>, 
<a href="/search/cs?searchtype=author&query=Fung%2C+S+W">Samy Wu Fung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 18 figures, 15 tables. Corresponding author: Michael Ivanitskiy (mivanits@mines.edu). Code available at <a href="https://github.com/understanding-search/structured-representations-maze-transformers">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Transformer models underpin many recent advances in practical machine
learning applications, yet understanding their internal behavior continues to
elude researchers. Given the size and complexity of these models, forming a
comprehensive picture of their inner workings remains a significant challenge.
To this end, we set out to understand small transformer models in a more
tractable setting: that of solving mazes. In this work, we focus on the
abstractions formed by these models and find evidence for the consistent
emergence of structured internal representations of maze topology and valid
paths. We demonstrate this by showing that the residual stream of only a single
token can be linearly decoded to faithfully reconstruct the entire maze. We
also find that the learned embeddings of individual tokens have spatial
structure. Furthermore, we take steps towards deciphering the circuity of
path-following by identifying attention heads (dubbed $\textit{adjacency
heads}$), which are implicated in finding valid subsequent tokens.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02567" title="Abstract">arXiv:2312.02567</a> [<a href="/pdf/2312.02567" title="Download PDF">pdf</a>, <a href="/format/2312.02567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Think Twice Before Selection: Federated Evidential Active Learning for  Medical Image Analysis with Domain Shifts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiayi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+B">Benteng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+H">Hengfei Cui</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yong Xia</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+K">Kwang-Ting Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Federated learning facilitates the collaborative learning of a global model
across multiple distributed medical institutions without centralizing data.
Nevertheless, the expensive cost of annotation on local clients remains an
obstacle to effectively utilizing local data. To mitigate this issue, federated
active learning methods suggest leveraging local and global model predictions
to select a relatively small amount of informative local data for annotation.
However, existing methods mainly focus on all local data sampled from the same
domain, making them unreliable in realistic medical scenarios with domain
shifts among different clients. In this paper, we make the first attempt to
assess the informativeness of local data derived from diverse domains and
propose a novel methodology termed Federated Evidential Active Learning (FEAL)
to calibrate the data evaluation under domain shift. Specifically, we introduce
a Dirichlet prior distribution in both local and global models to treat the
prediction as a distribution over the probability simplex and capture both
aleatoric and epistemic uncertainties by using the Dirichlet-based evidential
model. Then we employ the epistemic uncertainty to calibrate the aleatoric
uncertainty. Afterward, we design a diversity relaxation strategy to reduce
data redundancy and maintain data diversity. Extensive experiments and analyses
are conducted to show the superiority of FEAL over the state-of-the-art active
learning methods and the efficiency of FEAL under the federated active learning
framework.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02568" title="Abstract">arXiv:2312.02568</a> [<a href="/pdf/2312.02568" title="Download PDF">pdf</a>, <a href="/format/2312.02568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt2NeRF-PIL: Fast NeRF Generation via Pretrained Implicit Latent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianmeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Z">Zeyuan Meng</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+Y">Yu-Wing Tai</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chi-Keung Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper explores promptable NeRF generation (e.g., text prompt or single
image prompt) for direct conditioning and fast generation of NeRF parameters
for the underlying 3D scenes, thus undoing complex intermediate steps while
providing full 3D generation with conditional control. Unlike previous
diffusion-CLIP-based pipelines that involve tedious per-prompt optimizations,
Prompt2NeRF-PIL is capable of generating a variety of 3D objects with a single
forward pass, leveraging a pre-trained implicit latent space of NeRF
parameters. Furthermore, in zero-shot tasks, our experiments demonstrate that
the NeRFs produced by our method serve as semantically informative
initializations, significantly accelerating the inference process of existing
prompt-to-NeRF methods. Specifically, we will show that our approach speeds up
the text-to-NeRF model DreamFusion and the 3D reconstruction speed of the
image-to-NeRF method Zero-1-to-3 by 3 to 5 times.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02572" title="Abstract">arXiv:2312.02572</a> [<a href="/pdf/2312.02572" title="Download PDF">pdf</a>, <a href="/format/2312.02572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Enumeration of Recursive Plans in Transformation-based Query  Optimizers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fejza%2C+A">Amela Fejza</a> (TYREX), 
<a href="/search/cs?searchtype=author&query=Genev%C3%A8s%2C+P">Pierre Genev&#xe8;s</a> (TYREX), 
<a href="/search/cs?searchtype=author&query=Laya%C3%AFda%2C+N">Nabil Laya&#xef;da</a> (TYREX)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Query optimizers built on the transformation-based Volcano/Cascades framework
are used in many database systems. Transformations proposed earlier on the
logical query dag (LQDAG) data structure, which is key in such a framework,
focus only on recursion-free queries. In this paper, we propose the recursive
logical query dag (RLQDAG) which extends the LQDAG with the ability to capture
and transform recursive queries, leveraging recent developments in recursive
relational algebra. Specifically, this extension includes: (i) the ability of
capturing and transforming sets of recursive relational terms thanks to (ii)
annotated equivalence nodes used for guiding transformations that are more
complex in the presence of recursion; and (iii) RLQDAG rewrite rules that
transform sets of subterms in a grouped manner, instead of transforming
individual terms in a sequential manner; and that (iv) incrementally update the
necessary annotations. Core concepts of the RLQDAG are formalized using a
syntax and formal semantics with a particular focus on subterm sharing and
recursion. The result is a clean generalization of the LQDAG
transformation-based approach, enabling more efficient explorations of plan
spaces for recursive queries. An implementation of the proposed approach shows
significant performance gains compared to the state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02573" title="Abstract">arXiv:2312.02573</a> [<a href="/pdf/2312.02573" title="Download PDF">pdf</a>, <a href="/format/2312.02573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UTBoost: A Tree-boosting based System for Uplift Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Junjie Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiangyu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">DongDong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhixiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Bangqi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kai Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Uplift modeling refers to the set of machine learning techniques that a
manager may use to estimate customer uplift, that is, the net effect of an
action on some customer outcome. By identifying the subset of customers for
whom a treatment will have the greatest effect, uplift models assist
decision-makers in optimizing resource allocations and maximizing overall
returns. Accurately estimating customer uplift poses practical challenges, as
it requires assessing the difference between two mutually exclusive outcomes
for each individual. In this paper, we propose two innovative adaptations of
the well-established Gradient Boosting Decision Trees (GBDT) algorithm, which
learn the causal effect in a sequential way and overcome the counter-factual
nature. Both approaches innovate existing techniques in terms of ensemble
learning method and learning objectives, respectively. Experiments on
large-scale datasets demonstrate the usefulness of the proposed methods, which
often yielding remarkable improvements over base models. To facilitate the
application, we develop the UTBoost, an end-to-end tree boosting system
specifically designed for uplift modeling. The package is open source and has
been optimized for training speed to meet the needs of real industrial
applications.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02576" title="Abstract">arXiv:2312.02576</a> [<a href="/pdf/2312.02576" title="Download PDF">pdf</a>, <a href="/format/2312.02576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Integrated System for Spatio-Temporal Summarization of 360-degrees  Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kontostathis%2C+I">Ioannis Kontostathis</a>, 
<a href="/search/cs?searchtype=author&query=Apostolidis%2C+E">Evlampios Apostolidis</a>, 
<a href="/search/cs?searchtype=author&query=Mezaris%2C+V">Vasileios Mezaris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication, 30th Int. Conf. on MultiMedia Modeling (MMM 2024), Amsterdam, NL, Jan.-Feb. 2024. This is the "submitted manuscript" version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this work, we present an integrated system for spatiotemporal
summarization of 360-degrees videos. The video summary production mainly
involves the detection of salient events and their synopsis into a concise
summary. The analysis relies on state-of-the-art methods for saliency detection
in 360-degrees video (ATSal and SST-Sal) and video summarization (CA-SUM). It
also contains a mechanism that classifies a 360-degrees video based on the use
of static or moving camera during recording and decides which saliency
detection method will be used, as well as a 2D video production component that
is responsible to create a conventional 2D video containing the salient events
in the 360-degrees video. Quantitative evaluations using two datasets for
360-degrees video saliency detection (VR-EyeTracking, Sports-360) show the
accuracy and positive impact of the developed decision mechanism, and justify
our choice to use two different methods for detecting the salient events. A
qualitative analysis using content from these datasets, gives further insights
about the functionality of the decision mechanism, shows the pros and cons of
each used saliency detection method and demonstrates the advanced performance
of the trained summarization method against a more conventional approach.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02578" title="Abstract">arXiv:2312.02578</a> [<a href="/pdf/2312.02578" title="Download PDF">pdf</a>, <a href="/format/2312.02578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empathy and Distress Detection using Ensembles of Transformer Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chavan%2C+T">Tanmay Chavan</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+K">Kshitij Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Sonawane%2C+S">Sheetal Sonawane</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the WASSA 2023 workshop at ACL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper presents our approach for the WASSA 2023 Empathy, Emotion and
Personality Shared Task. Empathy and distress are human feelings that are
implicitly expressed in natural discourses. Empathy and distress detection are
crucial challenges in Natural Language Processing that can aid our
understanding of conversations. The provided dataset consists of several
long-text examples in the English language, with each example associated with a
numeric score for empathy and distress. We experiment with several BERT-based
models as a part of our approach. We also try various ensemble methods. Our
final submission has a Pearson's r score of 0.346, placing us third in the
empathy and distress detection subtask.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02585" title="Abstract">arXiv:2312.02585</a> [<a href="/pdf/2312.02585" title="Download PDF">pdf</a>, <a href="/format/2312.02585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CVE representation to build attack positions graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poisson%2C+M">Manuel Poisson</a> (CIDRE), 
<a href="/search/cs?searchtype=author&query=Tong%2C+V+V+T">Val&#xe9;rie Viet Triem Tong</a> (CIDRE), 
<a href="/search/cs?searchtype=author&query=Guette%2C+G">Gilles Guette</a> (CIDRE), 
<a href="/search/cs?searchtype=author&query=Guih%C3%A9ry%2C+F">Fr&#xe9;d&#xe9;ric Guih&#xe9;ry</a>, 
<a href="/search/cs?searchtype=author&query=Cr%C3%A9milleux%2C+D">Damien Cr&#xe9;milleux</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> CyberHunt 2023, Workshop on Cyber Threat Intelligence and Hunting,
  IEEE BigData, Dec 2023, Sorrento, Italy. pp.1-5
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In cybersecurity, CVEs (Common Vulnerabilities and Exposures) are publicly
disclosed hardware or software vulnerabilities. These vulnerabilities are
documented and listed in the NVD database maintained by the NIST. Knowledge of
the CVEs impacting an information system provides a measure of its level of
security. This article points out that these vulnerabilities should be
described in greater detail to understand how they could be chained together in
a complete attack scenario. This article presents the first proposal for the
CAPG format, which is a method for representing a CVE vulnerability, a
corresponding exploit, and associated attack positions.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02586" title="Abstract">arXiv:2312.02586</a> [<a href="/pdf/2312.02586" title="Download PDF">pdf</a>, <a href="/ps/2312.02586" title="Download PostScript">ps</a>, <a href="/format/2312.02586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mapping the Information Journey: Unveiling the Documentation Experience  of Software Developers in China
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhijun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiangying Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Meina Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">This research delves into understanding the behaviors and characteristics of
Chinese developers in relation to their use of technical documentation, which
is crucial for creating high-quality developer documentation. We conducted
interviews with 25 software developers and surveyed 177 participants, using the
preliminary interview findings to inform the survey design. Our approach
encompassed traditional user research methods, including persona and user
journey mapping, to develop typical personas and information journeys based on
the qualitative data from the interviews and quantitative results from the
survey. Our results revealed distinct characteristics and differences between
junior and senior developers in terms of their use of technical documentation,
broadly categorized into personality traits, learning habits, and working
habits. We observed that the information journey of both groups typically
encompasses four stages: Exploration, Understanding, Practice, and Application.
Consequently, we created two distinct personas and information journey maps to
represent these two developer groups. Our findings highlight that developers
prioritize the content, organization, and maintenance aspects of documentation.
In conclusion, we recommend organizing documentation content to align with
developers' information journeys, tailoring documentation to meet the needs of
developers at various levels, and focusing on the content, organization, and
maintenance aspects of documentation.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02589" title="Abstract">arXiv:2312.02589</a> [<a href="/pdf/2312.02589" title="Download PDF">pdf</a>, <a href="/format/2312.02589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ESP2CS: Securing Internet of Vehicles through Blockchain-enabled  Communications and Payments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jabbar%2C+R">Rateb Jabbar</a>, 
<a href="/search/cs?searchtype=author&query=Kharbeche%2C+M">Mohamed Kharbeche</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first GCC Engineering Symposium, GCCENG23, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The burgeoning domain of the Internet of Vehicles (IoV), a subset of the
Internet of Things (IoT), promises to revolutionize transportation through
enhanced safety, efficiency, and environmental sustainability. By amalgamating
technologies like sensors and cloud computing, the IoV paves the way for
optimized traffic management, heightened vehicle safety, and the birth of novel
business paradigms. However, this growth is shadowed by significant security
concerns, especially in the communication and payment sectors. Addressing the
pressing need for secure Vehicle to Everything (V2X) communications and
payments amidst rising cyber threats, this research introduces the Ethereum
based Secure Payment and Communication Solution (ESP2CS). Utilizing Ethereum as
a middleware, ESP2CS ensures robust and secure V2X interactions. The solution
is complemented by an Android Auto application for vehicles, streamlining inter
vehicle communication, parking space detection, and transaction management.
Furthermore, dedicated Android applications are developed for parking space
renters and the parking IoT system. Preliminary evaluations underscore ESP2CS's
superior cost effectiveness, integrity and consistency over contemporary
solutions, with Ethereum bolstering both security and efficiency.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02590" title="Abstract">arXiv:2312.02590</a> [<a href="/pdf/2312.02590" title="Download PDF">pdf</a>, <a href="/format/2312.02590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text Intimacy Analysis using Ensembles of Multilingual Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chavan%2C+T">Tanmay Chavan</a>, 
<a href="/search/cs?searchtype=author&query=Patwardhan%2C+V">Ved Patwardhan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Intimacy estimation of a given text has recently gained importance due to the
increase in direct interaction of NLP systems with humans. Intimacy is an
important aspect of natural language and has a substantial impact on our
everyday communication. Thus the level of intimacy can provide us with deeper
insights and richer semantics of conversations. In this paper, we present our
work on the SemEval shared task 9 on predicting the level of intimacy for the
given text. The dataset consists of tweets in ten languages, out of which only
six are available in the training dataset. We conduct several experiments and
show that an ensemble of multilingual models along with a language-specific
monolingual model has the best performance. We also evaluate other data
augmentation methods such as translation and present the results. Lastly, we
study the results thoroughly and present some noteworthy insights into this
problem.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02592" title="Abstract">arXiv:2312.02592</a> [<a href="/pdf/2312.02592" title="Download PDF">pdf</a>, <a href="/format/2312.02592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FRAPP&#xc9;: A Post-Processing Framework for Group Fairness Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C5%A2ifrea%2C+A">Alexandru &#x162;ifrea</a>, 
<a href="/search/cs?searchtype=author&query=Lahoti%2C+P">Preethi Lahoti</a>, 
<a href="/search/cs?searchtype=author&query=Packer%2C+B">Ben Packer</a>, 
<a href="/search/cs?searchtype=author&query=Halpern%2C+Y">Yoni Halpern</a>, 
<a href="/search/cs?searchtype=author&query=Beirami%2C+A">Ahmad Beirami</a>, 
<a href="/search/cs?searchtype=author&query=Prost%2C+F">Flavien Prost</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presubmission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Post-processing mitigation techniques for group fairness generally adjust the
decision threshold of a base model in order to improve fairness. Methods in
this family exhibit several advantages that make them appealing in practice:
post-processing requires no access to the model training pipeline, is agnostic
to the base model architecture, and offers a reduced computation cost compared
to in-processing. Despite these benefits, existing methods face other
challenges that limit their applicability: they require knowledge of the
sensitive attributes at inference time and are oftentimes outperformed by
in-processing. In this paper, we propose a general framework to transform any
in-processing method with a penalized objective into a post-processing
procedure. The resulting method is specifically designed to overcome the
aforementioned shortcomings of prior post-processing approaches. Furthermore,
we show theoretically and through extensive experiments on real-world data that
the resulting post-processing method matches or even surpasses the
fairness-error trade-off offered by the in-processing counterpart.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02593" title="Abstract">arXiv:2312.02593</a> [<a href="/pdf/2312.02593" title="Download PDF">pdf</a>, <a href="/format/2312.02593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 6D Assembly Pose Estimation by Point Cloud Registration for Robot  Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Samarawickrama%2C+K">K. Samarawickrama</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+G">G. Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Angleraud%2C+A">A. Angleraud</a>, 
<a href="/search/cs?searchtype=author&query=Pieters%2C+R">R. Pieters</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The demands on robotic manipulation skills to perform challenging tasks have
drastically increased in recent times. To perform these tasks with dexterity,
robots require perception tools to understand the scene and extract useful
information that transforms to robot control inputs. To this end, recent
research has introduced various object pose estimation and grasp pose detection
methods that yield precise results. Assembly pose estimation is a secondary yet
highly desirable skill in robotic assembling as it requires more detailed
information on object placement as compared to bin picking and pick-and-place
tasks. However, it has been often overlooked in research due to the complexity
of integration in an agile framework. To address this issue, we propose an
assembly pose estimation method with RGB-D input and 3D CAD models of the
associated objects. The framework consists of semantic segmentation of the
scene and registering point clouds of local surfaces against target point
clouds derived from CAD models to estimate 6D poses. We show that our method
can deliver sufficient accuracy for assembling object assemblies using
evaluation metrics and demonstrations. The source code and dataset for the work
can be found at: https://github.com/KulunuOS/6DAPose
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02595" title="Abstract">arXiv:2312.02595</a> [<a href="/pdf/2312.02595" title="Download PDF">pdf</a>, <a href="/format/2312.02595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Fairness Scheduling for Coded Caching in Multi-AP Multi-antenna  WLAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akcay%2C+K">Kagan Akcay</a>, 
<a href="/search/cs?searchtype=author&query=Salehi%2C+M">MohammadJavad Salehi</a>, 
<a href="/search/cs?searchtype=author&query=T%C3%B6lli%2C+A">Antti T&#xf6;lli</a>, 
<a href="/search/cs?searchtype=author&query=Caire%2C+G">Giuseppe Caire</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Coded caching (CC) schemes exploit the cumulative cache memory of network
users, outperforming traditional uncoded schemes where cache contents are only
used locally. Interestingly, this CC gain can also be combined with the spatial
multiplexing gain of multi-antenna transmissions. In this paper, we extend the
existing results of CC-aided data delivery in multi-access point (AP) wireless
local area networks (WLAN) and video streaming applications by assuming
multi-antenna transmitters at AP nodes. We present two distinct methods for
using the extra resource that multi-antenna transmitters provide. While the
first method tries to reduce the number of interference links in the network
graph, the second one aims to remove inter-stream interference so that users
with similar cache contents can be served simultaneously. While both methods
provide increased throughput, they differ significantly in the underlying
concept. Numerical simulations are used to compare the performance of different
methods.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02596" title="Abstract">arXiv:2312.02596</a> [<a href="/pdf/2312.02596" title="Download PDF">pdf</a>, <a href="/format/2312.02596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TSVR+: Twin support vector regression with privileged information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumari%2C+A">Anuradha Kumari</a>, 
<a href="/search/cs?searchtype=author&query=Tanveer%2C+M">M. Tanveer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In the realm of machine learning, the data may contain additional attributes,
known as privileged information (PI). The main purpose of PI is to assist in
the training of the model and then utilize the acquired knowledge to make
predictions for unseen samples. Support vector regression (SVR) is an effective
regression model, however, it has a low learning speed due to solving a convex
quadratic problem (QP) subject to a pair of constraints. In contrast, twin
support vector regression (TSVR) is more efficient than SVR as it solves two
QPs each subject to one set of constraints. However, TSVR and its variants are
trained only on regular features and do not use privileged features for
training. To fill this gap, we introduce a fusion of TSVR with learning using
privileged information (LUPI) and propose a novel approach called twin support
vector regression with privileged information (TSVR+). The regularization terms
in the proposed TSVR+ capture the essence of statistical learning theory and
implement the structural risk minimization principle. We use the successive
overrelaxation (SOR) technique to solve the optimization problem of the
proposed TSVR+, which enhances the training efficiency. As far as our knowledge
extends, the integration of the LUPI concept into twin variants of regression
models is a novel advancement. The numerical experiments conducted on UCI,
stock and time series data collectively demonstrate the superiority of the
proposed model.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02598" title="Abstract">arXiv:2312.02598</a> [<a href="/pdf/2312.02598" title="Download PDF">pdf</a>, <a href="/format/2312.02598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impact of Tokenization on LLaMa Russian Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tikhomirov%2C+M">Mikhail Tikhomirov</a>, 
<a href="/search/cs?searchtype=author&query=Chernyshev%2C+D">Daniil Chernyshev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Latest instruction-tuned large language models (LLM) show great results on
various tasks, however, they often face performance degradation for non-English
input. There is evidence that the reason lies in inefficient tokenization
caused by low language representation in pre-training data which hinders the
comprehension of non-English instructions, limiting the potential of target
language instruction-tuning. In this work we investigate the possibility of
addressing the issue with vocabulary substitution in the context of LLaMa
Russian language adaptation. We explore three variants of vocabulary adaptation
and test their performance on Saiga instruction-tuning and fine-tuning on
Russian Super Glue benchmark. The results of automatic evaluation show that
vocabulary substitution not only improves the model's quality in Russian but
also accelerates fine-tuning (35%) and inference (up to 60%) while reducing
memory consumption. Additional human evaluation of the instruction-tuned models
demonstrates that models with Russian-adapted vocabulary generate answers with
higher user preference than the original Saiga-LLaMa model.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02599" title="Abstract">arXiv:2312.02599</a> [<a href="/pdf/2312.02599" title="Download PDF">pdf</a>, <a href="/format/2312.02599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAINS: A Magnetic Field Aided Inertial Navigation System for Indoor  Positioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hendeby%2C+G">Gustaf Hendeby</a>, 
<a href="/search/cs?searchtype=author&query=Fourati%2C+H">Hassen Fourati</a>, 
<a href="/search/cs?searchtype=author&query=Prieur%2C+C">Christophe Prieur</a>, 
<a href="/search/cs?searchtype=author&query=Skog%2C+I">Isaac Skog</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">A Magnetic field Aided Inertial Navigation System (MAINS) for indoor
navigation is proposed in this paper. MAINS leverages an array of magnetometers
to measure spatial variations in the magnetic field, which are then used to
estimate the displacement and orientation changes of the system, thereby aiding
the inertial navigation system (INS). Experiments show that MAINS significantly
outperforms the stand-alone INS, demonstrating a remarkable two orders of
magnitude reduction in position error. Furthermore, when compared to the
state-of-the-art magnetic-field-aided navigation approach, the proposed method
exhibits slightly improved horizontal position accuracy. On the other hand, it
has noticeably larger vertical error on datasets with large magnetic field
variations. However, one of the main advantages of MAINS compared to the
state-of-the-art is that it enables flexible sensor configurations. The
experimental results show that the position error after 2 minutes of navigation
in most cases is less than 3 meters when using an array of 30 magnetometers.
Thus, the proposed navigation solution has the potential to solve one of the
key challenges faced with current magnetic-field simultaneous localization and
mapping (SLAM) solutions: the very limited allowable length of the exploration
phase during which unvisited areas are mapped.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02601" title="Abstract">arXiv:2312.02601</a> [<a href="/pdf/2312.02601" title="Download PDF">pdf</a>, <a href="/format/2312.02601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Neural Receiver for 5G NR Multi-user MIMO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cammerer%2C+S">Sebastian Cammerer</a>, 
<a href="/search/cs?searchtype=author&query=Aoudia%2C+F+A">Fay&#xe7;al A&#xef;t Aoudia</a>, 
<a href="/search/cs?searchtype=author&query=Hoydis%2C+J">Jakob Hoydis</a>, 
<a href="/search/cs?searchtype=author&query=Oeldemann%2C+A">Andreas Oeldemann</a>, 
<a href="/search/cs?searchtype=author&query=Roessler%2C+A">Andreas Roessler</a>, 
<a href="/search/cs?searchtype=author&query=Mayer%2C+T">Timo Mayer</a>, 
<a href="/search/cs?searchtype=author&query=Keller%2C+A">Alexander Keller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures, presented at IEEE Globecom 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">We introduce a neural network (NN)-based multiuser multiple-input
multiple-output (MU-MIMO) receiver with 5G New Radio (5G NR) physical uplink
shared channel (PUSCH) compatibility. The NN architecture is based on
convolution layers to exploit the time and frequency correlation of the channel
and a graph neural network (GNN) to handle multiple users. The proposed
architecture adapts to an arbitrary number of sub-carriers and supports a
varying number of multiple-input multiple-output (MIMO) layers and users
without the need for any retraining. The receiver operates on an entire 5G NR
slot, i.e., processes the entire received orthogonal frequency division
multiplexing (OFDM) time-frequency resource grid by jointly performing channel
estimation, equalization, and demapping. The proposed architecture operates
less than 1 dB away from a baseline using linear minimum mean square error
(LMMSE) channel estimation with K-best detection but benefits from a
significantly lower computational complexity. We show the importance of a
carefully designed training process such that the trained receiver is universal
for a wide range of different unseen channel conditions. Finally, we
demonstrate the results of a hardware-in-the-loop verification based on 3GPP
compliant conformance test scenarios.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02603" title="Abstract">arXiv:2312.02603</a> [<a href="/pdf/2312.02603" title="Download PDF">pdf</a>, <a href="/format/2312.02603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Robot Path Planning for Visual Inspection from Object Shape
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tasneem%2C+O">O. Tasneem</a>, 
<a href="/search/cs?searchtype=author&query=Pieters%2C+R">R. Pieters</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Visual inspection is a crucial yet time-consuming task across various
industries. Numerous established methods employ machine learning in inspection
tasks, necessitating specific training data that includes predefined inspection
poses and training images essential for the training of models. The acquisition
of such data and their integration into an inspection framework is challenging
due to the variety in objects and scenes involved and due to additional
bottlenecks caused by the manual collection of training data by humans, thereby
hindering the automation of visual inspection across diverse domains. This work
proposes a solution for automatic path planning using a single depth camera
mounted on a robot manipulator. Point clouds obtained from the depth images are
processed and filtered to extract object profiles and transformed to inspection
target paths for the robot end-effector. The approach relies on the geometry of
the object and generates an inspection path that follows the shape normal to
the surface. Depending on the object size and shape, inspection paths can be
defined as single or multi-path plans. Results are demonstrated in both
simulated and real-world environments, yielding promising inspection paths for
objects with varying sizes and shapes. Code and video are open-source available
at: https://github.com/CuriousLad1000/Auto-Path-Planner
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02607" title="Abstract">arXiv:2312.02607</a> [<a href="/pdf/2312.02607" title="Download PDF">pdf</a>, <a href="/ps/2312.02607" title="Download PostScript">ps</a>, <a href="/format/2312.02607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Projective Space Stern Decoding and Application to SDitH
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carrier%2C+K">Kevin Carrier</a>, 
<a href="/search/cs?searchtype=author&query=Hatey%2C+V">Val&#xe9;rian Hatey</a>, 
<a href="/search/cs?searchtype=author&query=Tillich%2C+J">Jean-Pierre Tillich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">We show that here standard decoding algorithms for generic linear codes over
a finite field can speeded up by a factor which is essentially the size of the
finite field by reducing it to a low weight codeword problem and working in the
relevant projective space. We apply this technique to SDitH and show that the
parameters of both the original submission and the updated version fall short
of meeting the security requirements asked by the NIST.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02608" title="Abstract">arXiv:2312.02608</a> [<a href="/pdf/2312.02608" title="Download PDF">pdf</a>, <a href="/format/2312.02608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Panoptica -- instance-wise evaluation of 3D semantic and instance  segmentation maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kofler%2C+F">Florian Kofler</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%B6ller%2C+H">Hendrik M&#xf6;ller</a>, 
<a href="/search/cs?searchtype=author&query=Buchner%2C+J+A">Josef A. Buchner</a>, 
<a href="/search/cs?searchtype=author&query=de+la+Rosa%2C+E">Ezequiel de la Rosa</a>, 
<a href="/search/cs?searchtype=author&query=Ezhov%2C+I">Ivan Ezhov</a>, 
<a href="/search/cs?searchtype=author&query=Rosier%2C+M">Marcel Rosier</a>, 
<a href="/search/cs?searchtype=author&query=Mekki%2C+I">Isra Mekki</a>, 
<a href="/search/cs?searchtype=author&query=Shit%2C+S">Suprosanna Shit</a>, 
<a href="/search/cs?searchtype=author&query=Negwer%2C+M">Moritz Negwer</a>, 
<a href="/search/cs?searchtype=author&query=Al-Maskari%2C+R">Rami Al-Maskari</a>, 
<a href="/search/cs?searchtype=author&query=Ert%C3%BCrk%2C+A">Ali Ert&#xfc;rk</a>, 
<a href="/search/cs?searchtype=author&query=Vinayahalingam%2C+S">Shankeeth Vinayahalingam</a>, 
<a href="/search/cs?searchtype=author&query=Isensee%2C+F">Fabian Isensee</a>, 
<a href="/search/cs?searchtype=author&query=Pati%2C+S">Sarthak Pati</a>, 
<a href="/search/cs?searchtype=author&query=Rueckert%2C+D">Daniel Rueckert</a>, 
<a href="/search/cs?searchtype=author&query=Kirschke%2C+J+S">Jan S. Kirschke</a>, 
<a href="/search/cs?searchtype=author&query=Ehrlich%2C+S+K">Stefan K. Ehrlich</a>, 
<a href="/search/cs?searchtype=author&query=Reinke%2C+A">Annika Reinke</a>, 
<a href="/search/cs?searchtype=author&query=Menze%2C+B">Bjoern Menze</a>, 
<a href="/search/cs?searchtype=author&query=Wiestler%2C+B">Benedikt Wiestler</a>, 
<a href="/search/cs?searchtype=author&query=Piraud%2C+M">Marie Piraud</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 6 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">This paper introduces panoptica, a versatile and performance-optimized
package designed for computing instance-wise segmentation quality metrics from
2D and 3D segmentation maps. panoptica addresses the limitations of existing
metrics and provides a modular framework that complements the original
intersection over union-based panoptic quality with other metrics, such as the
distance metric Average Symmetric Surface Distance. The package is open-source,
implemented in Python, and accompanied by comprehensive documentation and
tutorials. panoptica employs a three-step metrics computation process to cover
diverse use cases. The efficacy of panoptica is demonstrated on various
real-world biomedical datasets, where an instance-wise evaluation is
instrumental for an accurate representation of the underlying clinical task.
Overall, we envision panoptica as a valuable tool facilitating in-depth
evaluation of segmentation methods.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02611" title="Abstract">arXiv:2312.02611</a> [<a href="/pdf/2312.02611" title="Download PDF">pdf</a>, <a href="/format/2312.02611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Aware Data Acquisition under Data Similarity in Regression  Markets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pandey%2C+S+R">Shashi Raj Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Pinson%2C+P">Pierre Pinson</a>, 
<a href="/search/cs?searchtype=author&query=Popovski%2C+P">Petar Popovski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transactions on Neural Networks and Learning Systems (submission version)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Data markets facilitate decentralized data exchange for applications such as
prediction, learning, or inference. The design of these markets is challenged
by varying privacy preferences as well as data similarity among data owners.
Related works have often overlooked how data similarity impacts pricing and
data value through statistical information leakage. We demonstrate that data
similarity and privacy preferences are integral to market design and propose a
query-response protocol using local differential privacy for a two-party data
acquisition mechanism. In our regression data market model, we analyze
strategic interactions between privacy-aware owners and the learner as a
Stackelberg game over the asked price and privacy factor. Finally, we
numerically evaluate how data similarity affects market participation and
traded data value.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02613" title="Abstract">arXiv:2312.02613</a> [<a href="/pdf/2312.02613" title="Download PDF">pdf</a>, <a href="/format/2312.02613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Simulation Framework for Visual and Behavioral Fidelity in  Crowd Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bisagno%2C+N">Niccol&#xf2; Bisagno</a>, 
<a href="/search/cs?searchtype=author&query=Garau%2C+N">Nicola Garau</a>, 
<a href="/search/cs?searchtype=author&query=Stefani%2C+A+L">Antonio Luigi Stefani</a>, 
<a href="/search/cs?searchtype=author&query=Conci%2C+N">Nicola Conci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Simulation is a powerful tool to easily generate annotated data, and a highly
desirable feature, especially in those domains where learning models need large
training datasets. Machine learning and deep learning solutions, have proven to
be extremely data-hungry and sometimes, the available real-world data are not
sufficient to effectively model the given task. Despite the initial skepticism
of a portion of the scientific community, the potential of simulation has been
largely confirmed in many application areas, and the recent developments in
terms of rendering and virtualization engines, have shown a good ability also
in representing complex scenes. This includes environmental factors, such as
weather conditions and surface reflectance, as well as human-related events,
like human actions and behaviors. We present a human crowd simulator, called
UniCrowd, and its associated validation pipeline. We show how the simulator can
generate annotated data, suitable for computer vision tasks, in particular for
detection and segmentation, as well as the related applications, as crowd
counting, human pose estimation, trajectory analysis and prediction, and
anomaly detection.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02614" title="Abstract">arXiv:2312.02614</a> [<a href="/pdf/2312.02614" title="Download PDF">pdf</a>, <a href="/format/2312.02614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Optimization via Adversarial In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Do%2C+X+L">Xuan Long Do</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yiran Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+H">Hannah Brown</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yuxi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J+X">James Xu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N+F">Nancy F. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kawaguchi%2C+K">Kenji Kawaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+M+Q">Michael Qizhe Xie</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junxian He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">We propose a new method, Adversarial In-Context Learning (adv-ICL), to
optimize prompt for in-context learning (ICL) by employing one LLM as a
generator, another as a discriminator, and a third as a prompt modifier. As in
traditional adversarial learning, adv-ICL is implemented as a two-player game
between the generator and discriminator, where the generator tries to generate
realistic enough output to fool the discriminator. In each round, given an
input prefixed by task instructions and several exemplars, the generator
produces an output. The discriminator is then tasked with classifying the
generator input-output pair as model-generated or real data. Based on the
discriminator loss, the prompt modifier proposes possible edits to the
generator and discriminator prompts, and the edits that most improve the
adversarial loss are selected. We show that adv-ICL results in significant
improvements over state-of-the-art prompt optimization techniques for both open
and closed-source models on 11 generation and classification tasks including
summarization, arithmetic reasoning, machine translation, data-to-text
generation, and the MMLU and big-bench hard benchmarks. In addition, because
our method uses pre-trained models and updates only prompts rather than model
parameters, it is computationally efficient, easy to extend to any LLM and
task, and effective in low-resource settings.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02615" title="Abstract">arXiv:2312.02615</a> [<a href="/pdf/2312.02615" title="Download PDF">pdf</a>, <a href="/format/2312.02615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Projection Regret: Reducing Background Bias for Novelty Detection via  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Sungik Choi</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hankook Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Honglak Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Moontae Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Novelty detection is a fundamental task of machine learning which aims to
detect abnormal ($\textit{i.e.}$ out-of-distribution (OOD)) samples. Since
diffusion models have recently emerged as the de facto standard generative
framework with surprising generation results, novelty detection via diffusion
models has also gained much attention. Recent methods have mainly utilized the
reconstruction property of in-distribution samples. However, they often suffer
from detecting OOD samples that share similar background information to the
in-distribution data. Based on our observation that diffusion models can
\emph{project} any sample to an in-distribution sample with similar background
information, we propose \emph{Projection Regret (PR)}, an efficient novelty
detection method that mitigates the bias of non-semantic information. To be
specific, PR computes the perceptual distance between the test image and its
diffusion-based projection to detect abnormality. Since the perceptual distance
often fails to capture semantic changes when the background information is
dominant, we cancel out the background bias by comparing it against recursive
projections. Extensive experiments demonstrate that PR outperforms the prior
art of generative-model-based novelty detection methods by a significant
margin.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02616" title="Abstract">arXiv:2312.02616</a> [<a href="/pdf/2312.02616" title="Download PDF">pdf</a>, <a href="/format/2312.02616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Facilitating the Production of Well-tailored Video Summaries for Sharing  on Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Apostolidis%2C+E">Evlampios Apostolidis</a>, 
<a href="/search/cs?searchtype=author&query=Apostolidis%2C+K">Konstantinos Apostolidis</a>, 
<a href="/search/cs?searchtype=author&query=Mezaris%2C+V">Vasileios Mezaris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication, 30th Int. Conf. on MultiMedia Modeling (MMM 2024), Amsterdam, NL, Jan.-Feb. 2024. This is the "submitted manuscript" version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents a web-based tool that facilitates the production of
tailored summaries for online sharing on social media. Through an interactive
user interface, it supports a ``one-click'' video summarization process. Based
on the integrated AI models for video summarization and aspect ratio
transformation, it facilitates the generation of multiple summaries of a
full-length video according to the needs of target platforms with regard to the
video's length and aspect ratio.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02617" title="Abstract">arXiv:2312.02617</a> [<a href="/pdf/2312.02617" title="Download PDF">pdf</a>, <a href="/format/2312.02617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreaMo: Articulated 3D Reconstruction From A Single Casual Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tu%2C+T">Tao Tu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming-Feng Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C+H">Chieh Hubert Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yen-Chi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Min Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://ttaoretw.github.io/dreamo/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Articulated 3D reconstruction has valuable applications in various domains,
yet it remains costly and demands intensive work from domain experts. Recent
advancements in template-free learning methods show promising results with
monocular videos. Nevertheless, these approaches necessitate a comprehensive
coverage of all viewpoints of the subject in the input video, thus limiting
their applicability to casually captured videos from online sources. In this
work, we study articulated 3D shape reconstruction from a single and casually
captured internet video, where the subject's view coverage is incomplete. We
propose DreaMo that jointly performs shape reconstruction while solving the
challenging low-coverage regions with view-conditioned diffusion prior and
several tailored regularizations. In addition, we introduce a skeleton
generation strategy to create human-interpretable skeletons from the learned
neural bones and skinning weights. We conduct our study on a self-collected
internet video collection characterized by incomplete view coverage. DreaMo
shows promising quality in novel-view rendering, detailed articulated shape
reconstruction, and skeleton generation. Extensive qualitative and quantitative
studies validate the efficacy of each proposed component, and show existing
methods are unable to solve correct geometry due to the incomplete view
coverage.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02619" title="Abstract">arXiv:2312.02619</a> [<a href="/pdf/2312.02619" title="Download PDF">pdf</a>, <a href="/format/2312.02619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking and Simplifying Bootstrapped Graph Latents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wangbin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jintang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bingzhe Wu</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+Y">Yatao Bian</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zibin Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WSDM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph contrastive learning (GCL) has emerged as a representative paradigm in
graph self-supervised learning, where negative samples are commonly regarded as
the key to preventing model collapse and producing distinguishable
representations. Recent studies have shown that GCL without negative samples
can achieve state-of-the-art performance as well as scalability improvement,
with bootstrapped graph latent (BGRL) as a prominent step forward. However,
BGRL relies on a complex architecture to maintain the ability to scatter
representations, and the underlying mechanisms enabling the success remain
largely unexplored. In this paper, we introduce an instance-level decorrelation
perspective to tackle the aforementioned issue and leverage it as a springboard
to reveal the potential unnecessary model complexity within BGRL. Based on our
findings, we present SGCL, a simple yet effective GCL framework that utilizes
the outputs from two consecutive iterations as positive pairs, eliminating the
negative samples. SGCL only requires a single graph augmentation and a single
graph encoder without additional parameters. Extensive experiments conducted on
various graph benchmarks demonstrate that SGCL can achieve competitive
performance with fewer parameters, lower time and space costs, and significant
convergence speedup.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02622" title="Abstract">arXiv:2312.02622</a> [<a href="/pdf/2312.02622" title="Download PDF">pdf</a>, <a href="/format/2312.02622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Initialization of Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiahang Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yakun Song</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xiang Song</a>, 
<a href="/search/cs?searchtype=author&query=Wipf%2C+D+P">David Paul Wipf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Graph Neural Networks (GNNs) have displayed considerable promise in graph
representation learning across various applications. The core learning process
requires the initialization of model weight matrices within each GNN layer,
which is typically accomplished via classic initialization methods such as
Xavier initialization. However, these methods were originally motivated to
stabilize the variance of hidden embeddings and gradients across layers of
Feedforward Neural Networks (FNNs) and Convolutional Neural Networks (CNNs) to
avoid vanishing gradients and maintain steady information flow. In contrast,
within the GNN context classical initializations disregard the impact of the
input graph structure and message passing on variance. In this paper, we
analyze the variance of forward and backward propagation across GNN layers and
show that the variance instability of GNN initializations comes from the
combined effect of the activation function, hidden dimension, graph structure
and message passing. To better account for these influence factors, we propose
a new initialization method for Variance Instability Reduction within GNN
Optimization (Virgo), which naturally tends to equate forward and backward
variances across successive layers. We conduct comprehensive experiments on 15
datasets to show that Virgo can lead to superior model performance and more
stable variance at initialization on node classification, link prediction and
graph classification tasks. Codes are in
https://github.com/LspongebobJH/virgo_icml2023.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02625" title="Abstract">arXiv:2312.02625</a> [<a href="/pdf/2312.02625" title="Download PDF">pdf</a>, <a href="/format/2312.02625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Noise Feature: Accurate and Fast Generated Image Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yichi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaogang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generative models have reached an advanced stage where they can produce
remarkably realistic images. However, this remarkable generative capability
also introduces the risk of disseminating false or misleading information.
Notably, existing image detectors for generated images encounter challenges
such as low accuracy and limited generalization. This paper seeks to address
this issue by seeking a representation with strong generalization capabilities
to enhance the detection of generated images. Our investigation has revealed
that real and generated images display distinct latent Gaussian representations
when subjected to an inverse diffusion process within a pre-trained diffusion
model. Exploiting this disparity, we can amplify subtle artifacts in generated
images. Building upon this insight, we introduce a novel image representation
known as Diffusion Noise Feature (DNF). DNF is an ensemble representation that
estimates the noise generated during the inverse diffusion process. A simple
classifier, e.g., ResNet, trained on DNF achieves high accuracy, robustness,
and generalization capabilities for detecting generated images, even from
previously unseen classes or models. We conducted experiments using a widely
recognized and standard dataset, achieving state-of-the-art effects of
Detection.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02632" title="Abstract">arXiv:2312.02632</a> [<a href="/pdf/2312.02632" title="Download PDF">pdf</a>, <a href="/format/2312.02632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Good Is Open Bicycle Infrastructure Data? A Countrywide Case Study  of Denmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vier%C3%B8%2C+A+R">Ane Rahbek Vier&#xf8;</a>, 
<a href="/search/cs?searchtype=author&query=Vybornova%2C+A">Anastassia Vybornova</a>, 
<a href="/search/cs?searchtype=author&query=Szell%2C+M">Michael Szell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Cycling is a key ingredient for a sustainability shift of Denmark's
transportation system. To increase cycling rates, a better nationwide network
of bicycle infrastructure is required. Planning such a network requires
high-quality infrastructure data, however, the quality of bicycle
infrastructure data is severely understudied. Here, we compare Denmark's two
largest open data sets on dedicated bicycle infrastructure, OpenStreetMap (OSM)
and GeoDanmark, in a countrywide data quality assessment, asking whether data
is good enough for network-based analysis of cycling conditions. We find that
neither of the data sets is of sufficient quality, and that data set conflation
is necessary to obtain a complete dataset. Our analysis of the spatial
variation of data quality suggests that rural areas are more likely to suffer
from problems with data completeness. We demonstrate that the prevalent method
of using infrastructure density as a proxy for data completeness is not
suitable for bicycle infrastructure data, and that matching of corresponding
features thus is necessary to assess data completeness. Based on our data
quality assessment we recommend strategic mapping efforts towards data
completeness, consistent standards to support comparability between different
data sources, and increased focus on data topology to ensure high-quality
bicycle network data.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02635" title="Abstract">arXiv:2312.02635</a> [<a href="/pdf/2312.02635" title="Download PDF">pdf</a>, <a href="/format/2312.02635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-rotor Aerial Vehicles in Physical Interactions: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiawei Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Research on Multi-rotor Aerial Vehicles (MAVs) has experienced remarkable
advancements over the past two decades, propelling the field forward at an
accelerated pace. Through the implementation of motion control and the
integration of specialized mechanisms, researchers have unlocked the potential
of MAVs to perform a wide range of tasks in diverse scenarios. Notably, the
literature has highlighted the distinctive attributes of MAVs that endow them
with a competitive edge in physical interaction when compared to other robotic
systems. In this survey, we present a categorization of the various types of
physical interactions in which MAVs are involved, supported by comprehensive
case studies. We examine the approaches employed by researchers to address
different challenges using MAVs and their applications, including the
development of different types of controllers to handle uncertainties inherent
in these interactions. By conducting a thorough analysis of the strengths and
limitations associated with different methodologies, as well as engaging in
discussions about potential enhancements, this survey aims to illuminate the
path for future research focusing on MAVs with high actuation capabilities.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02638" title="Abstract">arXiv:2312.02638</a> [<a href="/pdf/2312.02638" title="Download PDF">pdf</a>, <a href="/format/2312.02638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synchronization is All You Need: Exocentric-to-Egocentric Transfer for  Temporal Action Segmentation with Unlabeled Synchronized Video Pairs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Quattrocchi%2C+C">Camillo Quattrocchi</a>, 
<a href="/search/cs?searchtype=author&query=Furnari%2C+A">Antonino Furnari</a>, 
<a href="/search/cs?searchtype=author&query=Di+Mauro%2C+D">Daniele Di Mauro</a>, 
<a href="/search/cs?searchtype=author&query=Giuffrida%2C+M+V">Mario Valerio Giuffrida</a>, 
<a href="/search/cs?searchtype=author&query=Farinella%2C+G+M">Giovanni Maria Farinella</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We consider the problem of transferring a temporal action segmentation system
initially designed for exocentric (fixed) cameras to an egocentric scenario,
where wearable cameras capture video data. The conventional supervised approach
requires the collection and labeling of a new set of egocentric videos to adapt
the model, which is costly and time-consuming. Instead, we propose a novel
methodology which performs the adaptation leveraging existing labeled
exocentric videos and a new set of unlabeled, synchronized
exocentric-egocentric video pairs, for which temporal action segmentation
annotations do not need to be collected. We implement the proposed methodology
with an approach based on knowledge distillation, which we investigate both at
the feature and model level. To evaluate our approach, we introduce a new
benchmark based on the Assembly101 dataset. Results demonstrate the feasibility
and effectiveness of the proposed method against classic unsupervised domain
adaptation and temporal sequence alignment approaches. Remarkably, without
bells and whistles, our best model performs on par with supervised approaches
trained on labeled egocentric data, without ever seeing a single egocentric
label, achieving a +15.99% (28.59% vs 12.60%) improvement in the edit score on
the Assembly101 dataset compared to a baseline model trained solely on
exocentric data.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02641" title="Abstract">arXiv:2312.02641</a> [<a href="/pdf/2312.02641" title="Download PDF">pdf</a>, <a href="/format/2312.02641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inertial Line-Of-Sight Stabilization Using a 3-DOF Spherical Parallel  Manipulator with Coaxial Input Shafts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+A">Alexandre Le</a>, 
<a href="/search/cs?searchtype=author&query=Rance%2C+G">Guillaume Rance</a>, 
<a href="/search/cs?searchtype=author&query=Rouillier%2C+F">Fabrice Rouillier</a>, 
<a href="/search/cs?searchtype=author&query=Chablat%2C+D">Damien Chablat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> OPTRO Conference 2024 (11th International Symposium on Optronics in Defense &amp; Security, 2024), 11 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This article dives into the use of a 3-RRR Spherical Parallel Manipulator
(SPM) for the purpose of inertial Line Of Sight (LOS) stabilization. Such a
parallel robot provides three Degrees of Freedom (DOF) in orientation and is
studied from the kinematic point of view. In particular, one guarantees that
the singular loci (with the resulting numerical instabilities and inappropriate
behavior of the mechanism) are far away from the prescribed workspace. Once the
kinematics of the device is certified, a control strategy needs to be
implemented in order to stabilize the LOS through the upper platform of the
mechanism. Such a work is done with MATLAB Simulink using a SimMechanics model
of our robot.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02642" title="Abstract">arXiv:2312.02642</a> [<a href="/pdf/2312.02642" title="Download PDF">pdf</a>, <a href="/format/2312.02642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Ethereum Mempool Security under Asymmetric DoS by Symbolic  Fuzzing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Wanning Ding</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kai Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yuzhe Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In blockchains, mempool controls transaction flow before consensus, denial of
whose service hurts the health and security of blockchain networks. This paper
presents MPFUZZ, the first mempool fuzzer to find asymmetric DoS bugs by
symbolically exploring mempool state space and optimistically estimating the
promisingness an intermediate state is in reaching bug oracles. Compared to the
baseline blockchain fuzzers, MPFUZZ achieves a &gt; 100x speedup in finding known
DETER exploits. Running MPFUZZ on six major Ethereum clients leads to the
discovering of new mempool vulnerabilities, which exhibit a wide variety of
sophisticated patterns including stealthy mempool eviction and mempool locking.
Rule-based mitigation schemes are proposed against newly discovered
vulnerabilities.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02646" title="Abstract">arXiv:2312.02646</a> [<a href="/pdf/2312.02646" title="Download PDF">pdf</a>, <a href="/format/2312.02646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAMSGL: Series-Aligned Multi-Scale Graph Learning for Spatio-Temporal  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xiaobei Zou</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+L">Luolin Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Kurths%2C+J">Jurgen Kurths</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Spatio-temporal forecasting in various domains, like traffic prediction and
weather forecasting, is a challenging endeavor, primarily due to the
difficulties in modeling propagation dynamics and capturing high-dimensional
interactions among nodes. Despite the significant strides made by graph-based
networks in spatio-temporal forecasting, there remain two pivotal factors
closely related to forecasting performance that need further consideration:
time delays in propagation dynamics and multi-scale high-dimensional
interactions. In this work, we present a Series-Aligned Multi-Scale Graph
Learning (SAMSGL) framework, aiming to enhance forecasting performance. In
order to handle time delays in spatial interactions, we propose a
series-aligned graph convolution layer to facilitate the aggregation of
non-delayed graph signals, thereby mitigating the influence of time delays for
the improvement in accuracy. To understand global and local spatio-temporal
interactions, we develop a spatio-temporal architecture via multi-scale graph
learning, which encompasses two essential components: multi-scale graph
structure learning and graph-fully connected (Graph-FC) blocks. The multi-scale
graph structure learning includes a global graph structure to learn both
delayed and non-delayed node embeddings, as well as a local one to learn node
variations influenced by neighboring factors. The Graph-FC blocks
synergistically fuse spatial and temporal information to boost prediction
accuracy. To evaluate the performance of SAMSGL, we conduct experiments on
meteorological and traffic forecasting datasets, which demonstrate its
effectiveness and superiority.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02647" title="Abstract">arXiv:2312.02647</a> [<a href="/pdf/2312.02647" title="Download PDF">pdf</a>, <a href="/format/2312.02647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TPA3D: Triplane Attention for Fast Text-to-3D Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hong-En Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bin-Shih Wu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Sheng-Yu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y+F">Yu-Chiang Frank Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Due to the lack of large-scale text-3D correspondence data, recent text-to-3D
generation works mainly rely on utilizing 2D diffusion models for synthesizing
3D data. Since diffusion-based methods typically require significant
optimization time for both training and inference, the use of GAN-based models
would still be desirable for fast 3D generation. In this work, we propose
Triplane Attention for text-guided 3D generation (TPA3D), an end-to-end
trainable GAN-based deep learning model for fast text-to-3D generation. With
only 3D shape data and their rendered 2D images observed during training, our
TPA3D is designed to retrieve detailed visual descriptions for synthesizing the
corresponding 3D mesh data. This is achieved by the proposed attention
mechanisms on the extracted sentence and word-level text features. In our
experiments, we show that TPA3D generates high-quality 3D textured shapes
aligned with fine-grained descriptions, while impressive computation efficiency
can be observed.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02649" title="Abstract">arXiv:2312.02649</a> [<a href="/pdf/2312.02649" title="Download PDF">pdf</a>, <a href="/format/2312.02649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Q-learning approach to the continuous control problem of robot  inverted pendulum balancing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Safeea%2C+M">Mohammad Safeea</a>, 
<a href="/search/cs?searchtype=author&query=Neto%2C+P">Pedro Neto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This study evaluates the application of a discrete action space reinforcement
learning method (Q-learning) to the continuous control problem of robot
inverted pendulum balancing. To speed up the learning process and to overcome
technical difficulties related to the direct learning on the real robotic
system, the learning phase is performed in simulation environment. A
mathematical model of the system dynamics is implemented, deduced by curve
fitting on data acquired from the real system. The proposed approach
demonstrated feasible, featuring its application on a real world robot that
learned to balance an inverted pendulum. This study also reinforces and
demonstrates the importance of an accurate representation of the physical world
in simulation to achieve a more efficient implementation of reinforcement
learning algorithms in real world, even when using a discrete action space
algorithm to control a continuous action.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02650" title="Abstract">arXiv:2312.02650</a> [<a href="/pdf/2312.02650" title="Download PDF">pdf</a>, <a href="/format/2312.02650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning convex objectives to reduce the complexity of model predictive  control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Turan%2C+E+M">E. M. Turan</a>, 
<a href="/search/eess?searchtype=author&query=Mdoe%2C+Z">Z. Mdoe</a>, 
<a href="/search/eess?searchtype=author&query=J%C3%A4schke%2C+J">J. J&#xe4;schke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">For large systems that consider uncertainty the online solution of model
predictive control problems can be computationally taxing, and even infeasible.
This can be offset by using a shorter horizon, however this can in turn result
in poor controller performance. In this work we consider the task of learning a
convex cost-to-go to allow the use of a short, potentially single step, control
horizon to reduce the online computational cost. We consider two surrogates:
(1) a convex interpolating function and (2) an input-convex neural network. We
highlight that irrespective of the choice of surrogate the behaviour of the
surrogate near the origin and ability of the surrogate to describe the feasible
region are key concerns for the closed loop performance of the new MPC problem.
We address these concerns by tailoring the design of the surrogate to ensure
good performance in both aspects. The paper concludes with a numerical example,
showing the clear and significant reduction in computational complexity through
the use of these convex surrogates.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02658" title="Abstract">arXiv:2312.02658</a> [<a href="/pdf/2312.02658" title="Download PDF">pdf</a>, <a href="/ps/2312.02658" title="Download PostScript">ps</a>, <a href="/format/2312.02658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do AI models produce better weather forecasts than physics-based models?  A quantitative evaluation case study of Storm Ciar&#xe1;n
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Charlton-Perez%2C+A+J">Andrew J. Charlton-Perez</a>, 
<a href="/search/cs?searchtype=author&query=Dacre%2C+H+F">Helen F. Dacre</a>, 
<a href="/search/cs?searchtype=author&query=Driscoll%2C+S">Simon Driscoll</a>, 
<a href="/search/cs?searchtype=author&query=Gray%2C+S+L">Suzanne L. Gray</a>, 
<a href="/search/cs?searchtype=author&query=Harvey%2C+B">Ben Harvey</a>, 
<a href="/search/cs?searchtype=author&query=Harvey%2C+N+J">Natalie J. Harvey</a>, 
<a href="/search/cs?searchtype=author&query=Hunt%2C+K+M+R">Kieran M. R. Hunt</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+R+W">Robert W. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Swaminathan%2C+R">Ranjini Swaminathan</a>, 
<a href="/search/cs?searchtype=author&query=Vandaele%2C+R">Remy Vandaele</a>, 
<a href="/search/cs?searchtype=author&query=Volont%C3%A9%2C+A">Ambrogio Volont&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">There has been huge recent interest in the potential of making operational
weather forecasts using machine learning techniques. As they become a part of
the weather forecasting toolbox, there is a pressing need to understand how
well current machine learning models can simulate high-impactweather events. We
compare forecasts of Storm Ciar\'an, a European windstorm that caused sixteen
deaths and extensive damage in Northern Europe, made by machine learning and
numericalweather prediction models. The four machine learning models considered
(FourCastNet, Pangu-Weather, GraphCast and FourCastNet-v2) produce forecasts
that accurately capture the synoptic-scale structure of the cyclone including
the position of the cloud head, shape of the warm sector and location of warm
conveyor belt jet, and the large-scale dynamical drivers important for the
rapid storm development such as the position of the storm relative to the
upper-level jet exit. However, their ability to resolve the more detailed
structures important for issuing weather warnings is more mixed. All of the
machine learning models underestimate the peak amplitude of winds associated
with the storm, only some machine learning models resolve the warm core
seclusion and none of the machine learning models capture the sharp bent-back
warm frontal gradient. Our study shows there is a great deal about the
performance and properties of machine learning weather forecasts that can be
derived from case studies of high-impact weather events such as Storm Ciar\'an.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02659" title="Abstract">arXiv:2312.02659</a> [<a href="/pdf/2312.02659" title="Download PDF">pdf</a>, <a href="/format/2312.02659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supervised learning of spatial features with STDP and homeostasis using  Spiking Neural Networks on SpiNNaker
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Davies%2C+S">Sergio Davies</a>, 
<a href="/search/cs?searchtype=author&query=Gait%2C+A">Andrew Gait</a>, 
<a href="/search/cs?searchtype=author&query=Rowley%2C+A">Andrew Rowley</a>, 
<a href="/search/cs?searchtype=author&query=Di+Nuovo%2C+A">Alessandro Di Nuovo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures (figure 6 has 9 sub-figures) for a total of 14 images, 10 tables, submitted to the Journal of Neural Networks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Artificial Neural Networks (ANN) have gained large popularity thanks to their
ability to learn using the well-known backpropagation algorithm. On the other
hand, Spiking Neural Networks (SNNs), despite having wider abilities than ANNs,
have always presented a challenge in the training phase. This paper shows a new
method to perform supervised learning on SNNs, using Spike Timing Dependent
Plasticity (STDP) and homeostasis, aiming at training the network to identify
spatial patterns. The method is tested using the SpiNNaker digital
architecture. A SNN is trained to recognise one or multiple patterns and
performance metrics are extracted to measure the performance of the network.
Some considerations are drawn from the results showing that, in the case of a
single trained pattern, the network behaves as the ideal detector, with 100%
accuracy in detecting the trained pattern. However, as the number of trained
patterns on a single network increases, the accuracy of the identification is
linked to the similarities between these patterns. This method of training an
SNN to detect spatial patterns may be applied on pattern recognition in static
images or traffic analysis in computer networks, where each network packet
represents a spatial pattern. It will be stipulated that the homeostatic factor
may enable the network to detect patterns with some degree of similarities,
rather than only perfectly matching patterns.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02661" title="Abstract">arXiv:2312.02661</a> [<a href="/pdf/2312.02661" title="Download PDF">pdf</a>, <a href="/format/2312.02661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Self-Commissioning Edge Computing Method for Data-Driven Anomaly  Detection in Power Electronic Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gomez%2C+P+I">Pere Izquierdo Gomez</a>, 
<a href="/search/cs?searchtype=author&query=Gajardo%2C+M+E+L">Miguel E. Lopez Gajardo</a>, 
<a href="/search/cs?searchtype=author&query=Mijatovic%2C+N">Nenad Mijatovic</a>, 
<a href="/search/cs?searchtype=author&query=Dragicevic%2C+T">Tomislav Dragicevic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Ensuring the reliability of power electronic converters is a matter of great
importance, and data-driven condition monitoring techniques are cementing
themselves as an important tool for this purpose. However, translating methods
that work well in controlled lab environments to field applications presents
significant challenges, notably because of the limited diversity and accuracy
of the lab training data. By enabling the use of field data, online machine
learning can be a powerful tool to overcome this problem, but it introduces
additional challenges in ensuring the stability and predictability of the
training processes. This work presents an edge computing method that mitigates
these shortcomings with minimal additional memory usage, by employing an
autonomous algorithm that prioritizes the storage of training samples with
larger prediction errors. The method is demonstrated on the use case of a
self-commissioning condition monitoring system, in the form of a thermal
anomaly detection scheme for a variable frequency motor drive, where the
algorithm self-learned to distinguish normal and anomalous operation with
minimal prior knowledge. The obtained results, based on experimental data, show
a significant improvement in prediction accuracy and training speed, when
compared to equivalent models trained online without the proposed data
selection process.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02663" title="Abstract">arXiv:2312.02663</a> [<a href="/pdf/2312.02663" title="Download PDF">pdf</a>, <a href="/format/2312.02663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FaceStudio: Put Your Face Everywhere in Seconds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yuxuan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Pei Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Gang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+B">Bin Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project homepage: <a href="https://icoz69.github.io/facestudio/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study investigates identity-preserving image synthesis, an intriguing
task in image generation that seeks to maintain a subject's identity while
adding a personalized, stylistic touch. Traditional methods, such as Textual
Inversion and DreamBooth, have made strides in custom image creation, but they
come with significant drawbacks. These include the need for extensive resources
and time for fine-tuning, as well as the requirement for multiple reference
images. To overcome these challenges, our research introduces a novel approach
to identity-preserving synthesis, with a particular focus on human images. Our
model leverages a direct feed-forward mechanism, circumventing the need for
intensive fine-tuning, thereby facilitating quick and efficient image
generation. Central to our innovation is a hybrid guidance framework, which
combines stylized images, facial images, and textual prompts to guide the image
generation process. This unique combination enables our model to produce a
variety of applications, such as artistic portraits and identity-blended
images. Our experimental results, including both qualitative and quantitative
evaluations, demonstrate the superiority of our method over existing baseline
models and previous works, particularly in its remarkable efficiency and
ability to preserve the subject's identity with high fidelity.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02664" title="Abstract">arXiv:2312.02664</a> [<a href="/pdf/2312.02664" title="Download PDF">pdf</a>, <a href="/ps/2312.02664" title="Download PostScript">ps</a>, <a href="/format/2312.02664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain-Specific Tensor Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bernardy%2C+J">Jean-Philippe Bernardy</a>, 
<a href="/search/cs?searchtype=author&query=Jansson%2C+P">Patrik Jansson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">The tensor notation used in several areas of mathematics is a useful one, but
it is not widely available to the functional programming community. In a
practical sense, the (embedded) domain-specific languages (DSLs) that are
currently in use for tensor algebra are either 1. array-oriented languages that
do not enforce or take advantage of tensor properties and algebraic structure
or 2. follow the categorical structure of tensors but require the programmer to
manipulate tensors in an unwieldy point-free notation. A deeper issue is that
for tensor calculus, the dominant pedagogical paradigm assumes an audience
which is either comfortable with notational liberties which programmers cannot
afford, or focus on the applied mathematics of tensors, largely leaving their
linguistic aspects (behaviour of variable binding, syntax and semantics, etc.)
for the reader to figure out by themselves. This state of affairs is hardly
surprising, because, as we highlight, several properties of standard tensor
notation are somewhat exotic from the perspective of lambda calculi. We bridge
the gap by defining a DSL, embedded in Haskell, whose syntax closely captures
the index notation for tensors in wide use in the literature. The semantics of
this EDSL is defined in terms of the algebraic structures which define tensors
in their full generality. This way, we believe that our EDSL can be used both
as a tool for scientific computing, but also as a vehicle to express and
present the theory and applications of tensors.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02665" title="Abstract">arXiv:2312.02665</a> [<a href="/pdf/2312.02665" title="Download PDF">pdf</a>, <a href="/format/2312.02665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lights out: training RL agents robust to temporary blindness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ordonez%2C+N">N. Ordonez</a>, 
<a href="/search/cs?searchtype=author&query=Tromp%2C+M">M. Tromp</a>, 
<a href="/search/cs?searchtype=author&query=Julbe%2C+P+M">P. M. Julbe</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%B6hmer%2C+W">W. B&#xf6;hmer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Agents trained with DQN rely on an observation at each timestep to decide
what action to take next. However, in real world applications observations can
change or be missing entirely. Examples of this could be a light bulb breaking
down, or the wallpaper in a certain room changing. While these situations
change the actual observation, the underlying optimal policy does not change.
Because of this we want our agent to continue taking actions until it receives
a (recognized) observation again. To achieve this we introduce a combination of
a neural network architecture that uses hidden representations of the
observations and a novel n-step loss function. Our implementation is able to
withstand location based blindness stretches longer than the ones it was
trained on, and therefore shows robustness to temporary blindness. For access
to our implementation, please email Nathan, Marije, or Pau.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02668" title="Abstract">arXiv:2312.02668</a> [<a href="/pdf/2312.02668" title="Download PDF">pdf</a>, <a href="/ps/2312.02668" title="Download PostScript">ps</a>, <a href="/format/2312.02668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximate Nash Equilibria Algorithms for Network Design Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gan%2C+H">Hangxin Gan</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+X">Xianhao Meng</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+C">Chunying Ren</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yongtang Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Dynamical Systems (math.DS)

</div>
<p class="mathjax">We consider a weighted network design game, where selfish players chooses
paths in a network to minimize their cost. The cost function of each edge in
the network is affine linear, namely c_e(W_e) = a_eW_e + b_e, where a_e, b_e &gt;
0 are only related to the edge e and We is the total weight of the players that
choose a path containing edge e. We first show the existence of
\alpha-approximate Nash equilibrium and prove the upper bound of \alpha is
O(log2(W)), where W is the sum of the weight of all players. Furthermore,
considering that compute the \alpha-approximate Nash equilibrium is
PLS-complete, we assume that {ae, be}_{e\in E} are \phi-smooth random variables
on [0, 1]. In this case, we show that \epsilon-better response dynamics can
compute the {\alpha}-approximate Nash Equilibrium in polynomial time by proving
the expected number of iterations is polynomial in 1/\epsilon, \phi, the number
of players and the number of edges in the network.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02672" title="Abstract">arXiv:2312.02672</a> [<a href="/pdf/2312.02672" title="Download PDF">pdf</a>, <a href="/format/2312.02672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Synthetic Data Useful for Egocentric Hand-Object Interaction  Detection? An Investigation and the HOI-Synth Domain Adaptation Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leonardi%2C+R">Rosario Leonardi</a>, 
<a href="/search/cs?searchtype=author&query=Furnari%2C+A">Antonino Furnari</a>, 
<a href="/search/cs?searchtype=author&query=Ragusa%2C+F">Francesco Ragusa</a>, 
<a href="/search/cs?searchtype=author&query=Farinella%2C+G+M">Giovanni Maria Farinella</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this study, we investigate the effectiveness of synthetic data in
enhancing hand-object interaction detection within the egocentric vision
domain. We introduce a simulator able to generate synthetic images of
hand-object interactions automatically labeled with hand-object contact states,
bounding boxes, and pixel-wise segmentation masks. Through comprehensive
experiments and comparative analyses on three egocentric datasets, VISOR,
EgoHOS, and ENIGMA-51, we demonstrate that the use of synthetic data and domain
adaptation techniques allows for comparable performance to conventional
supervised methods while requiring annotations on only a fraction of the real
data. When tested with in-domain synthetic data generated from 3D models of
real target environments and objects, our best models show consistent
performance improvements with respect to standard fully supervised approaches
based on labeled real data only. Our study also sets a new benchmark of domain
adaptation for egocentric hand-object interaction detection (HOI-Synth) and
provides baseline results to encourage the community to engage in this
challenging task. We release the generated data, code, and the simulator at the
following link: https://iplab.dmi.unict.it/HOI-Synth/.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02673" title="Abstract">arXiv:2312.02673</a> [<a href="/pdf/2312.02673" title="Download PDF">pdf</a>, <a href="/format/2312.02673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Backdoor Detection for Deep Learning via Topological Evolution  Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mo%2C+X">Xiaoxing Mo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yechao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L+Y">Leo Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Wei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+N">Nan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shengshan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Y">Yang Xiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages. To appear in IEEE Symposium on Security and Privacy 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">A backdoor attack in deep learning inserts a hidden backdoor in the model to
trigger malicious behavior upon specific input patterns. Existing detection
approaches assume a metric space (for either the original inputs or their
latent representations) in which normal samples and malicious samples are
separable. We show that this assumption has a severe limitation by introducing
a novel SSDT (Source-Specific and Dynamic-Triggers) backdoor, which obscures
the difference between normal samples and malicious samples.
<br />To overcome this limitation, we move beyond looking for a perfect metric
space that would work for different deep-learning models, and instead resort to
more robust topological constructs. We propose TED (Topological Evolution
Dynamics) as a model-agnostic basis for robust backdoor detection. The main
idea of TED is to view a deep-learning model as a dynamical system that evolves
inputs to outputs. In such a dynamical system, a benign input follows a natural
evolution trajectory similar to other benign inputs. In contrast, a malicious
sample displays a distinct trajectory, since it starts close to benign samples
but eventually shifts towards the neighborhood of attacker-specified target
samples to activate the backdoor.
<br />Extensive evaluations are conducted on vision and natural language datasets
across different network architectures. The results demonstrate that TED not
only achieves a high detection rate, but also significantly outperforms
existing state-of-the-art detection approaches, particularly in addressing the
sophisticated SSDT attack. The code to reproduce the results is made public on
GitHub.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02674" title="Abstract">arXiv:2312.02674</a> [<a href="/pdf/2312.02674" title="Download PDF">pdf</a>, <a href="/format/2312.02674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Amortized Bayesian Decision Making for simulation-based models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gorecki%2C+M">Mila Gorecki</a>, 
<a href="/search/cs?searchtype=author&query=Macke%2C+J+H">Jakob H. Macke</a>, 
<a href="/search/cs?searchtype=author&query=Deistler%2C+M">Michael Deistler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Simulation-based inference (SBI) provides a powerful framework for inferring
posterior distributions of stochastic simulators in a wide range of domains. In
many settings, however, the posterior distribution is not the end goal itself
-- rather, the derived parameter values and their uncertainties are used as a
basis for deciding what actions to take. Unfortunately, because posterior
distributions provided by SBI are (potentially crude) approximations of the
true posterior, the resulting decisions can be suboptimal. Here, we address the
question of how to perform Bayesian decision making on stochastic simulators,
and how one can circumvent the need to compute an explicit approximation to the
posterior. Our method trains a neural network on simulated data and can predict
the expected cost given any data and action, and can, thus, be directly used to
infer the action with lowest cost. We apply our method to several benchmark
problems and demonstrate that it induces similar cost as the true posterior
distribution. We then apply the method to infer optimal actions in a real-world
simulator in the medical neurosciences, the Bayesian Virtual Epileptic Patient,
and demonstrate that it allows to infer actions associated with low cost after
few simulations.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02677" title="Abstract">arXiv:2312.02677</a> [<a href="/pdf/2312.02677" title="Download PDF">pdf</a>, <a href="/format/2312.02677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contact Energy Based Hindsight Experience Prioritization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sayar%2C+E">Erdi Sayar</a>, 
<a href="/search/cs?searchtype=author&query=Bing%2C+Z">Zhenshan Bing</a>, 
<a href="/search/cs?searchtype=author&query=D%27Eramo%2C+C">Carlo D&#x27;Eramo</a>, 
<a href="/search/cs?searchtype=author&query=Oguz%2C+O+S">Ozgur S. Oguz</a>, 
<a href="/search/cs?searchtype=author&query=Knoll%2C+A">Alois Knoll</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multi-goal robot manipulation tasks with sparse rewards are difficult for
reinforcement learning (RL) algorithms due to the inefficiency in collecting
successful experiences. Recent algorithms such as Hindsight Experience Replay
(HER) expedite learning by taking advantage of failed trajectories and
replacing the desired goal with one of the achieved states so that any failed
trajectory can be utilized as a contribution to learning. However, HER
uniformly chooses failed trajectories, without taking into account which ones
might be the most valuable for learning. In this paper, we address this problem
and propose a novel approach Contact Energy Based Prioritization~(CEBP) to
select the samples from the replay buffer based on rich information due to
contact, leveraging the touch sensors in the gripper of the robot and object
displacement. Our prioritization scheme favors sampling of contact-rich
experiences, which are arguably the ones providing the largest amount of
information. We evaluate our proposed approach on various sparse reward robotic
tasks and compare them with the state-of-the-art methods. We show that our
method surpasses or performs on par with those methods on robot manipulation
tasks. Finally, we deploy the trained policy from our method to a real Franka
robot for a pick-and-place task. We observe that the robot can solve the task
successfully. The videos and code are publicly available at:
https://erdiphd.github.io/HER_force
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02682" title="Abstract">arXiv:2312.02682</a> [<a href="/pdf/2312.02682" title="Download PDF">pdf</a>, <a href="/format/2312.02682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> H-GAP: Humanoid Control with a Generalist Planner
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhengyao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yingchen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wagener%2C+N">Nolan Wagener</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yicheng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Janner%2C+M">Michael Janner</a>, 
<a href="/search/cs?searchtype=author&query=Grefenstette%2C+E">Edward Grefenstette</a>, 
<a href="/search/cs?searchtype=author&query=Rockt%C3%A4schel%2C+T">Tim Rockt&#xe4;schel</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuandong Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages including appendix, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Humanoid control is an important research challenge offering avenues for
integration into human-centric infrastructures and enabling physics-driven
humanoid animations. The daunting challenges in this field stem from the
difficulty of optimizing in high-dimensional action spaces and the instability
introduced by the bipedal morphology of humanoids. However, the extensive
collection of human motion-captured data and the derived datasets of humanoid
trajectories, such as MoCapAct, paves the way to tackle these challenges. In
this context, we present Humanoid Generalist Autoencoding Planner (H-GAP), a
state-action trajectory generative model trained on humanoid trajectories
derived from human motion-captured data, capable of adeptly handling downstream
control tasks with Model Predictive Control (MPC). For 56 degrees of freedom
humanoid, we empirically demonstrate that H-GAP learns to represent and
generate a wide range of motor behaviours. Further, without any learning from
online interactions, it can also flexibly transfer these behaviors to solve
novel downstream control tasks via planning. Notably, H-GAP excels established
MPC baselines that have access to the ground truth dynamics model, and is
superior or comparable to offline RL methods trained for individual tasks.
Finally, we do a series of empirical studies on the scaling properties of
H-GAP, showing the potential for performance gains via additional data but not
computing. Code and videos are available at
https://ycxuyingchen.github.io/hgap/.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02684" title="Abstract">arXiv:2312.02684</a> [<a href="/pdf/2312.02684" title="Download PDF">pdf</a>, <a href="/format/2312.02684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepPointMap: Advancing LiDAR SLAM with Unified Neural Descriptors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaze Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Ziheng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+Q">Qi Jing</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuejie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Wenchao Ding</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+R">Rui Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Point clouds have shown significant potential in various domains, including
Simultaneous Localization and Mapping (SLAM). However, existing approaches
either rely on dense point clouds to achieve high localization accuracy or use
generalized descriptors to reduce map size. Unfortunately, these two aspects
seem to conflict with each other. To address this limitation, we propose a
unified architecture, DeepPointMap, achieving excellent preference on both
aspects. We utilize neural network to extract highly representative and sparse
neural descriptors from point clouds, enabling memory-efficient map
representation and accurate multi-scale localization tasks (e.g., odometry and
loop-closure). Moreover, we showcase the versatility of our framework by
extending it to more challenging multi-agent collaborative SLAM. The promising
results obtained in these scenarios further emphasize the effectiveness and
potential of our approach.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02690" title="Abstract">arXiv:2312.02690</a> [<a href="/pdf/2312.02690" title="Download PDF">pdf</a>, <a href="/format/2312.02690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Study on Modelling and Control of Autonomous Underwater  Vehicle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Makam%2C+R">Rajini Makam</a>, 
<a href="/search/eess?searchtype=author&query=Mane%2C+P">Pruthviraj Mane</a>, 
<a href="/search/eess?searchtype=author&query=Sundaram%2C+S">Suresh Sundaram</a>, 
<a href="/search/eess?searchtype=author&query=Sujit%2C+P+B">P. B. Sujit</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Assistive Robotics, CRC Press, Taylor &amp; Francis, USA. This is the preprint version of the book chapter
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Autonomous underwater vehicles (AUV) have become the de facto vehicle for
remote operations involving oceanography, inspection, and monitoring tasks.
These vehicles operate in different and often challenging environments; hence,
the design and development of the AUV involving hydrodynamics and control
systems need to be designed in detail. This book chapter presents a study on
the modelling and robust control of a research vehicle in the presence of
uncertainties. The vehicle's dynamic behaviour is modelled using a
6-degree-of-freedom approach, considering the effect of ocean currents. The
level flight requirements for different speeds are derived, and the resulting
model is decomposed into horizontal and vertical subsystems for linear
analysis. The simulation results presented focus on the efficacy of linear
controllers within three key subsystems: depth, yaw, and speed. Moreover,
level-flight outcomes are demonstrated for a speed of 4 knots. The nonlinear
control strategies employed in this study encompass conventional and
sliding-mode control (SMC) methodologies. To ensure accurate tracking
performance, the controller design considers the vehicle's dynamics with
various uncertainties such as ocean currents, parameter uncertainty, CG (Center
of Gravity) deviation and buoyancy variation. Both conventional and nonlinear
SMC controllers' outcomes are showcased with a lawn-mowing manoeuvre scenario.
A systematic comparison is drawn between the robustness of SMC against
disturbances and parameter fluctuations in contrast to conventional
controllers. Importantly, these results underscore the trade-off that
accompanies SMC's robustness, as it necessitates a higher level of complexity
in terms of controller design, intricate implementation intricacies, and the
management of chattering phenomena.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02694" title="Abstract">arXiv:2312.02694</a> [<a href="/pdf/2312.02694" title="Download PDF">pdf</a>, <a href="/format/2312.02694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UPOCR: Towards Unified Pixel-Level OCR Interface
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+D">Dezhi Peng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhenhua Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chongyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yongxin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+K">Kai Ding</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+F">Fengjun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Lianwen Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, the optical character recognition (OCR) field has been
proliferating with plentiful cutting-edge approaches for a wide spectrum of
tasks. However, these approaches are task-specifically designed with divergent
paradigms, architectures, and training strategies, which significantly
increases the complexity of research and maintenance and hinders the fast
deployment in applications. To this end, we propose UPOCR, a
simple-yet-effective generalist model for Unified Pixel-level OCR interface.
Specifically, the UPOCR unifies the paradigm of diverse OCR tasks as
image-to-image transformation and the architecture as a vision Transformer
(ViT)-based encoder-decoder. Learnable task prompts are introduced to push the
general feature representations extracted by the encoder toward task-specific
spaces, endowing the decoder with task awareness. Moreover, the model training
is uniformly aimed at minimizing the discrepancy between the generated and
ground-truth images regardless of the inhomogeneity among tasks. Experiments
are conducted on three pixel-level OCR tasks including text removal, text
segmentation, and tampered text detection. Without bells and whistles, the
experimental results showcase that the proposed method can simultaneously
achieve state-of-the-art performance on three tasks with a unified single
model, which provides valuable strategies and insights for future research on
generalist OCR models. Code will be publicly available.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02696" title="Abstract">arXiv:2312.02696</a> [<a href="/pdf/2312.02696" title="Download PDF">pdf</a>, <a href="/format/2312.02696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing and Improving the Training Dynamics of Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karras%2C+T">Tero Karras</a>, 
<a href="/search/cs?searchtype=author&query=Aittala%2C+M">Miika Aittala</a>, 
<a href="/search/cs?searchtype=author&query=Lehtinen%2C+J">Jaakko Lehtinen</a>, 
<a href="/search/cs?searchtype=author&query=Hellsten%2C+J">Janne Hellsten</a>, 
<a href="/search/cs?searchtype=author&query=Aila%2C+T">Timo Aila</a>, 
<a href="/search/cs?searchtype=author&query=Laine%2C+S">Samuli Laine</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)

</div>
<p class="mathjax">Diffusion models currently dominate the field of data-driven image synthesis
with their unparalleled scaling to large datasets. In this paper, we identify
and rectify several causes for uneven and ineffective training in the popular
ADM diffusion model architecture, without altering its high-level structure.
Observing uncontrolled magnitude changes and imbalances in both the network
activations and weights over the course of training, we redesign the network
layers to preserve activation, weight, and update magnitudes on expectation. We
find that systematic application of this philosophy eliminates the observed
drifts and imbalances, resulting in considerably better networks at equal
computational complexity. Our modifications improve the previous record FID of
2.41 in ImageNet-512 synthesis to 1.81, achieved using fast deterministic
sampling.
<br />As an independent contribution, we present a method for setting the
exponential moving average (EMA) parameters post-hoc, i.e., after completing
the training run. This allows precise tuning of EMA length without the cost of
performing several training runs, and reveals its surprising interactions with
network architecture, training time, and guidance.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02697" title="Abstract">arXiv:2312.02697</a> [<a href="/pdf/2312.02697" title="Download PDF">pdf</a>, <a href="/format/2312.02697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Visual Policy Learning for Long-Horizon Robot Manipulation  in Densely Cluttered Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hecheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+L">Lizhe Qi</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+B">Bin Fang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yunquan Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this work, we focus on addressing the long-horizon manipulation tasks in
densely cluttered scenes. Such tasks require policies to effectively manage
severe occlusions among objects and continually produce actions based on visual
observations. We propose a vision-based Hierarchical policy for Cluttered-scene
Long-horizon Manipulation (HCLM). It employs a high-level policy and three
options to select and instantiate three parameterized action primitives: push,
pick, and place. We first train the pick and place options by behavior cloning
(BC). Subsequently, we use hierarchical reinforcement learning (HRL) to train
the high-level policy and push option. During HRL, we propose a Spatially
Extended Q-update (SEQ) to augment the updates for the push option and a
Two-Stage Update Scheme (TSUS) to alleviate the non-stationary transition
problem in updating the high-level policy. We demonstrate that HCLM
significantly outperforms baseline methods in terms of success rate and
efficiency in diverse tasks. We also highlight our method's ability to
generalize to more cluttered environments with more additional blocks.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02699" title="Abstract">arXiv:2312.02699</a> [<a href="/pdf/2312.02699" title="Download PDF">pdf</a>, <a href="/format/2312.02699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Vehicle Entrance and Parking Management: Deep Learning  Solutions for Efficiency and Security
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramzan%2C+M+U">Muhammad Umer Ramzan</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+U">Usman Ali</a>, 
<a href="/search/cs?searchtype=author&query=Naqvi%2C+S+H+A">Syed Haider Abbas Naqvi</a>, 
<a href="/search/cs?searchtype=author&query=Aslam%2C+Z">Zeeshan Aslam</a>, 
<a href="/search/cs?searchtype=author&query=Tehseen">Tehseen</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+H">Husnain Ali</a>, 
<a href="/search/cs?searchtype=author&query=Faheem%2C+M">Muhammad Faheem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the 25th International Multitopic Conference (INMIC) IEEE 2023, 6 Pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The auto-management of vehicle entrance and parking in any organization is a
complex challenge encompassing record-keeping, efficiency, and security
concerns. Manual methods for tracking vehicles and finding parking spaces are
slow and a waste of time. To solve the problem of auto management of vehicle
entrance and parking, we have utilized state-of-the-art deep learning models
and automated the process of vehicle entrance and parking into any
organization. To ensure security, our system integrated vehicle detection,
license number plate verification, and face detection and recognition models to
ensure that the person and vehicle are registered with the organization. We
have trained multiple deep-learning models for vehicle detection, license
number plate detection, face detection, and recognition, however, the YOLOv8n
model outperformed all the other models. Furthermore, License plate recognition
is facilitated by Google's Tesseract-OCR Engine. By integrating these
technologies, the system offers efficient vehicle detection, precise
identification, streamlined record keeping, and optimized parking slot
allocation in buildings, thereby enhancing convenience, accuracy, and security.
Future research opportunities lie in fine-tuning system performance for a wide
range of real-world applications.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02700" title="Abstract">arXiv:2312.02700</a> [<a href="/pdf/2312.02700" title="Download PDF">pdf</a>, <a href="/format/2312.02700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisit Human-Scene Interaction via Space Occupancy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinpeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+H">Haowen Hou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yanchao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong-Lu Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors contributed equally. Yong-Lu Li is the corresponding author. Project page: <a href="https://foruck.github.io/occu-page/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human-scene Interaction (HSI) generation is a challenging task and crucial
for various downstream tasks. However, one of the major obstacles is the
limited data scale. High-quality data with simultaneously captured human and 3D
environments is rare, resulting in limited data diversity and complexity. In
this work, we argue that interaction with a scene is essentially interacting
with the space occupancy of the scene from an abstract physical perspective,
leading us to a unified novel view of Human-Occupancy Interaction. By treating
pure motion sequences as records of humans interacting with invisible scene
occupancy, we can aggregate motion-only data into a large-scale paired
human-occupancy interaction database: Motion Occupancy Base (MOB). Thus, the
need for costly paired motion-scene datasets with high-quality scene scans can
be substantially alleviated. With this new unified view of Human-Occupancy
interaction, a single motion controller is proposed to reach the target state
given the surrounding occupancy. Once trained on MOB with complex occupancy
layout, the controller could handle cramped scenes and generalize well to
general scenes with limited complexity. With no GT 3D scenes for training, our
method can generate realistic and stable HSI motions in diverse scenarios,
including both static and dynamic scenes. Our code and data would be made
publicly available at https://foruck.github.io/occu-page/.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02702" title="Abstract">arXiv:2312.02702</a> [<a href="/pdf/2312.02702" title="Download PDF">pdf</a>, <a href="/format/2312.02702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Sign Actors: A diffusion model for 3D sign language production  from text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baltatzis%2C+V">Vasileios Baltatzis</a>, 
<a href="/search/cs?searchtype=author&query=Potamias%2C+R+A">Rolandos Alexandros Potamias</a>, 
<a href="/search/cs?searchtype=author&query=Ververas%2C+E">Evangelos Ververas</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Guanxiong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jiankang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zafeiriou%2C+S">Stefanos Zafeiriou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Sign Languages (SL) serve as the predominant mode of communication for the
Deaf and Hard of Hearing communities. The advent of deep learning has aided
numerous methods in SL recognition and translation, achieving remarkable
results. However, Sign Language Production (SLP) poses a challenge for the
computer vision community as the motions generated must be realistic and have
precise semantic meanings. Most SLP methods rely on 2D data, thus impeding
their ability to attain a necessary level of realism. In this work, we propose
a diffusion-based SLP model trained on a curated large-scale dataset of 4D
signing avatars and their corresponding text transcripts. The proposed method
can generate dynamic sequences of 3D avatars from an unconstrained domain of
discourse using a diffusion process formed on a novel and anatomically informed
graph neural network defined on the SMPL-X body skeleton. Through a series of
quantitative and qualitative experiments, we show that the proposed method
considerably outperforms previous methods of SLP. We believe that this work
presents an important and necessary step towards realistic neural sign avatars,
bridging the communication gap between Deaf and hearing communities. The code,
method and generated data will be made publicly available.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02703" title="Abstract">arXiv:2312.02703</a> [<a href="/pdf/2312.02703" title="Download PDF">pdf</a>, <a href="/format/2312.02703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MyPortrait: Morphable Prior-Guided Personalized Portrait Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+B">Bo Ding</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhenfeng Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shihong Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generating realistic talking faces is an interesting and long-standing topic
in the field of computer vision. Although significant progress has been made,
it is still challenging to generate high-quality dynamic faces with
personalized details. This is mainly due to the inability of the general model
to represent personalized details and the generalization problem to unseen
controllable parameters. In this work, we propose Myportrait, a simple,
general, and flexible framework for neural portrait generation. We incorporate
personalized prior in a monocular video and morphable prior in 3D face
morphable space for generating personalized details under novel controllable
parameters. Our proposed framework supports both video-driven and audio-driven
face animation given a monocular video of a single person. Distinguished by
whether the test data is sent to training or not, our method provides a
real-time online version and a high-quality offline version. Comprehensive
experiments in various metrics demonstrate the superior performance of our
method over the state-of-the-art methods. The code will be publicly available.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02705" title="Abstract">arXiv:2312.02705</a> [<a href="/pdf/2312.02705" title="Download PDF">pdf</a>, <a href="/format/2312.02705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified learning-based lossy and lossless JPEG recompression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianghui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuanyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Lina Guo</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jixiang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tongda Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Hongwei Qin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">JPEG is still the most widely used image compression algorithm. Most image
compression algorithms only consider uncompressed original image, while
ignoring a large number of already existing JPEG images. Recently, JPEG
recompression approaches have been proposed to further reduce the size of JPEG
files. However, those methods only consider JPEG lossless recompression, which
is just a special case of the rate-distortion theorem. In this paper, we
propose a unified lossly and lossless JPEG recompression framework, which
consists of learned quantization table and Markovian hierarchical variational
autoencoders. Experiments show that our method can achieve arbitrarily low
distortion when the bitrate is close to the upper bound, namely the bitrate of
the lossless compression model. To the best of our knowledge, this is the first
learned method that bridges the gap between lossy and lossless recompression of
JPEG images.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02706" title="Abstract">arXiv:2312.02706</a> [<a href="/pdf/2312.02706" title="Download PDF">pdf</a>, <a href="/format/2312.02706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Knowledge Model: Perspectives and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huajun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an early draft subject to revision in a near future
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Humankind's understanding of the world is fundamentally linked to our
perception and cognition, with \emph{human languages} serving as one of the
major carriers of \emph{world knowledge}. In this vein, \emph{Large Language
Models} (LLMs) like ChatGPT epitomize the pre-training of extensive,
sequence-based world knowledge into neural networks, facilitating the
processing and manipulation of this knowledge in a parametric space. This
article explores large models through the lens of ``knowledge''. We initially
investigate the role of symbolic knowledge such as Knowledge Graphs (KGs) in
enhancing LLMs, covering aspects like knowledge-augmented language model,
structure-inducing pre-training, knowledgeable prompts, structured CoT,
knowledge editing, semantic tools for LLM and knowledgeable AI agents.
Subsequently, we examine how LLMs can amplify traditional symbolic knowledge
bases, encompassing aspects like using LLM as KG builder and controller,
structured knowledge pretraining, LLM-enhanced symbolic reasoning, and the
amalgamation of perception with cognition. Considering the intricate nature of
human knowledge, we advocate for the creation of \emph{Large Knowledge Models}
(LKM), specifically engineered to manage diversified spectrum of knowledge
structures. This ambitious undertaking could entail several key challenges,
such as disentangling knowledge representation from language models,
restructuring pre-training with structured knowledge, and building large
commonsense models, among others. We finally propose a five-``A'' principle to
distinguish the concept of LKM.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02708" title="Abstract">arXiv:2312.02708</a> [<a href="/pdf/2312.02708" title="Download PDF">pdf</a>, <a href="/format/2312.02708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> (Provable) Adversarial Robustness for Group Equivariant Tasks: Graphs,  Point Clouds, Molecules, and More
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schuchardt%2C+J">Jan Schuchardt</a>, 
<a href="/search/cs?searchtype=author&query=Scholten%2C+Y">Yan Scholten</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCnnemann%2C+S">Stephan G&#xfc;nnemann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Machine Learning (stat.ML)

</div>
<p class="mathjax">A machine learning model is traditionally considered robust if its prediction
remains (almost) constant under input perturbations with small norm. However,
real-world tasks like molecular property prediction or point cloud segmentation
have inherent equivariances, such as rotation or permutation equivariance. In
such tasks, even perturbations with large norm do not necessarily change an
input's semantic content. Furthermore, there are perturbations for which a
model's prediction explicitly needs to change. For the first time, we propose a
sound notion of adversarial robustness that accounts for task equivariance. We
then demonstrate that provable robustness can be achieved by (1) choosing a
model that matches the task's equivariances (2) certifying traditional
adversarial robustness. Certification methods are, however, unavailable for
many models, such as those with continuous equivariances. We close this gap by
developing the framework of equivariance-preserving randomized smoothing, which
enables architecture-agnostic certification. We additionally derive the first
architecture-specific graph edit distance certificates, i.e. sound robustness
guarantees for isomorphism equivariant tasks like node classification. Overall,
a sound notion of robustness is an important prerequisite for future work at
the intersection of robust and geometric machine learning.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02710" title="Abstract">arXiv:2312.02710</a> [<a href="/pdf/2312.02710" title="Download PDF">pdf</a>, <a href="/ps/2312.02710" title="Download PostScript">ps</a>, <a href="/format/2312.02710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User Interaction Data in Apps: Comparing Policy Claims to  Implementations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+F">Feiyang Tang</a>, 
<a href="/search/cs?searchtype=author&query=%C3%98stvold%2C+B+M">Bjarte M. &#xd8;stvold</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at the 18th IFIP Summer School on Privacy and Identity Management 2023 (IFIPSC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">As mobile app usage continues to rise, so does the generation of extensive
user interaction data, which includes actions such as swiping, zooming, or the
time spent on a screen. Apps often collect a large amount of this data and
claim to anonymize it, yet concerns arise regarding the adequacy of these
measures. In many cases, the so-called anonymized data still has the potential
to profile and, in some instances, re-identify individual users. This situation
is compounded by a lack of transparency, leading to potential breaches of user
trust.
<br />Our work investigates the gap between privacy policies and actual app
behavior, focusing on the collection and handling of user interaction data. We
analyzed the top 100 apps across diverse categories using static analysis
methods to evaluate the alignment between policy claims and implemented data
collection techniques. Our findings highlight the lack of transparency in data
collection and the associated risk of re-identification, raising concerns about
user privacy and trust. This study emphasizes the importance of clear
communication and enhanced transparency in privacy practices for mobile app
development.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02711" title="Abstract">arXiv:2312.02711</a> [<a href="/pdf/2312.02711" title="Download PDF">pdf</a>, <a href="/format/2312.02711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HARMONIOUS -- Human-like reactive motion control and multimodal  perception for humanoid robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rozlivek%2C+J">Jakub Rozlivek</a>, 
<a href="/search/cs?searchtype=author&query=Roncone%2C+A">Alessandro Roncone</a>, 
<a href="/search/cs?searchtype=author&query=Pattacini%2C+U">Ugo Pattacini</a>, 
<a href="/search/cs?searchtype=author&query=Hoffmann%2C+M">Matej Hoffmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">For safe and effective operation of humanoid robots in human-populated
environments, the problem of commanding a large number of Degrees of Freedom
(DoF) while simultaneously considering dynamic obstacles and human proximity
has still not been solved. We present a new reactive motion controller that
commands two arms of a humanoid robot and three torso joints (17 DoF in total).
We formulate a quadratic program that seeks joint velocity commands respecting
multiple constraints while minimizing the magnitude of the velocities. We
introduce a new unified treatment of obstacles that dynamically maps visual and
proximity (pre-collision) and tactile (post-collision) obstacles as additional
constraints to the motion controller, in a distributed fashion over surface of
the upper-body of the iCub robot (with 2000 pressure-sensitive receptors). The
bio-inspired controller: (i) produces human-like minimum jerk movement
profiles; (ii) gives rise to a robot with whole-body visuo-tactile awareness,
resembling peripersonal space representations. The controller was extensively
experimentally validated, including a physical human-robot interaction
scenario.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02719" title="Abstract">arXiv:2312.02719</a> [<a href="/pdf/2312.02719" title="Download PDF">pdf</a>, <a href="/format/2312.02719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Conditional Denoising Diffusion Probabilistic Model for Point Cloud  Upsampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+W">Wentao Qu</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Yuantian Shao</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+L">Lingwu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaoshui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Liang Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Point cloud upsampling (PCU) enriches the representation of raw point clouds,
significantly improving the performance in downstream tasks such as
classification and reconstruction. Most of the existing point cloud upsampling
methods focus on sparse point cloud feature extraction and upsampling module
design. In a different way, we dive deeper into directly modelling the gradient
of data distribution from dense point clouds. In this paper, we proposed a
conditional denoising diffusion probability model (DDPM) for point cloud
upsampling, called PUDM. Specifically, PUDM treats the sparse point cloud as a
condition, and iteratively learns the transformation relationship between the
dense point cloud and the noise. Simultaneously, PUDM aligns with a dual
mapping paradigm to further improve the discernment of point features. In this
context, PUDM enables learning complex geometry details in the ground truth
through the dominant features, while avoiding an additional upsampling module
design. Furthermore, to generate high-quality arbitrary-scale point clouds
during inference, PUDM exploits the prior knowledge of the scale between sparse
point clouds and dense point clouds during training by parameterizing a rate
factor. Moreover, PUDM exhibits strong noise robustness in experimental
results. In the quantitative and qualitative evaluations on PU1K and PUGAN,
PUDM significantly outperformed existing methods in terms of Chamfer Distance
(CD) and Hausdorff Distance (HD), achieving state of the art (SOTA)
performance.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02720" title="Abstract">arXiv:2312.02720</a> [<a href="/pdf/2312.02720" title="Download PDF">pdf</a>, <a href="/format/2312.02720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards the Inferrence of Structural Similarity of Combinatorial  Landscapes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Mingyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Ke Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">One of the most common problem-solving heuristics is by analogy. For a given
problem, a solver can be viewed as a strategic walk on its fitness landscape.
Thus if a solver works for one problem instance, we expect it will also be
effective for other instances whose fitness landscapes essentially share
structural similarities with each other. However, due to the black-box nature
of combinatorial optimization, it is far from trivial to infer such similarity
in real-world scenarios. To bridge this gap, by using local optima network as a
proxy of fitness landscapes, this paper proposed to leverage graph data mining
techniques to conduct qualitative and quantitative analyses to explore the
latent topological structural information embedded in those landscapes. By
conducting large-scale empirical experiments on three classic combinatorial
optimization problems, we gain concrete evidence to support the existence of
structural similarity between landscapes of the same classes within neighboring
dimensions. We also interrogated the relationship between landscapes of
different problem classes.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02722" title="Abstract">arXiv:2312.02722</a> [<a href="/pdf/2312.02722" title="Download PDF">pdf</a>, <a href="/format/2312.02722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Algorithms for Minimum-Membership Geometric Set Cover
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Govindarajan%2C+S">Sathish Govindarajan</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S">Siddhartha Sarkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in CALDAM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Bandyapadhyay et al. introduced the generalized minimum-membership geometric
set cover (GMMGSC) problem [SoCG, 2023], which is defined as follows. We are
given two sets $P$ and $P'$ of points in $\mathbb{R}^{2}$, $n=\max(|P|, |P'|)$,
and a set $\mathcal{S}$ of $m$ axis-parallel unit squares. The goal is to find
a subset $\mathcal{S}^{*}\subseteq \mathcal{S}$ that covers all the points in
$P$ while minimizing $\mathsf{memb}(P', \mathcal{S}^{*})$, where
$\mathsf{memb}(P', \mathcal{S}^{*})=\max_{p\in P'}|\{s\in \mathcal{S}^{*}: p\in
s\}|$. We study GMMGSC problem and give a $16$-approximation algorithm that
runs in $O(m^2\log m + m^2n)$ time. Our result is a significant improvement to
the $144$-approximation given by Bandyapadhyay et al. that runs in
$\tilde{O}(nm)$ time.
<br />GMMGSC problem is a generalization of another well-studied problem called
Minimum Ply Geometric Set Cover (MPGSC), in which the goal is to minimize the
ply of $\mathcal{S}^{*}$, where the ply is the maximum cardinality of a subset
of the unit squares that have a non-empty intersection. The best-known result
for the MPGSC problem is an $8$-approximation algorithm by Durocher et al. that
runs in $O(n + m^{8}k^{4}\log k + m^{8}\log m\log k)$ time, where $k$ is the
optimal ply value [WALCOM, 2023].
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02724" title="Abstract">arXiv:2312.02724</a> [<a href="/pdf/2312.02724" title="Download PDF">pdf</a>, <a href="/format/2312.02724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RankZephyr: Effective and Robust Zero-Shot Listwise Reranking is a  Breeze!
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pradeep%2C+R">Ronak Pradeep</a>, 
<a href="/search/cs?searchtype=author&query=Sharifymoghaddam%2C+S">Sahel Sharifymoghaddam</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jimmy Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">In information retrieval, proprietary large language models (LLMs) such as
GPT-4 and open-source counterparts such as LLaMA and Vicuna have played a vital
role in reranking. However, the gap between open-source and closed models
persists, with reliance on proprietary, non-transparent models constraining
reproducibility. Addressing this gap, we introduce RankZephyr, a
state-of-the-art, open-source LLM for listwise zero-shot reranking. RankZephyr
not only bridges the effectiveness gap with GPT-4 but in some cases surpasses
the proprietary model. Our comprehensive evaluations across several datasets
(TREC Deep Learning Tracks; NEWS and COVID from BEIR) showcase this ability.
RankZephyr benefits from strategic training choices and is resilient against
variations in initial document ordering and the number of documents reranked.
Additionally, our model outperforms GPT-4 on the NovelEval test set, comprising
queries and passages past its training period, which addresses concerns about
data contamination. To foster further research in this rapidly evolving field,
we provide all code necessary to reproduce our results at
https://github.com/castorini/rank_llm.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02725" title="Abstract">arXiv:2312.02725</a> [<a href="/pdf/2312.02725" title="Download PDF">pdf</a>, <a href="/format/2312.02725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> R3D-SWIN:Use Shifted Window Attention for Single-View 3D Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenhuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Meihua Xiao</a>, 
<a href="/search/cs?searchtype=author&query=li%2C+z">zehuan li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Mengxi Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages,3 figures,5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, vision transformers have performed well in various computer vision
tasks, including voxel 3D reconstruction. However, the windows of the vision
transformer are not multi-scale, and there is no connection between the
windows, which limits the accuracy of voxel 3D reconstruction . Therefore, we
propose a shifted windows attention voxel 3D reconstruction network. To the
best of our knowledge, this is the first work to apply shifted window attention
to voxel 3D reconstruction. Experimental results on ShapeNet verify our method
achieves SOTA accuracy in single-view reconstruction.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02728" title="Abstract">arXiv:2312.02728</a> [<a href="/pdf/2312.02728" title="Download PDF">pdf</a>, <a href="/format/2312.02728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overview of RIS-Enabled Secure Transmission in 6G Wireless Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bae%2C+J">JungSook Bae</a>, 
<a href="/search/cs?searchtype=author&query=Khalid%2C+W">Waqas Khalid</a> (Co-first author), 
<a href="/search/cs?searchtype=author&query=Lee%2C+A">Anseok Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Heesoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Noh%2C+S">Song Noh</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Heejung Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for Digital Communications and Networks(DCN)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">As sixth-generation (6G) wireless communication networks evolve, privacy
concerns are expected due to the transmission of vast amounts of
security-sensitive private information. In this context, a reconfigurable
intelligent surface (RIS) emerges as a promising technology capable of
enhancing transmission efficiency and strengthening information security. This
study demonstrates how RISs can play a crucial role in making 6G networks more
secure against eavesdropping attacks. We discuss the fundamentals, and
standardization aspects of RISs, along with an in-depth analysis of
physical-layer security (PLS). Our discussion centers on PLS design using RIS,
highlighting aspects like beamforming, resource allocation, artificial noise,
and cooperative communications. We also identify the research issues, propose
potential solutions, and explore future perspectives. Finally, numerical
results are provided to support our discussions and demonstrate the enhanced
security enabled by RIS.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02730" title="Abstract">arXiv:2312.02730</a> [<a href="/pdf/2312.02730" title="Download PDF">pdf</a>, <a href="/format/2312.02730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Measuring Representational Similarity of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klabunde%2C+M">Max Klabunde</a>, 
<a href="/search/cs?searchtype=author&query=Amor%2C+M+B">Mehdi Ben Amor</a>, 
<a href="/search/cs?searchtype=author&query=Granitzer%2C+M">Michael Granitzer</a>, 
<a href="/search/cs?searchtype=author&query=Lemmerich%2C+F">Florian Lemmerich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended abstract in UniReps Workshop @ NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Understanding the similarity of the numerous released large language models
(LLMs) has many uses, e.g., simplifying model selection, detecting illegal
model reuse, and advancing our understanding of what makes LLMs perform well.
In this work, we measure the similarity of representations of a set of LLMs
with 7B parameters. Our results suggest that some LLMs are substantially
different from others. We identify challenges of using representational
similarity measures that suggest the need of careful study of similarity scores
to avoid false conclusions.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02731" title="Abstract">arXiv:2312.02731</a> [<a href="/pdf/2312.02731" title="Download PDF">pdf</a>, <a href="/format/2312.02731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> D-LGP: Dynamic Logic-Geometric Program for Combined Task and Motion  Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+T">Teng Xue</a>, 
<a href="/search/cs?searchtype=author&query=Razmjoo%2C+A">Amirreza Razmjoo</a>, 
<a href="/search/cs?searchtype=author&query=Calinon%2C+S">Sylvain Calinon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Many real-world sequential manipulation tasks involve a combination of
discrete symbolic search and continuous motion planning, collectively known as
combined task and motion planning (TAMP). However, prevailing methods often
struggle with the computational burden and intricate combinatorial challenges
stemming from the multitude of action skeletons. To address this, we propose
Dynamic Logic-Geometric Program (D-LGP), a novel approach integrating Dynamic
Tree Search and global optimization for efficient hybrid planning. Through
empirical evaluation on three benchmarks, we demonstrate the efficacy of our
approach, showcasing superior performance in comparison to state-of-the-art
techniques. We validate our approach through simulation and demonstrate its
capability for online replanning under uncertainty and external disturbances in
the real world.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02734" title="Abstract">arXiv:2312.02734</a> [<a href="/pdf/2312.02734" title="Download PDF">pdf</a>, <a href="/ps/2312.02734" title="Download PostScript">ps</a>, <a href="/format/2312.02734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometric Data-Driven Dimensionality Reduction in MPC with Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Schurig%2C+R">Roland Schurig</a>, 
<a href="/search/eess?searchtype=author&query=Himmel%2C+A">Andreas Himmel</a>, 
<a href="/search/eess?searchtype=author&query=Findeisen%2C+R">Rolf Findeisen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is currently under review for ECC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We consider the problem of reducing the dimension of the discrete-time
optimal control problem that is solved repeatedly online in model predictive
control. We show that a reduced-order scheme, which solves the optimization
problem in a low-dimensional subspace, inherits the stability and recursive
feasibility properties from the original formulation. We introduce a necessary
and sufficient condition for initial feasibility and incorporate that in the
subspace design. Finally, we use concepts of optimization over Riemannian
manifolds to compute a subspace that provides optimal representations for a set
of pre-defined high-dimensional optimizers under the initial admissibility
constraint.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02739" title="Abstract">arXiv:2312.02739</a> [<a href="/pdf/2312.02739" title="Download PDF">pdf</a>, <a href="/format/2312.02739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LExCI: A Framework for Reinforcement Learning with Embedded Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Badalian%2C+K">Kevin Badalian</a>, 
<a href="/search/cs?searchtype=author&query=Koch%2C+L">Lucas Koch</a>, 
<a href="/search/cs?searchtype=author&query=Brinkmann%2C+T">Tobias Brinkmann</a>, 
<a href="/search/cs?searchtype=author&query=Picerno%2C+M">Mario Picerno</a>, 
<a href="/search/cs?searchtype=author&query=Wegener%2C+M">Marius Wegener</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sung-Yong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Andert%2C+J">Jakob Andert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The code, models, and data used for this work are available in a separate branch of LExCI's GitHub repository (<a href="https://github.com/mechatronics-RWTH/lexci-2/tree/lexci_paper">this https URL</a>). This paper has been submitted to Applied Intelligence (<a href="https://link.springer.com/journal/10489">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Advances in artificial intelligence (AI) have led to its application in many
areas of everyday life. In the context of control engineering, reinforcement
learning (RL) represents a particularly promising approach as it is centred
around the idea of allowing an agent to freely interact with its environment to
find an optimal strategy. One of the challenges professionals face when
training and deploying RL agents is that the latter often have to run on
dedicated embedded devices. This could be to integrate them into an existing
toolchain or to satisfy certain performance criteria like real-time
constraints. Conventional RL libraries, however, cannot be easily utilised in
conjunction with that kind of hardware. In this paper, we present a framework
named LExCI, the Learning and Experiencing Cycle Interface, which bridges this
gap and provides end-users with a free and open-source tool for training agents
on embedded systems using the open-source library RLlib. Its operability is
demonstrated with two state-of-the-art RL-algorithms and a rapid control
prototyping system.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02741" title="Abstract">arXiv:2312.02741</a> [<a href="/pdf/2312.02741" title="Download PDF">pdf</a>, <a href="/format/2312.02741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Part-time Power Measurements: nvidia-smi&#x27;s Lack of Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zeyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Adamek%2C+K">Karel Adamek</a>, 
<a href="/search/cs?searchtype=author&query=Armour%2C+W">Wesley Armour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">The GPU has emerged as the go-to accelerator for high throughput and parallel
workloads, spanning scientific simulations to AI, thanks to its performance and
power efficiency. Given that 6 out of the top 10 fastest supercomputers in the
world use NVIDIA GPUs and many AI companies each employ 10,000's of NVIDIA
GPUs, an accurate understanding of GPU power consumption is essential for
making progress to further improve its efficiency. Despite the limited
documentation and the lack of understanding of its mechanisms, NVIDIA GPUs'
built-in power sensor, providing easily accessible power readings via the
nvidia-smi interface, is widely used in energy efficient computing research on
GPUs. Our study seeks to elucidate the internal mechanisms of the power
readings provided by nvidia-smi and assess the accuracy of the power and energy
consumption data. We have developed a suite of micro-benchmarks to profile the
behaviour of nvidia-smi power readings and have evaluated them on over 70
different GPUs from all architectural generations since power measurement was
first introduced in the 'Fermi' generation. We have identified several
unforeseen problems in terms of power/energy measurement using nvidia-smi, for
example on the A100 and H100 GPUs only 25% of the runtime is sampled for power
consumption, during the other 75% of the time, the GPU can be using drastically
different power and nvidia-smi and results presented by it are unaware of this.
This along with other findings can lead to a drastic under/overestimation of
energy consumed, especially when considering data centres housing tens of
thousands of GPUs. We proposed several good practices that help to mitigate
these problems. By comparing our results to those measured from an external
power-meter, we have reduced the error in the energy measurement by an average
of 35% and in some cases by as much as 65% in the test cases we present.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02746" title="Abstract">arXiv:2312.02746</a> [<a href="/pdf/2312.02746" title="Download PDF">pdf</a>, <a href="/format/2312.02746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empowering the 6G Cellular Architecture with Open RAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Polese%2C+M">Michele Polese</a>, 
<a href="/search/cs?searchtype=author&query=Dohler%2C+M">Mischa Dohler</a>, 
<a href="/search/cs?searchtype=author&query=Dressler%2C+F">Falko Dressler</a>, 
<a href="/search/cs?searchtype=author&query=Erol-Kantarci%2C+M">Melike Erol-Kantarci</a>, 
<a href="/search/cs?searchtype=author&query=Jana%2C+R">Rittwik Jana</a>, 
<a href="/search/cs?searchtype=author&query=Knopp%2C+R">Raymond Knopp</a>, 
<a href="/search/cs?searchtype=author&query=Melodia%2C+T">Tommaso Melodia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is part of the IEEE JSAC SI on Open RAN. Please cite as: M. Polese, M. Dohler, F. Dressler, M. Erol-Kantarci, R. Jana, R. Knopp, T. Melodia, "Empowering the 6G Cellular Architecture with Open RAN," in IEEE Journal on Selected Areas in Communications, doi: 10.1109/JSAC.2023.3334610
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Journal on Selected Areas in Communications, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Innovation and standardization in 5G have brought advancements to every facet
of the cellular architecture. This ranges from the introduction of new
frequency bands and signaling technologies for the radio access network (RAN),
to a core network underpinned by micro-services and network function
virtualization (NFV). However, like any emerging technology, the pace of
real-world deployments does not instantly match the pace of innovation. To
address this discrepancy, one of the key aspects under continuous development
is the RAN with the aim of making it more open, adaptive, functional, and easy
to manage. In this paper, we highlight the transformative potential of
embracing novel cellular architectures by transitioning from conventional
systems to the progressive principles of Open RAN. This promises to make 6G
networks more agile, cost-effective, energy-efficient, and resilient. It opens
up a plethora of novel use cases, ranging from ubiquitous support for
autonomous devices to cost-effective expansions in regions previously
underserved. The principles of Open RAN encompass: (i) a disaggregated
architecture with modular and standardized interfaces; (ii) cloudification,
programmability and orchestration; and (iii) AI-enabled data-centric
closed-loop control and automation. We first discuss the transformative role
Open RAN principles have played in the 5G era. Then, we adopt a system-level
approach and describe how these Open RAN principles will support 6G RAN and
architecture innovation. We qualitatively discuss potential performance gains
that Open RAN principles yield for specific 6G use cases. For each principle,
we outline the steps that research, development and standardization communities
ought to take to make Open RAN principles central to next-generation cellular
network designs.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02748" title="Abstract">arXiv:2312.02748</a> [<a href="/pdf/2312.02748" title="Download PDF">pdf</a>, <a href="/format/2312.02748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Generalization for Data-to-Text Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xinnuo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Titov%2C+I">Ivan Titov</a>, 
<a href="/search/cs?searchtype=author&query=Lapata%2C+M">Mirella Lapata</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Data-to-text generation involves transforming structured data, often
represented as predicate-argument tuples, into coherent textual descriptions.
Despite recent advances, systems still struggle when confronted with unseen
combinations of predicates, producing unfaithful descriptions (e.g.
hallucinations or omissions). We refer to this issue as compositional
generalisation, and it encouraged us to create a benchmark for assessing the
performance of different approaches on this specific problem. Furthermore, we
propose a novel model that addresses compositional generalization by clustering
predicates into groups. Our model generates text in a sentence-by-sentence
manner, relying on one cluster of predicates at a time. This approach
significantly outperforms T5~baselines across all evaluation metrics.Notably,
it achieved a 31% improvement over T5 in terms of a metric focused on
maintaining faithfulness to the input.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02751" title="Abstract">arXiv:2312.02751</a> [<a href="/pdf/2312.02751" title="Download PDF">pdf</a>, <a href="/format/2312.02751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> C-NERF: Representing Scene Changes as Directional Consistency  Difference-based NeRF
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Rui Huang</a> (1), 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Binbin Jiang</a> (1), 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qingyi Zhao</a> (1), 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">William Wang</a> (2), 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuxiang Zhang</a> (1), 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qing Guo</a> (3 and 4) ((1) College of Computer Science and Technology, Civil Aviation University of China, China, (2) University of South Carolina, The USA, (3) IHPC, Agency for Science, Technology and Research, Singapore, (4) CFAR, Agency for Science, Technology and Research, Singapore)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this work, we aim to detect the changes caused by object variations in a
scene represented by the neural radiance fields (NeRFs). Given an arbitrary
view and two sets of scene images captured at different timestamps, we can
predict the scene changes in that view, which has significant potential
applications in scene monitoring and measuring. We conducted preliminary
studies and found that such an exciting task cannot be easily achieved by
utilizing existing NeRFs and 2D change detection methods with many false or
missing detections. The main reason is that the 2D change detection is based on
the pixel appearance difference between spatial-aligned image pairs and
neglects the stereo information in the NeRF. To address the limitations, we
propose the C-NERF to represent scene changes as directional consistency
difference-based NeRF, which mainly contains three modules. We first perform
the spatial alignment of two NeRFs captured before and after changes. Then, we
identify the change points based on the direction-consistent constraint; that
is, real change points have similar change representations across view
directions, but fake change points do not. Finally, we design the change map
rendering process based on the built NeRFs and can generate the change map of
an arbitrarily specified view direction. To validate the effectiveness, we
build a new dataset containing ten scenes covering diverse scenarios with
different changing objects. Our approach surpasses state-of-the-art 2D change
detection and NeRF-based methods by a significant margin.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02752" title="Abstract">arXiv:2312.02752</a> [<a href="/pdf/2312.02752" title="Download PDF">pdf</a>, <a href="/format/2312.02752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Airdrops: Giving Money Away Is Harder Than It Seems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Messias%2C+J">Johnnatan Messias</a>, 
<a href="/search/cs?searchtype=author&query=Yaish%2C+A">Aviv Yaish</a>, 
<a href="/search/cs?searchtype=author&query=Livshits%2C+B">Benjamin Livshits</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This research article is a work of scholarship and reflects the authors' own views and opinions. It does not necessarily reflect the views or opinions of any other person or organization, including the authors' employer. Readers should not rely on this article for making strategic or commercial decisions, and the authors are not responsible for any losses that may result from such use
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Airdrops are used by blockchain applications and platforms to attract an
initial user base, and to grow the user base over time. In the case of many
airdrops, tokens are distributed to select users as a "reward" for interacting
with the underlying platform, with a long-term goal of creating a loyal
community that will generate genuine economic activity well after the airdrop
has been completed. Although airdrops are widely used by the blockchain
industry, a proper understanding of the factors contributing to an airdrop's
success is generally lacking. In this work, we outline the design space for
airdrops, and specify a reasonable list of outcomes that an airdrop should
ideally result in. We then analyze on-chain data from several larger-scale
airdrops to empirically evaluate the success of previous airdrops, with respect
to our desiderata. In our analysis, we demonstrate that airdrop farmers
frequently dispose of the lion's share of airdrops proceeds via exchanges. Our
analysis is followed by an overview of common pitfalls that common airdrop
designs lend themselves to, which are then used to suggest concrete guidelines
for better airdrops.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02756" title="Abstract">arXiv:2312.02756</a> [<a href="/pdf/2312.02756" title="Download PDF">pdf</a>, <a href="/ps/2312.02756" title="Download PostScript">ps</a>, <a href="/format/2312.02756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GenVectorX: A performance-portable SYCL library for Lorentz Vectors  operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dessole%2C+M">Monica Dessole</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jolly Chen</a>, 
<a href="/search/cs?searchtype=author&query=Naumann%2C+A">Axel Naumann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The Large Hadron Collider (LHC) at CERN will see an upgraded hardware
configuration which will bring a new era of physics data taking and related
computational challenges. To this end, it is necessary to exploit the ever
increasing variety of computational architectures, featuring GPUs from multiple
vendors and new accelerators. Performance portable frameworks, like SYCL, allow
to offload the computational work on non-CPU resources, while retaining their
performance, without the need to maintain different implementations of the same
code. The High Energy Physics (HEP) community employs a wide variety of
algorithms and tools for accelerators, but it still lacks a streamlined
coherent approach that can target many use cases without compromising the
usability aspect. In this paper, we present our efforts in creating GenVectorX,
a C++ package that provides classes and functionalities to represent and
manipulate particle events using the SYCL programming model. The SYCL-based
implementation exhibits comparable performance and scalability as the CUDA
implementation when targeting NVIDIA GPUs.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02758" title="Abstract">arXiv:2312.02758</a> [<a href="/pdf/2312.02758" title="Download PDF">pdf</a>, <a href="/ps/2312.02758" title="Download PostScript">ps</a>, <a href="/format/2312.02758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Data-Driven Predictive Control: Regularization, Estimation,  and Constraint Tightening
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yin%2C+M">Mingzhou Yin</a>, 
<a href="/search/eess?searchtype=author&query=Iannelli%2C+A">Andrea Iannelli</a>, 
<a href="/search/eess?searchtype=author&query=Smith%2C+R+S">Roy S. Smith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Data-driven predictive control methods based on the Willems' fundamental
lemma have shown great success in recent years. These approaches use receding
horizon predictive control with nonparametric data-driven predictors instead of
model-based predictors. This study addresses three problems of applying such
algorithms under unbounded stochastic uncertainties: 1) tuning-free regularizer
design, 2) initial condition estimation, and 3) reliable constraint
satisfaction, by using stochastic prediction error quantification. The
regularizer is designed by leveraging the expected output cost. An initial
condition estimator is proposed by filtering the measurements with the
one-step-ahead stochastic data-driven prediction. A novel constraint-tightening
method, using second-order cone constraints, is presented to ensure
high-probability chance constraint satisfaction. Numerical results demonstrate
that the proposed methods lead to satisfactory control performance in terms of
both control cost and constraint satisfaction, with significantly improved
initial condition estimation.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02769" title="Abstract">arXiv:2312.02769</a> [<a href="/pdf/2312.02769" title="Download PDF">pdf</a>, <a href="/ps/2312.02769" title="Download PostScript">ps</a>, <a href="/format/2312.02769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blockchain Participation Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaidos%2C+P">Pyrros Chaidos</a>, 
<a href="/search/cs?searchtype=author&query=Kiayias%2C+A">Aggelos Kiayias</a>, 
<a href="/search/cs?searchtype=author&query=Markakis%2C+E">Evangelos Markakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We study game-theoretic models for capturing participation in blockchain
systems. Permissionless blockchains can be naturally viewed as games, where a
set of potentially interested users is faced with the dilemma of whether to
engage with the protocol or not. Engagement here implies that the user will be
asked to complete certain tasks, whenever they are selected to contribute
(typically according to some stochastic process) and be rewarded if they choose
to do so. Apart from the basic dilemma of engaging or not, even more strategic
considerations arise in settings where users may be able to declare
participation and then retract before completing their tasks (but are still
able to receive rewards) or are rewarded independently of whether they
contribute. Such variations occur naturally in the blockchain setting due to
the complexity of tracking ``on-chain'' the behavior of the participants.
<br />We capture these participation considerations offering a series of models
that enable us to reason about the basic dilemma, the case where retraction
effects influence the outcome and the case when payments are given universally
irrespective of the stochastic process. In all cases we provide
characterization results or necessary conditions on the structure of Nash
equilibria. Our findings reveal that appropriate reward mechanisms can be used
to stimulate participation and avoid negative effects of free riding, results
that are in line but also can inform real world blockchain system deployments.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02770" title="Abstract">arXiv:2312.02770</a> [<a href="/pdf/2312.02770" title="Download PDF">pdf</a>, <a href="/format/2312.02770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning &quot;Look-Ahead&quot; Nonlocal Traffic Dynamics in a Ring Road
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chenguang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Huan Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The macroscopic traffic flow model is widely used for traffic control and
management. To incorporate drivers' anticipative behaviors and to remove
impractical speed discontinuity inherent in the classic
Lighthill-Whitham-Richards (LWR) traffic model, nonlocal partial differential
equation (PDE) models with ``look-ahead" dynamics have been proposed, which
assume that the speed is a function of weighted downstream traffic density.
However, it lacks data validation on two important questions: whether there
exist nonlocal dynamics, and how the length and weight of the ``look-ahead"
window affect the spatial temporal propagation of traffic densities. In this
paper, we adopt traffic trajectory data from a ring-road experiment and design
a physics-informed neural network to learn the fundamental diagram and
look-ahead kernel that best fit the data, and reinvent a data-enhanced nonlocal
LWR model via minimizing the loss function combining the data discrepancy and
the nonlocal model discrepancy. Results show that the learned nonlocal LWR
yields a more accurate prediction of traffic wave propagation in three
different scenarios: stop-and-go oscillations, congested, and free traffic. We
first demonstrate the existence of ``look-ahead" effect with real traffic data.
The optimal nonlocal kernel is found out to take a length of around 35 to 50
meters, and the kernel weight within 5 meters accounts for the majority of the
nonlocal effect. Our results also underscore the importance of choosing a
priori physics in machine learning models.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02771" title="Abstract">arXiv:2312.02771</a> [<a href="/pdf/2312.02771" title="Download PDF">pdf</a>, <a href="/ps/2312.02771" title="Download PostScript">ps</a>, <a href="/format/2312.02771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling-up Memristor Monte Carlo with magnetic domain-wall physics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dalgaty%2C+T">Thomas Dalgaty</a>, 
<a href="/search/cs?searchtype=author&query=Yamada%2C+S">Shogo Yamada</a>, 
<a href="/search/cs?searchtype=author&query=Molnos%2C+A">Anca Molnos</a>, 
<a href="/search/cs?searchtype=author&query=Kawasaki%2C+E">Eiji Kawasaki</a>, 
<a href="/search/cs?searchtype=author&query=Mesquida%2C+T">Thomas Mesquida</a>, 
<a href="/search/cs?searchtype=author&query=Rummens%2C+F">Fran&#xe7;ois Rummens</a>, 
<a href="/search/cs?searchtype=author&query=Shibata%2C+T">Tatsuo Shibata</a>, 
<a href="/search/cs?searchtype=author&query=Urakawa%2C+Y">Yukihiro Urakawa</a>, 
<a href="/search/cs?searchtype=author&query=Terasaki%2C+Y">Yukio Terasaki</a>, 
<a href="/search/cs?searchtype=author&query=Sasaki%2C+T">Tomoyuki Sasaki</a>, 
<a href="/search/cs?searchtype=author&query=Duranton%2C+M">Marc Duranton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the 1st workshop on Machine Learning with New Compute Paradigms (MLNCP) at NeurIPS 2023 (New Orleans, USA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Applied Physics (physics.app-ph)

</div>
<p class="mathjax">By exploiting the intrinsic random nature of nanoscale devices, Memristor
Monte Carlo (MMC) is a promising enabler of edge learning systems. However, due
to multiple algorithmic and device-level limitations, existing demonstrations
have been restricted to very small neural network models and datasets. We
discuss these limitations, and describe how they can be overcome, by mapping
the stochastic gradient Langevin dynamics (SGLD) algorithm onto the physics of
magnetic domain-wall Memristors to scale-up MMC models by five orders of
magnitude. We propose the push-pull pulse programming method that realises SGLD
in-physics, and use it to train a domain-wall based ResNet18 on the CIFAR-10
dataset. On this task, we observe no performance degradation relative to a
floating point model down to an update precision of between 6 and 7-bits,
indicating we have made a step towards a large-scale edge learning system
leveraging noisy analogue devices.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02772" title="Abstract">arXiv:2312.02772</a> [<a href="/pdf/2312.02772" title="Download PDF">pdf</a>, <a href="/format/2312.02772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Fine-Grained Human Motions Using ChatGPT-Refined Descriptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Chuanchen Luo</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Junran Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yunlian Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://sx0207.github.io/fg-mdm/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, significant progress has been made in text-based motion generation,
enabling the generation of diverse and high-quality human motions that conform
to textual descriptions. However, it remains challenging to generate
fine-grained or stylized motions due to the lack of datasets annotated with
detailed textual descriptions. By adopting a divide-and-conquer strategy, we
propose a new framework named Fine-Grained Human Motion Diffusion Model
(FG-MDM) for human motion generation. Specifically, we first parse previous
vague textual annotation into fine-grained description of different body parts
by leveraging a large language model (GPT-3.5). We then use these fine-grained
descriptions to guide a transformer-based diffusion model. FG-MDM can generate
fine-grained and stylized motions even outside of the distribution of the
training data. Our experimental results demonstrate the superiority of FG-MDM
over previous methods, especially the strong generalization capability. We will
release our fine-grained textual annotations for HumanML3D and KIT.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02773" title="Abstract">arXiv:2312.02773</a> [<a href="/pdf/2312.02773" title="Download PDF">pdf</a>, <a href="/format/2312.02773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating Plug-and-Play Data Priors with Weighted Prediction Error for  Speech Dereverberation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ziye Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenxing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+K">Kai Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jie Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Speech dereverberation aims to alleviate the detrimental effects of
late-reverberant components. While the weighted prediction error (WPE) method
has shown superior performance in dereverberation, there is still room for
further improvement in terms of performance and robustness in complex and noisy
environments. Recent research has highlighted the effectiveness of integrating
physics-based and data-driven methods, enhancing the performance of various
signal processing tasks while maintaining interpretability. Motivated by these
advancements, this paper presents a novel dereverberation frame-work, which
incorporates data-driven methods for capturing speech priors within the WPE
framework. The plug-and-play strategy (PnP), specifically the regularization by
denoising (RED) strategy, is utilized to incorporate speech prior information
learnt from data during the optimization problem solving iterations.
Experimental results validate the effectiveness of the proposed approach.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02776" title="Abstract">arXiv:2312.02776</a> [<a href="/pdf/2312.02776" title="Download PDF">pdf</a>, <a href="/ps/2312.02776" title="Download PostScript">ps</a>, <a href="/format/2312.02776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Age of Information and Energy-Transfer in a STAR-RIS-assisted System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kavianinia%2C+M+R">Mohammad Reza Kavianinia</a>, 
<a href="/search/cs?searchtype=author&query=Setoode%2C+M+M">Mohammad Mehdi Setoode</a>, 
<a href="/search/cs?searchtype=author&query=Emadi%2C+M+J">Mohammad Javad Emadi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures, submitted in IEEE Transactions on Vehicular Technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Battery-limited devices and time-sensitive applications are considered as key
players in the forthcoming wireless sensor network. Therefore, the main goal of
the network is two-fold; Charge battery-limited devices, and provide status
updates to users where information-freshness matters. In this paper, a
multi-antenna base station (BS) in assistance of
simultaneously-transmitting-and-reflecting reconfigurable intelligent surface
(STAR-RIS) transmits power to energy-harvesting devices while controlling
status update performance at information-users by analyzing age of information
(AoI) metric. Therefore, we derive a scheduling policy at BS, and analyze joint
transmit beamforming and amplitude-phase optimization at BS and STAR-RIS,
respectively, to reduce average sum-AoI for the time-sensitive
information-users while satisfying minimum required energy at energy-harvesting
users. Moreover, two different energy-splitting and mode switching policies at
STAR-RIS are studied. Then, by use of an alternating optimization algorithm,
the optimization problem is studied and non-convexity of the problem is tackled
by using the successive convex approximation technique. Through numerical
results, AoI-metric and energy harvesting requirements of the network are
analyzed versus different parameters such as number of antennas at BS, size of
STAR-RIS, and transmitted power to highlight how we can improve two fold
performance of the system by utilizing STAR-RIS compared to the conventional
RIS structure.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02780" title="Abstract">arXiv:2312.02780</a> [<a href="/pdf/2312.02780" title="Download PDF">pdf</a>, <a href="/format/2312.02780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Laws for Adversarial Attacks on Language Model Activations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fort%2C+S">Stanislav Fort</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">We explore a class of adversarial attacks targeting the activations of
language models. By manipulating a relatively small subset of model
activations, $a$, we demonstrate the ability to control the exact prediction of
a significant number (in some cases up to 1000) of subsequent tokens $t$. We
empirically verify a scaling law where the maximum number of target tokens
$t_\mathrm{max}$ predicted depends linearly on the number of tokens $a$ whose
activations the attacker controls as $t_\mathrm{max} = \kappa a$. We find that
the number of bits of control in the input space needed to control a single bit
in the output space (what we call attack resistance $\chi$) is remarkably
constant between $\approx 16$ and $\approx 25$ over 2 orders of magnitude of
model sizes for different language models. Compared to attacks on tokens,
attacks on activations are predictably much stronger, however, we identify a
surprising regularity where one bit of input steered either via activations or
via tokens is able to exert control over a similar amount of output bits. This
gives support for the hypothesis that adversarial attacks are a consequence of
dimensionality mismatch between the input and output spaces. A practical
implication of the ease of attacking language model activations instead of
tokens is for multi-modal and selected retrieval models, where additional data
sources are added as activations directly, sidestepping the tokenized input.
This opens up a new, broad attack surface. By using language models as a
controllable test-bed to study adversarial attacks, we were able to experiment
with input-output dimensions that are inaccessible in computer vision,
especially where the output dimension dominates.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02781" title="Abstract">arXiv:2312.02781</a> [<a href="/pdf/2312.02781" title="Download PDF">pdf</a>, <a href="/format/2312.02781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PMMTalk: Speech-Driven 3D Facial Animation from Complementary Pseudo  Multi-modal Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+T">Tianshun Han</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+S">Shengnan Gui</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yiqing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Baihui Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lijian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Benjia Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+N">Ning Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Quan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhi%2C+R">Ruicong Zhi</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yanyan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Du Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+J">Jun Wan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Speech-driven 3D facial animation has improved a lot recently while most
related works only utilize acoustic modality and neglect the influence of
visual and textual cues, leading to unsatisfactory results in terms of
precision and coherence. We argue that visual and textual cues are not trivial
information. Therefore, we present a novel framework, namely PMMTalk, using
complementary Pseudo Multi-Modal features for improving the accuracy of facial
animation. The framework entails three modules: PMMTalk encoder, cross-modal
alignment module, and PMMTalk decoder. Specifically, the PMMTalk encoder
employs the off-the-shelf talking head generation architecture and speech
recognition technology to extract visual and textual information from speech,
respectively. Subsequently, the cross-modal alignment module aligns the
audio-image-text features at temporal and semantic levels. Then PMMTalk decoder
is employed to predict lip-syncing facial blendshape coefficients. Contrary to
prior methods, PMMTalk only requires an additional random reference face image
but yields more accurate results. Additionally, it is artist-friendly as it
seamlessly integrates into standard animation production workflows by
introducing facial blendshape coefficients. Finally, given the scarcity of 3D
talking face datasets, we introduce a large-scale 3D Chinese Audio-Visual
Facial Animation (3D-CAVFA) dataset. Extensive experiments and user studies
show that our approach outperforms the state of the art. We recommend watching
the supplementary video.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02783" title="Abstract">arXiv:2312.02783</a> [<a href="/pdf/2312.02783" title="Download PDF">pdf</a>, <a href="/format/2312.02783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models on Graphs: A Comprehensive Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+B">Bowen Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Gang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+C">Chi Han</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Meng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Heng Ji</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jiawei Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs), such as ChatGPT and LLaMA, are creating
significant advancements in natural language processing, due to their strong
text encoding/decoding ability and newly found emergent capability (e.g.,
reasoning). While LLMs are mainly designed to process pure texts, there are
many real-world scenarios where text data are associated with rich structure
information in the form of graphs (e.g., academic networks, and e-commerce
networks) or scenarios where graph data are paired with rich textual
information (e.g., molecules with descriptions). Besides, although LLMs have
shown their pure text-based reasoning ability, it is underexplored whether such
ability can be generalized to graph scenarios (i.e., graph-based reasoning). In
this paper, we provide a systematic review of scenarios and techniques related
to large language models on graphs. We first summarize potential scenarios of
adopting LLMs on graphs into three categories, namely pure graphs, text-rich
graphs, and text-paired graphs. We then discuss detailed techniques for
utilizing LLMs on graphs, including LLM as Predictor, LLM as Encoder, and LLM
as Aligner, and compare the advantages and disadvantages of different schools
of models. Furthermore, we mention the real-world applications of such methods
and summarize open-source codes and benchmark datasets. Finally, we conclude
with potential future research directions in this fast-growing field. The
related source can be found at
https://github.com/PeterGriffinJin/Awesome-Language-Model-on-Graphs.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02790" title="Abstract">arXiv:2312.02790</a> [<a href="/pdf/2312.02790" title="Download PDF">pdf</a>, <a href="/format/2312.02790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Low-cost, High-impact Node Injection Approach for Attacking Social  Network Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shuyu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yunxiang Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+X">Xian Mo</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Rui Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Social network alignment (SNA) holds significant importance for various
downstream applications, prompting numerous professionals to develop and share
SNA tools. Unfortunately, these tools can be exploited by malicious actors to
integrate sensitive user information, posing cybersecurity risks. While many
researchers have explored attacking SNA (ASNA) through a network modification
attack way, practical feasibility remains a challenge. This paper introduces a
novel approach, the node injection attack. To overcome the problem of modeling
and solving within a limited time and balancing costs and benefits, we propose
a low-cost, high-impact node injection attack via dynamic programming (DPNIA)
framework. DPNIA models ASNA as a problem of maximizing the number of confirmed
incorrect correspondent node pairs who have a greater similarity scores than
the pairs between existing nodes, making ASNA solvable. Meanwhile, it employs a
cross-network evaluation method to identify node vulnerability, facilitating a
progressive attack from easy to difficult. Additionally, it utilizes an optimal
injection strategy searching method, based on dynamic programming, to determine
which links should be added between injected nodes and existing nodes, thereby
achieving a high impact for attack effectiveness at a low cost. Experiments on
four real-world datasets consistently demonstrate that DPNIA consistently and
significantly outperforms various attack baselines.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02798" title="Abstract">arXiv:2312.02798</a> [<a href="/pdf/2312.02798" title="Download PDF">pdf</a>, <a href="/format/2312.02798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly Supervised Detection of Hallucinations in LLM Activations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rateike%2C+M">Miriam Rateike</a>, 
<a href="/search/cs?searchtype=author&query=Cintas%2C+C">Celia Cintas</a>, 
<a href="/search/cs?searchtype=author&query=Wamburu%2C+J">John Wamburu</a>, 
<a href="/search/cs?searchtype=author&query=Akumu%2C+T">Tanya Akumu</a>, 
<a href="/search/cs?searchtype=author&query=Speakman%2C+S">Skyler Speakman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">We propose an auditing method to identify whether a large language model
(LLM) encodes patterns such as hallucinations in its internal states, which may
propagate to downstream tasks. We introduce a weakly supervised auditing
technique using a subset scanning approach to detect anomalous patterns in LLM
activations from pre-trained models. Importantly, our method does not need
knowledge of the type of patterns a-priori. Instead, it relies on a reference
dataset devoid of anomalies during testing. Further, our approach enables the
identification of pivotal nodes responsible for encoding these patterns, which
may offer crucial insights for fine-tuning specific sub-networks for bias
mitigation. We introduce two new scanning methods to handle LLM activations for
anomalous sentences that may deviate from the expected distribution in either
direction. Our results confirm prior findings of BERT's limited internal
capacity for encoding hallucinations, while OPT appears capable of encoding
hallucination information internally. Importantly, our scanning approach,
without prior exposure to false statements, performs comparably to a fully
supervised out-of-distribution classifier.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02803" title="Abstract">arXiv:2312.02803</a> [<a href="/pdf/2312.02803" title="Download PDF">pdf</a>, <a href="/format/2312.02803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Domain Adaptation and Data Augmentation to Improve Qur&#x27;anic  IR in English and Arabic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pavlova%2C+V">Vera Pavlova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this work, we approach the problem of Qur'anic information retrieval (IR)
in Arabic and English. Using the latest state-of-the-art methods in neural IR,
we research what helps to tackle this task more efficiently. Training retrieval
models requires a lot of data, which is difficult to obtain for training
in-domain. Therefore, we commence with training on a large amount of general
domain data and then continue training on in-domain data. To handle the lack of
in-domain data, we employed a data augmentation technique, which considerably
improved results in MRR@10 and NDCG@5 metrics, setting the state-of-the-art in
Qur'anic IR for both English and Arabic. The absence of an Islamic corpus and
domain-specific model for IR task in English motivated us to address this lack
of resources and take preliminary steps of the Islamic corpus compilation and
domain-specific language model (LM) pre-training, which helped to improve the
performance of the retrieval models that use the domain-specific LM as the
shared backbone. We examined several language models (LMs) in Arabic to select
one that efficiently deals with the Qur'anic IR task. Besides transferring
successful experiments from English to Arabic, we conducted additional
experiments with retrieval task in Arabic to amortize the scarcity of general
domain datasets used to train the retrieval models. Handling Qur'anic IR task
combining English and Arabic allowed us to enhance the comparison and share
valuable insights across models and languages.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02804" title="Abstract">arXiv:2312.02804</a> [<a href="/pdf/2312.02804" title="Download PDF">pdf</a>, <a href="/format/2312.02804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Score-Aware Policy-Gradient Methods and Performance Guarantees using  Local Lyapunov Conditions: Applications to Product-Form Stochastic Networks  and Queueing Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Comte%2C+C">C&#xe9;line Comte</a>, 
<a href="/search/cs?searchtype=author&query=Jonckheere%2C+M">Matthieu Jonckheere</a>, 
<a href="/search/cs?searchtype=author&query=Sanders%2C+J">Jaron Sanders</a>, 
<a href="/search/cs?searchtype=author&query=Senen-Cerda%2C+A">Albert Senen-Cerda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Performance (cs.PF); Optimization and Control (math.OC); Probability (math.PR)

</div>
<p class="mathjax">Stochastic networks and queueing systems often lead to Markov decision
processes (MDPs) with large state and action spaces as well as nonconvex
objective functions, which hinders the convergence of many reinforcement
learning (RL) algorithms. Policy-gradient methods perform well on MDPs with
large state and action spaces, but they sometimes experience slow convergence
due to the high variance of the gradient estimator. In this paper, we show that
some of these difficulties can be circumvented by exploiting the structure of
the underlying MDP. We first introduce a new family of gradient estimators
called score-aware gradient estimators (SAGEs). When the stationary
distribution of the MDP belongs to an exponential family parametrized by the
policy parameters, SAGEs allow us to estimate the policy gradient without
relying on value-function estimation, contrary to classical policy-gradient
methods like actor-critic. To demonstrate their applicability, we examine two
common control problems arising in stochastic networks and queueing systems
whose stationary distributions have a product-form, a special case of
exponential families. As a second contribution, we show that, under appropriate
assumptions, the policy under a SAGE-based policy-gradient method has a large
probability of converging to an optimal policy, provided that it starts
sufficiently close to it, even with a nonconvex objective function and multiple
maximizers. Our key assumptions are that, locally around a maximizer, a
nondegeneracy property of the Hessian of the objective function holds and a
Lyapunov function exists. Finally, we conduct a numerical comparison between a
SAGE-based policy-gradient method and an actor-critic algorithm. The results
demonstrate that the SAGE-based method finds close-to-optimal policies more
rapidly, highlighting its superior performance over the traditional
actor-critic method.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02809" title="Abstract">arXiv:2312.02809</a> [<a href="/pdf/2312.02809" title="Download PDF">pdf</a>, <a href="/format/2312.02809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-implicit Continuous Newton Method for Power Flow Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yu%2C+R">Ruizhi Yu</a>, 
<a href="/search/eess?searchtype=author&query=Gu%2C+W">Wei Gu</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+S">Shuai Lu</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Y">Yijun Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper proposes a semi-implicit version of continuous Newton method (CNM)
for power flow analysis. The proposed method succeeds the numerical robustness
from the implicit CNM (ICNM) framework while prevents the iterative solution of
nonlinear systems, hence revealing higher convergence speed and computation
efficiency. The intractability of ICNM consists in its nonlinear implicit
ordinary-differential-equation (ODE) nature. We circumvent this by introducing
intermediate variables, hence converting the implicit ODEs into differential
algebraic equations (DAEs), and solve the DAEs with a linear scheme, the
stiffly accurate Rosenbrock type method (SARM). A new 4-stage 3rd-order
hyper-stable SARM, together with a 2nd-order embedded formula to control the
step size, is constructed. Case studies on system 9241pegase verified the
alleged performance.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02810" title="Abstract">arXiv:2312.02810</a> [<a href="/pdf/2312.02810" title="Download PDF">pdf</a>, <a href="/ps/2312.02810" title="Download PostScript">ps</a>, <a href="/format/2312.02810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using the SP!CE Framework to Code Influence Campaign Activity on Social  Media: Case Study on the 2022 Brazilian Presidential Election
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gosco%2C+A">Alexander Gosco</a>, 
<a href="/search/cs?searchtype=author&query=Brito%2C+C+P">Claudia Perez Brito</a>, 
<a href="/search/cs?searchtype=author&query=Ruesca%2C+B">Bryan Ruesca</a>, 
<a href="/search/cs?searchtype=author&query=Mendes%2C+A">Allen Mendes</a>, 
<a href="/search/cs?searchtype=author&query=Finlayson%2C+M+A">Mark A. Finlayson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 34 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">We describe a case study in the use of the Structured Process for Information
Campaign Enhancement (SP!CE, version 2.1) to evaluate influence campaigns
present in the 2nd round of the Brazilian presidential election in 2022
October. SP!CE is a US-military focused framework for describing both friendly
and adversary actions in influence campaigns, and is inter-operable with the
Disinformation Analysis and Risk Management (DISARM) framework. The purpose of
the case study is to demonstrate how SP!CE can be used to describe influence
campaign behaviors. We selected the Brazilian election as the target of the
case study as it is known that there were significant amounts of mis- and
disinformation present on social media during the campaigns. Our goal was to
demonstrate how SP!CE could be applied in such a context, showing how social
media content could be aligned with information campaign behaviors and how such
an alignment can be used to analyze which mis- and disinformation narratives
were in play. Additionally, we aim to provide insights on best practices
regarding how to apply the framework in further research. We release the coding
and screenshots of the relevant social media posts to support future research.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02812" title="Abstract">arXiv:2312.02812</a> [<a href="/pdf/2312.02812" title="Download PDF">pdf</a>, <a href="/format/2312.02812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulating Vision Impairment in Virtual Reality -- A Comparison of  Visual Task Performance with Real and Simulated Tunnel Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neugebauer%2C+A">Alexander Neugebauer</a>, 
<a href="/search/cs?searchtype=author&query=Castner%2C+N">Nora Castner</a>, 
<a href="/search/cs?searchtype=author&query=Severitt%2C+B">Bj&#xf6;rn Severitt</a>, 
<a href="/search/cs?searchtype=author&query=Stingl%2C+K">Katarina Stingl</a>, 
<a href="/search/cs?searchtype=author&query=Ivanov%2C+I">Iliya Ivanov</a>, 
<a href="/search/cs?searchtype=author&query=Wahl%2C+S">Siegfried Wahl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Purpose: In this work, we explore the potential and limitations of simulating
gaze-contingent tunnel vision conditions using Virtual Reality (VR) with
built-in eye tracking technology. This approach promises an easy and accessible
way of expanding study populations and test groups for visual training, visual
aids, or accessibility evaluations. However, it is crucial to assess the
validity and reliability of simulating these types of visual impairments and
evaluate the extend to which participants with simulated tunnel vision can
represent real patients. Methods: Two age-matched participant groups were
acquired: The first group (n=8 aged 20-60, average 49.1, sd 13.2) consisted of
patients diagnosed with Retinitis pigmentosa (RP). The second group (n=8, aged
27-59, average 46.5, sd 10.8) consisted of visually healthy participants with
simulated tunnel vision. Both groups carried out different visual tasks in a
virtual environment for 30 minutes per day over the course of four weeks. Task
performances as well as gaze characteristics were evaluated in both groups over
the course of the study. Results: Using the "two one-sided tests for
equivalence" method, the two groups were found to perform similar in all three
visual tasks. Significant differences between groups were found in different
aspects of their gaze behavior, though most of these aspects seem to converge
over time. Conclusion: Our study evaluates the potential and limitations of
using Virtual Reality technology to simulate the effects of tunnel vision
within controlled virtual environments. We find that the simulation accurately
represents performance of RP patients in the context of group averages, but
fails to fully replicate effects on gaze behavior.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02813" title="Abstract">arXiv:2312.02813</a> [<a href="/pdf/2312.02813" title="Download PDF">pdf</a>, <a href="/format/2312.02813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BIVDiff: A Training-Free Framework for General-Purpose Video Synthesis  via Bridging Image and Video Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+F">Fengyuan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiaxi Gu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Songcen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Limin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Diffusion models have made tremendous progress in text-driven image and video
generation. Now text-to-image foundation models are widely applied to various
downstream image synthesis tasks, such as controllable image generation and
image editing, while downstream video synthesis tasks are less explored for
several reasons. First, it requires huge memory and compute overhead to train a
video generation foundation model. Even with video foundation models,
additional costly training is still required for downstream video synthesis
tasks. Second, although some works extend image diffusion models into videos in
a training-free manner, temporal consistency cannot be well kept. Finally,
these adaption methods are specifically designed for one task and fail to
generalize to different downstream video synthesis tasks. To mitigate these
issues, we propose a training-free general-purpose video synthesis framework,
coined as BIVDiff, via bridging specific image diffusion models and general
text-to-video foundation diffusion models. Specifically, we first use an image
diffusion model (like ControlNet, Instruct Pix2Pix) for frame-wise video
generation, then perform Mixed Inversion on the generated video, and finally
input the inverted latents into the video diffusion model for temporal
smoothing. Decoupling image and video models enables flexible image model
selection for different purposes, which endows the framework with strong task
generalization and high efficiency. To validate the effectiveness and general
use of BIVDiff, we perform a wide range of video generation tasks, including
controllable video generation video editing, video inpainting and outpainting.
Our project page is available at https://bivdiff.github.io.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02819" title="Abstract">arXiv:2312.02819</a> [<a href="/pdf/2312.02819" title="Download PDF">pdf</a>, <a href="/format/2312.02819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deterministic Guidance Diffusion Model for Probabilistic Weather  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoon%2C+D">Donggeun Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+M">Minseok Seo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Doyi Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yeji Choi</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+D">Donghyeon Cho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Weather forecasting requires not only accuracy but also the ability to
perform probabilistic prediction. However, deterministic weather forecasting
methods do not support probabilistic predictions, and conversely, probabilistic
models tend to be less accurate. To address these challenges, in this paper, we
introduce the \textbf{\textit{D}}eterministic \textbf{\textit{G}}uidance
\textbf{\textit{D}}iffusion \textbf{\textit{M}}odel (DGDM) for probabilistic
weather forecasting, integrating benefits of both deterministic and
probabilistic approaches. During the forward process, both the deterministic
and probabilistic models are trained end-to-end. In the reverse process,
weather forecasting leverages the predicted result from the deterministic
model, using as an intermediate starting point for the probabilistic model. By
fusing deterministic models with probabilistic models in this manner, DGDM is
capable of providing accurate forecasts while also offering probabilistic
predictions. To evaluate DGDM, we assess it on the global weather forecasting
dataset (WeatherBench) and the common video frame prediction benchmark (Moving
MNIST). We also introduce and evaluate the Pacific Northwest Windstorm
(PNW)-Typhoon weather satellite dataset to verify the effectiveness of DGDM in
high-resolution regional forecasting. As a result of our experiments, DGDM
achieves state-of-the-art results not only in global forecasting but also in
regional forecasting. The code is available at:
\url{https://github.com/DongGeun-Yoon/DGDM}.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02820" title="Abstract">arXiv:2312.02820</a> [<a href="/pdf/2312.02820" title="Download PDF">pdf</a>, <a href="/format/2312.02820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clustering Pseudo Language Family in Multilingual Translation Models  with Fisher Information Matrix
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xinyu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuebo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In multilingual translation research, the comprehension and utilization of
language families are of paramount importance. Nevertheless, clustering
languages based solely on their ancestral families can yield suboptimal results
due to variations in the datasets employed during the model's training phase.
To mitigate this challenge, we introduce an innovative method that leverages
the fisher information matrix (FIM) to cluster language families, anchored on
the multilingual translation model's characteristics. We hypothesize that
language pairs with similar effects on model parameters exhibit a considerable
degree of linguistic congruence and should thus be grouped cohesively. This
concept has led us to define pseudo language families. We provide an in-depth
discussion regarding the inception and application of these pseudo language
families. Empirical evaluations reveal that employing these pseudo language
families enhances performance over conventional language families in adapting a
multilingual translation model to unfamiliar language pairs. The proposed
methodology may also be extended to scenarios requiring language similarity
measurements. The source code and associated scripts can be accessed at
https://github.com/ecoli-hit/PseudoFamily.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02821" title="Abstract">arXiv:2312.02821</a> [<a href="/pdf/2312.02821" title="Download PDF">pdf</a>, <a href="/format/2312.02821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RotaTR: Detection Transformer for Dense and Rotated Object
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuke%2C+Z">Zhu Yuke</a>, 
<a href="/search/cs?searchtype=author&query=Yumeng%2C+R">Ruan Yumeng</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Y">Yang Lei</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+G">Guo Sheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Detecting the objects in dense and rotated scenes is a challenging task.
Recent works on this topic are mostly based on Faster RCNN or Retinanet. As
they are highly dependent on the pre-set dense anchors and the NMS operation,
the approach is indirect and suboptimal.The end-to-end DETR-based detectors
have achieved great success in horizontal object detection and many other areas
like segmentation, tracking, action recognition and etc.However, the DETR-based
detectors perform poorly on dense rotated target tasks and perform worse than
most modern CNN-based detectors. In this paper, we find the most significant
reason for the poor performance is that the original attention can not
accurately focus on the oriented targets. Accordingly, we propose Rotated
object detection TRansformer (RotaTR) as an extension of DETR to oriented
detection. Specifically, we design Rotation Sensitive deformable (RSDeform)
attention to enhance the DETR's ability to detect oriented targets. It is used
to build the feature alignment module and rotation-sensitive decoder for our
model. We test RotaTR on four challenging-oriented benchmarks. It shows a great
advantage in detecting dense and oriented objects compared to the original
DETR. It also achieves competitive results when compared to the
state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02825" title="Abstract">arXiv:2312.02825</a> [<a href="/pdf/2312.02825" title="Download PDF">pdf</a>, <a href="/format/2312.02825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-consistent integration of mechanical systems based on Livens  principle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kinon%2C+P+L">Philipp L. Kinon</a>, 
<a href="/search/cs?searchtype=author&query=Betsch%2C+P">Peter Betsch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures, Proceeding for the ECCOMAS Thematic Conference on Multibody Dynamics July 24 - 28, 2023, Lisbon, Portugal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Dynamical Systems (math.DS); Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this work we make us of Livens principle (sometimes also referred to as
Hamilton-Pontryagin principle) in order to obtain a novel structure-preserving
integrator for mechanical systems. In contrast to the canonical Hamiltonian
equations of motion, the Euler-Lagrange equations pertaining to Livens
principle circumvent the need to invert the mass matrix. This is an essential
advantage with respect to singular mass matrices, which can yield severe
difficulties for the modelling and simulation of multibody systems. Moreover,
Livens principle unifies both Lagrangian and Hamiltonian viewpoints on
mechanics. Additionally, the present framework avoids the need to set up the
system's Hamiltonian. The novel scheme algorithmically conserves a general
energy function and aims at the preservation of momentum maps corresponding to
symmetries of the system. We present an extension to mechanical systems subject
to holonomic constraints. The performance of the newly devised method is
studied in representative examples.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02826" title="Abstract">arXiv:2312.02826</a> [<a href="/pdf/2312.02826" title="Download PDF">pdf</a>, <a href="/format/2312.02826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calibrated Adaptive Teacher for Domain Adaptive Intelligent Fault  Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Forest%2C+F">Florent Forest</a>, 
<a href="/search/cs?searchtype=author&query=Fink%2C+O">Olga Fink</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages. Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP); Machine Learning (stat.ML)

</div>
<p class="mathjax">Intelligent Fault Diagnosis (IFD) based on deep learning has proven to be an
effective and flexible solution, attracting extensive research. Deep neural
networks can learn rich representations from vast amounts of representative
labeled data for various applications. In IFD, they achieve high classification
performance from signals in an end-to-end manner, without requiring extensive
domain knowledge. However, deep learning models usually only perform well on
the data distribution they have been trained on. When applied to a different
distribution, they may experience performance drops. This is also observed in
IFD, where assets are often operated in working conditions different from those
in which labeled data have been collected. Unsupervised domain adaptation (UDA)
deals with the scenario where labeled data are available in a source domain,
and only unlabeled data are available in a target domain, where domains may
correspond to operating conditions. Recent methods rely on training with
confident pseudo-labels for target samples. However, the confidence-based
selection of pseudo-labels is hindered by poorly calibrated confidence
estimates in the target domain, primarily due to over-confident predictions,
which limits the quality of pseudo-labels and leads to error accumulation. In
this paper, we propose a novel UDA method called Calibrated Adaptive Teacher
(CAT), where we propose to calibrate the predictions of the teacher network
throughout the self-training process, leveraging post-hoc calibration
techniques. We evaluate CAT on domain-adaptive IFD and perform extensive
experiments on the Paderborn benchmark for bearing fault diagnosis under
varying operating conditions. Our proposed method achieves state-of-the-art
performance on most transfer tasks.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02827" title="Abstract">arXiv:2312.02827</a> [<a href="/pdf/2312.02827" title="Download PDF">pdf</a>, <a href="/format/2312.02827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing $k$-Crossing Visibility through $k$-levels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duque%2C+F">Frank Duque</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">Let $\mathcal{A}$ be an arrangement of straight lines in the plane (or planes
in $\mathbb{R}^3$). The $k$-crossing visibility of a point $p$ on $\mathcal{A}$
is the set of point $q$ in elements of $\mathcal{A}$ such that the segment $pq$
intersects at most $k$ elements of $\mathcal{A}$. In this paper, we obtain
algorithms for computing the $k$-crossing visibility. In particular we obtain
$O(n\log n + kn)$ and $O(n\log n + k^2n)$ time algorithms, for arrangements of
lines in the plane and planes in $\mathbb{R}^3$; which are optimal for
$k=\Omega(\log n)$ and $k=\Omega(\sqrt{\log n})$, respectively. We also
introduce another algorithm for computing $k$-crossing visibilities on
polygons, which reaches the same asymptotical time as the one presented by
Bahoo et al. The ideas introduced in this paper can be easily adapted for
obtaining $k$-crossing visibilities on other arrangements whose $(\leq
k)$-level is known.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02829" title="Abstract">arXiv:2312.02829</a> [<a href="/pdf/2312.02829" title="Download PDF">pdf</a>, <a href="/format/2312.02829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MIMONets: Multiple-Input-Multiple-Output Neural Networks Exploiting  Computation in Superposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Menet%2C+N">Nicolas Menet</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Hersche%2C+M">Michael Hersche</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Karunaratne%2C+G">Geethan Karunaratne</a> (1), 
<a href="/search/cs?searchtype=author&query=Benini%2C+L">Luca Benini</a> (2), 
<a href="/search/cs?searchtype=author&query=Sebastian%2C+A">Abu Sebastian</a> (1), 
<a href="/search/cs?searchtype=author&query=Rahimi%2C+A">Abbas Rahimi</a> (1) ((1) IBM Research - Zurich, (2) ETH Zurich)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted in NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">With the advent of deep learning, progressively larger neural networks have
been designed to solve complex tasks. We take advantage of these capacity-rich
models to lower the cost of inference by exploiting computation in
superposition. To reduce the computational burden per input, we propose
Multiple-Input-Multiple-Output Neural Networks (MIMONets) capable of handling
many inputs at once. MIMONets augment various deep neural network architectures
with variable binding mechanisms to represent an arbitrary number of inputs in
a compositional data structure via fixed-width distributed representations.
Accordingly, MIMONets adapt nonlinear neural transformations to process the
data structure holistically, leading to a speedup nearly proportional to the
number of superposed input items in the data structure. After processing in
superposition, an unbinding mechanism recovers each transformed input of
interest. MIMONets also provide a dynamic trade-off between accuracy and
throughput by an instantaneous on-demand switching between a set of
accuracy-throughput operating points, yet within a single set of fixed
parameters. We apply the concept of MIMONets to both CNN and Transformer
architectures resulting in MIMOConv and MIMOFormer, respectively. Empirical
evaluations show that MIMOConv achieves about 2-4 x speedup at an accuracy
delta within [+0.68, -3.18]% compared to WideResNet CNNs on CIFAR10 and
CIFAR100. Similarly, MIMOFormer can handle 2-4 inputs at once while maintaining
a high average accuracy within a [-1.07, -3.43]% delta on the long range arena
benchmark. Finally, we provide mathematical bounds on the interference between
superposition channels in MIMOFormer. Our code is available at
https://github.com/IBM/multiple-input-multiple-output-nets.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02831" title="Abstract">arXiv:2312.02831</a> [<a href="/pdf/2312.02831" title="Download PDF">pdf</a>, <a href="/format/2312.02831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detection of Seismic Infrasonic Elephant Rumbles Using Spectrogram-Based  Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Costa%2C+A+M+J+V">A. M. J. V. Costa</a>, 
<a href="/search/cs?searchtype=author&query=Pallikkonda%2C+C+S">C. S. Pallikkonda</a>, 
<a href="/search/cs?searchtype=author&query=Hiroshan%2C+H+H+R">H. H. R. Hiroshan</a>, 
<a href="/search/cs?searchtype=author&query=Gamlath%2C+G+R+U+Y">G. R. U. Y. Gamlath</a>, 
<a href="/search/cs?searchtype=author&query=Munasinghe%2C+S+R">S. R. Munasinghe</a>, 
<a href="/search/cs?searchtype=author&query=Edussooriya%2C+C+U+S">C. U. S. Edussooriya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures, journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Geophysics (physics.geo-ph)

</div>
<p class="mathjax">This paper presents an effective method of identifying elephant rumbles in
infrasonic seismic signals. The design and implementation of electronic
circuitry to amplify, filter, and digitize the seismic signals captured through
geophones are presented. A collection of seismic infrasonic elephant rumbles
was collected at a free-ranging area of an elephant orphanage in Sri Lanka. The
seismic rumbles were converted to spectrograms, and several methods were used
for spectral feature extraction. Using LasyPredict, the features extracted
using different methods were fed into their corresponding machine-learning
algorithms to train them for automatic seismic rumble identification. It was
found that the Mel frequency cepstral coefficient (MFCC) together with the
Ridge classifier machine learning algorithm produced the best performance in
identifying seismic elephant rumbles. A novel method for denoising the spectrum
that leads to enhanced accuracy in identifying seismic rumbles is also
presented.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02839" title="Abstract">arXiv:2312.02839</a> [<a href="/pdf/2312.02839" title="Download PDF">pdf</a>, <a href="/format/2312.02839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-complexity Linear Multicast Beamforming for Cache-aided MIMO  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=NaseriTehrani%2C+M">Mohammad NaseriTehrani</a>, 
<a href="/search/cs?searchtype=author&query=Salehi%2C+M">MohammadJavad Salehi</a>, 
<a href="/search/cs?searchtype=author&query=T%C3%B6lli%2C+A">Antti T&#xf6;lli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">A practical and scalable multicast beamformer design in multi-input
multi-output~(MIMO) coded caching~(CC) systems is introduced in this paper. The
proposed approach allows multicast transmission to multiple groups with
partially overlapping user sets using receiver dimensions to distinguish
between different group-specific streams. Additionally, it provides flexibility
in accommodating various parameter configurations of the MIMO-CC setup and
overcomes practical limitations, such as the requirement to use successive
interference cancellation~(SIC) at the receiver, while achieving the same
degrees-of-freedom~(DoF). To evaluate the proposed scheme, we define the
symmetric rate as the sum rate of the partially overlapping streams received
per user, comprising a linear multistream multicast transmission vector and the
linear minimum mean square error~(LMMSE) receiver. The resulting non-convex
symmetric rate maximization problem is solved using alternative optimization
and successive convex approximation~(SCA). Moreover, a fast iterative
Lagrangian-based algorithm is developed, significantly reducing the
computational overhead compared to previous designs. The effectiveness of our
proposed method is demonstrated by extensive simulations.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02843" title="Abstract">arXiv:2312.02843</a> [<a href="/pdf/2312.02843" title="Download PDF">pdf</a>, <a href="/format/2312.02843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Vision Transformers More Data Hungry Than Newborn Visual Systems?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pandey%2C+L">Lalit Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Wood%2C+S+M+W">Samantha M. W. Wood</a>, 
<a href="/search/cs?searchtype=author&query=Wood%2C+J+N">Justin N. Wood</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Vision transformers (ViTs) are top performing models on many computer vision
benchmarks and can accurately predict human behavior on object recognition
tasks. However, researchers question the value of using ViTs as models of
biological learning because ViTs are thought to be more data hungry than
brains, with ViTs requiring more training data to reach similar levels of
performance. To test this assumption, we directly compared the learning
abilities of ViTs and animals, by performing parallel controlled rearing
experiments on ViTs and newborn chicks. We first raised chicks in impoverished
visual environments containing a single object, then simulated the training
data available in those environments by building virtual animal chambers in a
video game engine. We recorded the first-person images acquired by agents
moving through the virtual chambers and used those images to train self
supervised ViTs that leverage time as a teaching signal, akin to biological
visual systems. When ViTs were trained through the eyes of newborn chicks, the
ViTs solved the same view invariant object recognition tasks as the chicks.
Thus, ViTs were not more data hungry than newborn visual systems: both learned
view invariant object representations in impoverished visual environments. The
flexible and generic attention based learning mechanism in ViTs combined with
the embodied data streams available to newborn animals appears sufficient to
drive the development of animal-like object recognition.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02845" title="Abstract">arXiv:2312.02845</a> [<a href="/pdf/2312.02845" title="Download PDF">pdf</a>, <a href="/ps/2312.02845" title="Download PostScript">ps</a>, <a href="/format/2312.02845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Review of Password-less User Authentication Schemes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oduguwa%2C+T">Tunde Oduguwa</a>, 
<a href="/search/cs?searchtype=author&query=Arabo%2C+A">Abdullahi Arabo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, submitted to Internet Technology Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Since the demise of the password was predicted in 2004, different attempts in
industry and academia have been made to create an alternative for the use of
passwords in authentication, without compromising on security and user
experience. This review examines password-less authentication schemes that have
been proposed since after the death knell was placed on passwords in 2004. We
start with a brief discussion of the requirements of authentication systems and
then identify various password-less authentication proposals to date. We then
evaluate the truly password-less and practical schemes using a framework that
examines authentication credentials based on their impact on user experience,
overall security, and ease of deployment. The findings of this review observe a
difficulty in balancing security with a user experience compared to that of
passwords in new password-less schemes, providing the opportunity for new
applied research to leverage existing knowledge and combine technologies and
techniques in innovative ways that can address this imbalance.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02847" title="Abstract">arXiv:2312.02847</a> [<a href="/pdf/2312.02847" title="Download PDF">pdf</a>, <a href="/format/2312.02847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A complex-projected Rayleigh quotient iteration for targeting interior  eigenvalues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Friess%2C+N">Nils Friess</a>, 
<a href="/search/math?searchtype=author&query=Gilbert%2C+A+D">Alexander D. Gilbert</a>, 
<a href="/search/math?searchtype=author&query=Scheichl%2C+R">Robert Scheichl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 6 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We introduce a new Projected Rayleigh Quotient Iteration aimed at improving
the convergence behaviour of classic Rayleigh Quotient iteration (RQI) by
incorporating approximate information about the target eigenvector at each
step. While classic RQI exhibits local cubic convergence for Hermitian
matrices, its global behaviour can be unpredictable, whereby it may converge to
an eigenvalue far away from the target, even when started with accurate initial
conditions. This problem is exacerbated when the eigenvalues are closely
spaced. The key idea of the new algorithm is at each step to add a
complex-valued projection to the original matrix (that depends on the current
eigenvector approximation), such that the unwanted eigenvalues are lifted into
the complex plane while the target stays close to the real line, thereby
increasing the spacing between the target eigenvalue and the rest of the
spectrum. Making better use of the eigenvector approximation leads to more
robust convergence behaviour and the new method converges reliably to the
correct target eigenpair for a significantly wider range of initial vectors
than does classic RQI. We prove that the method converges locally cubically and
we present several numerical examples demonstrating the improved global
convergence behaviour. In particular, we apply it to compute eigenvalues in a
band-gap spectrum of a Sturm-Liouville operator used to model photonic crystal
fibres, where the target and unwanted eigenvalues are closely spaced. The
examples show that the new method converges to the desired eigenpair even when
the eigenvalue spacing is very small, often succeeding when classic RQI fails.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02851" title="Abstract">arXiv:2312.02851</a> [<a href="/pdf/2312.02851" title="Download PDF">pdf</a>, <a href="/format/2312.02851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Checkpoint-based rollback recovery in session programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mezzina%2C+C+A">Claudio Antares Mezzina</a>, 
<a href="/search/cs?searchtype=author&query=Tiezzi%2C+F">Francesco Tiezzi</a>, 
<a href="/search/cs?searchtype=author&query=Yoshida%2C+N">Nobuko Yoshida</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">To react to unforeseen circumstances or amend abnormal situations in
communication-centric systems, programmers are in charge of "undoing" the
interactions which led to an undesired state. To assist this task,
session-based languages can be endowed with reversibility mechanisms. In this
paper we propose a language enriched with programming facilities to commit
session interactions, to roll back the computation to a previous commit point,
and to abort the session. Rollbacks in our language always bring the system to
previous visited states and a rollback cannot bring the system back to a point
prior to the last commit. Programmers are relieved from the burden of ensuring
that a rollback never restores a checkpoint imposed by a session participant
different from the rollback requester. Such undesired situations are prevented
at design-time (statically) by relying on a decidable compliance check at the
type level, implemented in MAUDE. We show that the language satisfies
error-freedom and progress of a session.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02852" title="Abstract">arXiv:2312.02852</a> [<a href="/pdf/2312.02852" title="Download PDF">pdf</a>, <a href="/format/2312.02852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expert-guided Bayesian Optimisation for Human-in-the-loop Experimental  Design of Known Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Savage%2C+T">Tom Savage</a>, 
<a href="/search/cs?searchtype=author&query=del+Rio+Chanona%2C+E+A">Ehecatl Antonio del Rio Chanona</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Workshop on Adaptive Experimental Design and Active Learning in the Real World. Main text: 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC); Optimization and Control (math.OC)

</div>
<p class="mathjax">Domain experts often possess valuable physical insights that are overlooked
in fully automated decision-making processes such as Bayesian optimisation. In
this article we apply high-throughput (batch) Bayesian optimisation alongside
anthropological decision theory to enable domain experts to influence the
selection of optimal experiments. Our methodology exploits the hypothesis that
humans are better at making discrete choices than continuous ones and enables
experts to influence critical early decisions. At each iteration we solve an
augmented multi-objective optimisation problem across a number of alternate
solutions, maximising both the sum of their utility function values and the
determinant of their covariance matrix, equivalent to their total variability.
By taking the solution at the knee point of the Pareto front, we return a set
of alternate solutions at each iteration that have both high utility values and
are reasonably distinct, from which the expert selects one for evaluation. We
demonstrate that even in the case of an uninformed practitioner, our algorithm
recovers the regret of standard Bayesian optimisation.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02855" title="Abstract">arXiv:2312.02855</a> [<a href="/pdf/2312.02855" title="Download PDF">pdf</a>, <a href="/format/2312.02855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Error Bits for Memory Failure Prediction: An In-Depth  Correlative Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qiao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wengui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cardoso%2C+J">Jorge Cardoso</a>, 
<a href="/search/cs?searchtype=author&query=Kao%2C+O">Odej Kao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ICCAD 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE/ACM International Conference on Computer Aided Design
  (ICCAD), San Francisco, CA, USA, 2023, pp. 01-09
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">In large-scale datacenters, memory failure is a common cause of server
crashes, with uncorrectable errors (UEs) being a major indicator of Dual Inline
Memory Module (DIMM) defects. Existing approaches primarily focus on predicting
UEs using correctable errors (CEs), without fully considering the information
provided by error bits. However, error bit patterns have a strong correlation
with the occurrence of uncorrectable errors (UEs). In this paper, we present a
comprehensive study on the correlation between CEs and UEs, specifically
emphasizing the importance of spatio-temporal error bit information. Our
analysis reveals a strong correlation between spatio-temporal error bits and UE
occurrence. Through evaluations using real-world datasets, we demonstrate that
our approach significantly improves prediction performance by 15% in F1-score
compared to the state-of-the-art algorithms. Overall, our approach effectively
reduces the number of virtual machine interruptions caused by UEs by
approximately 59%.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02858" title="Abstract">arXiv:2312.02858</a> [<a href="/pdf/2312.02858" title="Download PDF">pdf</a>, <a href="/format/2312.02858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Causal Representations of Climate Model Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boussard%2C+J">Julien Boussard</a>, 
<a href="/search/cs?searchtype=author&query=Nagda%2C+C">Chandni Nagda</a>, 
<a href="/search/cs?searchtype=author&query=Kaltenborn%2C+J">Julia Kaltenborn</a>, 
<a href="/search/cs?searchtype=author&query=Lange%2C+C+E+E">Charlotte Emilie Elektra Lange</a>, 
<a href="/search/cs?searchtype=author&query=Brouillard%2C+P">Philippe Brouillard</a>, 
<a href="/search/cs?searchtype=author&query=Gurwicz%2C+Y">Yaniv Gurwicz</a>, 
<a href="/search/cs?searchtype=author&query=Nowack%2C+P">Peer Nowack</a>, 
<a href="/search/cs?searchtype=author&query=Rolnick%2C+D">David Rolnick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Atmospheric and Oceanic Physics (physics.ao-ph); Methodology (stat.ME)

</div>
<p class="mathjax">Climate models, such as Earth system models (ESMs), are crucial for
simulating future climate change based on projected Shared Socioeconomic
Pathways (SSP) greenhouse gas emissions scenarios. While ESMs are sophisticated
and invaluable, machine learning-based emulators trained on existing simulation
data can project additional climate scenarios much faster and are
computationally efficient. However, they often lack generalizability and
interpretability. This work delves into the potential of causal representation
learning, specifically the \emph{Causal Discovery with Single-parent Decoding}
(CDSD) method, which could render climate model emulation efficient
\textit{and} interpretable. We evaluate CDSD on multiple climate datasets,
focusing on emissions, temperature, and precipitation. Our findings shed light
on the challenges, limitations, and promise of using CDSD as a stepping stone
towards more interpretable and robust climate model emulation.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02859" title="Abstract">arXiv:2312.02859</a> [<a href="/pdf/2312.02859" title="Download PDF">pdf</a>, <a href="/format/2312.02859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lessons from Usable ML Deployments and Application to Wind Turbine  Monitoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zytek%2C+A">Alexandra Zytek</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei-En Wang</a>, 
<a href="/search/cs?searchtype=author&query=Koukoura%2C+S">Sofia Koukoura</a>, 
<a href="/search/cs?searchtype=author&query=Veeramachaneni%2C+K">Kalyan Veeramachaneni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented in XAI in Action: Past, Present, and Future Applications @ NeurIPS 2023. 8 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Through past experiences deploying what we call usable ML (one step beyond
explainable ML, including both explanations and other augmenting information)
to real-world domains, we have learned three key lessons. First, many
organizations are beginning to hire people who we call ``bridges'' because they
bridge the gap between ML developers and domain experts, and these people fill
a valuable role in developing usable ML applications. Second, a configurable
system that enables easily iterating on usable ML interfaces during
collaborations with bridges is key. Finally, there is a need for continuous,
in-deployment evaluations to quantify the real-world impact of usable ML.
Throughout this paper, we apply these lessons to the task of wind turbine
monitoring, an essential task in the renewable energy domain. Turbine engineers
and data analysts must decide whether to perform costly in-person
investigations on turbines to prevent potential cases of brakepad failure, and
well-tuned usable ML interfaces can aid with this decision-making process.
Through the applications of our lessons to this task, we hope to demonstrate
the potential real-world impact of usable ML in the renewable energy domain.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02863" title="Abstract">arXiv:2312.02863</a> [<a href="/pdf/2312.02863" title="Download PDF">pdf</a>, <a href="/format/2312.02863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A look at the Kolmogorov complexity of finite groupoids and algebras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Card%C3%B3%2C+C">Carles Card&#xf3;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The incompressibility method is a counting argument in the framework of
algorithmic complexity that permits discovering properties that are satisfied
by most objects of a class. This paper gives a preliminary insight into
Kolmogorov's complexity of groupoids and some algebras. The incompressibility
method shows that almost all the groupoids are asymmetric and simple: Only
trivial or constant homomorphisms are possible. However, highly random
groupoids allow subgroupoids with interesting restrictions that reveal
intrinsic structural properties. We also study the issue of the algebraic
varieties and wonder which equational identities allow randomness.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02867" title="Abstract">arXiv:2312.02867</a> [<a href="/pdf/2312.02867" title="Download PDF">pdf</a>, <a href="/format/2312.02867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Supervised Health Index Monitoring with Feature Generation and  Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frusque%2C+G">Ga&#xeb;tan Frusque</a>, 
<a href="/search/cs?searchtype=author&query=Nejjar%2C+I">Ismail Nejjar</a>, 
<a href="/search/cs?searchtype=author&query=Nabavi%2C+M">Majid Nabavi</a>, 
<a href="/search/cs?searchtype=author&query=Fink%2C+O">Olga Fink</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">The Health Index (HI) is crucial for evaluating system health, aiding tasks
like anomaly detection and predicting remaining useful life for systems
demanding high safety and reliability. Tight monitoring is crucial for
achieving high precision at a lower cost, with applications such as spray
coating. Obtaining HI labels in real-world applications is often
cost-prohibitive, requiring continuous, precise health measurements. Therefore,
it is more convenient to leverage run-to failure datasets that may provide
potential indications of machine wear condition, making it necessary to apply
semi-supervised tools for HI construction. In this study, we adapt the Deep
Semi-supervised Anomaly Detection (DeepSAD) method for HI construction. We use
the DeepSAD embedding as a condition indicators to address interpretability
challenges and sensitivity to system-specific factors. Then, we introduce a
diversity loss to enrich condition indicators. We employ an alternating
projection algorithm with isotonic constraints to transform the DeepSAD
embedding into a normalized HI with an increasing trend. Validation on the PHME
2010 milling dataset, a recognized benchmark with ground truth HIs demonstrates
meaningful HIs estimations. Our methodology is then applied to monitor wear
states of thermal spray coatings using high-frequency voltage. Our
contributions create opportunities for more accessible and reliable HI
estimation, particularly in cases where obtaining ground truth HI labels is
unfeasible.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02869" title="Abstract">arXiv:2312.02869</a> [<a href="/pdf/2312.02869" title="Download PDF">pdf</a>, <a href="/ps/2312.02869" title="Download PostScript">ps</a>, <a href="/format/2312.02869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can a Tabula Recta provide security in the XXI century?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruiz%2C+F">Francisco Ruiz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY)

</div>
<p class="mathjax">In the not so unlikely scenario of total compromise of computers accessible
to a group of users, they might be tempted to resort to human-computable
paper-and-pencil cryptographic methods aided by a classic Tabula Recta, which
helps to perform addition and subtraction directly with letters. But do these
classic algorithms, or some new ones using the same simple tools, have any
chance against computer-aided cryptanalysis? In this paper I discuss how some
human-computable algorithms can indeed afford sufficient security in this
situation, drawing conclusions from computer-based statistical analysis. Three
kinds of algorithms are discussed: those that concentrate entropy from shared
text sources, stream ciphers based on arithmetic of non-binary spaces, and
hash-like algorithms that may be used to generate a password from a challenge
text.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02871" title="Abstract">arXiv:2312.02871</a> [<a href="/pdf/2312.02871" title="Download PDF">pdf</a>, <a href="/format/2312.02871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-enhanced neural differential equations for physics-informed  deep learning of ion transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rehman%2C+D">Danyal Rehman</a>, 
<a href="/search/cs?searchtype=author&query=Lienhard%2C+J+H">John H. Lienhard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures. Accepted in the NeurIPS Machine Learning and the Physical Sciences Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Mathematical Physics (math-ph); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Species transport models typically combine partial differential equations
(PDEs) with relations from hindered transport theory to quantify
electromigrative, convective, and diffusive transport through complex
nanoporous systems; however, these formulations are frequently substantial
simplifications of the governing dynamics, leading to the poor generalization
performance of PDE-based models. Given the growing interest in deep learning
methods for the physical sciences, we develop a machine learning-based approach
to characterize ion transport across nanoporous membranes. Our proposed
framework centers around attention-enhanced neural differential equations that
incorporate electroneutrality-based inductive biases to improve generalization
performance relative to conventional PDE-based methods. In addition, we study
the role of the attention mechanism in illuminating physically-meaningful
ion-pairing relationships across diverse mixture compositions. Further, we
investigate the importance of pre-training on simulated data from PDE-based
models, as well as the performance benefits from hard vs. soft inductive
biases. Our results indicate that physics-informed deep learning solutions can
outperform their classical PDE-based counterparts and provide promising avenues
for modelling complex transport phenomena across diverse applications.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02872" title="Abstract">arXiv:2312.02872</a> [<a href="/pdf/2312.02872" title="Download PDF">pdf</a>, <a href="/format/2312.02872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimental Insights Towards Explainable and Interpretable Pedestrian  Crossing Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Melo%2C+A+N">Angie Nataly Melo</a>, 
<a href="/search/cs?searchtype=author&query=Salinas%2C+C">Carlota Salinas</a>, 
<a href="/search/cs?searchtype=author&query=Sotelo%2C+M+A">Miguel Angel Sotelo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Systems and Control (eess.SY)

</div>
<p class="mathjax">In the context of autonomous driving, pedestrian crossing prediction is a key
component for improving road safety. Presently, the focus of these predictions
extends beyond achieving trustworthy results; it is shifting towards the
explainability and interpretability of these predictions. This research
introduces a novel neuro-symbolic approach that combines deep learning and
fuzzy logic for an explainable and interpretable pedestrian crossing
prediction. We have developed an explainable predictor (ExPedCross), which
utilizes a set of explainable features and employs a fuzzy inference system to
predict whether the pedestrian will cross or not. Our approach was evaluated on
both the PIE and JAAD datasets. The results offer experimental insights into
achieving explainability and interpretability in the pedestrian crossing
prediction task. Furthermore, the testing results yield a set of guidelines and
recommendations regarding the process of dataset selection, feature selection,
and explainability.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02873" title="Abstract">arXiv:2312.02873</a> [<a href="/pdf/2312.02873" title="Download PDF">pdf</a>, <a href="/ps/2312.02873" title="Download PostScript">ps</a>, <a href="/format/2312.02873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward autocorrection of chemical process flowsheets using large  language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balhorn%2C+L+S">Lukas Schulze Balhorn</a>, 
<a href="/search/cs?searchtype=author&query=Caballero%2C+M">Marc Caballero</a>, 
<a href="/search/cs?searchtype=author&query=Schweidtmann%2C+A+M">Artur M. Schweidtmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The process engineering domain widely uses Process Flow Diagrams (PFDs) and
Process and Instrumentation Diagrams (P&amp;IDs) to represent process flows and
equipment configurations. However, the P&amp;IDs and PFDs, hereafter called
flowsheets, can contain errors causing safety hazards, inefficient operation,
and unnecessary expenses. Correcting and verifying flowsheets is a tedious,
manual process. We propose a novel generative AI methodology for automatically
identifying errors in flowsheets and suggesting corrections to the user, i.e.,
autocorrecting flowsheets. Inspired by the breakthrough of Large Language
Models (LLMs) for grammatical autocorrection of human language, we investigate
LLMs for the autocorrection of flowsheets. The input to the model is a
potentially erroneous flowsheet and the output of the model are suggestions for
a corrected flowsheet. We train our autocorrection model on a synthetic dataset
in a supervised manner. The model achieves a top-1 accuracy of 80% and a top-5
accuracy of 84% on an independent test dataset of synthetically generated
flowsheets. The results suggest that the model can learn to autocorrect the
synthetic flowsheets. We envision that flowsheet autocorrection will become a
useful tool for chemical engineers.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02877" title="Abstract">arXiv:2312.02877</a> [<a href="/pdf/2312.02877" title="Download PDF">pdf</a>, <a href="/format/2312.02877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Dynamic Network for Efficient Point Cloud Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ai%2C+Y">Yang Ai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xi Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">For the point cloud registration task, a significant challenge arises from
non-overlapping points that consume extensive computational resources while
negatively affecting registration accuracy. In this paper, we introduce a
dynamic approach, widely utilized to improve network efficiency in computer
vision tasks, to the point cloud registration task. We employ an iterative
registration process on point cloud data multiple times to identify regions
where matching points cluster, ultimately enabling us to remove noisy points.
Specifically, we begin with deep global sampling to perform coarse global
registration. Subsequently, we employ the proposed refined node proposal module
to further narrow down the registration region and perform local registration.
Furthermore, we utilize a spatial consistency-based classifier to evaluate the
results of each registration stage. The model terminates once it reaches
sufficient confidence, avoiding unnecessary computations. Extended experiments
demonstrate that our model significantly reduces time consumption compared to
other methods with similar results, achieving a speed improvement of over 41%
on indoor dataset (3DMatch) and 33% on outdoor datasets (KITTI) while
maintaining competitive registration recall requirements.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02878" title="Abstract">arXiv:2312.02878</a> [<a href="/pdf/2312.02878" title="Download PDF">pdf</a>, <a href="/format/2312.02878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards More Practical Group Activity Detection: A New Benchmark and  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dongkeun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Youngkil Song</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+M">Minsu Cho</a>, 
<a href="/search/cs?searchtype=author&query=Kwak%2C+S">Suha Kwak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://cvlab.postech.ac.kr/research/CAFE">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Group activity detection (GAD) is the task of identifying members of each
group and classifying the activity of the group at the same time in a video.
While GAD has been studied recently, there is still much room for improvement
in both dataset and methodology due to their limited capability to address
practical GAD scenarios. To resolve these issues, we first present a new
dataset, dubbed Caf\'e. Unlike existing datasets, Caf\'e is constructed
primarily for GAD and presents more practical evaluation scenarios and metrics,
as well as being large-scale and providing rich annotations. Along with the
dataset, we propose a new GAD model that deals with an unknown number of groups
and latent group members efficiently and effectively. We evaluated our model on
three datasets including Caf\'e, where it outperformed previous work in terms
of both accuracy and inference speed. Both our dataset and code base will be
open to the public to promote future research on GAD.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02880" title="Abstract">arXiv:2312.02880</a> [<a href="/pdf/2312.02880" title="Download PDF">pdf</a>, <a href="/format/2312.02880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PULSAR: Simultaneous Many-Row Activation for Reliable and  High-Performance Computing in Off-the-Shelf DRAM Chips
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuksel%2C+I+E">Ismail Emir Yuksel</a>, 
<a href="/search/cs?searchtype=author&query=Tugrul%2C+Y+C">Yahya Can Tugrul</a>, 
<a href="/search/cs?searchtype=author&query=Bostanci%2C+F+N">F. Nisa Bostanci</a>, 
<a href="/search/cs?searchtype=author&query=Yaglikci%2C+A+G">Abdullah Giray Yaglikci</a>, 
<a href="/search/cs?searchtype=author&query=Olgun%2C+A">Ataberk Olgun</a>, 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+G+F">Geraldo F. Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Soysal%2C+M">Melina Soysal</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haocong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Luna%2C+J+G">Juan Gomez Luna</a>, 
<a href="/search/cs?searchtype=author&query=Sadrosadati%2C+M">Mohammad Sadrosadati</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Data movement between the processor and the main memory is a first-order
obstacle against improving performance and energy efficiency in modern systems.
To address this obstacle, Processing-using-Memory (PuM) is a promising approach
where bulk-bitwise operations are performed leveraging intrinsic analog
properties within the DRAM array and massive parallelism across DRAM columns.
Unfortunately, 1) modern off-the-shelf DRAM chips do not officially support PuM
operations, and 2) existing techniques of performing PuM operations on
off-the-shelf DRAM chips suffer from two key limitations. First, these
techniques have low success rates, i.e., only a small fraction of DRAM columns
can correctly execute PuM operations because they operate beyond
manufacturer-recommended timing constraints, causing these operations to be
highly susceptible to noise and process variation. Second, these techniques
have limited compute primitives, preventing them from fully leveraging
parallelism across DRAM columns and thus hindering their performance benefits.
<br />We propose PULSAR, a new technique to enable high-success-rate and
high-performance PuM operations in off-the-shelf DRAM chips. PULSAR leverages
our new observation that a carefully crafted sequence of DRAM commands
simultaneously activates up to 32 DRAM rows. PULSAR overcomes the limitations
of existing techniques by 1) replicating the input data to improve the success
rate and 2) enabling new bulk bitwise operations (e.g., many-input majority,
Multi-RowInit, and Bulk-Write) to improve the performance.
<br />Our analysis on 120 off-the-shelf DDR4 chips from two major manufacturers
shows that PULSAR achieves a 24.18% higher success rate and 121% higher
performance over seven arithmetic-logic operations compared to FracDRAM, a
state-of-the-art off-the-shelf DRAM-based PuM technique.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02881" title="Abstract">arXiv:2312.02881</a> [<a href="/pdf/2312.02881" title="Download PDF">pdf</a>, <a href="/format/2312.02881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Divergence-Free Flux Globalization Based Well-Balanced Path-Conservative  Central-Upwind Schemes for Rotating Shallow Water Magnetohydrodynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chertock%2C+A">Alina Chertock</a>, 
<a href="/search/math?searchtype=author&query=Kurganov%2C+A">Alexander Kurganov</a>, 
<a href="/search/math?searchtype=author&query=Redle%2C+M">Michael Redle</a>, 
<a href="/search/math?searchtype=author&query=Zeitlin%2C+V">Vladimir Zeitlin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We develop a new second-order flux globalization based path-conservative
central-upwind (PCCU) scheme for rotating shallow water magnetohydrodynamic
equations. The new scheme is designed not only to maintain the divergence-free
constraint of the magnetic field at the discrete level but also to satisfy the
well-balanced (WB) property by exactly preserving some physically relevant
steady states of the underlying system. The locally divergence-free constraint
of the magnetic field is enforced by following the method recently introduced
in [A. Chertock, A. Kurganov, M. Redle, and K. Wu, ArXiv preprint (2022),
<a href="/abs/2212.02682">arXiv:2212.02682</a>]: we consider a Godunov-Powell modified version of the studied
system, introduce additional equations by spatially differentiating the
magnetic field equations, and modify the reconstruction procedures for magnetic
field variables. The WB property is ensured by implementing a flux
globalization approach within the PCCU scheme, leading to a method capable of
preserving both still- and moving-water equilibria exactly. In addition to
provably achieving both the WB and divergence-free properties, the new method
is implemented on an unstaggered grid and does not require any (approximate)
Riemann problem solvers. The performance of the proposed method is demonstrated
in several numerical experiments that confirm the lack of spurious
oscillations, robustness, and high resolution of the obtained results.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02882" title="Abstract">arXiv:2312.02882</a> [<a href="/pdf/2312.02882" title="Download PDF">pdf</a>, <a href="/format/2312.02882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero Trust for Cyber Resilience
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yunfei Ge</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Quanyan Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">The increased connectivity and potential insider threats make traditional
network defense vulnerable. Instead of assuming that everything behind the
security perimeter is safe, the zero-trust security model verifies every
incoming request before granting access. This chapter draws attention to the
cyber resilience within the zero-trust model. We introduce the evolution from
traditional perimeter-based security to zero trust and discuss their
difference. Two key elements of the zero-trust engine are trust evaluation (TE)
and policy engine (PE). We introduce the design of the two components and
discuss how their interplay would contribute to cyber resilience. Dynamic game
theory and learning are applied as quantitative approaches to achieve automated
zero-trust cyber resilience. Several case studies and implementations are
introduced to illustrate the benefits of such a security model.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02891" title="Abstract">arXiv:2312.02891</a> [<a href="/pdf/2312.02891" title="Download PDF">pdf</a>, <a href="/ps/2312.02891" title="Download PostScript">ps</a>, <a href="/format/2312.02891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inexact linear solves in the low-rank ADI iteration for large Sylvester  equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=K%C3%BCrschner%2C+P">Patrick K&#xfc;rschner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider the low-rank alternating directions implicit (ADI) iteration for
approximately solving large-scale algebraic Sylvester equations. Inside every
iteration step of this iterative process a pair of linear systems of equations
has to be solved. We investigate the situation when those inner linear systems
are solved inexactly by an iterative methods such as, for example,
preconditioned Krylov subspace methods. The main contribution of this work are
thresholds for the required accuracies regarding the inner linear systems which
dictate when the employed inner Krylov subspace methods can be safely
terminated. The goal is to save computational effort by solving the inner
linear system as inaccurate as possible without endangering the functionality
of the low-rank Sylvester-ADI method. Ideally, the inexact ADI method mimics
the convergence behaviour of the more expensive exact ADI method, where the
linear systems are solved directly. Alongside the theoretical results, also
strategies for an actual practical implementation of the stopping criteria are
developed. Numerical experiments confirm the effectiveness of the proposed
strategies.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02892" title="Abstract">arXiv:2312.02892</a> [<a href="/pdf/2312.02892" title="Download PDF">pdf</a>, <a href="/format/2312.02892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Stabilization with Model Uncertainties: A Universal Formula with  Gaussian Process Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+M">Ming Li</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+Z">Zhiyong Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">A combination of control Lyapunov functions (CLFs) and control barrier
functions (CBFs) forms an efficient framework for addressing control challenges
in safe stabilization. In our previous research, we developed an analytical
control strategy, namely the universal formula, that incorporates CLF and CBF
conditions for safe stabilization. However, successful implementation of this
universal formula relies on an accurate model, as any mismatch between the
model and the actual system can compromise stability and safety. In this paper,
we propose a new universal formula that leverages Gaussian processes (GPs)
learning to address safe stabilization in the presence of model uncertainty. By
utilizing the results related to bounded learning errors, we achieve a high
probability of stability and safety guarantees with the proposed universal
formula. Additionally, we introduce a probabilistic compatibility condition to
evaluate conflicts between the modified CLF and CBF conditions with GP learning
results. In cases where compatibility assumptions fail and control system
limits are present, we propose a modified universal formula that relaxes
stability constraints and a projection-based method accommodating control
limits. We illustrate the effectiveness of our approach through a simulation of
adaptive cruise control (ACC), highlighting its potential for practical
applications in real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02896" title="Abstract">arXiv:2312.02896</a> [<a href="/pdf/2312.02896" title="Download PDF">pdf</a>, <a href="/format/2312.02896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BenchLMM: Benchmarking Cross-style Visual Capability of Large Multimodal  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+R">Rizhao Cai</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zirui Song</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+D">Dayan Guan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xing Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+C">Chenyu Yi</a>, 
<a href="/search/cs?searchtype=author&query=Kot%2C+A">Alex Kot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at <a href="https://github.com/AIFEG/BenchGPT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large Multimodal Models (LMMs) such as GPT-4V and LLaVA have shown remarkable
capabilities in visual reasoning with common image styles. However, their
robustness against diverse style shifts, crucial for practical applications,
remains largely unexplored. In this paper, we propose a new benchmark,
BenchLMM, to assess the robustness of LMMs against three different styles:
artistic image style, imaging sensor style, and application style, where each
style has five sub-styles. Utilizing BenchLMM, we comprehensively evaluate
state-of-the-art LMMs and reveal: 1) LMMs generally suffer performance
degradation when working with other styles; 2) An LMM performs better than
another model in common style does not guarantee its superior performance in
other styles; 3) LMMs' reasoning capability can be enhanced by prompting LMMs
to predict the style first, based on which we propose a versatile and
training-free method for improving LMMs; 4) An intelligent LMM is expected to
interpret the causes of its errors when facing stylistic variations. We hope
that our benchmark and analysis can shed new light on developing more
intelligent and versatile LMMs.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02897" title="Abstract">arXiv:2312.02897</a> [<a href="/pdf/2312.02897" title="Download PDF">pdf</a>, <a href="/format/2312.02897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perspectives from Naive Participants and Experienced Social Science  Researchers on Addressing Embodiment in a Virtual Cyberball Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+T">Tao Long</a>, 
<a href="/search/cs?searchtype=author&query=Pandita%2C+S">Swati Pandita</a>, 
<a href="/search/cs?searchtype=author&query=Won%2C+A+S">Andrea Stevenson Won</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 8 figures, In Companion Proceedings of the 26th ACM Conference On Computer-Supported Cooperative Work And Social Computing (CSCW'23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">We describe the design of an immersive virtual Cyberball task that included
avatar customization, and user feedback on this design. We first created a
prototype of an avatar customization template and added it to a Cyberball
prototype built in the Unity3D game engine. Then, we conducted in-depth user
testing and feedback sessions with 15 Cyberball stakeholders: five naive
participants with no prior knowledge of Cyberball and ten experienced
researchers with extensive experience using the Cyberball paradigm. We report
the divergent perspectives of the two groups on the following design insights;
designing for intuitive use, inclusivity, and realistic experiences versus
minimalism. Participant responses shed light on how system design problems may
contribute to or perpetuate negative experiences when customizing avatars. They
also demonstrate the value of considering multiple stakeholders' feedback in
the design process for virtual reality, presenting a more comprehensive view in
designing future Cyberball prototypes and interactive systems for social
science research.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02901" title="Abstract">arXiv:2312.02901</a> [<a href="/pdf/2312.02901" title="Download PDF">pdf</a>, <a href="/format/2312.02901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concept Drift Adaptation in Text Stream Mining Settings: A Comprehensive  Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garcia%2C+C+M">Cristiano Mesquita Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Abilio%2C+R+S">Ramon Simoes Abilio</a>, 
<a href="/search/cs?searchtype=author&query=Koerich%2C+A+L">Alessandro Lameiras Koerich</a>, 
<a href="/search/cs?searchtype=author&query=de+Souza+Britto%2C+A">Alceu de Souza Britto Jr.</a>, 
<a href="/search/cs?searchtype=author&query=Barddal%2C+J+P">Jean Paul Barddal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 49 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Due to the advent and increase in the popularity of the Internet, people have
been producing and disseminating textual data in several ways, such as reviews,
social media posts, and news articles. As a result, numerous researchers have
been working on discovering patterns in textual data, especially because social
media posts function as social sensors, indicating peoples' opinions,
interests, etc. However, most tasks regarding natural language processing are
addressed using traditional machine learning methods and static datasets. This
setting can lead to several problems, such as an outdated dataset, which may
not correspond to reality, and an outdated model, which has its performance
degrading over time. Concept drift is another aspect that emphasizes these
issues, which corresponds to data distribution and pattern changes. In a text
stream scenario, it is even more challenging due to its characteristics, such
as the high speed and data arriving sequentially. In addition, models for this
type of scenario must adhere to the constraints mentioned above while learning
from the stream by storing texts for a limited time and consuming low memory.
In this study, we performed a systematic literature review regarding concept
drift adaptation in text stream scenarios. Considering well-defined criteria,
we selected 40 papers to unravel aspects such as text drift categories, types
of text drift detection, model update mechanism, the addressed stream mining
tasks, types of text representations, and text representation update mechanism.
In addition, we discussed drift visualization and simulation and listed
real-world datasets used in the selected papers. Therefore, this paper
comprehensively reviews the concept drift adaptation in text stream mining
scenarios.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02902" title="Abstract">arXiv:2312.02902</a> [<a href="/pdf/2312.02902" title="Download PDF">pdf</a>, <a href="/format/2312.02902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HeadGaS: Real-Time Animatable Head Avatars via 3D Gaussian Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhamo%2C+H">Helisa Dhamo</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Y">Yinyu Nie</a>, 
<a href="/search/cs?searchtype=author&query=Moreau%2C+A">Arthur Moreau</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jifei Song</a>, 
<a href="/search/cs?searchtype=author&query=Shaw%2C+R">Richard Shaw</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yiren Zhou</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez-Pellitero%2C+E">Eduardo P&#xe9;rez-Pellitero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D head animation has seen major quality and runtime improvements over the
last few years, particularly empowered by the advances in differentiable
rendering and neural radiance fields. Real-time rendering is a highly desirable
goal for real-world applications. We propose HeadGaS, the first model to use 3D
Gaussian Splats (3DGS) for 3D head reconstruction and animation. In this paper
we introduce a hybrid model that extends the explicit representation from 3DGS
with a base of learnable latent features, which can be linearly blended with
low-dimensional parameters from parametric head models to obtain
expression-dependent final color and opacity values. We demonstrate that
HeadGaS delivers state-of-the-art results in real-time inference frame rates,
which surpasses baselines by up to ~2dB, while accelerating rendering speed by
over x10.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02906" title="Abstract">arXiv:2312.02906</a> [<a href="/pdf/2312.02906" title="Download PDF">pdf</a>, <a href="/format/2312.02906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncovering Patterns of Participant-Invariant Influence in Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaojie%2C+M">Min Shaojie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">In this paper, we explore the nature of influence in a network. The concept
of participant-invariant influence is derived from an influence matrix M
specifically designed to explore this phenomenon. Through nonnegative matrix
factorization approximation, we managed to extract a participant-invariant
matrix H representing a shared pattern that all participants must obey. The
acquired H is highly field-related and can be further utilized to cluster
factual networks. Our discovery of the unveiled participant-independent
influence within network dynamics opens up new avenues for further research on
network behavior and its implications.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02912" title="Abstract">arXiv:2312.02912</a> [<a href="/pdf/2312.02912" title="Download PDF">pdf</a>, <a href="/format/2312.02912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Realistic Scatterer Based Adversarial Attacks on SAR Image Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+T">Tian Ye</a>, 
<a href="/search/cs?searchtype=author&query=Kannan%2C+R">Rajgopal Kannan</a>, 
<a href="/search/cs?searchtype=author&query=Prasanna%2C+V">Viktor Prasanna</a>, 
<a href="/search/cs?searchtype=author&query=Busart%2C+C">Carl Busart</a>, 
<a href="/search/cs?searchtype=author&query=Kaplan%2C+L">Lance Kaplan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Adversarial attacks have highlighted the vulnerability of classifiers based
on machine learning for Synthetic Aperture Radar (SAR) Automatic Target
Recognition (ATR) tasks. An adversarial attack perturbs SAR images of on-ground
targets such that the classifiers are misled into making incorrect predictions.
However, many existing attacking techniques rely on arbitrary manipulation of
SAR images while overlooking the feasibility of executing the attacks on
real-world SAR imagery. Instead, adversarial attacks should be able to be
implemented by physical actions, for example, placing additional false objects
as scatterers around the on-ground target to perturb the SAR image and fool the
SAR ATR.
<br />In this paper, we propose the On-Target Scatterer Attack (OTSA), a
scatterer-based physical adversarial attack. To ensure the feasibility of its
physical execution, we enforce a constraint on the positioning of the
scatterers. Specifically, we restrict the scatterers to be placed only on the
target instead of in the shadow regions or the background. To achieve this, we
introduce a positioning score based on Gaussian kernels and formulate an
optimization problem for our OTSA attack. Using a gradient ascent method to
solve the optimization problem, the OTSA can generate a vector of parameters
describing the positions, shapes, sizes and amplitudes of the scatterers to
guide the physical execution of the attack that will mislead SAR image
classifiers. The experimental results show that our attack obtains
significantly higher success rates under the positioning constraint compared
with the existing method.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02913" title="Abstract">arXiv:2312.02913</a> [<a href="/pdf/2312.02913" title="Download PDF">pdf</a>, <a href="/format/2312.02913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Let the LLMs Talk: Simulating Human-to-Human Conversational QA via  Zero-Shot LLM-to-LLM Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abbasiantaeb%2C+Z">Zahra Abbasiantaeb</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yifei Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Kanoulas%2C+E">Evangelos Kanoulas</a>, 
<a href="/search/cs?searchtype=author&query=Aliannejadi%2C+M">Mohammad Aliannejadi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WSDM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Conversational question-answering (CQA) systems aim to create interactive
search systems that effectively retrieve information by interacting with users.
To replicate human-to-human conversations, existing work uses human annotators
to play the roles of the questioner (student) and the answerer (teacher).
Despite its effectiveness, challenges exist as human annotation is
time-consuming, inconsistent, and not scalable. To address this issue and
investigate the applicability of large language models (LLMs) in CQA
simulation, we propose a simulation framework that employs zero-shot learner
LLMs for simulating teacher-student interactions. Our framework involves two
LLMs interacting on a specific topic, with the first LLM acting as a student,
generating questions to explore a given search topic. The second LLM plays the
role of a teacher by answering questions and is equipped with additional
information, including a text on the given topic. We implement both the student
and teacher by zero-shot prompting the GPT-4 model. To assess the effectiveness
of LLMs in simulating CQA interactions and understand the disparities between
LLM- and human-generated conversations, we evaluate the simulated data from
various perspectives. We begin by evaluating the teacher's performance through
both automatic and human assessment. Next, we evaluate the performance of the
student, analyzing and comparing the disparities between questions generated by
the LLM and those generated by humans. Furthermore, we conduct extensive
analyses to thoroughly examine the LLM performance by benchmarking
state-of-the-art reading comprehension models on both datasets. Our results
reveal that the teacher LLM generates lengthier answers that tend to be more
accurate and complete. The student LLM generates more diverse questions,
covering more aspects of a given topic.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02914" title="Abstract">arXiv:2312.02914</a> [<a href="/pdf/2312.02914" title="Download PDF">pdf</a>, <a href="/format/2312.02914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Video Domain Adaptation with Masked Pre-Training and  Collaborative Self-Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reddy%2C+A">Arun Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+W">William Paul</a>, 
<a href="/search/cs?searchtype=author&query=Rivera%2C+C">Corban Rivera</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+K">Ketul Shah</a>, 
<a href="/search/cs?searchtype=author&query=de+Melo%2C+C+M">Celso M. de Melo</a>, 
<a href="/search/cs?searchtype=author&query=Chellappa%2C+R">Rama Chellappa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this work, we tackle the problem of unsupervised domain adaptation (UDA)
for video action recognition. Our approach, which we call UNITE, uses an image
teacher model to adapt a video student model to the target domain. UNITE first
employs self-supervised pre-training to promote discriminative feature learning
on target domain videos using a teacher-guided masked distillation objective.
We then perform self-training on masked target data, using the video student
model and image teacher model together to generate improved pseudolabels for
unlabeled target videos. Our self-training process successfully leverages the
strengths of both models to achieve strong transfer performance across domains.
We evaluate our approach on multiple video domain adaptation benchmarks and
observe significant improvements upon previously reported results.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02915" title="Abstract">arXiv:2312.02915</a> [<a href="/pdf/2312.02915" title="Download PDF">pdf</a>, <a href="/ps/2312.02915" title="Download PostScript">ps</a>, <a href="/format/2312.02915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Sparsity Approach to Scheduling and Control of Networked Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dasgupta%2C+A">Anubhab Dasgupta</a>, 
<a href="/search/eess?searchtype=author&query=Kundu%2C+A">Atreyee Kundu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">We study the design of scheduling logic and control logic for networked
control systems (NCSs) where plants communicate with their remotely located
controllers over a shared band-limited communication network. Due to a limited
capacity of the network, only a subset of the plants can exchange information
with their controllers at any instant of time and the remaining plants operate
in open-loop. Our key contribution is a new algorithm that co-designs (a) an
allocation scheme of the communication network among the plants (scheduling
logic) and (b) the control inputs for the plants accessing the network (control
logic) under which given non-zero initial states are steered to zero in a given
time horizon for all the plants in the NCS. Sparse optimization is the primary
apparatus for our analysis. We also provide sufficient conditions on the plant
dynamics, capacity of the communication network and the given time horizon that
lead to a numerically tractable implementation of our algorithm. A numerical
experiment is presented to demonstrate the proposed results.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02916" title="Abstract">arXiv:2312.02916</a> [<a href="/pdf/2312.02916" title="Download PDF">pdf</a>, <a href="/format/2312.02916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MIND: Multi-Task Incremental Network Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bonato%2C+J">Jacopo Bonato</a>, 
<a href="/search/cs?searchtype=author&query=Pelosin%2C+F">Francesco Pelosin</a>, 
<a href="/search/cs?searchtype=author&query=Sabetta%2C+L">Luigi Sabetta</a>, 
<a href="/search/cs?searchtype=author&query=Nicolosi%2C+A">Alessandro Nicolosi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The recent surge in pervasive devices generating dynamic data streams has
underscored the necessity for learning systems to adapt to data distributional
shifts continually. To tackle this challenge, the research community has put
forth a spectrum of methodologies, including the demanding pursuit of
class-incremental learning without replay data. In this study, we present MIND,
a parameter isolation method that aims to significantly enhance the performance
of replay-free solutions and achieve state-of-the-art results on several widely
studied datasets. Our approach introduces two main contributions: two
alternative distillation procedures that significantly improve the efficiency
of MIND increasing the accumulated knowledge of each sub-network, and the
optimization of the BachNorm layers across tasks inside the sub-networks.
Overall, MIND outperforms all the state-of-the-art methods for rehearsal-free
Class-Incremental learning (with an increment in classification accuracy of
approx. +6% on CIFAR-100/10 and +10% on TinyImageNet/10) reaching up to approx.
+40% accuracy in Domain-Incremental scenarios. Moreover, we ablated each
contribution to demonstrate its impact on performance improvement. Our results
showcase the superior performance of MIND indicating its potential for
addressing the challenges posed by Class-incremental and Domain-Incremental
learning in resource-constrained environments.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02918" title="Abstract">arXiv:2312.02918</a> [<a href="/pdf/2312.02918" title="Download PDF">pdf</a>, <a href="/format/2312.02918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Prompt Perceiver: Empower Adaptiveness, Generalizability and  Fidelity for All-in-One Image Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ai%2C+Y">Yuang Ai</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huaibo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaoqiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiexiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ran He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite substantial progress, all-in-one image restoration (IR) grapples with
persistent challenges in handling intricate real-world degradations. This paper
introduces MPerceiver: a novel multimodal prompt learning approach that
harnesses Stable Diffusion (SD) priors to enhance adaptiveness,
generalizability and fidelity for all-in-one image restoration. Specifically,
we develop a dual-branch module to master two types of SD prompts: textual for
holistic representation and visual for multiscale detail representation. Both
prompts are dynamically adjusted by degradation predictions from the CLIP image
encoder, enabling adaptive responses to diverse unknown degradations. Moreover,
a plug-in detail refinement module improves restoration fidelity via direct
encoder-to-decoder information transformation. To assess our method, MPerceiver
is trained on 9 tasks for all-in-one IR and outperforms state-of-the-art
task-specific methods across most tasks. Post multitask pre-training,
MPerceiver attains a generalized representation in low-level vision, exhibiting
remarkable zero-shot and few-shot capabilities in unseen tasks. Extensive
experiments on 16 IR tasks and 26 benchmarks underscore the superiority of
MPerceiver in terms of adaptiveness, generalizability and fidelity.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02919" title="Abstract">arXiv:2312.02919</a> [<a href="/pdf/2312.02919" title="Download PDF">pdf</a>, <a href="/format/2312.02919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-grained Controllable Video Generation via Object Appearance and  Context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hsin-Ping Huang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yu-Chuan Su</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Deqing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Lu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xuhui Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yukun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://hhsinping.github.io/factor">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-to-video generation has shown promising results. However, by taking only
natural languages as input, users often face difficulties in providing detailed
information to precisely control the model's output. In this work, we propose
fine-grained controllable video generation (FACTOR) to achieve detailed
control. Specifically, FACTOR aims to control objects' appearances and context,
including their location and category, in conjunction with the text prompt. To
achieve detailed control, we propose a unified framework to jointly inject
control signals into the existing text-to-video model. Our model consists of a
joint encoder and adaptive cross-attention layers. By optimizing the encoder
and the inserted layer, we adapt the model to generate videos that are aligned
with both text prompts and fine-grained control. Compared to existing methods
relying on dense control signals such as edge maps, we provide a more intuitive
and user-friendly interface to allow object-level fine-grained control. Our
method achieves controllability of object appearances without finetuning, which
reduces the per-subject optimization efforts for the users. Extensive
experiments on standard benchmark datasets and user-provided inputs validate
that our model obtains a 70% improvement in controllability metrics over
competitive baselines.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02921" title="Abstract">arXiv:2312.02921</a> [<a href="/pdf/2312.02921" title="Download PDF">pdf</a>, <a href="/ps/2312.02921" title="Download PostScript">ps</a>, <a href="/format/2312.02921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cyber Insurance for Cyber Resilience
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shutian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Quanyan Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Cyber insurance is a complementary mechanism to further reduce the financial
impact on the systems after their effort in defending against cyber attacks and
implementing resilience mechanism to maintain the system-level operator even
though the attacker is already in the system. This chapter presents a review of
the quantitative cyber insurance design framework that takes into account the
incentives as well as the perceptual aspects of multiple parties. The design
framework builds on the correlation between state-of-the-art attacker vectors
and defense mechanisms. In particular, we propose the notion of residual risks
to characterize the goal of cyber insurance design. By elaborating the
insurer's observations necessary for the modeling of the cyber insurance
contract, we make comparison between the design strategies of the insurer under
scenarios with different monitoring rules. These distinct but practical
scenarios give rise to the concept of the intensity of the moral hazard issue.
Using the modern techniques in quantifying the risk preferences of individuals,
we link the economic impacts of perception manipulation with moral hazard. With
the joint design of cyber insurance design and risk perceptions, cyber
resilience can be enhanced under mild assumptions on the monitoring of
insurees' actions. Finally, we discuss possible extensions on the cyber
insurance design framework to more sophisticated settings and the regulations
to strengthen the cyber insurance markets.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02923" title="Abstract">arXiv:2312.02923</a> [<a href="/pdf/2312.02923" title="Download PDF">pdf</a>, <a href="/format/2312.02923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Split &amp; Merge: Unlocking the Potential of Visual Adapters via Sparse  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qizhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+B">Bocheng Zou</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+R">Ruichuan An</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanghang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 7 figures. Official code: <a href="https://github.com/Theia-4869/MoSA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the rapid growth in the scale of pre-trained foundation models,
parameter-efficient fine-tuning techniques have gained significant attention,
among which Adapter Tuning is the most widely used. Despite achieving
efficiency, Adapter Tuning still underperforms full fine-tuning, and the
performance improves at the cost of an increase in parameters. Recent efforts
address this issue by pruning the original adapters, but it also introduces
training instability and suboptimal performance on certain datasets. Motivated
by this, we propose Mixture of Sparse Adapters, or MoSA, as a novel Adapter
Tuning method to fully unleash the potential of each parameter in the adapter.
We first split the standard adapter into multiple non-overlapping modules, then
stochastically activate modules for sparse training, and finally merge them to
form a complete adapter after tuning. In this way, MoSA can achieve
significantly better performance than standard adapters without any additional
computational or storage overhead. Furthermore, we propose a hierarchical
sparse strategy to better leverage limited training data. Extensive experiments
on a series of 27 visual tasks demonstrate that MoSA consistently outperforms
other Adapter Tuning methods as well as other baselines by a significant
margin. Furthermore, in two challenging scenarios with low-resource and
multi-task settings, MoSA achieves satisfactory results, further demonstrating
the effectiveness of our design. Our code will be released.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02928" title="Abstract">arXiv:2312.02928</a> [<a href="/pdf/2312.02928" title="Download PDF">pdf</a>, <a href="/format/2312.02928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LivePhoto: Real Image Animation with Text-guided Motion Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mengting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yutong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yujun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hengshuang Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://xavierchen34.github.io/LivePhoto-Page/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite the recent progress in text-to-video generation, existing studies
usually overlook the issue that only spatial contents but not temporal motions
in synthesized videos are under the control of text. Towards such a challenge,
this work presents a practical system, named LivePhoto, which allows users to
animate an image of their interest with text descriptions. We first establish a
strong baseline that helps a well-learned text-to-image generator (i.e., Stable
Diffusion) take an image as a further input. We then equip the improved
generator with a motion module for temporal modeling and propose a carefully
designed training pipeline to better link texts and motions. In particular,
considering the facts that (1) text can only describe motions roughly (e.g.,
regardless of the moving speed) and (2) text may include both content and
motion descriptions, we introduce a motion intensity estimation module as well
as a text re-weighting module to reduce the ambiguity of text-to-motion
mapping. Empirical evidence suggests that our approach is capable of well
decoding motion-related textual instructions into videos, such as actions,
camera movements, or even conjuring new contents from thin air (e.g., pouring
water into an empty glass). Interestingly, thanks to the proposed intensity
learning mechanism, our system offers users an additional control signal (i.e.,
the motion intensity) besides text for video customization.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02930" title="Abstract">arXiv:2312.02930</a> [<a href="/pdf/2312.02930" title="Download PDF">pdf</a>, <a href="/ps/2312.02930" title="Download PostScript">ps</a>, <a href="/format/2312.02930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing Nonlinear Diffusion Acceleration for Boltzmann Fokker Planck  Equation in Slab Geometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Patel%2C+J+K">Japan K. Patel</a>, 
<a href="/search/math?searchtype=author&query=Ganapol%2C+B+D">Barry D. Ganapol</a>, 
<a href="/search/math?searchtype=author&query=Matuszak%2C+M+M">Martha M. Matuszak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This draft has been submitted to Physor 2024 for review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The convergence of Boltzmann Fokker Planck solution can become arbitrarily
slow with iterative procedures like source iteration. This paper derives and
investigates a nonlinear diffusion acceleration scheme for the solution of the
Boltzmann Fokker Planck equation in slab geometry. This method is a
conventional high order low order scheme with a traditional
diffusion-plus-drift low-order system. The method, however, differs from the
earlier variants as the definition of the low order equation, which is adjusted
according to the zeroth and first moments of the Boltzmann Fokker Planck
equation. For the problems considered, we observe that the NDA-accelerated
solution follows the unaccelerated well and provides roughly an order of
magnitude savings in iteration count and runtime compared to source iteration.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02931" title="Abstract">arXiv:2312.02931</a> [<a href="/pdf/2312.02931" title="Download PDF">pdf</a>, <a href="/format/2312.02931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WhisBERT: Multimodal Text-Audio Language Modeling on 100M Words
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wolf%2C+L">Lukas Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Kotar%2C+K">Klemen Kotar</a>, 
<a href="/search/cs?searchtype=author&query=Tuckute%2C+G">Greta Tuckute</a>, 
<a href="/search/cs?searchtype=author&query=Hosseini%2C+E">Eghbal Hosseini</a>, 
<a href="/search/cs?searchtype=author&query=Regev%2C+T">Tamar Regev</a>, 
<a href="/search/cs?searchtype=author&query=Wilcox%2C+E">Ethan Wilcox</a>, 
<a href="/search/cs?searchtype=author&query=Warstadt%2C+A">Alex Warstadt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at the BabyLM Challenge, a shared task co-sponsored by CMCL 2023 and CoNLL 2023, hosted by EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Training on multiple modalities of input can augment the capabilities of a
language model. Here, we ask whether such a training regime can improve the
quality and efficiency of these systems as well. We focus on text--audio and
introduce Whisbert, which is inspired by the text--image approach of FLAVA
\citep{singh_flava_2022}. In accordance with Babylm \citep{warstadt2023papers}
guidelines, we pretrain Whisbert on a dataset comprising only 100 million words
plus their corresponding speech from the word-aligned version of the People's
Speech dataset \citep{galvez_peoples_2021}. To assess the impact of
multimodality, we compare versions of the model that are trained on text only
and on both audio and text simultaneously. We find that while Whisbert is able
to perform well on multimodal masked modeling and surpasses the Babylm
baselines in most benchmark tasks, it struggles to optimize its complex
objective and outperform its text-only Whisbert baseline.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02934" title="Abstract">arXiv:2312.02934</a> [<a href="/pdf/2312.02934" title="Download PDF">pdf</a>, <a href="/format/2312.02934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WoVoGen: World Volume-aware Diffusion for Controllable Multi-camera  Driving Scene Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiachen Lu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Ze Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiahui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zeyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generating multi-camera street-view videos is critical for augmenting
autonomous driving datasets, addressing the urgent demand for extensive and
varied data. Due to the limitations in diversity and challenges in handling
lighting conditions, traditional rendering-based methods are increasingly being
supplanted by diffusion-based methods. However, a significant challenge in
diffusion-based methods is ensuring that the generated sensor data preserve
both intra-world consistency and inter-sensor coherence. To address these
challenges, we combine an additional explicit world volume and propose the
World Volume-aware Multi-camera Driving Scene Generator (WoVoGen). This system
is specifically designed to leverage 4D world volume as a foundational element
for video generation. Our model operates in two distinct phases: (i)
envisioning the future 4D temporal world volume based on vehicle control
sequences, and (ii) generating multi-camera videos, informed by this envisioned
4D temporal world volume and sensor interconnectivity. The incorporation of the
4D world volume empowers WoVoGen not only to generate high-quality street-view
videos in response to vehicle control inputs but also to facilitate scene
editing tasks.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02936" title="Abstract">arXiv:2312.02936</a> [<a href="/pdf/2312.02936" title="Download PDF">pdf</a>, <a href="/format/2312.02936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Drag-A-Video: Non-rigid Video Editing with Point-based Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teng%2C+Y">Yao Teng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+E">Enze Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+H">Haoyu Han</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xihui Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video editing is a challenging task that requires manipulating videos on both
the spatial and temporal dimensions. Existing methods for video editing mainly
focus on changing the appearance or style of the objects in the video, while
keeping their structures unchanged. However, there is no existing method that
allows users to interactively ``drag'' any points of instances on the first
frame to precisely reach the target points with other frames consistently
deformed. In this paper, we propose a new diffusion-based method for
interactive point-based video manipulation, called Drag-A-Video. Our method
allows users to click pairs of handle points and target points as well as masks
on the first frame of an input video. Then, our method transforms the inputs
into point sets and propagates these sets across frames. To precisely modify
the contents of the video, we employ a new video-level motion supervision to
update the features of the video and introduce the latent offsets to achieve
this update at multiple denoising timesteps. We propose a temporal-consistent
point tracking module to coordinate the movement of the points in the handle
point sets. We demonstrate the effectiveness and flexibility of our method on
various videos. The website of our work is available here:
https://drag-a-video.github.io/.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02937" title="Abstract">arXiv:2312.02937</a> [<a href="/pdf/2312.02937" title="Download PDF">pdf</a>, <a href="/format/2312.02937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synergistic Perception and Control Simplex for Verifiable Safe Vertical  Landing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bansal%2C+A">Ayoosh Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">James Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Sheng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuliang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+H">Hyung-Jin Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hunmin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hovakimyan%2C+N">Naira Hovakimyan</a>, 
<a href="/search/cs?searchtype=author&query=Sha%2C+L">Lui Sha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in AIAA SciTech 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Perception, Planning, and Control form the essential components of autonomy
in advanced air mobility. This work advances the holistic integration of these
components to enhance the performance and robustness of the complete
cyber-physical system. We adapt Perception Simplex, a system for verifiable
collision avoidance amidst obstacle detection faults, to the vertical landing
maneuver for autonomous air mobility vehicles. We improve upon this system by
replacing static assumptions of control capabilities with dynamic confirmation,
i.e., real-time confirmation of control limitations of the system, ensuring
reliable fulfillment of safety maneuvers and overrides, without dependence on
overly pessimistic assumptions. Parameters defining control system capabilities
and limitations, e.g., maximum deceleration, are continuously tracked within
the system and used to make safety-critical decisions. We apply these
techniques to propose a verifiable collision avoidance solution for autonomous
aerial mobility vehicles operating in cluttered and potentially unsafe
environments.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02939" title="Abstract">arXiv:2312.02939</a> [<a href="/pdf/2312.02939" title="Download PDF">pdf</a>, <a href="/ps/2312.02939" title="Download PostScript">ps</a>, <a href="/format/2312.02939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Switching LPV Approach for Analysis and Control of TCP-based  Cyber-Physical Systems under DoS Attack
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Barchinezhad%2C+S">Soheila Barchinezhad</a>, 
<a href="/search/eess?searchtype=author&query=Puig%2C+V">Vicen&#xe7; Puig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Cyberphysical systems (CPSs) integrate controllers, sensors, actuators, and
communication networks. Tight integration with communication networks makes
CPSs vulnerable to cyberattacks. In this paper, we investigate the impact of
denial of service (DoS) attack on the stability of cyber physical systems by
considering the transmission control protocol (TCP) and extract a sufficient
stability condition in linear matrix inequality (LMI) form. To this end, we
model the TCP-CPS under DoS attack as a switching LPV time delay system by
using the Markov jump model. Then, we design parameter dependent stabilizing
controller for CPS under DoS attack, by considering the network parameters.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02944" title="Abstract">arXiv:2312.02944</a> [<a href="/pdf/2312.02944" title="Download PDF">pdf</a>, <a href="/format/2312.02944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An alternating peak-optimization method for optimal trajectory  generation of quadrotor drones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Vries%2C+W+A+B">Wytze A.B. de Vries</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Q">Qirui Song</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhiyong Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In this paper, we propose an alternating optimization method to address a
time-optimal trajectory generation problem. Different from the existing
solutions, our approach introduces a new formulation that minimizes the overall
trajectory running time while maintaining the polynomial smoothness constraints
and incorporating hard limits on motion derivatives to ensure feasibility. To
address this problem, an alternating peak-optimization method is developed,
which splits the optimization process into two sub-optimizations: the first
sub-optimization optimizes polynomial coefficients for smoothness, and the
second sub-optimization adjusts the time allocated to each trajectory segment.
These are alternated until a feasible minimum-time solution is found. We offer
a comprehensive set of simulations and experiments to showcase the superior
performance of our approach in comparison to existing methods.
<br />A collection of demonstration videos with real drone flying experiments can
be accessed at
https://www.youtube.com/playlist?list=PLQGtPFK17zUYkwFT-fr0a8E49R8Uq712l .
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02949" title="Abstract">arXiv:2312.02949</a> [<a href="/pdf/2312.02949" title="Download PDF">pdf</a>, <a href="/format/2312.02949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLaVA-Grounding: Grounded Visual Chat with Large Multimodal Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Feng Li</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+T">Tianhe Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xueyan Zou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shilong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shijia Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianfeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianwei Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the recent significant advancements in large multi-modal models (LMMs),
the importance of their grounding capability in visual chat is increasingly
recognized. Despite recent efforts to enable LMMs to support grounding, their
capabilities for grounding and chat are usually separate, and their chat
performance drops dramatically when asked to ground. The problem is the lack of
a dataset for grounded visual chat (GVC). Existing grounding datasets only
contain short captions. To address this issue, we have created GVC data that
allows for the combination of grounding and chat capabilities. To better
evaluate the GVC capabilities, we have introduced a benchmark called
Grounding-Bench. Additionally, we have proposed a model design that can support
GVC and various types of visual prompts by connecting segmentation models with
language models. Experimental results demonstrate that our model outperforms
other LMMs on Grounding-Bench. Furthermore, our model achieves competitive
performance on classic grounding benchmarks like RefCOCO/+/g and Flickr30K
Entities. Our code will be released at
https://github.com/UX-Decoder/LLaVA-Grounding .
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02955" title="Abstract">arXiv:2312.02955</a> [<a href="/pdf/2312.02955" title="Download PDF">pdf</a>, <a href="/format/2312.02955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Switch Points of Bi-Persistence Matching Distance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brooks%2C+R">Robyn Brooks</a>, 
<a href="/search/cs?searchtype=author&query=Hacker%2C+C">Celia Hacker</a>, 
<a href="/search/cs?searchtype=author&query=Landi%2C+C">Claudia Landi</a>, 
<a href="/search/cs?searchtype=author&query=Mahler%2C+B+I">Barbara I. Mahler</a>, 
<a href="/search/cs?searchtype=author&query=Stephenson%2C+E+R">Elizabeth R. Stephenson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 10 figures. Comments welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Algebraic Topology (math.AT)

</div>
<p class="mathjax">In multi-parameter persistence, the matching distance is defined as the
supremum of weighted bottleneck distances on the barcodes given by the
restriction of persistence modules to lines with a positive slope. In the case
of finitely presented bi-persistence modules, all the available methods to
compute the matching distance are based on restricting the computation to lines
through pairs from a finite set of points in the plane. Some of these points
are determined by the filtration data as they are entrance values of critical
simplices. However, these critical values alone are not sufficient for the
matching distance computation and it is necessary to add so-called switch
points, i.e. points such that on a line through any of them, the bottleneck
matching switches the matched pair.
<br />This paper is devoted to the algorithmic computation of the set of switch
points given a set of critical values. We find conditions under which a
candidate switch point is erroneous or superfluous. The obtained conditions are
turned into algorithms that have been implemented. With this, we analyze how
the size of the set of switch points increases as the number of critical values
increases, and how it varies depending on the distribution of critical values.
Experiments are carried out on various types of bi-persistence modules.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02957" title="Abstract">arXiv:2312.02957</a> [<a href="/pdf/2312.02957" title="Download PDF">pdf</a>, <a href="/format/2312.02957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification for everyone : Building geography agnostic models for  fairer recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jindal%2C+A">Akshat Jindal</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Shreya Singh</a>, 
<a href="/search/cs?searchtype=author&query=Gadgil%2C+S">Soham Gadgil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we analyze different methods to mitigate inherent geographical
biases present in state of the art image classification models. We first
quantitatively present this bias in two datasets - The Dollar Street Dataset
and ImageNet, using images with location information. We then present different
methods which can be employed to reduce this bias. Finally, we analyze the
effectiveness of the different techniques on making these models more robust to
geographical locations of the images.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02962" title="Abstract">arXiv:2312.02962</a> [<a href="/pdf/2312.02962" title="Download PDF">pdf</a>, <a href="/format/2312.02962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Horizontal Gene Transfers with Perfect Transfer Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez%2C+A+L">Alitzel L&#xf3;pez S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Lafond%2C+M">Manuel Lafond</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO); Populations and Evolution (q-bio.PE)

</div>
<p class="mathjax">Horizontal gene transfer inference approaches are usually based on gene
sequences: parametric methods search for patterns that deviate from a
particular genomic signature, while phylogenetic methods use sequences to
reconstruct the gene and species trees. However, it is well-known that
sequences have difficulty identifying ancient transfers since mutations have
enough time to erase all evidence of such events. In this work, we ask whether
character-based methods can predict gene transfers. Their advantage over
sequences is that homologous genes can have low DNA similarity, but still have
retained enough important common motifs that allow them to have common
character traits, for instance the same functional or expression profile. A
phylogeny that has two separate clades that acquired the same character
independently might indicate the presence of a transfer even in the absence of
sequence similarity. We introduce perfect transfer networks, which are
phylogenetic networks that can explain the character diversity of a set of taxa
under the assumption that characters have unique births, and that once a
character is gained it is rarely lost. Examples of such traits include
transposable elements, biochemical markers and emergence of organelles, just to
name a few. We study the differences between our model and two similar models:
perfect phylogenetic networks and ancestral recombination networks. Our goals
are to initiate a study on the structural and algorithmic properties of perfect
transfer networks. We then show that in polynomial time, one can decide whether
a given network is a valid explanation for a set of taxa, and show how, for a
given tree, one can add transfer edges to it so that it explains a set of taxa.
We finally provide lower and upper bounds on the number of transfers required
to explain a set of taxa, in the worst case.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02963" title="Abstract">arXiv:2312.02963</a> [<a href="/pdf/2312.02963" title="Download PDF">pdf</a>, <a href="/format/2312.02963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MVHumanNet: A Large-scale Dataset of Multi-view Daily Dressing Human  Captures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zhangyang Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenghong Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kenkun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+H">Hongjie Liao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jianqiao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Junyi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+S">Shuliang Ning</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Lingteng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chongjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shuguang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaoguang Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://x-zhangyang.github.io/MVHumanNet/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this era, the success of large language models and text-to-image models
can be attributed to the driving force of large-scale datasets. However, in the
realm of 3D vision, while remarkable progress has been made with models trained
on large-scale synthetic and real-captured object data like Objaverse and
MVImgNet, a similar level of progress has not been observed in the domain of
human-centric tasks partially due to the lack of a large-scale human dataset.
Existing datasets of high-fidelity 3D human capture continue to be mid-sized
due to the significant challenges in acquiring large-scale high-quality 3D
human data. To bridge this gap, we present MVHumanNet, a dataset that comprises
multi-view human action sequences of 4,500 human identities. The primary focus
of our work is on collecting human data that features a large number of diverse
identities and everyday clothing using a multi-view human capture system, which
facilitates easily scalable data collection. Our dataset contains 9,000 daily
outfits, 60,000 motion sequences and 645 million frames with extensive
annotations, including human masks, camera parameters, 2D and 3D keypoints,
SMPL/SMPLX parameters, and corresponding textual descriptions. To explore the
potential of MVHumanNet in various 2D and 3D visual tasks, we conducted pilot
studies on view-consistent action recognition, human NeRF reconstruction,
text-driven view-unconstrained human image generation, as well as 2D
view-unconstrained human image and 3D avatar generation. Extensive experiments
demonstrate the performance improvements and effective applications enabled by
the scale provided by MVHumanNet. As the current largest-scale 3D human
dataset, we hope that the release of MVHumanNet data with annotations will
foster further innovations in the domain of 3D human-centric tasks at scale.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02966" title="Abstract">arXiv:2312.02966</a> [<a href="/pdf/2312.02966" title="Download PDF">pdf</a>, <a href="/format/2312.02966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-SS3D: Diffusion Model for Semi-supervised 3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ho%2C+C">Cheng-Ju Ho</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+C">Chen-Hsuan Tai</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yen-Yu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+Y">Yi-Hsuan Tsai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in NeurIPS 2023. Code is available at <a href="https://github.com/luluho1208/Diffusion-SS3D">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semi-supervised object detection is crucial for 3D scene understanding,
efficiently addressing the limitation of acquiring large-scale 3D bounding box
annotations. Existing methods typically employ a teacher-student framework with
pseudo-labeling to leverage unlabeled point clouds. However, producing reliable
pseudo-labels in a diverse 3D space still remains challenging. In this work, we
propose Diffusion-SS3D, a new perspective of enhancing the quality of
pseudo-labels via the diffusion model for semi-supervised 3D object detection.
Specifically, we include noises to produce corrupted 3D object size and class
label distributions, and then utilize the diffusion model as a denoising
process to obtain bounding box outputs. Moreover, we integrate the diffusion
model into the teacher-student framework, so that the denoised bounding boxes
can be used to improve pseudo-label generation, as well as the entire
semi-supervised learning process. We conduct experiments on the ScanNet and SUN
RGB-D benchmark datasets to demonstrate that our approach achieves
state-of-the-art performance against existing methods. We also present
extensive analysis to understand how our diffusion model design affects
performance in semi-supervised learning.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02967" title="Abstract">arXiv:2312.02967</a> [<a href="/pdf/2312.02967" title="Download PDF">pdf</a>, <a href="/format/2312.02967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AmbiGen: Generating Ambigrams from Pre-trained Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Boheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Hanocka%2C+R">Rana Hanocka</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+R+A">Raymond A. Yeh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://raymond-yeh.com/AmbiGen/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Ambigrams are calligraphic designs that have different meanings depending on
the viewing orientation. Creating ambigrams is a challenging task even for
skilled artists, as it requires maintaining the meaning under two different
viewpoints at the same time. In this work, we propose to generate ambigrams by
distilling a large-scale vision and language diffusion model, namely DeepFloyd
IF, to optimize the letters' outline for legibility in the two viewing
orientations. Empirically, we demonstrate that our approach outperforms
existing ambigram generation methods. On the 500 most common words in English,
our method achieves more than an 11.6% increase in word accuracy and at least a
41.9% reduction in edit distance.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02969" title="Abstract">arXiv:2312.02969</a> [<a href="/pdf/2312.02969" title="Download PDF">pdf</a>, <a href="/format/2312.02969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rank-without-GPT: Building GPT-Independent Listwise Rerankers on  Open-Source Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hofst%C3%A4tter%2C+S">Sebastian Hofst&#xe4;tter</a>, 
<a href="/search/cs?searchtype=author&query=Lewis%2C+P">Patrick Lewis</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Raphael Tang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jimmy Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Listwise rerankers based on large language models (LLM) are the zero-shot
state-of-the-art. However, current works in this direction all depend on the
GPT models, making it a single point of failure in scientific reproducibility.
Moreover, it raises the concern that the current research findings only hold
for GPT models but not LLM in general. In this work, we lift this pre-condition
and build for the first time effective listwise rerankers without any form of
dependency on GPT. Our passage retrieval experiments show that our best list se
reranker surpasses the listwise rerankers based on GPT-3.5 by 13% and achieves
97% effectiveness of the ones built on GPT-4. Our results also show that the
existing training datasets, which were expressly constructed for pointwise
ranking, are insufficient for building such listwise rerankers. Instead,
high-quality listwise ranking data is required and crucial, calling for further
work on building human-annotated listwise data resources.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02970" title="Abstract">arXiv:2312.02970</a> [<a href="/pdf/2312.02970" title="Download PDF">pdf</a>, <a href="/format/2312.02970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alchemist: Parametric Control of Material Properties with Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+P">Prafull Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Jampani%2C+V">Varun Jampani</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanzhen Li</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xuhui Jia</a>, 
<a href="/search/cs?searchtype=author&query=Lagun%2C+D">Dmitry Lagun</a>, 
<a href="/search/cs?searchtype=author&query=Durand%2C+F">Fredo Durand</a>, 
<a href="/search/cs?searchtype=author&query=Freeman%2C+W+T">William T. Freeman</a>, 
<a href="/search/cs?searchtype=author&query=Matthews%2C+M">Mark Matthews</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">We propose a method to control material attributes of objects like roughness,
metallic, albedo, and transparency in real images. Our method capitalizes on
the generative prior of text-to-image models known for photorealism, employing
a scalar value and instructions to alter low-level material properties.
Addressing the lack of datasets with controlled material attributes, we
generated an object-centric synthetic dataset with physically-based materials.
Fine-tuning a modified pre-trained text-to-image model on this synthetic
dataset enables us to edit material properties in real-world images while
preserving all other attributes. We show the potential application of our model
to material edited NeRFs.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02973" title="Abstract">arXiv:2312.02973</a> [<a href="/pdf/2312.02973" title="Download PDF">pdf</a>, <a href="/format/2312.02973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GauHuman: Articulated Gaussian Splatting from Monocular Human Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shoukang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> project page: <a href="https://skhu101.github.io/GauHuman/">this https URL</a>; code: <a href="https://github.com/skhu101/GauHuman">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present, GauHuman, a 3D human model with Gaussian Splatting for both fast
training (1 ~ 2 minutes) and real-time rendering (up to 189 FPS), compared with
existing NeRF-based implicit representation modelling frameworks demanding
hours of training and seconds of rendering per frame. Specifically, GauHuman
encodes Gaussian Splatting in the canonical space and transforms 3D Gaussians
from canonical space to posed space with linear blend skinning (LBS), in which
effective pose and LBS refinement modules are designed to learn fine details of
3D humans under negligible computational cost. Moreover, to enable fast
optimization of GauHuman, we initialize and prune 3D Gaussians with 3D human
prior, while splitting/cloning via KL divergence guidance, along with a novel
merge operation for further speeding up. Extensive experiments on ZJU_Mocap and
MonoCap datasets demonstrate that GauHuman achieves state-of-the-art
performance quantitatively and qualitatively with fast training and real-time
rendering speed. Notably, without sacrificing rendering quality, GauHuman can
fast model the 3D human performer with ~13k 3D Gaussians.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02974" title="Abstract">arXiv:2312.02974</a> [<a href="/pdf/2312.02974" title="Download PDF">pdf</a>, <a href="/format/2312.02974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Describing Differences in Image Sets with Natural Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dunlap%2C+L">Lisa Dunlap</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaohan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+R">Ruiqi Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Darrell%2C+T">Trevor Darrell</a>, 
<a href="/search/cs?searchtype=author&query=Steinhardt%2C+J">Jacob Steinhardt</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+J+E">Joseph E. Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Yeung-Levy%2C+S">Serena Yeung-Levy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">How do two sets of images differ? Discerning set-level differences is crucial
for understanding model behaviors and analyzing datasets, yet manually sifting
through thousands of images is impractical. To aid in this discovery process,
we explore the task of automatically describing the differences between two
$\textbf{sets}$ of images, which we term Set Difference Captioning. This task
takes in image sets $D_A$ and $D_B$, and outputs a description that is more
often true on $D_A$ than $D_B$. We outline a two-stage approach that first
proposes candidate difference descriptions from image sets and then re-ranks
the candidates by checking how well they can differentiate the two sets. We
introduce VisDiff, which first captions the images and prompts a language model
to propose candidate descriptions, then re-ranks these descriptions using CLIP.
To evaluate VisDiff, we collect VisDiffBench, a dataset with 187 paired image
sets with ground truth difference descriptions. We apply VisDiff to various
domains, such as comparing datasets (e.g., ImageNet vs. ImageNetV2), comparing
classification models (e.g., zero-shot CLIP vs. supervised ResNet), summarizing
model failure modes (supervised ResNet), characterizing differences between
generative models (e.g., StableDiffusionV1 and V2), and discovering what makes
images memorable. Using VisDiff, we are able to find interesting and previously
unknown differences in datasets and models, demonstrating its utility in
revealing nuanced insights.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02975" title="Abstract">arXiv:2312.02975</a> [<a href="/pdf/2312.02975" title="Download PDF">pdf</a>, <a href="/format/2312.02975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dexterous Functional Grasping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+A">Ananye Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Uppal%2C+S">Shagun Uppal</a>, 
<a href="/search/cs?searchtype=author&query=Shaw%2C+K">Kenneth Shaw</a>, 
<a href="/search/cs?searchtype=author&query=Pathak%2C+D">Deepak Pathak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In CoRL 2023. Website at <a href="https://dexfunc.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">While there have been significant strides in dexterous manipulation, most of
it is limited to benchmark tasks like in-hand reorientation which are of
limited utility in the real world. The main benefit of dexterous hands over
two-fingered ones is their ability to pickup tools and other objects (including
thin ones) and grasp them firmly to apply force. However, this task requires
both a complex understanding of functional affordances as well as precise
low-level control. While prior work obtains affordances from human data this
approach doesn't scale to low-level control. Similarly, simulation training
cannot give the robot an understanding of real-world semantics. In this paper,
we aim to combine the best of both worlds to accomplish functional grasping for
in-the-wild objects. We use a modular approach. First, affordances are obtained
by matching corresponding regions of different objects and then a low-level
policy trained in sim is run to grasp it. We propose a novel application of
eigengrasps to reduce the search space of RL using a small amount of human data
and find that it leads to more stable and physically realistic motion. We find
that eigengrasp action space beats baselines in simulation and outperforms
hardcoded grasping in real and matches or outperforms a trained human
teleoperator. Results visualizations and videos at https://dexfunc.github.io/
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02976" title="Abstract">arXiv:2312.02976</a> [<a href="/pdf/2312.02976" title="Download PDF">pdf</a>, <a href="/format/2312.02976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imitating Shortest Paths in Simulation Enables Effective Navigation and  Manipulation in the Real World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ehsani%2C+K">Kiana Ehsani</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+T">Tanmay Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Hendrix%2C+R">Rose Hendrix</a>, 
<a href="/search/cs?searchtype=author&query=Salvador%2C+J">Jordi Salvador</a>, 
<a href="/search/cs?searchtype=author&query=Weihs%2C+L">Luca Weihs</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+K">Kuo-Hao Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+K+P">Kunal Pratap Singh</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yejin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+W">Winson Han</a>, 
<a href="/search/cs?searchtype=author&query=Herrasti%2C+A">Alvaro Herrasti</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+R">Ranjay Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Schwenk%2C+D">Dustin Schwenk</a>, 
<a href="/search/cs?searchtype=author&query=VanderBilt%2C+E">Eli VanderBilt</a>, 
<a href="/search/cs?searchtype=author&query=Kembhavi%2C+A">Aniruddha Kembhavi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First six authors contributed equally. Project page: <a href="https://spoc-robot.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Reinforcement learning (RL) with dense rewards and imitation learning (IL)
with human-generated trajectories are the most widely used approaches for
training modern embodied agents. RL requires extensive reward shaping and
auxiliary losses and is often too slow and ineffective for long-horizon tasks.
While IL with human supervision is effective, collecting human trajectories at
scale is extremely expensive. In this work, we show that imitating
shortest-path planners in simulation produces agents that, given a language
instruction, can proficiently navigate, explore, and manipulate objects in both
simulation and in the real world using only RGB sensors (no depth map or GPS
coordinates). This surprising result is enabled by our end-to-end,
transformer-based, SPOC architecture, powerful visual encoders paired with
extensive image augmentation, and the dramatic scale and diversity of our
training data: millions of frames of shortest-path-expert trajectories
collected inside approximately 200,000 procedurally generated houses containing
40,000 unique 3D assets. Our models, data, training code, and newly proposed
10-task benchmarking suite CHORES will be open-sourced.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02980" title="Abstract">arXiv:2312.02980</a> [<a href="/pdf/2312.02980" title="Download PDF">pdf</a>, <a href="/format/2312.02980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT4Point: A Unified Framework for Point-Language Understanding and  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zhangyang Qi</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Ye Fang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zeyi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaoyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hengshuang Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multimodal Large Language Models (MLLMs) have excelled in 2D image-text
comprehension and image generation, but their understanding of the 3D world is
notably deficient, limiting progress in 3D language understanding and
generation. To solve this problem, we introduce GPT4Point, an innovative
groundbreaking point-language multimodal model designed specifically for
unified 3D object understanding and generation within the MLLM framework.
GPT4Point as a powerful 3D MLLM seamlessly can execute a variety of point-text
reference tasks such as point-cloud captioning and Q&amp;A. Additionally, GPT4Point
is equipped with advanced capabilities for controllable 3D generation, it can
get high-quality results through a low-quality point-text feature maintaining
the geometric shapes and colors. To support the expansive needs of 3D
object-text pairs, we develop Pyramid-XL, a point-language dataset annotation
engine. It constructs a large-scale database over 1M objects of varied text
granularity levels from the Objaverse-XL dataset, essential for training
GPT4Point. A comprehensive benchmark has been proposed to evaluate 3D
point-language understanding capabilities. In extensive evaluations, GPT4Point
has demonstrated superior performance in understanding and generation.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02981" title="Abstract">arXiv:2312.02981</a> [<a href="/pdf/2312.02981" title="Download PDF">pdf</a>, <a href="/format/2312.02981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReconFusion: 3D Reconstruction with Diffusion Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Rundi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Mildenhall%2C+B">Ben Mildenhall</a>, 
<a href="/search/cs?searchtype=author&query=Henzler%2C+P">Philipp Henzler</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+K">Keunhong Park</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Ruiqi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Watson%2C+D">Daniel Watson</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+P+P">Pratul P. Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Verbin%2C+D">Dor Verbin</a>, 
<a href="/search/cs?searchtype=author&query=Barron%2C+J+T">Jonathan T. Barron</a>, 
<a href="/search/cs?searchtype=author&query=Poole%2C+B">Ben Poole</a>, 
<a href="/search/cs?searchtype=author&query=Holynski%2C+A">Aleksander Holynski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://reconfusion.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D reconstruction methods such as Neural Radiance Fields (NeRFs) excel at
rendering photorealistic novel views of complex scenes. However, recovering a
high-quality NeRF typically requires tens to hundreds of input images,
resulting in a time-consuming capture process. We present ReconFusion to
reconstruct real-world scenes using only a few photos. Our approach leverages a
diffusion prior for novel view synthesis, trained on synthetic and multiview
datasets, which regularizes a NeRF-based 3D reconstruction pipeline at novel
camera poses beyond those captured by the set of input images. Our method
synthesizes realistic geometry and texture in underconstrained regions while
preserving the appearance of observed regions. We perform an extensive
evaluation across various real-world datasets, including forward-facing and
360-degree scenes, demonstrating significant performance improvements over
previous few-view NeRF reconstruction approaches.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Wed,  6 Dec 23</h3>
<dl>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.14115" title="Abstract">arXiv:2206.14115</a> (cross-list from quant-ph) [<a href="/pdf/2206.14115" title="Download PDF">pdf</a>, <a href="/format/2206.14115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Neural Architecture Search with Quantum Circuits Metric and  Bayesian Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Duong%2C+T">Trong Duong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Truong%2C+S+T">Sang T. Truong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tam%2C+M">Minh Tam</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bach%2C+B">Bao Bach</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ryu%2C+J">Ju-Young Ryu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Rhee%2C+J+K">June-Koo Kevin Rhee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to ICML 2022 Workshop AI4Science
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">Quantum neural networks are promising for a wide range of applications in the
Noisy Intermediate-Scale Quantum era. As such, there is an increasing demand
for automatic quantum neural architecture search. We tackle this challenge by
designing a quantum circuits metric for Bayesian optimization with Gaussian
process. To this goal, we propose a new quantum gates distance that
characterizes the gates' action over every quantum state and provide a
theoretical perspective on its geometrical properties. Our approach
significantly outperforms the benchmark on three empirical quantum machine
learning problems including training a quantum generative adversarial network,
solving combinatorial optimization in the MaxCut problem, and simulating
quantum Fourier transform. Our method can be extended to characterize behaviors
of various quantum machine learning models.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.11665" title="Abstract">arXiv:2208.11665</a> (cross-list from stat.ME) [<a href="/pdf/2208.11665" title="Download PDF">pdf</a>, <a href="/format/2208.11665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical exploration of the Manifold Hypothesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Whiteley%2C+N">Nick Whiteley</a>, 
<a href="/search/stat?searchtype=author&query=Gray%2C+A">Annie Gray</a>, 
<a href="/search/stat?searchtype=author&query=Rubin-Delanchy%2C+P">Patrick Rubin-Delanchy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">The Manifold Hypothesis is a widely accepted tenet of Machine Learning which
asserts that nominally high-dimensional data are in fact concentrated near a
low-dimensional manifold, embedded in high-dimensional space. This phenomenon
is observed empirically in many real world situations, has led to development
of a wide range of statistical methods in the last few decades, and has been
suggested as a key factor in the success of modern AI technologies. We show
that rich and sometimes intricate manifold structure in data can emerge from a
generic and remarkably simple statistical model -- the Latent Metric Model --
via elementary concepts such as latent variables, correlation and stationarity.
This establishes a general statistical explanation for why the Manifold
Hypothesis seems to hold in so many situations. Informed by the Latent Metric
Model we derive procedures to discover and interpret the geometry of
high-dimensional data, and explore hypotheses about the data generating
mechanism. These procedures operate under minimal assumptions and make use of
well known, scaleable graph-analytic algorithms.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02178" title="Abstract">arXiv:2312.02178</a> (cross-list from eess.SP) [<a href="/pdf/2312.02178" title="Download PDF">pdf</a>, <a href="/format/2312.02178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical ML Codebook Design for Extreme MIMO Beam Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dreifuerst%2C+R+M">Ryan M. Dreifuerst</a>, 
<a href="/search/eess?searchtype=author&query=Heath%2C+R+W">Robert W. Heath Jr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be submitted to IEEE TMLCN
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Beam management is a strategy to unify beamforming and channel state
information (CSI) acquisition with large antenna arrays in 5G. Codebooks serve
multiple uses in beam management including beamforming reference signals, CSI
reporting, and analog beam training. In this paper, we propose and evaluate a
machine learning-refined codebook design process for extremely large
multiple-input multiple-output (X-MIMO) systems. We propose a neural network
and beam selection strategy to design the initial access and refinement
codebooks using end-to-end learning from beamspace representations. The
algorithm, called Extreme-Beam Management (X-BM), can significantly improve the
performance of extremely large arrays as envisioned for 6G and capture
realistic wireless and physical layer aspects. Our results show an 8dB
improvement in initial access and overall effective spectral efficiency
improvements compared to traditional codebook methods.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02203" title="Abstract">arXiv:2312.02203</a> (cross-list from q-bio.NC) [<a href="/pdf/2312.02203" title="Download PDF">pdf</a>, <a href="/format/2312.02203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning High-Order Relationships of Brain Regions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Qiu%2C+W">Weikang Qiu</a>, 
<a href="/search/q-bio?searchtype=author&query=Chu%2C+H">Huangrui Chu</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+S">Selena Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Zuo%2C+H">Haolan Zuo</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+X">Xiaoxiao Li</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhao%2C+Y">Yize Zhao</a>, 
<a href="/search/q-bio?searchtype=author&query=Ying%2C+R">Rex Ying</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Discovering reliable and informative interactions among brain regions from
functional magnetic resonance imaging (fMRI) signals is essential in
neuroscientific predictions of cognition. Most of the current methods fail to
accurately characterize those interactions because they only focus on pairwise
connections and overlook the high-order relationships of brain regions. We
delve into this problem and argue that these high-order relationships should be
maximally informative and minimally redundant (MIMR). However, identifying such
high-order relationships is challenging and highly under-explored. Methods that
can be tailored to our context are also non-existent. In response to this gap,
we propose a novel method named HyBRiD that aims to extract MIMR high-order
relationships from fMRI data. HyBRiD employs a Constructor to identify
hyperedge structures, and a Weighter to compute a weight for each hyperedge.
HyBRiD achieves the MIMR objective through an innovative information bottleneck
framework named multi-head drop-bottleneck with theoretical guarantees. Our
comprehensive experiments demonstrate the effectiveness of our model. Our model
outperforms the state-of-the-art predictive model by an average of 12.1%,
regarding the quality of hyperedges measured by CPM, a standard protocol for
studying brain connections.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02211" title="Abstract">arXiv:2312.02211</a> (cross-list from physics.med-ph) [<a href="/pdf/2312.02211" title="Download PDF">pdf</a>, <a href="/ps/2312.02211" title="Download PostScript">ps</a>, <a href="/format/2312.02211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cycle-consistent Generative Adversarial Network Synthetic CT for MR-only  Adaptive Radiation Therapy on MR-Linac
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Asher%2C+G+L">Gabriel L. Asher</a>, 
<a href="/search/physics?searchtype=author&query=Zaki%2C+B+I">Bassem I. Zaki</a>, 
<a href="/search/physics?searchtype=author&query=Russo%2C+G+A">Gregory A. Russo</a>, 
<a href="/search/physics?searchtype=author&query=Gill%2C+G+S">Gobind S. Gill</a>, 
<a href="/search/physics?searchtype=author&query=Thomas%2C+C+R">Charles R. Thomas</a>, 
<a href="/search/physics?searchtype=author&query=Prioleau%2C+T+O">Temiloluwa O. Prioleau</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+R">Rongxiao Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Hunt%2C+B">Brady Hunt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Purpose: This study assesses the effectiveness of Deep Learning (DL) for
creating synthetic CT (sCT) images in MR-guided adaptive radiation therapy
(MRgART).
<br />Methods: A Cycle-GAN model was trained with MRI and CT scan slices from
MR-LINAC treatments, generating sCT volumes. The analysis involved
retrospective treatment plan data from patients with various tumors. sCT images
were compared with standard CT scans using mean absolute error in Hounsfield
Units (HU) and image similarity metrics (SSIM, PSNR, NCC). sCT volumes were
integrated into a clinical treatment system for dosimetric re-evaluation.
<br />Results: The model, trained on 8405 frames from 57 patients and tested on 357
sCT frames from 17 patients, showed sCTs comparable to dCTs in electron density
and structural similarity with MRI scans. The MAE between sCT and dCT was 49.2
+/- 13.2 HU, with sCT NCC exceeding dCT by 0.06, and SSIM and PSNR at 0.97 +/-
0.01 and 19.9 +/- 1.6 respectively. Dosimetric evaluations indicated minimal
differences between sCTs and dCTs, with sCTs showing better air-bubble
reconstruction.
<br />Conclusions: DL-based sCT generation on MR-Linacs is accurate for dose
calculation and optimization in MRgART. This could facilitate MR-only treatment
planning, enhancing simulation and adaptive planning efficiency on MR-Linacs.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02225" title="Abstract">arXiv:2312.02225</a> (cross-list from physics.med-ph) [<a href="/pdf/2312.02225" title="Download PDF">pdf</a>, <a href="/format/2312.02225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital Histopathology with Graph Neural Networks: Concepts and  Explanations for Clinicians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=di+Villaforesta%2C+A+F">Alessandro Farace di Villaforesta</a>, 
<a href="/search/physics?searchtype=author&query=Magister%2C+L+C">Lucie Charlotte Magister</a>, 
<a href="/search/physics?searchtype=author&query=Barbiero%2C+P">Pietro Barbiero</a>, 
<a href="/search/physics?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">To address the challenge of the ``black-box" nature of deep learning in
medical settings, we combine GCExplainer - an automated concept discovery
solution - along with Logic Explained Networks to provide global explanations
for Graph Neural Networks. We demonstrate this using a generally applicable
graph construction and classification pipeline, involving panoptic segmentation
with HoVer-Net and cancer prediction with Graph Convolution Networks. By
training on H&amp;E slides of breast cancer, we show promising results in offering
explainable and trustworthy AI tools for clinicians.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02241" title="Abstract">arXiv:2312.02241</a> (cross-list from eess.SP) [<a href="/pdf/2312.02241" title="Download PDF">pdf</a>, <a href="/format/2312.02241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Mapping of Triangular Block Interleavers to DRAM for Optical Satellite  Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Steiner%2C+L">Lukas Steiner</a>, 
<a href="/search/eess?searchtype=author&query=Lehnigk-Emden%2C+T">Timo Lehnigk-Emden</a>, 
<a href="/search/eess?searchtype=author&query=Fehrenz%2C+M">Markus Fehrenz</a>, 
<a href="/search/eess?searchtype=author&query=Wehn%2C+N">Norbert Wehn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Communication in optical downlinks of low earth orbit (LEO) satellites
requires interleaving to enable reliable data transmission. These interleavers
are orders of magnitude larger than conventional interleavers utilized for
example in wireless communication. Hence, the capacity of on-chip memories
(SRAMs) is insufficient to store all symbols and external memories (DRAMs) must
be used. Due to the overall requirement for very high data rates beyond 100
Gbit/s, DRAM bandwidth then quickly becomes a critical bottleneck of the
communication system. In this paper, we investigate triangular block
interleavers for the aforementioned application and show that the standard
mapping of symbols used for SRAMs results in low bandwidth utilization for
DRAMs, in some cases below 50 %. As a solution, we present a novel mapping
approach that combines different optimizations and achieves over 90 % bandwidth
utilization in all tested configurations. Further, the mapping can be applied
to any JEDEC-compliant DRAM device.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02248" title="Abstract">arXiv:2312.02248</a> (cross-list from q-bio.QM) [<a href="/pdf/2312.02248" title="Download PDF">pdf</a>, <a href="/ps/2312.02248" title="Download PostScript">ps</a>, <a href="/format/2312.02248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards early diagnosis of Alzheimer&#x27;s disease: Advances in  immune-related blood biomarkers and computational modeling approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Krix%2C+S">Sophia Krix</a>, 
<a href="/search/q-bio?searchtype=author&query=Wilczynski%2C+E">Ella Wilczynski</a>, 
<a href="/search/q-bio?searchtype=author&query=Falg%C3%A0s%2C+N">Neus Falg&#xe0;s</a>, 
<a href="/search/q-bio?searchtype=author&query=S%C3%A1nchez-Valle%2C+R">Raquel S&#xe1;nchez-Valle</a>, 
<a href="/search/q-bio?searchtype=author&query=Yoles%2C+E">Eti Yoles</a>, 
<a href="/search/q-bio?searchtype=author&query=Nevo%2C+U">Uri Nevo</a>, 
<a href="/search/q-bio?searchtype=author&query=Baruch%2C+K">Kuti Baruch</a>, 
<a href="/search/q-bio?searchtype=author&query=Fr%C3%B6hlich%2C+H">Holger Fr&#xf6;hlich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Alzheimer's disease has an increasing prevalence in the population
world-wide, yet current diagnostic methods based on recommended biomarkers are
only available in specialized clinics. Due to these circumstances, Alzheimer's
disease is usually diagnosed late, which contrasts with the currently available
treatment options that are only effective for patients at an early stage.
Blood-based biomarkers could fill in the gap of easily accessible and low-cost
methods for early diagnosis of the disease. In particular, immune-based
blood-biomarkers might be a promising option, given the recently discovered
cross-talk of immune cells of the central nervous system with those in the
peripheral immune system. With the help of machine learning algorithms and
mechanistic modeling approaches, such as agent-based modeling, an in-depth
analysis of the simulation of cell dynamics is possible as well as of
high-dimensional omics resources indicative of pathway signaling changes. Here,
we give a background on advances in research on brain-immune system cross-talk
in Alzheimer's disease and review recent machine learning and mechanistic
modeling approaches which leverage modern omics technologies for blood-based
immune system-related biomarker discovery.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02264" title="Abstract">arXiv:2312.02264</a> (cross-list from hep-ph) [<a href="/pdf/2312.02264" title="Download PDF">pdf</a>, <a href="/format/2312.02264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Laws in Jet Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ph?searchtype=author&query=Batson%2C+J">Joshua Batson</a>, 
<a href="/search/hep-ph?searchtype=author&query=Kahn%2C+Y">Yonatan Kahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10+2 pages, 7 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Phenomenology (hep-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We demonstrate the emergence of scaling laws in the benchmark top versus QCD
jet classification problem in collider physics. Six distinct
physically-motivated classifiers exhibit power-law scaling of the binary
cross-entropy test loss as a function of training set size, with distinct power
law indices. This result highlights the importance of comparing classifiers as
a function of dataset size rather than for a fixed training set, as the optimal
classifier may change considerably as the dataset is scaled up. We speculate on
the interpretation of our results in terms of previous models of scaling laws
observed in natural language and image datasets.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02277" title="Abstract">arXiv:2312.02277</a> (cross-list from math.OC) [<a href="/pdf/2312.02277" title="Download PDF">pdf</a>, <a href="/format/2312.02277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ALEXR: Optimal Single-Loop Algorithms for Convex Finite-Sum Coupled  Compositional Stochastic Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+B">Bokun Wang</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+T">Tianbao Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper revisits a class of convex Finite-Sum Coupled Compositional
Stochastic Optimization (cFCCO) problems with many applications, including
group distributionally robust optimization (GDRO), reinforcement learning, and
learning to rank. To better solve these problems, we introduce a unified family
of efficient single-loop primal-dual block-coordinate proximal algorithms,
dubbed ALEXR. This algorithm leverages block-coordinate stochastic mirror
ascent updates for the dual variable and stochastic proximal gradient descent
updates for the primal variable. We establish the convergence rates of ALEXR in
both convex and strongly convex cases under smoothness and non-smoothness
conditions of involved functions, which not only improve the best rates in
previous works on smooth cFCCO problems but also expand the realm of cFCCO for
solving more challenging non-smooth problems such as the dual form of GDRO.
Finally, we present lower complexity bounds to demonstrate that the convergence
rates of ALEXR are optimal among first-order block-coordinate stochastic
algorithms for the considered class of cFCCO problems.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02298" title="Abstract">arXiv:2312.02298</a> (cross-list from eess.SP) [<a href="/pdf/2312.02298" title="Download PDF">pdf</a>, <a href="/format/2312.02298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MoE-AMC: Enhancing Automatic Modulation Classification Performance Using  Mixture-of-Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gao%2C+J">Jiaxin Gao</a>, 
<a href="/search/eess?searchtype=author&query=Cao%2C+Q">Qinglong Cao</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yuntian Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">Automatic Modulation Classification (AMC) plays a vital role in time series
analysis, such as signal classification and identification within wireless
communications. Deep learning-based AMC models have demonstrated significant
potential in this domain. However, current AMC models inadequately consider the
disparities in handling signals under conditions of low and high
Signal-to-Noise Ratio (SNR), resulting in an unevenness in their performance.
In this study, we propose MoE-AMC, a novel Mixture-of-Experts (MoE) based model
specifically crafted to address AMC in a well-balanced manner across varying
SNR conditions. Utilizing the MoE framework, MoE-AMC seamlessly combines the
strengths of LSRM (a Transformer-based model) for handling low SNR signals and
HSRM (a ResNet-based model) for high SNR signals. This integration empowers
MoE-AMC to achieve leading performance in modulation classification, showcasing
its efficacy in capturing distinctive signal features under diverse SNR
scenarios. We conducted experiments using the RML2018.01a dataset, where
MoE-AMC achieved an average classification accuracy of 71.76% across different
SNR levels, surpassing the performance of previous SOTA models by nearly 10%.
This study represents a pioneering application of MoE techniques in the realm
of AMC, offering a promising avenue for elevating signal classification
accuracy within wireless communication systems.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02341" title="Abstract">arXiv:2312.02341</a> (cross-list from math.OC) [<a href="/pdf/2312.02341" title="Download PDF">pdf</a>, <a href="/format/2312.02341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incentive Systems for Fleets of New Mobility Services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ghafelebashi%2C+A">Ali Ghafelebashi</a>, 
<a href="/search/math?searchtype=author&query=Razaviyayn%2C+M">Meisam Razaviyayn</a>, 
<a href="/search/math?searchtype=author&query=Dessouky%2C+M">Maged Dessouky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 12 figures. arXiv admin note: text overlap with <a href="/abs/2204.07306">arXiv:2204.07306</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Traffic congestion has become an inevitable challenge in large cities due to
population increases and expansion of urban areas. Various approaches are
introduced to mitigate traffic issues, encompassing from expanding the road
infrastructure to employing demand management. Congestion pricing and incentive
schemes are extensively studied for traffic control in traditional networks
where each driver is a network "player". In this setup, drivers' "selfish"
behavior hinders the network from reaching a socially optimal state. In future
mobility services, on the other hand, a large portion of drivers/vehicles may
be controlled by a small number of companies/organizations. In such a system,
offering incentives to organizations can potentially be much more effective in
reducing traffic congestion rather than offering incentives directly to
drivers. This paper studies the problem of offering incentives to organizations
to change the behavior of their individual drivers (or individuals relying on
the organization's services). We developed a model where incentives are offered
to each organization based on the aggregated travel time loss across all
drivers in that organization. Such an incentive offering mechanism requires
solving a large-scale optimization problem to minimize the system-level travel
time. We propose an efficient algorithm for solving this optimization problem.
Numerous experiments on Los Angeles County traffic data reveal the ability of
our method to reduce system-level travel time by up to 6.9%. Moreover, our
experiments demonstrate that incentivizing organizations can be up to 8 times
more efficient than incentivizing individual drivers in terms of
incentivization monetary cost.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02365" title="Abstract">arXiv:2312.02365</a> (cross-list from eess.IV) [<a href="/pdf/2312.02365" title="Download PDF">pdf</a>, <a href="/format/2312.02365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MEDPSeg: End-to-end segmentation of pulmonary structures and lesions in  computed tomography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Carmo%2C+D+S">Diedre S. Carmo</a>, 
<a href="/search/eess?searchtype=author&query=Ribeiro%2C+J">Jean Ribeiro</a>, 
<a href="/search/eess?searchtype=author&query=Comellas%2C+A+P">Alejandro P. Comellas</a>, 
<a href="/search/eess?searchtype=author&query=Reinhardt%2C+J+M">Joseph M. Reinhardt</a>, 
<a href="/search/eess?searchtype=author&query=Gerard%2C+S+E">Sarah E. Gerard</a>, 
<a href="/search/eess?searchtype=author&query=Rittner%2C+L">Let&#xed;cia Rittner</a>, 
<a href="/search/eess?searchtype=author&query=Lotufo%2C+R+A">Roberto A. Lotufo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The COVID-19 pandemic response highlighted the potential of deep learning
methods in facilitating the diagnosis and prognosis of lung diseases through
automated segmentation of normal and abnormal tissue in computed tomography
(CT). Such methods not only have the potential to aid in clinical
decision-making but also contribute to the comprehension of novel diseases. In
light of the labor-intensive nature of manual segmentation for large chest CT
cohorts, there is a pressing need for reliable automated approaches that enable
efficient analysis of chest CT anatomy in vast research databases, especially
in more scarcely annotated targets such as pneumonia consolidations. A limiting
factor for the development of such methods is that most current models optimize
a fixed annotation format per network output. To tackle this problem,
polymorphic training is used to optimize a network with a fixed number of
output channels to represent multiple hierarchical anatomic structures,
indirectly optimizing more complex labels with simpler annotations. We combined
over 6000 volumetric CT scans containing varying formats of manual and
automated labels from different sources, and used polymorphic training along
with multitask learning to develop MEDPSeg, an end-to-end method for the
segmentation of lungs, airways, pulmonary artery, and lung lesions with
separation of ground glass opacities, and parenchymal consolidations, all in a
single forward prediction. We achieve state-of-the-art performance in multiple
targets, particularly in the segmentation of ground glass opacities and
consolidations, a challenging problem with limited manual annotation
availability. In addition, we provide an open-source implementation with a
graphical user interface at https://github.com/MICLab-Unicamp/medpseg.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02367" title="Abstract">arXiv:2312.02367</a> (cross-list from q-bio.NC) [<a href="/pdf/2312.02367" title="Download PDF">pdf</a>, <a href="/format/2312.02367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> States as goal-directed concepts: an epistemic approach to  state-representation learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Amir%2C+N">Nadav Amir</a>, 
<a href="/search/q-bio?searchtype=author&query=Niv%2C+Y">Yael Niv</a>, 
<a href="/search/q-bio?searchtype=author&query=Langdon%2C+A">Angela Langdon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Our goals fundamentally shape how we experience the world. For example, when
we are hungry, we tend to view objects in our environment according to whether
or not they are edible (or tasty). Alternatively, when we are cold, we may view
the very same objects according to their ability to produce heat. Computational
theories of learning in cognitive systems, such as reinforcement learning, use
the notion of "state-representation" to describe how agents decide which
features of their environment are behaviorally-relevant and which can be
ignored. However, these approaches typically assume "ground-truth" state
representations that are known by the agent, and reward functions that need to
be learned. Here we suggest an alternative approach in which
state-representations are not assumed veridical, or even pre-defined, but
rather emerge from the agent's goals through interaction with its environment.
We illustrate this novel perspective by inferring the goals driving rat
behavior in an odor-guided choice task and discuss its implications for
developing, from first principles, an information-theoretic account of
goal-directed state representation learning and behavior.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02372" title="Abstract">arXiv:2312.02372</a> (cross-list from eess.SP) [<a href="/pdf/2312.02372" title="Download PDF">pdf</a>, <a href="/format/2312.02372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Trade-Off between Stability and Representational Capacity in  Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gao%2C+Z">Zhan Gao</a>, 
<a href="/search/eess?searchtype=author&query=Prorok%2C+A">Amanda Prorok</a>, 
<a href="/search/eess?searchtype=author&query=Isufi%2C+E">Elvin Isufi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Analyzing the stability of graph neural networks (GNNs) under topological
perturbations is key to understanding their transferability and the role of
each architecture component. However, stability has been investigated only for
particular architectures, questioning whether it holds for a broader spectrum
of GNNs or only for a few instances. To answer this question, we study the
stability of EdgeNet: a general GNN framework that unifies more than twenty
solutions including the convolutional and attention-based classes, as well as
graph isomorphism networks and hybrid architectures. We prove that all GNNs
within the EdgeNet framework are stable to topological perturbations. By
studying the effect of different EdgeNet categories on the stability, we show
that GNNs with fewer degrees of freedom in their parameter space, linked to a
lower representational capacity, are more stable. The key factor yielding this
trade-off is the eigenvector misalignment between the EdgeNet parameter
matrices and the graph shift operator. For example, graph convolutional neural
networks that assign a single scalar per signal shift (hence, with a perfect
alignment) are more stable than the more involved node or edge-varying
counterparts. Extensive numerical results corroborate our theoretical findings
and highlight the role of different architecture components in the trade-off.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02375" title="Abstract">arXiv:2312.02375</a> (cross-list from stat.ML) [<a href="/pdf/2312.02375" title="Download PDF">pdf</a>, <a href="/format/2312.02375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CityTFT: Temporal Fusion Transformer for Urban Building Energy Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Dai%2C+T">Ting-Yu Dai</a>, 
<a href="/search/stat?searchtype=author&query=Niyogi%2C+D">Dev Niyogi</a>, 
<a href="/search/stat?searchtype=author&query=Nagy%2C+Z">Zoltan Nagy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Urban Building Energy Modeling (UBEM) is an emerging method to investigate
urban design and energy systems against the increasing energy demand at urban
and neighborhood levels. However, current UBEM methods are mostly physic-based
and time-consuming in multiple climate change scenarios. This work proposes
CityTFT, a data-driven UBEM framework, to accurately model the energy demands
in urban environments. With the empowerment of the underlying TFT framework and
an augmented loss function, CityTFT could predict heating and cooling triggers
in unseen climate dynamics with an F1 score of 99.98 \% while RMSE of loads of
13.57 kWh.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02401" title="Abstract">arXiv:2312.02401</a> (cross-list from stat.ML) [<a href="/pdf/2312.02401" title="Download PDF">pdf</a>, <a href="/format/2312.02401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harmonizing Global Voices: Culturally-Aware Models for Enhanced Content  Moderation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chan%2C+A+J">Alex J. Chan</a>, 
<a href="/search/stat?searchtype=author&query=Garc%C3%ADa%2C+J+L+R">Jos&#xe9; Luis Redondo Garc&#xed;a</a>, 
<a href="/search/stat?searchtype=author&query=Silvestri%2C+F">Fabrizio Silvestri</a>, 
<a href="/search/stat?searchtype=author&query=O%27Donnel%2C+C">Colm O&#x27;Donnel</a>, 
<a href="/search/stat?searchtype=author&query=Palla%2C+K">Konstantina Palla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 Figures. Supplementary material
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Content moderation at scale faces the challenge of considering local cultural
distinctions when assessing content. While global policies aim to maintain
decision-making consistency and prevent arbitrary rule enforcement, they often
overlook regional variations in interpreting natural language as expressed in
content. In this study, we are looking into how moderation systems can tackle
this issue by adapting to local comprehension nuances. We train large language
models on extensive datasets of media news and articles to create culturally
attuned models. The latter aim to capture the nuances of communication across
geographies with the goal of recognizing cultural and societal variations in
what is considered offensive content. We further explore the capability of
these models to generate explanations for instances of content violation,
aiming to shed light on how policy guidelines are perceived when cultural and
societal contexts change. We find that training on extensive media datasets
successfully induced cultural awareness and resulted in improvements in
handling content violations on a regional basis. Additionally, these
advancements include the ability to provide explanations that align with the
specific local norms and nuances as evidenced by the annotators' preference in
our conducted study. This multifaceted success reinforces the critical role of
an adaptable content moderation approach in keeping pace with the ever-evolving
nature of the content it oversees.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02417" title="Abstract">arXiv:2312.02417</a> (cross-list from math.ST) [<a href="/pdf/2312.02417" title="Download PDF">pdf</a>, <a href="/format/2312.02417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-Optimal Mean Estimation with Unknown, Heteroskedastic Variances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Compton%2C+S">Spencer Compton</a>, 
<a href="/search/math?searchtype=author&query=Valiant%2C+G">Gregory Valiant</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (stat.ML)

</div>
<p class="mathjax">Given data drawn from a collection of Gaussian variables with a common mean
but different and unknown variances, what is the best algorithm for estimating
their common mean? We present an intuitive and efficient algorithm for this
task. As different closed-form guarantees can be hard to compare, the
Subset-of-Signals model serves as a benchmark for heteroskedastic mean
estimation: given $n$ Gaussian variables with an unknown subset of $m$
variables having variance bounded by 1, what is the optimal estimation error as
a function of $n$ and $m$? Our algorithm resolves this open question up to
logarithmic factors, improving upon the previous best known estimation error by
polynomial factors when $m = n^c$ for all $0&lt;c&lt;1$. Of particular note, we
obtain error $o(1)$ with $m = \tilde{O}(n^{1/4})$ variance-bounded samples,
whereas previous work required $m = \tilde{\Omega}(n^{1/2})$. Finally, we show
that in the multi-dimensional setting, even for $d=2$, our techniques enable
rates comparable to knowing the variance of each sample.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02430" title="Abstract">arXiv:2312.02430</a> (cross-list from math.OC) [<a href="/pdf/2312.02430" title="Download PDF">pdf</a>, <a href="/ps/2312.02430" title="Download PostScript">ps</a>, <a href="/format/2312.02430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Almost-Sure Safety Guarantees of Stochastic Zero-Control Barrier  Functions Do Not Hold
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=So%2C+O">Oswin So</a>, 
<a href="/search/math?searchtype=author&query=Clark%2C+A">Andrew Clark</a>, 
<a href="/search/math?searchtype=author&query=Fan%2C+C">Chuchu Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">The 2021 paper "Control barrier functions for stochastic systems" provides
theorems that give almost sure safety guarantees given stochastic zero control
barrier function (ZCBF). Unfortunately, both the theorem and its proof is
invalid. In this letter, we illustrate on a toy example that the almost sure
safety guarantees for stochastic ZCBF do not hold and explain why the proof is
flawed. Although stochastic reciprocal barrier functions (RCBF) also uses the
same proof technique, we provide a different proof technique that verifies that
stochastic RCBFs are indeed safe with probability one. Using the RCBF, we
derive a modified ZCBF condition that guarantees safety with probability one.
Finally, we provide some discussion on the role of unbounded controls in the
almost-sure safety guarantees of RCBFs, and show that the rate of divergence of
the ratio of the drift and diffusion is the key for whether a system has almost
sure safety guarantees.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02450" title="Abstract">arXiv:2312.02450</a> (cross-list from stat.ML) [<a href="/pdf/2312.02450" title="Download PDF">pdf</a>, <a href="/format/2312.02450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GIT-Net: Generalized Integral Transform for Operator Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wang%2C+C">Chao Wang</a>, 
<a href="/search/stat?searchtype=author&query=Thiery%2C+A+H">Alexandre Hoang Thiery</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transactions on Machine Learning Research (05 Dec 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This article introduces GIT-Net, a deep neural network architecture for
approximating Partial Differential Equation (PDE) operators, inspired by
integral transform operators. GIT-NET harnesses the fact that differential
operators commonly used for defining PDEs can often be represented
parsimoniously when expressed in specialized functional bases (e.g., Fourier
basis). Unlike rigid integral transforms, GIT-Net parametrizes adaptive
generalized integral transforms with deep neural networks. When compared to
several recently proposed alternatives, GIT-Net's computational and memory
requirements scale gracefully with mesh discretizations, facilitating its
application to PDE problems on complex geometries. Numerical experiments
demonstrate that GIT-Net is a competitive neural network operator, exhibiting
small test errors and low evaluations across a range of PDE problems. This
stands in contrast to existing neural network operators, which typically excel
in just one of these areas.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02494" title="Abstract">arXiv:2312.02494</a> (cross-list from physics.med-ph) [<a href="/pdf/2312.02494" title="Download PDF">pdf</a>, <a href="/ps/2312.02494" title="Download PostScript">ps</a>, <a href="/format/2312.02494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReconU-Net: a direct PET image reconstruction using U-Net architecture  with back projection-induced skip connection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Hashimoto%2C+F">Fumio Hashimoto</a>, 
<a href="/search/physics?searchtype=author&query=Ote%2C+K">Kibo Ote</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">[Objective] This study aims to introduce a novel back projection-induced
U-Net-shaped architecture, called ReconU-Net, for deep learning-based direct
positron emission tomography (PET) image reconstruction. Additionally, our
objective is to analyze the behavior of direct PET image reconstruction and
gain deeper insights by comparing the proposed ReconU-Net architecture with
other encoder-decoder architectures without skip connections. [Approach] The
proposed ReconU-Net architecture uniquely integrates the physical model of the
back projection operation into the skip connection. This distinctive feature
facilitates the effective transfer of intrinsic spatial information from the
input sinogram to the reconstructed image via an embedded physical model. The
proposed ReconU-Net was trained using Monte Carlo simulation data from the
Brainweb phantom and tested on both simulated and real Hoffman brain phantom
data. [Main results] The proposed ReconU-Net method generated a reconstructed
image with a more accurate structure compared to other deep learning-based
direct reconstruction methods. Further analysis showed that the proposed
ReconU-Net architecture has the ability to transfer features of multiple
resolutions, especially non-abstract high-resolution information, through skip
connections. Despite limited training on simulated data, the proposed
ReconU-Net successfully reconstructed the real Hoffman brain phantom, unlike
other deep learning-based direct reconstruction methods, which failed to
produce a reconstructed image. [Significance] The proposed ReconU-Net can
improve the fidelity of direct PET image reconstruction, even when dealing with
small training datasets, by leveraging the synergistic relationship between
data-driven modeling and the physics model of the imaging process.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02537" title="Abstract">arXiv:2312.02537</a> (cross-list from physics.optics) [<a href="/pdf/2312.02537" title="Download PDF">pdf</a>, <a href="/format/2312.02537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymmetric leader-laggard cluster synchronization for collective  decision-making with laser network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kotoku%2C+S">Shun Kotoku</a>, 
<a href="/search/physics?searchtype=author&query=Mihana%2C+T">Takatomo Mihana</a>, 
<a href="/search/physics?searchtype=author&query=R%C3%B6hm%2C+A">Andr&#xe9; R&#xf6;hm</a>, 
<a href="/search/physics?searchtype=author&query=Horisaki%2C+R">Ryoichi Horisaki</a>, 
<a href="/search/physics?searchtype=author&query=Naruse%2C+M">Makoto Naruse</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Machine Learning (cs.LG); Chaotic Dynamics (nlin.CD)

</div>
<p class="mathjax">Photonic accelerators have recently attracted soaring interest, harnessing
the ultimate nature of light for information processing. Collective
decision-making with a laser network, employing the chaotic and synchronous
dynamics of optically interconnected lasers to address the competitive
multi-armed bandit (CMAB) problem, is a highly compelling approach due to its
scalability and experimental feasibility. We investigated essential network
structures for collective decision-making through quantitative stability
analysis. Moreover, we demonstrated the asymmetric preferences of players in
the CMAB problem, extending its functionality to more practical applications.
Our study highlights the capability and significance of machine learning built
upon chaotic lasers and photonic devices.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02541" title="Abstract">arXiv:2312.02541</a> (cross-list from eess.IV) [<a href="/pdf/2312.02541" title="Download PDF">pdf</a>, <a href="/format/2312.02541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Severity ranking via pairwise n-hidden comparison: a case  study of glaucoma
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+H">Hong Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+C+V">Cuong V. Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Narayanan%2C+S">Shrikanth Narayanan</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+B+Y">Benjamin Y. Xu</a>, 
<a href="/search/eess?searchtype=author&query=Pazzani%2C+M">Michael Pazzani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Primary open-angle glaucoma (POAG) is a chronic and progressive optic nerve
condition that results in an acquired loss of optic nerve fibers and potential
blindness. The gradual onset of glaucoma results in patients progressively
losing their vision without being consciously aware of the changes. To diagnose
POAG and determine its severity, patients must undergo a comprehensive dilated
eye examination. In this work, we build a framework to rank, compare, and
interpret the severity of glaucoma using fundus images. We introduce a
siamese-based severity ranking using pairwise n-hidden comparisons. We
additionally have a novel approach to explaining why a specific image is deemed
more severe than others. Our findings indicate that the proposed severity
ranking model surpasses traditional ones in terms of diagnostic accuracy and
delivers improved saliency explanations.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02544" title="Abstract">arXiv:2312.02544</a> (cross-list from physics.app-ph) [<a href="/pdf/2312.02544" title="Download PDF">pdf</a>, <a href="/ps/2312.02544" title="Download PostScript">ps</a>, <a href="/format/2312.02544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterization of Locality in Spin States and Forced Moves for  Optimizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Sato%2C+Y">Yoshiki Sato</a>, 
<a href="/search/physics?searchtype=author&query=Konoshima%2C+M">Makiko Konoshima</a>, 
<a href="/search/physics?searchtype=author&query=Tamura%2C+H">Hirotaka Tamura</a>, 
<a href="/search/physics?searchtype=author&query=Ohkubo%2C+J">Jun Ohkubo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applied Physics (physics.app-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Ising formulations are widely utilized to solve combinatorial optimization
problems, and a variety of quantum or semiconductor-based hardware has recently
been made available. In combinatorial optimization problems, the existence of
local minima in energy landscapes is problematic to use to seek the global
minimum. We note that the aim of the optimization is not to obtain exact
samplings from the Boltzmann distribution, and there is thus no need to satisfy
detailed balance conditions. In light of this fact, we develop an algorithm to
get out of the local minima efficiently while it does not yield the exact
samplings. For this purpose, we utilize a feature that characterizes locality
in the current state, which is easy to obtain with a type of specialized
hardware. Furthermore, as the proposed algorithm is based on a rejection-free
algorithm, the computational cost is low. In this work, after presenting the
details of the proposed algorithm, we report the results of numerical
experiments that demonstrate the effectiveness of the proposed feature and
algorithm.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02579" title="Abstract">arXiv:2312.02579</a> (cross-list from math.NT) [<a href="/pdf/2312.02579" title="Download PDF">pdf</a>, <a href="/ps/2312.02579" title="Download PostScript">ps</a>, <a href="/format/2312.02579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simple and fast Algorithm for Finding Roots of Error-Locator  Polynomials: Modulus Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Glushchenko%2C+G+N">Gennady N. Glushchenko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Number Theory (math.NT)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">A novel very simple method for finding roots of polynomials over finite
fields has been proposed. The essence of the proposed method is to search the
roots via nested cycles over the subgroups of the multiplicative group of the
Galois field. The modified Chien search is actually used in the inner cycles,
but the internal polynomials are small. The word "modulus" was used because the
search is doing on subsets like alpha^(a+bi), where a,b=const. In addition,
modulo division of polynomials is actively used. The algorithm is applicable
not for all Galois fields, but for selective ones, starting from GF(2^8). The
algorithm has an advantage for large polynomials. The number of operations is
significant for small polynomials, but it grows very slowly with the degree of
the polynomial. When the polynomial is large or very large, the proposed method
can be 10-100 times faster than Chien search.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02581" title="Abstract">arXiv:2312.02581</a> (cross-list from eess.AS) [<a href="/pdf/2312.02581" title="Download PDF">pdf</a>, <a href="/ps/2312.02581" title="Download PostScript">ps</a>, <a href="/format/2312.02581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auralization based on multi-perspective ambisonic room impulse responses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=M%C3%BCller%2C+K">Kaspar M&#xfc;ller</a>, 
<a href="/search/eess?searchtype=author&query=Zotter%2C+F">Franz Zotter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, published in Acta Acustica (Open Access)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Acta Acustica, Volume 4, Number 6, Article Number 25, 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Most often, virtual acoustic rendering employs real-time updated room
acoustic simulations to accomplish auralization for a variable listener
perspective. As an alternative, we propose and test a technique to interpolate
room impulse responses, specifically Ambisonic room impulse responses (ARIRs)
available at a grid of spatially distributed receiver perspectives, measured or
simulated in a desired acoustic environment. In particular, we extrapolate a
triplet of neighboring ARIRs to the variable listener perspective, preceding
their linear interpolation. The extrapolation is achieved by decomposing each
ARIR into localized sound events and re-assigning their direction, time, and
level to what could be observed at the listener perspective, with as much
temporal, directional, and perspective context as possible. We propose to
undertake this decomposition in two levels: Peaks in the early ARIRs are
decomposed into jointly localized sound events, based on time differences of
arrival observed in either an ARIR triplet, or all ARIRs observing the direct
sound. Sound events that could not be jointly localized are treated as
residuals whose less precise localization utilizes direction-of-arrival
detection and the estimated time of arrival. For the interpolated rendering,
suitable parameter settings are found by evaluating the proposed method in a
listening experiment, using both measured and simulated ARIR data sets, under
static and time-varying conditions.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02605" title="Abstract">arXiv:2312.02605</a> (cross-list from eess.IV) [<a href="/pdf/2312.02605" title="Download PDF">pdf</a>, <a href="/format/2312.02605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Learnt Video Codecs with Gradient Decay and Layer-wise  Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Peng%2C+T">Tianhao Peng</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+G">Ge Gao</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+H">Heming Sun</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Bull%2C+D">David Bull</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In recent years, end-to-end learnt video codecs have demonstrated their
potential to compete with conventional coding algorithms in term of compression
efficiency. However, most learning-based video compression models are
associated with high computational complexity and latency, in particular at the
decoder side, which limits their deployment in practical applications. In this
paper, we present a novel model-agnostic pruning scheme based on gradient decay
and adaptive layer-wise distillation. Gradient decay enhances parameter
exploration during sparsification whilst preventing runaway sparsity and is
superior to the standard Straight-Through Estimation. The adaptive layer-wise
distillation regulates the sparse training in various stages based on the
distortion of intermediate features. This stage-wise design efficiently updates
parameters with minimal computational overhead. The proposed approach has been
applied to three popular end-to-end learnt video codecs, FVC, DCVC, and
DCVC-HEM. Results confirm that our method yields up to 65% reduction in MACs
and 2x speed-up with less than 0.3dB drop in BD-PSNR. Supporting code and
supplementary material can be downloaded from:
https://jasminepp.github.io/lightweightdvc/
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02652" title="Abstract">arXiv:2312.02652</a> (cross-list from hep-ex) [<a href="/pdf/2312.02652" title="Download PDF">pdf</a>, <a href="/format/2312.02652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Machine Learning Can Do for Focusing Aerogel Detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ex?searchtype=author&query=Shipilov%2C+F">Foma Shipilov</a>, 
<a href="/search/hep-ex?searchtype=author&query=Barnyakov%2C+A">Alexander Barnyakov</a>, 
<a href="/search/hep-ex?searchtype=author&query=Bobrovnikov%2C+V">Vladimir Bobrovnikov</a>, 
<a href="/search/hep-ex?searchtype=author&query=Kononov%2C+S">Sergey Kononov</a>, 
<a href="/search/hep-ex?searchtype=author&query=Ratnikov%2C+F">Fedor Ratnikov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, to be published in 26th International Conference on Computing in High Energy &amp; Nuclear Physics (CHEP2023) proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Experiment (hep-ex)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Particle identification at the Super Charm-Tau factory experiment will be
provided by a Focusing Aerogel Ring Imaging CHerenkov detector (FARICH). The
specifics of detector location make proper cooling difficult, therefore a
significant number of ambient background hits are captured. They must be
mitigated to reduce the data flow and improve particle velocity resolution. In
this work we present several approaches to filtering signal hits, inspired by
machine learning techniques from computer vision.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02671" title="Abstract">arXiv:2312.02671</a> (cross-list from stat.ML) [<a href="/pdf/2312.02671" title="Download PDF">pdf</a>, <a href="/ps/2312.02671" title="Download PostScript">ps</a>, <a href="/format/2312.02671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning a Sparse Representation of Barron Functions with the Inverse  Scale Space Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Heeringa%2C+T+J">Tjeerd Jan Heeringa</a>, 
<a href="/search/stat?searchtype=author&query=Roith%2C+T">Tim Roith</a>, 
<a href="/search/stat?searchtype=author&query=Brune%2C+C">Christoph Brune</a>, 
<a href="/search/stat?searchtype=author&query=Burger%2C+M">Martin Burger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 0 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Functional Analysis (math.FA); Numerical Analysis (math.NA)

</div>
<p class="mathjax">This paper presents a method for finding a sparse representation of Barron
functions. Specifically, given an $L^2$ function $f$, the inverse scale space
flow is used to find a sparse measure $\mu$ minimising the $L^2$ loss between
the Barron function associated to the measure $\mu$ and the function $f$. The
convergence properties of this method are analysed in an ideal setting and in
the cases of measurement noise and sampling bias. In an ideal setting the
objective decreases strictly monotone in time to a minimizer with
$\mathcal{O}(1/t)$, and in the case of measurement noise or sampling bias the
optimum is achieved up to a multiplicative or additive constant. This
convergence is preserved on discretization of the parameter space, and the
minimizers on increasingly fine discretizations converge to the optimum on the
full parameter space.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02683" title="Abstract">arXiv:2312.02683</a> (cross-list from eess.AS) [<a href="/pdf/2312.02683" title="Download PDF">pdf</a>, <a href="/format/2312.02683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-Based Speech Enhancement in Matched and Mismatched Conditions  Using a Heun-Based Sampler
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gonzalez%2C+P">Philippe Gonzalez</a>, 
<a href="/search/eess?searchtype=author&query=Tan%2C+Z">Zheng-Hua Tan</a>, 
<a href="/search/eess?searchtype=author&query=%C3%98stergaard%2C+J">Jan &#xd8;stergaard</a>, 
<a href="/search/eess?searchtype=author&query=Jensen%2C+J">Jesper Jensen</a>, 
<a href="/search/eess?searchtype=author&query=Alstr%C3%B8m%2C+T+S">Tommy Sonne Alstr&#xf8;m</a>, 
<a href="/search/eess?searchtype=author&query=May%2C+T">Tobias May</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">Diffusion models are a new class of generative models that have recently been
applied to speech enhancement successfully. Previous works have demonstrated
their superior performance in mismatched conditions compared to state-of-the
art discriminative models. However, this was investigated with a single
database for training and another one for testing, which makes the results
highly dependent on the particular databases. Moreover, recent developments
from the image generation literature remain largely unexplored for speech
enhancement. These include several design aspects of diffusion models, such as
the noise schedule or the reverse sampler. In this work, we systematically
assess the generalization performance of a diffusion-based speech enhancement
model by using multiple speech, noise and binaural room impulse response (BRIR)
databases to simulate mismatched acoustic conditions. We also experiment with a
noise schedule and a sampler that have not been applied to speech enhancement
before. We show that the proposed system substantially benefits from using
multiple databases for training, and achieves superior performance compared to
state-of-the-art discriminative models in both matched and mismatched
conditions. We also show that a Heun-based sampler achieves superior
performance at a smaller computational cost compared to a sampler commonly used
for speech enhancement.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02691" title="Abstract">arXiv:2312.02691</a> (cross-list from math.CO) [<a href="/pdf/2312.02691" title="Download PDF">pdf</a>, <a href="/ps/2312.02691" title="Download PostScript">ps</a>, <a href="/format/2312.02691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge coloring of products of signed graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Janczewski%2C+R">Robert Janczewski</a>, 
<a href="/search/math?searchtype=author&query=Turowski%2C+K">Krzysztof Turowski</a>, 
<a href="/search/math?searchtype=author&query=Wr%C3%B3blewski%2C+B">Bart&#x142;omiej Wr&#xf3;blewski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">In 2020, Behr defined the problem of edge coloring of signed graphs and
showed that every signed graph $(G, \sigma)$ can be colored using exactly
$\Delta(G)$ or $\Delta(G) + 1$ colors, where $\Delta(G)$ is the maximum degree
in graph $G$.
<br />In this paper, we focus on products of signed graphs. We recall the
definitions of the Cartesian, tensor, strong, and corona products of signed
graphs and prove results for them. In particular, we show that $(1)$ the
Cartesian product of $\Delta$-edge-colorable signed graphs is
$\Delta$-edge-colorable, $(2)$ the tensor product of a $\Delta$-edge-colorable
signed graph and a signed tree requires only $\Delta$ colors and $(3)$ the
corona product of almost any two signed graphs is $\Delta$-edge-colorable. We
also prove some results related to the coloring of products of signed paths and
cycles.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02753" title="Abstract">arXiv:2312.02753</a> (cross-list from eess.IV) [<a href="/pdf/2312.02753" title="Download PDF">pdf</a>, <a href="/format/2312.02753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> C3: High-performance and low-complexity neural compression from a single  image or video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kim%2C+H">Hyunjik Kim</a>, 
<a href="/search/eess?searchtype=author&query=Bauer%2C+M">Matthias Bauer</a>, 
<a href="/search/eess?searchtype=author&query=Theis%2C+L">Lucas Theis</a>, 
<a href="/search/eess?searchtype=author&query=Schwarz%2C+J+R">Jonathan Richard Schwarz</a>, 
<a href="/search/eess?searchtype=author&query=Dupont%2C+E">Emilien Dupont</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Most neural compression models are trained on large datasets of images or
videos in order to generalize to unseen data. Such generalization typically
requires large and expressive architectures with a high decoding complexity.
Here we introduce C3, a neural compression method with strong rate-distortion
(RD) performance that instead overfits a small model to each image or video
separately. The resulting decoding complexity of C3 can be an order of
magnitude lower than neural baselines with similar RD performance. C3 builds on
COOL-CHIC (Ladune et al.) and makes several simple and effective improvements
for images. We further develop new methodology to apply C3 to videos. On the
CLIC2020 image benchmark, we match the RD performance of VTM, the reference
implementation of the H.266 codec, with less than 3k MACs/pixel for decoding.
On the UVG video benchmark, we match the RD performance of the Video
Compression Transformer (Mentzer et al.), a well-established neural video
codec, with less than 5k MACs/pixel for decoding.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02762" title="Abstract">arXiv:2312.02762</a> (cross-list from eess.IV) [<a href="/pdf/2312.02762" title="Download PDF">pdf</a>, <a href="/format/2312.02762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Cortical Anomaly through Masked Encoding for Unsupervised  Heterogeneity Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+H">Hao-Chun Yang</a>, 
<a href="/search/eess?searchtype=author&query=Andreassen%2C+O">Ole Andreassen</a>, 
<a href="/search/eess?searchtype=author&query=Westlye%2C+L+T">Lars Tjelta Westlye</a>, 
<a href="/search/eess?searchtype=author&query=Marquand%2C+A+F">Andre F. Marquand</a>, 
<a href="/search/eess?searchtype=author&query=Beckmann%2C+C+F">Christian F. Beckmann</a>, 
<a href="/search/eess?searchtype=author&query=Wolfers%2C+T">Thomas Wolfers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The detection of heterogeneous mental disorders based on brain readouts
remains challenging due to the complexity of symptoms and the absence of
reliable biomarkers. This paper introduces CAM (Cortical Anomaly Detection
through Masked Image Modeling), a novel self-supervised framework designed for
the unsupervised detection of complex brain disorders using cortical surface
features. We employ this framework for the detection of individuals on the
psychotic spectrum and demonstrate its capabilities compared to state-ofthe-art
methods, achieving an AUC of 0.696 for Schizoaffective and 0.769 for
Schizophreniform, without the need for any labels. Furthermore, the analysis of
atypical cortical regions includes Pars Triangularis and several frontal areas,
often implicated in schizophrenia, provide further confidence in our approach.
Altogether, we demonstrate a scalable approach for anomaly detection of complex
brain disorders based on cortical abnormalities.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02786" title="Abstract">arXiv:2312.02786</a> (cross-list from physics.ao-ph) [<a href="/pdf/2312.02786" title="Download PDF">pdf</a>, <a href="/ps/2312.02786" title="Download PostScript">ps</a>, <a href="/format/2312.02786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning Driven Sensitivity Analysis of E3SM Land Model  Parameters for Wetland Methane Emissions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Chinta%2C+S">Sandeep Chinta</a>, 
<a href="/search/physics?searchtype=author&query=Gao%2C+X">Xiang Gao</a>, 
<a href="/search/physics?searchtype=author&query=Zhu%2C+Q">Qing Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 9 figures and 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">Methane (CH4) is the second most critical greenhouse gas after carbon
dioxide, contributing to 16-25% of the observed atmospheric warming. Wetlands
are the primary natural source of methane emissions globally. However, wetland
methane emission estimates from biogeochemistry models contain considerable
uncertainty. One of the main sources of this uncertainty arises from the
numerous uncertain model parameters within various physical, biological, and
chemical processes that influence methane production, oxidation, and transport.
Sensitivity Analysis (SA) can help identify critical parameters for methane
emission and achieve reduced biases and uncertainties in future projections.
This study performs SA for 19 selected parameters responsible for critical
biogeochemical processes in the methane module of the Energy Exascale Earth
System Model (E3SM) land model (ELM). The impact of these parameters on various
CH4 fluxes is examined at 14 FLUXNET- CH4 sites with diverse vegetation types.
Given the extensive number of model simulations needed for global
variance-based SA, we employ a machine learning (ML) algorithm to emulate the
complex behavior of ELM methane biogeochemistry. ML enables the computational
time to be shortened significantly from 6 CPU hours to 0.72 milliseconds,
achieving reduced computational costs. We found that parameters linked to CH4
production and diffusion generally present the highest sensitivities despite
apparent seasonal variation. Comparing simulated emissions from perturbed
parameter sets against FLUXNET-CH4 observations revealed that better
performances can be achieved at each site compared to the default parameter
values. This presents a scope for further improving simulated emissions using
parameter calibration with advanced optimization techniques like Bayesian
optimization.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02796" title="Abstract">arXiv:2312.02796</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2312.02796" title="Download PDF">pdf</a>, <a href="/format/2312.02796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Materials Expert-Artificial Intelligence for Materials Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Liu%2C+Y">Yanjun Liu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Jovanovic%2C+M">Milena Jovanovic</a>, 
<a href="/search/cond-mat?searchtype=author&query=Mallayya%2C+K">Krishnanand Mallayya</a>, 
<a href="/search/cond-mat?searchtype=author&query=Maddox%2C+W+J">Wesley J. Maddox</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wilson%2C+A+G">Andrew Gordon Wilson</a>, 
<a href="/search/cond-mat?searchtype=author&query=Klemenz%2C+S">Sebastian Klemenz</a>, 
<a href="/search/cond-mat?searchtype=author&query=Schoop%2C+L+M">Leslie M. Schoop</a>, 
<a href="/search/cond-mat?searchtype=author&query=Kim%2C+E">Eun-Ah Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages main text, 4 figs, 8 pages Supplementary material
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Strongly Correlated Electrons (cond-mat.str-el); Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">The advent of material databases provides an unprecedented opportunity to
uncover predictive descriptors for emergent material properties from vast data
space. However, common reliance on high-throughput ab initio data necessarily
inherits limitations of such data: mismatch with experiments. On the other
hand, experimental decisions are often guided by an expert's intuition honed
from experiences that are rarely articulated. We propose using machine learning
to "bottle" such operational intuition into quantifiable descriptors using
expertly curated measurement-based data. We introduce "Materials
Expert-Artificial Intelligence" (ME-AI) to encapsulate and articulate this
human intuition. As a first step towards such a program, we focus on the
topological semimetal (TSM) among square-net materials as the property inspired
by the expert-identified descriptor based on structural information: the
tolerance factor. We start by curating a dataset encompassing 12 primary
features of 879 square-net materials, using experimental data whenever
possible. We then use Dirichlet-based Gaussian process regression using a
specialized kernel to reveal composite descriptors for square-net topological
semimetals. The ME-AI learned descriptors independently reproduce expert
intuition and expand upon it. Specifically, new descriptors point to
hypervalency as a critical chemical feature predicting TSM within square-net
compounds. Our success with a carefully defined problem points to the "machine
bottling human insight" approach as promising for machine learning-aided
material discovery.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02828" title="Abstract">arXiv:2312.02828</a> (cross-list from stat.ML) [<a href="/pdf/2312.02828" title="Download PDF">pdf</a>, <a href="/ps/2312.02828" title="Download PostScript">ps</a>, <a href="/format/2312.02828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence Rates for Stochastic Approximation: Biased Noise with  Unbounded Variance, and Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Karandikar%2C+R+L">Rajeeva L. Karandikar</a>, 
<a href="/search/stat?searchtype=author&query=Vidyasagar%2C+M">M. Vidyasagar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Probability (math.PR)

</div>
<p class="mathjax">The Stochastic Approximation (SA) algorithm introduced by Robbins and Monro
in 1951 has been a standard method for solving equations of the form
$\mathbf{f}({\boldsymbol {\theta}}) = \mathbf{0}$, when only noisy measurements
of $\mathbf{f}(\cdot)$ are available. If $\mathbf{f}({\boldsymbol {\theta}}) =
\nabla J({\boldsymbol {\theta}})$ for some function $J(\cdot)$, then SA can
also be used to find a stationary point of $J(\cdot)$. In much of the
literature, it is assumed that the error term ${\boldsymbol {xi}}_{t+1}$ has
zero conditional mean, and that its conditional variance is bounded as a
function of $t$ (though not necessarily with respect to ${\boldsymbol
{\theta}}_t$). Also, for the most part, the emphasis has been on
``synchronous'' SA, whereby, at each time $t$, \textit{every} component of
${\boldsymbol {\theta}}_t$ is updated. Over the years, SA has been applied to a
variety of areas, out of which two are the focus in this paper: Convex and
nonconvex optimization, and Reinforcement Learning (RL). As it turns out, in
these applications, the above-mentioned assumptions do not always hold. In
zero-order methods, the error neither has zero mean nor bounded conditional
variance. In the present paper, we extend SA theory to encompass errors with
nonzero conditional mean and/or unbounded conditional variance, and also
asynchronous SA. In addition, we derive estimates for the rate of convergence
of the algorithm. Then we apply the new results to problems in nonconvex
optimization, and to Markovian SA, a recently emerging area in RL. We prove
that SA converges in these situations, and compute the ``optimal step size
sequences'' to maximize the estimated rate of convergence.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02849" title="Abstract">arXiv:2312.02849</a> (cross-list from math.ST) [<a href="/pdf/2312.02849" title="Download PDF">pdf</a>, <a href="/ps/2312.02849" title="Download PostScript">ps</a>, <a href="/format/2312.02849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithms for mean-field variational inference via polyhedral  optimization in the Wasserstein space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jiang%2C+Y">Yiheng Jiang</a>, 
<a href="/search/math?searchtype=author&query=Chewi%2C+S">Sinho Chewi</a>, 
<a href="/search/math?searchtype=author&query=Pooladian%2C+A">Aram-Alexandre Pooladian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">We develop a theory of finite-dimensional polyhedral subsets over the
Wasserstein space and optimization of functionals over them via first-order
methods. Our main application is to the problem of mean-field variational
inference, which seeks to approximate a distribution $\pi$ over $\mathbb{R}^d$
by a product measure $\pi^\star$. When $\pi$ is strongly log-concave and
log-smooth, we provide (1) approximation rates certifying that $\pi^\star$ is
close to the minimizer $\pi^\star_\diamond$ of the KL divergence over a
\emph{polyhedral} set $\mathcal{P}_\diamond$, and (2) an algorithm for
minimizing $\text{KL}(\cdot\|\pi)$ over $\mathcal{P}_\diamond$ with accelerated
complexity $O(\sqrt \kappa \log(\kappa d/\varepsilon^2))$, where $\kappa$ is
the condition number of $\pi$.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02850" title="Abstract">arXiv:2312.02850</a> (cross-list from stat.ML) [<a href="/pdf/2312.02850" title="Download PDF">pdf</a>, <a href="/ps/2312.02850" title="Download PostScript">ps</a>, <a href="/format/2312.02850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Kernel-Based Neural Network Test for High-dimensional Sequencing Data  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hou%2C+T">Tingting Hou</a>, 
<a href="/search/stat?searchtype=author&query=Jiang%2C+C">Chang Jiang</a>, 
<a href="/search/stat?searchtype=author&query=Lu%2C+Q">Qing Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 5 figures and 3 tabels
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">The recent development of artificial intelligence (AI) technology, especially
the advance of deep neural network (DNN) technology, has revolutionized many
fields. While DNN plays a central role in modern AI technology, it has been
rarely used in sequencing data analysis due to challenges brought by
high-dimensional sequencing data (e.g., overfitting). Moreover, due to the
complexity of neural networks and their unknown limiting distributions,
building association tests on neural networks for genetic association analysis
remains a great challenge. To address these challenges and fill the important
gap of using AI in high-dimensional sequencing data analysis, we introduce a
new kernel-based neural network (KNN) test for complex association analysis of
sequencing data. The test is built on our previously developed KNN framework,
which uses random effects to model the overall effects of high-dimensional
genetic data and adopts kernel-based neural network structures to model complex
genotype-phenotype relationships. Based on KNN, a Wald-type test is then
introduced to evaluate the joint association of high-dimensional genetic data
with a disease phenotype of interest, considering non-linear and non-additive
effects (e.g., interaction effects). Through simulations, we demonstrated that
our proposed method attained higher power compared to the sequence kernel
association test (SKAT), especially in the presence of non-linear and
interaction effects. Finally, we apply the methods to the whole genome
sequencing (WGS) dataset from the Alzheimer's Disease Neuroimaging Initiative
(ADNI) study, investigating new genes associated with the hippocampal volume
change over time.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02908" title="Abstract">arXiv:2312.02908</a> (cross-list from astro-ph.GA) [<a href="/pdf/2312.02908" title="Download PDF">pdf</a>, <a href="/format/2312.02908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning Segmentation of Spiral Arms and Bars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Walmsley%2C+M">Mike Walmsley</a>, 
<a href="/search/astro-ph?searchtype=author&query=Spindler%2C+A">Ashley Spindler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Machine Learning and the Physical Sciences Workshop, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Astrophysics of Galaxies (astro-ph.GA)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We present the first deep learning model for segmenting galactic spiral arms
and bars. In a blinded assessment by expert astronomers, our predicted spiral
arm masks are preferred over both current automated methods (99% of
evaluations) and our original volunteer labels (79% of evaluations). Experts
rated our spiral arm masks as `mostly good' to `perfect' in 89% of evaluations.
Bar lengths trivially derived from our predicted bar masks are in excellent
agreement with a dedicated crowdsourcing project. The pixelwise precision of
our masks, previously impossible at scale, will underpin new research into how
spiral arms and bars evolve.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02910" title="Abstract">arXiv:2312.02910</a> (cross-list from astro-ph.GA) [<a href="/pdf/2312.02910" title="Download PDF">pdf</a>, <a href="/format/2312.02910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rare Galaxy Classes Identified In Foundation Model Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Walmsley%2C+M">Mike Walmsley</a>, 
<a href="/search/astro-ph?searchtype=author&query=Scaife%2C+A+M+M">Anna M.M. Scaife</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Machine Learning and the Physical Sciences Workshop, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Astrophysics of Galaxies (astro-ph.GA)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We identify rare and visually distinctive galaxy populations by searching for
structure within the learned representations of pretrained models. We show that
these representations arrange galaxies by appearance in patterns beyond those
needed to predict the pretraining labels. We design a clustering approach to
isolate specific local patterns, revealing groups of galaxies with rare and
scientifically-interesting morphologies.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02941" title="Abstract">arXiv:2312.02941</a> (cross-list from eess.IV) [<a href="/pdf/2312.02941" title="Download PDF">pdf</a>, <a href="/format/2312.02941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast CT anatomic localization algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Oved%2C+A">Amit Oved</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Automatically determining the position of every slice in a CT scan is a basic
yet powerful capability allowing fast retrieval of region of interest for
visual inspection and automated analysis. Unlike conventional localization
approaches which work at the slice level, we directly localize only a fraction
of the slices and and then fit a linear model which maps slice index to its
estimated axial anatomical position based on those slices. The model is then
used to assign axial position to every slices of the scan. This approach proves
to be both computationally efficient, with a typical processing time of less
than a second per scan (regardless of its size), accurate, with a typical
median localization error of 1 cm, and robust to different noise sources,
imaging protocols, metal induced artifacts, anatomical deformations etc.
Another key element of our approach is the introduction of a mapping confidence
score. This score acts as a fail safe mechanism which allows a rejection of
unreliable localization results in rare cases of anomalous scans. Our algorithm
sets new State Of The Art results in terms of localization accuracy. It also
offers a decrease of two orders of magnitude in processing time with respect to
all published processing times. It was designed to be invariant to various scan
resolutions, scan protocols, patient orientations, strong artifacts and various
deformations and abnormalities. Additionally, our algorithm is the first one to
the best of our knowledge which supports the entire body from head to feet and
is not confined to specific anatomical region. This algorithm was tested on
thousands of scans and proves to be very reliable and useful as a preprocessing
stage for many applications.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02956" title="Abstract">arXiv:2312.02956</a> (cross-list from eess.IV) [<a href="/pdf/2312.02956" title="Download PDF">pdf</a>, <a href="/format/2312.02956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Choroidalyzer: An open-source, end-to-end pipeline for choroidal  analysis in optical coherence tomography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Engelmann%2C+J">Justin Engelmann</a>, 
<a href="/search/eess?searchtype=author&query=Burke%2C+J">Jamie Burke</a>, 
<a href="/search/eess?searchtype=author&query=Hamid%2C+C">Charlene Hamid</a>, 
<a href="/search/eess?searchtype=author&query=Reid-Schachter%2C+M">Megan Reid-Schachter</a>, 
<a href="/search/eess?searchtype=author&query=Pugh%2C+D">Dan Pugh</a>, 
<a href="/search/eess?searchtype=author&query=Dhaun%2C+N">Neeraj Dhaun</a>, 
<a href="/search/eess?searchtype=author&query=Moukaddem%2C+D">Diana Moukaddem</a>, 
<a href="/search/eess?searchtype=author&query=Gray%2C+L">Lyle Gray</a>, 
<a href="/search/eess?searchtype=author&query=Strang%2C+N">Niall Strang</a>, 
<a href="/search/eess?searchtype=author&query=McGraw%2C+P">Paul McGraw</a>, 
<a href="/search/eess?searchtype=author&query=Storkey%2C+A">Amos Storkey</a>, 
<a href="/search/eess?searchtype=author&query=Steptoe%2C+P+J">Paul J. Steptoe</a>, 
<a href="/search/eess?searchtype=author&query=King%2C+S">Stuart King</a>, 
<a href="/search/eess?searchtype=author&query=MacGillivray%2C+T">Tom MacGillivray</a>, 
<a href="/search/eess?searchtype=author&query=Bernabeu%2C+M+O">Miguel O. Bernabeu</a>, 
<a href="/search/eess?searchtype=author&query=MacCormick%2C+I+J+C">Ian J.C. MacCormick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Purpose: To develop Choroidalyzer, an open-source, end-to-end pipeline for
segmenting the choroid region, vessels, and fovea, and deriving choroidal
thickness, area, and vascular index.
<br />Methods: We used 5,600 OCT B-scans (233 subjects, 6 systemic disease cohorts,
3 device types, 2 manufacturers). To generate region and vessel ground-truths,
we used state-of-the-art automatic methods following manual correction of
inaccurate segmentations, with foveal positions manually annotated. We trained
a U-Net deep-learning model to detect the region, vessels, and fovea to
calculate choroid thickness, area, and vascular index in a fovea-centred region
of interest. We analysed segmentation agreement (AUC, Dice) and choroid metrics
agreement (Pearson, Spearman, mean absolute error (MAE)) in internal and
external test sets. We compared Choroidalyzer to two manual graders on a small
subset of external test images and examined cases of high error.
<br />Results: Choroidalyzer took 0.299 seconds per image on a standard laptop and
achieved excellent region (Dice: internal 0.9789, external 0.9749), very good
vessel segmentation performance (Dice: internal 0.8817, external 0.8703) and
excellent fovea location prediction (MAE: internal 3.9 pixels, external 3.4
pixels). For thickness, area, and vascular index, Pearson correlations were
0.9754, 0.9815, and 0.8285 (internal) / 0.9831, 0.9779, 0.7948 (external),
respectively (all p&lt;0.0001). Choroidalyzer's agreement with graders was
comparable to the inter-grader agreement across all metrics.
<br />Conclusions: Choroidalyzer is an open-source, end-to-end pipeline that
accurately segments the choroid and reliably extracts thickness, area, and
vascular index. Especially choroidal vessel segmentation is a difficult and
subjective task, and fully-automatic methods like Choroidalyzer could provide
objectivity and standardisation.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02959" title="Abstract">arXiv:2312.02959</a> (cross-list from stat.ML) [<a href="/pdf/2312.02959" title="Download PDF">pdf</a>, <a href="/format/2312.02959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting algorithmic bias in medical AI-models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Smith%2C+J">Jeffrey Smith</a>, 
<a href="/search/stat?searchtype=author&query=Holder%2C+A">Andre Holder</a>, 
<a href="/search/stat?searchtype=author&query=Kamaleswaran%2C+R">Rishikesan Kamaleswaran</a>, 
<a href="/search/stat?searchtype=author&query=Xie%2C+Y">Yao Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">With the growing prevalence of machine learning and artificial
intelligence-based medical decision support systems, it is equally important to
ensure that these systems provide patient outcomes in a fair and equitable
fashion. This paper presents an innovative framework for detecting areas of
algorithmic bias in medical-AI decision support systems. Our approach
efficiently identifies potential biases in medical-AI models, specifically in
the context of sepsis prediction, by employing the Classification and
Regression Trees (CART) algorithm. We verify our methodology by conducting a
series of synthetic data experiments, showcasing its ability to estimate areas
of bias in controlled settings precisely. The effectiveness of the concept is
further validated by experiments using electronic medical records from Grady
Memorial Hospital in Atlanta, Georgia. These tests demonstrate the practical
implementation of our strategy in a clinical environment, where it can function
as a vital instrument for guaranteeing fairness and equity in AI-based medical
decisions.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Wed,  6 Dec 23</h3>
<dl>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.01347" title="Abstract">arXiv:2107.01347</a> (replaced) [<a href="/e-print/2107.01347" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Traffic Signal Control with Communicative Deep Reinforcement Learning  Agents: a Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fazzini%2C+P">Paolo Fazzini</a>, 
<a href="/search/cs?searchtype=author&query=Wheeler%2C+I">Isaac Wheeler</a>, 
<a href="/search/cs?searchtype=author&query=Petracchini%2C+F">Francesco Petracchini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Obsolete version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.00955" title="Abstract">arXiv:2112.00955</a> (replaced) [<a href="/pdf/2112.00955" title="Download PDF">pdf</a>, <a href="/format/2112.00955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Source Free Unsupervised Graph Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+H">Haitao Mao</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Lun Du</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yujia Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Q">Qiang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zelin Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shi Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.07908" title="Abstract">arXiv:2201.07908</a> (replaced) [<a href="/pdf/2201.07908" title="Download PDF">pdf</a>, <a href="/ps/2201.07908" title="Download PostScript">ps</a>, <a href="/format/2201.07908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Markov decision processes with observation costs: framework and  computation with a penalty scheme
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Reisinger%2C+C">Christoph Reisinger</a>, 
<a href="/search/math?searchtype=author&query=Tam%2C+J">Jonathan Tam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 8 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.06467" title="Abstract">arXiv:2202.06467</a> (replaced) [<a href="/pdf/2202.06467" title="Download PDF">pdf</a>, <a href="/format/2202.06467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuroMixGDP: A Neural Collapse-Inspired Random Mixup for Private Data  Release
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Donghao Li</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuan Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.03181" title="Abstract">arXiv:2204.03181</a> (replaced) [<a href="/pdf/2204.03181" title="Download PDF">pdf</a>, <a href="/format/2204.03181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reaching Consensus in the Byzantine Empire: A Comprehensive Review of  BFT Consensus Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gengrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+F">Fei Pan</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yunhao Mao</a>, 
<a href="/search/cs?searchtype=author&query=Tijanic%2C+S">Sofia Tijanic</a>, 
<a href="/search/cs?searchtype=author&query=Dang%27ana%2C+M">Michael Dang&#x27;ana</a>, 
<a href="/search/cs?searchtype=author&query=Motepalli%2C+S">Shashank Motepalli</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiquan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jacobsen%2C+H">Hans-Arno Jacobsen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.08057" title="Abstract">arXiv:2204.08057</a> (replaced) [<a href="/pdf/2204.08057" title="Download PDF">pdf</a>, <a href="/format/2204.08057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast solution of Sylvester-structured systems for spatial source  separation of the Cosmic Microwave Background
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Soodhalter%2C+K+M">Kirk M. Soodhalter</a>, 
<a href="/search/math?searchtype=author&query=Wilson%2C+S">Simon Wilson</a>, 
<a href="/search/math?searchtype=author&query=Pham%2C+D">Dung Pham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> resubmitted for publication/title changes from v2
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM)

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.11505" title="Abstract">arXiv:2204.11505</a> (replaced) [<a href="/pdf/2204.11505" title="Download PDF">pdf</a>, <a href="/format/2204.11505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Offline and online energy-efficient monitoring of scattered uncertain  logs using a bounding model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ghosh%2C+B">Bineet Ghosh</a>, 
<a href="/search/eess?searchtype=author&query=Andr%C3%A9%2C+%C3%89">&#xc9;tienne Andr&#xe9;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the author version of the manuscript published in the proceedings of FORTE 2022 AND ALSO THE EXTENDED VERSION submitted to LMCS. This work is partially supported by the ANR-NRF research program ProMiS (ANR-19-CE25-0015 / 2019 ANR NRF 0092) and ANR BisoUS (ANR-22-CE48-0012), and the National Science Foundation (NSF) of the United States of America under grant number 2038960
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 42nd International Conference on Formal
  Techniques for Distributed Objects, Components, and Systems (FORTE 2022),
  LNCS 13273, pages 67-87, Springer, 2022 AND AWAITING EVALUATION AT LMCS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.03408" title="Abstract">arXiv:2205.03408</a> (replaced) [<a href="/pdf/2205.03408" title="Download PDF">pdf</a>, <a href="/ps/2205.03408" title="Download PostScript">ps</a>, <a href="/format/2205.03408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HRCTCov19 -- A High-Resolution Chest CT Scan Image Dataset for COVID-19  Diagnosis and Differentiation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Abedi%2C+I">Iraj Abedi</a>, 
<a href="/search/eess?searchtype=author&query=Vali%2C+M">Mahsa Vali</a>, 
<a href="/search/eess?searchtype=author&query=Otroshi%2C+B">Bentolhoda Otroshi</a>, 
<a href="/search/eess?searchtype=author&query=Zamanian%2C+M">Maryam Zamanian</a>, 
<a href="/search/eess?searchtype=author&query=Bolhasani%2C+H">Hamidreza Bolhasani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures and 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.14784" title="Abstract">arXiv:2205.14784</a> (replaced) [<a href="/pdf/2205.14784" title="Download PDF">pdf</a>, <a href="/format/2205.14784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transient Behavior of Gossip Opinion Dynamics with Community Structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Xing%2C+Y">Yu Xing</a>, 
<a href="/search/physics?searchtype=author&query=Johansson%2C+K+H">Karl H. Johansson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.02016" title="Abstract">arXiv:2207.02016</a> (replaced) [<a href="/pdf/2207.02016" title="Download PDF">pdf</a>, <a href="/format/2207.02016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Reinforcement Learning in Continuous Control Tasks with  Uncertainty Set Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Boedecker%2C+J">Joschka Boedecker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CoRL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.06033" title="Abstract">arXiv:2208.06033</a> (replaced) [<a href="/pdf/2208.06033" title="Download PDF">pdf</a>, <a href="/format/2208.06033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Soft Actor-Critic: A Directed Acyclic Strategy Graph Based Deep  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Parasuraman%2C+R">Ramviyas Parasuraman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.06561" title="Abstract">arXiv:2208.06561</a> (replaced) [<a href="/pdf/2208.06561" title="Download PDF">pdf</a>, <a href="/format/2208.06561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Point with Image: A Simple and Efficient Method for UAV  Self-Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+M">Ming Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+E">Enhui Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhenhua Feng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiahao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wankou Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.07753" title="Abstract">arXiv:2208.07753</a> (replaced) [<a href="/pdf/2208.07753" title="Download PDF">pdf</a>, <a href="/format/2208.07753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Policy Resonance Approach to Solve the Problem of Responsibility  Diffusion in Multiagent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+Q">Qingxu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+T">Tenghai Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jianqiang Yi</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+Z">Zhiqiang Pu</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+X">Xiaolin Ai</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Wanmai Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.00383" title="Abstract">arXiv:2209.00383</a> (replaced) [<a href="/pdf/2209.00383" title="Download PDF">pdf</a>, <a href="/format/2209.00383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TokenCut: Segmenting Objects in Images and Videos with Self-supervised  Transformer and Normalized Cut
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yangtao Wang</a> (M-PSI), 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xi Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuan Yuan</a> (MIT CSAIL), 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yuming Du</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Maomao Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S+X">Shell Xu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Crowley%2C+J+L">James L Crowley</a> (M-PSI), 
<a href="/search/cs?searchtype=author&query=Vaufreydaz%2C+D">Dominique Vaufreydaz</a> (M-PSI)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2202.11539">arXiv:2202.11539</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.09981" title="Abstract">arXiv:2209.09981</a> (replaced) [<a href="/pdf/2209.09981" title="Download PDF">pdf</a>, <a href="/format/2209.09981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparsity promoting reconstructions via hierarchical prior models in  diffuse optical tomography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Manninen%2C+A">Anssi Manninen</a>, 
<a href="/search/math?searchtype=author&query=Mozumder%2C+M">Meghdoot Mozumder</a>, 
<a href="/search/math?searchtype=author&query=Tarvainen%2C+T">Tanja Tarvainen</a>, 
<a href="/search/math?searchtype=author&query=Hauptmann%2C+A">Andreas Hauptmann</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Inverse Problems and Imaging, 2024, 18(1): 113-137
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.12003" title="Abstract">arXiv:2209.12003</a> (replaced) [<a href="/pdf/2209.12003" title="Download PDF">pdf</a>, <a href="/ps/2209.12003" title="Download PostScript">ps</a>, <a href="/format/2209.12003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mutual Contact Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoepman%2C+J">Jaap-Henk Hoepman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages (including appendix)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.14823" title="Abstract">arXiv:2209.14823</a> (replaced) [<a href="/pdf/2209.14823" title="Download PDF">pdf</a>, <a href="/ps/2209.14823" title="Download PostScript">ps</a>, <a href="/format/2209.14823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physical Human-Robot Interaction Control of an Upper Limb Exoskeleton  with a Decentralized Neuro-Adaptive Control Scheme
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hejrati%2C+M">Mahdi Hejrati</a>, 
<a href="/search/cs?searchtype=author&query=Mattila%2C+J">Jouni Mattila</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been accepted for publication by the IEEE Transactions on Control Systems Technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.00685" title="Abstract">arXiv:2210.00685</a> (replaced) [<a href="/pdf/2210.00685" title="Download PDF">pdf</a>, <a href="/ps/2210.00685" title="Download PostScript">ps</a>, <a href="/format/2210.00685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two new classes of exponential Runge-Kutta integrators for efficiently  solving stiff systems or highly oscillatory problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/math?searchtype=author&query=Hu%2C+X">Xianfa Hu</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+X">Xinyuan Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.08387" title="Abstract">arXiv:2210.08387</a> (replaced) [<a href="/pdf/2210.08387" title="Download PDF">pdf</a>, <a href="/format/2210.08387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Varying Semidefinite Programming: Path Following a Burer-Monteiro  Factorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bellon%2C+A">Antonio Bellon</a>, 
<a href="/search/math?searchtype=author&query=Dressler%2C+M">Mareike Dressler</a>, 
<a href="/search/math?searchtype=author&query=Kungurtsev%2C+V">Vyacheslav Kungurtsev</a>, 
<a href="/search/math?searchtype=author&query=Marecek%2C+J">Jakub Marecek</a>, 
<a href="/search/math?searchtype=author&query=Uschmajew%2C+A">Andr&#xe9; Uschmajew</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.09701" title="Abstract">arXiv:2210.09701</a> (replaced) [<a href="/pdf/2210.09701" title="Download PDF">pdf</a>, <a href="/ps/2210.09701" title="Download PostScript">ps</a>, <a href="/format/2210.09701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A stable local commuting projector and optimal $hp$ approximation  estimates in ${\boldsymbol H}(\mathrm{curl})$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chaumont-Frelet%2C+T">Th&#xe9;ophile Chaumont-Frelet</a>, 
<a href="/search/math?searchtype=author&query=Vohral%C3%ADk%2C+M">Martin Vohral&#xed;k</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01751" title="Abstract">arXiv:2211.01751</a> (replaced) [<a href="/pdf/2211.01751" title="Download PDF">pdf</a>, <a href="/format/2211.01751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterative autoregression: a novel trick to improve your low-latency  speech enhancement model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Andreev%2C+P">Pavel Andreev</a>, 
<a href="/search/cs?searchtype=author&query=Babaev%2C+N">Nicholas Babaev</a>, 
<a href="/search/cs?searchtype=author&query=Saginbaev%2C+A">Azat Saginbaev</a>, 
<a href="/search/cs?searchtype=author&query=Shchekotov%2C+I">Ivan Shchekotov</a>, 
<a href="/search/cs?searchtype=author&query=Alanov%2C+A">Aibek Alanov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Interspeech 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.02900" title="Abstract">arXiv:2211.02900</a> (replaced) [<a href="/pdf/2211.02900" title="Download PDF">pdf</a>, <a href="/format/2211.02900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grassmann Manifold Flows for Stable Shape Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yataka%2C+R">Ryoma Yataka</a>, 
<a href="/search/cs?searchtype=author&query=Hirashima%2C+K">Kazuki Hirashima</a>, 
<a href="/search/cs?searchtype=author&query=Shiraishi%2C+M">Masashi Shiraishi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Differential Geometry (math.DG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08739" title="Abstract">arXiv:2211.08739</a> (replaced) [<a href="/pdf/2211.08739" title="Download PDF">pdf</a>, <a href="/ps/2211.08739" title="Download PostScript">ps</a>, <a href="/format/2211.08739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A higher order approximation method for jump-diffusion SDEs with  discontinuous drift coefficient
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Przyby%C5%82owicz%2C+P">Pawe&#x142; Przyby&#x142;owicz</a>, 
<a href="/search/math?searchtype=author&query=Schwarz%2C+V">Verena Schwarz</a>, 
<a href="/search/math?searchtype=author&query=Sz%C3%B6lgyenyi%2C+M">Michaela Sz&#xf6;lgyenyi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.09618" title="Abstract">arXiv:2211.09618</a> (replaced) [<a href="/pdf/2211.09618" title="Download PDF">pdf</a>, <a href="/format/2211.09618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A (simple) classical algorithm for estimating Betti numbers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Apers%2C+S">Simon Apers</a>, 
<a href="/search/cs?searchtype=author&query=Gribling%2C+S">Sander Gribling</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+S">Sayantan Sen</a>, 
<a href="/search/cs?searchtype=author&query=Szab%C3%B3%2C+D">D&#xe1;niel Szab&#xf3;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v3: final version, accepted to Quantum
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13838" title="Abstract">arXiv:2211.13838</a> (replaced) [<a href="/e-print/2211.13838" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Signed Binary Weight Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuhar%2C+S">Sachit Kuhar</a>, 
<a href="/search/cs?searchtype=author&query=Tumanov%2C+A">Alexey Tumanov</a>, 
<a href="/search/cs?searchtype=author&query=Hoffman%2C+J">Judy Hoffman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> it is being updated
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.15498" title="Abstract">arXiv:2211.15498</a> (replaced) [<a href="/pdf/2211.15498" title="Download PDF">pdf</a>, <a href="/format/2211.15498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-informed neural networks with unknown measurement noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Pilar%2C+P">Philipp Pilar</a>, 
<a href="/search/stat?searchtype=author&query=Wahlstr%C3%B6m%2C+N">Niklas Wahlstr&#xf6;m</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.16934" title="Abstract">arXiv:2211.16934</a> (replaced) [<a href="/pdf/2211.16934" title="Download PDF">pdf</a>, <a href="/format/2211.16934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VideoDubber: Machine Translation with Speech-Aware Length Control for  Video Dubbing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yihan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Junliang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bohan Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+R">Ruihua Song</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Lei He</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Menezes%2C+A">Arul Menezes</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2023 camera version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.16994" title="Abstract">arXiv:2211.16994</a> (replaced) [<a href="/pdf/2211.16994" title="Download PDF">pdf</a>, <a href="/format/2211.16994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Learning with Distributed Optimization: Does CoCoA Forget?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hellkvist%2C+M">Martin Hellkvist</a>, 
<a href="/search/stat?searchtype=author&query=%C3%96z%C3%A7elikkale%2C+A">Ay&#xe7;a &#xd6;z&#xe7;elikkale</a>, 
<a href="/search/stat?searchtype=author&query=Ahl%C3%A9n%2C+A">Anders Ahl&#xe9;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.00411" title="Abstract">arXiv:2212.00411</a> (replaced) [<a href="/pdf/2212.00411" title="Download PDF">pdf</a>, <a href="/format/2212.00411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Randomized Milstein algorithm for approximation of solutions of  jump-diffusion SDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Przyby%C5%82owicz%2C+P">Pawe&#x142; Przyby&#x142;owicz</a>, 
<a href="/search/math?searchtype=author&query=Schwarz%2C+V">Verena Schwarz</a>, 
<a href="/search/math?searchtype=author&query=Sz%C3%B6lgyenyi%2C+M">Michaela Sz&#xf6;lgyenyi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.00433" title="Abstract">arXiv:2212.00433</a> (replaced) [<a href="/pdf/2212.00433" title="Download PDF">pdf</a>, <a href="/format/2212.00433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regularization Trade-offs with Fake Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hellkvist%2C+M">Martin Hellkvist</a>, 
<a href="/search/cs?searchtype=author&query=%C3%96z%C3%A7elikkale%2C+A">Ay&#xe7;a &#xd6;z&#xe7;elikkale</a>, 
<a href="/search/cs?searchtype=author&query=Ahl%C3%A9n%2C+A">Anders Ahl&#xe9;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.06959" title="Abstract">arXiv:2212.06959</a> (replaced) [<a href="/pdf/2212.06959" title="Download PDF">pdf</a>, <a href="/ps/2212.06959" title="Download PostScript">ps</a>, <a href="/format/2212.06959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mechanics of geodesics in Information geometry and Black Hole  Thermodynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chanda%2C+S">Sumanto Chanda</a>, 
<a href="/search/cs?searchtype=author&query=Wada%2C+T">Tatsuaki Wada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages. Corrections made. New section and 2 references added. Please comment
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09917" title="Abstract">arXiv:2212.09917</a> (replaced) [<a href="/pdf/2212.09917" title="Download PDF">pdf</a>, <a href="/format/2212.09917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inverse Reinforcement Learning for Text Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+D">Deyi Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yue Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures; accepted to Findings of EMNLP 2013
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03150" title="Abstract">arXiv:2301.03150</a> (replaced) [<a href="/pdf/2301.03150" title="Download PDF">pdf</a>, <a href="/format/2301.03150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MOTOR: A Time-To-Event Foundation Model For Structured Medical Records
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Steinberg%2C+E">Ethan Steinberg</a>, 
<a href="/search/cs?searchtype=author&query=Fries%2C+J">Jason Fries</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yizhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+N">Nigam Shah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03573" title="Abstract">arXiv:2301.03573</a> (replaced) [<a href="/pdf/2301.03573" title="Download PDF">pdf</a>, <a href="/format/2301.03573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balance is Essence: Accelerating Sparse Training via Adaptive Gradient  Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+B">Bowen Lei</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dongkuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shuren He</a>, 
<a href="/search/cs?searchtype=author&query=Mallick%2C+B+K">Bani K. Mallick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03962" title="Abstract">arXiv:2301.03962</a> (replaced) [<a href="/pdf/2301.03962" title="Download PDF">pdf</a>, <a href="/format/2301.03962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Theory of Diversity in Ensemble Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wood%2C+D">Danny Wood</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+T">Tingting Mu</a>, 
<a href="/search/cs?searchtype=author&query=Webb%2C+A">Andrew Webb</a>, 
<a href="/search/cs?searchtype=author&query=Reeve%2C+H">Henry Reeve</a>, 
<a href="/search/cs?searchtype=author&query=Lujan%2C+M">Mikel Lujan</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+G">Gavin Brown</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.04295" title="Abstract">arXiv:2301.04295</a> (replaced) [<a href="/pdf/2301.04295" title="Download PDF">pdf</a>, <a href="/format/2301.04295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear Time Online Algorithms for Constructing Linear-size Suffix Trie
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hendrian%2C+D">Diptarama Hendrian</a>, 
<a href="/search/cs?searchtype=author&query=Takagi%2C+T">Takuya Takagi</a>, 
<a href="/search/cs?searchtype=author&query=Inenaga%2C+S">Shunsuke Inenaga</a>, 
<a href="/search/cs?searchtype=author&query=Goto%2C+K">Keisuke Goto</a>, 
<a href="/search/cs?searchtype=author&query=Funakoshi%2C+M">Mitsuru Funakoshi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 14 figures. arXiv admin note: text overlap with <a href="/abs/1901.10045">arXiv:1901.10045</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.05352" title="Abstract">arXiv:2301.05352</a> (replaced) [<a href="/pdf/2301.05352" title="Download PDF">pdf</a>, <a href="/ps/2301.05352" title="Download PostScript">ps</a>, <a href="/format/2301.05352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concentration in Gossip Opinion Dynamics over Random Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xing%2C+Y">Yu Xing</a>, 
<a href="/search/eess?searchtype=author&query=Johansson%2C+K+H">Karl Henrik Johansson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.06216" title="Abstract">arXiv:2301.06216</a> (replaced) [<a href="/pdf/2301.06216" title="Download PDF">pdf</a>, <a href="/format/2301.06216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modelling human logical reasoning process in dynamic environmental  stress with cognitive agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Songlin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10250" title="Abstract">arXiv:2301.10250</a> (replaced) [<a href="/pdf/2301.10250" title="Download PDF">pdf</a>, <a href="/format/2301.10250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Inverse Physics Problems with Score Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Holzschuh%2C+B+J">Benjamin J. Holzschuh</a>, 
<a href="/search/cs?searchtype=author&query=Vegetti%2C+S">Simona Vegetti</a>, 
<a href="/search/cs?searchtype=author&query=Thuerey%2C+N">Nils Thuerey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023; code available at <a href="https://github.com/tum-pbs/SMDP">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02367" title="Abstract">arXiv:2302.02367</a> (replaced) [<a href="/pdf/2302.02367" title="Download PDF">pdf</a>, <a href="/format/2302.02367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FastPillars: A Deployment-friendly Pillar-based 3D Detector
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Sifan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhi Tian</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+X">Xiangxiang Chu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiaobo Lu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chengjian Feng</a>, 
<a href="/search/cs?searchtype=author&query=Jie%2C+Z">Zequn Jie</a>, 
<a href="/search/cs?searchtype=author&query=Chiang%2C+P+Y">Patrick Yin Chiang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lin Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02858" title="Abstract">arXiv:2302.02858</a> (replaced) [<a href="/pdf/2302.02858" title="Download PDF">pdf</a>, <a href="/format/2302.02858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TR3D: Towards Real-Time Indoor 3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rukhovich%2C+D">Danila Rukhovich</a>, 
<a href="/search/cs?searchtype=author&query=Vorontsova%2C+A">Anna Vorontsova</a>, 
<a href="/search/cs?searchtype=author&query=Konushin%2C+A">Anton Konushin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06353" title="Abstract">arXiv:2302.06353</a> (replaced) [<a href="/pdf/2302.06353" title="Download PDF">pdf</a>, <a href="/format/2302.06353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contour-based Interactive Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Galeev%2C+D">Danil Galeev</a>, 
<a href="/search/cs?searchtype=author&query=Popenova%2C+P">Polina Popenova</a>, 
<a href="/search/cs?searchtype=author&query=Vorontsova%2C+A">Anna Vorontsova</a>, 
<a href="/search/cs?searchtype=author&query=Konushin%2C+A">Anton Konushin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08272" title="Abstract">arXiv:2302.08272</a> (replaced) [<a href="/pdf/2302.08272" title="Download PDF">pdf</a>, <a href="/format/2302.08272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Hidden Representations in Transfer Learning for Medical  Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Juodelyte%2C+D">Dovile Juodelyte</a>, 
<a href="/search/cs?searchtype=author&query=Jim%C3%A9nez-S%C3%A1nchez%2C+A">Amelia Jim&#xe9;nez-S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Cheplygina%2C+V">Veronika Cheplygina</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in TMLR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00438" title="Abstract">arXiv:2303.00438</a> (replaced) [<a href="/pdf/2303.00438" title="Download PDF">pdf</a>, <a href="/format/2303.00438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Framework for Neurosymbolic Robot Action Planning using Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Capitanelli%2C+A">Alessio Capitanelli</a>, 
<a href="/search/cs?searchtype=author&query=Mastrogiovanni%2C+F">Fulvio Mastrogiovanni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to journal. 28 pages, 6 figures, 2 tables. Updated according to reviewers' comments. Previous title: A Framework to Generate Neurosymbolic PDDL-compliant Planners
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01015" title="Abstract">arXiv:2303.01015</a> (replaced) [<a href="/pdf/2303.01015" title="Download PDF">pdf</a>, <a href="/format/2303.01015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward a certified greedy Loewner framework with minimal sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pradovera%2C+D">Davide Pradovera</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Adv. Comput. Math. (2023), 49(6)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02159" title="Abstract">arXiv:2303.02159</a> (replaced) [<a href="/pdf/2303.02159" title="Download PDF">pdf</a>, <a href="/ps/2303.02159" title="Download PostScript">ps</a>, <a href="/format/2303.02159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Parameter Estimation for Rational Ordinary Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bassik%2C+O">Oren Bassik</a>, 
<a href="/search/cs?searchtype=author&query=Berman%2C+Y">Yosef Berman</a>, 
<a href="/search/cs?searchtype=author&query=Go%2C+S">Soo Go</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+H">Hoon Hong</a>, 
<a href="/search/cs?searchtype=author&query=Ilmer%2C+I">Ilia Ilmer</a>, 
<a href="/search/cs?searchtype=author&query=Ovchinnikov%2C+A">Alexey Ovchinnikov</a>, 
<a href="/search/cs?searchtype=author&query=Rackauckas%2C+C">Chris Rackauckas</a>, 
<a href="/search/cs?searchtype=author&query=Soto%2C+P">Pedro Soto</a>, 
<a href="/search/cs?searchtype=author&query=Yap%2C+C">Chee Yap</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Redesigned derivative estimation and benchmarking, is based on an updated software implementation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Software (cs.MS)</span>; Symbolic Computation (cs.SC); Dynamical Systems (math.DS); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05404" title="Abstract">arXiv:2303.05404</a> (replaced) [<a href="/pdf/2303.05404" title="Download PDF">pdf</a>, <a href="/format/2303.05404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Onboard LiDAR-based Flying Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vrba%2C+M">Matou&#x161; Vrba</a>, 
<a href="/search/cs?searchtype=author&query=Walter%2C+V">Viktor Walter</a>, 
<a href="/search/cs?searchtype=author&query=Pritzl%2C+V">V&#xe1;clav Pritzl</a>, 
<a href="/search/cs?searchtype=author&query=Pliska%2C+M">Michal Pliska</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%A1%C4%8Da%2C+T">Tom&#xe1;&#x161; B&#xe1;&#x10d;a</a>, 
<a href="/search/cs?searchtype=author&query=Spurn%C3%BD%2C+V">Vojt&#x11b;ch Spurn&#xfd;</a>, 
<a href="/search/cs?searchtype=author&query=He%C5%99t%2C+D">Daniel He&#x159;t</a>, 
<a href="/search/cs?searchtype=author&query=Saska%2C+M">Martin Saska</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05945" title="Abstract">arXiv:2303.05945</a> (replaced) [<a href="/pdf/2303.05945" title="Download PDF">pdf</a>, <a href="/ps/2303.05945" title="Download PostScript">ps</a>, <a href="/format/2303.05945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lower error bounds and optimality of approximation for jump-diffusion  SDEs with discontinuous drift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Przyby%C5%82owicz%2C+P">Pawe&#x142; Przyby&#x142;owicz</a>, 
<a href="/search/math?searchtype=author&query=Schwarz%2C+V">Verena Schwarz</a>, 
<a href="/search/math?searchtype=author&query=Sz%C3%B6lgyenyi%2C+M">Michaela Sz&#xf6;lgyenyi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07527" title="Abstract">arXiv:2303.07527</a> (replaced) [<a href="/pdf/2303.07527" title="Download PDF">pdf</a>, <a href="/format/2303.07527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Generalization via Nuclear Norm Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhenmei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Ming%2C+Y">Yifei Ming</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Ying Fan</a>, 
<a href="/search/cs?searchtype=author&query=Sala%2C+F">Frederic Sala</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yingyu Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12479" title="Abstract">arXiv:2303.12479</a> (replaced) [<a href="/e-print/2303.12479" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Two-tier DRL Framework for Cell-Free Network: Association,  Beamforming and Power Allocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yu%2C+K">Kaiwen Yu</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+C">Chonghao Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+G">Gang Wu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+G+Y">Geoffrey Ye Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has some updated
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13737" title="Abstract">arXiv:2303.13737</a> (replaced) [<a href="/pdf/2303.13737" title="Download PDF">pdf</a>, <a href="/format/2303.13737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An adaptive RKHS regularization for Fredholm integral equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lu%2C+F">Fei Lu</a>, 
<a href="/search/math?searchtype=author&query=Ou%2C+M+Y">Miao-Jung Yvonne Ou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16786" title="Abstract">arXiv:2303.16786</a> (replaced) [<a href="/pdf/2303.16786" title="Download PDF">pdf</a>, <a href="/format/2303.16786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Certification of the proximal gradient method under fixed-point  arithmetic for box-constrained QP problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Krupa%2C+P">Pablo Krupa</a>, 
<a href="/search/math?searchtype=author&query=Inverso%2C+O">Omar Inverso</a>, 
<a href="/search/math?searchtype=author&query=Tribastone%2C+M">Mirco Tribastone</a>, 
<a href="/search/math?searchtype=author&query=Bemporad%2C+A">Alberto Bemporad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Automatica, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16894" title="Abstract">arXiv:2303.16894</a> (replaced) [<a href="/pdf/2303.16894" title="Download PDF">pdf</a>, <a href="/format/2303.16894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViewRefer: Grasp the Multi-view Knowledge for 3D Visual Grounding with  GPT and Prototype Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zoey Guo</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yiwen Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ray Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhigang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuelong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023. Code is released at <a href="https://github.com/Ivan-Tang-3D/ViewRefer3D">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01407" title="Abstract">arXiv:2304.01407</a> (replaced) [<a href="/pdf/2304.01407" title="Download PDF">pdf</a>, <a href="/ps/2304.01407" title="Download PostScript">ps</a>, <a href="/format/2304.01407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monotonicity of Multi-Term Floating-Point Adders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mikaitis%2C+M">Mantas Mikaitis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Software (cs.MS)</span>; Hardware Architecture (cs.AR); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03367" title="Abstract">arXiv:2304.03367</a> (replaced) [<a href="/pdf/2304.03367" title="Download PDF">pdf</a>, <a href="/format/2304.03367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constraint Inference in Control Tasks from Expert Demonstrations via  Inverse Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papadimitriou%2C+D">Dimitris Papadimitriou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingqi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03448" title="Abstract">arXiv:2304.03448</a> (replaced) [<a href="/pdf/2304.03448" title="Download PDF">pdf</a>, <a href="/format/2304.03448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum delegation with an off-the-shelf device
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Broadbent%2C+A">Anne Broadbent</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mehta%2C+A">Arthur Mehta</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhao%2C+Y">Yuming Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages. This version (v2) contains new results that were not presented in an earlier version (v1) of this paper. We have also rephrased the OTS model to focus on the OTS device being generic and efficient
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06059" title="Abstract">arXiv:2304.06059</a> (replaced) [<a href="/pdf/2304.06059" title="Download PDF">pdf</a>, <a href="/ps/2304.06059" title="Download PostScript">ps</a>, <a href="/format/2304.06059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Deep Learning Models for Privacy-preserving People Counting on  Low-resolution Infrared Arrays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Chen Xie</a>, 
<a href="/search/cs?searchtype=author&query=Daghero%2C+F">Francesco Daghero</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yukai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Castellano%2C+M">Marco Castellano</a>, 
<a href="/search/cs?searchtype=author&query=Gandolfi%2C+L">Luca Gandolfi</a>, 
<a href="/search/cs?searchtype=author&query=Calimera%2C+A">Andrea Calimera</a>, 
<a href="/search/cs?searchtype=author&query=Macii%2C+E">Enrico Macii</a>, 
<a href="/search/cs?searchtype=author&query=Poncino%2C+M">Massimo Poncino</a>, 
<a href="/search/cs?searchtype=author&query=Pagliari%2C+D+J">Daniele Jahier Pagliari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article has been accepted for publication in IEEE Internet of Things Journal; Fixed typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06470" title="Abstract">arXiv:2304.06470</a> (replaced) [<a href="/pdf/2304.06470" title="Download PDF">pdf</a>, <a href="/format/2304.06470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Qualitative Failures of Image Generation Models and Their Application in  Detecting Deepfakes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borji%2C+A">Ali Borji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08784" title="Abstract">arXiv:2304.08784</a> (replaced) [<a href="/pdf/2304.08784" title="Download PDF">pdf</a>, <a href="/format/2304.08784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A probabilistic reduced basis method for parameter-dependent problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Billaud-Friess%2C+M">Marie Billaud-Friess</a>, 
<a href="/search/math?searchtype=author&query=Macherey%2C+A">Arthur Macherey</a>, 
<a href="/search/math?searchtype=author&query=Nouy%2C+A">Anthony Nouy</a>, 
<a href="/search/math?searchtype=author&query=Prieur%2C+C">Cl&#xe9;mentine Prieur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08956" title="Abstract">arXiv:2304.08956</a> (replaced) [<a href="/pdf/2304.08956" title="Download PDF">pdf</a>, <a href="/format/2304.08956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PG-VTON: A Novel Image-Based Virtual Try-On Method via Progressive  Inference Paradigm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+N">Naiyu Fang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Lemiao Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuyou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zili Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+K">Kerui Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13616" title="Abstract">arXiv:2304.13616</a> (replaced) [<a href="/pdf/2304.13616" title="Download PDF">pdf</a>, <a href="/format/2304.13616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CROP: Towards Distributional-Shift Robust Reinforcement Learning using  Compact Reshaped Observation Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Altmann%2C+P">Philipp Altmann</a>, 
<a href="/search/cs?searchtype=author&query=Ritz%2C+F">Fabian Ritz</a>, 
<a href="/search/cs?searchtype=author&query=Feuchtinger%2C+L">Leonard Feuchtinger</a>, 
<a href="/search/cs?searchtype=author&query=N%C3%BC%C3%9Flein%2C+J">Jonas N&#xfc;&#xdf;lein</a>, 
<a href="/search/cs?searchtype=author&query=Linnhoff-Popien%2C+C">Claudia Linnhoff-Popien</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+T">Thomy Phan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures, published at IJCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00026" title="Abstract">arXiv:2305.00026</a> (replaced) [<a href="/pdf/2305.00026" title="Download PDF">pdf</a>, <a href="/format/2305.00026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-grained classification of journal articles by relying on multiple  layers of information through similarity network fusion: the case of the  Cambridge Journal of Economics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baccini%2C+A">Alberto Baccini</a>, 
<a href="/search/cs?searchtype=author&query=Baccini%2C+F">Federica Baccini</a>, 
<a href="/search/cs?searchtype=author&query=Barabesi%2C+L">Lucio Barabesi</a>, 
<a href="/search/cs?searchtype=author&query=Cioni%2C+M">Martina Cioni</a>, 
<a href="/search/cs?searchtype=author&query=Petrovich%2C+E">Eugenio Petrovich</a>, 
<a href="/search/cs?searchtype=author&query=Pignalosa%2C+D">Daria Pignalosa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 4 figures, 10 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01090" title="Abstract">arXiv:2305.01090</a> (replaced) [<a href="/pdf/2305.01090" title="Download PDF">pdf</a>, <a href="/ps/2305.01090" title="Download PostScript">ps</a>, <a href="/format/2305.01090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autoencoders for discovering manifold dimension and coordinates in data  from complex dynamical systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+K">Kevin Zeng</a>, 
<a href="/search/cs?searchtype=author&query=De+Jes%C3%BAs%2C+C+E+P">Carlos E. P&#xe9;rez De Jes&#xfa;s</a>, 
<a href="/search/cs?searchtype=author&query=Fox%2C+A+J">Andrew J. Fox</a>, 
<a href="/search/cs?searchtype=author&query=Graham%2C+M+D">Michael D. Graham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Chaotic Dynamics (nlin.CD)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05398" title="Abstract">arXiv:2305.05398</a> (replaced) [<a href="/pdf/2305.05398" title="Download PDF">pdf</a>, <a href="/format/2305.05398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Approach for Approximating 2-Edge-Connected Spanning Subgraph  and 2-Vertex-Connected Spanning Subgraph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%87ivril%2C+A">Ali &#xc7;ivril</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11863" title="Abstract">arXiv:2305.11863</a> (replaced) [<a href="/pdf/2305.11863" title="Download PDF">pdf</a>, <a href="/format/2305.11863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling laws for language encoding models in fMRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Antonello%2C+R">Richard Antonello</a>, 
<a href="/search/cs?searchtype=author&query=Vaidya%2C+A">Aditya Vaidya</a>, 
<a href="/search/cs?searchtype=author&query=Huth%2C+A+G">Alexander G. Huth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the Thirty-seventh Annual Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12265" title="Abstract">arXiv:2305.12265</a> (replaced) [<a href="/pdf/2305.12265" title="Download PDF">pdf</a>, <a href="/format/2305.12265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tweetorial Hooks: Generative AI Tools to Motivate Science on Social  Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+T">Tao Long</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dorothy Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Grace Li</a>, 
<a href="/search/cs?searchtype=author&query=Taraif%2C+B">Batool Taraif</a>, 
<a href="/search/cs?searchtype=author&query=Menon%2C+S">Samia Menon</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+K+S">Kynnedy Simone Smith</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sitong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gero%2C+K+I">Katy Ilonka Gero</a>, 
<a href="/search/cs?searchtype=author&query=Chilton%2C+L+B">Lydia B. Chilton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 10 figures. Proceedings of the 14th International Conference on Computational Creativity (ICCC'23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13277" title="Abstract">arXiv:2305.13277</a> (replaced) [<a href="/pdf/2305.13277" title="Download PDF">pdf</a>, <a href="/format/2305.13277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> U-TILISE: A Sequence-to-sequence Model for Cloud Removal in Optical  Satellite Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stucker%2C+C">Corinne Stucker</a>, 
<a href="/search/cs?searchtype=author&query=Garnot%2C+V+S+F">Vivien Sainte Fare Garnot</a>, 
<a href="/search/cs?searchtype=author&query=Schindler%2C+K">Konrad Schindler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in the IEEE Transactions on Geoscience and Remote Sensing
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Geoscience and Remote Sensing, Vol. 61, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15583" title="Abstract">arXiv:2305.15583</a> (replaced) [<a href="/pdf/2305.15583" title="Download PDF">pdf</a>, <a href="/format/2305.15583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alleviating Exposure Bias in Diffusion Models through Sampling with  Shifted Time Steps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingxiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+T">Tingyu Qu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+R">Ruicong Yao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Moens%2C+M">Marie-Francine Moens</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> added new results &amp; proof
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15930" title="Abstract">arXiv:2305.15930</a> (replaced) [<a href="/pdf/2305.15930" title="Download PDF">pdf</a>, <a href="/format/2305.15930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-End Meta-Bayesian Optimisation with Transformer Neural Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maraval%2C+A">Alexandre Maraval</a>, 
<a href="/search/cs?searchtype=author&query=Zimmer%2C+M">Matthieu Zimmer</a>, 
<a href="/search/cs?searchtype=author&query=Grosnit%2C+A">Antoine Grosnit</a>, 
<a href="/search/cs?searchtype=author&query=Ammar%2C+H+B">Haitham Bou Ammar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15956" title="Abstract">arXiv:2305.15956</a> (replaced) [<a href="/pdf/2305.15956" title="Download PDF">pdf</a>, <a href="/format/2305.15956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anomaly Detection with Conditioned Denoising Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mousakhan%2C+A">Arian Mousakhan</a>, 
<a href="/search/cs?searchtype=author&query=Brox%2C+T">Thomas Brox</a>, 
<a href="/search/cs?searchtype=author&query=Tayyub%2C+J">Jawad Tayyub</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16450" title="Abstract">arXiv:2305.16450</a> (replaced) [<a href="/pdf/2305.16450" title="Download PDF">pdf</a>, <a href="/ps/2305.16450" title="Download PostScript">ps</a>, <a href="/format/2305.16450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigation of UAV Detection in Images with Complex Backgrounds and  Rainy Artifacts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Munir%2C+A">Adnan Munir</a>, 
<a href="/search/cs?searchtype=author&query=Siddiqui%2C+A+J">Abdul Jabbar Siddiqui</a>, 
<a href="/search/cs?searchtype=author&query=Anwar%2C+S">Saeed Anwar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the Real-World Surveillance Workshop, IEEE/CVF Winter Conference on Applications of Computer Vision 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16573" title="Abstract">arXiv:2305.16573</a> (replaced) [<a href="/pdf/2305.16573" title="Download PDF">pdf</a>, <a href="/format/2305.16573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Weight Balancing on Long-Tailed Recognition Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hasegawa%2C+N">Naoya Hasegawa</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+I">Issei Sato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17819" title="Abstract">arXiv:2305.17819</a> (replaced) [<a href="/pdf/2305.17819" title="Download PDF">pdf</a>, <a href="/format/2305.17819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models, scientific knowledge and factuality: A systematic  analysis in antibiotic discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wysocka%2C+M">Magdalena Wysocka</a>, 
<a href="/search/cs?searchtype=author&query=Wysocki%2C+O">Oskar Wysocki</a>, 
<a href="/search/cs?searchtype=author&query=Delmas%2C+M">Maxime Delmas</a>, 
<a href="/search/cs?searchtype=author&query=Mutel%2C+V">Vincent Mutel</a>, 
<a href="/search/cs?searchtype=author&query=Freitas%2C+A">Andre Freitas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19798" title="Abstract">arXiv:2305.19798</a> (replaced) [<a href="/pdf/2305.19798" title="Download PDF">pdf</a>, <a href="/format/2305.19798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Primal-Attention: Self-attention through Asymmetric Kernel SVD in Primal  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+Q">Qinghua Tao</a>, 
<a href="/search/cs?searchtype=author&query=Tonin%2C+F">Francesco Tonin</a>, 
<a href="/search/cs?searchtype=author&query=Suykens%2C+J+A+K">Johan A.K. Suykens</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. We provide a primal-dual representation for the asymmetric self-attention in transformer that allows to avoid explicit computation of the kernel matrix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02666" title="Abstract">arXiv:2306.02666</a> (replaced) [<a href="/pdf/2306.02666" title="Download PDF">pdf</a>, <a href="/format/2306.02666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does a sparse ReLU network training problem always admit an optimum?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+Q">Quoc-Tung Le</a> (LIP, OCKHAM), 
<a href="/search/cs?searchtype=author&query=Riccietti%2C+E">Elisa Riccietti</a> (OCKHAM), 
<a href="/search/cs?searchtype=author&query=Gribonval%2C+R">R&#xe9;mi Gribonval</a> (OCKHAM)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 - Thirty-seventh Conference on Neural Information Processing Systems, Dec 2023, New Orleans (Lousiane), United States
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Algebraic Geometry (math.AG); Functional Analysis (math.FA); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04026" title="Abstract">arXiv:2306.04026</a> (replaced) [<a href="/pdf/2306.04026" title="Download PDF">pdf</a>, <a href="/format/2306.04026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Value Functions are Control Barrier Functions: Verification of Safe  Policies using Control Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+D+C+H">Daniel C.H. Tan</a>, 
<a href="/search/cs?searchtype=author&query=Acero%2C+F">Fernando Acero</a>, 
<a href="/search/cs?searchtype=author&query=McCarthy%2C+R">Robert McCarthy</a>, 
<a href="/search/cs?searchtype=author&query=Kanoulas%2C+D">Dimitrios Kanoulas</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhibin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04037" title="Abstract">arXiv:2306.04037</a> (replaced) [<a href="/pdf/2306.04037" title="Download PDF">pdf</a>, <a href="/format/2306.04037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantitative Analysis of Primary Attribution Explainable Artificial  Intelligence Methods for Remote Sensing Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohan%2C+A">Akshatha Mohan</a>, 
<a href="/search/cs?searchtype=author&query=Peeples%2C+J">Joshua Peeples</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 figures, Accepted to 2023 IGARSS Community-Contributed Sessions - Opening the Black Box: Explainable AI/ML in Remote Sensing Analysis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04743" title="Abstract">arXiv:2306.04743</a> (replaced) [<a href="/pdf/2306.04743" title="Download PDF">pdf</a>, <a href="/format/2306.04743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ScienceBenchmark: A Complex Real-World Benchmark for Evaluating Natural  Language to SQL Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Deriu%2C+J">Jan Deriu</a>, 
<a href="/search/cs?searchtype=author&query=Katsogiannis-Meimarakis%2C+G">George Katsogiannis-Meimarakis</a>, 
<a href="/search/cs?searchtype=author&query=Kosten%2C+C">Catherine Kosten</a>, 
<a href="/search/cs?searchtype=author&query=Koutrika%2C+G">Georgia Koutrika</a>, 
<a href="/search/cs?searchtype=author&query=Stockinger%2C+K">Kurt Stockinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 2 figures, 5 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> PVLDB Volume 17, 2023-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05427" title="Abstract">arXiv:2306.05427</a> (replaced) [<a href="/pdf/2306.05427" title="Download PDF">pdf</a>, <a href="/format/2306.05427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grounded Text-to-Image Synthesis with Attention Refocusing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phung%2C+Q">Quynh Phung</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+S">Songwei Ge</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jia-Bin Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://attention-refocusing.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08310" title="Abstract">arXiv:2306.08310</a> (replaced) [<a href="/pdf/2306.08310" title="Download PDF">pdf</a>, <a href="/format/2306.08310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TWIGMA: A dataset of AI-Generated Images with Metadata From Twitter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chen%2C+Y">Yiqun Chen</a>, 
<a href="/search/stat?searchtype=author&query=Zou%2C+J">James Zou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09750" title="Abstract">arXiv:2306.09750</a> (replaced) [<a href="/pdf/2306.09750" title="Download PDF">pdf</a>, <a href="/format/2306.09750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fedstellar: A Platform for Decentralized Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beltr%C3%A1n%2C+E+T+M">Enrique Tom&#xe1;s Mart&#xed;nez Beltr&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez%2C+%C3%81+L+P">&#xc1;ngel Luis Perales G&#xf3;mez</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chao Feng</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez%2C+P+M+S">Pedro Miguel S&#xe1;nchez S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Bernal%2C+S+L">Sergio L&#xf3;pez Bernal</a>, 
<a href="/search/cs?searchtype=author&query=Bovet%2C+G">G&#xe9;r&#xf4;me Bovet</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+M+G">Manuel Gil P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+G+M">Gregorio Mart&#xed;nez P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Celdr%C3%A1n%2C+A+H">Alberto Huertas Celdr&#xe1;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10191" title="Abstract">arXiv:2306.10191</a> (replaced) [<a href="/pdf/2306.10191" title="Download PDF">pdf</a>, <a href="/format/2306.10191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Priming for Sample-Efficient Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wallingford%2C+M">Matthew Wallingford</a>, 
<a href="/search/cs?searchtype=author&query=Ramanujan%2C+V">Vivek Ramanujan</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+A">Alex Fang</a>, 
<a href="/search/cs?searchtype=author&query=Kusupati%2C+A">Aditya Kusupati</a>, 
<a href="/search/cs?searchtype=author&query=Mottaghi%2C+R">Roozbeh Mottaghi</a>, 
<a href="/search/cs?searchtype=author&query=Kembhavi%2C+A">Aniruddha Kembhavi</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+L">Ludwig Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Farhadi%2C+A">Ali Farhadi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 7 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10797" title="Abstract">arXiv:2306.10797</a> (replaced) [<a href="/pdf/2306.10797" title="Download PDF">pdf</a>, <a href="/format/2306.10797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variability of echo state network prediction horizon for partially  observed dynamical systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mahata%2C+A">Ajit Mahata</a>, 
<a href="/search/eess?searchtype=author&query=Padhi%2C+R">Reetish Padhi</a>, 
<a href="/search/eess?searchtype=author&query=Apte%2C+A">Amit Apte</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10926" title="Abstract">arXiv:2306.10926</a> (replaced) [<a href="/pdf/2306.10926" title="Download PDF">pdf</a>, <a href="/format/2306.10926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invariant Descriptors of Motion and Force Trajectories for Interpreting  Object Manipulation Tasks in Contact
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vochten%2C+M">Maxim Vochten</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadi%2C+A+M">Ali Mousavi Mohammadi</a>, 
<a href="/search/cs?searchtype=author&query=Verduyn%2C+A">Arno Verduyn</a>, 
<a href="/search/cs?searchtype=author&query=De+Laet%2C+T">Tinne De Laet</a>, 
<a href="/search/cs?searchtype=author&query=Aertbeli%C3%ABn%2C+E">Erwin Aertbeli&#xeb;n</a>, 
<a href="/search/cs?searchtype=author&query=De+Schutter%2C+J">Joris De Schutter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 14 figures. Accepted for Publication in IEEE Transactions on Robotics (July 25, 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11300" title="Abstract">arXiv:2306.11300</a> (replaced) [<a href="/pdf/2306.11300" title="Download PDF">pdf</a>, <a href="/format/2306.11300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RS5M: A Large Scale Vision-Language Dataset for Remote Sensing  Vision-Language Foundation Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zilun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tiancheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yulong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jianwei Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> RS5M dataset v5
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15448" title="Abstract">arXiv:2306.15448</a> (replaced) [<a href="/pdf/2306.15448" title="Download PDF">pdf</a>, <a href="/format/2306.15448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Social Reasoning in Language Models with Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gandhi%2C+K">Kanishk Gandhi</a>, 
<a href="/search/cs?searchtype=author&query=Fr%C3%A4nken%2C+J">Jan-Philipp Fr&#xe4;nken</a>, 
<a href="/search/cs?searchtype=author&query=Gerstenberg%2C+T">Tobias Gerstenberg</a>, 
<a href="/search/cs?searchtype=author&query=Goodman%2C+N+D">Noah D. Goodman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16334" title="Abstract">arXiv:2306.16334</a> (replaced) [<a href="/pdf/2306.16334" title="Download PDF">pdf</a>, <a href="/format/2306.16334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Identifiability of Quantized Factors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barin-Pacela%2C+V">Vit&#xf3;ria Barin-Pacela</a>, 
<a href="/search/cs?searchtype=author&query=Ahuja%2C+K">Kartik Ahuja</a>, 
<a href="/search/cs?searchtype=author&query=Lacoste-Julien%2C+S">Simon Lacoste-Julien</a>, 
<a href="/search/cs?searchtype=author&query=Vincent%2C+P">Pascal Vincent</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17046" title="Abstract">arXiv:2306.17046</a> (replaced) [<a href="/pdf/2306.17046" title="Download PDF">pdf</a>, <a href="/format/2306.17046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spiking Denoising Diffusion Probabilistic Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiahang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hanzhong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Renjing Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17082" title="Abstract">arXiv:2306.17082</a> (replaced) [<a href="/pdf/2306.17082" title="Download PDF">pdf</a>, <a href="/format/2306.17082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Latent Entity Expansion for Document Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mackie%2C+I">Iain Mackie</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+S">Shubham Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=MacAvaney%2C+S">Sean MacAvaney</a>, 
<a href="/search/cs?searchtype=author&query=Dalton%2C+J">Jeffrey Dalton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17840" title="Abstract">arXiv:2306.17840</a> (replaced) [<a href="/pdf/2306.17840" title="Download PDF">pdf</a>, <a href="/format/2306.17840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statler: State-Maintaining Language Models for Embodied Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoneda%2C+T">Takuma Yoneda</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Jiading Fang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huanyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+T">Tianchong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shengjie Lin</a>, 
<a href="/search/cs?searchtype=author&query=Picker%2C+B">Ben Picker</a>, 
<a href="/search/cs?searchtype=author&query=Yunis%2C+D">David Yunis</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+H">Hongyuan Mei</a>, 
<a href="/search/cs?searchtype=author&query=Walter%2C+M+R">Matthew R. Walter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In submission; Project website: <a href="https://statler-lm.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00347" title="Abstract">arXiv:2307.00347</a> (replaced) [<a href="/pdf/2307.00347" title="Download PDF">pdf</a>, <a href="/format/2307.00347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial-Temporal Enhanced Transformer Towards Multi-Frame 3D Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhiyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Junhui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Dapeng Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00371" title="Abstract">arXiv:2307.00371</a> (replaced) [<a href="/pdf/2307.00371" title="Download PDF">pdf</a>, <a href="/format/2307.00371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Content-enhanced Mask Transformer for Domain Generalized  Urban-Scene Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bi%2C+Q">Qi Bi</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+S">Shaodi You</a>, 
<a href="/search/cs?searchtype=author&query=Gevers%2C+T">Theo Gevers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00908" title="Abstract">arXiv:2307.00908</a> (replaced) [<a href="/pdf/2307.00908" title="Download PDF">pdf</a>, <a href="/format/2307.00908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Machine Learning on Near-Term Quantum Devices: Current State of  Supervised and Unsupervised Techniques for Real-World Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Gujju%2C+Y">Yaswitha Gujju</a>, 
<a href="/search/quant-ph?searchtype=author&query=Matsuo%2C+A">Atsushi Matsuo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Raymond%2C+R">Rudy Raymond</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02848" title="Abstract">arXiv:2307.02848</a> (replaced) [<a href="/pdf/2307.02848" title="Download PDF">pdf</a>, <a href="/format/2307.02848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Computer-Aided Tuberculosis Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yu-Huan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shi-Chen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Li Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Min Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Ming-Ming Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE TPAMI; 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03868" title="Abstract">arXiv:2307.03868</a> (replaced) [<a href="/pdf/2307.03868" title="Download PDF">pdf</a>, <a href="/format/2307.03868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Stability Analysis of Piecewise Affine Dynamics Using Vertices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Samanipour%2C+P">Pouya Samanipour</a>, 
<a href="/search/eess?searchtype=author&query=Poonawala%2C+H+A">Hasan A. Poonawala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 11 figures, Presented at Allerton 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04500" title="Abstract">arXiv:2307.04500</a> (replaced) [<a href="/pdf/2307.04500" title="Download PDF">pdf</a>, <a href="/ps/2307.04500" title="Download PostScript">ps</a>, <a href="/format/2307.04500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Academic Plan Derived from Community College Articulation  Agreements: A Preliminary Experiment on Algorithm-Generated and  Human-Generated Academic Plans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+V">David V. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Doroudi%2C+S">Shayan Doroudi</a>, 
<a href="/search/cs?searchtype=author&query=Epstein%2C+D+A">Daniel A. Epstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06046" title="Abstract">arXiv:2307.06046</a> (replaced) [<a href="/pdf/2307.06046" title="Download PDF">pdf</a>, <a href="/format/2307.06046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-Task Perspective for Link Prediction with New Relation Types and  Nodes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jincheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Bevilacqua%2C+B">Beatrice Bevilacqua</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+B">Bruno Ribeiro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS GLFrontiers 2023. 24 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06614" title="Abstract">arXiv:2307.06614</a> (replaced) [<a href="/pdf/2307.06614" title="Download PDF">pdf</a>, <a href="/format/2307.06614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable 2D Vision Models for 3D Medical Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ziller%2C+A">Alexander Ziller</a>, 
<a href="/search/eess?searchtype=author&query=Erdur%2C+A+C">Ayhan Can Erdur</a>, 
<a href="/search/eess?searchtype=author&query=Trigui%2C+M">Marwa Trigui</a>, 
<a href="/search/eess?searchtype=author&query=G%C3%BCvenir%2C+A">Alp G&#xfc;venir</a>, 
<a href="/search/eess?searchtype=author&query=Mueller%2C+T+T">Tamara T. Mueller</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%BCller%2C+P">Philip M&#xfc;ller</a>, 
<a href="/search/eess?searchtype=author&query=Jungmann%2C+F">Friederike Jungmann</a>, 
<a href="/search/eess?searchtype=author&query=Brandt%2C+J">Johannes Brandt</a>, 
<a href="/search/eess?searchtype=author&query=Peeken%2C+J">Jan Peeken</a>, 
<a href="/search/eess?searchtype=author&query=Braren%2C+R">Rickmer Braren</a>, 
<a href="/search/eess?searchtype=author&query=Rueckert%2C+D">Daniel Rueckert</a>, 
<a href="/search/eess?searchtype=author&query=Kaissis%2C+G">Georgios Kaissis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07980" title="Abstract">arXiv:2307.07980</a> (replaced) [<a href="/pdf/2307.07980" title="Download PDF">pdf</a>, <a href="/format/2307.07980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Byzantine-Robust Distributed Online Learning: Taming Adversarial  Participants in An Adversarial Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xingrong Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhaoxian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+Q">Qing Ling</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhi Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09496" title="Abstract">arXiv:2307.09496</a> (replaced) [<a href="/pdf/2307.09496" title="Download PDF">pdf</a>, <a href="/ps/2307.09496" title="Download PostScript">ps</a>, <a href="/format/2307.09496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explaining conflict violence in terms of conflict actor dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Tkacova%2C+K">Katerina Tkacova</a>, 
<a href="/search/physics?searchtype=author&query=Idler%2C+A">Annette Idler</a>, 
<a href="/search/physics?searchtype=author&query=Johnson%2C+N">Neil Johnson</a>, 
<a href="/search/physics?searchtype=author&query=L%C3%B3pez%2C+E">Eduardo L&#xf3;pez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 4 figures, 3 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sci Rep 13, 21187 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10988" title="Abstract">arXiv:2307.10988</a> (replaced) [<a href="/pdf/2307.10988" title="Download PDF">pdf</a>, <a href="/format/2307.10988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On minimizing the training set fill distance in machine learning  regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Climaco%2C+P">Paolo Climaco</a>, 
<a href="/search/cs?searchtype=author&query=Garcke%2C+J">Jochen Garcke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12582" title="Abstract">arXiv:2307.12582</a> (replaced) [<a href="/pdf/2307.12582" title="Download PDF">pdf</a>, <a href="/ps/2307.12582" title="Download PostScript">ps</a>, <a href="/format/2307.12582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Algorithms for Bounded Knapsack and Bounded Subset Sum Via  Fine-Grained Proximity Results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+J">Jiayi Lian</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yuchen Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guochuan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in SODA2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12810" title="Abstract">arXiv:2307.12810</a> (replaced) [<a href="/pdf/2307.12810" title="Download PDF">pdf</a>, <a href="/format/2307.12810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HeteFedRec: Federated Recommender Systems with Model Heterogeneity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Wei Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+L">Liang Qu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+L">Lizhen Cui</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+Y">Yongxin Tong</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaofang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongzhi Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15202" title="Abstract">arXiv:2307.15202</a> (replaced) [<a href="/pdf/2307.15202" title="Download PDF">pdf</a>, <a href="/format/2307.15202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Robot Multi-Room Exploration with Geometric Cue Extraction and  Circular Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungchan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Corah%2C+M">Micah Corah</a>, 
<a href="/search/cs?searchtype=author&query=Keller%2C+J">John Keller</a>, 
<a href="/search/cs?searchtype=author&query=Best%2C+G">Graeme Best</a>, 
<a href="/search/cs?searchtype=author&query=Scherer%2C+S">Sebastian Scherer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00673" title="Abstract">arXiv:2308.00673</a> (replaced) [<a href="/pdf/2308.00673" title="Download PDF">pdf</a>, <a href="/format/2308.00673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orthonormal eigenfunction expansions for sixth-order boundary value  problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Papanicolaou%2C+N+C">N C Papanicolaou</a>, 
<a href="/search/math?searchtype=author&query=Christov%2C+I+C">I C Christov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 5 figures, IoP jpconf style; v2: correct minor typos, to appear in the proceedings of the Fifteenth Conference of the Euro-American Consortium for Promoting the Application of Mathematics in Technical and Natural Sciences (AMiTaNS'23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01830" title="Abstract">arXiv:2308.01830</a> (replaced) [<a href="/pdf/2308.01830" title="Download PDF">pdf</a>, <a href="/format/2308.01830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning beyond sensations: how dreams organize neuronal representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Deperrois%2C+N">Nicolas Deperrois</a>, 
<a href="/search/q-bio?searchtype=author&query=Petrovici%2C+M+A">Mihai A. Petrovici</a>, 
<a href="/search/q-bio?searchtype=author&query=Senn%2C+W">Walter Senn</a>, 
<a href="/search/q-bio?searchtype=author&query=Jordan%2C+J">Jakob Jordan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 3 figures, perspective article
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05810" title="Abstract">arXiv:2308.05810</a> (replaced) [<a href="/pdf/2308.05810" title="Download PDF">pdf</a>, <a href="/format/2308.05810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spintronics for image recognition: performance benchmarking via  ultrafast data-driven simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moureaux%2C+A">Anatole Moureaux</a>, 
<a href="/search/cs?searchtype=author&query=Chopin%2C+C">Chlo&#xe9; Chopin</a>, 
<a href="/search/cs?searchtype=author&query=Jacques%2C+L">Laurent Jacques</a>, 
<a href="/search/cs?searchtype=author&query=Araujo%2C+F+A">Flavio Abreu Araujo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06053" title="Abstract">arXiv:2308.06053</a> (replaced) [<a href="/pdf/2308.06053" title="Download PDF">pdf</a>, <a href="/format/2308.06053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cost-effective On-device Continual Learning over Memory Hierarchy with  Miro
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xinyue Ma</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+S">Suyeon Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Minjia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jonghyun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+M">Myeongjae Jeon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is published in the 29th Annual International Conference on Mobile Computing and Networking (ACM MobiCom '23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06562" title="Abstract">arXiv:2308.06562</a> (replaced) [<a href="/pdf/2308.06562" title="Download PDF">pdf</a>, <a href="/format/2308.06562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient-Based Markov Chain Monte Carlo for MIMO Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+X">Xingyu Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Liang%2C+L">Le Liang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wen%2C+C">Chao-Kai Wen</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+S">Shi Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 12 figures, 2 tables. This paper has been accepted for publication by the IEEE Transactions on Wireless Communications. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08410" title="Abstract">arXiv:2308.08410</a> (replaced) [<a href="/pdf/2308.08410" title="Download PDF">pdf</a>, <a href="/format/2308.08410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital twinning of cardiac electrophysiology models from the surface  ECG: a geodesic backpropagation approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Grandits%2C+T">Thomas Grandits</a>, 
<a href="/search/math?searchtype=author&query=Verh%C3%BClsdonk%2C+J">Jan Verh&#xfc;lsdonk</a>, 
<a href="/search/math?searchtype=author&query=Haase%2C+G">Gundolf Haase</a>, 
<a href="/search/math?searchtype=author&query=Effland%2C+A">Alexander Effland</a>, 
<a href="/search/math?searchtype=author&query=Pezzuto%2C+S">Simone Pezzuto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Medical Physics (physics.med-ph)

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11068" title="Abstract">arXiv:2308.11068</a> (replaced) [<a href="/pdf/2308.11068" title="Download PDF">pdf</a>, <a href="/format/2308.11068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topological Graph Signal Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bern%C3%A1rdez%2C+G">Guillermo Bern&#xe1;rdez</a>, 
<a href="/search/cs?searchtype=author&query=Telyatnikov%2C+L">Lev Telyatnikov</a>, 
<a href="/search/cs?searchtype=author&query=Alarc%C3%B3n%2C+E">Eduard Alarc&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Cabellos-Aparicio%2C+A">Albert Cabellos-Aparicio</a>, 
<a href="/search/cs?searchtype=author&query=Barlet-Ros%2C+P">Pere Barlet-Ros</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as Oral at the Second Learning on Graphs Conference (LoG 2023). The recording of the talk can be found in <a href="https://www.youtube.com/watch?v=OcruIkiRkiU">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11487" title="Abstract">arXiv:2308.11487</a> (replaced) [<a href="/pdf/2308.11487" title="Download PDF">pdf</a>, <a href="/format/2308.11487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Free Lunch for Gait Recognition: A Novel Relation Descriptor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+S">Saihui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+C">Chunshui Cao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yongzhen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianzhu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Add new figures and fix some typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16549" title="Abstract">arXiv:2308.16549</a> (replaced) [<a href="/pdf/2308.16549" title="Download PDF">pdf</a>, <a href="/format/2308.16549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Thesis Distillation: Investigating The Impact of Bias in NLP Models on  Hate Speech Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elsafoury%2C+F">Fatma Elsafoury</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01004" title="Abstract">arXiv:2309.01004</a> (replaced) [<a href="/pdf/2309.01004" title="Download PDF">pdf</a>, <a href="/format/2309.01004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Projection-based reduced order modeling of an iterative coupling scheme  for linear thermo-poroelasticity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ballarin%2C+F">Francesco Ballarin</a>, 
<a href="/search/math?searchtype=author&query=Lee%2C+S">Sanghyun Lee</a>, 
<a href="/search/math?searchtype=author&query=Yi%2C+S">Son-Young Yi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02521" title="Abstract">arXiv:2309.02521</a> (replaced) [<a href="/pdf/2309.02521" title="Download PDF">pdf</a>, <a href="/format/2309.02521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Analysis of CPU and GPU Profiling for Deep Learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gyawali%2C+D">Dipesh Gyawali</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04295" title="Abstract">arXiv:2309.04295</a> (replaced) [<a href="/pdf/2309.04295" title="Download PDF">pdf</a>, <a href="/format/2309.04295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FIMO: A Challenge Formal Dataset for Automated Theorem Proving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chengwu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jianhao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+H">Huajian Xin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Ye Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haiming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+W">Wei Ju</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chuanyang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yichun Yin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Ming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qun Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added a hyperlink to the dataset made accessible on GitHub
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04331" title="Abstract">arXiv:2309.04331</a> (replaced) [<a href="/pdf/2309.04331" title="Download PDF">pdf</a>, <a href="/format/2309.04331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Model Fusion for Improved License Plate Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laroca%2C+R">Rayson Laroca</a>, 
<a href="/search/cs?searchtype=author&query=Zanlorensi%2C+L+A">Luiz A. Zanlorensi</a>, 
<a href="/search/cs?searchtype=author&query=Estevam%2C+V">Valter Estevam</a>, 
<a href="/search/cs?searchtype=author&query=Minetto%2C+R">Rodrigo Minetto</a>, 
<a href="/search/cs?searchtype=author&query=Menotti%2C+D">David Menotti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at the Iberoamerican Congress on Pattern Recognition (CIARP) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04437" title="Abstract">arXiv:2309.04437</a> (replaced) [<a href="/pdf/2309.04437" title="Download PDF">pdf</a>, <a href="/format/2309.04437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single View Refractive Index Tomography with Neural Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Brandon Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Levis%2C+A">Aviad Levis</a>, 
<a href="/search/cs?searchtype=author&query=Connor%2C+L">Liam Connor</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+P+P">Pratul P. Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Bouman%2C+K+L">Katherine L. Bouman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cosmology and Nongalactic Astrophysics (astro-ph.CO)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10313" title="Abstract">arXiv:2309.10313</a> (replaced) [<a href="/pdf/2309.10313" title="Download PDF">pdf</a>, <a href="/format/2309.10313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating the Catastrophic Forgetting in Multimodal Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhai%2C+Y">Yuexiang Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+S">Shengbang Tong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+M">Mu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Q">Qing Qu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y+J">Yong Jae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yi Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11523" title="Abstract">arXiv:2309.11523</a> (replaced) [<a href="/pdf/2309.11523" title="Download PDF">pdf</a>, <a href="/format/2309.11523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RMT: Retentive Networks Meet Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Q">Qihang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huaibo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingrui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongmin Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ran He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fix the bug in the UperNet. Code is available at <a href="https://github.com/qhfan/RMT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12307" title="Abstract">arXiv:2309.12307</a> (replaced) [<a href="/pdf/2309.12307" title="Download PDF">pdf</a>, <a href="/format/2309.12307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yukang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+S">Shengju Qian</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Haotian Tang</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+X">Xin Lai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhijian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Song Han</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jiaya Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code, models, dataset, and demo are available at <a href="https://github.com/dvlab-research/LongLoRA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12334" title="Abstract">arXiv:2309.12334</a> (replaced) [<a href="/pdf/2309.12334" title="Download PDF">pdf</a>, <a href="/ps/2309.12334" title="Download PostScript">ps</a>, <a href="/format/2309.12334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Knowledge Tracing is an implicit dynamic multidimensional item  response theory model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vie%2C+J">Jill-J&#xea;nn Vie</a> (SODA), 
<a href="/search/cs?searchtype=author&query=Kashima%2C+H">Hisashi Kashima</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICCE 2023 - The 31st International Conference on Computers in
  Education, Asia-Pacific Society for Computers in Education, Dec 2023, Matsue,
  Shimane, Japan
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13762" title="Abstract">arXiv:2309.13762</a> (replaced) [<a href="/pdf/2309.13762" title="Download PDF">pdf</a>, <a href="/format/2309.13762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Veer: Verifying Equivalence of Dataflow Versions in Iterative Data  Analytics (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alsudais%2C+S">Sadeem Alsudais</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Avinash Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14162" title="Abstract">arXiv:2309.14162</a> (replaced) [<a href="/pdf/2309.14162" title="Download PDF">pdf</a>, <a href="/format/2309.14162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Upcycling Knowledge Distillation for Image Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Simiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hanting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hailing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhijun Tu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+B">Bingyi Jing</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhe Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14235" title="Abstract">arXiv:2309.14235</a> (replaced) [<a href="/pdf/2309.14235" title="Download PDF">pdf</a>, <a href="/format/2309.14235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stackelberg Driver Model for Continual Policy Improvement in  Scenario-Based Closed-Loop Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+H">Haoyi Niu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qimao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jianming Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16948" title="Abstract">arXiv:2309.16948</a> (replaced) [<a href="/pdf/2309.16948" title="Download PDF">pdf</a>, <a href="/format/2309.16948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Denoising Diffusion Bridge Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Linqi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+A">Aaron Lou</a>, 
<a href="/search/cs?searchtype=author&query=Khanna%2C+S">Samar Khanna</a>, 
<a href="/search/cs?searchtype=author&query=Ermon%2C+S">Stefano Ermon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Github: <a href="https://github.com/alexzhou907/DDBM/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17059" title="Abstract">arXiv:2309.17059</a> (replaced) [<a href="/pdf/2309.17059" title="Download PDF">pdf</a>, <a href="/format/2309.17059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GSDC Transformer: An Efficient and Effective Cue Fusion for Monocular  Multi-Frame Depth Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+N">Naiyu Fang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Lemiao Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuyou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zili Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zheyuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+K">Kerui Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01415" title="Abstract">arXiv:2310.01415</a> (replaced) [<a href="/pdf/2310.01415" title="Download PDF">pdf</a>, <a href="/format/2310.01415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT-Driver: Learning to Drive with GPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+J">Jiageng Mao</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yuxi Qian</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Junjie Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Foundation Models for Decision Making Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02903" title="Abstract">arXiv:2310.02903</a> (replaced) [<a href="/pdf/2310.02903" title="Download PDF">pdf</a>, <a href="/format/2310.02903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FroSSL: Frobenius Norm Minimization for Self-Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Skean%2C+O">Oscar Skean</a>, 
<a href="/search/cs?searchtype=author&query=Dhakal%2C+A">Aayush Dhakal</a>, 
<a href="/search/cs?searchtype=author&query=Jacobs%2C+N">Nathan Jacobs</a>, 
<a href="/search/cs?searchtype=author&query=Giraldo%2C+L+G+S">Luis Gonzalo Sanchez Giraldo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03152" title="Abstract">arXiv:2310.03152</a> (replaced) [<a href="/pdf/2310.03152" title="Download PDF">pdf</a>, <a href="/format/2310.03152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards out-of-distribution generalizable predictions of chemical  kinetics properties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yongqiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yang Duan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weijiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bo Han</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">James Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+H">Hanghang Tong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Workshop in AI for Scientific Discovery: From Theory to Practice. 11 pages, 1 figure, and 5 tables Data and code can be found in <a href="https://github.com/zihao-wang/ReactionOOD">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04406" title="Abstract">arXiv:2310.04406</a> (replaced) [<a href="/pdf/2310.04406" title="Download PDF">pdf</a>, <a href="/format/2310.04406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Agent Tree Search Unifies Reasoning Acting and Planning in  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A">Andy Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+K">Kai Yan</a>, 
<a href="/search/cs?searchtype=author&query=Shlapentokh-Rothman%2C+M">Michal Shlapentokh-Rothman</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haohan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Xiong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Website and code can be found at <a href="https://andyz245.github.io/LanguageAgentTreeSearch">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05063" title="Abstract">arXiv:2310.05063</a> (replaced) [<a href="/pdf/2310.05063" title="Download PDF">pdf</a>, <a href="/format/2310.05063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pushing the Limits of Pre-training for Time Series Forecasting in the  CloudOps Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Woo%2C+G">Gerald Woo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chenghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Akshat Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Sahoo%2C+D">Doyen Sahoo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05867" title="Abstract">arXiv:2310.05867</a> (replaced) [<a href="/pdf/2310.05867" title="Download PDF">pdf</a>, <a href="/format/2310.05867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain-wise Invariant Learning for Panoptic Scene Graph Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">You Qin</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+W">Wei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuxiao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zimmermann%2C+R">Roger Zimmermann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2307.15567">arXiv:2307.15567</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06259" title="Abstract">arXiv:2310.06259</a> (replaced) [<a href="/pdf/2310.06259" title="Download PDF">pdf</a>, <a href="/format/2310.06259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-modal Cognitive Consensus guided Audio-Visual Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shi%2C+Z">Zhaofeng Shi</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Q">Qingbo Wu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Hongliang Li</a>, 
<a href="/search/eess?searchtype=author&query=Meng%2C+F">Fanman Meng</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+L">Linfeng Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06609" title="Abstract">arXiv:2310.06609</a> (replaced) [<a href="/pdf/2310.06609" title="Download PDF">pdf</a>, <a href="/format/2310.06609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering Interpretable Physical Models using Symbolic Regression and  Discrete Exterior Calculus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manti%2C+S">Simone Manti</a>, 
<a href="/search/cs?searchtype=author&query=Lucantonio%2C+A">Alessandro Lucantonio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Discrete Mathematics (cs.DM); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07135" title="Abstract">arXiv:2310.07135</a> (replaced) [<a href="/pdf/2310.07135" title="Download PDF">pdf</a>, <a href="/format/2310.07135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing Styles across Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Havaldar%2C+S">Shreya Havaldar</a>, 
<a href="/search/cs?searchtype=author&query=Pressimone%2C+M">Matthew Pressimone</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+E">Eric Wong</a>, 
<a href="/search/cs?searchtype=author&query=Ungar%2C+L">Lyle Ungar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07726" title="Abstract">arXiv:2310.07726</a> (replaced) [<a href="/pdf/2310.07726" title="Download PDF">pdf</a>, <a href="/format/2310.07726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Warfare:Breaking the Watermark Protection of AI-Generated Content
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanlin Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yifei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Shangwei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08529" title="Abstract">arXiv:2310.08529</a> (replaced) [<a href="/pdf/2310.08529" title="Download PDF">pdf</a>, <a href="/format/2310.08529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GaussianDreamer: Fast Generation from Text to 3D Gaussians by Bridging  2D and 3D Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+T">Taoran Yi</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Jiemin Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Guanjun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lingxi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaopeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qi Tian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinggang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://taoranyi.com/gaussiandreamer/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09078" title="Abstract">arXiv:2310.09078</a> (replaced) [<a href="/pdf/2310.09078" title="Download PDF">pdf</a>, <a href="/format/2310.09078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DNFS-VNE: Deep Neuro Fuzzy System Driven Virtual Network Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+A">Ailing Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Ning Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Sheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peiying Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chunxiao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09485" title="Abstract">arXiv:2310.09485</a> (replaced) [<a href="/pdf/2310.09485" title="Download PDF">pdf</a>, <a href="/format/2310.09485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applying Bayesian Ridge Regression AI Modeling in Virus Severity  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pal%2C+J">Jai Pal</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+B">Bryan Hong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures, 5 listings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10123" title="Abstract">arXiv:2310.10123</a> (replaced) [<a href="/pdf/2310.10123" title="Download PDF">pdf</a>, <a href="/format/2310.10123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoDIR: Automatic All-in-One Image Restoration with Latent Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yitong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+T">Tianfan Xue</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinwei Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11479" title="Abstract">arXiv:2310.11479</a> (replaced) [<a href="/pdf/2310.11479" title="Download PDF">pdf</a>, <a href="/format/2310.11479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Temperature of Bayesian Graph Neural Networks for Conformal  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cha%2C+S">Seohyeon Cha</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+H">Honggu Kang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Joonhyuk Kang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12835" title="Abstract">arXiv:2310.12835</a> (replaced) [<a href="/pdf/2310.12835" title="Download PDF">pdf</a>, <a href="/format/2310.12835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High Dynamic Range mmWave Massive MU-MIMO with Householder Reflections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Palhares%2C+V">Victoria Palhares</a>, 
<a href="/search/cs?searchtype=author&query=Marti%2C+G">Gian Marti</a>, 
<a href="/search/cs?searchtype=author&query=Casta%C3%B1eda%2C+O">Oscar Casta&#xf1;eda</a>, 
<a href="/search/cs?searchtype=author&query=Studer%2C+C">Christoph Studer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the Asilomar Conference on Signals, Systems, and Computers 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13572" title="Abstract">arXiv:2310.13572</a> (replaced) [<a href="/pdf/2310.13572" title="Download PDF">pdf</a>, <a href="/format/2310.13572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unraveling the Enigma of Double Descent: An In-depth Analysis through  the Lens of Learned Feature Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yufei Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiaoqing Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Aste%2C+T">Tomaso Aste</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14768" title="Abstract">arXiv:2310.14768</a> (replaced) [<a href="/pdf/2310.14768" title="Download PDF">pdf</a>, <a href="/format/2310.14768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Policy Gradient with Kernel Quadrature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hayakawa%2C+S">Satoshi Hayakawa</a>, 
<a href="/search/cs?searchtype=author&query=Morimura%2C+T">Tetsuro Morimura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15478" title="Abstract">arXiv:2310.15478</a> (replaced) [<a href="/pdf/2310.15478" title="Download PDF">pdf</a>, <a href="/format/2310.15478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Train Your Neural Control Barrier Function: Learning Safety  Filters for Complex Input-Constrained Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=So%2C+O">Oswin So</a>, 
<a href="/search/math?searchtype=author&query=Serlin%2C+Z">Zachary Serlin</a>, 
<a href="/search/math?searchtype=author&query=Mann%2C+M">Makai Mann</a>, 
<a href="/search/math?searchtype=author&query=Gonzales%2C+J">Jake Gonzales</a>, 
<a href="/search/math?searchtype=author&query=Rutledge%2C+K">Kwesi Rutledge</a>, 
<a href="/search/math?searchtype=author&query=Roy%2C+N">Nicholas Roy</a>, 
<a href="/search/math?searchtype=author&query=Fan%2C+C">Chuchu Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA 2024. Project page can be found at <a href="https://mit-realm.github.io/pncbf">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16546" title="Abstract">arXiv:2310.16546</a> (replaced) [<a href="/pdf/2310.16546" title="Download PDF">pdf</a>, <a href="/format/2310.16546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pitfall of Optimism: Distributional Reinforcement Learning by  Randomizing Risk Criterion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+T">Taehyun Cho</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Seungyub Han</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Heesoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kyungjae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jungwoo Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16570" title="Abstract">arXiv:2310.16570</a> (replaced) [<a href="/pdf/2310.16570" title="Download PDF">pdf</a>, <a href="/format/2310.16570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Give Me the Facts! A Survey on Factual Knowledge Probing in Pre-trained  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Youssef%2C+P">Paul Youssef</a>, 
<a href="/search/cs?searchtype=author&query=Kora%C5%9F%2C+O+A">Osman Alperen Kora&#x15f;</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Meijie Li</a>, 
<a href="/search/cs?searchtype=author&query=Schl%C3%B6tterer%2C+J">J&#xf6;rg Schl&#xf6;tterer</a>, 
<a href="/search/cs?searchtype=author&query=Seifert%2C+C">Christin Seifert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP Findings 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17951" title="Abstract">arXiv:2310.17951</a> (replaced) [<a href="/pdf/2310.17951" title="Download PDF">pdf</a>, <a href="/format/2310.17951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Parameter Saliency via Extreme Value Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+I">Issei Sato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18351" title="Abstract">arXiv:2310.18351</a> (replaced) [<a href="/pdf/2310.18351" title="Download PDF">pdf</a>, <a href="/ps/2310.18351" title="Download PostScript">ps</a>, <a href="/format/2310.18351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BioImage.IO Chatbot: A Personalized Assistant for BioImage Analysis  Augmented by Community Knowledge Base
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+W">Wanlu Lei</a>, 
<a href="/search/cs?searchtype=author&query=Fuster-Barcel%C3%B3%2C+C">Caterina Fuster-Barcel&#xf3;</a>, 
<a href="/search/cs?searchtype=author&query=Mu%C3%B1oz-Barrutia%2C+A">Arrate Mu&#xf1;oz-Barrutia</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wei Ouyang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18428" title="Abstract">arXiv:2310.18428</a> (replaced) [<a href="/pdf/2310.18428" title="Download PDF">pdf</a>, <a href="/ps/2310.18428" title="Download PostScript">ps</a>, <a href="/format/2310.18428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Bayesian Stability Zoo
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moran%2C+S">Shay Moran</a>, 
<a href="/search/cs?searchtype=author&query=Schefler%2C+H">Hilla Schefler</a>, 
<a href="/search/cs?searchtype=author&query=Shafer%2C+J">Jonathan Shafer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v2, minor typo fix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18784" title="Abstract">arXiv:2310.18784</a> (replaced) [<a href="/pdf/2310.18784" title="Download PDF">pdf</a>, <a href="/format/2310.18784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-probability Convergence Bounds for Nonlinear Stochastic Gradient  Descent Under Heavy-tailed Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Armacki%2C+A">Aleksandar Armacki</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+P">Pranay Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+G">Gauri Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Bajovic%2C+D">Dragana Bajovic</a>, 
<a href="/search/cs?searchtype=author&query=Jakovetic%2C+D">Dusan Jakovetic</a>, 
<a href="/search/cs?searchtype=author&query=Kar%2C+S">Soummya Kar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19535" title="Abstract">arXiv:2310.19535</a> (replaced) [<a href="/pdf/2310.19535" title="Download PDF">pdf</a>, <a href="/format/2310.19535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revitalizing Legacy Video Content: Deinterlacing with Bidirectional  Information Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhaowei Gao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Mingyang Song</a>, 
<a href="/search/cs?searchtype=author&query=Schroers%2C+C">Christopher Schroers</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20138" title="Abstract">arXiv:2310.20138</a> (replaced) [<a href="/pdf/2310.20138" title="Download PDF">pdf</a>, <a href="/format/2310.20138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DEPN: Detecting and Editing Privacy Neurons in Pretrained Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xinwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junzhuo Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Minghui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+W">Weilong Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shuangzhi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+C">Chao Bian</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+D">Deyi Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20204" title="Abstract">arXiv:2310.20204</a> (replaced) [<a href="/pdf/2310.20204" title="Download PDF">pdf</a>, <a href="/format/2310.20204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> General-Purpose Retrieval-Enhanced Medical Prediction Model Using  Near-Infinite History
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Junu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Shim%2C+C">Chaeeun Shim</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B+S+K">Bosco Seong Kyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Im%2C+C">Chami Im</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+S+Y">Sung Yoon Lim</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+H">Han-Gil Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+E">Edward Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The source codes corresponding to this paper are available at: <a href="https://github.com/starmpcc/REMed">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00230" title="Abstract">arXiv:2311.00230</a> (replaced) [<a href="/pdf/2311.00230" title="Download PDF">pdf</a>, <a href="/format/2311.00230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DINO-Mix: Enhancing Visual Place Recognition with Foundational Vision  Model and Feature Mixing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gaoshuang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaofei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenglong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Luying Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+W">Wenjian Gan</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+M">Mingbo Hou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review / Open source code
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00613" title="Abstract">arXiv:2311.00613</a> (replaced) [<a href="/pdf/2311.00613" title="Download PDF">pdf</a>, <a href="/format/2311.00613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controllable Music Production with Diffusion Models and Guidance  Gradients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Levy%2C+M">Mark Levy</a>, 
<a href="/search/cs?searchtype=author&query=Di+Giorgi%2C+B">Bruno Di Giorgi</a>, 
<a href="/search/cs?searchtype=author&query=Weers%2C+F">Floris Weers</a>, 
<a href="/search/cs?searchtype=author&query=Katharopoulos%2C+A">Angelos Katharopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Nickson%2C+T">Tom Nickson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01164" title="Abstract">arXiv:2311.01164</a> (replaced) [<a href="/pdf/2311.01164" title="Download PDF">pdf</a>, <a href="/format/2311.01164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Insight Into SEER
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lekan%2C+K">Kasra Lekan</a>, 
<a href="/search/cs?searchtype=author&query=Choquette%2C+N">Nicki Choquette</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02495" title="Abstract">arXiv:2311.02495</a> (replaced) [<a href="/pdf/2311.02495" title="Download PDF">pdf</a>, <a href="/ps/2311.02495" title="Download PostScript">ps</a>, <a href="/format/2311.02495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Quantification in Multivariable Regression for Material  Property Prediction with Bayesian Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Longze Li</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+J">Jiang Chang</a>, 
<a href="/search/cs?searchtype=author&query=Vakanski%2C+A">Aleksandar Vakanski</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yachun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+T">Tiankai Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+M">Min Xian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Materials Science (cond-mat.mtrl-sci)

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03191" title="Abstract">arXiv:2311.03191</a> (replaced) [<a href="/pdf/2311.03191" title="Download PDF">pdf</a>, <a href="/format/2311.03191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepInception: Hypnotize Large Language Model to Be Jailbreaker
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhanke Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jianing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiangchao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tongliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bo Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03236" title="Abstract">arXiv:2311.03236</a> (replaced) [<a href="/pdf/2311.03236" title="Download PDF">pdf</a>, <a href="/format/2311.03236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Out-of-distribution Detection Learning with Unreliable  Out-of-distribution Sources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Haotian Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qizhou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhen Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xiaobo Xia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Feng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tongliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bo Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04923" title="Abstract">arXiv:2311.04923</a> (replaced) [<a href="/pdf/2311.04923" title="Download PDF">pdf</a>, <a href="/format/2311.04923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is one brick enough to break the wall of spoken dialogue state tracking?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Druart%2C+L">Lucas Druart</a> (LIA), 
<a href="/search/cs?searchtype=author&query=Vielzeuf%2C+V">Valentin Vielzeuf</a>, 
<a href="/search/cs?searchtype=author&query=Est%C3%A8ve%2C+Y">Yannick Est&#xe8;ve</a> (LIA)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Bug found in previous version, ongoing work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05197" title="Abstract">arXiv:2311.05197</a> (replaced) [<a href="/pdf/2311.05197" title="Download PDF">pdf</a>, <a href="/ps/2311.05197" title="Download PostScript">ps</a>, <a href="/format/2311.05197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning in Computed Tomography Pulmonary Angiography Imaging: A  Dual-Pronged Approach for Pulmonary Embolism Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bushra%2C+F">Fabiha Bushra</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+M+E+H">Muhammad E. H. Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Sarmun%2C+R">Rusab Sarmun</a>, 
<a href="/search/cs?searchtype=author&query=Kabir%2C+S">Saidul Kabir</a>, 
<a href="/search/cs?searchtype=author&query=Said%2C+M">Menatalla Said</a>, 
<a href="/search/cs?searchtype=author&query=Zoghoul%2C+S+B">Sohaib Bassam Zoghoul</a>, 
<a href="/search/cs?searchtype=author&query=Mushtak%2C+A">Adam Mushtak</a>, 
<a href="/search/cs?searchtype=author&query=Al-Hashimi%2C+I">Israa Al-Hashimi</a>, 
<a href="/search/cs?searchtype=author&query=Alqahtani%2C+A">Abdulrahman Alqahtani</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+A">Anwarul Hasan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 13 figures, Submitted to Expert Systems With Applications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05440" title="Abstract">arXiv:2311.05440</a> (replaced) [<a href="/pdf/2311.05440" title="Download PDF">pdf</a>, <a href="/format/2311.05440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Practical Approach to Novel Class Discovery in Tabular Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Troisemaine%2C+C">Colin Troisemaine</a>, 
<a href="/search/cs?searchtype=author&query=Reiffers-Masson%2C+A">Alexandre Reiffers-Masson</a>, 
<a href="/search/cs?searchtype=author&query=Gosselin%2C+S">St&#xe9;phane Gosselin</a>, 
<a href="/search/cs?searchtype=author&query=Lemaire%2C+V">Vincent Lemaire</a>, 
<a href="/search/cs?searchtype=author&query=Vaton%2C+S">Sandrine Vaton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, including 3 pages of annexes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07822" title="Abstract">arXiv:2311.07822</a> (replaced) [<a href="/pdf/2311.07822" title="Download PDF">pdf</a>, <a href="/format/2311.07822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Central Motor System Inspired Pre-training Reinforcement Learning for  Robotic Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+Z">Zhaobo Hua</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jinliang Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07964" title="Abstract">arXiv:2311.07964</a> (replaced) [<a href="/pdf/2311.07964" title="Download PDF">pdf</a>, <a href="/ps/2311.07964" title="Download PostScript">ps</a>, <a href="/format/2311.07964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Surveying Wikipedians: a dataset of users and contributors&#x27; practices on  Wikipedia in 8 languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cruciani%2C+C">Caterina Cruciani</a>, 
<a href="/search/cs?searchtype=author&query=Joubert%2C+L">L&#xe9;o Joubert</a> (LEST, DySoLab), 
<a href="/search/cs?searchtype=author&query=Jullien%2C+N">Nicolas Jullien</a> (IMT Atlantique - LUSSI, MARSOUIN, LEGO), 
<a href="/search/cs?searchtype=author&query=Mell%2C+L">Laurent Mell</a> (CREAD, MARSOUIN), 
<a href="/search/cs?searchtype=author&query=Piccione%2C+S">Sasha Piccione</a>, 
<a href="/search/cs?searchtype=author&query=Vermeirsche%2C+J">Jeanne Vermeirsche</a> (AU)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07989" title="Abstract">arXiv:2311.07989</a> (replaced) [<a href="/pdf/2311.07989" title="Download PDF">pdf</a>, <a href="/format/2311.07989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unifying the Perspectives of NLP and Software Engineering: A Survey on  Language Models for Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziyin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaoyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bingchang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+C">Cong Liao</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Z">Zi Gong</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Repo is available at <a href="https://github.com/codefuse-ai/Awesome-Code-LLM.">this https URL</a> 8 figures, 9 tables, and 694 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08843" title="Abstract">arXiv:2311.08843</a> (replaced) [<a href="/pdf/2311.08843" title="Download PDF">pdf</a>, <a href="/format/2311.08843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalized Video Relighting With an At-Home Light Stage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+J+M">Jun Myeong Choi</a>, 
<a href="/search/cs?searchtype=author&query=Christman%2C+M">Max Christman</a>, 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+R">Roni Sengupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09655" title="Abstract">arXiv:2311.09655</a> (replaced) [<a href="/pdf/2311.09655" title="Download PDF">pdf</a>, <a href="/format/2311.09655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-View Spectrogram Transformer for Respiratory Sound Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+W">Wentao He</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yuchen Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jianfeng Ren</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+R">Ruibin Bai</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xudong Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10515" title="Abstract">arXiv:2311.10515</a> (replaced) [<a href="/pdf/2311.10515" title="Download PDF">pdf</a>, <a href="/format/2311.10515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometric Fiber Classification of Morphisms and a Geometric Approach to  Cylindrical Algebraic Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+R">Rizeng Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages (32 pages on theory, 5 pages on application and 6 pages on analysis), many figures. Comments are welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Geometry (math.AG)</span>; Symbolic Computation (cs.SC); Commutative Algebra (math.AC)

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11567" title="Abstract">arXiv:2311.11567</a> (replaced) [<a href="/pdf/2311.11567" title="Download PDF">pdf</a>, <a href="/format/2311.11567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InfiMM-Eval: Complex Open-Ended Reasoning Evaluation For Multi-Modal  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaotian Han</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Q">Quanzeng You</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yongfei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wentao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Huangjie Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Mrini%2C+K">Khalil Mrini</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xudong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+B">Bohan Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jianbo Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Heng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongxia Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11602" title="Abstract">arXiv:2311.11602</a> (replaced) [<a href="/e-print/2311.11602" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-In-Single-Out Network for Video Frame Interpolation without  Optical Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaemin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+M">Minseok Seo</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sangwoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Hyobin Park</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+D">Dong-Geol Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Discovering a problem with the manuscript
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11905" title="Abstract">arXiv:2311.11905</a> (replaced) [<a href="/pdf/2311.11905" title="Download PDF">pdf</a>, <a href="/ps/2311.11905" title="Download PostScript">ps</a>, <a href="/format/2311.11905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Surface-to-Air Missile Engagement Zone Prediction Using  Simulation and Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dantas%2C+J+P+A">Joao P. A. Dantas</a>, 
<a href="/search/cs?searchtype=author&query=Geraldo%2C+D">Diego Geraldo</a>, 
<a href="/search/cs?searchtype=author&query=Medeiros%2C+F+L+L">Felipe L. L. Medeiros</a>, 
<a href="/search/cs?searchtype=author&query=Maximo%2C+M+R+O+A">Marcos R. O. A. Maximo</a>, 
<a href="/search/cs?searchtype=author&query=Yoneyama%2C+T">Takashi Yoneyama</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12188" title="Abstract">arXiv:2311.12188</a> (replaced) [<a href="/pdf/2311.12188" title="Download PDF">pdf</a>, <a href="/ps/2311.12188" title="Download PostScript">ps</a>, <a href="/format/2311.12188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT and post-test probability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weisenthal%2C+S+J">Samuel J. Weisenthal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 138 pages, 4 tables. Updated abstract, methods, affiliations, and acknowledgements
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12886" title="Abstract">arXiv:2311.12886</a> (replaced) [<a href="/pdf/2311.12886" title="Download PDF">pdf</a>, <a href="/format/2311.12886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnimateAnything: Fine-Grained Open Domain Image Animation with Motion  Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+Z">Zuozhuo Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenghao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+B">Bingxue Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Siyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+L">Long Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weizhi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13307" title="Abstract">arXiv:2311.13307</a> (replaced) [<a href="/pdf/2311.13307" title="Download PDF">pdf</a>, <a href="/format/2311.13307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Radiology Report Generation via Causal Reasoning and  Counterfactual Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xiao Song</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiafan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yun Li</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+W">Wenbin Lei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruxin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages,5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13890" title="Abstract">arXiv:2311.13890</a> (replaced) [<a href="/pdf/2311.13890" title="Download PDF">pdf</a>, <a href="/format/2311.13890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical bounds on the Crouzeix ratio for a class of matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Michel%2C+C">Crouzeix Michel</a> (IRMAR), 
<a href="/search/math?searchtype=author&query=Anne%2C+G">Greenbaum Anne</a>, 
<a href="/search/math?searchtype=author&query=Kenan%2C+L">Li Kenan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14062" title="Abstract">arXiv:2311.14062</a> (replaced) [<a href="/pdf/2311.14062" title="Download PDF">pdf</a>, <a href="/format/2311.14062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hardware Resilience Properties of Text-Guided Image Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wasim%2C+S+T">Syed Talal Wasim</a>, 
<a href="/search/cs?searchtype=author&query=Soboka%2C+K+H">Kabila Haile Soboka</a>, 
<a href="/search/cs?searchtype=author&query=Mahmoud%2C+A">Abdulrahman Mahmoud</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Salman Khan</a>, 
<a href="/search/cs?searchtype=author&query=Brooks%2C+D">David Brooks</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+G">Gu-Yeon Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15138" title="Abstract">arXiv:2311.15138</a> (replaced) [<a href="/pdf/2311.15138" title="Download PDF">pdf</a>, <a href="/format/2311.15138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can SAM recognize crops? Quantifying the zero-shot performance of a  semantic segmentation foundation model on generating crop-type maps using  satellite imagery for precision agriculture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gurav%2C+R">Rutuja Gurav</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+H">Het Patel</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+Z">Zhuocheng Shang</a>, 
<a href="/search/cs?searchtype=author&query=Eldawy%2C+A">Ahmed Eldawy</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jia Chen</a>, 
<a href="/search/cs?searchtype=author&query=Scudiero%2C+E">Elia Scudiero</a>, 
<a href="/search/cs?searchtype=author&query=Papalexakis%2C+E">Evangelos Papalexakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023 AI for Science Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15218" title="Abstract">arXiv:2311.15218</a> (replaced) [<a href="/pdf/2311.15218" title="Download PDF">pdf</a>, <a href="/format/2311.15218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Online Stock Forecasting Utilizing Integrated Quantitative and  Qualitative Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bathini%2C+S+A">Sai Akash Bathini</a>, 
<a href="/search/cs?searchtype=author&query=Cihan%2C+D">Dagli Cihan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15260" title="Abstract">arXiv:2311.15260</a> (replaced) [<a href="/pdf/2311.15260" title="Download PDF">pdf</a>, <a href="/format/2311.15260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuRAD: Neural Rendering for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tonderski%2C+A">Adam Tonderski</a>, 
<a href="/search/cs?searchtype=author&query=Lindstr%C3%B6m%2C+C">Carl Lindstr&#xf6;m</a>, 
<a href="/search/cs?searchtype=author&query=Hess%2C+G">Georg Hess</a>, 
<a href="/search/cs?searchtype=author&query=Ljungbergh%2C+W">William Ljungbergh</a>, 
<a href="/search/cs?searchtype=author&query=Svensson%2C+L">Lennart Svensson</a>, 
<a href="/search/cs?searchtype=author&query=Petersson%2C+C">Christoffer Petersson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15776" title="Abstract">arXiv:2311.15776</a> (replaced) [<a href="/pdf/2311.15776" title="Download PDF">pdf</a>, <a href="/format/2311.15776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable Segment Anything Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Q">Qi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+X">Xin Tao</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+L">Lei Ke</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+M">Mingqiao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+P">Pengfei Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+Y">Yu-Wing Tai</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chi-Keung Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Smaller file size for the easy access. Codes will be released upon acceptance. <a href="https://github.com/fanq15/Stable-SAM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16473" title="Abstract">arXiv:2311.16473</a> (replaced) [<a href="/pdf/2311.16473" title="Download PDF">pdf</a>, <a href="/format/2311.16473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GS-IR: 3D Gaussian Splatting for Inverse Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zhihao Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Ying Feng</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+K">Kui Jia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16495" title="Abstract">arXiv:2311.16495</a> (replaced) [<a href="/pdf/2311.16495" title="Download PDF">pdf</a>, <a href="/format/2311.16495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Egocentric Whole-Body Motion Capture with FisheyeViT and Diffusion-Based  Motion Refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhe Cao</a>, 
<a href="/search/cs?searchtype=author&query=Luvizon%2C+D">Diogo Luvizon</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+K">Kripasindhu Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+D">Danhang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Beeler%2C+T">Thabo Beeler</a>, 
<a href="/search/cs?searchtype=author&query=Theobalt%2C+C">Christian Theobalt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16512" title="Abstract">arXiv:2311.16512</a> (replaced) [<a href="/pdf/2311.16512" title="Download PDF">pdf</a>, <a href="/format/2311.16512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoSeR: Bridging Image and Language for Cognitive Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haoze Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenbo Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianzhuang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haoyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+R">Renjing Pei</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xueyi Zou</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Youliang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujiu Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://coser-main.github.io">this https URL</a> ; GitHub repository: <a href="https://github.com/VINHYU/CoSeR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16926" title="Abstract">arXiv:2311.16926</a> (replaced) [<a href="/pdf/2311.16926" title="Download PDF">pdf</a>, <a href="/format/2311.16926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLaFS: When Large-Language Models Meet Few-Shot Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lanyun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianrun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+D">Deyi Ji</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jieping Ye</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16989" title="Abstract">arXiv:2311.16989</a> (replaced) [<a href="/pdf/2311.16989" title="Download PDF">pdf</a>, <a href="/format/2311.16989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT&#x27;s One-year Anniversary: Are Open-Source Large Language Models  Catching up?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hailin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+F">Fangkai Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+C">Chengwei Qin</a>, 
<a href="/search/cs?searchtype=author&query=Ravaut%2C+M">Mathieu Ravaut</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Ruochen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Caiming Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Joty%2C+S">Shafiq Joty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> version v3
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17074" title="Abstract">arXiv:2311.17074</a> (replaced) [<a href="/pdf/2311.17074" title="Download PDF">pdf</a>, <a href="/format/2311.17074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Learning of Whole and Component-Based Semantic  Representations for Person Re-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Siyuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yifan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Kathirvel%2C+R+P">Ram Prabhakar Kathirvel</a>, 
<a href="/search/cs?searchtype=author&query=Chellappa%2C+R">Rama Chellappa</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+C+P">Chun Pong Lau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17431" title="Abstract">arXiv:2311.17431</a> (replaced) [<a href="/pdf/2311.17431" title="Download PDF">pdf</a>, <a href="/format/2311.17431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grounding Foundation Models through Federated Transfer Learning: A  General Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yan Kang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+T">Tao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hanlin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lixin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qiang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In progress. fixed some typos, errors, and revised the text a little bit
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17932" title="Abstract">arXiv:2311.17932</a> (replaced) [<a href="/pdf/2311.17932" title="Download PDF">pdf</a>, <a href="/format/2311.17932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Molecular Conformer Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Wang%2C+Y">Yuyang Wang</a>, 
<a href="/search/physics?searchtype=author&query=Elhag%2C+A+A">Ahmed A. Elhag</a>, 
<a href="/search/physics?searchtype=author&query=Jaitly%2C+N">Navdeep Jaitly</a>, 
<a href="/search/physics?searchtype=author&query=Susskind%2C+J+M">Joshua M. Susskind</a>, 
<a href="/search/physics?searchtype=author&query=Bautista%2C+M+A">Miguel Angel Bautista</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 11 figures. arXiv admin note: text overlap with <a href="/abs/2305.15586">arXiv:2305.15586</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18593" title="Abstract">arXiv:2311.18593</a> (replaced) [<a href="/pdf/2311.18593" title="Download PDF">pdf</a>, <a href="/format/2311.18593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Old Idea: Beam-Steering Reflectarrays for Efficient Sub-THz  Multiuser MIMO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tiwari%2C+K+K">Krishan Kumar Tiwari</a>, 
<a href="/search/eess?searchtype=author&query=Caire%2C+G">Giuseppe Caire</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18674" title="Abstract">arXiv:2311.18674</a> (replaced) [<a href="/pdf/2311.18674" title="Download PDF">pdf</a>, <a href="/format/2311.18674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable and Lightweight Post-Quantum Authentication for Internet of  Things
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yavuz%2C+A+A">Attila A. Yavuz</a>, 
<a href="/search/cs?searchtype=author&query=Darzi%2C+S">Saleh Darzi</a>, 
<a href="/search/cs?searchtype=author&query=Nouma%2C+S+E">Saif E. Nouma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18743" title="Abstract">arXiv:2311.18743</a> (replaced) [<a href="/pdf/2311.18743" title="Download PDF">pdf</a>, <a href="/format/2311.18743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AlignBench: Benchmarking Chinese Alignment of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+X">Xuanyu Lei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shengyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yue Huang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhuoer Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+B">Bosi Wen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jiale Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+P">Pei Ke</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yifan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tam%2C+W+L">Weng Lam Tam</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaohan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongning Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Minlie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuxiao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jie Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18826" title="Abstract">arXiv:2311.18826</a> (replaced) [<a href="/pdf/2311.18826" title="Download PDF">pdf</a>, <a href="/format/2311.18826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometry-Aware Normalizing Wasserstein Flows for Optimal Causal  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+K">Kaiwen Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18828" title="Abstract">arXiv:2311.18828</a> (replaced) [<a href="/pdf/2311.18828" title="Download PDF">pdf</a>, <a href="/format/2311.18828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-step Diffusion with Distribution Matching Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+T">Tianwei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Gharbi%2C+M">Micha&#xeb;l Gharbi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Richard Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shechtman%2C+E">Eli Shechtman</a>, 
<a href="/search/cs?searchtype=author&query=Durand%2C+F">Fredo Durand</a>, 
<a href="/search/cs?searchtype=author&query=Freeman%2C+W+T">William T. Freeman</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+T">Taesung Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://tianweiy.github.io/dmd/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00072" title="Abstract">arXiv:2312.00072</a> (replaced) [<a href="/pdf/2312.00072" title="Download PDF">pdf</a>, <a href="/format/2312.00072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CRAFT: Contextual Re-Activation of Filters for face recognition Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhatta%2C+A">Aman Bhatta</a>, 
<a href="/search/cs?searchtype=author&query=Mery%2C+D">Domingo Mery</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haiyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Bowyer%2C+K+W">Kevin W. Bowyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00564" title="Abstract">arXiv:2312.00564</a> (replaced) [<a href="/pdf/2312.00564" title="Download PDF">pdf</a>, <a href="/format/2312.00564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Discontinuous Strain Method: accurately representing fatigue and  failure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herrmann%2C+L">Leon Herrmann</a>, 
<a href="/search/cs?searchtype=author&query=Daneshyar%2C+A">Alireza Daneshyar</a>, 
<a href="/search/cs?searchtype=author&query=Kollmannsberger%2C+S">Stefan Kollmannsberger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00839" title="Abstract">arXiv:2312.00839</a> (replaced) [<a href="/pdf/2312.00839" title="Download PDF">pdf</a>, <a href="/format/2312.00839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PipeOptim: Ensuring Effective 1F1B Schedule with Optimizer-Dependent  Weight Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+L">Lei Guan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jiye Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xicheng Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00878" title="Abstract">arXiv:2312.00878</a> (replaced) [<a href="/pdf/2312.00878" title="Download PDF">pdf</a>, <a href="/format/2312.00878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grounding Everything: Emerging Localization Properties in  Vision-Language Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bousselham%2C+W">Walid Bousselham</a>, 
<a href="/search/cs?searchtype=author&query=Petersen%2C+F">Felix Petersen</a>, 
<a href="/search/cs?searchtype=author&query=Ferrari%2C+V">Vittorio Ferrari</a>, 
<a href="/search/cs?searchtype=author&query=Kuehne%2C+H">Hilde Kuehne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code available at <a href="https://github.com/WalBouss/GEM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00886" title="Abstract">arXiv:2312.00886</a> (replaced) [<a href="/pdf/2312.00886" title="Download PDF">pdf</a>, <a href="/format/2312.00886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nash Learning from Human Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Munos%2C+R">R&#xe9;mi Munos</a>, 
<a href="/search/stat?searchtype=author&query=Valko%2C+M">Michal Valko</a>, 
<a href="/search/stat?searchtype=author&query=Calandriello%2C+D">Daniele Calandriello</a>, 
<a href="/search/stat?searchtype=author&query=Azar%2C+M+G">Mohammad Gheshlaghi Azar</a>, 
<a href="/search/stat?searchtype=author&query=Rowland%2C+M">Mark Rowland</a>, 
<a href="/search/stat?searchtype=author&query=Guo%2C+Z+D">Zhaohan Daniel Guo</a>, 
<a href="/search/stat?searchtype=author&query=Tang%2C+Y">Yunhao Tang</a>, 
<a href="/search/stat?searchtype=author&query=Geist%2C+M">Matthieu Geist</a>, 
<a href="/search/stat?searchtype=author&query=Mesnard%2C+T">Thomas Mesnard</a>, 
<a href="/search/stat?searchtype=author&query=Michi%2C+A">Andrea Michi</a>, 
<a href="/search/stat?searchtype=author&query=Selvi%2C+M">Marco Selvi</a>, 
<a href="/search/stat?searchtype=author&query=Girgin%2C+S">Sertan Girgin</a>, 
<a href="/search/stat?searchtype=author&query=Momchev%2C+N">Nikola Momchev</a>, 
<a href="/search/stat?searchtype=author&query=Bachem%2C+O">Olivier Bachem</a>, 
<a href="/search/stat?searchtype=author&query=Mankowitz%2C+D+J">Daniel J. Mankowitz</a>, 
<a href="/search/stat?searchtype=author&query=Precup%2C+D">Doina Precup</a>, 
<a href="/search/stat?searchtype=author&query=Piot%2C+B">Bilal Piot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01003" title="Abstract">arXiv:2312.01003</a> (replaced) [<a href="/pdf/2312.01003" title="Download PDF">pdf</a>, <a href="/format/2312.01003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Evolving Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jung%2C+J">Jaewoo Jung</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jisang Han</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiwon Kang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seongchan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kwak%2C+M">Min-Seop Kwak</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungryong Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 21 figures Our project page can be found at : <a href="https://ku-cvlab.github.io/SE-NeRF/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01179" title="Abstract">arXiv:2312.01179</a> (replaced) [<a href="/e-print/2312.01179" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The time dimensional reduction method to determine the initial  conditions for nonlinear and nonlocal hyperbolic equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dang%2C+T+D">Trong D. Dang</a>, 
<a href="/search/math?searchtype=author&query=Nguyen%2C+L+H">Loc H. Nguyen</a>, 
<a href="/search/math?searchtype=author&query=Vu%2C+H+T+T">Huong T. T. Vu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> I will submit a better version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01203" title="Abstract">arXiv:2312.01203</a> (replaced) [<a href="/pdf/2312.01203" title="Download PDF">pdf</a>, <a href="/format/2312.01203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing Discrete Representations For Continual Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meyer%2C+E">Edan Meyer</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+A">Adam White</a>, 
<a href="/search/cs?searchtype=author&query=Machado%2C+M+C">Marlos C. Machado</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 16 figures, submitted to ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01232" title="Abstract">arXiv:2312.01232</a> (replaced) [<a href="/pdf/2312.01232" title="Download PDF">pdf</a>, <a href="/format/2312.01232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Study of Vision Transformers in Image Classification  Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khalil%2C+M">Mahmoud Khalil</a>, 
<a href="/search/cs?searchtype=author&query=Khalil%2C+A">Ahmad Khalil</a>, 
<a href="/search/cs?searchtype=author&query=Ngom%2C+A">Alioune Ngom</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2012.06567">arXiv:2012.06567</a>, <a href="/abs/1406.6247">arXiv:1406.6247</a>, <a href="/abs/1906.05909">arXiv:1906.05909</a> by other authors. arXiv admin note: text overlap with <a href="/abs/2012.06567">arXiv:2012.06567</a>, <a href="/abs/1406.6247">arXiv:1406.6247</a>, <a href="/abs/1906.05909">arXiv:1906.05909</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01239" title="Abstract">arXiv:2312.01239</a> (replaced) [<a href="/pdf/2312.01239" title="Download PDF">pdf</a>, <a href="/format/2312.01239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion Informed Needle Segmentation in Ultrasound Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Goel%2C+R">Raghavv Goel</a>, 
<a href="/search/eess?searchtype=author&query=Morales%2C+C">Cecilia Morales</a>, 
<a href="/search/eess?searchtype=author&query=Singh%2C+M">Manpreet Singh</a>, 
<a href="/search/eess?searchtype=author&query=Dubrawski%2C+A">Artur Dubrawski</a>, 
<a href="/search/eess?searchtype=author&query=Galeotti%2C+J">John Galeotti</a>, 
<a href="/search/eess?searchtype=author&query=Choset%2C+H">Howie Choset</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01384" title="Abstract">arXiv:2312.01384</a> (replaced) [<a href="/pdf/2312.01384" title="Download PDF">pdf</a>, <a href="/format/2312.01384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Tight Lower Bound for 3-Coloring Grids in the Online-LOCAL Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yi-Jun Chang</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+G">Gopinath Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+H">Thuan Hung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mingyang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+Y">Yu-Cheng Yeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01529" title="Abstract">arXiv:2312.01529</a> (replaced) [<a href="/pdf/2312.01529" title="Download PDF">pdf</a>, <a href="/format/2312.01529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> T3D: Towards 3D Medical Image Understanding through Vision-Language  Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Che Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+C">Cheng Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yinda Chen</a>, 
<a href="/search/cs?searchtype=author&query=Quilodr%C3%A1n-Casas%2C+C+C">Cesar C&#xe9;sar Quilodr&#xe1;n-Casas</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yike Guo</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Anand Shah</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+W">Wenjia Bai</a>, 
<a href="/search/cs?searchtype=author&query=Arcucci%2C+R">Rossella Arcucci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01550" title="Abstract">arXiv:2312.01550</a> (replaced) [<a href="/pdf/2312.01550" title="Download PDF">pdf</a>, <a href="/format/2312.01550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using human and robot synthetic data for training smart hand tools
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bendana%2C+J">Jose Bendana</a>, 
<a href="/search/cs?searchtype=author&query=S.%2C+S+S+V">Sundar Sripada V. S.</a>, 
<a href="/search/cs?searchtype=author&query=Salazar%2C+C+D">Carlos D. Salazar</a>, 
<a href="/search/cs?searchtype=author&query=Chinchali%2C+S">Sandeep Chinchali</a>, 
<a href="/search/cs?searchtype=author&query=Longoria%2C+R+G">Raul G. Longoria</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In submission at ICRA 2024; added acknowledgements
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01554" title="Abstract">arXiv:2312.01554</a> (replaced) [<a href="/pdf/2312.01554" title="Download PDF">pdf</a>, <a href="/format/2312.01554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building Ears for Robots: Machine Hearing in the Age of Autonomy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+X">Xuan Zhong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures. The materials covered in this article were presented and discussed at the Hearing Seminar at Stanford University organized by Malcolm Slaney in October, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Robotics (cs.RO); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01583" title="Abstract">arXiv:2312.01583</a> (replaced) [<a href="/pdf/2312.01583" title="Download PDF">pdf</a>, <a href="/format/2312.01583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Collision Detection Oriented Motion Primitives for Path  Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=DallaLibera%2C+F">Fabio DallaLibera</a>, 
<a href="/search/cs?searchtype=author&query=Abe%2C+S">Shinya Abe</a>, 
<a href="/search/cs?searchtype=author&query=Ando%2C+T">Takeshi Ando</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01606" title="Abstract">arXiv:2312.01606</a> (replaced) [<a href="/pdf/2312.01606" title="Download PDF">pdf</a>, <a href="/ps/2312.01606" title="Download PostScript">ps</a>, <a href="/format/2312.01606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-Driven Enhancement of Welding Quality Control: Predicting  Welding Depth and Pore Volume in Hairpin Welding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Darwish%2C+A">Amena Darwish</a>, 
<a href="/search/cs?searchtype=author&query=Ericson%2C+S">Stefan Ericson</a>, 
<a href="/search/cs?searchtype=author&query=Ghasemi%2C+R">Rohollah Ghasemi</a>, 
<a href="/search/cs?searchtype=author&query=Andersson%2C+T">Tobias Andersson</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B6nn%2C+D">Dan L&#xf6;nn</a>, 
<a href="/search/cs?searchtype=author&query=Lassila%2C+A+A">Andreas Andersson Lassila</a>, 
<a href="/search/cs?searchtype=author&query=Salomonsson%2C+K">Kent Salomonsson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01656" title="Abstract">arXiv:2312.01656</a> (replaced) [<a href="/pdf/2312.01656" title="Download PDF">pdf</a>, <a href="/format/2312.01656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Contemporary Art of Image Search: Iterative User Intent Expansion  via Vision-Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yilin Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qian Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+S">Shishi Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Wei Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by The 2024 ACM SIGCHI Conference on Computer-Supported Cooperative Work &amp; Social Computing (CSCW) (Proc. CSCW 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01677" title="Abstract">arXiv:2312.01677</a> (replaced) [<a href="/e-print/2312.01677" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-task Image Restoration Guided By Robust DINO Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+C">Chao Ren</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+K+C+K">Kelvin C.K. Chan</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+L">Lu Qi</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jinshan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Some important information need to add
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01678" title="Abstract">arXiv:2312.01678</a> (replaced) [<a href="/pdf/2312.01678" title="Download PDF">pdf</a>, <a href="/format/2312.01678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jellyfish: A Large Language Model for Data Preprocessing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haochen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuyang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chuan Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Oyamada%2C+M">Masafumi Oyamada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Databases (cs.DB); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01697" title="Abstract">arXiv:2312.01697</a> (replaced) [<a href="/pdf/2312.01697" title="Download PDF">pdf</a>, <a href="/format/2312.01697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hulk: A Universal Knowledge Translator for Human-Centric Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yizhou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yixuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shixiang Tang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+W">Weizhen He</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Feng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+L">Lei Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tong He</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01709" title="Abstract">arXiv:2312.01709</a> (replaced) [<a href="/pdf/2312.01709" title="Download PDF">pdf</a>, <a href="/ps/2312.01709" title="Download PostScript">ps</a>, <a href="/format/2312.01709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Challenging Curve Fitting Benchmark Test Set for Global  Optimization Solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cheng%2C+P">Peicong Cheng</a>, 
<a href="/search/math?searchtype=author&query=Cheng%2C+P">Peicheng Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Mathematical Software (cs.MS); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01912" title="Abstract">arXiv:2312.01912</a> (replaced) [<a href="/pdf/2312.01912" title="Download PDF">pdf</a>, <a href="/ps/2312.01912" title="Download PostScript">ps</a>, <a href="/format/2312.01912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource Leak Checker (RLC#) for C# Code using CodeQL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gharat%2C+P">Pritam Gharat</a>, 
<a href="/search/cs?searchtype=author&query=Shadab%2C+N">Narges Shadab</a>, 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+S">Shrey Tiwari</a>, 
<a href="/search/cs?searchtype=author&query=Lahiri%2C+S">Shuvendu Lahiri</a>, 
<a href="/search/cs?searchtype=author&query=Lal%2C+A">Akash Lal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02087" title="Abstract">arXiv:2312.02087</a> (replaced) [<a href="/pdf/2312.02087" title="Download PDF">pdf</a>, <a href="/format/2312.02087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VideoSwap: Customized Video Subject Swapping with Interactive Semantic  Point Correspondence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuchao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yipin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bichen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Licheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jia-Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J+Z">Jay Zhangjie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D+J">David Junhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+K">Kevin Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page at <a href="https://videoswap.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02111" title="Abstract">arXiv:2312.02111</a> (replaced) [<a href="/pdf/2312.02111" title="Download PDF">pdf</a>, <a href="/format/2312.02111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TriDeNT: Triple Deep Network Training for Privileged Knowledge  Distillation in Histopathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farndale%2C+L">Lucas Farndale</a>, 
<a href="/search/cs?searchtype=author&query=Insall%2C+R">Robert Insall</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+K">Ke Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Tissues and Organs (q-bio.TO)

</div>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02143" title="Abstract">arXiv:2312.02143</a> (replaced) [<a href="/pdf/2312.02143" title="Download PDF">pdf</a>, <a href="/format/2312.02143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Competition-Level Problems are Effective LLM Evaluators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yiming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhenghao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yeyun Gong</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shuai Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+F">Fangyu Lei</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yaobo Liang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yelong Shen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+N">Nan Duan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weizhu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item365">Cross-lists</a></li>
<li><a href="#item408">Replacements</a></li>
</ul>
<small>[ total of 627 entries:  <b>1-627</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2312">2312</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
