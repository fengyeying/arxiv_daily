<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Tue  5 Dec 23  to  Wed  6 Dec 23, announced Thu,  7 Dec 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item310">Cross-lists</a></li>
<li><a href="#item357">Replacements</a></li>
</ul>
<small>[ total of 561 entries:  <b>1-561</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Thu,  7 Dec 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02984" title="Abstract">arXiv:2312.02984</a> [<a href="/pdf/2312.02984" title="Download PDF">pdf</a>, <a href="/format/2312.02984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diff-GO: Diffusion Goal-Oriented Communications to Achieve Ultra-High  Spectrum Efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wijesinghe%2C+A">Achintha Wijesinghe</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Songyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wanninayaka%2C+S">Suchinthaka Wanninayaka</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zhi Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE International Conference on Communications (ICC) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM); Signal Processing (eess.SP)

</div>
<p class="mathjax">The latest advances in artificial intelligence (AI) present many
unprecedented opportunities to achieve much improved bandwidth saving in
communications. Unlike conventional communication systems focusing on packet
transport, rich datasets and AI makes it possible to efficiently transfer only
the information most critical to the goals of message recipients. One of the
most exciting advances in generative AI known as diffusion model presents a
unique opportunity for designing ultra-fast communication systems well beyond
language-based messages. This work presents an ultra-efficient communication
design by utilizing generative AI-based on diffusion models as a specific
example of the general goal-oriented communication framework. To better control
the regenerated message at the receiver output, our diffusion system design
includes a local regeneration module with finite dimensional noise latent. The
critical significance of noise latent control and sharing residing on our
Diff-GO is the ability to introduce the concept of "local generative feedback"
(Local-GF), which enables the transmitter to monitor the quality and gauge the
quality or accuracy of the message recovery at the semantic system receiver. To
this end, we propose a new low-dimensional noise space for the training of
diffusion models, which significantly reduces the communication overhead and
achieves satisfactory message recovery performance. Our experimental results
demonstrate that the proposed noise space and the diffusion-based generative
model achieve ultra-high spectrum efficiency and accurate recovery of
transmitted image signals. By trading off computation for bandwidth efficiency
(C4BE), this new framework provides an important avenue to achieve exceptional
computation-bandwidth tradeoff.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02985" title="Abstract">arXiv:2312.02985</a> [<a href="/pdf/2312.02985" title="Download PDF">pdf</a>, <a href="/format/2312.02985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FocalPose++: Focal Length and Object Pose Estimation via Render and  Compare
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=C%C3%ADfka%2C+M">Martin C&#xed;fka</a>, 
<a href="/search/cs?searchtype=author&query=Ponimatkin%2C+G">Georgy Ponimatkin</a>, 
<a href="/search/cs?searchtype=author&query=Labb%C3%A9%2C+Y">Yann Labb&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Russell%2C+B">Bryan Russell</a>, 
<a href="/search/cs?searchtype=author&query=Aubry%2C+M">Mathieu Aubry</a>, 
<a href="/search/cs?searchtype=author&query=Petrik%2C+V">Vladimir Petrik</a>, 
<a href="/search/cs?searchtype=author&query=Sivic%2C+J">Josef Sivic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 18 figures. arXiv admin note: substantial text overlap with <a href="/abs/2204.05145">arXiv:2204.05145</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce FocalPose++, a neural render-and-compare method for jointly
estimating the camera-object 6D pose and camera focal length given a single RGB
input image depicting a known object. The contributions of this work are
threefold. First, we derive a focal length update rule that extends an existing
state-of-the-art render-and-compare 6D pose estimator to address the joint
estimation task. Second, we investigate several different loss functions for
jointly estimating the object pose and focal length. We find that a combination
of direct focal length regression with a reprojection loss disentangling the
contribution of translation, rotation, and focal length leads to improved
results. Third, we explore the effect of different synthetic training data on
the performance of our method. Specifically, we investigate different
distributions used for sampling object's 6D pose and camera's focal length when
rendering the synthetic images, and show that parametric distribution fitted on
real training data works the best. We show results on three challenging
benchmark datasets that depict known 3D models in uncontrolled settings. We
demonstrate that our focal length and 6D pose estimates have lower error than
the existing state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02988" title="Abstract">arXiv:2312.02988</a> [<a href="/pdf/2312.02988" title="Download PDF">pdf</a>, <a href="/format/2312.02988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Subgraph Isomorphism Finding in Large Graphs using  Eccentricity and Limiting Recursive Calls
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ansari%2C+Z+A">Zubair Ali Ansari</a>, 
<a href="/search/cs?searchtype=author&query=Abulaish%2C+M">Muhammad Abulaish</a>, 
<a href="/search/cs?searchtype=author&query=Thoker%2C+I+R">Irfan Rashid Thoker</a>, 
<a href="/search/cs?searchtype=author&query=Jahiruddin">Jahiruddin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">The subgraph isomorphism finding problem is a well-studied problem in the
field of computer science and graph theory, and it aims to enumerate all
instances of a query graph in the respective data graph. In this paper, we
propose an efficient method, SubISO, to find subgraph isomorphisms using an
objective function, which exploits some isomorphic invariants and eccentricity
of the query graph's vertices. The proposed objective function is used to
determine pivot vertex, which minimizes both number and size of the candidate
regions in the data graph. SubISO also limits the maximum recursive calls of
the generic SubgraphSearch function to deal with straggler queries for which
most of the existing algorithms show exponential behaviour. The proposed
approach is evaluated over three benchmark datasets. It is also compared with
three well known subgraph isomorphism finding algorithms in terms of execution
time, number of identified embeddings, and ability to deal with the straggler
queries, and it performs significantly better.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02991" title="Abstract">arXiv:2312.02991</a> [<a href="/pdf/2312.02991" title="Download PDF">pdf</a>, <a href="/format/2312.02991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> REFRESH FPGAs: Sustainable FPGA Chiplet Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Peipei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+J">Jinming Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Cahoon%2C+S">Stephen Cahoon</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yue Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhuoping Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xingzhen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yiyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jingtong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+A+K">Alex K. Jones</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">There is a growing call for greater amounts of increasingly agile
computational power for edge and cloud infrastructure to serve the
computationally complex needs of ubiquitous computing devices. Thus, an
important challenge is addressing the holistic environmental impacts of these
next-generation computing systems. To accomplish this, a life-cycle view of
sustainability for computing advancements is necessary to reduce environmental
impacts such as greenhouse warming gas emissions from these computing choices.
Unfortunately, decadal efforts to address operational energy efficiency in
computing devices have ignored and in some cases exacerbated embodied impacts
from manufacturing these edge and cloud systems, particularly their integrated
circuits. During this time FPGA architectures have not changed dramatically
except to increase in size. Given this context, we propose REFRESH FPGAs to
build new FPGA devices and architectures from recently retired FPGA dies using
2.5D integration. To build REFRESH FPGAs requires creative architectures that
leverage existing chiplet pins with an inexpensive to-manufacture interposer
coupled with creative design automation. In this paper, we discuss how REFRESH
FPGAs can leverage industry trends for renewable energy integration into data
centers while providing an overall improvement for sustainability and
amortizing their significant embodied cost investment over a much longer
``first'' lifetime.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02992" title="Abstract">arXiv:2312.02992</a> [<a href="/pdf/2312.02992" title="Download PDF">pdf</a>, <a href="/ps/2312.02992" title="Download PostScript">ps</a>, <a href="/format/2312.02992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Web Accessibility -- A guide to transitioning Design Systems  from WCAG 2.0 to WCAG 2.1
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+H">Hardik Shah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 figures, 15th International Conference on Web services &amp; Semantic Technology (WeST 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">This research focuses on the critical process of upgrading a Design System
from Web Content Accessibility Guidelines (WCAG) 2.0 to WCAG 2.1, which is an
essential step in enhancing web accessibility. It emphasizes the importance of
staying up to date on increasing accessibility requirements, as well as the
critical function of Design Systems in supporting inclusion in digital
environments. The article lays out a complete strategy for meeting WCAG 2.1
compliance. Assessment, strategic planning, implementation, and testing are all
part of this strategy. The need for collaboration and user involvement is
emphasized as critical strategies and best practices for a successful migration
journey. In addition, the article digs into migration barriers and discusses
significant lessons acquired, offering a realistic view of the intricacies of
this transforming road. Finally, it is a practical guide and a necessary
resource for organizations committed to accessible and user-centered design.
The document provides them with the knowledge and resources they need to
navigate the changing world of web accessibility properly.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02993" title="Abstract">arXiv:2312.02993</a> [<a href="/pdf/2312.02993" title="Download PDF">pdf</a>, <a href="/format/2312.02993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZTCloudGuard: Zero Trust Context-Aware Access Management Framework to  Avoid Misuse Cases in the Era of Generative AI and Cloud-based Health  Information Ecosystem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Al-hammuri%2C+K">Khalid Al-hammuri</a>, 
<a href="/search/cs?searchtype=author&query=Gebali%2C+F">Fayez Gebali</a>, 
<a href="/search/cs?searchtype=author&query=Kanan%2C+A">Awos Kanan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Managing access between large numbers of distributed medical devices has
become a crucial aspect of modern healthcare systems, enabling the
establishment of smart hospitals and telehealth infrastructure. However, as
telehealth technology continues to evolve and Internet of Things (IoT) devices
become more widely used, they are also becoming increasingly exposed to various
types of vulnerabilities and medical errors. In healthcare information systems,
about 90\% of vulnerabilities emerged from misuse cases and human errors. As a
result, there is a need for additional research and development of security
tools to prevent such attacks. This article proposes a zero-trust-based
context-aware framework for managing access to the main components of the cloud
ecosystem, including users, devices and output data. The main goal and benefit
of the proposed framework is to build a scoring system to prevent or alleviate
misuse cases while using distributed medical devices in cloud-based healthcare
information systems. The framework has two main scoring schemas to maintain the
chain of trust. First, it proposes a critical trust score based on cloud-native
micro-services of authentication, encryption, logging, and authorizations.
Second, creating a bond trust scoring to assess the real-time semantic and
syntactic analysis of attributes stored in a healthcare information system. The
analysis is based on a pre-trained machine learning model to generate the
semantic and syntactic scores. The framework also takes into account regulatory
compliance and user consent to create a scoring system. The advantage of this
method is that it is applicable to any language and adapts to all attributes as
it relies on a language model, not just a set of predefined and limited
attributes. The results show a high F1 score of 93.5%, which proves that it is
valid for detecting misuse cases.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02995" title="Abstract">arXiv:2312.02995</a> [<a href="/pdf/2312.02995" title="Download PDF">pdf</a>, <a href="/ps/2312.02995" title="Download PostScript">ps</a>, <a href="/format/2312.02995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Literature Review on the Studies of MR Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aiersilan%2C+A">Aizierjiang Aiersilan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">In the world reference context, though mixed reality have been an emerging
methodology for several years, only today technological and scientific advances
have made them suitable to revolutionize in the industry and among people's
daily life through the provision of enhanced functionalities and improved
services. This systematic review provides the state-of-the-art applications and
utilities of the Microsoft HoloLens 2 by reviewing the related papers during
2022-2023. Focusing on the potential that this technology has in providing
digitally supported simulations and other utilities, highlighting the potential
and limitations of the HoloLens 2-based innovative solutions and also bringing
focus to emerging research topics, such as telemedicine, remote control and
optimization of direct volume rendering.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02996" title="Abstract">arXiv:2312.02996</a> [<a href="/pdf/2312.02996" title="Download PDF">pdf</a>, <a href="/ps/2312.02996" title="Download PostScript">ps</a>, <a href="/format/2312.02996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Relation Algebra for Term Rewriting: A differential approach to  sequential reduction (Revised Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pace%2C+L">Lorenzo Pace</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Recently, Gavazzo has developed a relational theory of symbolic manipulation,
that allows to study syntax-based rewriting systems without relying on specific
notions of syntax. This theory was obtained by extending the algebra of
relations with syntax-inspired operators. Within the algebras thus obtained, it
is possible to encode notions of parallel and full reduction for first-order
rewriting systems, as well as to prove nontrivial properties about them in an
algebraic and syntax-independent fashion. Sequential reduction, however, was
not explored, but it was conjectured that it could be studied through a
differential relational theory of rewriting. This manuscript proves the above
conjecture by defining differential algebras of term relations, viz. algebras
of term relations extended with novel operators inspired by the theory of
functor derivatives. We give a set of axioms and rules for such operators and
show that the resulting theory is expressive enough to define notions of
parallel, full, and sequential reduction. We prove fundamental results relating
all these notions in a purely algebraic and syntax-independent way, and
showcase the effectiveness of our theory by proving the soundness of a proof
technique for weak confluence akin to the so-called Critical Pair Lemma.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02998" title="Abstract">arXiv:2312.02998</a> [<a href="/pdf/2312.02998" title="Download PDF">pdf</a>, <a href="/format/2312.02998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personality of AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Byunggu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Junwhan Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This research paper delves into the evolving landscape of fine-tuning large
language models (LLMs) to align with human users, extending beyond basic
alignment to propose "personality alignment" for language models in
organizational settings. Acknowledging the impact of training methods on the
formation of undefined personality traits in AI models, the study draws
parallels with human fitting processes using personality tests. Through an
original case study, we demonstrate the necessity of personality fine-tuning
for AIs and raise intriguing questions about applying human-designed tests to
AIs, engineering specialized AI personality tests, and shaping AI personalities
to suit organizational roles. The paper serves as a starting point for
discussions and developments in the burgeoning field of AI personality
alignment, offering a foundational anchor for future exploration in
human-machine teaming and co-existence.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02999" title="Abstract">arXiv:2312.02999</a> [<a href="/pdf/2312.02999" title="Download PDF">pdf</a>, <a href="/format/2312.02999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Incremental Potential Contact for Actuated Face Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lingchen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Solenthaler%2C+B">Barbara Solenthaler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGGRAPH Asia 2023 Technical Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">We present a quasi-static finite element simulator for human face animation.
We model the face as an actuated soft body, which can be efficiently simulated
using Projective Dynamics (PD). We adopt Incremental Potential Contact (IPC) to
handle self-intersection. However, directly integrating IPC into the simulation
would impede the high efficiency of the PD solver, since the stiffness matrix
in the global step is no longer constant and cannot be pre-factorized. We
notice that the actual number of vertices affected by the collision is only a
small fraction of the whole model, and by utilizing this fact we effectively
decrease the scale of the linear system to be solved. With the proposed
optimization method for collision, we achieve high visual fidelity at a
relatively low performance overhead.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03000" title="Abstract">arXiv:2312.03000</a> [<a href="/pdf/2312.03000" title="Download PDF">pdf</a>, <a href="/format/2312.03000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VidereX: A Navigational Application inspired by ants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koh%2C+N+H">Nam Ho Koh</a>, 
<a href="/search/cs?searchtype=author&query=Amos%2C+D">Doran Amos</a>, 
<a href="/search/cs?searchtype=author&query=Graham%2C+P">Paul Graham</a>, 
<a href="/search/cs?searchtype=author&query=Philippides%2C+A">Andrew Philippides</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 7 figures, Workshop on Rapid and Robust Robotic Active Learning (R3AL) - Robotics: Science and Systems 2023 (RSS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Navigation is a crucial element in any person's life, whether for work,
education, social living or any other miscellaneous reason; naturally, the
importance of it is universally recognised and valued. One of the critical
components of navigation is vision, which facilitates movement from one place
to another. Navigating unfamiliar settings, especially for the blind or
visually impaired, can pose significant challenges, impacting their
independence and quality of life. Current assistive travel solutions have
shortcomings, including GPS limitations and a demand for an efficient,
user-friendly, and portable model. Addressing these concerns, this paper
presents VidereX: a smartphone-based solution using an ant-inspired navigation
algorithm. Emulating ants' ability to learn a route between nest and feeding
grounds after a single traversal, VidereX enables users to rapidly acquire
navigational data using a one/few-shot learning strategy. A key component of
VidereX is its emphasis on active user engagement. Like ants with a scanning
behaviour to actively investigate their environment, users wield the camera,
actively exploring the visual landscape. Far from the passive reception of
data, this process constitutes a dynamic exploration, echoing nature's
navigational mechanisms.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03002" title="Abstract">arXiv:2312.03002</a> [<a href="/pdf/2312.03002" title="Download PDF">pdf</a>, <a href="/format/2312.03002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The mechanistic basis of data dependence and abrupt learning in an  in-context classification task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reddy%2C+G">Gautam Reddy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Transformer models exhibit in-context learning: the ability to accurately
predict the response to a novel query based on illustrative examples in the
input sequence. In-context learning contrasts with traditional in-weights
learning of query-output relationships. What aspects of the training data
distribution and architecture favor in-context vs in-weights learning? Recent
work has shown that specific distributional properties inherent in language,
such as burstiness, large dictionaries and skewed rank-frequency distributions,
control the trade-off or simultaneous appearance of these two forms of
learning. We first show that these results are recapitulated in a minimal
attention-only network trained on a simplified dataset. In-context learning
(ICL) is driven by the abrupt emergence of an induction head, which
subsequently competes with in-weights learning. By identifying progress
measures that precede in-context learning and targeted experiments, we
construct a two-parameter model of an induction head which emulates the full
data distributional dependencies displayed by the attention-based network. A
phenomenological model of induction head formation traces its abrupt emergence
to the sequential learning of three nested logits enabled by an intrinsic
curriculum. We propose that the sharp transitions in attention-based networks
arise due to a specific chain of multi-layer operations necessary to achieve
ICL, which is implemented by nested nonlinearities sequentially learned during
training.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03003" title="Abstract">arXiv:2312.03003</a> [<a href="/pdf/2312.03003" title="Download PDF">pdf</a>, <a href="/format/2312.03003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explore, Select, Derive, and Recall: Augmenting LLM with Human-like  Memory for Mobile Task Automation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sunjae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Junyoung Choi</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jungjae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+H">Hojun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+S+Y">Steven Y. Ko</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+S">Sangeun Oh</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+I">Insik Shin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">The advent of large language models (LLMs) has opened up new opportunities in
the field of mobile task automation. Their superior language understanding and
reasoning capabilities allow users to automate complex and repetitive tasks.
However, due to the inherent unreliability and high operational cost of LLMs,
their practical applicability is quite limited. To address these issues, this
paper introduces MemoDroid, an innovative LLM-based mobile task automator
enhanced with a unique app memory. MemoDroid emulates the cognitive process of
humans interacting with a mobile app -- explore, select, derive, and recall.
This approach allows for a more precise and efficient learning of a task's
procedure by breaking it down into smaller, modular components that can be
re-used, re-arranged, and adapted for various objectives. We implement
MemoDroid using online LLMs services (GPT-3.5 and GPT-4) and evaluate its
performance on 50 unique mobile tasks across 5 widely used mobile apps. The
results indicate that MemoDroid can adapt learned tasks to varying contexts
with 100% accuracy and reduces their latency and cost by 69.22% and 77.36%
compared to a GPT-4 powered baseline.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03004" title="Abstract">arXiv:2312.03004</a> [<a href="/pdf/2312.03004" title="Download PDF">pdf</a>, <a href="/format/2312.03004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Multi-graph Structure for Temporal Knowledge Graph Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinchuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+B">Bei Hui</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+C">Chong Mu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+L">Ling Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Temporal Knowledge Graph (TKG) reasoning that forecasts future events based
on historical snapshots distributed over timestamps is denoted as extrapolation
and has gained significant attention. Owing to its extreme versatility and
variation in spatial and temporal correlations, TKG reasoning presents a
challenging task, demanding efficient capture of concurrent structures and
evolutional interactions among facts. While existing methods have made strides
in this direction, they still fall short of harnessing the diverse forms of
intrinsic expressive semantics of TKGs, which encompass entity correlations
across multiple timestamps and periodicity of temporal information. This
limitation constrains their ability to thoroughly reflect historical
dependencies and future trends. In response to these drawbacks, this paper
proposes an innovative reasoning approach that focuses on Learning Multi-graph
Structure (LMS). Concretely, it comprises three distinct modules concentrating
on multiple aspects of graph structure knowledge within TKGs, including
concurrent and evolutional patterns along timestamps, query-specific
correlations across timestamps, and semantic dependencies of timestamps, which
capture TKG features from various perspectives. Besides, LMS incorporates an
adaptive gate for merging entity representations both along and across
timestamps effectively. Moreover, it integrates timestamp semantics into graph
attention calculations and time-aware decoders, in order to impose temporal
constraints on events and narrow down prediction scopes with historical
statistics. Extensive experimental results on five event-based benchmark
datasets demonstrate that LMS outperforms state-of-the-art extrapolation
models, indicating the superiority of modeling a multi-graph perspective for
TKG reasoning.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03005" title="Abstract">arXiv:2312.03005</a> [<a href="/pdf/2312.03005" title="Download PDF">pdf</a>, <a href="/format/2312.03005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-Shot Anomaly Detection with Adversarial Loss for Robust Feature  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+Y">Jae Young Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+W">Wonjun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jaehyun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yongkwi Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+Y+S">Young Seog Yoon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> BMVC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Anomaly detection is a critical and challenging task that aims to identify
data points deviating from normal patterns and distributions within a dataset.
Various methods have been proposed using a one-class-one-model approach, but
these techniques often face practical problems such as memory inefficiency and
the requirement of sufficient data for training. In particular, few-shot
anomaly detection presents significant challenges in industrial applications,
where limited samples are available before mass production. In this paper, we
propose a few-shot anomaly detection method that integrates adversarial
training loss to obtain more robust and generalized feature representations. We
utilize the adversarial loss previously employed in domain adaptation to align
feature distributions between source and target domains, to enhance feature
robustness and generalization in few-shot anomaly detection tasks. We
hypothesize that adversarial loss is effective when applied to features that
should have similar characteristics, such as those from the same layer in a
Siamese network's parallel branches or input-output pairs of
reconstruction-based methods. Experimental results demonstrate that the
proposed method generally achieves better performance when utilizing the
adversarial loss.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03006" title="Abstract">arXiv:2312.03006</a> [<a href="/pdf/2312.03006" title="Download PDF">pdf</a>, <a href="/format/2312.03006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cone Ranking for Multi-Criteria Decision Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamel%2C+A+H">Andreas H Hamel</a>, 
<a href="/search/cs?searchtype=author&query=Kostner%2C+D">Daniel Kostner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
<p class="mathjax">Recently introduced cone distribution functions from statistics are turned
into multi-criteria decision making (MCDM) tools. It is demonstrated that this
procedure can be considered as an upgrade of the weighted sum scalarization
insofar as it absorbs a whole collection of weighted sum scalarizations at once
instead of fixing a particular one in advance. Moreover, situations are
characterized in which different types of rank reversal occur, and it is
explained why this might even be useful for analyzing the ranking procedure. A
few examples will be discussed and a potential application in machine learning
is outlined.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03008" title="Abstract">arXiv:2312.03008</a> [<a href="/pdf/2312.03008" title="Download PDF">pdf</a>, <a href="/format/2312.03008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning for Community Battery Scheduling under  Uncertainties of Load, PV Generation, and Energy Prices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jiarong Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 7th IEEE Conference on Energy Internet and Energy System Integration (EI2 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
<p class="mathjax">In response to the growing uptake of distributed energy resources (DERs),
community batteries have emerged as a promising solution to support renewable
energy integration, reduce peak load, and enhance grid reliability. This paper
presents a deep reinforcement learning (RL) strategy, centered around the soft
actor-critic (SAC) algorithm, to schedule a community battery system in the
presence of uncertainties, such as solar photovoltaic (PV) generation, local
demand, and real-time energy prices. We position the community battery to play
a versatile role, in integrating local PV energy, reducing peak load, and
exploiting energy price fluctuations for arbitrage, thereby minimizing the
system cost. To improve exploration and convergence during RL training, we
utilize the noisy network technique. This paper conducts a comparative study of
different RL algorithms, including proximal policy optimization (PPO) and deep
deterministic policy gradient (DDPG) algorithms, to evaluate their
effectiveness in the community battery scheduling problem. The results
demonstrate the potential of RL in addressing community battery scheduling
challenges and show that the SAC algorithm achieves the best performance
compared to RL and optimization benchmarks.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03009" title="Abstract">arXiv:2312.03009</a> [<a href="/pdf/2312.03009" title="Download PDF">pdf</a>, <a href="/format/2312.03009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> I-PHYRE: Interactive Physical Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shiqian Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kewen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yixin Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Current evaluation protocols predominantly assess physical reasoning in
stationary scenes, creating a gap in evaluating agents' abilities to interact
with dynamic events. While contemporary methods allow agents to modify initial
scene configurations and observe consequences, they lack the capability to
interact with events in real time. To address this, we introduce I-PHYRE, a
framework that challenges agents to simultaneously exhibit intuitive physical
reasoning, multi-step planning, and in-situ intervention. Here, intuitive
physical reasoning refers to a quick, approximate understanding of physics to
address complex problems; multi-step denotes the need for extensive sequence
planning in I-PHYRE, considering each intervention can significantly alter
subsequent choices; and in-situ implies the necessity for timely object
manipulation within a scene, where minor timing deviations can result in task
failure. We formulate four game splits to scrutinize agents' learning and
generalization of essential principles of interactive physical reasoning,
fostering learning through interaction with representative scenarios. Our
exploration involves three planning strategies and examines several supervised
and reinforcement agents' zero-shot generalization proficiency on I-PHYRE. The
outcomes highlight a notable gap between existing learning algorithms and human
performance, emphasizing the imperative for more research in enhancing agents
with interactive physical reasoning capabilities. The environment and baselines
will be made publicly available.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03011" title="Abstract">arXiv:2312.03011</a> [<a href="/pdf/2312.03011" title="Download PDF">pdf</a>, <a href="/format/2312.03011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InstructBooth: Instruction-following Personalized Text-to-Image  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chae%2C+D">Daewon Chae</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+N">Nokyung Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jinkyu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kimin Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Personalizing text-to-image models using a limited set of images for a
specific object has been explored in subject-specific image generation.
However, existing methods often encounter challenges in aligning with text
prompts due to overfitting to the limited training images. In this work, we
introduce InstructBooth, a novel method designed to enhance image-text
alignment in personalized text-to-image models. Our approach first personalizes
text-to-image models with a small number of subject-specific images using a
unique identifier. After personalization, we fine-tune personalized
text-to-image models using reinforcement learning to maximize a reward that
quantifies image-text alignment. Additionally, we propose complementary
techniques to increase the synergy between these two processes. Our method
demonstrates superior image-text alignment compared to baselines while
maintaining personalization ability. In human evaluations, InstructBooth
outperforms DreamBooth when considering all comprehensive factors.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03014" title="Abstract">arXiv:2312.03014</a> [<a href="/pdf/2312.03014" title="Download PDF">pdf</a>, <a href="/format/2312.03014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foundation Models for Weather and Climate Data Understanding: A  Comprehensive Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shengchao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+G">Guodong Long</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jing Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dikai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chengqi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Ongoing work. Survey Paper. 35 pages, 2 figures, 4 tables. The first work to comprehensively and systematically summarize DL-based weather and climate data understanding, paving the way for the development of weather and climate foundation models
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">As artificial intelligence (AI) continues to rapidly evolve, the realm of
Earth and atmospheric sciences is increasingly adopting data-driven models,
powered by progressive developments in deep learning (DL). Specifically, DL
techniques are extensively utilized to decode the chaotic and nonlinear aspects
of Earth systems, and to address climate challenges via understanding weather
and climate data. Cutting-edge performance on specific tasks within narrower
spatio-temporal scales has been achieved recently through DL. The rise of large
models, specifically large language models (LLMs), has enabled fine-tuning
processes that yield remarkable outcomes across various downstream tasks,
thereby propelling the advancement of general AI. However, we are still
navigating the initial stages of crafting general AI for weather and climate.
In this survey, we offer an exhaustive, timely overview of state-of-the-art AI
methodologies specifically engineered for weather and climate data, with a
special focus on time series and text data. Our primary coverage encompasses
four critical aspects: types of weather and climate data, principal model
architectures, model scopes and applications, and datasets for weather and
climate. Furthermore, in relation to the creation and application of foundation
models for weather and climate data understanding, we delve into the field's
prevailing challenges, offer crucial insights, and propose detailed avenues for
future research. This comprehensive approach equips practitioners with the
requisite knowledge to make substantial progress in this domain. Our survey
encapsulates the most recent breakthroughs in research on large, data-driven
models for weather and climate data understanding, emphasizing robust
foundations, current advancements, practical applications, crucial resources,
and prospective research opportunities.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03015" title="Abstract">arXiv:2312.03015</a> [<a href="/pdf/2312.03015" title="Download PDF">pdf</a>, <a href="/format/2312.03015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PartSLIP++: Enhancing Low-Shot 3D Part Segmentation via Multi-View  Instance Segmentation and Maximum Likelihood Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuchen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiayuan Gu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuanlin Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Minghua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yunhao Fang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hao Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Open-world 3D part segmentation is pivotal in diverse applications such as
robotics and AR/VR. Traditional supervised methods often grapple with limited
3D data availability and struggle to generalize to unseen object categories.
PartSLIP, a recent advancement, has made significant strides in zero- and
few-shot 3D part segmentation. This is achieved by harnessing the capabilities
of the 2D open-vocabulary detection module, GLIP, and introducing a heuristic
method for converting and lifting multi-view 2D bounding box predictions into
3D segmentation masks. In this paper, we introduce PartSLIP++, an enhanced
version designed to overcome the limitations of its predecessor. Our approach
incorporates two major improvements. First, we utilize a pre-trained 2D
segmentation model, SAM, to produce pixel-wise 2D segmentations, yielding more
precise and accurate annotations than the 2D bounding boxes used in PartSLIP.
Second, PartSLIP++ replaces the heuristic 3D conversion process with an
innovative modified Expectation-Maximization algorithm. This algorithm
conceptualizes 3D instance segmentation as unobserved latent variables, and
then iteratively refines them through an alternating process of 2D-3D matching
and optimization with gradient descent. Through extensive evaluations, we show
that PartSLIP++ demonstrates better performance over PartSLIP in both low-shot
3D semantic and instance-based object part segmentation tasks. Code released at
https://github.com/zyc00/PartSLIP2.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03017" title="Abstract">arXiv:2312.03017</a> [<a href="/pdf/2312.03017" title="Download PDF">pdf</a>, <a href="/format/2312.03017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-driven emergence of frequency information non-uniform distribution  via THz metasurface spectrum prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+X">Xiaohua Xing</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yuqi Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+D">Die Zou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiankun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+B">Bingxuan Mao</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jianquan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+D">Deyi Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Liang Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optics (physics.optics)

</div>
<p class="mathjax">Recently, artificial intelligence has been extensively deployed across
various scientific disciplines, optimizing and guiding the progression of
experiments through the integration of abundant datasets, whilst continuously
probing the vast theoretical space encapsulated within the data. Particularly,
deep learning models, due to their end-to-end adaptive learning capabilities,
are capable of autonomously learning intrinsic data features, thereby
transcending the limitations of traditional experience to a certain extent.
Here, we unveil previously unreported information characteristics pertaining to
different frequencies emerged during our work on predicting the terahertz
spectral modulation effects of metasurfaces based on AI-prediction. Moreover,
we have substantiated that our proposed methodology of simply adding
supplementary multi-frequency inputs to the existing dataset during the target
spectral prediction process can significantly enhance the predictive accuracy
of the network. This approach effectively optimizes the utilization of existing
datasets and paves the way for interdisciplinary research and applications in
artificial intelligence, chemistry, composite material design, biomedicine, and
other fields.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03018" title="Abstract">arXiv:2312.03018</a> [<a href="/pdf/2312.03018" title="Download PDF">pdf</a>, <a href="/format/2312.03018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreamVideo: High-Fidelity Image-to-Video Generation with Image Retention  and Text Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiaxi Gu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+P">Panwen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Songcen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaodan Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image-to-video generation, which aims to generate a video starting from a
given reference image, has drawn great attention. Existing methods try to
extend pre-trained text-guided image diffusion models to image-guided video
generation models. Nevertheless, these methods often result in either low
fidelity or flickering over time due to their limitation to shallow image
guidance and poor temporal consistency. To tackle these problems, we propose a
high-fidelity image-to-video generation method by devising a frame retention
branch on the basis of a pre-trained video diffusion model, named DreamVideo.
Instead of integrating the reference image into the diffusion process in a
semantic level, our DreamVideo perceives the reference image via convolution
layers and concatenate the features with the noisy latents as model input. By
this means, the details of the reference image can be preserved to the greatest
extent. In addition, by incorporating double-condition classifier-free
guidance, a single image can be directed to videos of different actions by
providing varying prompt texts. This has significant implications for
controllable video generation and holds broad application prospects. We conduct
comprehensive experiments on the public dataset, both quantitative and
qualitative results indicate that our method outperforms the state-of-the-art
method. Especially for fidelity, our model has powerful image retention ability
and result in high FVD in UCF101 compared to other image-to-video models. Also,
precise control can be achieved by giving different text prompts. Further
details and comprehensive results of our model will be presented in
https://anonymous0769.github.io/DreamVideo/.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03022" title="Abstract">arXiv:2312.03022</a> [<a href="/pdf/2312.03022" title="Download PDF">pdf</a>, <a href="/format/2312.03022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Isolation: Multi-Agent Synergy for Improving Knowledge Graph  Construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Hongbin Ye</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+H">Honghao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Aijia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+W">Wei Hua</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+W">Weiqiang Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in progress; 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Knowledge graph construction (KGC) is a multifaceted undertaking involving
the extraction of entities, relations, and events. Traditionally, large
language models (LLMs) have been viewed as solitary task-solving agents in this
complex landscape. However, this paper challenges this paradigm by introducing
a novel framework, CooperKGC. Departing from the conventional approach,
CooperKGC establishes a collaborative processing network, assembling a KGC
collaboration team capable of concurrently addressing entity, relation, and
event extraction tasks. Our experiments unequivocally demonstrate that
fostering collaboration and information interaction among diverse agents within
CooperKGC yields superior results compared to individual cognitive processes
operating in isolation. Importantly, our findings reveal that the collaboration
facilitated by CooperKGC enhances knowledge selection, correction, and
aggregation capabilities across multiple rounds of interactions.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03024" title="Abstract">arXiv:2312.03024</a> [<a href="/pdf/2312.03024" title="Download PDF">pdf</a>, <a href="/format/2312.03024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Role of Uncertainty in Anticipatory Trajectory Prediction for a  Ping-Pong Playing Robot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahmanian%2C+N">Nima Rahmanian</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+M">Michael Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Soatto%2C+R">Renzo Soatto</a>, 
<a href="/search/cs?searchtype=author&query=Nachuri%2C+S">Srisai Nachuri</a>, 
<a href="/search/cs?searchtype=author&query=Psenka%2C+M">Michael Psenka</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Sastry%2C+S+S">S. Shankar Sastry</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robotic interaction in fast-paced environments presents a substantial
challenge, particularly in tasks requiring the prediction of dynamic,
non-stationary objects for timely and accurate responses. An example of such a
task is ping-pong, where the physical limitations of a robot may prevent it
from reaching its goal in the time it takes the ball to cross the table. The
scene of a ping-pong match contains rich visual information of a player's
movement that can allow future game state prediction, with varying degrees of
uncertainty. To this aim, we present a visual modeling, prediction, and control
system to inform a ping-pong playing robot utilizing visual model uncertainty
to allow earlier motion of the robot throughout the game. We present
demonstrations and metrics in simulation to show the benefit of incorporating
model uncertainty, the limitations of current standard model uncertainty
estimators, and the need for more verifiable model uncertainty estimation. Our
code is publicly available.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03025" title="Abstract">arXiv:2312.03025</a> [<a href="/pdf/2312.03025" title="Download PDF">pdf</a>, <a href="/format/2312.03025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training on Synthetic Data Beats Real Data in Multimodal Relation  Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zilin Du</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boyang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The task of multimodal relation extraction has attracted significant research
attention, but progress is constrained by the scarcity of available training
data. One natural thought is to extend existing datasets with cross-modal
generative models. In this paper, we consider a novel problem setting, where
only unimodal data, either text or image, are available during training. We aim
to train a multimodal classifier from synthetic data that perform well on real
multimodal test data. However, training with synthetic data suffers from two
obstacles: lack of data diversity and label information loss. To alleviate the
issues, we propose Mutual Information-aware Multimodal Iterated Relational dAta
GEneration (MI2RAGE), which applies Chained Cross-modal Generation (CCG) to
promote diversity in the generated data and exploits a teacher network to
select valuable training samples with high mutual information with the
ground-truth labels. Comparing our method to direct training on synthetic data,
we observed a significant improvement of 24.06% F1 with synthetic text and
26.42% F1 with synthetic images. Notably, our best model trained on completely
synthetic images outperforms prior state-of-the-art models trained on real
multimodal data by a margin of 3.76% in F1. Our codebase will be made available
upon acceptance.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03026" title="Abstract">arXiv:2312.03026</a> [<a href="/pdf/2312.03026" title="Download PDF">pdf</a>, <a href="/format/2312.03026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uni3DL: Unified Model for 3D and Language Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jian Ding</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhaoyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Elhoseiny%2C+M">Mohamed Elhoseiny</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this work, we present Uni3DL, a unified model for 3D and Language
understanding. Distinct from existing unified vision-language models in 3D
which are limited in task variety and predominantly dependent on projected
multi-view images, Uni3DL operates directly on point clouds. This approach
significantly expands the range of supported tasks in 3D, encompassing both
vision and vision-language tasks in 3D. At the core of Uni3DL, a query
transformer is designed to learn task-agnostic semantic and mask outputs by
attending to 3D visual features, and a task router is employed to selectively
generate task-specific outputs required for diverse tasks. With a unified
architecture, our Uni3DL model enjoys seamless task decomposition and
substantial parameter sharing across tasks. Uni3DL has been rigorously
evaluated across diverse 3D vision-language understanding tasks, including
semantic segmentation, object detection, instance segmentation, visual
grounding, 3D captioning, and text-3D cross-modal retrieval. It demonstrates
performance on par with or surpassing state-of-the-art (SOTA) task-specific
models. We hope our benchmark and Uni3DL model will serve as a solid step to
ease future research in unified models in the realm of 3D and language
understanding. Project page: https://uni3dl.github.io.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03027" title="Abstract">arXiv:2312.03027</a> [<a href="/pdf/2312.03027" title="Download PDF">pdf</a>, <a href="/format/2312.03027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable Diffusion Exposed: Gender Bias from Prompt to Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yankun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Nakashima%2C+Y">Yuta Nakashima</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+N">Noa Garcia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent studies have highlighted biases in generative models, shedding light
on their predisposition towards gender-based stereotypes and imbalances. This
paper contributes to this growing body of research by introducing an evaluation
protocol designed to automatically analyze the impact of gender indicators on
Stable Diffusion images. Leveraging insights from prior work, we explore how
gender indicators not only affect gender presentation but also the
representation of objects and layouts within the generated images. Our findings
include the existence of differences in the depiction of objects, such as
instruments tailored for specific genders, and shifts in overall layouts. We
also reveal that neutral prompts tend to produce images more aligned with
masculine prompts than their feminine counterparts, providing valuable insights
into the nuanced gender biases inherent in Stable Diffusion.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03029" title="Abstract">arXiv:2312.03029</a> [<a href="/pdf/2312.03029" title="Download PDF">pdf</a>, <a href="/format/2312.03029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Head Avatar: Ultra High-fidelity Head Avatar via Dynamic  Gaussians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuelang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Benwang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lizhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zerong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yebin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Projectpage: <a href="https://yuelangx.github.io/gaussianheadavatar/">this https URL</a>, Code: <a href="https://github.com/YuelangX/Gaussian-Head-Avatar">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Creating high-fidelity 3D head avatars has always been a research hotspot,
but there remains a great challenge under lightweight sparse view setups. In
this paper, we propose Gaussian Head Avatar represented by controllable 3D
Gaussians for high-fidelity head avatar modeling. We optimize the neutral 3D
Gaussians and a fully learned MLP-based deformation field to capture complex
expressions. The two parts benefit each other, thereby our method can model
fine-grained dynamic details while ensuring expression accuracy. Furthermore,
we devise a well-designed geometry-guided initialization strategy based on
implicit SDF and Deep Marching Tetrahedra for the stability and convergence of
the training procedure. Experiments show our approach outperforms other
state-of-the-art sparse-view methods, achieving ultra high-fidelity rendering
quality at 2K resolution even under exaggerated expressions.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03030" title="Abstract">arXiv:2312.03030</a> [<a href="/pdf/2312.03030" title="Download PDF">pdf</a>, <a href="/format/2312.03030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Visually Realistic Adversarial Patch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaosen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kunyu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep neural networks (DNNs) are vulnerable to various types of adversarial
examples, bringing huge threats to security-critical applications. Among these,
adversarial patches have drawn increasing attention due to their good
applicability to fool DNNs in the physical world. However, existing works often
generate patches with meaningless noise or patterns, making it conspicuous to
humans. To address this issue, we explore how to generate visually realistic
adversarial patches to fool DNNs. Firstly, we analyze that a high-quality
adversarial patch should be realistic, position irrelevant, and printable to be
deployed in the physical world. Based on this analysis, we propose an effective
attack called VRAP, to generate visually realistic adversarial patches.
Specifically, VRAP constrains the patch in the neighborhood of a real image to
ensure the visual reality, optimizes the patch at the poorest position for
position irrelevance, and adopts Total Variance loss as well as gamma
transformation to make the generated patch printable without losing
information. Empirical evaluations on the ImageNet dataset demonstrate that the
proposed VRAP exhibits outstanding attack performance in the digital world.
Moreover, the generated adversarial patches can be disguised as the scrawl or
logo in the physical world to fool the deep models without being detected,
bringing significant threats to DNNs-enabled applications.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03031" title="Abstract">arXiv:2312.03031</a> [<a href="/pdf/2312.03031" title="Download PDF">pdf</a>, <a href="/format/2312.03031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is Ego Status All You Need for Open-Loop End-to-End Autonomous Driving?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhiding Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+S">Shiyi Lan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiahan Li</a>, 
<a href="/search/cs?searchtype=author&query=Kautz%2C+J">Jan Kautz</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Alvarez%2C+J+M">Jose M. Alvarez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">End-to-end autonomous driving recently emerged as a promising research
direction to target autonomy from a full-stack perspective. Along this line,
many of the latest works follow an open-loop evaluation setting on nuScenes to
study the planning behavior. In this paper, we delve deeper into the problem by
conducting thorough analyses and demystifying more devils in the details. We
initially observed that the nuScenes dataset, characterized by relatively
simple driving scenarios, leads to an under-utilization of perception
information in end-to-end models incorporating ego status, such as the ego
vehicle's velocity. These models tend to rely predominantly on the ego
vehicle's status for future path planning. Beyond the limitations of the
dataset, we also note that current metrics do not comprehensively assess the
planning quality, leading to potentially biased conclusions drawn from existing
benchmarks. To address this issue, we introduce a new metric to evaluate
whether the predicted trajectories adhere to the road. We further propose a
simple baseline able to achieve competitive results without relying on
perception annotations. Given the current limitations on the benchmark and
metrics, we suggest the community reassess relevant prevailing research and be
cautious whether the continued pursuit of state-of-the-art would yield
convincing and universal conclusions. Code and models are available at
\url{https://github.com/NVlabs/BEV-Planner}
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03032" title="Abstract">arXiv:2312.03032</a> [<a href="/pdf/2312.03032" title="Download PDF">pdf</a>, <a href="/format/2312.03032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Point Cloud Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+G">Guofeng Mei</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+B">Bin Ren</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaoshui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Poiesi%2C+F">Fabio Poiesi</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>, 
<a href="/search/cs?searchtype=author&query=Sebe%2C+N">Nicu Sebe</a>, 
<a href="/search/cs?searchtype=author&query=Lepri%2C+B">Bruno Lepri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learning-based point cloud registration approaches have significantly
outperformed their traditional counterparts. However, they typically require
extensive training on specific datasets. In this paper, we propose , the first
zero-shot point cloud registration approach that eliminates the need for
training on point cloud datasets. The cornerstone of ZeroReg is the novel
transfer of image features from keypoints to the point cloud, enriched by
aggregating information from 3D geometric neighborhoods. Specifically, we
extract keypoints and features from 2D image pairs using a frozen pretrained 2D
backbone. These features are then projected in 3D, and patches are constructed
by searching for neighboring points. We integrate the geometric and visual
features of each point using our novel parameter-free geometric decoder.
Subsequently, the task of determining correspondences between point clouds is
formulated as an optimal transport problem. Extensive evaluations of ZeroReg
demonstrate its competitive performance against both traditional and
learning-based methods. On benchmarks such as 3DMatch, 3DLoMatch, and ScanNet,
ZeroReg achieves impressive Recall Ratios (RR) of over 84%, 46%, and 75%,
respectively.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03033" title="Abstract">arXiv:2312.03033</a> [<a href="/pdf/2312.03033" title="Download PDF">pdf</a>, <a href="/format/2312.03033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiDAR-based Person Re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wenxuan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhiyu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yingping Liang</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+Z">Ziheng Xi</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z+C">Zhi Chen Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jianjiang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Camera-based person re-identification (ReID) systems have been widely applied
in the field of public security. However, cameras often lack the perception of
3D morphological information of human and are susceptible to various
limitations, such as inadequate illumination, complex background, and personal
privacy. In this paper, we propose a LiDAR-based ReID framework, ReID3D, that
utilizes pre-training strategy to retrieve features of 3D body shape and
introduces Graph-based Complementary Enhancement Encoder for extracting
comprehensive features. Due to the lack of LiDAR datasets, we build LReID, the
first LiDAR-based person ReID dataset, which is collected in several outdoor
scenes with variations in natural conditions. Additionally, we introduce
LReID-sync, a simulated pedestrian dataset designed for pre-training encoders
with tasks of point cloud completion and shape parameter learning. Extensive
experiments on LReID show that ReID3D achieves exceptional performance with a
rank-1 accuracy of 94.0, highlighting the significant potential of LiDAR in
addressing person ReID tasks. To the best of our knowledge, we are the first to
propose a solution for LiDAR-based ReID. The code and datasets will be released
soon.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03035" title="Abstract">arXiv:2312.03035</a> [<a href="/pdf/2312.03035" title="Download PDF">pdf</a>, <a href="/format/2312.03035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEVA: Leveraging sketches to evaluate alignment between human and  machine visual abstraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+K">Kushin Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Huey%2C+H">Holly Huey</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xuanchen Lu</a>, 
<a href="/search/cs?searchtype=author&query=Vinker%2C+Y">Yael Vinker</a>, 
<a href="/search/cs?searchtype=author&query=Aguina-Kang%2C+R">Rio Aguina-Kang</a>, 
<a href="/search/cs?searchtype=author&query=Shamir%2C+A">Ariel Shamir</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J+E">Judith E. Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the Advances in Neural Information Processing Systems (Datasets and Benchmarks Track) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Sketching is a powerful tool for creating abstract images that are sparse but
meaningful. Sketch understanding poses fundamental challenges for
general-purpose vision algorithms because it requires robustness to the
sparsity of sketches relative to natural visual inputs and because it demands
tolerance for semantic ambiguity, as sketches can reliably evoke multiple
meanings. While current vision algorithms have achieved high performance on a
variety of visual tasks, it remains unclear to what extent they understand
sketches in a human-like way. Here we introduce SEVA, a new benchmark dataset
containing approximately 90K human-generated sketches of 128 object concepts
produced under different time constraints, and thus systematically varying in
sparsity. We evaluated a suite of state-of-the-art vision algorithms on their
ability to correctly identify the target concept depicted in these sketches and
to generate responses that are strongly aligned with human response patterns on
the same sketch recognition task. We found that vision algorithms that better
predicted human sketch recognition performance also better approximated human
uncertainty about sketch meaning, but there remains a sizable gap between model
and human response patterns. To explore the potential of models that emulate
human visual abstraction in generative tasks, we conducted further evaluations
of a recently developed sketch generation algorithm (Vinker et al., 2022)
capable of generating sketches that vary in sparsity. We hope that public
release of this dataset and evaluation protocol will catalyze progress towards
algorithms with enhanced capacities for human-like visual abstraction.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03037" title="Abstract">arXiv:2312.03037</a> [<a href="/pdf/2312.03037" title="Download PDF">pdf</a>, <a href="/ps/2312.03037" title="Download PostScript">ps</a>, <a href="/format/2312.03037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis and mining of low-carbon and energy-saving tourism data  characteristics based on machine learning algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wierzbinski%2C+L">Lukasz Wierzbinski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In order to study the formation mechanism of residents' low-carbon awareness
and provide an important basis for traffic managers to guide urban residents to
choose low-carbon travel mode, this paper proposes a low-carbon energy-saving
travel data feature analysis and mining based on machine learning algorithm.
This paper uses data mining technology to analyze the data of low-carbon travel
questionnaire, and regards the 15-dimensional problem under the framework of
planned behavior theory as the internal cause variable that characterizes
residents' low-carbon travel willingness. The author uses K-means clustering
algorithm to classify the intensity of residents' low-carbon travel
willingness, and applies the results as the explanatory variables to the random
forest model to explore the mechanism of residents' social attribute
characteristics, travel characteristics, etc. on their low-carbon travel
willingness. The experimental results show that based on the Silhouette index
test and t-SNE dimensionality reduction, residents' low-carbon travel
willingness can be divided into three categories: strong, neutral, and not
strong; Based on the importance index, the four most significant factors are
the occupation, residence, family composition and commuting time of residents.
Conclusion: This method provides policy recommendations for the development and
management of urban traffic low-carbon from multiple perspectives.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03038" title="Abstract">arXiv:2312.03038</a> [<a href="/pdf/2312.03038" title="Download PDF">pdf</a>, <a href="/ps/2312.03038" title="Download PostScript">ps</a>, <a href="/format/2312.03038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample-based Dynamic Hierarchical Transformer with Layer and Head  Flexibility via Contextual Bandit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fanfei Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lele Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, accepted by Proceedings on Engineering Sciences, Vol.6, 2620-2832
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Transformer requires a fixed number of layers and heads which makes them
inflexible to the complexity of individual samples and expensive in training
and inference. To address this, we propose a sample-based Dynamic Hierarchical
Transformer (DHT) model whose layers and heads can be dynamically configured
with single data samples via solving contextual bandit problems. To determine
the number of layers and heads, we use the Uniform Confidence Bound while we
deploy combinatorial Thompson Sampling in order to select specific head
combinations given their number. Different from previous work that focuses on
compressing trained networks for inference only, DHT is not only advantageous
for adaptively optimizing the underlying network architecture during training
but also has a flexible network for efficient inference. To the best of our
knowledge, this is the first comprehensive data-driven dynamic transformer
without any additional auxiliary neural networks that implement the dynamic
system. According to the experiment results, we achieve up to 74% computational
savings for both training and inference with a minimal loss of accuracy.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03041" title="Abstract">arXiv:2312.03041</a> [<a href="/pdf/2312.03041" title="Download PDF">pdf</a>, <a href="/ps/2312.03041" title="Download PostScript">ps</a>, <a href="/format/2312.03041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer-Based Deep Learning Model for Bored Pile Load-Deformation  Prediction in Bangkok Subsoil
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Youwai%2C+S">Sompote Youwai</a>, 
<a href="/search/cs?searchtype=author&query=Thongnoo%2C+C">Chissanupong Thongnoo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">This paper presents a novel deep learning model based on the transformer
architecture to predict the load-deformation behavior of large bored piles in
Bangkok subsoil. The model encodes the soil profile and pile features as
tokenization input, and generates the load-deformation curve as output. The
model also incorporates the previous sequential data of load-deformation curve
into the decoder to improve the prediction accuracy. The model also
incorporates the previous sequential data of load-deformation curve into the
decoder. The model shows a satisfactory accuracy and generalization ability for
the load-deformation curve prediction, with a mean absolute error of 5.72% for
the test data. The model could also be used for parametric analysis and design
optimization of piles under different soil and pile conditions, pile cross
section, pile length and type of pile.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03042" title="Abstract">arXiv:2312.03042</a> [<a href="/pdf/2312.03042" title="Download PDF">pdf</a>, <a href="/format/2312.03042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inherent limitations of LLMs regarding spatial information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">He Yan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xinyao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xiangpeng Wan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chengyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+K">Kai Zou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shiqi Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite the significant advancements in natural language processing
capabilities demonstrated by large language models such as ChatGPT, their
proficiency in comprehending and processing spatial information, especially
within the domains of 2D and 3D route planning, remains notably underdeveloped.
This paper investigates the inherent limitations of ChatGPT and similar models
in spatial reasoning and navigation-related tasks, an area critical for
applications ranging from autonomous vehicle guidance to assistive technologies
for the visually impaired. In this paper, we introduce a novel evaluation
framework complemented by a baseline dataset, meticulously crafted for this
study. This dataset is structured around three key tasks: plotting spatial
points, planning routes in two-dimensional (2D) spaces, and devising pathways
in three-dimensional (3D) environments. We specifically developed this dataset
to assess the spatial reasoning abilities of ChatGPT. Our evaluation reveals
key insights into the model's capabilities and limitations in spatial
understanding.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03044" title="Abstract">arXiv:2312.03044</a> [<a href="/pdf/2312.03044" title="Download PDF">pdf</a>, <a href="/format/2312.03044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> REST: Enhancing Group Robustness in DNNs through Reweighted Sparse  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiaxu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+L">Lu Yin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shiwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+M">Meng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Pechenizkiy%2C+M">Mykola Pechenizkiy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The deep neural network (DNN) has been proven effective in various domains.
However, they often struggle to perform well on certain minority groups during
inference, despite showing strong performance on the majority of data groups.
This is because over-parameterized models learned \textit{bias attributes} from
a large number of \textit{bias-aligned} training samples. These bias attributes
are strongly spuriously correlated with the target variable, causing the models
to be biased towards spurious correlations (i.e., \textit{bias-conflicting}).
To tackle this issue, we propose a novel \textbf{re}weighted \textbf{s}parse
\textbf{t}raining framework, dubbed as \textit{\textbf{REST}}, which aims to
enhance the performance of biased data while improving computation and memory
efficiency. Our proposed REST framework has been experimentally validated on
three datasets, demonstrating its effectiveness in exploring unbiased
subnetworks. We found that REST reduces the reliance on spuriously correlated
features, leading to better performance across a wider range of data groups
with fewer training and inference resources. We highlight that the
\textit{REST} framework represents a promising approach for improving the
performance of DNNs on biased data, while simultaneously improving computation
and memory efficiency. By reducing the reliance on spurious correlations, REST
has the potential to enhance the robustness of DNNs and improve their
generalization capabilities. Code is released at
\url{https://github.com/zhao1402072392/REST}
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03045" title="Abstract">arXiv:2312.03045</a> [<a href="/pdf/2312.03045" title="Download PDF">pdf</a>, <a href="/format/2312.03045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Customization Assistant for Text-to-image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yufan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruiyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiuxiang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+T">Tong Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Customizing pre-trained text-to-image generation model has attracted massive
research interest recently, due to its huge potential in real-world
applications. Although existing methods are able to generate creative content
for a novel concept contained in single user-input image, their capability are
still far from perfection. Specifically, most existing methods require
fine-tuning the generative model on testing images. Some existing methods do
not require fine-tuning, while their performance are unsatisfactory.
Furthermore, the interaction between users and models are still limited to
directive and descriptive prompts such as instructions and captions. In this
work, we build a customization assistant based on pre-trained large language
model and diffusion model, which can not only perform customized generation in
a tuning-free manner, but also enable more user-friendly interactions: users
can chat with the assistant and input either ambiguous text or clear
instruction. Specifically, we propose a new framework consists of a new model
design and a novel training strategy. The resulting assistant can perform
customized generation in 2-5 seconds without any test time fine-tuning.
Extensive experiments are conducted, competitive results have been obtained
across different domains, illustrating the effectiveness of the proposed
method.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03046" title="Abstract">arXiv:2312.03046</a> [<a href="/pdf/2312.03046" title="Download PDF">pdf</a>, <a href="/format/2312.03046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diversified in-domain synthesis with efficient fine-tuning for few-shot  classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=da+Costa%2C+V+G+T">Victor G. Turrisi da Costa</a>, 
<a href="/search/cs?searchtype=author&query=Dall%27Asen%2C+N">Nicola Dall&#x27;Asen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sebe%2C+N">Nicu Sebe</a>, 
<a href="/search/cs?searchtype=author&query=Ricci%2C+E">Elisa Ricci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Few-shot image classification aims to learn an image classifier using only a
small set of labeled examples per class. A recent research direction for
improving few-shot classifiers involves augmenting the labelled samples with
synthetic images created by state-of-the-art text-to-image generation models.
Following this trend, we propose Diversified in-domain synthesis with efficient
fine-tuning (DISEF), a novel approach which addresses the generalization
challenge in few-shot learning using synthetic data. DISEF consists of two main
components. First, we propose a novel text-to-image augmentation pipeline that,
by leveraging the real samples and their rich semantics coming from an advanced
captioning model, promotes in-domain sample diversity for better
generalization. Second, we emphasize the importance of effective model
fine-tuning in few-shot recognition, proposing to use Low-Rank Adaptation
(LoRA) for joint adaptation of the text and image encoders in a Vision Language
Model. We validate our method in ten different benchmarks, consistently
outperforming baselines and establishing a new state-of-the-art for few-shot
classification. Code is available at \url{https://github.com/vturrisi/disef}
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03047" title="Abstract">arXiv:2312.03047</a> [<a href="/pdf/2312.03047" title="Download PDF">pdf</a>, <a href="/format/2312.03047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MagicStick: Controllable Video Editing via Control Handle  Transformations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yue Ma</a>, 
<a href="/search/cs?searchtype=author&query=Cun%2C+X">Xiaodong Cun</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yingqing He</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+C">Chenyang Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xintao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiu Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qifeng Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://magic-stick-edit.github.io/">this https URL</a> Github repository: <a href="https://github.com/mayuelala/MagicStick">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-based video editing has recently attracted considerable interest in
changing the style or replacing the objects with a similar structure. Beyond
this, we demonstrate that properties such as shape, size, location, motion,
etc., can also be edited in videos. Our key insight is that the keyframe
transformations of the specific internal feature (e.g., edge maps of objects or
human pose), can easily propagate to other frames to provide generation
guidance. We thus propose MagicStick, a controllable video editing method that
edits the video properties by utilizing the transformation on the extracted
internal control signals. In detail, to keep the appearance, we inflate both
the pretrained image diffusion model and ControlNet to the temporal dimension
and train low-rank adaptions (LORA) layers to fit the specific scenes. Then, in
editing, we perform an inversion and editing framework. Differently, finetuned
ControlNet is introduced in both inversion and generation for attention
guidance with the proposed attention remix between the spatial attention maps
of inversion and editing. Yet succinct, our method is the first method to show
the ability of video property editing from the pre-trained text-to-image model.
We present experiments on numerous examples within our unified framework. We
also compare with shape-aware text-based editing and handcrafted motion video
generation, demonstrating our superior temporal consistency and editing
capability than previous works. The code and models will be made publicly
available.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03048" title="Abstract">arXiv:2312.03048</a> [<a href="/pdf/2312.03048" title="Download PDF">pdf</a>, <a href="/format/2312.03048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DGInStyle: Domain-Generalizable Semantic Segmentation with Image  Diffusion Models and Stylized Semantic Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yuru Jia</a>, 
<a href="/search/cs?searchtype=author&query=Hoyer%2C+L">Lukas Hoyer</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shengyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianfu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>, 
<a href="/search/cs?searchtype=author&query=Schindler%2C+K">Konrad Schindler</a>, 
<a href="/search/cs?searchtype=author&query=Obukhov%2C+A">Anton Obukhov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large, pretrained latent diffusion models (LDMs) have demonstrated an
extraordinary ability to generate creative content, specialize to user data
through few-shot fine-tuning, and condition their output on other modalities,
such as semantic maps. However, are they usable as large-scale data generators,
e.g., to improve tasks in the perception stack, like semantic segmentation? We
investigate this question in the context of autonomous driving, and answer it
with a resounding "yes". We propose an efficient data generation pipeline
termed DGInStyle. First, we examine the problem of specializing a pretrained
LDM to semantically-controlled generation within a narrow domain. Second, we
design a Multi-resolution Latent Fusion technique to overcome the bias of LDMs
towards dominant objects. Third, we propose a Style Swap technique to endow the
rich generative prior with the learned semantic control. Using DGInStyle, we
generate a diverse dataset of street scenes, train a domain-agnostic semantic
segmentation model on it, and evaluate the model on multiple popular autonomous
driving datasets. Our approach consistently increases the performance of
several domain generalization methods, in some cases by +2.5 mIoU compared to
the previous state-of-the-art method without our generative augmentation
scheme. Source code and dataset are available at https://dginstyle.github.io .
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03049" title="Abstract">arXiv:2312.03049</a> [<a href="/pdf/2312.03049" title="Download PDF">pdf</a>, <a href="/ps/2312.03049" title="Download PostScript">ps</a>, <a href="/format/2312.03049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Architectural Approaches to Overcome Challenges in the Development of  Data-Intensive Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dimov%2C+A">Aleksandar Dimov</a>, 
<a href="/search/cs?searchtype=author&query=Emanuilov%2C+S">Simeon Emanuilov</a>, 
<a href="/search/cs?searchtype=author&query=Bontchev%2C+B">Boyan Bontchev</a>, 
<a href="/search/cs?searchtype=author&query=Dankov%2C+Y">Yavor Dankov</a>, 
<a href="/search/cs?searchtype=author&query=Papapostolu%2C+T">Tasos Papapostolu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Human Factors in Software and Systems Engineering, Vol. 61, 2022,
  38-43
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Orientation of modern software systems towards data-intensive processing
raises new difficulties in software engineering on how to build and maintain
such systems. Some of the important challenges concern the design of software
architecture. In this article, we survey the fundamental challenges when
designing data-intensive computing systems and present some of the most popular
software architectural styles together with their potential to tackle these
challenges.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03050" title="Abstract">arXiv:2312.03050</a> [<a href="/pdf/2312.03050" title="Download PDF">pdf</a>, <a href="/format/2312.03050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HIG: Hierarchical Interlacement Graph Approach to Scene Graph Generation  in Video Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Trong-Thuan Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+P">Pha Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+K">Khoa Luu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual interactivity understanding within visual scenes presents a
significant challenge in computer vision. Existing methods focus on complex
interactivities while leveraging a simple relationship model. These methods,
however, struggle with a diversity of appearance, situation, position,
interaction, and relation in videos. This limitation hinders the ability to
fully comprehend the interplay within the complex visual dynamics of subjects.
In this paper, we delve into interactivities understanding within visual
content by deriving scene graph representations from dense interactivities
among humans and objects. To achieve this goal, we first present a new dataset
containing Appearance-Situation-Position-Interaction-Relation predicates, named
ASPIRe, offering an extensive collection of videos marked by a wide range of
interactivities. Then, we propose a new approach named Hierarchical
Interlacement Graph (HIG), which leverages a unified layer and graph within a
hierarchical structure to provide deep insights into scene changes across five
distinct tasks. Our approach demonstrates superior performance to other methods
through extensive experiments conducted in various scenarios.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03051" title="Abstract">arXiv:2312.03051</a> [<a href="/pdf/2312.03051" title="Download PDF">pdf</a>, <a href="/format/2312.03051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Interpretable Networks using Hypernetworks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+I">Isaac Liao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tegmark%2C+M">Max Tegmark</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">An essential goal in mechanistic interpretability to decode a network, i.e.,
to convert a neural network's raw weights to an interpretable algorithm. Given
the difficulty of the decoding problem, progress has been made to understand
the easier encoding problem, i.e., to convert an interpretable algorithm into
network weights. Previous works focus on encoding existing algorithms into
networks, which are interpretable by definition. However, focusing on encoding
limits the possibility of discovering new algorithms that humans have never
stumbled upon, but that are nevertheless interpretable. In this work, we
explore the possibility of using hypernetworks to generate interpretable
networks whose underlying algorithms are not yet known. The hypernetwork is
carefully designed such that it can control network complexity, leading to a
diverse family of interpretable algorithms ranked by their complexity. All of
them are interpretable in hindsight, although some of them are less intuitive
to humans, hence providing new insights regarding how to "think" like a neural
network. For the task of computing L1 norms, hypernetworks find three
algorithms: (a) the double-sided algorithm, (b) the convexity algorithm, (c)
the pudding algorithm, although only the first algorithm was expected by the
authors before experiments. We automatically classify these algorithms and
analyze how these algorithmic phases develop during training, as well as how
they are affected by complexity control. Furthermore, we show that a trained
hypernetwork can correctly construct models for input dimensions not seen in
training, demonstrating systematic generalization.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03052" title="Abstract">arXiv:2312.03052</a> [<a href="/pdf/2312.03052" title="Download PDF">pdf</a>, <a href="/format/2312.03052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Program Distillation: Distilling Tools and Programmatic Reasoning  into Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yushi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Stretcu%2C+O">Otilia Stretcu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chun-Ta Lu</a>, 
<a href="/search/cs?searchtype=author&query=Viswanathan%2C+K">Krishnamurthy Viswanathan</a>, 
<a href="/search/cs?searchtype=author&query=Hata%2C+K">Kenji Hata</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+E">Enming Luo</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+R">Ranjay Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Fuxman%2C+A">Ariel Fuxman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Solving complex visual tasks such as "Who invented the musical instrument on
the right?" involves a composition of skills: understanding space, recognizing
instruments, and also retrieving prior knowledge. Recent work shows promise by
decomposing such tasks using a large language model (LLM) into an executable
program that invokes specialized vision models. However, generated programs are
error-prone: they omit necessary steps, include spurious ones, and are unable
to recover when the specialized models give incorrect outputs. Moreover, they
require loading multiple models, incurring high latency and computation costs.
We propose Visual Program Distillation (VPD), an instruction tuning framework
that produces a vision-language model (VLM) capable of solving complex visual
tasks with a single forward pass. VPD distills the reasoning ability of LLMs by
using them to sample multiple candidate programs, which are then executed and
verified to identify a correct one. It translates each correct program into a
language description of the reasoning steps, which are then distilled into a
VLM. Extensive experiments show that VPD improves the VLM's ability to count,
understand spatial relations, and reason compositionally. Our VPD-trained
PaLI-X outperforms all prior VLMs, achieving state-of-the-art performance
across complex vision tasks, including MMBench, OK-VQA, A-OKVQA, TallyQA, POPE,
and Hateful Memes. An evaluation with human annotators also confirms that VPD
improves model response factuality and consistency. Finally, experiments on
content moderation demonstrate that VPD is also helpful for adaptation to
real-world applications with limited data.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03053" title="Abstract">arXiv:2312.03053</a> [<a href="/pdf/2312.03053" title="Download PDF">pdf</a>, <a href="/format/2312.03053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffusionPCR: Diffusion Models for Robust Multi-Step Point Cloud  Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yufan Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+Z">Zheng Dang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+W">Wenbing Tao</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%BCsstrunk%2C+S">Sabine S&#xfc;sstrunk</a>, 
<a href="/search/cs?searchtype=author&query=Salzmann%2C+M">Mathieu Salzmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Point Cloud Registration (PCR) estimates the relative rigid transformation
between two point clouds. We propose formulating PCR as a denoising diffusion
probabilistic process, mapping noisy transformations to the ground truth.
However, using diffusion models for PCR has nontrivial challenges, such as
adapting a generative model to a discriminative task and leveraging the
estimated nonlinear transformation from the previous step. Instead of training
a diffusion model to directly map pure noise to ground truth, we map the
predictions of an off-the-shelf PCR model to ground truth. The predictions of
off-the-shelf models are often imperfect, especially in challenging cases where
the two points clouds have low overlap, and thus could be seen as noisy
versions of the real rigid transformation. In addition, we transform the
rotation matrix into a spherical linear space for interpolation between samples
in the forward process, and convert rigid transformations into auxiliary
information to implicitly exploit last-step estimations in the reverse process.
As a result, conditioned on time step, the denoising model adapts to the
increasing accuracy across steps and refines registrations. Our extensive
experiments showcase the effectiveness of our DiffusionPCR, yielding
state-of-the-art registration recall rates (95.3%/81.6%) on 3DMatch and
3DLoMatch. The code will be made public upon publication.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03076" title="Abstract">arXiv:2312.03076</a> [<a href="/pdf/2312.03076" title="Download PDF">pdf</a>, <a href="/ps/2312.03076" title="Download PostScript">ps</a>, <a href="/format/2312.03076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XOR Lemmas for Communication via Marginal Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Iyer%2C+S">Siddharth Iyer</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+A">Anup Rao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">We define the $\textit{marginal information}$ of a communication protocol,
and use it to prove XOR lemmas for communication complexity. We show that if
every $C$-bit protocol has bounded advantage for computing a Boolean function
$f$, then every $\tilde \Omega(C \sqrt{n})$-bit protocol has advantage
$\exp(-\Omega(n))$ for computing the $n$-fold xor $f^{\oplus n}$. We prove
exponentially small bounds in the average case setting, and near optimal bounds
for product distributions and for bounded-round protocols.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03077" title="Abstract">arXiv:2312.03077</a> [<a href="/pdf/2312.03077" title="Download PDF">pdf</a>, <a href="/format/2312.03077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clinical Notes Reveal Physician Fatigue
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hsu%2C+C">Chao-Chun Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Obermeyer%2C+Z">Ziad Obermeyer</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Chenhao Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Physicians write notes about patients. In doing so, they reveal much about
themselves. Using data from 129,228 emergency room visits, we train a model to
identify notes written by fatigued physicians -- those who worked 5 or more of
the prior 7 days. In a hold-out set, the model accurately identifies notes
written by these high-workload physicians, and also flags notes written in
other high-fatigue settings: on overnight shifts, and after high patient
volumes. Model predictions also correlate with worse decision-making on at
least one important metric: yield of testing for heart attack is 18% lower with
each standard deviation increase in model-predicted fatigue. Finally, the model
indicates that notes written about Black and Hispanic patients have 12% and 21%
higher predicted fatigue than Whites -- larger than overnight vs. daytime
differences. These results have an important implication for large language
models (LLMs). Our model indicates that fatigued doctors write more predictable
notes. Perhaps unsurprisingly, because word prediction is the core of how LLMs
work, we find that LLM-written notes have 17% higher predicted fatigue than
real physicians' notes. This indicates that LLMs may introduce distortions in
generated text that are not yet fully understood.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03079" title="Abstract">arXiv:2312.03079</a> [<a href="/pdf/2312.03079" title="Download PDF">pdf</a>, <a href="/format/2312.03079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LooseControl: Lifting ControlNet for Generalized Depth Conditioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhat%2C+S+F">Shariq Farooq Bhat</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+N+J">Niloy J. Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Wonka%2C+P">Peter Wonka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We present LooseControl to allow generalized depth conditioning for
diffusion-based image generation. ControlNet, the SOTA for depth-conditioned
image generation, produces remarkable results but relies on having access to
detailed depth maps for guidance. Creating such exact depth maps, in many
scenarios, is challenging. This paper introduces a generalized version of depth
conditioning that enables many new content-creation workflows. Specifically, we
allow (C1) scene boundary control for loosely specifying scenes with only
boundary conditions, and (C2) 3D box control for specifying layout locations of
the target objects rather than the exact shape and appearance of the objects.
Using LooseControl, along with text guidance, users can create complex
environments (e.g., rooms, street views, etc.) by specifying only scene
boundaries and locations of primary objects. Further, we provide two editing
mechanisms to refine the results: (E1) 3D box editing enables the user to
refine images by changing, adding, or removing boxes while freezing the style
of the image. This yields minimal changes apart from changes induced by the
edited boxes. (E2) Attribute editing proposes possible editing directions to
change one particular aspect of the scene, such as the overall object density
or a particular object. Extensive tests and comparisons with baselines
demonstrate the generality of our method. We believe that LooseControl can
become an important design tool for easily creating complex environments and be
extended to other forms of guidance channels. Code and more information are
available at https://shariqfarooq123.github.io/loose-control/ .
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03084" title="Abstract">arXiv:2312.03084</a> [<a href="/pdf/2312.03084" title="Download PDF">pdf</a>, <a href="/ps/2312.03084" title="Download PostScript">ps</a>, <a href="/format/2312.03084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Market-Based Framework for Increasing Responsive Loads In  Distribution Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Panahazari%2C+M">Mohammad Panahazari</a>, 
<a href="/search/eess?searchtype=author&query=Mohebbifar%2C+M">Minoo Mohebbifar</a>, 
<a href="/search/eess?searchtype=author&query=Farsani%2C+V+N">Vahid Nazari Farsani</a>, 
<a href="/search/eess?searchtype=author&query=Haghifam%2C+M">Mahmoud-Reza Haghifam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13th Smart Grid Conference (SGC 2023), Tehran, Iran
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Regarding the pervasive application of information and telecommunication
technologies in the power distribution industry, responsive loads (RLs) have
been widely employed in the operation of distribution and transmission systems.
The utilization of these loads in the competitive environment of the power
market has led to a decrease in costs and an increase in the flexibility of the
distribution system and, consequently, the power system. This paper presents a
framework for the competitive presence of RLs in local markets. The technical
cooperation method of the Distribution System Operator (DSO) and Transmission
System Operator (TSO), the persuasion mechanism of DSOs, and financial signals
for getting and increasing the participation of consumers are represented based
on local markets and market clearing mechanisms.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03085" title="Abstract">arXiv:2312.03085</a> [<a href="/pdf/2312.03085" title="Download PDF">pdf</a>, <a href="/format/2312.03085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ScAR: Scaling Adversarial Robustness for LiDAR Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiaohu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Radha%2C+H">Hayder Radha</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The adversarial robustness of a model is its ability to resist adversarial
attacks in the form of small perturbations to input data. Universal adversarial
attack methods such as Fast Sign Gradient Method (FSGM) and Projected Gradient
Descend (PGD) are popular for LiDAR object detection, but they are often
deficient compared to task-specific adversarial attacks. Additionally, these
universal methods typically require unrestricted access to the model's
information, which is difficult to obtain in real-world applications. To
address these limitations, we present a black-box Scaling Adversarial
Robustness (ScAR) method for LiDAR object detection. By analyzing the
statistical characteristics of 3D object detection datasets such as KITTI,
Waymo, and nuScenes, we have found that the model's prediction is sensitive to
scaling of 3D instances. We propose three black-box scaling adversarial attack
methods based on the available information: model-aware attack,
distribution-aware attack, and blind attack. We also introduce a strategy for
generating scaling adversarial examples to improve the model's robustness
against these three scaling adversarial attacks. Comparison with other methods
on public datasets under different 3D object detection architectures
demonstrates the effectiveness of our proposed method.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03088" title="Abstract">arXiv:2312.03088</a> [<a href="/pdf/2312.03088" title="Download PDF">pdf</a>, <a href="/format/2312.03088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMs for Multi-Modal Knowledge Extraction and Analysis in  Intelligence/Safety-Critical Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Israelsen%2C+B">Brett Israelsen</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S">Soumalya Sarkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> initial draft
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models have seen rapid progress in capability in recent years;
this progress has been accelerating and their capabilities, measured by various
benchmarks, are beginning to approach those of humans. There is a strong demand
to use such models in a wide variety of applications but, due to unresolved
vulnerabilities and limitations, great care needs to be used before applying
them to intelligence and safety-critical applications. This paper reviews
recent literature related to LLM assessment and vulnerabilities to synthesize
the current research landscape and to help understand what advances are most
critical to enable use of of these technologies in intelligence and
safety-critical applications. The vulnerabilities are broken down into ten
high-level categories and overlaid onto a high-level life cycle of an LLM. Some
general categories of mitigations are reviewed.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03089" title="Abstract">arXiv:2312.03089</a> [<a href="/pdf/2312.03089" title="Download PDF">pdf</a>, <a href="/ps/2312.03089" title="Download PostScript">ps</a>, <a href="/format/2312.03089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Localized Load Reduction Market Development Considering Network  Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Panahazari%2C+M">Mohammad Panahazari</a>, 
<a href="/search/eess?searchtype=author&query=Mohebbifar%2C+M">Minoo Mohebbifar</a>, 
<a href="/search/eess?searchtype=author&query=Farsani%2C+V+N">Vahid Nazari Farsani</a>, 
<a href="/search/eess?searchtype=author&query=Haghifam%2C+M">Mahmoud-Reza Haghifam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13th Smart Grid Conference (SGC 2023), Tehran, Iran
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">With the development of the smart grid concept and the increasing expansion
of advanced communication and measurement equipment, consumers can actively
participate in the power system operation. The intelligent use of these
facilities greatly helps the power system entities to achieve their objectives
more efficiently and less expensively. As a beneficial facility, the market
mechanism has proven to be a solution to various power system challenges.
Furthermore, distributed and localized solutions have shown to be helpful in
both reducing operation costs and accelerating the execution of the programs.
In a generation shortage condition, to prevent unwanted load curtailment and
wholesale market price spikes, utilities can get consumers' help to reduce the
load in return for payments. This paper proposes a localized load reduction
market model in the distribution system, in which consumers bid for their
participation rate at the corresponding prices. Then, a market optimization
problem will be solved by considering the technical constraints of the network
through the use of Genetic Algorithm (GA). The paper then shows that utilizing
the proposed model reduces operation costs.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03090" title="Abstract">arXiv:2312.03090</a> [<a href="/pdf/2312.03090" title="Download PDF">pdf</a>, <a href="/format/2312.03090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Critiquing Computing Artifacts through Programming Satirical Python  Scripts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Padiyath%2C+A">Aadarsh Padiyath</a>, 
<a href="/search/cs?searchtype=author&query=Nelson-Fromm%2C+T">Tamara Nelson-Fromm</a>, 
<a href="/search/cs?searchtype=author&query=Ericson%2C+B">Barbara Ericson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Peer-Reviewed, Accepted for publication in the proceedings of the 2023 IEEE Conference on Research in Equity and Sustained Participation in Engineering, Computing, and Technology (RESPECT)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Computing artifacts tend to exclude marginalized students, so we must create
new methods to critique and change them. We studied the potential for
"satirical programming" to critique artifacts as part of culturally responsive
computing (CRC) pedagogy. We conducted a one-hour session for three different
BPC programs (N=51). We showed an example of a satirical Python script and
taught elements of Python to create a script. Our findings suggest this method
is a promising CRC pedagogical approach: 50% of marginalized students worked
together to create a satirical script, and 80% enjoyed translating their
"glitches" into satirical Python scripts.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03093" title="Abstract">arXiv:2312.03093</a> [<a href="/pdf/2312.03093" title="Download PDF">pdf</a>, <a href="/format/2312.03093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RESIN-EDITOR: A Schema-guided Hierarchical Event Graph Visualizer and  Editor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+K+D">Khanh Duy Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zixuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Suchocki%2C+R">Reece Suchocki</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sha Li</a>, 
<a href="/search/cs?searchtype=author&query=Palmer%2C+M">Martha Palmer</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+S">Susan Brown</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jiawei Han</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Heng Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors contribute equally to this paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">In this paper, we present RESIN-EDITOR, an interactive event graph visualizer
and editor designed for analyzing complex events. Our RESIN-EDITOR system
allows users to render and freely edit hierarchical event graphs extracted from
multimedia and multi-document news clusters with guidance from human-curated
event schemas. RESIN-EDITOR's unique features include hierarchical graph
visualization, comprehensive source tracing, and interactive user editing,
which is more powerful and versatile than existing Information Extraction (IE)
visualization tools. In our evaluation of RESIN-EDITOR, we demonstrate ways in
which our tool is effective in understanding complex events and enhancing
system performance. The source code, a video demonstration, and a live website
for RESIN-EDITOR have been made publicly available.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03095" title="Abstract">arXiv:2312.03095</a> [<a href="/pdf/2312.03095" title="Download PDF">pdf</a>, <a href="/format/2312.03095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Environmental Posts: Sentiment and Emotion Analysis of  Social Media Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amangeldi%2C+D">Daniyar Amangeldi</a>, 
<a href="/search/cs?searchtype=author&query=Usmanova%2C+A">Aida Usmanova</a>, 
<a href="/search/cs?searchtype=author&query=Shamoi%2C+P">Pakizar Shamoi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Social media is now the predominant source of information due to the
availability of immediate public response. As a result, social media data has
become a valuable resource for comprehending public sentiments. Studies have
shown that it can amplify ideas and influence public sentiments. This study
analyzes the public perception of climate change and the environment over a
decade from 2014 to 2023. Using the Pointwise Mutual Information (PMI)
algorithm, we identify sentiment and explore prevailing emotions expressed
within environmental tweets across various social media platforms, namely
Twitter, Reddit, and YouTube. Accuracy on a human-annotated dataset was 0.65,
higher than Vader score but lower than that of an expert rater (0.90). Our
findings suggest that negative environmental tweets are far more common than
positive or neutral ones. Climate change, air quality, emissions, plastic, and
recycling are the most discussed topics on all social media platforms,
highlighting its huge global concern. The most common emotions in environmental
tweets are fear, trust, and anticipation, demonstrating public reactions wide
and complex nature. By identifying patterns and trends in opinions related to
the environment, we hope to provide insights that can help raise awareness
regarding environmental issues, inform the development of interventions, and
adapt further actions to meet environmental challenges.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03096" title="Abstract">arXiv:2312.03096</a> [<a href="/pdf/2312.03096" title="Download PDF">pdf</a>, <a href="/format/2312.03096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incidental Polysemanticity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lecomte%2C+V">Victor Lecomte</a>, 
<a href="/search/cs?searchtype=author&query=Thaman%2C+K">Kushal Thaman</a>, 
<a href="/search/cs?searchtype=author&query=Chow%2C+T">Trevor Chow</a>, 
<a href="/search/cs?searchtype=author&query=Schaeffer%2C+R">Rylan Schaeffer</a>, 
<a href="/search/cs?searchtype=author&query=Koyejo%2C+S">Sanmi Koyejo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Polysemantic neurons (neurons that activate for a set of unrelated features)
have been seen as a significant obstacle towards interpretability of
task-optimized deep networks, with implications for AI safety. The classic
origin story of polysemanticity is that the data contains more "features" than
neurons, such that learning to perform a task forces the network to co-allocate
multiple unrelated features to the same neuron, endangering our ability to
understand the network's internal processing. In this work, we present a second
and non-mutually exclusive origin story of polysemanticity. We show that
polysemanticity can arise incidentally, even when there are ample neurons to
represent all features in the data, using a combination of theory and
experiments. This second type of polysemanticity occurs because random
initialization can, by chance alone, initially assign multiple features to the
same neuron, and the training dynamics then strengthen such overlap. Due to its
origin, we term this \textit{incidental polysemanticity}.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03097" title="Abstract">arXiv:2312.03097</a> [<a href="/pdf/2312.03097" title="Download PDF">pdf</a>, <a href="/format/2312.03097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> State of Health Estimation for Battery Modules with Parallel-Connected  Cells Under Cell-to-Cell Variations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Q">Qinan Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Anderson%2C+D">Dyche Anderson</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+J">Jing Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">State of health (SOH) estimation for lithium-ion battery modules with cells
connected in parallel is a challenging problem, especially with cell-to-cell
variations. Incremental capacity analysis (ICA) and differential voltage
analysis (DVA) are effective at the cell level, but they cannot be directly
applied to module-level SOH estimation, when only module-level measurements are
available. This paper proposes a new method and demonstrates that, with
multiple features systematically selected from the module-level ICA and DVA,
the module-level SOH can be estimated with high accuracy and confidence in the
presence of cell-to-cell variations. First, a new information theory-based
feature selection algorithm is proposed to find an optimal set of features for
module-level SOH estimation. Second, a new relevance vector regression
(RVR)-based module-level SOH estimation model is proposed to provide both point
estimates and three-sigma credible intervals while maintaining model sparsity.
Experimental datasets are used to illustrate and evaluate the proposed method.
With more selected features incorporated, the proposed method achieves better
estimation accuracy and higher confidence at the expense of higher model
complexity. This trade-off is explored through a case study. When applied to a
large experimental dataset, the proposed method and the resulting sparse model
lead to module-level SOH estimates with 0.5% root-mean-square errors and 1.5%
average three-sigma values. With all the optimization and training processes
completed offboard, the proposed method has low computational complexity for
onboard implementations.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03105" title="Abstract">arXiv:2312.03105</a> [<a href="/pdf/2312.03105" title="Download PDF">pdf</a>, <a href="/ps/2312.03105" title="Download PostScript">ps</a>, <a href="/format/2312.03105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Automated Algorithm Selection by Advancing Fitness Landscape  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prager%2C+R+P">Raphael Patrick Prager</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Optimization is ubiquitous in our daily lives. In the past, (sub-)optimal
solutions to any problem have been derived by trial and error, sheer luck, or
the expertise of knowledgeable individuals. In our contemporary age, there
thankfully exists a plethora of different algorithms that can find solutions
more reliably than ever before. Yet, choosing an appropriate algorithm for any
given problem is challenging in itself. The field of automated algorithm
selection provides various approaches to tackle this latest problem. This is
done by delegating the selection of a suitable algorithm for a given problem to
a complex computer model. This computer model is generated through the use of
Artificial Intelligence. Many of these computer models rely on some sort of
information about the problem to make a reasonable selection. Various methods
exist to provide this informative input to the computer model in the form of
numerical data.
<br />In this cumulative dissertation, I propose several improvements to the
different variants of informative inputs. This in turn enhances and refines the
current state-of-the-art of automated algorithm selection. Specifically, I
identify and address current issues with the existing body of work to
strengthen the foundation that future work builds upon. Furthermore, the rise
of deep learning offers ample opportunities for automated algorithm selection.
In several joint works, my colleagues and I developed and evaluated several
different methods that replace the existing methods to extract an informative
input. Lastly, automated algorithm selection approaches have been restricted to
certain types of problems. I propose a method to extend the generation of
informative inputs to other problem types and provide an outlook on further
promising research directions.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03111" title="Abstract">arXiv:2312.03111</a> [<a href="/pdf/2312.03111" title="Download PDF">pdf</a>, <a href="/format/2312.03111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallel Proof-of-Work with DAG-Style Voting and Targeted Reward  Discounting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Keller%2C+P">Patrik Keller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">We present parallel proof-of-work with DAG-style voting, a novel
proof-of-work cryptocurrency protocol that, compared to Bitcoin, provides
better consistency guarantees, higher transaction throughput, lower transaction
confirmation latency, and higher resilience against incentive attacks. The
superior consistency guarantees follow from implementing parallel
proof-of-work, a recent consensus scheme that enforces a configurable number of
proof-of-work votes per block. Our work is inspired by another recent protocol,
Tailstorm, which structures the individual votes as tree and mitigates
incentive attacks by discounting the mining rewards proportionally to the depth
of the tree. We propose to structure the votes as a directed acyclic graph
(DAG) instead of a tree. This allows for a more targeted punishment of
offending miners and, as we show through a reinforcement learning based attack
search, makes the protocol even more resilient to incentive attacks. An
interesting by-product of our analysis is that parallel proof-of-work without
reward discounting is less resilient to incentive attacks than Bitcoin in some
realistic network scenarios.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03113" title="Abstract">arXiv:2312.03113</a> [<a href="/pdf/2312.03113" title="Download PDF">pdf</a>, <a href="/format/2312.03113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPU Graph Processing on CXL-Based Microsecond-Latency External Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sano%2C+S">Shintaro Sano</a>, 
<a href="/search/cs?searchtype=author&query=Bando%2C+Y">Yosuke Bando</a>, 
<a href="/search/cs?searchtype=author&query=Hiwada%2C+K">Kazuhiro Hiwada</a>, 
<a href="/search/cs?searchtype=author&query=Kajihara%2C+H">Hirotsugu Kajihara</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+T">Tomoya Suzuki</a>, 
<a href="/search/cs?searchtype=author&query=Nakanishi%2C+Y">Yu Nakanishi</a>, 
<a href="/search/cs?searchtype=author&query=Taki%2C+D">Daisuke Taki</a>, 
<a href="/search/cs?searchtype=author&query=Kaneko%2C+A">Akiyuki Kaneko</a>, 
<a href="/search/cs?searchtype=author&query=Shiozawa%2C+T">Tatsuo Shiozawa</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the SC '23 Workshops of The International
  Conference on High Performance Computing, Network, Storage, and Analysis
  (SC-W '23), pp. 962-972, November 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>

</div>
<p class="mathjax">In GPU graph analytics, the use of external memory such as the host DRAM and
solid-state drives is a cost-effective approach to processing large graphs
beyond the capacity of the GPU onboard memory. This paper studies the use of
Compute Express Link (CXL) memory as alternative external memory for GPU graph
processing in order to see if this emerging memory expansion technology enables
graph processing that is as fast as using the host DRAM. Through analysis and
evaluation using FPGA prototypes, we show that representative GPU graph
traversal algorithms involving fine-grained random access can tolerate an
external memory latency of up to a few microseconds introduced by the CXL
interface as well as by the underlying memory devices. This insight indicates
that microsecond-latency flash memory may be used as CXL memory devices to
realize even more cost-effective GPU graph processing while still achieving
performance close to using the host DRAM.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03119" title="Abstract">arXiv:2312.03119</a> [<a href="/pdf/2312.03119" title="Download PDF">pdf</a>, <a href="/format/2312.03119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-SAM: Automatic and Interactive Segment Anything Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yimu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sitao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gernand%2C+A+D">Alison D. Gernand</a>, 
<a href="/search/cs?searchtype=author&query=Goldstein%2C+J+A">Jeffery A. Goldstein</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J+Z">James Z. Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semantic segmentation is a core task in computer vision. Existing methods are
generally divided into two categories: automatic and interactive. Interactive
approaches, exemplified by the Segment Anything Model (SAM), have shown promise
as pre-trained models. However, current adaptation strategies for these models
tend to lean towards either automatic or interactive approaches. Interactive
methods depend on prompts user input to operate, while automatic ones bypass
the interactive promptability entirely. Addressing these limitations, we
introduce a novel paradigm and its first model: the Automatic and Interactive
Segment Anything Model (AI-SAM). In this paradigm, we conduct a comprehensive
analysis of prompt quality and introduce the pioneering Automatic and
Interactive Prompter (AI-Prompter) that automatically generates initial point
prompts while accepting additional user inputs. Our experimental results
demonstrate AI-SAM's effectiveness in the automatic setting, achieving
state-of-the-art performance. Significantly, it offers the flexibility to
incorporate additional user prompts, thereby further enhancing its performance.
The project page is available at https://github.com/ymp5078/AI-SAM.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03120" title="Abstract">arXiv:2312.03120</a> [<a href="/pdf/2312.03120" title="Download PDF">pdf</a>, <a href="/format/2312.03120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Landscape of Modern Machine Learning: A Review of Machine,  Distributed and Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Subasi%2C+O">Omer Subasi</a>, 
<a href="/search/cs?searchtype=author&query=Bel%2C+O">Oceane Bel</a>, 
<a href="/search/cs?searchtype=author&query=Manzano%2C+J">Joseph Manzano</a>, 
<a href="/search/cs?searchtype=author&query=Barker%2C+K">Kevin Barker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">With the advance of the powerful heterogeneous, parallel and distributed
computing systems and ever increasing immense amount of data, machine learning
has become an indispensable part of cutting-edge technology, scientific
research and consumer products. In this study, we present a review of modern
machine and deep learning. We provide a high-level overview for the latest
advanced machine learning algorithms, applications, and frameworks. Our
discussion encompasses parallel distributed learning, deep learning as well as
federated learning. As a result, our work serves as an introductory text to the
vast field of modern machine learning.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03121" title="Abstract">arXiv:2312.03121</a> [<a href="/pdf/2312.03121" title="Download PDF">pdf</a>, <a href="/format/2312.03121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Agents using Social Choice Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lanctot%2C+M">Marc Lanctot</a>, 
<a href="/search/cs?searchtype=author&query=Larson%2C+K">Kate Larson</a>, 
<a href="/search/cs?searchtype=author&query=Bachrach%2C+Y">Yoram Bachrach</a>, 
<a href="/search/cs?searchtype=author&query=Marris%2C+L">Luke Marris</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zun Li</a>, 
<a href="/search/cs?searchtype=author&query=Bhoopchand%2C+A">Avishkar Bhoopchand</a>, 
<a href="/search/cs?searchtype=author&query=Anthony%2C+T">Thomas Anthony</a>, 
<a href="/search/cs?searchtype=author&query=Tanner%2C+B">Brian Tanner</a>, 
<a href="/search/cs?searchtype=author&query=Koop%2C+A">Anna Koop</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">We argue that many general evaluation problems can be viewed through the lens
of voting theory. Each task is interpreted as a separate voter, which requires
only ordinal rankings or pairwise comparisons of agents to produce an overall
evaluation. By viewing the aggregator as a social welfare function, we are able
to leverage centuries of research in social choice theory to derive principled
evaluation frameworks with axiomatic foundations. These evaluations are
interpretable and flexible, while avoiding many of the problems currently
facing cross-task evaluation. We apply this Voting-as-Evaluation (VasE)
framework across multiple settings, including reinforcement learning, large
language models, and humans. In practice, we observe that VasE can be more
robust than popular evaluation frameworks (Elo and Nash averaging), discovers
properties in the evaluation data not evident from scores alone, and can
predict outcomes better than Elo in a complex seven-player game. We identify
one particular approach, maximal lotteries, that satisfies important
consistency properties relevant to evaluation, is computationally efficient
(polynomial in the size of the evaluation data), and identifies game-theoretic
cycles
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03122" title="Abstract">arXiv:2312.03122</a> [<a href="/pdf/2312.03122" title="Download PDF">pdf</a>, <a href="/ps/2312.03122" title="Download PostScript">ps</a>, <a href="/format/2312.03122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assertion Enhanced Few-Shot Learning: Instructive Technique for Large  Language Models to Generate Educational Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shahriar%2C+T">Tasmia Shahriar</a>, 
<a href="/search/cs?searchtype=author&query=Matsuda%2C+N">Noboru Matsuda</a>, 
<a href="/search/cs?searchtype=author&query=Ramos%2C+K">Kelly Ramos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Human educators possess an intrinsic ability to anticipate and seek
educational explanations from students, which drives them to pose
thought-provoking questions when students cannot articulate these explanations
independently. We aim to imbue Intelligent Tutoring Systems with this ability
using few-shot learning capability of Large Language Models. Our work proposes
a novel prompting technique, Assertion Enhanced Few-Shot Learning, to
facilitate the generation of accurate, detailed oriented educational
explanations. Our central hypothesis is that, in educational domain, few-shot
demonstrations are necessary but not a sufficient condition for quality
explanation generation. We conducted a study involving 12 in-service teachers,
comparing our approach to Traditional Few-Shot Learning. The results show that
Assertion Enhanced Few-Shot Learning improves explanation accuracy by 15% and
yields higher-quality explanations, as evaluated by teachers. We also conduct a
qualitative ablation study to factor the impact of assertions to provide
educator-friendly prompting guidelines for generating explanations in their
domain of interest.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03126" title="Abstract">arXiv:2312.03126</a> [<a href="/pdf/2312.03126" title="Download PDF">pdf</a>, <a href="/format/2312.03126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Curricula in Open-Ended Worlds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Minqi Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD dissertation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep reinforcement learning (RL) provides powerful methods for training
optimal sequential decision-making agents. As collecting real-world
interactions can entail additional costs and safety risks, the common paradigm
of sim2real conducts training in a simulator, followed by real-world
deployment. Unfortunately, RL agents easily overfit to the choice of simulated
training environments, and worse still, learning ends when the agent masters
the specific set of simulated environments. In contrast, the real world is
highly open-ended, featuring endlessly evolving environments and challenges,
making such RL approaches unsuitable. Simply randomizing over simulated
environments is insufficient, as it requires making arbitrary distributional
assumptions and can be combinatorially less likely to sample specific
environment instances that are useful for learning. An ideal learning process
should automatically adapt the training environment to maximize the learning
potential of the agent over an open-ended task space that matches or surpasses
the complexity of the real world. This thesis develops a class of methods
called Unsupervised Environment Design (UED), which aim to produce such
open-ended processes. Given an environment design space, UED automatically
generates an infinite sequence or curriculum of training environments at the
frontier of the learning agent's capabilities. Through extensive empirical
studies and theoretical arguments founded on minimax-regret decision theory and
game theory, the findings in this thesis show that UED autocurricula can
produce RL agents exhibiting significantly improved robustness and
generalization to previously unseen environment instances. Such autocurricula
are promising paths toward open-ended learning systems that achieve more
general intelligence by continually generating and mastering additional
challenges of their own design.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03131" title="Abstract">arXiv:2312.03131</a> [<a href="/pdf/2312.03131" title="Download PDF">pdf</a>, <a href="/format/2312.03131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heterogeneous radio access with multiple latency targets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leyva-Mayorga%2C+I">Israel Leyva-Mayorga</a>, 
<a href="/search/cs?searchtype=author&query=Gimenez-Guzman%2C+J+M">Jose Manuel Gimenez-Guzman</a>, 
<a href="/search/cs?searchtype=author&query=Valentini%2C+L">Lorenzo Valentini</a>, 
<a href="/search/cs?searchtype=author&query=Popovski%2C+P">Petar Popovski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in Proceedings of Asilomar conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Since the advent of ultra-reliable and low-latency communications (URLLC),
the requirements of low-latency applications tend to be completely
characterized by a single pre-defined latency-reliability target. That is,
operation is optimal whenever the pre-defined latency threshold is met but the
system is assumed to be in error when the latency threshold is violated. This
vision is severely limited and does not capture the real requirements of most
applications, where multiple latency thresholds can be defined, together with
incentives or rewards associated with meeting each of them. Such formulation is
a generalization of the single-threshold case popularized by URLLC and, in the
asymptotic case, approximates to defining a cost for each point in the support
of the latency distribution. In this paper, we explore the implications of
defining multiple latency targets on the design of access protocols and on the
optimization of repetition-based access strategies in orthogonal and
non-orthogonal multiple access scenarios with users that present heterogeneous
traffic characteristics and requirements. We observe that the access strategies
of the users can be effectively adapted to the requirements of the application
by carefully defining the latency targets and the associated rewards.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03134" title="Abstract">arXiv:2312.03134</a> [<a href="/pdf/2312.03134" title="Download PDF">pdf</a>, <a href="/format/2312.03134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hardware Evaluation Framework for Large Language Model Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hengrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+A">August Ning</a>, 
<a href="/search/cs?searchtype=author&query=Prabhakar%2C+R">Rohan Prabhakar</a>, 
<a href="/search/cs?searchtype=author&query=Wentzlaff%2C+D">David Wentzlaff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">The past year has witnessed the increasing popularity of Large Language
Models (LLMs). Their unprecedented scale and associated high hardware cost have
impeded their broader adoption, calling for efficient hardware designs. With
the large hardware needed to simply run LLM inference, evaluating different
hardware designs becomes a new bottleneck.
<br />This work introduces LLMCompass, a hardware evaluation framework for LLM
inference workloads. LLMCompass is fast, accurate, versatile, and able to
describe and evaluate different hardware designs. LLMCompass includes a mapper
to automatically find performance-optimal mapping and scheduling. It also
incorporates an area-based cost model to help architects reason about their
design choices. Compared to real-world hardware, LLMCompass' estimated latency
achieves an average 10.4% error rate across various operators with various
input sizes and an average 4.1% error rate for LLM inference. With LLMCompass,
simulating a 4-NVIDIA A100 GPU node running GPT-3 175B inference can be done
within 16 minutes on commodity hardware, including 26,400 rounds of the
mapper's parameter search.
<br />With the aid of LLMCompass, this work draws architectural implications and
explores new cost-effective hardware designs. By reducing the compute
capability or replacing High Bandwidth Memory (HBM) with traditional DRAM,
these new designs can achieve as much as 3.41x improvement in performance/cost
compared to an NVIDIA A100, making them promising choices for democratizing
LLMs.
<br />LLMCompass is planned to be fully open-source.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03136" title="Abstract">arXiv:2312.03136</a> [<a href="/pdf/2312.03136" title="Download PDF">pdf</a>, <a href="/format/2312.03136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A geometrically and thermodynamically compatible finite volume scheme  for continuum mechanics on unstructured polygonal meshes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Boscheri%2C+W">Walter Boscheri</a>, 
<a href="/search/math?searchtype=author&query=Loub%C3%A9re%2C+R">Raphael Loub&#xe9;re</a>, 
<a href="/search/math?searchtype=author&query=Braeunig%2C+J">Jean-Philippe Braeunig</a>, 
<a href="/search/math?searchtype=author&query=Maire%2C+P">Pierre-Henri Maire</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present a novel Finite Volume (FV) scheme on unstructured polygonal meshes
that is provably compliant with the Second Law of Thermodynamics and the
Geometric Conservation Law (GCL) at the same time. The governing equations are
provided by a subset of the class of symmetric and hyperbolic thermodynamically
compatible (SHTC) models. Our numerical method discretizes the equations for
the conservation of momentum, total energy, distortion tensor and thermal
impulse vector, hence accounting in one single unified mathematical formalism
for a wide range of physical phenomena in continuum mechanics. By means of two
conservative corrections directly embedded in the definition of the numerical
fluxes, the new schemes are proven to satisfy two extra conservation laws,
namely an entropy balance law and a geometric equation that links the
distortion tensor to the density evolution. As such, the classical mass
conservation equation can be discarded. Firstly, the GCL is derived at the
continuous level, and subsequently it is satisfied by introducing the new
concepts of general potential and generalized Gibbs relation. Once
compatibility of the GCL is ensured, thermodynamic compatibility is tackled in
the same manner, thus achieving the satisfaction of a local cell entropy
inequality. The two corrections are orthogonal, meaning that they can coexist
simultaneously without interfering with each other. The compatibility of the
new FV schemes holds true at the semi-discrete level, and time integration of
the governing PDE is carried out relying on Runge-Kutta schemes. A large suite
of test cases demonstrates the structure preserving properties of the schemes
at the discrete level as well.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03137" title="Abstract">arXiv:2312.03137</a> [<a href="/pdf/2312.03137" title="Download PDF">pdf</a>, <a href="/format/2312.03137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Role of Net-Zero Energy Residential Buildings in Florida&#x27;s Energy  Transition: Economic Analysis and Technical Benefits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Haggi%2C+H">Hamed Haggi</a>, 
<a href="/search/eess?searchtype=author&query=Fenton%2C+J+M">James M. Fenton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Net-zero emission policies, coupled with declining costs of renewables,
battery storage, and electric vehicles, require both direct and indirect
electrification (such as green hydrogen) of the energy infrastructure to
address climate change impacts, improve resilience, and lower energy expenses.
In this paper, a comprehensive techno-economic analysis was performed that
integrated net-zero energy buildings within the context of Florida energy
transition by the year 2050. The analysis compares the monthly cost savings of
owning photovoltaic (PV) on the roof, battery storage, and Electric Vehicle
(EV) to the cost of buying electricity from the grid for both existing and
newly built Orlando homes. The impact of income tax credits (ITC) and energy
efficiency improvements on monthly savings was taken into account. The
levelized cost of electricity for residential PV and PV + battery systems was
determined and extended to provide a cost equivalent to gasoline for an average
EV. Rooftop solar fueling an EV for 10,000 miles saves \$100 per month over
purchasing gasoline. Today, Florida residents can save on their monthly costs
of electricity and gasoline if they have both PV on their roof and a battery
system (sized for average daily residence load), and benefit from the federal
ITC. Florida residents can cost-effectively transition to their own solar,
battery storage, and electric vehicle to home systems. Allowing utility-scale
solar to be used for on-site EV fast-charging and hydrogen production through
electrolysis for fuel cell vehicles or blending with natural gas, minimizing
the need for electricity transmission and distribution costs across the power
grids.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03140" title="Abstract">arXiv:2312.03140</a> [<a href="/pdf/2312.03140" title="Download PDF">pdf</a>, <a href="/format/2312.03140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlexModel: A Framework for Interpretability of Distributed Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+M">Matthew Choi</a>, 
<a href="/search/cs?searchtype=author&query=Asif%2C+M+A">Muhammad Adil Asif</a>, 
<a href="/search/cs?searchtype=author&query=Willes%2C+J">John Willes</a>, 
<a href="/search/cs?searchtype=author&query=Emerson%2C+D">David Emerson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures. To appear at the Socially Responsible Language Modelling Research (SoLaR) Workshop, 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">With the growth of large language models, now incorporating billions of
parameters, the hardware prerequisites for their training and deployment have
seen a corresponding increase. Although existing tools facilitate model
parallelization and distributed training, deeper model interactions, crucial
for interpretability and responsible AI techniques, still demand thorough
knowledge of distributed computing. This often hinders contributions from
researchers with machine learning expertise but limited distributed computing
background. Addressing this challenge, we present FlexModel, a software package
providing a streamlined interface for engaging with models distributed across
multi-GPU and multi-node configurations. The library is compatible with
existing model distribution libraries and encapsulates PyTorch models. It
exposes user-registerable HookFunctions to facilitate straightforward
interaction with distributed model internals, bridging the gap between
distributed and single-device model paradigms. Primarily, FlexModel enhances
accessibility by democratizing model interactions and promotes more inclusive
research in the domain of large-scale neural networks. The package is found at
https://github.com/VectorInstitute/flex_model.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03141" title="Abstract">arXiv:2312.03141</a> [<a href="/pdf/2312.03141" title="Download PDF">pdf</a>, <a href="/format/2312.03141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Storage Acceleration of Graph-Traversal-Based Approximate Nearest  Neighbor Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yitu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shiyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Q">Qilin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Linghao Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongwang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+A">Andrew Chang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H+%22">Hai &quot;Helen&quot; Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiran Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Approximate nearest neighbor search (ANNS) is a key retrieval technique for
vector database and many data center applications, such as person
re-identification and recommendation systems. Among all the ANNS algorithms,
graph-traversal-based ANNS achieves the highest recall rate. However, as the
size of dataset increases, the graph may require hundreds of gigabytes of
memory, exceeding the main memory capacity of a single workstation node.
Although we can do partitioning and use solid-state drive (SSD) as the backing
storage, the limited SSD I/O bandwidth severely degrades the performance of the
system. To address this challenge, we present NDSearch, a near-data processing
(NDP) solution for ANNS processing. NDSearch consists of a novel in-storage
computing architecture, namely, SEARSSD, that supports the ANNS kernels and
leverages logic unit (LUN)-level parallelism inside the NAND flash chips.
NDSearch also includes a processing model that is customized for NDP and
cooperates with SEARSSD. The processing model enables us to apply a two-level
scheduling to improve the data locality and exploit the internal bandwidth in
NDSEARCH, and a speculative searching mechanism to further accelerate the ANNS
workload. Our results show that NDSearch improves the throughput by up to
31.7x, 14.6x, 7.4x, 2.9x over CPU, GPU, a state-of-the-art SmartSSD-only
design, and DeepStore, respectively. NDSEARCH also achieves two
orders-of-magnitude higher energy efficiency than CPU and GPU.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03146" title="Abstract">arXiv:2312.03146</a> [<a href="/pdf/2312.03146" title="Download PDF">pdf</a>, <a href="/format/2312.03146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LRMP: Layer Replication with Mixed Precision for Spatial In-memory DNN  Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nallathambi%2C+A">Abinand Nallathambi</a>, 
<a href="/search/cs?searchtype=author&query=Bose%2C+C+D">Christin David Bose</a>, 
<a href="/search/cs?searchtype=author&query=Haensch%2C+W">Wilfried Haensch</a>, 
<a href="/search/cs?searchtype=author&query=Raghunathan%2C+A">Anand Raghunathan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">In-memory computing (IMC) with non-volatile memories (NVMs) has emerged as a
promising approach to address the rapidly growing computational demands of Deep
Neural Networks (DNNs). Mapping DNN layers spatially onto NVM-based IMC
accelerators achieves high degrees of parallelism. However, two challenges that
arise in this approach are the highly non-uniform distribution of layer
processing times and high area requirements. We propose LRMP, a method to
jointly apply layer replication and mixed precision quantization to improve the
performance of DNNs when mapped to area-constrained NVM-based IMC accelerators.
LRMP uses a combination of reinforcement learning and integer linear
programming to search the replication-quantization design space using a model
that is closely informed by the target hardware architecture. Across five DNN
benchmarks, LRMP achieves 2.8-9$\times$ latency and 11.8-19$\times$ throughput
improvement at iso-accuracy.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03147" title="Abstract">arXiv:2312.03147</a> [<a href="/pdf/2312.03147" title="Download PDF">pdf</a>, <a href="/format/2312.03147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural parameter calibration and uncertainty quantification for epidemic  forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gaskin%2C+T">Thomas Gaskin</a>, 
<a href="/search/cs?searchtype=author&query=Conrad%2C+T">Tim Conrad</a>, 
<a href="/search/cs?searchtype=author&query=Pavliotis%2C+G+A">Grigorios A. Pavliotis</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%BCtte%2C+C">Christof Sch&#xfc;tte</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">The recent COVID-19 pandemic has thrown the importance of accurately
forecasting contagion dynamics and learning infection parameters into sharp
focus. At the same time, effective policy-making requires knowledge of the
uncertainty on such predictions, in order, for instance, to be able to ready
hospitals and intensive care units for a worst-case scenario without needlessly
wasting resources. In this work, we apply a novel and powerful computational
method to the problem of learning probability densities on contagion parameters
and providing uncertainty quantification for pandemic projections. Using a
neural network, we calibrate an ODE model to data of the spread of COVID-19 in
Berlin in 2020, achieving both a significantly more accurate calibration and
prediction than Markov-Chain Monte Carlo (MCMC)-based sampling schemes. The
uncertainties on our predictions provide meaningful confidence intervals e.g.
on infection figures and hospitalisation rates, while training and running the
neural scheme takes minutes where MCMC takes hours. We show convergence of our
method to the true posterior on a simplified SIR model of epidemics, and also
demonstrate our method's learning capabilities on a reduced dataset, where a
complex model is learned from a small number of compartments for which data is
available.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03151" title="Abstract">arXiv:2312.03151</a> [<a href="/pdf/2312.03151" title="Download PDF">pdf</a>, <a href="/format/2312.03151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multitask Learning Can Improve Worst-Group Outcomes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+A">Atharva Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Dery%2C+L">Lucio Dery</a>, 
<a href="/search/cs?searchtype=author&query=Setlur%2C+A">Amrith Setlur</a>, 
<a href="/search/cs?searchtype=author&query=Raghunathan%2C+A">Aditi Raghunathan</a>, 
<a href="/search/cs?searchtype=author&query=Talwalkar%2C+A">Ameet Talwalkar</a>, 
<a href="/search/cs?searchtype=author&query=Neubig%2C+G">Graham Neubig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 7 tables, 6 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In order to create machine learning systems that serve a variety of users
well, it is vital to not only achieve high average performance but also ensure
equitable outcomes across diverse groups. However, most machine learning
methods are designed to improve a model's average performance on a chosen end
task without consideration for their impact on worst group error. Multitask
learning (MTL) is one such widely used technique. In this paper, we seek not
only to understand the impact of MTL on worst-group accuracy but also to
explore its potential as a tool to address the challenge of group-wise
fairness. We primarily consider the common setting of fine-tuning a pre-trained
model, where, following recent work (Gururangan et al., 2020; Dery et al.,
2023), we multitask the end task with the pre-training objective constructed
from the end task data itself. In settings with few or no group annotations, we
find that multitasking often, but not always, achieves better worst-group
accuracy than Just-Train-Twice (JTT; Liu et al. (2021)) -- a representative
distributionally robust optimization (DRO) method. Leveraging insights from
synthetic data experiments, we propose to modify standard MTL by regularizing
the joint multitask representation space. We run a large number of fine-tuning
experiments across computer vision and natural language and find that our
regularized MTL approach consistently outperforms JTT on both worst and average
group outcomes. Our official code can be found here:
https://github.com/atharvajk98/MTL-group-robustness.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03154" title="Abstract">arXiv:2312.03154</a> [<a href="/pdf/2312.03154" title="Download PDF">pdf</a>, <a href="/format/2312.03154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViscoNet: Bridging and Harmonizing Visual and Textual Conditioning for  ControlNet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheong%2C+S+Y">Soon Yau Cheong</a>, 
<a href="/search/cs?searchtype=author&query=Mustafa%2C+A">Armin Mustafa</a>, 
<a href="/search/cs?searchtype=author&query=Gilbert%2C+A">Andrew Gilbert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper introduces ViscoNet, a novel method that enhances text-to-image
human generation models with visual prompting. Unlike existing methods that
rely on lengthy text descriptions to control the image structure, ViscoNet
allows users to specify the visual appearance of the target object with a
reference image. ViscoNet disentangles the object's appearance from the image
background and injects it into a pre-trained latent diffusion model (LDM) model
via a ControlNet branch. This way, ViscoNet mitigates the style mode collapse
problem and enables precise and flexible visual control. We demonstrate the
effectiveness of ViscoNet on human image generation, where it can manipulate
visual attributes and artistic styles with text and image prompts. We also show
that ViscoNet can learn visual conditioning from small and specific object
domains while preserving the generative power of the LDM backbone.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03160" title="Abstract">arXiv:2312.03160</a> [<a href="/pdf/2312.03160" title="Download PDF">pdf</a>, <a href="/format/2312.03160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HybridNeRF: Efficient Neural Rendering via Adaptive Volumetric Surfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Turki%2C+H">Haithem Turki</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+V">Vasu Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Bul%C3%B2%2C+S+R">Samuel Rota Bul&#xf2;</a>, 
<a href="/search/cs?searchtype=author&query=Porzi%2C+L">Lorenzo Porzi</a>, 
<a href="/search/cs?searchtype=author&query=Kontschieder%2C+P">Peter Kontschieder</a>, 
<a href="/search/cs?searchtype=author&query=Ramanan%2C+D">Deva Ramanan</a>, 
<a href="/search/cs?searchtype=author&query=Zollh%C3%B6fer%2C+M">Michael Zollh&#xf6;fer</a>, 
<a href="/search/cs?searchtype=author&query=Richardt%2C+C">Christian Richardt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://haithemturki.com/hybrid-nerf/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Neural radiance fields provide state-of-the-art view synthesis quality but
tend to be slow to render. One reason is that they make use of volume
rendering, thus requiring many samples (and model queries) per ray at render
time. Although this representation is flexible and easy to optimize, most
real-world objects can be modeled more efficiently with surfaces instead of
volumes, requiring far fewer samples per ray. This observation has spurred
considerable progress in surface representations such as signed distance
functions, but these may struggle to model semi-opaque and thin structures. We
propose a method, HybridNeRF, that leverages the strengths of both
representations by rendering most objects as surfaces while modeling the
(typically) small fraction of challenging regions volumetrically. We evaluate
HybridNeRF against the challenging Eyeful Tower dataset along with other
commonly used view synthesis datasets. When comparing to state-of-the-art
baselines, including recent rasterization-based approaches, we improve error
rates by 15-30% while achieving real-time framerates (at least 36 FPS) for
virtual-reality resolutions (2Kx2K).
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03166" title="Abstract">arXiv:2312.03166</a> [<a href="/pdf/2312.03166" title="Download PDF">pdf</a>, <a href="/format/2312.03166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning for Fast Inference of Mechanistic Models&#x27; Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borisyak%2C+M">Maxim Borisyak</a>, 
<a href="/search/cs?searchtype=author&query=Born%2C+S">Stefan Born</a>, 
<a href="/search/cs?searchtype=author&query=Neubauer%2C+P">Peter Neubauer</a>, 
<a href="/search/cs?searchtype=author&query=Cruz-Bournazou%2C+M+N">Mariano Nicolas Cruz-Bournazou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Inferring parameters of macro-kinetic growth models, typically represented by
Ordinary Differential Equations (ODE), from the experimental data is a crucial
step in bioprocess engineering. Conventionally, estimates of the parameters are
obtained by fitting the mechanistic model to observations. Fitting, however,
requires a significant computational power. Specifically, during the
development of new bioprocesses that use previously unknown organisms or
strains, efficient, robust, and computationally cheap methods for parameter
estimation are of great value. In this work, we propose using Deep Neural
Networks (NN) for directly predicting parameters of mechanistic models given
observations. The approach requires spending computational resources for
training a NN, nonetheless, once trained, such a network can provide parameter
estimates orders of magnitude faster than conventional methods. We consider a
training procedure that combines Neural Networks and mechanistic models. We
demonstrate the performance of the proposed algorithms on data sampled from
several mechanistic models used in bioengineering describing a typical
industrial batch process and compare the proposed method, a typical
gradient-based fitting procedure, and the combination of the two. We find that,
while Neural Network estimates are slightly improved by further fitting, these
estimates are measurably better than the fitting procedure alone.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03167" title="Abstract">arXiv:2312.03167</a> [<a href="/pdf/2312.03167" title="Download PDF">pdf</a>, <a href="/format/2312.03167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive spectral graph wavelets for collaborative filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alshareet%2C+O">Osama Alshareet</a>, 
<a href="/search/cs?searchtype=author&query=Hamza%2C+A+B">A. Ben Hamza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Collaborative filtering is a popular approach in recommender systems, whose
objective is to provide personalized item suggestions to potential users based
on their purchase or browsing history. However, personalized recommendations
require considerable amount of behavioral data on users, which is usually
unavailable for new users, giving rise to the cold-start problem. To help
alleviate this challenging problem, we introduce a spectral graph wavelet
collaborative filtering framework for implicit feedback data, where users,
items and their interactions are represented as a bipartite graph.
Specifically, we first propose an adaptive transfer function by leveraging a
power transform with the goal of stabilizing the variance of graph frequencies
in the spectral domain. Then, we design a deep recommendation model for
efficient learning of low-dimensional embeddings of users and items using
spectral graph wavelets in an end-to-end fashion. In addition to capturing the
graph's local and global structures, our approach yields localization of graph
signals in both spatial and spectral domains, and hence not only learns
discriminative representations of users and items, but also promotes the
recommendation quality. The effectiveness of our proposed model is demonstrated
through extensive experiments on real-world benchmark datasets, achieving
better recommendation performance compared with strong baseline methods.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03171" title="Abstract">arXiv:2312.03171</a> [<a href="/pdf/2312.03171" title="Download PDF">pdf</a>, <a href="/format/2312.03171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combining Counting Processes and Classification Improves a Stopping Rule  for Technology Assisted Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bin-Hezam%2C+R">Reem Bin-Hezam</a>, 
<a href="/search/cs?searchtype=author&query=Stevenson%2C+M">Mark Stevenson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Technology Assisted Review (TAR) stopping rules aim to reduce the cost of
manually assessing documents for relevance by minimising the number of
documents that need to be examined to ensure a desired level of recall. This
paper extends an effective stopping rule using information derived from a text
classifier that can be trained without the need for any additional annotation.
Experiments on multiple data sets (CLEF e-Health, TREC Total Recall, TREC Legal
and RCV1) showed that the proposed approach consistently improves performance
and outperforms several alternative methods.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03173" title="Abstract">arXiv:2312.03173</a> [<a href="/pdf/2312.03173" title="Download PDF">pdf</a>, <a href="/format/2312.03173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative Study of AI-Generated (GPT-4) and Human-crafted MCQs in  Programming Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doughty%2C+J">Jacob Doughty</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Zipiao Wan</a>, 
<a href="/search/cs?searchtype=author&query=Bompelli%2C+A">Anishka Bompelli</a>, 
<a href="/search/cs?searchtype=author&query=Qayum%2C+J">Jubahed Qayum</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Taozhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Juran Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yujia Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Doyle%2C+A">Aidan Doyle</a>, 
<a href="/search/cs?searchtype=author&query=Sridhar%2C+P">Pragnya Sridhar</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+A">Arav Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Bogart%2C+C">Christopher Bogart</a>, 
<a href="/search/cs?searchtype=author&query=Keylor%2C+E">Eric Keylor</a>, 
<a href="/search/cs?searchtype=author&query=Kultur%2C+C">Can Kultur</a>, 
<a href="/search/cs?searchtype=author&query=Savelka%2C+J">Jaromir Savelka</a>, 
<a href="/search/cs?searchtype=author&query=Sakr%2C+M">Majd Sakr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">There is a constant need for educators to develop and maintain effective
up-to-date assessments. While there is a growing body of research in computing
education on utilizing large language models (LLMs) in generation and
engagement with coding exercises, the use of LLMs for generating programming
MCQs has not been extensively explored. We analyzed the capability of GPT-4 to
produce multiple-choice questions (MCQs) aligned with specific learning
objectives (LOs) from Python programming classes in higher education.
Specifically, we developed an LLM-powered (GPT-4) system for generation of MCQs
from high-level course context and module-level LOs. We evaluated 651
LLM-generated and 449 human-crafted MCQs aligned to 246 LOs from 6 Python
courses. We found that GPT-4 was capable of producing MCQs with clear language,
a single correct choice, and high-quality distractors. We also observed that
the generated MCQs appeared to be well-aligned with the LOs. Our findings can
be leveraged by educators wishing to take advantage of the state-of-the-art
generative models to support MCQ authoring efforts.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03176" title="Abstract">arXiv:2312.03176</a> [<a href="/pdf/2312.03176" title="Download PDF">pdf</a>, <a href="/format/2312.03176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Learning for Abrupt Shifts Change-point Detection via  Derivative-Aware Gaussian Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+R">Rong Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Change-point detection (CPD) is crucial for identifying abrupt shifts in
data, which influence decision-making and efficient resource allocation across
various domains. To address the challenges posed by the costly and
time-intensive data acquisition in CPD, we introduce the Derivative-Aware
Change Detection (DACD) method. It leverages the derivative process of a
Gaussian process (GP) for Active Learning (AL), aiming to pinpoint change-point
locations effectively. DACD balances the exploitation and exploration of
derivative processes through multiple data acquisition functions (AFs). By
utilizing GP derivative mean and variance as criteria, DACD sequentially
selects the next sampling data point, thus enhancing algorithmic efficiency and
ensuring reliable and accurate results. We investigate the effectiveness of
DACD method in diverse scenarios and show it outperforms other active learning
change-point detection approaches.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03177" title="Abstract">arXiv:2312.03177</a> [<a href="/pdf/2312.03177" title="Download PDF">pdf</a>, <a href="/ps/2312.03177" title="Download PostScript">ps</a>, <a href="/format/2312.03177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Curiosity for an Even Representation of Tasks in Continual Offline  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pathmanathan%2C+P">Pankayaraj Pathmanathan</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz-Rodr%C3%ADguez%2C+N">Natalia D&#xed;az-Rodr&#xed;guez</a>, 
<a href="/search/cs?searchtype=author&query=Del+Ser%2C+J">Javier Del Ser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this work, we investigate the means of using curiosity on replay buffers
to improve offline multi-task continual reinforcement learning when tasks,
which are defined by the non-stationarity in the environment, are non labeled
and not evenly exposed to the learner in time. In particular, we investigate
the use of curiosity both as a tool for task boundary detection and as a
priority metric when it comes to retaining old transition tuples, which we
respectively use to propose two different buffers. Firstly, we propose a Hybrid
Reservoir Buffer with Task Separation (HRBTS), where curiosity is used to
detect task boundaries that are not known due to the task agnostic nature of
the problem. Secondly, by using curiosity as a priority metric when it comes to
retaining old transition tuples, a Hybrid Curious Buffer (HCB) is proposed. We
ultimately show that these buffers, in conjunction with regular reinforcement
learning algorithms, can be used to alleviate the catastrophic forgetting issue
suffered by the state of the art on replay buffers when the agent's exposure to
tasks is not equal along time. We evaluate catastrophic forgetting and the
efficiency of our proposed buffers against the latest works such as the Hybrid
Reservoir Buffer (HRB) and the Multi-Time Scale Replay Buffer (MTR) in three
different continual reinforcement learning settings. Experiments were done on
classical control tasks and Metaworld environment. Experiments show that our
proposed replay buffers display better immunity to catastrophic forgetting
compared to existing works in most of the settings.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03180" title="Abstract">arXiv:2312.03180</a> [<a href="/pdf/2312.03180" title="Download PDF">pdf</a>, <a href="/format/2312.03180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image reconstructions using sparse dictionary representations and  implicit, non-negative mappings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Newman%2C+E">Elizabeth Newman</a>, 
<a href="/search/math?searchtype=author&query=Solomon%2C+J+M">Jack Michael Solomon</a>, 
<a href="/search/math?searchtype=author&query=Chung%2C+M">Matthias Chung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Many imaging science tasks can be modeled as a discrete linear inverse
problem. Solving linear inverse problems is often challenging, with
ill-conditioned operators and potentially non-unique solutions. Embedding prior
knowledge, such as smoothness, into the solution can overcome these challenges.
In this work, we encode prior knowledge using a non-negative patch dictionary,
which effectively learns a basis from a training set of natural images. In this
dictionary basis, we desire solutions that are non-negative and sparse (i.e.,
contain many zero entries). With these constraints, standard methods for
solving discrete linear inverse problems are not directly applicable. One such
approach is the modified residual norm steepest descent (MRNSD), which produces
non-negative solutions but does not induce sparsity. In this paper, we provide
two methods based on MRNSD that promote sparsity. In our first method, we add
an $\ell_1$-regularization term with a new, optimal step size. In our second
method, we propose a new non-negative, sparsity-promoting mapping of the
solution. We compare the performance of our proposed methods on a number of
numerical experiments, including deblurring, image completion, computer
tomography, and superresolution. Our results show that these methods
effectively solve discrete linear inverse problems with non-negativity and
sparsity constraints.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03182" title="Abstract">arXiv:2312.03182</a> [<a href="/pdf/2312.03182" title="Download PDF">pdf</a>, <a href="/format/2312.03182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Technology Usage Span by Analyzing Users&#x27; Q&amp;A Traces in  Stack Overflow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mondal%2C+S">Saikat Mondal</a>, 
<a href="/search/cs?searchtype=author&query=Mondal%2C+D">Debajyoti Mondal</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+C+K">Chanchal K. Roy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the 30th Asia-Pacific Software Engineering Conference (APSEC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Choosing an appropriate software development technology (e.g., programming
language) is challenging due to the proliferation of diverse options. The
selection of inappropriate technologies for development may have a far-reaching
effect on software developers' career growth. Switching to a different
technology after working with one may lead to a complex learning curve and,
thus, be more challenging. Therefore, it is crucial for software developers to
find technologies that have a high usage span. Intuitively, the usage span of a
technology can be determined by the time span developers have used that
technology. Existing literature focuses on the technology landscape to explore
the complex and implicit dependencies among technologies but lacks formal
studies to draw insights about their usage span. This paper investigates the
technology usage span by analyzing the question and answering (Q&amp;A) traces of
Stack Overflow (SO), the largest technical Q&amp;A website available to date. In
particular, we analyze 6.7 million Q&amp;A traces posted by about 97K active SO
users and see what technologies have appeared in their questions or answers
over 15 years. According to our analysis, C# and Java programming languages
have a high usage span, followed by JavaScript. Besides, developers used the
.NET framework, iOS &amp; Windows Operating Systems (OS), and SQL query language
for a long time (on average). Our study also exposes the emerging (i.e., newly
growing) technologies. For example, usages of technologies such as SwiftUI,
.NET-6.0, Visual Studio 2022, and Blazor WebAssembly framework are increasing.
The findings from our study can assist novice developers, startup software
industries, and software users in determining appropriate technologies. This
also establishes an initial benchmark for future investigation on the use span
of software technologies.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03186" title="Abstract">arXiv:2312.03186</a> [<a href="/pdf/2312.03186" title="Download PDF">pdf</a>, <a href="/format/2312.03186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Traffic Reconstruction and Kernel Methods for Identifying  Stop-and-Go Congestion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanchez%2C+E+R">Edgar Ramirez Sanchez</a>, 
<a href="/search/cs?searchtype=author&query=Raghavan%2C+S">Shreyaa Raghavan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Cathy Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at NeurIPS 2023 workshops: Tackling Climate Change with Machine Learning &amp; Computational Sustainability
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Identifying stop-and-go events (SAGs) in traffic flow presents an important
avenue for advancing data-driven research for climate change mitigation and
sustainability, owing to their substantial impact on carbon emissions, travel
time, fuel consumption, and roadway safety. In fact, SAGs are estimated to
account for 33-50% of highway driving externalities. However, insufficient
attention has been paid to precisely quantifying where, when, and how much
these SAGs take place -necessary for downstream decision making, such as
intervention design and policy analysis. A key challenge is that the data
available to researchers and governments are typically sparse and aggregated to
a granularity that obscures SAGs. To overcome such data limitations, this study
thus explores the use of traffic reconstruction techniques for SAG
identification. In particular, we introduce a kernel-based method for
identifying spatio-temporal features in traffic and leverage bootstrapping to
quantify the uncertainty of the reconstruction process. Experimental results on
California highway data demonstrate the promise of the method for capturing
SAGs. This work contributes to a foundation for data-driven decision making to
advance sustainability of traffic systems.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03187" title="Abstract">arXiv:2312.03187</a> [<a href="/pdf/2312.03187" title="Download PDF">pdf</a>, <a href="/format/2312.03187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FERGI: Automatic Annotation of User Preferences for Text-to-Image  Generation from Spontaneous Facial Expression Reaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+S">Shuangquan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Junhua Ma</a>, 
<a href="/search/cs?searchtype=author&query=de+Sa%2C+V+R">Virginia R. de Sa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Researchers have proposed to use data of human preference feedback to
fine-tune text-to-image generative models. However, the scalability of human
feedback collection has been limited by its reliance on manual annotation.
Therefore, we develop and test a method to automatically annotate user
preferences from their spontaneous facial expression reaction to the generated
images. We collect a dataset of Facial Expression Reaction to Generated Images
(FERGI) and show that the activations of multiple facial action units (AUs) are
highly correlated with user evaluations of the generated images. Specifically,
AU4 (brow lowerer) is most consistently reflective of negative evaluations of
the generated image. This can be useful in two ways. Firstly, we can
automatically annotate user preferences between image pairs with substantial
difference in AU4 responses to them with an accuracy significantly
outperforming state-of-the-art scoring models. Secondly, directly integrating
the AU4 responses with the scoring models improves their consistency with human
preferences. Additionally, the AU4 response best reflects the user's evaluation
of the image fidelity, making it complementary to the state-of-the-art scoring
models, which are generally better at reflecting image-text alignment. Finally,
this method of automatic annotation with facial expression analysis can be
potentially generalized to other generation tasks. The code is available at
https://github.com/ShuangquanFeng/FERGI, and the dataset is also available at
the same link for research purposes.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03193" title="Abstract">arXiv:2312.03193</a> [<a href="/pdf/2312.03193" title="Download PDF">pdf</a>, <a href="/format/2312.03193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conceptualizing the Relationship between AI Explanations and User Agency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adenuga%2C+I">Iyadunni Adenuga</a>, 
<a href="/search/cs?searchtype=author&query=Dodge%2C+J">Jonathan Dodge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CHI 2023 Workshop: Human-Centered Explainable AI (HCXAI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">We grapple with the question: How, for whom and why should explainable
artificial intelligence (XAI) aim to support the user goal of agency? In
particular, we analyze the relationship between agency and explanations through
a user-centric lens through case studies and thought experiments. We find that
explanation serves as one of several possible first steps for agency by
allowing the user convert forethought to outcome in a more effective manner in
future interactions. Also, we observe that XAI systems might better cater to
laypersons, particularly "tinkerers", when combining explanations and user
control, so they can make meaningful changes.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03194" title="Abstract">arXiv:2312.03194</a> [<a href="/pdf/2312.03194" title="Download PDF">pdf</a>, <a href="/format/2312.03194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Corporate Bankruptcy Prediction with Domain-Adapted BERT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+A">Alex Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S">Sangwon Yoon</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the Third Workshop on Economics and Natural
  Language Processing, 2021, 26--36
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); General Economics (econ.GN)

</div>
<p class="mathjax">This study performs BERT-based analysis, which is a representative
contextualized language model, on corporate disclosure data to predict
impending bankruptcies. Prior literature on bankruptcy prediction mainly
focuses on developing more sophisticated prediction methodologies with
financial variables. However, in our study, we focus on improving the quality
of input dataset. Specifically, we employ BERT model to perform sentiment
analysis on MD&amp;A disclosures. We show that BERT outperforms dictionary-based
predictions and Word2Vec-based predictions in terms of adjusted R-square in
logistic regression, k-nearest neighbor (kNN-5), and linear kernel support
vector machine (SVM). Further, instead of pre-training the BERT model from
scratch, we apply self-learning with confidence-based filtering to corporate
disclosure data (10-K). We achieve the accuracy rate of 91.56% and demonstrate
that the domain adaptation procedure brings a significant improvement in
prediction accuracy.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03195" title="Abstract">arXiv:2312.03195</a> [<a href="/pdf/2312.03195" title="Download PDF">pdf</a>, <a href="/format/2312.03195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Rumor Veracity with Only Textual Information by Double-Channel  Structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+A">Alex Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S">Sangwon Yoon</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the Tenth International Workshop on Natural
  Language Processing for Social Media, 2022, 35--44,
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Kyle (1985) proposes two types of rumors: informed rumors which are based on
some private information and uninformed rumors which are not based on any
information (i.e. bluffing). Also, prior studies find that when people have
credible source of information, they are likely to use a more confident textual
tone in their spreading of rumors. Motivated by these theoretical findings, we
propose a double-channel structure to determine the ex-ante veracity of rumors
on social media. Our ultimate goal is to classify each rumor into true, false,
or unverifiable category. We first assign each text into either certain
(informed rumor) or uncertain (uninformed rumor) category. Then, we apply lie
detection algorithm to informed rumors and thread-reply agreement detection
algorithm to uninformed rumors. Using the dataset of SemEval 2019 Task 7, which
requires ex-ante threefold classification (true, false, or unverifiable) of
social media rumors, our model yields a macro-F1 score of 0.4027, outperforming
all the baseline models and the second-place winner (Gorrell et al., 2019).
Furthermore, we empirically validate that the double-channel structure
outperforms single-channel structures which use either lie detection or
agreement detection algorithm to all posts.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03196" title="Abstract">arXiv:2312.03196</a> [<a href="/pdf/2312.03196" title="Download PDF">pdf</a>, <a href="/format/2312.03196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Invariant Representation Learning and Sleep Dynamics Modeling for  Automatic Sleep Staging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seungyeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+T">Thai-Hoang Pham</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Ping Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Sleep staging has become a critical task in diagnosing and treating sleep
disorders to prevent sleep related diseases. With rapidly growing large scale
public sleep databases and advances in machine learning, significant progress
has been made toward automatic sleep staging. However, previous studies face
some critical problems in sleep studies; the heterogeneity of subjects'
physiological signals, the inability to extract meaningful information from
unlabeled sleep signal data to improve predictive performances, the difficulty
in modeling correlations between sleep stages, and the lack of an effective
mechanism to quantify predictive uncertainty. In this study, we propose a
neural network based automatic sleep staging model, named DREAM, to learn
domain generalized representations from physiological signals and models sleep
dynamics. DREAM learns sleep related and subject invariant representations from
diverse subjects' sleep signal segments and models sleep dynamics by capturing
interactions between sequential signal segments and between sleep stages. In
the experiments, we demonstrate that DREAM outperforms the existing sleep
staging methods on three datasets. The case study demonstrates that our model
can learn the generalized decision function resulting in good prediction
performances for the new subjects, especially in case there are differences
between testing and training subjects. The usage of unlabeled data shows the
benefit of leveraging unlabeled EEG data. Further, uncertainty quantification
demonstrates that DREAM provides prediction uncertainty, making the model
reliable and helping sleep experts in real world applications.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03203" title="Abstract">arXiv:2312.03203</a> [<a href="/pdf/2312.03203" title="Download PDF">pdf</a>, <a href="/format/2312.03203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature 3DGS: Supercharging 3D Gaussian Splatting to Enable Distilled  Feature Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shijie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">Haoran Chang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Sicheng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhiwen Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zehao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dejia Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chari%2C+P">Pradyumna Chari</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+S">Suya You</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kadambi%2C+A">Achuta Kadambi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D scene representations have gained immense popularity in recent years.
Methods that use Neural Radiance fields are versatile for traditional tasks
such as novel view synthesis. In recent times, some work has emerged that aims
to extend the functionality of NeRF beyond view synthesis, for semantically
aware tasks such as editing and segmentation using 3D feature field
distillation from 2D foundation models. However, these methods have two major
limitations: (a) they are limited by the rendering speed of NeRF pipelines, and
(b) implicitly represented feature fields suffer from continuity artifacts
reducing feature quality. Recently, 3D Gaussian Splatting has shown
state-of-the-art performance on real-time radiance field rendering. In this
work, we go one step further: in addition to radiance field rendering, we
enable 3D Gaussian splatting on arbitrary-dimension semantic features via 2D
foundation model distillation. This translation is not straightforward: naively
incorporating feature fields in the 3DGS framework leads to warp-level
divergence. We propose architectural and training changes to efficiently avert
this problem. Our proposed method is general, and our experiments showcase
novel view semantic segmentation, language-guided editing and segment anything
through learning feature fields from state-of-the-art 2D foundation models such
as SAM and CLIP-LSeg. Across experiments, our distillation method is able to
provide comparable or better results, while being significantly faster to both
train and render. Additionally, to the best of our knowledge, we are the first
method to enable point and bounding-box prompting for radiance field
manipulation, by leveraging the SAM model. Project website at:
https://feature-3dgs.github.io/
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03205" title="Abstract">arXiv:2312.03205</a> [<a href="/pdf/2312.03205" title="Download PDF">pdf</a>, <a href="/format/2312.03205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Who Leaked the Model? Tracking IP Infringers in Accountable Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shuyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Junyuan Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yi Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+R">Ruoxi Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiayu Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Federated learning (FL) emerges as an effective collaborative learning
framework to coordinate data and computation resources from massive and
distributed clients in training. Such collaboration results in non-trivial
intellectual property (IP) represented by the model parameters that should be
protected and shared by the whole party rather than an individual user.
Meanwhile, the distributed nature of FL endorses a malicious client the
convenience to compromise IP through illegal model leakage to unauthorized
third parties. To block such IP leakage, it is essential to make the IP
identifiable in the shared model and locate the anonymous infringer who first
leaks it. The collective challenges call for \emph{accountable federated
learning}, which requires verifiable ownership of the model and is capable of
revealing the infringer's identity upon leakage. In this paper, we propose
Decodable Unique Watermarking (DUW) for complying with the requirements of
accountable FL. Specifically, before a global model is sent to a client in an
FL round, DUW encodes a client-unique key into the model by leveraging a
backdoor-based watermark injection. To identify the infringer of a leaked
model, DUW examines the model and checks if the triggers can be decoded as the
corresponding keys. Extensive empirical results show that DUW is highly
effective and robust, achieving over $99\%$ watermark success rate for Digits,
CIFAR-10, and CIFAR-100 datasets under heterogeneous FL settings, and
identifying the IP infringer with $100\%$ accuracy even after common watermark
removal attempts.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03207" title="Abstract">arXiv:2312.03207</a> [<a href="/pdf/2312.03207" title="Download PDF">pdf</a>, <a href="/format/2312.03207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Satellite Imagery and AI: A New Era in Ocean Conservation, from Research  to Deployment and Impact
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beukema%2C+P">Patrick Beukema</a>, 
<a href="/search/cs?searchtype=author&query=Bastani%2C+F">Favyen Bastani</a>, 
<a href="/search/cs?searchtype=author&query=Wolters%2C+P">Piper Wolters</a>, 
<a href="/search/cs?searchtype=author&query=Herzog%2C+H">Henry Herzog</a>, 
<a href="/search/cs?searchtype=author&query=Ferdinando%2C+J">Joe Ferdinando</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures, submitted to NeurIPS Computational Sustainability 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Illegal, unreported, and unregulated (IUU) fishing poses a global threat to
ocean habitats. Publicly available satellite data offered by NASA and the
European Space Agency (ESA) provide an opportunity to actively monitor this
activity. Effectively leveraging satellite data for maritime conservation
requires highly reliable machine learning models operating globally with
minimal latency. This paper introduces three specialized computer vision models
designed for synthetic aperture radar (Sentinel-1), optical imagery
(Sentinel-2), and nighttime lights (Suomi-NPP/NOAA-20). It also presents best
practices for developing and delivering real-time computer vision services for
conservation. These models have been deployed in Skylight, a real time maritime
monitoring platform, which is provided at no cost to users worldwide.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03209" title="Abstract">arXiv:2312.03209</a> [<a href="/pdf/2312.03209" title="Download PDF">pdf</a>, <a href="/format/2312.03209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cache Me if You Can: Accelerating Diffusion Models through Block Caching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wimbauer%2C+F">Felix Wimbauer</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bichen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Schoenfeld%2C+E">Edgar Schoenfeld</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xiaoliang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Ji Hou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zijian He</a>, 
<a href="/search/cs?searchtype=author&query=Sanakoyeu%2C+A">Artsiom Sanakoyeu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peizhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+S">Sam Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Kohler%2C+J">Jonas Kohler</a>, 
<a href="/search/cs?searchtype=author&query=Rupprecht%2C+C">Christian Rupprecht</a>, 
<a href="/search/cs?searchtype=author&query=Cremers%2C+D">Daniel Cremers</a>, 
<a href="/search/cs?searchtype=author&query=Vajda%2C+P">Peter Vajda</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jialiang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion models have recently revolutionized the field of image synthesis
due to their ability to generate photorealistic images. However, one of the
major drawbacks of diffusion models is that the image generation process is
costly. A large image-to-image network has to be applied many times to
iteratively refine an image from random noise. While many recent works propose
techniques to reduce the number of required steps, they generally treat the
underlying denoising network as a black box. In this work, we investigate the
behavior of the layers within the network and find that 1) the layers' output
changes smoothly over time, 2) the layers show distinct patterns of change, and
3) the change from step to step is often very small. We hypothesize that many
layer computations in the denoising network are redundant. Leveraging this, we
introduce block caching, in which we reuse outputs from layer blocks of
previous steps to speed up inference. Furthermore, we propose a technique to
automatically determine caching schedules based on each block's changes over
timesteps. In our experiments, we show through FID, human evaluation and
qualitative analysis that Block Caching allows to generate images with higher
visual quality at the same computational cost. We demonstrate this for
different state-of-the-art models (LDM and EMU) and solvers (DDIM and DPM).
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03212" title="Abstract">arXiv:2312.03212</a> [<a href="/pdf/2312.03212" title="Download PDF">pdf</a>, <a href="/format/2312.03212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained Bayesian Optimization Under Partial Observations: Balanced  Improvements and Provable Convergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shengbo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Ke Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 8 figures, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">The partially observable constrained optimization problems (POCOPs) impede
data-driven optimization techniques since an infeasible solution of POCOPs can
provide little information about the objective as well as the constraints. We
endeavor to design an efficient and provable method for expensive POCOPs under
the framework of constrained Bayesian optimization. Our method consists of two
key components. Firstly, we present an improved design of the acquisition
functions that introduces balanced exploration during optimization. We
rigorously study the convergence properties of this design to demonstrate its
effectiveness. Secondly, we propose a Gaussian process embedding different
likelihoods as the surrogate model for a partially observable constraint. This
model leads to a more accurate representation of the feasible regions compared
to traditional classification-based models. Our proposed method is empirically
studied on both synthetic and real-world problems. The results demonstrate the
competitiveness of our method for solving POCOPs.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03213" title="Abstract">arXiv:2312.03213</a> [<a href="/pdf/2312.03213" title="Download PDF">pdf</a>, <a href="/format/2312.03213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bootstrap Your Own Variance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Turishcheva%2C+P">Polina Turishcheva</a>, 
<a href="/search/cs?searchtype=author&query=Ramapuram%2C+J">Jason Ramapuram</a>, 
<a href="/search/cs?searchtype=author&query=Williamson%2C+S">Sinead Williamson</a>, 
<a href="/search/cs?searchtype=author&query=Busbridge%2C+D">Dan Busbridge</a>, 
<a href="/search/cs?searchtype=author&query=Dhekane%2C+E">Eeshan Dhekane</a>, 
<a href="/search/cs?searchtype=author&query=Webb%2C+R">Russ Webb</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023 Workshop: Self-Supervised Learning - Theory and
  Practice
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Understanding model uncertainty is important for many applications. We
propose Bootstrap Your Own Variance (BYOV), combining Bootstrap Your Own Latent
(BYOL), a negative-free Self-Supervised Learning (SSL) algorithm, with Bayes by
Backprop (BBB), a Bayesian method for estimating model posteriors. We find that
the learned predictive std of BYOV vs. a supervised BBB model is well captured
by a Gaussian distribution, providing preliminary evidence that the learned
parameter posterior is useful for label free uncertainty estimation. BYOV
improves upon the deterministic BYOL baseline (+2.83% test ECE, +1.03% test
Brier) and presents better calibration and reliability when tested with various
augmentations (eg: +2.4% test ECE, +1.2% test Brier for Salt &amp; Pepper noise).
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03214" title="Abstract">arXiv:2312.03214</a> [<a href="/pdf/2312.03214" title="Download PDF">pdf</a>, <a href="/format/2312.03214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimistic Global Function Merger
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kyungwoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+M">Manman Ren</a>, 
<a href="/search/cs?searchtype=author&query=Hoag%2C+E">Ellis Hoag</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Function merging is a pivotal technique for reducing code size by combining
identical or similar functions into a single function. While prior research has
extensively explored this technique, it has not been assessed in conjunction
with function outlining and linker's identical code folding, despite
substantial common ground. The traditional approaches necessitate the complete
intermediate representation to compare functions. Consequently, none of these
approaches offer a scalable solution compatible with separate compilations
while achieving global function merging, which is critical for large app
development. In this paper, we introduce our global function merger, leveraging
global merge information from previous code generation runs to optimistically
create merging instances within each module context independently. Notably, our
approach remains sound even when intermediate representations change, making it
well-suited for distributed build environments. We present a comprehensive code
generation framework that can run both the state-of-the-art global function
outliner and our global function merger. These components complement each
other, resulting in a positive impact on code size reduction. Our evaluation
demonstrates that when integrating the global function merger with a
state-of-the-art global function outliner that is fully optimized with ThinLTO,
a further reduction of up to 3.5% in code size can be attained. This is in
addition to the initial average reduction of 17.3% achieved through global
function outlining for real-world iOS apps, all with minimal extra build time.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03216" title="Abstract">arXiv:2312.03216</a> [<a href="/pdf/2312.03216" title="Download PDF">pdf</a>, <a href="/format/2312.03216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SDSRA: A Skill-Driven Skill-Recombination Algorithm for Efficient Policy  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+E+H">Eric H. Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lizarraga%2C+A">Andrew Lizarraga</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we introduce a novel algorithm - the Skill-Driven Skill
Recombination Algorithm (SDSRA) - an innovative framework that significantly
enhances the efficiency of achieving maximum entropy in reinforcement learning
tasks. We find that SDSRA achieves faster convergence compared to the
traditional Soft Actor-Critic (SAC) algorithm and produces improved policies.
By integrating skill-based strategies within the robust Actor-Critic framework,
SDSRA demonstrates remarkable adaptability and performance across a wide array
of complex and diverse benchmarks.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03217" title="Abstract">arXiv:2312.03217</a> [<a href="/pdf/2312.03217" title="Download PDF">pdf</a>, <a href="/format/2312.03217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking E-Commerce Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haixun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Na%2C+T">Taesik Na</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SIGIR Forum 57, 2, Article 24 (December 2023), 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">E-commerce search and recommendation usually operate on structured data such
as product catalogs and taxonomies. However, creating better search and
recommendation systems often requires a large variety of unstructured data
including customer reviews and articles on the web. Traditionally, the solution
has always been converting unstructured data into structured data through
information extraction, and conducting search over the structured data.
However, this is a costly approach that often has low quality. In this paper,
we envision a solution that does entirely the opposite. Instead of converting
unstructured data (web pages, customer reviews, etc) to structured data, we
instead convert structured data (product inventory, catalogs, taxonomies, etc)
into textual data, which can be easily integrated into the text corpus that
trains LLMs. Then, search and recommendation can be performed through a Q/A
mechanism through an LLM instead of using traditional information retrieval
methods over structured data.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03218" title="Abstract">arXiv:2312.03218</a> [<a href="/pdf/2312.03218" title="Download PDF">pdf</a>, <a href="/format/2312.03218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerated Gradient Algorithms with Adaptive Subspace Search for  Instance-Faster Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanshi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hanzhen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+P">Pengyun Yue</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Cong Fang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Optimization for Machine Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Complexity (cs.CC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Gradient-based minimax optimal algorithms have greatly promoted the
development of continuous optimization and machine learning. One seminal work
due to Yurii Nesterov [Nes83a] established $\tilde{\mathcal{O}}(\sqrt{L/\mu})$
gradient complexity for minimizing an $L$-smooth $\mu$-strongly convex
objective. However, an ideal algorithm would adapt to the explicit complexity
of a particular objective function and incur faster rates for simpler problems,
triggering our reconsideration of two defeats of existing optimization modeling
and analysis. (i) The worst-case optimality is neither the instance optimality
nor such one in reality. (ii) Traditional $L$-smoothness condition may not be
the primary abstraction/characterization for modern practical problems.
<br />In this paper, we open up a new way to design and analyze gradient-based
algorithms with direct applications in machine learning, including linear
regression and beyond. We introduce two factors $(\alpha, \tau_{\alpha})$ to
refine the description of the degenerated condition of the optimization
problems based on the observation that the singular values of Hessian often
drop sharply. We design adaptive algorithms that solve simpler problems without
pre-known knowledge with reduced gradient or analogous oracle accesses. The
algorithms also improve the state-of-art complexities for several problems in
machine learning, thereby solving the open problem of how to design faster
algorithms in light of the known complexity lower bounds. Specially, with the
$\mathcal{O}(1)$-nuclear norm bounded, we achieve an optimal
$\tilde{\mathcal{O}}(\mu^{-1/3})$ (v.s. $\tilde{\mathcal{O}}(\mu^{-1/2})$)
gradient complexity for linear regression. We hope this work could invoke the
rethinking for understanding the difficulty of modern problems in optimization.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03222" title="Abstract">arXiv:2312.03222</a> [<a href="/pdf/2312.03222" title="Download PDF">pdf</a>, <a href="/format/2312.03222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Scores of Various Aesthetic Attribute Sets by Learning from  Overall Score Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Heng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yaqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+H">Hao Lou</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chaoen Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shuai Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinning Li</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+D">Dongqing Zou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Now many mobile phones embed deep-learning models for evaluation or guidance
on photography. These models cannot provide detailed results like human pose
scores or scene color scores because of the rare of corresponding aesthetic
attribute data. However, the annotation of image aesthetic attribute scores
requires experienced artists and professional photographers, which hinders the
collection of large-scale fully-annotated datasets. In this paper, we propose
to replace image attribute labels with feature extractors. First, a novel
aesthetic attribute evaluation framework based on attribute features is
proposed to predict attribute scores and overall scores. We call it the F2S
(attribute features to attribute scores) model. We use networks from different
tasks to provide attribute features to our F2S models. Then, we define an
aesthetic attribute contribution to describe the role of aesthetic attributes
throughout an image and use it with the attribute scores and the overall scores
to train our F2S model. Sufficient experiments on publicly available datasets
demonstrate that our F2S model achieves comparable performance with those
trained on the datasets with fully-annotated aesthetic attribute score labels.
Our method makes it feasible to learn meaningful attribute scores for various
aesthetic attribute sets in different types of images with only overall
aesthetic scores.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03223" title="Abstract">arXiv:2312.03223</a> [<a href="/pdf/2312.03223" title="Download PDF">pdf</a>, <a href="/format/2312.03223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical RL-Guided Large-scale Navigation of a Snake Robot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shuo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Salagame%2C+A">Adarsh Salagame</a>, 
<a href="/search/cs?searchtype=author&query=Ramezani%2C+A">Alireza Ramezani</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+L">Lawson Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2311.14878">arXiv:2311.14878</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Classical snake robot control leverages mimicking snake-like gaits tuned for
specific environments. However, to operate adaptively in unstructured
environments, gait generation must be dynamically scheduled. In this work, we
present a four-layer hierarchical control scheme to enable the snake robot to
navigate freely in large-scale environments. The proposed model decomposes
navigation into global planning, local planning, gait generation, and gait
tracking. Using reinforcement learning (RL) and a central pattern generator
(CPG), our method learns to navigate in complex mazes within hours and can be
directly deployed to arbitrary new environments in a zero-shot fashion. We use
the high-fidelity model of Northeastern's slithering robot COBRA to test the
effectiveness of the proposed hierarchical control approach.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03225" title="Abstract">arXiv:2312.03225</a> [<a href="/pdf/2312.03225" title="Download PDF">pdf</a>, <a href="/format/2312.03225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Snake Robot with Tactile Perception Navigates on Large-scale Challenging  Terrain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shuo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Salagame%2C+A">Adarsh Salagame</a>, 
<a href="/search/cs?searchtype=author&query=Ramezani%2C+A">Alireza Ramezani</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+L">Lawson Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Along with the advancement of robot skin technology, there has been notable
progress in the development of snake robots featuring body-surface tactile
perception. In this study, we proposed a locomotion control framework for snake
robots that integrates tactile perception to augment their adaptability to
various terrains. Our approach embraces a hierarchical reinforcement learning
(HRL) architecture, wherein the high-level orchestrates global navigation
strategies while the low-level uses curriculum learning for local navigation
maneuvers. Due to the significant computational demands of collision detection
in whole-body tactile sensing, the efficiency of the simulator is severely
compromised. Thus a distributed training pattern to mitigate the efficiency
reduction was adopted. We evaluated the navigation performance of the snake
robot in complex large-scale cave exploration with challenging terrains to
exhibit improvements in motion efficiency, evidencing the efficacy of tactile
perception in terrain-adaptive locomotion of snake robots.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03226" title="Abstract">arXiv:2312.03226</a> [<a href="/pdf/2312.03226" title="Download PDF">pdf</a>, <a href="/format/2312.03226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Object Saliency Ranking: A Novel Whole-flow Processing  Paradigm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Mengke Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linfeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Dunquan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+W">Wenfeng Song</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chenglizhao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 14 figures, accepted by IEEE Transactions on Image Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing salient object detection methods are capable of predicting binary
maps that highlight visually salient regions. However, these methods are
limited in their ability to differentiate the relative importance of multiple
objects and the relationships among them, which can lead to errors and reduced
accuracy in downstream tasks that depend on the relative importance of multiple
objects. To conquer, this paper proposes a new paradigm for saliency ranking,
which aims to completely focus on ranking salient objects by their "importance
order". While previous works have shown promising performance, they still face
ill-posed problems. First, the saliency ranking ground truth (GT) orders
generation methods are unreasonable since determining the correct ranking order
is not well-defined, resulting in false alarms. Second, training a ranking
model remains challenging because most saliency ranking methods follow the
multi-task paradigm, leading to conflicts and trade-offs among different tasks.
Third, existing regression-based saliency ranking methods are complex for
saliency ranking models due to their reliance on instance mask-based saliency
ranking orders. These methods require a significant amount of data to perform
accurately and can be challenging to implement effectively. To solve these
problems, this paper conducts an in-depth analysis of the causes and proposes a
whole-flow processing paradigm of saliency ranking task from the perspective of
"GT data generation", "network structure design" and "training protocol". The
proposed approach outperforms existing state-of-the-art methods on the
widely-used SALICON set, as demonstrated by extensive experiments with fair and
reasonable comparisons. The saliency ranking task is still in its infancy, and
our proposed unified framework can serve as a fundamental strategy to guide
future work.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03227" title="Abstract">arXiv:2312.03227</a> [<a href="/pdf/2312.03227" title="Download PDF">pdf</a>, <a href="/format/2312.03227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Body Model based ID using Shape and Pose Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sundaresan%2C+A">Aravind Sundaresan</a>, 
<a href="/search/cs?searchtype=author&query=Burns%2C+B">Brian Burns</a>, 
<a href="/search/cs?searchtype=author&query=Sur%2C+I">Indranil Sur</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yi Yao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sujeong Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to be published in IEEE International Joint Conference on Biometrics, Ljubljana, Slovenia 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">We present a Human Body model based IDentification system (HMID) system that
is jointly trained for shape, pose and biometric identification. HMID is based
on the Human Mesh Recovery (HMR) network and we propose additional losses to
improve and stabilize shape estimation and biometric identification while
maintaining the pose and shape output. We show that when our HMID network is
trained using additional shape and pose losses, it shows a significant
improvement in biometric identification performance when compared to an
identical model that does not use such losses. The HMID model uses raw images
instead of silhouettes and is able to perform robust recognition on images
collected at range and altitude as many anthropometric properties are
reasonably invariant to clothing, view and range. We show results on the USF
dataset as well as the BRIAR dataset which includes probes with both clothing
and view changes. Our approach (using body model losses) shows a significant
improvement in Rank20 accuracy and True Accuracy Rate on the BRIAR evaluation
dataset.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03229" title="Abstract">arXiv:2312.03229</a> [<a href="/pdf/2312.03229" title="Download PDF">pdf</a>, <a href="/ps/2312.03229" title="Download PostScript">ps</a>, <a href="/format/2312.03229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attaining Equilibria Using Control Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Polevoy%2C+G">Gleb Polevoy</a>, 
<a href="/search/cs?searchtype=author&query=Schweichhart%2C+J">Jonas Schweichhart</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Many interactions result in a socially suboptimal equilibrium, or in a
non-equilibrium state, from which arriving at an equilibrium through simple
dynamics can be impossible of too long. Aiming to achieve a certain
equilibrium, we persuade, bribe, or coerce a group of participants to make them
act in a way that will motivate the rest of the players to act accordingly to
the desired equilibrium. Formally, we ask which subset of the players can adopt
the goal equilibrium strategies that will make acting according to the desired
equilibrium a best response for the other players. We call such a subset a
direct control set, prove some connections to strength of equilibrium, and
study the hardness to find such lightest sets, even approximately. We then
solve important subcases and provide approximation algorithms, assuming
monotonicity. Next, we concentrate on potential games and prove that, while the
problem of finding such a set is \NP-hard, even for constant-factor
approximation, we can still solve the problem approximately or even precisely
in relevant special cases. We approximately solve this problem for singleton
potential games and treat more closely specific potential games, such as
symmetric games and coordination games on graphs.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03231" title="Abstract">arXiv:2312.03231</a> [<a href="/pdf/2312.03231" title="Download PDF">pdf</a>, <a href="/format/2312.03231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Multimodal Fusion for Surgical Feedback Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kocielnik%2C+R">Rafal Kocielnik</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+E+Y">Elyssa Y. Wong</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+T+N">Timothy N. Chu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Lydia Lin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">De-An Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiayun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Anandkumar%2C+A">Anima Anandkumar</a>, 
<a href="/search/cs?searchtype=author&query=Hung%2C+A+J">Andrew J. Hung</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Published in Proceedings of Machine Learning for Health 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Quantification of real-time informal feedback delivered by an experienced
surgeon to a trainee during surgery is important for skill improvements in
surgical training. Such feedback in the live operating room is inherently
multimodal, consisting of verbal conversations (e.g., questions and answers) as
well as non-verbal elements (e.g., through visual cues like pointing to
anatomic elements). In this work, we leverage a clinically-validated
five-category classification of surgical feedback: "Anatomic", "Technical",
"Procedural", "Praise" and "Visual Aid". We then develop a multi-label machine
learning model to classify these five categories of surgical feedback from
inputs of text, audio, and video modalities. The ultimate goal of our work is
to help automate the annotation of real-time contextual surgical feedback at
scale. Our automated classification of surgical feedback achieves AUCs ranging
from 71.5 to 77.6 with the fusion improving performance by 3.1%. We also show
that high-quality manual transcriptions of feedback audio from experts improve
AUCs to between 76.5 and 96.2, which demonstrates a clear path toward future
improvements. Empirically, we find that the Staged training strategy, with
first pre-training each modality separately and then training them jointly, is
more effective than training different modalities altogether. We also present
intuitive findings on the importance of modalities for different feedback
categories. This work offers an important first look at the feasibility of
automated classification of real-world live surgical feedback based on text,
audio, and video modalities.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03235" title="Abstract">arXiv:2312.03235</a> [<a href="/pdf/2312.03235" title="Download PDF">pdf</a>, <a href="/format/2312.03235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HEET: A Heterogeneity Measure to Quantify the Difference across  Distributed Computing Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mokhtari%2C+A">Ali Mokhtari</a> (University of Louisiana at Lafayette, LA, USA), 
<a href="/search/cs?searchtype=author&query=Ghafouri%2C+S">Saeid Ghafouri</a> (Queen Mary University of London, London, UK), 
<a href="/search/cs?searchtype=author&query=Jamshidi%2C+P">Pooyan Jamshidi</a> (University of South Carolina, SC, USA), 
<a href="/search/cs?searchtype=author&query=Salehi%2C+M+A">Mohsen Amini Salehi</a> (University of North Texas, TX, USA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
<p class="mathjax">Although system heterogeneity has been extensively studied in the past, there
is yet to be a study on measuring the impact of heterogeneity on system
performance. For this purpose, we propose a heterogeneity measure that can
characterize the impact of the heterogeneity of a system on its performance
behavior in terms of throughput or makespan. We develop a mathematical model to
characterize a heterogeneous system in terms of its task and machine
heterogeneity dimensions and then reduce it to a single value, called
Homogeneous Equivalent Execution Time (HEET), which represents the execution
time behavior of the entire system. We used AWS EC2 instances to implement a
real-world machine learning inference system. Performance evaluation of the
HEET score across different heterogeneous system configurations demonstrates
that HEET can accurately characterize the performance behavior of these
systems. In particular, the results show that our proposed method is capable of
predicting the true makespan of heterogeneous systems without online
evaluations with an average precision of 84%. This heterogeneity measure is
instrumental for solution architects to configure their systems proactively to
be sufficiently heterogeneous to meet their desired performance objectives.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03236" title="Abstract">arXiv:2312.03236</a> [<a href="/pdf/2312.03236" title="Download PDF">pdf</a>, <a href="/format/2312.03236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multicoated and Folded Graph Neural Networks with Strong Lottery Tickets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jiale Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ito%2C+H">Hiroaki Ito</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa-Arias%2C+%C3%81+L">&#xc1;ngel L&#xf3;pez Garc&#xed;a-Arias</a>, 
<a href="/search/cs?searchtype=author&query=Okoshi%2C+Y">Yasuyuki Okoshi</a>, 
<a href="/search/cs?searchtype=author&query=Otsuka%2C+H">Hikari Otsuka</a>, 
<a href="/search/cs?searchtype=author&query=Kawamura%2C+K">Kazushi Kawamura</a>, 
<a href="/search/cs?searchtype=author&query=Van+Chu%2C+T">Thiem Van Chu</a>, 
<a href="/search/cs?searchtype=author&query=Motomura%2C+M">Masato Motomura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, accepted in the Second Learning on Graphs Conference (LoG 2023)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the Second Learning on Graphs Conference (LoG
  2023), PMLR 231
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">The Strong Lottery Ticket Hypothesis (SLTH) demonstrates the existence of
high-performing subnetworks within a randomly initialized model, discoverable
through pruning a convolutional neural network (CNN) without any weight
training. A recent study, called Untrained GNNs Tickets (UGT), expanded SLTH
from CNNs to shallow graph neural networks (GNNs). However, discrepancies
persist when comparing baseline models with learned dense weights.
Additionally, there remains an unexplored area in applying SLTH to deeper GNNs,
which, despite delivering improved accuracy with additional layers, suffer from
excessive memory requirements. To address these challenges, this work utilizes
Multicoated Supermasks (M-Sup), a scalar pruning mask method, and implements it
in GNNs by proposing a strategy for setting its pruning thresholds adaptively.
In the context of deep GNNs, this research uncovers the existence of untrained
recurrent networks, which exhibit performance on par with their trained
feed-forward counterparts. This paper also introduces the Multi-Stage Folding
and Unshared Masks methods to expand the search space in terms of both
architecture and parameters. Through the evaluation of various datasets,
including the Open Graph Benchmark (OGB), this work establishes a triple-win
scenario for SLTH-based GNNs: by achieving high sparsity, competitive
performance, and high memory efficiency with up to 98.7\% reduction, it
demonstrates suitability for energy-efficient graph processing.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03243" title="Abstract">arXiv:2312.03243</a> [<a href="/pdf/2312.03243" title="Download PDF">pdf</a>, <a href="/format/2312.03243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizable Neural Physics Solvers by Baldwinian Evolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wong%2C+J+C">Jian Cheng Wong</a>, 
<a href="/search/cs?searchtype=author&query=Ooi%2C+C+C">Chin Chun Ooi</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhishek Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Chiu%2C+P">Pao-Hsiung Chiu</a>, 
<a href="/search/cs?searchtype=author&query=Low%2C+J+S+Z">Joshua Shao Zheng Low</a>, 
<a href="/search/cs?searchtype=author&query=Dao%2C+M+H">My Ha Dao</a>, 
<a href="/search/cs?searchtype=author&query=Ong%2C+Y">Yew-Soon Ong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
<p class="mathjax">Physics-informed neural networks (PINNs) are at the forefront of scientific
machine learning, making possible the creation of machine intelligence that is
cognizant of physical laws and able to accurately simulate them. In this paper,
the potential of discovering PINNs that generalize over an entire family of
physics tasks is studied, for the first time, through a biological lens of the
Baldwin effect. Drawing inspiration from the neurodevelopment of precocial
species that have evolved to learn, predict and react quickly to their
environment, we envision PINNs that are pre-wired with connection strengths
inducing strong biases towards efficient learning of physics. To this end,
evolutionary selection pressure (guided by proficiency over a family of tasks)
is coupled with lifetime learning (to specialize on a smaller subset of those
tasks) to produce PINNs that demonstrate fast and physics-compliant prediction
capabilities across a range of empirically challenging problem instances. The
Baldwinian approach achieves an order of magnitude improvement in prediction
accuracy at a fraction of the computation cost compared to state-of-the-art
results with PINNs meta-learned by gradient descent. This paper marks a leap
forward in the meta-learning of PINNs as generalizable physics solvers.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03245" title="Abstract">arXiv:2312.03245</a> [<a href="/pdf/2312.03245" title="Download PDF">pdf</a>, <a href="/format/2312.03245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple Framework to Enhance the Adversarial Robustness of Deep  Learning-based Intrusion Detection System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xinwei Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shu Han</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Hongliang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+X">Xianglong Kong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Computers &amp; Security
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep learning based intrusion detection systems (DL-based IDS) have emerged
as one of the best choices for providing security solutions against various
network intrusion attacks. However, due to the emergence and development of
adversarial deep learning technologies, it becomes challenging for the adoption
of DL models into IDS. In this paper, we propose a novel IDS architecture that
can enhance the robustness of IDS against adversarial attacks by combining
conventional machine learning (ML) models and Deep Learning models. The
proposed DLL-IDS consists of three components: DL-based IDS, adversarial
example (AE) detector, and ML-based IDS. We first develop a novel AE detector
based on the local intrinsic dimensionality (LID). Then, we exploit the low
attack transferability between DL models and ML models to find a robust ML
model that can assist us in determining the maliciousness of AEs. If the input
traffic is detected as an AE, the ML-based IDS will predict the maliciousness
of input traffic, otherwise the DL-based IDS will work for the prediction. The
fusion mechanism can leverage the high prediction accuracy of DL models and low
attack transferability between DL models and ML models to improve the
robustness of the whole system. In our experiments, we observe a significant
improvement in the prediction performance of the IDS when subjected to
adversarial attack, achieving high accuracy with low resource consumption.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03246" title="Abstract">arXiv:2312.03246</a> [<a href="/pdf/2312.03246" title="Download PDF">pdf</a>, <a href="/ps/2312.03246" title="Download PostScript">ps</a>, <a href="/format/2312.03246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Topological Conditions for Enabling Transient Control in  Leader-follower Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+F">Fei Chen</a>, 
<a href="/search/eess?searchtype=author&query=Dimarogonas%2C+D+V">Dimos V. Dimarogonas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review at Automatica
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">We derive necessary and sufficient conditions for leader-follower multi-agent
systems such that we can further apply prescribed performance control to
achieve the desired formation while satisfying certain transient constraints. A
leader-follower framework is considered in the sense that a group of agents
with external inputs are selected as leaders in order to drive the group of
followers in a way that the entire system can achieve target formation within
certain prescribed performance transient bounds. We first derive necessary
conditions on the leader-follower graph topology under which the target
formation together with the prescribed performance guarantees can be fulfilled.
Afterwards, the derived necessary conditions are extended to necessary and
sufficient conditions for leader-follower formation control under transient
constraints. Finally, the proposed results are illustrated with simulation
examples.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03248" title="Abstract">arXiv:2312.03248</a> [<a href="/pdf/2312.03248" title="Download PDF">pdf</a>, <a href="/format/2312.03248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Customizable Combination of Parameter-Efficient Modules for Multi-Task  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haowen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+T">Tao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Cong Fan</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinjie Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Modular and composable transfer learning is an emerging direction in the
field of Parameter Efficient Fine-Tuning, as it enables neural networks to
better organize various aspects of knowledge, leading to improved cross-task
generalization. In this paper, we introduce a novel approach Customized
Polytropon C-Poly that combines task-common skills and task-specific skills,
while the skill parameters being highly parameterized using low-rank
techniques. Each task is associated with a customizable number of exclusive
specialized skills and also benefits from skills shared with peer tasks. A
skill assignment matrix is jointly learned. To evaluate our approach, we
conducted extensive experiments on the Super-NaturalInstructions and the
SuperGLUE benchmarks. Our findings demonstrate that C-Poly outperforms
fully-shared, task-specific, and skill-indistinguishable baselines,
significantly enhancing the sample efficiency in multi-task learning scenarios.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03250" title="Abstract">arXiv:2312.03250</a> [<a href="/pdf/2312.03250" title="Download PDF">pdf</a>, <a href="/format/2312.03250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Add more config detail&quot;: A Taxonomy of Installation Instruction Changes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Haoyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Treude%2C+C">Christoph Treude</a>, 
<a href="/search/cs?searchtype=author&query=Zahedi%2C+M">Mansooreh Zahedi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under submission to Transaction on Software Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">README files play an important role in providing installation-related
instructions to software users and are widely used in open source software
systems on platforms such as GitHub. However, these files often suffer from
various documentation issues, leading to challenges in comprehension and
potential errors in content. Despite their significance, there is a lack of
systematic understanding regarding the documentation efforts invested in README
files, especially in the context of installation-related instructions, which
are crucial for users to start with a software project. To fill the research
gap, we conducted a qualitative study, investigating 400 GitHub repositories
with 1,163 README commits that focused on updates in installation-related
sections. Our research revealed six major categories of changes in the README
commits, namely pre-installation instructions, installation instructions,
post-installation instructions, help information updates, document
presentation, and external resource management. We further provide detailed
insights into modification behaviours and offer examples of these updates.
Based on our findings, we provide recommendations to practitioners for
maintaining their README files, as well as motivations for future research
directions. These recommendations and research directions encompass
completeness, correctness and up-to-dateness, and information presentation
consideration. The proposed research directions span the development of
automated documentation tools and empirical studies to enhance comprehension of
the needs of documentation users. Furthermore, we provide a comprehensive
README template tailored to cover the installation-related sections for
document maintainers, serving as a practical starting point for their efforts.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03252" title="Abstract">arXiv:2312.03252</a> [<a href="/pdf/2312.03252" title="Download PDF">pdf</a>, <a href="/ps/2312.03252" title="Download PostScript">ps</a>, <a href="/format/2312.03252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Preserving Task-Oriented Semantic Communications Against Model  Inversion Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanhu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Shuaishuai Guo</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yiqin Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haixia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuguang Fang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Semantic communication has been identified as a core technology for the sixth
generation (6G) of wireless networks. Recently, task-oriented semantic
communications have been proposed for low-latency inference with limited
bandwidth. Although transmitting only task-related information does protect a
certain level of user privacy, adversaries could apply model inversion
techniques to reconstruct the raw data or extract useful information, thereby
infringing on users' privacy. To mitigate privacy infringement, this paper
proposes an information bottleneck and adversarial learning (IBAL) approach to
protect users' privacy against model inversion attacks. Specifically, we
extract task-relevant features from the input based on the information
bottleneck (IB) theory. To overcome the difficulty in calculating the mutual
information in high-dimensional space, we derive a variational upper bound to
estimate the true mutual information. To prevent data reconstruction from
task-related features by adversaries, we leverage adversarial learning to train
encoder to fool adversaries by maximizing reconstruction distortion.
Furthermore, considering the impact of channel variations on privacy-utility
trade-off and the difficulty in manually tuning the weights of each loss, we
propose an adaptive weight adjustment method. Numerical results demonstrate
that the proposed approaches can effectively protect privacy without
significantly affecting task performance and achieve better privacy-utility
trade-offs than baseline methods.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03253" title="Abstract">arXiv:2312.03253</a> [<a href="/pdf/2312.03253" title="Download PDF">pdf</a>, <a href="/format/2312.03253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seller-side Outcome Fairness in Online Marketplaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zikun Ye</a>, 
<a href="/search/cs?searchtype=author&query=Maragheh%2C+R+Y">Reza Yousefi Maragheh</a>, 
<a href="/search/cs?searchtype=author&query=Morishetti%2C+L">Lalitesh Morishetti</a>, 
<a href="/search/cs?searchtype=author&query=Vashishtha%2C+S">Shanu Vashishtha</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+J">Jason Cho</a>, 
<a href="/search/cs?searchtype=author&query=Nag%2C+K">Kaushiki Nag</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sushant Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Achan%2C+K">Kannan Achan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper aims to investigate and achieve seller-side fairness within online
marketplaces, where many sellers and their items are not sufficiently exposed
to customers in an e-commerce platform. This phenomenon raises concerns
regarding the potential loss of revenue associated with less exposed items as
well as less marketplace diversity. We introduce the notion of seller-side
outcome fairness and build an optimization model to balance collected
recommendation rewards and the fairness metric. We then propose a
gradient-based data-driven algorithm based on the duality and bandit theory.
Our numerical experiments on real e-commerce data sets show that our algorithm
can lift seller fairness measures while not hurting metrics like collected
Gross Merchandise Value (GMV) and total purchases.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03255" title="Abstract">arXiv:2312.03255</a> [<a href="/pdf/2312.03255" title="Download PDF">pdf</a>, <a href="/format/2312.03255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Densifying MIMO: Channel Modeling, Physical Constraints, and Performance  Evaluation for Holographic Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Y. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">M. Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">T. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">A. Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Debbah%2C+M">M. Debbah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 20 figures, accepted by JSAC-SI-ESIT
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">As the backbone of the fifth-generation (5G) cellular network, massive
multiple-input multiple-output (MIMO) encounters a significant challenge in
practical applications: how to deploy a large number of antenna elements within
limited spaces. Recently, holographic communication has emerged as a potential
solution to this issue. It employs dense antenna arrays and provides a
tractable model. Nevertheless, some challenges must be addressed to actualize
this innovative concept. One is the mutual coupling among antenna elements
within an array. When the element spacing is small, near-field coupling becomes
the dominant factor that strongly restricts the array performance. Another is
the polarization of electromagnetic waves. As an intrinsic property, it was not
fully considered in the previous channel modeling of holographic communication.
The third is the lack of real-world experiments to show the potential and
possible defects of a holographic communication system. In this paper, we
propose an electromagnetic channel model based on the characteristics of
electromagnetic waves. This model encompasses the impact of mutual coupling in
the transceiver sides and the depolarization in the propagation environment.
Furthermore, by approximating an infinite array, the performance restrictions
of large-scale dense antenna arrays are also studied theoretically to exploit
the potential of the proposed channel. In addition, numerical simulations and a
channel measurement experiment are conducted. The findings reveal that within
limited spaces, the coupling effect, particularly for element spacing smaller
than half of the wavelength, is the primary factor leading to the inflection
point for the performance of holographic communications.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03256" title="Abstract">arXiv:2312.03256</a> [<a href="/pdf/2312.03256" title="Download PDF">pdf</a>, <a href="/format/2312.03256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAFE: Towards Compact, Adaptive, and Fast Embedding for Large-scale  Recommendation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hailin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zirui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Boxuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yikai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+B">Bin Cui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Recently, the growing memory demands of embedding tables in Deep Learning
Recommendation Models (DLRMs) pose great challenges for model training and
deployment. Existing embedding compression solutions cannot simultaneously meet
three key design requirements: memory efficiency, low latency, and adaptability
to dynamic data distribution. This paper presents CAFE, a Compact, Adaptive,
and Fast Embedding compression framework that addresses the above requirements.
The design philosophy of CAFE is to dynamically allocate more memory resources
to important features (called hot features), and allocate less memory to
unimportant ones. In CAFE, we propose a fast and lightweight sketch data
structure, named HotSketch, to capture feature importance and report hot
features in real time. For each reported hot feature, we assign it a unique
embedding. For the non-hot features, we allow multiple features to share one
embedding by using hash embedding technique. Guided by our design philosophy,
we further propose a multi-level hash embedding framework to optimize the
embedding tables of non-hot features. We theoretically analyze the accuracy of
HotSketch, and analyze the model convergence against deviation. Extensive
experiments show that CAFE significantly outperforms existing embedding
compression methods, yielding 3.92% and 3.68% superior testing AUC on Criteo
Kaggle dataset and CriteoTB dataset at a compression ratio of 10000x. The
source codes of CAFE are available at GitHub.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03259" title="Abstract">arXiv:2312.03259</a> [<a href="/pdf/2312.03259" title="Download PDF">pdf</a>, <a href="/format/2312.03259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> f-FERM: A Scalable Framework for Robust Fair Empirical Risk Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baharlouei%2C+S">Sina Baharlouei</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+S">Shivam Patel</a>, 
<a href="/search/cs?searchtype=author&query=Razaviyayn%2C+M">Meisam Razaviyayn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 Pages,5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Training and deploying machine learning models that meet fairness criteria
for protected groups are fundamental in modern artificial intelligence. While
numerous constraints and regularization terms have been proposed in the
literature to promote fairness in machine learning tasks, most of these methods
are not amenable to stochastic optimization due to the complex and nonlinear
structure of constraints and regularizers. Here, the term "stochastic" refers
to the ability of the algorithm to work with small mini-batches of data.
Motivated by the limitation of existing literature, this paper presents a
unified stochastic optimization framework for fair empirical risk minimization
based on f-divergence measures (f-FERM). The proposed stochastic algorithm
enjoys theoretical convergence guarantees. In addition, our experiments
demonstrate the superiority of fairness-accuracy tradeoffs offered by f-FERM
for almost all batch sizes (ranging from full-batch to batch size of one).
Moreover, we show that our framework can be extended to the case where there is
a distribution shift from training to the test data. Our extension is based on
a distributionally robust optimization reformulation of f-FERM objective under
$L_p$ norms as uncertainty sets. Again, in this distributionally robust
setting, f-FERM not only enjoys theoretical convergence guarantees but also
outperforms other baselines in the literature in the tasks involving
distribution shifts. An efficient stochastic implementation of $f$-FERM is
publicly available.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03263" title="Abstract">arXiv:2312.03263</a> [<a href="/pdf/2312.03263" title="Download PDF">pdf</a>, <a href="/format/2312.03263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weathering Ongoing Uncertainty: Learning and Planning in a Time-Varying  Partially Observable Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Puthumanaillam%2C+G">Gokul Puthumanaillam</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiangyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mehr%2C+N">Negar Mehr</a>, 
<a href="/search/cs?searchtype=author&query=Ornik%2C+M">Melkior Ornik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Optimal decision-making presents a significant challenge for autonomous
systems operating in uncertain, stochastic and time-varying environments.
Environmental variability over time can significantly impact the system's
optimal decision making strategy for mission completion. To model such
environments, our work combines the previous notion of Time-Varying Markov
Decision Processes (TVMDP) with partial observability and introduces
Time-Varying Partially Observable Markov Decision Processes (TV-POMDP). We
propose a two-pronged approach to accurately estimate and plan within the
TV-POMDP: 1) Memory Prioritized State Estimation (MPSE), which leverages
weighted memory to provide more accurate time-varying transition estimates; and
2) an MPSE-integrated planning strategy that optimizes long-term rewards while
accounting for temporal constraint. We validate the proposed framework and
algorithms using simulations and hardware, with robots exploring a partially
observable, time-varying environments. Our results demonstrate superior
performance over standard methods, highlighting the framework's effectiveness
in stochastic, uncertain, time-varying domains.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03266" title="Abstract">arXiv:2312.03266</a> [<a href="/pdf/2312.03266" title="Download PDF">pdf</a>, <a href="/format/2312.03266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SO-NeRF: Active View Planning for NeRF using Surrogate Objectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Keifer Lee</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Shubham Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sunglyoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Makwana%2C+B">Bhargav Makwana</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chen Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite the great success of Neural Radiance Fields (NeRF), its
data-gathering process remains vague with only a general rule of thumb of
sampling as densely as possible. The lack of understanding of what actually
constitutes good views for NeRF makes it difficult to actively plan a sequence
of views that yield the maximal reconstruction quality. We propose Surrogate
Objectives for Active Radiance Fields (SOAR), which is a set of interpretable
functions that evaluates the goodness of views using geometric and photometric
visual cues - surface coverage, geometric complexity, textural complexity, and
ray diversity. Moreover, by learning to infer the SOAR scores from a deep
network, SOARNet, we are able to effectively select views in mere seconds
instead of hours, without the need for prior visits to all the candidate views
or training any radiance field during such planning. Our experiments show
SOARNet outperforms the baselines with $\sim$80x speed-up while achieving
better or comparable reconstruction qualities. We finally show that SOAR is
model-agnostic, thus it generalizes across fully neural-implicit to fully
explicit approaches.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03270" title="Abstract">arXiv:2312.03270</a> [<a href="/pdf/2312.03270" title="Download PDF">pdf</a>, <a href="/format/2312.03270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometric Deep Learning Towards the Iterative Classification of  Graph-Based Aircraft Thermal Management Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sirico%2C+A">Anthony Sirico Jr.</a>, 
<a href="/search/cs?searchtype=author&query=Herber%2C+D+R">Daniel R Herber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 8 figures, 2024 AIAA SciTech Forum
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">In this paper, we use graph-based techniques to investigate the use of
geometric deep learning (GDL) in the classification and down-selection of
aircraft thermal management systems (TMS). Previous work developed an
enumerative graph generation procedure using a component catalog with network
structure constraints to represent novel aircraft TMSs as graphs. However, as
with many enumerative approaches, combinatorial explosion limits its efficacy
in many real-world problems, particularly when simulations and optimization
must be performed on the many (automatically-generated) physics models.
Therefore, we present an approach that takes the directed graphs representing
aircraft TMSs and use GDL to predict the critical characteristics of the
remaining graphs. This paper's findings demonstrate that incorporating
additional graph-based features enhances performance, achieving an accuracy of
97% for determining a graph's compilability and simulatability while using only
5% of the data for training. By applying iterative classification methods, we
also successfully segmented the total set of graphs into more specific groups
with an average inclusion of 84.7 of the top 100 highest-performing graphs,
achieved by training on 45% of the data.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03273" title="Abstract">arXiv:2312.03273</a> [<a href="/pdf/2312.03273" title="Download PDF">pdf</a>, <a href="/format/2312.03273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perfectly matched layers for the Boltzmann equation: stability and  sensitivity analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sutti%2C+M">Marco Sutti</a>, 
<a href="/search/math?searchtype=author&query=Hesthaven%2C+J+S">Jan S. Hesthaven</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 2 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">We study the stability and sensitivity of an absorbing layer for the
Boltzmann equation by examining the Bhatnagar-Gross-Krook (BGK) approximation
and using the perfectly matched layer (PML) technique. To ensure stability, we
discard some parameters in the model and calculate the total sensitivity
indices of the remaining parameters using the ANOVA expansion of multivariate
functions. We conduct extensive numerical experiments to study stability and
compute the total sensitivity indices, which allow us to identify the essential
parameters of the model.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03275" title="Abstract">arXiv:2312.03275</a> [<a href="/pdf/2312.03275" title="Download PDF">pdf</a>, <a href="/format/2312.03275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VLFM: Vision-Language Frontier Maps for Zero-Shot Semantic Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yokoyama%2C+N">Naoki Yokoyama</a>, 
<a href="/search/cs?searchtype=author&query=Ha%2C+S">Sehoon Ha</a>, 
<a href="/search/cs?searchtype=author&query=Batra%2C+D">Dhruv Batra</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiuguang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bucher%2C+B">Bernadette Bucher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Understanding how humans leverage semantic knowledge to navigate unfamiliar
environments and decide where to explore next is pivotal for developing robots
capable of human-like search behaviors. We introduce a zero-shot navigation
approach, Vision-Language Frontier Maps (VLFM), which is inspired by human
reasoning and designed to navigate towards unseen semantic objects in novel
environments. VLFM builds occupancy maps from depth observations to identify
frontiers, and leverages RGB observations and a pre-trained vision-language
model to generate a language-grounded value map. VLFM then uses this map to
identify the most promising frontier to explore for finding an instance of a
given target object category. We evaluate VLFM in photo-realistic environments
from the Gibson, Habitat-Matterport 3D (HM3D), and Matterport 3D (MP3D)
datasets within the Habitat simulator. Remarkably, VLFM achieves
state-of-the-art results on all three datasets as measured by success weighted
by path length (SPL) for the Object Goal Navigation task. Furthermore, we show
that VLFM's zero-shot nature enables it to be readily deployed on real-world
robots such as the Boston Dynamics Spot mobile manipulation platform. We deploy
VLFM on Spot and demonstrate its capability to efficiently navigate to target
objects within an office building in the real world, without any prior
knowledge of the environment. The accomplishments of VLFM underscore the
promising potential of vision-language models in advancing the field of
semantic navigation. Videos of real-world deployment can be viewed at
naoki.io/vlfm.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03277" title="Abstract">arXiv:2312.03277</a> [<a href="/pdf/2312.03277" title="Download PDF">pdf</a>, <a href="/format/2312.03277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anomaly Detection for Scalable Task Grouping in Reinforcement  Learning-based RAN Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jimmy Li</a>, 
<a href="/search/cs?searchtype=author&query=Kozlov%2C+I">Igor Kozlov</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Di Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dudek%2C+G">Gregory Dudek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The use of learning-based methods for optimizing cellular radio access
networks (RAN) has received increasing attention in recent years. This
coincides with a rapid increase in the number of cell sites worldwide, driven
largely by dramatic growth in cellular network traffic. Training and
maintaining learned models that work well across a large number of cell sites
has thus become a pertinent problem. This paper proposes a scalable framework
for constructing a reinforcement learning policy bank that can perform RAN
optimization across a large number of cell sites with varying traffic patterns.
Central to our framework is a novel application of anomaly detection techniques
to assess the compatibility between sites (tasks) and the policy bank. This
allows our framework to intelligently identify when a policy can be reused for
a task, and when a new policy needs to be trained and added to the policy bank.
Our results show that our approach to compatibility assessment leads to an
efficient use of computational resources, by allowing us to construct a
performant policy bank without exhaustively training on all tasks, which makes
it applicable under real-world constraints.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03278" title="Abstract">arXiv:2312.03278</a> [<a href="/pdf/2312.03278" title="Download PDF">pdf</a>, <a href="/format/2312.03278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Almanac: An API for Recommending Text Annotations For Time-Series Charts  Using News Headlines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ibanez%2C+T">Terrell Ibanez</a>, 
<a href="/search/cs?searchtype=author&query=Setlur%2C+V">Vidya Setlur</a>, 
<a href="/search/cs?searchtype=author&query=Agrawala%2C+M">Maneesh Agrawala</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Authors often add text annotations to charts to provide additional context
for visually prominent features such as peaks, valleys, and trends. However,
writing annotations that provide contextual information, such as descriptions
of temporal events, often requires considerable manual effort. To address this
problem, we introduce Almanac, a JavaScript API that recommends annotations
sourced from the New York Times Archive of news headlines. Almanac consists of
two independent parts: (1) a prominence feature detector and (2) a contextual
annotation recommender. We demonstrate the utility of the API using D3.js and
Vega-Lite to annotate a variety of time-series charts covering many different
data domains. Preliminary user feedback shows that Almanac is useful to support
the authoring of charts with more descriptive annotations.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03282" title="Abstract">arXiv:2312.03282</a> [<a href="/pdf/2312.03282" title="Download PDF">pdf</a>, <a href="/format/2312.03282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monte Carlo Optimization for Solving Multilevel Stackelberg Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koirala%2C+P">Pravesh Koirala</a>, 
<a href="/search/cs?searchtype=author&query=Laine%2C+F">Forrest Laine</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Stackelberg games originate where there are market leaders and followers, and
the actions of leaders influence the behavior of the followers. Mathematical
modelling of such games results in what's called a Bilevel Optimization
problem. There is an entire area of research dedicated to analyzing and solving
Bilevel Optimization problems which are often complex, and finding solutions
for such problems is known to be NP-Hard. A generalization of Stackelberg games
is a Multilevel Stackelberg game where we may have nested leaders and
followers, such that a follower is, in turn, a leader for all lower-level
players. These problems are much more difficult to solve, and existing solution
approaches typically require extensive cooperation between the players (which
generally can't be assumed) or make restrictive assumptions about the structure
of the problem. In this paper, we present a stochastic algorithm to approximate
the local equilibrium solutions for these Multilevel games. We then construct a
few examples of such Multilevel problems, including: a) a nested toll-setting
problem; and b) an adversarial initial condition determination problem for
Robust Trajectory Optimization. We test our algorithm on our constructed
problems as well as some trilevel problems from the literature, and show that
it is able to approximate the optimum solutions for these problems within a
reasonable error margin. We also provide an asymptotic proof for the
convergence of the algorithm and empirically analyze its accuracy and
convergence speed for different parameters. Lastly, we compare it with existing
solution strategies from the literature and demonstrate that it outperforms
them.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03286" title="Abstract">arXiv:2312.03286</a> [<a href="/pdf/2312.03286" title="Download PDF">pdf</a>, <a href="/format/2312.03286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Indirect Gradient Matching for Adversarial Robust Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hongsin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+S">Seungju Cho</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Changick Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Adversarial training significantly improves adversarial robustness, but
superior performance is primarily attained with large models. This substantial
performance gap for smaller models has spurred active research into adversarial
distillation (AD) to mitigate the difference. Existing AD methods leverage the
teacher's logits as a guide. In contrast to these approaches, we aim to
transfer another piece of knowledge from the teacher, the input gradient. In
this paper, we propose a distillation module termed Indirect Gradient
Distillation Module (IGDM) that indirectly matches the student's input gradient
with that of the teacher. We hypothesize that students can better acquire the
teacher's knowledge by matching the input gradient. Leveraging the observation
that adversarial training renders the model locally linear on the input space,
we employ Taylor approximation to effectively align gradients without directly
calculating them. Experimental results show that IGDM seamlessly integrates
with existing AD methods, significantly enhancing the performance of all AD
methods. Particularly, utilizing IGDM on the CIFAR-100 dataset improves the
AutoAttack accuracy from 28.06% to 30.32% with the ResNet-18 model and from
26.18% to 29.52% with the MobileNetV2 model when integrated into the SOTA
method without additional data augmentation. The code will be made available.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03288" title="Abstract">arXiv:2312.03288</a> [<a href="/pdf/2312.03288" title="Download PDF">pdf</a>, <a href="/ps/2312.03288" title="Download PostScript">ps</a>, <a href="/format/2312.03288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STEP CATFormer: Spatial-Temporal Effective Body-Part Cross Attention  Transformer for Skeleton-based Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+N+H+B">Nguyen Huu Bao Long</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to BMVC 2023: Computer Vision for Games and Games for Computer Vision (CVG). 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Graph convolutional networks (GCNs) have been widely used and achieved
remarkable results in skeleton-based action recognition. We think the key to
skeleton-based action recognition is a skeleton hanging in frames, so we focus
on how the Graph Convolutional Convolution networks learn different topologies
and effectively aggregate joint features in the global temporal and local
temporal. In this work, we propose three Channel-wise Tolopogy Graph
Convolution based on Channel-wise Topology Refinement Graph Convolution
(CTR-GCN). Combining CTR-GCN with two joint cross-attention modules can capture
the upper-lower body part and hand-foot relationship skeleton features. After
that, to capture features of human skeletons changing in frames we design the
Temporal Attention Transformers to extract skeletons effectively. The Temporal
Attention Transformers can learn the temporal features of human skeleton
sequences. Finally, we fuse the temporal features output scale with MLP and
classification. We develop a powerful graph convolutional network named Spatial
Temporal Effective Body-part Cross Attention Transformer which notably
high-performance on the NTU RGB+D, NTU RGB+D 120 datasets. Our code and models
are available at https://github.com/maclong01/STEP-CATFormer
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03289" title="Abstract">arXiv:2312.03289</a> [<a href="/pdf/2312.03289" title="Download PDF">pdf</a>, <a href="/format/2312.03289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Class Incremental Learning for Adversarial Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+S">Seungju Cho</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hongshin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Changick Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Adversarial training integrates adversarial examples during model training to
enhance robustness. However, its application in fixed dataset settings differs
from real-world dynamics, where data accumulates incrementally. In this study,
we investigate Adversarially Robust Class Incremental Learning (ARCIL), a
method that combines adversarial robustness with incremental learning. We
observe that combining incremental learning with naive adversarial training
easily leads to a loss of robustness. We discover that this is attributed to
the disappearance of the flatness of the loss function, a characteristic of
adversarial training. To address this issue, we propose the Flatness Preserving
Distillation (FPD) loss that leverages the output difference between
adversarial and clean examples. Additionally, we introduce the Logit Adjustment
Distillation (LAD) loss, which adapts the model's knowledge to perform well on
new tasks. Experimental results demonstrate the superiority of our method over
approaches that apply adversarial training to existing incremental learning
methods, which provides a strong baseline for incremental learning on
adversarial robustness in the future. Our method achieves AutoAttack accuracy
that is 5.99\%p, 5.27\%p, and 3.90\%p higher on average than the baseline on
split CIFAR-10, CIFAR-100, and Tiny ImageNet, respectively. The code will be
made available.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03290" title="Abstract">arXiv:2312.03290</a> [<a href="/pdf/2312.03290" title="Download PDF">pdf</a>, <a href="/format/2312.03290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can language agents be alternatives to PPO? A Preliminary Empirical  Study On OpenAI Gym
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sheng%2C+J">Junjie Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zixiao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chuyun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+Y">Yun Hua</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+B">Bo Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+H">Hongyuan Zha</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiangfeng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The formidable capacity for zero- or few-shot decision-making in language
agents encourages us to pose a compelling question: Can language agents be
alternatives to PPO agents in traditional sequential decision-making tasks? To
investigate this, we first take environments collected in OpenAI Gym as our
testbeds and ground them to textual environments that construct the TextGym
simulator. This allows for straightforward and efficient comparisons between
PPO agents and language agents, given the widespread adoption of OpenAI Gym. To
ensure a fair and effective benchmarking, we introduce $5$ levels of scenario
for accurate domain-knowledge controlling and a unified RL-inspired framework
for language agents. Additionally, we propose an innovative
explore-exploit-guided language (EXE) agent to solve tasks within TextGym.
Through numerical experiments and ablation studies, we extract valuable
insights into the decision-making capabilities of language agents and make a
preliminary evaluation of their potential to be alternatives to PPO in
classical sequential decision-making problems. This paper sheds light on the
performance of language agents and paves the way for future research in this
exciting domain. Our code is publicly available
at~\url{https://github.com/mail-ecnu/Text-Gym-Agents}.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03291" title="Abstract">arXiv:2312.03291</a> [<a href="/pdf/2312.03291" title="Download PDF">pdf</a>, <a href="/format/2312.03291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OMNIINPUT: A Model-centric Evaluation Framework through Output  Distribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weitang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y+W">Ying Wai Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianle Wang</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yi-Zhuang You</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+J">Jingbo Shang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We propose a novel model-centric evaluation framework, OmniInput, to evaluate
the quality of an AI/ML model's predictions on all possible inputs (including
human-unrecognizable ones), which is crucial for AI safety and reliability.
Unlike traditional data-centric evaluation based on pre-defined test sets, the
test set in OmniInput is self-constructed by the model itself and the model
quality is evaluated by investigating its output distribution. We employ an
efficient sampler to obtain representative inputs and the output distribution
of the trained model, which, after selective annotation, can be used to
estimate the model's precision and recall at different output values and a
comprehensive precision-recall curve. Our experiments demonstrate that
OmniInput enables a more fine-grained comparison between models, especially
when their performance is almost the same on pre-defined datasets, leading to
new findings and insights for how to train more robust, generalizable models.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03292" title="Abstract">arXiv:2312.03292</a> [<a href="/pdf/2312.03292" title="Download PDF">pdf</a>, <a href="/format/2312.03292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Molecular Property Prediction via Mixture of Collaborative  Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xu Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Shuang Liang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Songqiao Han</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hailiang Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Molecular Property Prediction (MPP) task involves predicting biochemical
properties based on molecular features, such as molecular graph structures,
contributing to the discovery of lead compounds in drug development. To address
data scarcity and imbalance in MPP, some studies have adopted Graph Neural
Networks (GNN) as an encoder to extract commonalities from molecular graphs.
However, these approaches often use a separate predictor for each task,
neglecting the shared characteristics among predictors corresponding to
different tasks. In response to this limitation, we introduce the GNN-MoCE
architecture. It employs the Mixture of Collaborative Experts (MoCE) as
predictors, exploiting task commonalities while confronting the homogeneity
issue in the expert pool and the decision dominance dilemma within the expert
group. To enhance expert diversity for collaboration among all experts, the
Expert-Specific Projection method is proposed to assign a unique projection
perspective to each expert. To balance decision-making influence for
collaboration within the expert group, the Expert-Specific Loss is presented to
integrate individual expert loss into the weighted decision loss of the group
for more equitable training. Benefiting from the enhancements of MoCE in expert
creation, dynamic expert group formation, and experts' collaboration, our model
demonstrates superior performance over traditional methods on 24 MPP datasets,
especially in tasks with limited data or high imbalance.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03293" title="Abstract">arXiv:2312.03293</a> [<a href="/pdf/2312.03293" title="Download PDF">pdf</a>, <a href="/ps/2312.03293" title="Download PostScript">ps</a>, <a href="/format/2312.03293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Securing Data Platforms: Strategic Masking Techniques for Privacy and  Security for B2B Enterprise Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khoje%2C+M">Mandar Khoje</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">In today's digital age, the imperative to protect data privacy and security
is a paramount concern, especially for business-to-business (B2B) enterprises
that handle sensitive information. These enterprises are increasingly
constructing data platforms, which are integrated suites of technology
solutions architected for the efficient management, processing, storage, and
data analysis. It has become critical to design these data platforms with
mechanisms that inherently support data privacy and security, particularly as
they encounter the added complexity of safeguarding unstructured data types
such as log files and text documents. Within this context, data masking stands
out as a vital feature of data platform architecture. It proactively conceals
sensitive elements, ensuring data privacy while preserving the information's
value for business operations and analytics. This protective measure entails a
strategic two-fold process: firstly, accurately pinpointing the sensitive data
that necessitates concealment, and secondly, applying sophisticated methods to
disguise that data effectively within the data platform infrastructure. This
research delves into the nuances of embedding advanced data masking techniques
within the very fabric of data platforms and an in-depth exploration of how
enterprises can adopt a comprehensive approach toward effective data masking
implementation by exploring different identification and anonymization
techniques.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03295" title="Abstract">arXiv:2312.03295</a> [<a href="/pdf/2312.03295" title="Download PDF">pdf</a>, <a href="/format/2312.03295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-analytic physics informed neural network for convection-dominated  boundary layer problems in 2D
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gie%2C+G">Gung-Min Gie</a>, 
<a href="/search/math?searchtype=author&query=Hong%2C+Y">Youngjoon Hong</a>, 
<a href="/search/math?searchtype=author&query=Jung%2C+C">Chang-Yeol Jung</a>, 
<a href="/search/math?searchtype=author&query=Lee%2C+D">Dongseok Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This research investigates the numerical approximation of the two-dimensional
convection-dominated singularly perturbed problem on square, circular, and
elliptic domains. Singularly perturbed boundary value problems present a
significant challenge due to the presence of sharp boundary layers in their
solutions. Additionally, the considered domain exhibits characteristic points,
giving rise to a degenerate boundary layer problem. The stiffness of the
problem is attributed to the sharp singular layers, which can result in
substantial computational errors if not appropriately addressed. Traditional
numerical methods typically require extensive mesh refinements near the
boundary to achieve accurate solutions, which can be computationally expensive.
To address the challenges posed by singularly perturbed problems, we employ
physics-informed neural networks (PINNs). However, PINNs may struggle with
rapidly varying singularly perturbed solutions over a small domain region,
leading to inadequate resolution and potentially inaccurate or unstable
results. To overcome this limitation, we introduce a semi-analytic method that
augments PINNs with singular layers or corrector functions. Through our
numerical experiments, we demonstrate significant improvements in both accuracy
and stability, thus demonstrating the effectiveness of our proposed approach.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03296" title="Abstract">arXiv:2312.03296</a> [<a href="/pdf/2312.03296" title="Download PDF">pdf</a>, <a href="/format/2312.03296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cooperative Probabilistic Trajectory Forecasting under Occlusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nayak%2C+A">Anshul Nayak</a>, 
<a href="/search/cs?searchtype=author&query=Eskandarian%2C+A">Azim Eskandarian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 13 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Perception and planning under occlusion is essential for safety-critical
tasks. Occlusion-aware planning often requires communicating the information of
the occluded object to the ego agent for safe navigation. However,
communicating rich sensor information under adverse conditions during
communication loss and limited bandwidth may not be always feasible. Further,
in GPS denied environments and indoor navigation, localizing and sharing of
occluded objects can be challenging. To overcome this, relative pose estimation
between connected agents sharing a common field of view can be a
computationally effective way of communicating information about surrounding
objects. In this paper, we design an end-to-end network that cooperatively
estimates the current states of occluded pedestrian in the reference frame of
ego agent and then predicts the trajectory with safety guarantees.
Experimentally, we show that the uncertainty-aware trajectory prediction of
occluded pedestrian by the ego agent is almost similar to the ground truth
trajectory assuming no occlusion. The current research holds promise for
uncertainty-aware navigation among multiple connected agents under occlusion.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03297" title="Abstract">arXiv:2312.03297</a> [<a href="/pdf/2312.03297" title="Download PDF">pdf</a>, <a href="/format/2312.03297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoftMAC: Differentiable Soft Body Simulation with Forecast-based Contact  Model and Two-way Coupling with Articulated Rigid Bodies and Clothes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Min Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Gang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Siyuan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+L">Lin Shao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">Differentiable physics simulation provides an avenue for tackling previously
intractable challenges through gradient-based optimization, thereby greatly
improving the efficiency of solving robotics-related problems. To apply
differentiable simulation in diverse robotic manipulation scenarios, a key
challenge is to integrate various materials in a unified framework. We present
SoftMAC, a differentiable simulation framework coupling soft bodies with
articulated rigid bodies and clothes. SoftMAC simulates soft bodies with the
continuum-mechanics-based Material Point Method (MPM). We provide a
forecast-based contact model for MPM, which greatly reduces artifacts like
penetration and unnatural rebound. To couple MPM particles with deformable and
non-volumetric clothes meshes, we also propose a penetration tracing algorithm
that reconstructs the signed distance field in local area. Based on simulators
for each modality and the contact model, we develop a differentiable coupling
mechanism to simulate the interactions between soft bodies and the other two
types of materials. Comprehensive experiments are conducted to validate the
effectiveness and accuracy of the proposed differentiable pipeline in
downstream robotic manipulation applications. Supplementary materials and
videos are available on our project website at
https://sites.google.com/view/softmac.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03298" title="Abstract">arXiv:2312.03298</a> [<a href="/pdf/2312.03298" title="Download PDF">pdf</a>, <a href="/format/2312.03298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffPMAE: Diffusion Masked Autoencoders for Point Cloud Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanlong Li</a>, 
<a href="/search/cs?searchtype=author&query=Madarasingha%2C+C">Chamara Madarasingha</a>, 
<a href="/search/cs?searchtype=author&query=Thilakarathna%2C+K">Kanchana Thilakarathna</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Point cloud streaming is increasingly getting popular, evolving into the norm
for interactive service delivery and the future Metaverse. However, the
substantial volume of data associated with point clouds presents numerous
challenges, particularly in terms of high bandwidth consumption and large
storage capacity. Despite various solutions proposed thus far, with a focus on
point cloud compression, upsampling, and completion, these
reconstruction-related methods continue to fall short in delivering high
fidelity point cloud output. As a solution, in DiffPMAE, we propose an
effective point cloud reconstruction architecture. Inspired by self-supervised
learning concepts, we combine Masked Auto-Encoding and Diffusion Model
mechanism to remotely reconstruct point cloud data. By the nature of this
reconstruction process, DiffPMAE can be extended to many related downstream
tasks including point cloud compression, upsampling and completion. Leveraging
ShapeNet-55 and ModelNet datasets with over 60000 objects, we validate the
performance of DiffPMAE exceeding many state-of-the-art methods in-terms of
auto-encoding and downstream tasks considered.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03299" title="Abstract">arXiv:2312.03299</a> [<a href="/pdf/2312.03299" title="Download PDF">pdf</a>, <a href="/format/2312.03299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Channel-Transferable Semantic Communications for Multi-User OFDM-NOMA  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Lan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wenjun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fengyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yimeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Ping Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Semantic communications are expected to become the core new paradigms of the
sixth generation (6G) wireless networks. Most existing works implicitly utilize
channel information for codecs training, which leads to poor communications
when channel type or statistical characteristics change. To tackle this issue
posed by various channels, a novel channel-transferable semantic communications
(CT-SemCom) framework is proposed, which adapts the codecs learned on one type
of channel to other types of channels. Furthermore, integrating the proposed
framework and the orthogonal frequency division multiplexing systems
integrating non-orthogonal multiple access technologies, i.e., OFDM-NOMA
systems, a power allocation problem to realize the transfer from additive white
Gaussian noise (AWGN) channels to multi-subcarrier Rayleigh fading channels is
formulated. We then design a semantics-similar dual transformation (SSDT)
algorithm to derive analytical solutions with low complexity. Simulation
results show that the proposed CT-SemCom framework with SSDT algorithm
significantly outperforms the existing work w.r.t. channel transferability,
e.g., the peak signal-to-noise ratio (PSNR) of image transmission improves by
4.2-7.3 dB under different variances of Rayleigh fading channels.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03301" title="Abstract">arXiv:2312.03301</a> [<a href="/pdf/2312.03301" title="Download PDF">pdf</a>, <a href="/format/2312.03301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masking Behaviors in Epidemiological Networks with Cognitively-plausible  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mitsopoulos%2C+K">Konstantinos Mitsopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Baker%2C+L">Lawrence Baker</a>, 
<a href="/search/cs?searchtype=author&query=Lebiere%2C+C">Christian Lebiere</a>, 
<a href="/search/cs?searchtype=author&query=Pirolli%2C+P">Peter Pirolli</a>, 
<a href="/search/cs?searchtype=author&query=Orr%2C+M">Mark Orr</a>, 
<a href="/search/cs?searchtype=author&query=Vardavas%2C+R">Raffaele Vardavas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">The COVID-19 pandemic highlighted the critical role of human behavior in
influencing infectious disease transmission and the need for models capturing
this complex dynamic. We present an agent-based model integrating an
epidemiological simulation of disease spread with a cognitive architecture
driving individual mask-wearing decisions. Agents decide whether to mask based
on a utility function weighting factors like peer conformity, personal risk
tolerance, and mask-wearing discomfort. By conducting experiments
systematically varying behavioral model parameters and social network
structures, we demonstrate how adaptive decision-making interacts with network
connectivity patterns to impact population-level infection outcomes. The model
provides a flexible computational framework for gaining insights into how
behavioral interventions like mask mandates may differentially influence
disease spread across communities with diverse social structures. Findings
highlight the importance of integrating realistic human decision processes in
epidemiological models to inform policy decisions during public health crises.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03303" title="Abstract">arXiv:2312.03303</a> [<a href="/pdf/2312.03303" title="Download PDF">pdf</a>, <a href="/format/2312.03303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dyport: Dynamic Importance-based Hypothesis Generation Benchmarking  Technique
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tyagin%2C+I">Ilya Tyagin</a>, 
<a href="/search/cs?searchtype=author&query=Safro%2C+I">Ilya Safro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper presents a novel benchmarking framework Dyport for evaluating
biomedical hypothesis generation systems. Utilizing curated datasets, our
approach tests these systems under realistic conditions, enhancing the
relevance of our evaluations. We integrate knowledge from the curated databases
into a dynamic graph, accompanied by a method to quantify discovery importance.
This not only assesses hypothesis accuracy but also their potential impact in
biomedical research which significantly extends traditional link prediction
benchmarks. Applicability of our benchmarking process is demonstrated on
several link prediction systems applied on biomedical semantic knowledge
graphs. Being flexible, our benchmarking system is designed for broad
application in hypothesis generation quality verification, aiming to expand the
scope of scientific discovery within the biomedical research community.
Availability and implementation: Dyport framework is fully open-source. All
code and datasets are available at: https://github.com/IlyaTyagin/Dyport
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03305" title="Abstract">arXiv:2312.03305</a> [<a href="/pdf/2312.03305" title="Download PDF">pdf</a>, <a href="/format/2312.03305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A path forward: Improving Internet routing security by enabling zones of  trust
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Clark%2C+D">David Clark</a>, 
<a href="/search/cs?searchtype=author&query=Testart%2C+C">Cecilia Testart</a>, 
<a href="/search/cs?searchtype=author&query=Luckie%2C+M">Matthew Luckie</a>, 
<a href="/search/cs?searchtype=author&query=Claffy%2C+K">KC Claffy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Although Internet routing security best practices have recently seen
auspicious increases in uptake, ISPs have limited incentives to deploy them.
They are operationally complex and expensive to implement, provide little
competitive advantage, and protect only against origin hijacks, leaving
unresolved the more general threat of path hijacks. We propose a new approach
that achieves four design goals: improved incentive alignment to implement best
practices; protection against path hijacks; expanded scope of such protection
to customers of those engaged in the practices; and reliance on existing
capabilities rather than needing complex new software in every participating
router.
<br />Our proposal leverages an existing coherent core of interconnected ISPs to
create a zone of trust, a topological region that protects not only all
networks in the region, but all directly attached customers of those networks.
Customers benefit from choosing ISPs committed to the practices, and ISPs thus
benefit from committing to the practices. We compare our approach to other
schemes, and discuss how a related proposal, ASPA, could be used to increase
the scope of protection our scheme achieves. We hope this proposal inspires
discussion of how the industry can make practical, measurable progress against
the threat of route hijacks in the short term by leveraging institutionalized
cooperation rooted in transparency and accountability.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03309" title="Abstract">arXiv:2312.03309</a> [<a href="/pdf/2312.03309" title="Download PDF">pdf</a>, <a href="/format/2312.03309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Continual Learning from Cognitive Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoqian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+P">Peipei Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Continual learning addresses the problem of continuously acquiring and
transferring knowledge without catastrophic forgetting of old concepts. While
humans achieve continual learning via diverse neurocognitive mechanisms, there
is a mismatch between cognitive properties and evaluation methods of continual
learning models. First, the measurement of continual learning models mostly
relies on evaluation metrics at a micro-level, which cannot characterize
cognitive capacities of the model. Second, the measurement is method-specific,
emphasizing model strengths in one aspect while obscuring potential weaknesses
in other respects. To address these issues, we propose to integrate model
cognitive capacities and evaluation metrics into a unified evaluation paradigm.
We first characterize model capacities via desiderata derived from cognitive
properties supporting human continual learning. The desiderata concern (1)
adaptability in varying lengths of task sequence; (2) sensitivity to dynamic
task variations; and (3) efficiency in memory usage and training time
consumption. Then we design evaluation protocols for each desideratum to assess
cognitive capacities of recent continual learning models. Experimental results
show that no method we consider has satisfied all the desiderata and is still
far away from realizing truly continual learning. Although some methods exhibit
some degree of adaptability and efficiency, no method is able to identify task
relationships when encountering dynamic task variations, or achieve a trade-off
in learning similarities and differences between tasks. Inspired by these
results, we discuss possible factors that influence model performance in these
desiderata and provide guidance for the improvement of continual learning
models.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03312" title="Abstract">arXiv:2312.03312</a> [<a href="/pdf/2312.03312" title="Download PDF">pdf</a>, <a href="/format/2312.03312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Two-Pass Cross-Lingual Transfer Learning: Phoneme Recognition  and Phoneme to Grapheme Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+W">Wonjun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+G+G">Gary Geunbae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yunsu Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, ASRU 2023 Accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This research optimizes two-pass cross-lingual transfer learning in
low-resource languages by enhancing phoneme recognition and phoneme-to-grapheme
translation models. Our approach optimizes these two stages to improve speech
recognition across languages. We optimize phoneme vocabulary coverage by
merging phonemes based on shared articulatory characteristics, thus improving
recognition accuracy. Additionally, we introduce a global phoneme noise
generator for realistic ASR noise during phoneme-to-grapheme training to reduce
error propagation. Experiments on the CommonVoice 12.0 dataset show significant
reductions in Word Error Rate (WER) for low-resource languages, highlighting
the effectiveness of our approach. This research contributes to the
advancements of two-pass ASR systems in low-resource languages, offering the
potential for improved cross-lingual transfer learning.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03315" title="Abstract">arXiv:2312.03315</a> [<a href="/pdf/2312.03315" title="Download PDF">pdf</a>, <a href="/ps/2312.03315" title="Download PostScript">ps</a>, <a href="/format/2312.03315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impact of parallel code optimization on computer power consumption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kiselev%2C+E+A">E. A. Kiselev</a>, 
<a href="/search/cs?searchtype=author&query=Telegin%2C+P+N">P. N. Telegin</a>, 
<a href="/search/cs?searchtype=author&query=Baranov%2C+A+V">A. V. Baranov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Software (cs.MS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">The increase in performance and power of computing systems requires the wider
use of program optimizations. The goal of performing optimizations is not only
to reduce program runtime, but also to reduce other computer resources
including power consumption. The goal of the study was to evaluate the impact
of different optimization levels and various optimization strategies on power
consumption. In a series of experiments, it was established that the average
power consumption tends to peak for the programs with optimized source code.
The articles also describes the impact of changing computer architecture on
power consumption graphs. The relationships between the average and median
values of power consumption by example programs are considered. The possibility
of creating program energy consumption profile for a parallel program is shown.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03318" title="Abstract">arXiv:2312.03318</a> [<a href="/pdf/2312.03318" title="Download PDF">pdf</a>, <a href="/format/2312.03318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complementary Benefits of Contrastive Learning and Self-Training Under  Distribution Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garg%2C+S">Saurabh Garg</a>, 
<a href="/search/cs?searchtype=author&query=Setlur%2C+A">Amrith Setlur</a>, 
<a href="/search/cs?searchtype=author&query=Lipton%2C+Z+C">Zachary Chase Lipton</a>, 
<a href="/search/cs?searchtype=author&query=Balakrishnan%2C+S">Sivaraman Balakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+V">Virginia Smith</a>, 
<a href="/search/cs?searchtype=author&query=Raghunathan%2C+A">Aditi Raghunathan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
<p class="mathjax">Self-training and contrastive learning have emerged as leading techniques for
incorporating unlabeled data, both under distribution shift (unsupervised
domain adaptation) and when it is absent (semi-supervised learning). However,
despite the popularity and compatibility of these techniques, their efficacy in
combination remains unexplored. In this paper, we undertake a systematic
empirical investigation of this combination, finding that (i) in domain
adaptation settings, self-training and contrastive learning offer significant
complementary gains; and (ii) in semi-supervised learning settings,
surprisingly, the benefits are not synergistic. Across eight distribution shift
datasets (e.g., BREEDs, WILDS), we demonstrate that the combined method obtains
3--8% higher accuracy than either approach independently. We then theoretically
analyze these techniques in a simplified model of distribution shift,
demonstrating scenarios under which the features produced by contrastive
learning can yield a good initialization for self-training to further amplify
gains and achieve optimal performance, even when either method alone would
fail.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03322" title="Abstract">arXiv:2312.03322</a> [<a href="/pdf/2312.03322" title="Download PDF">pdf</a>, <a href="/format/2312.03322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Background Clustering Pre-training for Few-shot Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhimiao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+T">Tiancheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yi Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures, ICIP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent few-shot segmentation (FSS) methods introduce an extra pre-training
stage before meta-training to obtain a stronger backbone, which has become a
standard step in few-shot learning. Despite the effectiveness, current
pre-training scheme suffers from the merged background problem: only base
classes are labelled as foregrounds, making it hard to distinguish between
novel classes and actual background. In this paper, we propose a new
pre-training scheme for FSS via decoupling the novel classes from background,
called Background Clustering Pre-Training (BCPT). Specifically, we adopt online
clustering to the pixel embeddings of merged background to explore the
underlying semantic structures, bridging the gap between pre-training and
adaptation to novel classes. Given the clustering results, we further propose
the background mining loss and leverage base classes to guide the clustering
process, improving the quality and stability of clustering results. Experiments
on PASCAL-5i and COCO-20i show that BCPT yields advanced performance. Code will
be available.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03325" title="Abstract">arXiv:2312.03325</a> [<a href="/pdf/2312.03325" title="Download PDF">pdf</a>, <a href="/format/2312.03325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GCFA:Geodesic Curve Feature Augmentation via Shape Space Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yuexing Han</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+G">Guanxin Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bing Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning has yielded remarkable outcomes in various domains. However,
the challenge of requiring large-scale labeled samples still persists in deep
learning. Thus, data augmentation has been introduced as a critical strategy to
train deep learning models. However, data augmentation suffers from information
loss and poor performance in small sample environments. To overcome these
drawbacks, we propose a feature augmentation method based on shape space
theory, i.e., Geodesic curve feature augmentation, called GCFA in brevity.
First, we extract features from the image with the neural network model. Then,
the multiple image features are projected into a pre-shape space as features.
In the pre-shape space, a Geodesic curve is built to fit the features. Finally,
the many generated features on the Geodesic curve are used to train the various
machine learning models. The GCFA module can be seamlessly integrated with most
machine learning methods. And the proposed method is simple, effective and
insensitive for the small sample datasets. Several examples demonstrate that
the GCFA method can greatly improve the performance of the data preprocessing
model in a small sample environment.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03327" title="Abstract">arXiv:2312.03327</a> [<a href="/pdf/2312.03327" title="Download PDF">pdf</a>, <a href="/format/2312.03327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building Category Graphs Representation with Spatial and Temporal  Attention for Visual Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaobo Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Youfang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">HeHe Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhihao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+K">Kai Lv</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages; 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Given an object of interest, visual navigation aims to reach the object's
location based on a sequence of partial observations. To this end, an agent
needs to 1) learn a piece of certain knowledge about the relations of object
categories in the world during training and 2) look for the target object based
on the pre-learned object category relations and its moving trajectory in the
current unseen environment. In this paper, we propose a Category Relation Graph
(CRG) to learn the knowledge of object category layout relations and a
Temporal-Spatial-Region (TSR) attention architecture to perceive the long-term
spatial-temporal dependencies of objects helping the navigation. We learn prior
knowledge of object layout, establishing a category relationship graph to
deduce the positions of specific objects. Subsequently, we introduced TSR to
capture the relationships of objects in temporal, spatial, and regions within
the observation trajectories. Specifically, we propose a Temporal attention
module (T) to model the temporal structure of the observation sequence, which
implicitly encodes the historical moving or trajectory information. Then, a
Spatial attention module (S) is used to uncover the spatial context of the
current observation objects based on the category relation graph and past
observations. Last, a Region attention module (R) shifts the attention to the
target-relevant region. Based on the visual representation extracted by our
method, the agent can better perceive the environment and easily learn superior
navigation policy. Experiments on AI2-THOR demonstrate our CRG-TSR method
significantly outperforms existing methods regarding both effectiveness and
efficiency. The code has been included in the supplementary material and will
be publicly available.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03328" title="Abstract">arXiv:2312.03328</a> [<a href="/pdf/2312.03328" title="Download PDF">pdf</a>, <a href="/format/2312.03328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning for Koopman-based Dynamic Movement Primitives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+T">Tyler Han</a>, 
<a href="/search/cs?searchtype=author&query=Henshaw%2C+C+G">Carl Glen Henshaw</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The challenge of teaching robots to perform dexterous manipulation, dynamic
locomotion, or whole--body manipulation from a small number of demonstrations
is an important research field that has attracted interest from across the
robotics community. In this work, we propose a novel approach by joining the
theories of Koopman Operators and Dynamic Movement Primitives to Learning from
Demonstration. Our approach, named \gls{admd}, projects nonlinear dynamical
systems into linear latent spaces such that a solution reproduces the desired
complex motion. Use of an autoencoder in our approach enables generalizability
and scalability, while the constraint to a linear system attains
interpretability. Our results are comparable to the Extended Dynamic Mode
Decomposition on the LASA Handwriting dataset but with training on only a small
fractions of the letters.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03330" title="Abstract">arXiv:2312.03330</a> [<a href="/pdf/2312.03330" title="Download PDF">pdf</a>, <a href="/format/2312.03330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring Misogyny in Natural Language Generation: Preliminary Results  from a Case Study on two Reddit Communities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Snoswell%2C+A+J">Aaron J. Snoswell</a>, 
<a href="/search/cs?searchtype=author&query=Nelson%2C+L">Lucinda Nelson</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Hao Xue</a>, 
<a href="/search/cs?searchtype=author&query=Salim%2C+F+D">Flora D. Salim</a>, 
<a href="/search/cs?searchtype=author&query=Suzor%2C+N">Nicolas Suzor</a>, 
<a href="/search/cs?searchtype=author&query=Burgess%2C+J">Jean Burgess</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This extended abstract was presented at the Generation, Evaluation and Metrics workshop at Empirical Methods in Natural Language Processing in 2023 (GEM@EMNLP 2023) in Singapore
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Generic `toxicity' classifiers continue to be used for evaluating the
potential for harm in natural language generation, despite mounting evidence of
their shortcomings. We consider the challenge of measuring misogyny in natural
language generation, and argue that generic `toxicity' classifiers are
inadequate for this task. We use data from two well-characterised `Incel'
communities on Reddit that differ primarily in their degrees of misogyny to
construct a pair of training corpora which we use to fine-tune two language
models. We show that an open source `toxicity' classifier is unable to
distinguish meaningfully between generations from these models. We contrast
this with a misogyny-specific lexicon recently proposed by feminist
subject-matter experts, demonstrating that, despite the limitations of simple
lexicon-based approaches, this shows promise as a benchmark to evaluate
language models for misogyny, and that it is sensitive enough to reveal the
known differences in these Reddit communities. Our preliminary findings
highlight the limitations of a generic approach to evaluating harms, and
further emphasise the need for careful benchmark design and selection in
natural language evaluation.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03335" title="Abstract">arXiv:2312.03335</a> [<a href="/pdf/2312.03335" title="Download PDF">pdf</a>, <a href="/ps/2312.03335" title="Download PostScript">ps</a>, <a href="/format/2312.03335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EndWatch: A Practical Method for Detecting Non-Termination in Real-World  Software
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaofei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yi Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaohong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Detecting non-termination is crucial for ensuring program correctness and
security, such as preventing denial-of-service attacks. While termination
analysis has been studied for many years, existing methods have limited
scalability and are only effective on small programs. To address this issue, we
propose a practical termination checking technique, called EndWatch, for
detecting non-termination caused by infinite loops through testing.
Specifically, we introduce two methods to generate non-termination oracles
based on checking state revisits, i.e., if the program returns to a previously
visited state at the same program location, it does not terminate. The
non-termination oracles can be incorporated into testing tools (e.g., AFL used
in this paper) to detect non-termination in large programs. For linear loops,
we perform symbolic execution on individual loops to infer State Revisit
Conditions (SRCs) and instrument SRCs into target loops. For non-linear loops,
we instrument target loops for checking concrete state revisits during
execution. We evaluated EndWatch on standard benchmarks with small-sized
programs and real-world projects with large-sized programs. The evaluation
results show that EndWatch is more effective than the state-of-the-art tools on
standard benchmarks (detecting 87% of non-terminating programs while the best
baseline detects only 67%), and useful in detecting non-termination in
real-world projects (detecting 90% of known non-termination CVEs and 4 unknown
bugs).
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03337" title="Abstract">arXiv:2312.03337</a> [<a href="/pdf/2312.03337" title="Download PDF">pdf</a>, <a href="/format/2312.03337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of Generalized Iteratively Regularized Landweber Iterations  driven by data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aspri%2C+A">Andrea Aspri</a>, 
<a href="/search/math?searchtype=author&query=Scherzer%2C+O">Otmar Scherzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We investigate generalized versions of the Iteratively Regularized Landweber
Method, initially introduced in [Appl. Math. Optim., 38(1):45-68, 1998], to
address linear and nonlinear ill-posed problems. Our approach is inspired by
the data-driven perspective emphasized in the introduction by Aspri et al.
[Numer. Funct. Anal. Optim., 41(10):1190-1227, 2020]. We provide a rigorous
analysis establishing convergence and stability results and present numerical
outcomes for linear operators, with the Radon transform serving as a prototype.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03339" title="Abstract">arXiv:2312.03339</a> [<a href="/pdf/2312.03339" title="Download PDF">pdf</a>, <a href="/ps/2312.03339" title="Download PostScript">ps</a>, <a href="/format/2312.03339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PointJEM: Self-supervised Point Cloud Understanding for Reducing Feature  Redundancy via Joint Entropy Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+H">Huan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xinxin Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kang Li</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+L">Linzhi Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Most deep learning-based point cloud processing methods are supervised and
require large scale of labeled data. However, manual labeling of point cloud
data is laborious and time-consuming. Self-supervised representation learning
can address the aforementioned issue by learning robust and generalized
representations from unlabeled datasets. Nevertheless, the embedded features
obtained by representation learning usually contain redundant information, and
most current methods reduce feature redundancy by linear correlation
constraints. In this paper, we propose PointJEM, a self-supervised
representation learning method applied to the point cloud field. PointJEM
comprises an embedding scheme and a loss function based on joint entropy. The
embedding scheme divides the embedding vector into different parts, each part
can learn a distinctive feature. To reduce redundant information in the
features, PointJEM maximizes the joint entropy between the different parts,
thereby rendering the learned feature variables pairwise independent. To
validate the effectiveness of our method, we conducted experiments on multiple
datasets. The results demonstrate that our method can significantly reduce
feature redundancy beyond linear correlation. Furthermore, PointJEM achieves
competitive performance in downstream tasks such as classification and
segmentation.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03341" title="Abstract">arXiv:2312.03341</a> [<a href="/pdf/2312.03341" title="Download PDF">pdf</a>, <a href="/format/2312.03341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Vectorized HD Map Construction using Geometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhixin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+X">Xiaohan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+F">Fusheng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+X">Xiangyu Yue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website <a href="https://invictus717.github.io/GeMap/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The construction of online vectorized High-Definition (HD) maps is critical
for downstream prediction and planning. Recent efforts have built strong
baselines for this task, however, shapes and relations of instances in urban
road systems are still under-explored, such as parallelism, perpendicular, or
rectangle-shape. In our work, we propose GeMap ($\textbf{Ge}$ometry
$\textbf{Map}$), which end-to-end learns Euclidean shapes and relations of map
instances beyond basic perception. Specifically, we design a geometric loss
based on angle and distance clues, which is robust to rigid transformations. We
also decouple self-attention to independently handle Euclidean shapes and
relations. Our method achieves new state-of-the-art performance on the NuScenes
and Argoverse 2 datasets. Remarkably, it reaches a 71.8% mAP on the large-scale
Argoverse 2 dataset, outperforming MapTR V2 by +4.4% and surpassing the 70% mAP
threshold for the first time. Code is available at
https://github.com/cnzzx/GeMap
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03342" title="Abstract">arXiv:2312.03342</a> [<a href="/pdf/2312.03342" title="Download PDF">pdf</a>, <a href="/format/2312.03342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topic and genre in dialogue
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Decker%2C+A">Amandine Decker</a> (LORIA, GU, UL), 
<a href="/search/cs?searchtype=author&query=Breitholtz%2C+E">Ellen Breitholtz</a> (GU), 
<a href="/search/cs?searchtype=author&query=Howes%2C+C">Christine Howes</a> (GU), 
<a href="/search/cs?searchtype=author&query=Larsson%2C+S">Staffan Larsson</a> (GU)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SEMDIAL 2023, Aug 2023, Maribor, Slovenia. pp.143-145
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this paper we argue that topic plays a fundamental role in conversations,
and that the concept is needed in addition to that of genre to define
interactions. In particular, the concepts of genre and topic need to be
separated and orthogonally defined. This would enable modular, reliable and
controllable flexible-domain dialogue systems.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03344" title="Abstract">arXiv:2312.03344</a> [<a href="/pdf/2312.03344" title="Download PDF">pdf</a>, <a href="/format/2312.03344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable Mechanistic Representations for Meal-level Glycemic  Control in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+K+A">Ke Alexander Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fox%2C+E+B">Emily B. Fox</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of Machine Learning for Health (ML4H) 2023. Code available at: <a href="https://github.com/KeAWang/interpretable-cgm-representations">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Dynamical Systems (math.DS); Applications (stat.AP); Machine Learning (stat.ML)

</div>
<p class="mathjax">Diabetes encompasses a complex landscape of glycemic control that varies
widely among individuals. However, current methods do not faithfully capture
this variability at the meal level. On the one hand, expert-crafted features
lack the flexibility of data-driven methods; on the other hand, learned
representations tend to be uninterpretable which hampers clinical adoption. In
this paper, we propose a hybrid variational autoencoder to learn interpretable
representations of CGM and meal data. Our method grounds the latent space to
the inputs of a mechanistic differential equation, producing embeddings that
reflect physiological quantities, such as insulin sensitivity, glucose
effectiveness, and basal glucose levels. Moreover, we introduce a novel method
to infer the glucose appearance rate, making the mechanistic model robust to
unreliable meal logs. On a dataset of CGM and self-reported meals from
individuals with type-2 diabetes and pre-diabetes, our unsupervised
representation discovers a separation between individuals proportional to their
disease severity. Our embeddings produce clusters that are up to 4x better than
naive, expert, black-box, and pure mechanistic features. Our method provides a
nuanced, yet interpretable, embedding space to compare glycemic control within
and across individuals, directly learnable from in-the-wild data.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03345" title="Abstract">arXiv:2312.03345</a> [<a href="/pdf/2312.03345" title="Download PDF">pdf</a>, <a href="/format/2312.03345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraNet: A Multi-Level Graph Network for 6-DoF Grasp Pose Generation in  Cluttered Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haowen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+W">Wanhao Niu</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+C">Chungang Zhuang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">6-DoF object-agnostic grasping in unstructured environments is a critical yet
challenging task in robotics. Most current works use non-optimized approaches
to sample grasp locations and learn spatial features without concerning the
grasping task. This paper proposes GraNet, a graph-based grasp pose generation
framework that translates a point cloud scene into multi-level graphs and
propagates features through graph neural networks. By building graphs at the
scene level, object level, and grasp point level, GraNet enhances feature
embedding at multiple scales while progressively converging to the ideal
grasping locations by learning. Our pipeline can thus characterize the spatial
distribution of grasps in cluttered scenes, leading to a higher rate of
effective grasping. Furthermore, we enhance the representation ability of
scalable graph networks by a structure-aware attention mechanism to exploit
local relations in graphs. Our method achieves state-of-the-art performance on
the large-scale GraspNet-1Billion benchmark, especially in grasping unseen
objects (+11.62 AP). The real robot experiment shows a high success rate in
grasping scattered objects, verifying the effectiveness of the proposed
approach in unstructured environments.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03347" title="Abstract">arXiv:2312.03347</a> [<a href="/pdf/2312.03347" title="Download PDF">pdf</a>, <a href="/format/2312.03347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying hubs in directed networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kirkley%2C+A">Alec Kirkley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Nodes in networks that exhibit high connectivity, also called "hubs", play a
critical role in determining the structural and functional properties of
networked systems. However, there is no clear definition of what constitutes a
hub node in a network, and the classification of network hubs in existing work
has either been purely qualitative or relies on ad hoc criteria for
thresholding continuous data that do not generalize well to networks with
certain degree sequences. Here we develop a set of efficient nonparametric
methods that classify hub nodes in directed networks using the Minimum
Description Length principle, effectively providing a clear and principled
definition for network hubs. We adapt our methods to both unweighted and
weighted networks and demonstrate them in a range of example applications using
real and synthetic network data.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03348" title="Abstract">arXiv:2312.03348</a> [<a href="/pdf/2312.03348" title="Download PDF">pdf</a>, <a href="/format/2312.03348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Propagation on Unimodular Matrix Lie Groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ye%2C+J">Jikai Ye</a>, 
<a href="/search/eess?searchtype=author&query=Jayaraman%2C+A+S">Amitesh S. Jayaraman</a>, 
<a href="/search/eess?searchtype=author&query=Chirikjian%2C+G+S">Gregory S. Chirikjian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This paper addresses uncertainty propagation on unimodular matrix Lie groups
that have a surjective exponential map. We derive the exact formula for the
propagation of mean and covariance in a continuous-time setting from the
governing Fokker-Planck equation. Two approximate propagation methods are
discussed based on the exact formula. One uses numerical quadrature and another
utilizes the expansion of moments. A closed-form second-order propagation
formula is derived. We apply the general theory to the joint attitude and
angular momentum uncertainty propagation problem and numerical experiments
demonstrate two approximation methods. These results show that our new methods
have high accuracy while being computationally efficient.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03350" title="Abstract">arXiv:2312.03350</a> [<a href="/pdf/2312.03350" title="Download PDF">pdf</a>, <a href="/ps/2312.03350" title="Download PostScript">ps</a>, <a href="/format/2312.03350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PointMoment:Mixed-Moment-based Self-Supervised Representation Learning  for 3D Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xinxin Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mengna Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages,3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large and rich data is a prerequisite for effective training of deep neural
networks. However, the irregularity of point cloud data makes manual annotation
time-consuming and laborious. Self-supervised representation learning, which
leverages the intrinsic structure of large-scale unlabelled data to learn
meaningful feature representations, has attracted increasing attention in the
field of point cloud research. However, self-supervised representation learning
often suffers from model collapse, resulting in reduced information and
diversity of the learned representation, and consequently degrading the
performance of downstream tasks. To address this problem, we propose
PointMoment, a novel framework for point cloud self-supervised representation
learning that utilizes a high-order mixed moment loss function rather than the
conventional contrastive loss function. Moreover, our framework does not
require any special techniques such as asymmetric network architectures,
gradient stopping, etc. Specifically, we calculate the high-order mixed moment
of the feature variables and force them to decompose into products of their
individual moment, thereby making multiple variables more independent and
minimizing the feature redundancy. We also incorporate a contrastive learning
approach to maximize the feature invariance under different data augmentations
of the same point cloud. Experimental results show that our approach
outperforms previous unsupervised learning methods on the downstream task of 3D
point cloud classification and segmentation.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03357" title="Abstract">arXiv:2312.03357</a> [<a href="/pdf/2312.03357" title="Download PDF">pdf</a>, <a href="/format/2312.03357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RING-NeRF: A Versatile Architecture based on Residual Implicit Neural  Grids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Petit%2C+D">Doriand Petit</a>, 
<a href="/search/cs?searchtype=author&query=Bourgeois%2C+S">Steve Bourgeois</a>, 
<a href="/search/cs?searchtype=author&query=Pavel%2C+D">Dumitru Pavel</a>, 
<a href="/search/cs?searchtype=author&query=Gay-Bellile%2C+V">Vincent Gay-Bellile</a>, 
<a href="/search/cs?searchtype=author&query=Chabot%2C+F">Florian Chabot</a>, 
<a href="/search/cs?searchtype=author&query=Barthe%2C+L">Loic Barthe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Since their introduction, Neural Fields have become very popular for 3D
reconstruction and new view synthesis. Recent researches focused on
accelerating the process, as well as improving the robustness to variation of
the observation distance and limited number of supervised viewpoints. However,
those approaches often led to dedicated solutions that cannot be easily
combined. To tackle this issue, we introduce a new simple but efficient
architecture named RING-NeRF, based on Residual Implicit Neural Grids, that
provides a control on the level of detail of the mapping function between the
scene and the latent spaces. Associated with a distance-aware forward mapping
mechanism and a continuous coarse-to-fine reconstruction process, our versatile
architecture demonstrates both fast training and state-of-the-art performances
in terms of: (1) anti-aliased rendering, (2) reconstruction quality from few
supervised viewpoints, and (3) robustness in the absence of appropriate
scene-specific initialization for SDF-based NeRFs. We also demonstrate that our
architecture can dynamically add grids to increase the details of the
reconstruction, opening the way to adaptive reconstruction.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03360" title="Abstract">arXiv:2312.03360</a> [<a href="/pdf/2312.03360" title="Download PDF">pdf</a>, <a href="/ps/2312.03360" title="Download PostScript">ps</a>, <a href="/format/2312.03360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teaching Specific Scientific Knowledge into Large Language Models  through Additional Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hatakeyama-Sato%2C+K">Kan Hatakeyama-Sato</a>, 
<a href="/search/cs?searchtype=author&query=Igarashi%2C+Y">Yasuhiko Igarashi</a>, 
<a href="/search/cs?searchtype=author&query=Katakami%2C+S">Shun Katakami</a>, 
<a href="/search/cs?searchtype=author&query=Nabae%2C+Y">Yuta Nabae</a>, 
<a href="/search/cs?searchtype=author&query=Hayakawa%2C+T">Teruaki Hayakawa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Through additional training, we explore embedding specialized scientific
knowledge into the Llama 2 Large Language Model (LLM). Key findings reveal that
effective knowledge integration requires reading texts from multiple
perspectives, especially in instructional formats. We utilize text augmentation
to tackle the scarcity of specialized texts, including style conversions and
translations. Hyperparameter optimization proves crucial, with different size
models (7b, 13b, and 70b) reasonably undergoing additional training. Validating
our methods, we construct a dataset of 65,000 scientific papers. Although we
have succeeded in partially embedding knowledge, the study highlights the
complexities and limitations of incorporating specialized information into
LLMs, suggesting areas for further improvement.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03361" title="Abstract">arXiv:2312.03361</a> [<a href="/pdf/2312.03361" title="Download PDF">pdf</a>, <a href="/format/2312.03361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KhabarChin: Automatic Detection of Important News in the Persian  Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hemati%2C+H+H">Hamed Hematian Hemati</a> (1), 
<a href="/search/cs?searchtype=author&query=Lagzian%2C+A">Arash Lagzian</a> (1), 
<a href="/search/cs?searchtype=author&query=Sartakhti%2C+M+S">Moein Salimi Sartakhti</a> (1), 
<a href="/search/cs?searchtype=author&query=Beigy%2C+H">Hamid Beigy</a> (1), 
<a href="/search/cs?searchtype=author&query=Asgari%2C+E">Ehsaneddin Asgari</a> (2) ((1) AI Group, Computer Engineering Department, Sharif University of Technology, (2) AI Innovation, Data:Lab Munich, Volkswagen AG)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Being aware of important news is crucial for staying informed and making
well-informed decisions efficiently. Natural Language Processing (NLP)
approaches can significantly automate this process. This paper introduces the
detection of important news, in a previously unexplored area, and presents a
new benchmarking dataset (Khabarchin) for detecting important news in the
Persian language. We define important news articles as those deemed significant
for a considerable portion of society, capable of influencing their mindset or
decision-making. The news articles are obtained from seven different prominent
Persian news agencies, resulting in the annotation of 7,869 samples and the
creation of the dataset. Two challenges of high disagreement and imbalance
between classes were faced, and solutions were provided for them. We also
propose several learning-based models, ranging from conventional machine
learning to state-of-the-art transformer models, to tackle this task.
Furthermore, we introduce the second task of important sentence detection in
news articles, as they often come with a significant contextual length that
makes it challenging for readers to identify important information. We identify
these sentences in a weakly supervised manner.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03365" title="Abstract">arXiv:2312.03365</a> [<a href="/pdf/2312.03365" title="Download PDF">pdf</a>, <a href="/format/2312.03365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demand response for residential building heating: Effective Monte Carlo  Tree Search control based on physics-informed neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pavirani%2C+F">Fabio Pavirani</a>, 
<a href="/search/eess?searchtype=author&query=Gokhale%2C+G">Gargya Gokhale</a>, 
<a href="/search/eess?searchtype=author&query=Claessens%2C+B">Bert Claessens</a>, 
<a href="/search/eess?searchtype=author&query=Develder%2C+C">Chris Develder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Controlling energy consumption in buildings through demand response (DR) has
become increasingly important to reduce global carbon emissions and limit
climate change. In this paper, we specifically focus on controlling the heating
system of a residential building to optimize its energy consumption while
respecting user's thermal comfort. Recent works in this area have mainly
focused on either model-based control, e.g., model predictive control (MPC), or
model-free reinforcement learning (RL) to implement practical DR algorithms. A
specific RL method that recently has achieved impressive success in domains
such as board games (go, chess) is Monte Carlo Tree Search (MCTS). Yet, for
building control it has remained largely unexplored. Thus, we study MCTS
specifically for building demand response. Its natural structure allows a
flexible optimization that implicitly integrate exogenous constraints (as
opposed, for example, to conventional RL solutions), making MCTS a promising
candidate for DR control problems. We demonstrate how to improve MCTS control
performance by incorporating a Physics-informed Neural Network (PiNN) model for
its underlying thermal state prediction, as opposed to traditional purely
data-driven Black-Box approaches. Our MCTS implementation aligned with a PiNN
model is able to obtain a 3% increment of the obtained reward compared to a
rule-based controller; leading to a 10% cost reduction and 35% reduction on
temperature difference with the desired one when applied to an artificial price
profile. We further implemented a Deep Learning layer into the Monte Carlo Tree
Search technique using a neural network that leads the tree search through more
optimal nodes. We then compared this addition with its Vanilla version, showing
the improvement in computational cost required.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03367" title="Abstract">arXiv:2312.03367</a> [<a href="/pdf/2312.03367" title="Download PDF">pdf</a>, <a href="/format/2312.03367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lazy-k: Decoding for Constrained Token Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hemmer%2C+A">Arthur Hemmer</a>, 
<a href="/search/cs?searchtype=author&query=Coustaty%2C+M">Micka&#xeb;l Coustaty</a>, 
<a href="/search/cs?searchtype=author&query=Bartolo%2C+N">Nicola Bartolo</a>, 
<a href="/search/cs?searchtype=author&query=Brachat%2C+J">J&#xe9;r&#xf4;me Brachat</a>, 
<a href="/search/cs?searchtype=author&query=Ogier%2C+J">Jean-Marc Ogier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted EMNLP Main 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We explore the possibility of improving probabilistic models in structured
prediction. Specifically, we combine the models with constrained decoding
approaches in the context of token classification for information extraction.
The decoding methods search for constraint-satisfying label-assignments while
maximizing the total probability. To do this, we evaluate several existing
approaches, as well as propose a novel decoding method called Lazy-$k$. Our
findings demonstrate that constrained decoding approaches can significantly
improve the models' performances, especially when using smaller models. The
Lazy-$k$ approach allows for more flexibility between decoding time and
accuracy. The code for using Lazy-$k$ decoding can be found here:
https://github.com/ArthurDevNL/lazyk.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03369" title="Abstract">arXiv:2312.03369</a> [<a href="/pdf/2312.03369" title="Download PDF">pdf</a>, <a href="/format/2312.03369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of Linux-PRNG (Pseudo Random Number Generator)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bansal%2C+A">Ayush Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Subramanyan%2C+P">Pramod Subramanyan</a>, 
<a href="/search/cs?searchtype=author&query=Nandakumar%2C+S">Satyadev Nandakumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">The Linux pseudorandom number generator (PRNG) is a PRNG with entropy inputs
and is widely used in many security-related applications and protocols. This
PRNG is written as an open-source code which is subject to regular changes. It
has been analysed in the works of Gutterman et al., Lacharme et al., while in
the meantime, several changes have been applied to the code, to counter the
attacks presented since then. Our work describes the Linux PRNG of kernel
versions 5.3 and upwards. We discuss the PRNG architecture briefly and in
detail about the entropy mixing function.
<br />Our goal is to study the entropy mixing function and analyse it over two
properties, namely, injectivity and length of the longest chain. For this
purpose, we will be using SAT solving and model counting over targetted
formulas involving multiple states of the Linux entropy store.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03372" title="Abstract">arXiv:2312.03372</a> [<a href="/pdf/2312.03372" title="Download PDF">pdf</a>, <a href="/ps/2312.03372" title="Download PostScript">ps</a>, <a href="/format/2312.03372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the point cloud of individual trees generated from images  based on Neural Radiance fields (NeRF) method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hongyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+G">Guoji Tian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chongcheng Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages; 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Three-dimensional (3D) reconstruction of trees has always been a key task in
precision forestry management and research. Due to the complex branch
morphological structure of trees themselves and the occlusions from tree stems,
branches and foliage, it is difficult to recreate a complete three-dimensional
tree model from a two-dimensional image by conventional photogrammetric
methods. In this study, based on tree images collected by various cameras in
different ways, the Neural Radiance Fields (NeRF) method was used for
individual tree reconstruction and the exported point cloud models are compared
with point cloud derived from photogrammetric reconstruction and laser scanning
methods. The results show that the NeRF method performs well in individual tree
3D reconstruction, as it has higher successful reconstruction rate, better
reconstruction in the canopy area, it requires less amount of images as input.
Compared with photogrammetric reconstruction method, NeRF has significant
advantages in reconstruction efficiency and is adaptable to complex scenes, but
the generated point cloud tends to be noisy and low resolution. The accuracy of
tree structural parameters (tree height and diameter at breast height)
extracted from the photogrammetric point cloud is still higher than those of
derived from the NeRF point cloud. The results of this study illustrate the
great potential of NeRF method for individual tree reconstruction, and it
provides new ideas and research directions for 3D reconstruction and
visualization of complex forest scenes.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03373" title="Abstract">arXiv:2312.03373</a> [<a href="/pdf/2312.03373" title="Download PDF">pdf</a>, <a href="/format/2312.03373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EnvGuard : Guaranteeing Environment-Centric Properties in Web of Things
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Bingkun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Liwei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jialin Ren</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xin Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">With the accelerated advancement of IoT, diverse devices are ubiquitously
deployed in environments. Building on this, Web of Things (WoT) further
integrates fragmented device services and provides unified interfaces using
standardized Web technologies, promoting the development and deployment of WoT
applications to sense and regulate the environment. However, disparate WoT
applications independently control devices in the WoT environment, causing
interference among devices and with the environment. This results in device
behaviors that deviate from user expectations, causing violations of the user's
desired environment properties. The intricate interplay of applications, user
activities, and environment changes makes identifying and resolving potential
violations a complex task. In this paper, we introduce EnvGuard, an
environment-centric approach for property description, violation
identification, and resolution in WoT environment. EnvGuard proposes a
conceptual schema to model the relationship between device services and
environment context, and automatically extends the conceptual schema into a
specific environment representation based on device and space information.
Furthermore, EnvGuard employs a template-based approach, enabling users to
describe spatial and temporal properties based on the abstract device effects
on the environment, and translating properties description into formal
expressions. EnvGuard adopts a hybrid model checking method to respectively
identify the spatial and temporal violations, and a resolution strategy that
align with user intention is proposed to resolve violations. We evaluate
EnvGuard through user studies and our proposed dataset, which is constructed by
collecting real-world data from a laboratory WoT environment and manually
labeling ten types of violations. The results confirm the usability,
feasibility and efficiency of EnvGuard.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03374" title="Abstract">arXiv:2312.03374</a> [<a href="/pdf/2312.03374" title="Download PDF">pdf</a>, <a href="/format/2312.03374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implementing Digital Twin in Field-Deployed Optical Networks: Uncertain  Factors, Operational Guidance, and Field-Trial Demonstration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yuchen Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Shikui Shen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+B">Bingli Guo</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shanguo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Danshi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures Accepted by IEEE Network Magazine, early access
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Digital twin has revolutionized optical communication networks by enabling
their full life-cycle management, including design, troubleshooting,
optimization, upgrade, and prediction. While extensive literature exists on
frameworks, standards, and applications of digital twin, there is a pressing
need in implementing digital twin in field-deployed optical networks operating
in real-world environments, as opposed to controlled laboratory settings. This
paper addresses this challenge by examining the uncertain factors behind the
inaccuracy of digital twin in field-deployed optical networks from three main
challenges and proposing operational guidance for implementing accurate digital
twin in field-deployed optical networks. Through the proposed guidance, we
demonstrate the effective implementation of digital twin in a field-trial
C+L-band optical transmission link, showcasing its capabilities in performance
recovery in a fiber cut scenario.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03376" title="Abstract">arXiv:2312.03376</a> [<a href="/pdf/2312.03376" title="Download PDF">pdf</a>, <a href="/format/2312.03376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beacon-enabled TDMA Ultraviolet Communication Network System Design and  Realization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pan%2C+Y">Yuchen Pan</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yubo Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Long%2C+F">Fei Long</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+P">Ping Li</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+H">Haotian Shi</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+J">Jiazhao Shi</a>, 
<a href="/search/eess?searchtype=author&query=Xiao%2C+H">Hanlin Xiao</a>, 
<a href="/search/eess?searchtype=author&query=Gong%2C+C">Chen Gong</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Z">Zhengyuan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Nonline of sight (NLOS) ultraviolet (UV) scattering communication can serve
as a good candidate for outdoor optical wireless communication (OWC) in the
cases of non-perfect transmitter-receiver alignment and radio silence. We
design and demonstrate a NLOS UV scattering communication network system in
this paper, where a beacon-enabled time division multiple access (TDMA) scheme
is adopted. In our system, LED and PMT are employed for transmitter and
receiver devices, repectivey. Furthermore, we design algorithms for beacon
transmission, beacon reception, time compensation, and time slot transition for
hardware realization in field-programmable gate array (FPGA) board based on
master-slave structure, where master node periodically transmits beacon signals
to slave nodes. Experimental results are provided to evaluate the time
synchronization error and specify the system key parameters for real-time
implementation. We perform field tests for real-time communication network with
the transmission range over 110 multiplied by 90 square meters, where the
system throughput reaches 800kbps.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03378" title="Abstract">arXiv:2312.03378</a> [<a href="/pdf/2312.03378" title="Download PDF">pdf</a>, <a href="/format/2312.03378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Riemannian Complex Matrix Convolution Network for PolSAR Image  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Junfei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Haiyan Jin</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+M">Mengmeng Nie</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shanshan Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, deep learning methods have achieved superior performance for
Polarimetric Synthetic Aperture Radar(PolSAR) image classification. Existing
deep learning methods learn PolSAR data by converting the covariance matrix
into a feature vector or complex-valued vector as the input. However, all these
methods cannot learn the structure of complex matrix directly and destroy the
channel correlation. To learn geometric structure of complex matrix, we propose
a Riemannian complex matrix convolution network for PolSAR image classification
in Riemannian space for the first time, which directly utilizes the complex
matrix as the network input and defines the Riemannian operations to learn
complex matrix's features. The proposed Riemannian complex matrix convolution
network considers PolSAR complex matrix endowed in Riemannian manifold, and
defines a series of new Riemannian convolution, ReLu and LogEig operations in
Riemannian space, which breaks through the Euclidean constraint of conventional
networks. Then, a CNN module is appended to enhance contextual Riemannian
features. Besides, a fast kernel learning method is developed for the proposed
method to learn class-specific features and reduce the computation time
effectively. Experiments are conducted on three sets of real PolSAR data with
different bands and sensors. Experiments results demonstrates the proposed
method can obtain superior performance than the state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03379" title="Abstract">arXiv:2312.03379</a> [<a href="/pdf/2312.03379" title="Download PDF">pdf</a>, <a href="/format/2312.03379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Text-to-Text Model for Multilingual Offensive Language Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ranasinghe%2C+T">Tharindu Ranasinghe</a>, 
<a href="/search/cs?searchtype=author&query=Zampieri%2C+M">Marcos Zampieri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Findings of IJCNLP-AACL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The ubiquity of offensive content on social media is a growing cause for
concern among companies and government organizations. Recently,
transformer-based models such as BERT, XLNET, and XLM-R have achieved
state-of-the-art performance in detecting various forms of offensive content
(e.g. hate speech, cyberbullying, and cyberaggression). However, the majority
of these models are limited in their capabilities due to their encoder-only
architecture, which restricts the number and types of labels in downstream
tasks. Addressing these limitations, this study presents the first pre-trained
model with encoder-decoder architecture for offensive language identification
with text-to-text transformers (T5) trained on two large offensive language
identification datasets; SOLID and CCTK. We investigate the effectiveness of
combining two datasets and selecting an optimal threshold in semi-supervised
instances in SOLID in the T5 retraining step. Our pre-trained T5 model
outperforms other transformer-based models fine-tuned for offensive language
detection, such as fBERT and HateBERT, in multiple English benchmarks.
Following a similar approach, we also train the first multilingual pre-trained
model for offensive language identification using mT5 and evaluate its
performance on a set of six different languages (German, Hindi, Korean,
Marathi, Sinhala, and Spanish). The results demonstrate that this multilingual
model achieves a new state-of-the-art on all the above datasets, showing its
usefulness in multilingual scenarios. Our proposed T5-based models will be made
freely available to the community.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03386" title="Abstract">arXiv:2312.03386</a> [<a href="/pdf/2312.03386" title="Download PDF">pdf</a>, <a href="/format/2312.03386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Infinite-Width Analysis on the Jacobian-Regularised Training of a  Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taeyoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongseok Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 72 pages, 21 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">The recent theoretical analysis of deep neural networks in their
infinite-width limits has deepened our understanding of initialisation, feature
learning, and training of those networks, and brought new practical techniques
for finding appropriate hyperparameters, learning network weights, and
performing inference. In this paper, we broaden this line of research by
showing that this infinite-width analysis can be extended to the Jacobian of a
deep neural network. We show that a multilayer perceptron (MLP) and its
Jacobian at initialisation jointly converge to a Gaussian process (GP) as the
widths of the MLP's hidden layers go to infinity and characterise this GP. We
also prove that in the infinite-width limit, the evolution of the MLP under the
so-called robust training (i.e., training with a regulariser on the Jacobian)
is described by a linear first-order ordinary differential equation that is
determined by a variant of the Neural Tangent Kernel. We experimentally show
the relevance of our theoretical claims to wide finite networks, and
empirically analyse the properties of kernel regression solution to obtain an
insight into Jacobian regularisation.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03391" title="Abstract">arXiv:2312.03391</a> [<a href="/pdf/2312.03391" title="Download PDF">pdf</a>, <a href="/format/2312.03391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Action Scene Graphs for Long-Form Understanding of Egocentric Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rodin%2C+I">Ivan Rodin</a>, 
<a href="/search/cs?searchtype=author&query=Furnari%2C+A">Antonino Furnari</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+K">Kyle Min</a>, 
<a href="/search/cs?searchtype=author&query=Tripathi%2C+S">Subarna Tripathi</a>, 
<a href="/search/cs?searchtype=author&query=Farinella%2C+G+M">Giovanni Maria Farinella</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present Egocentric Action Scene Graphs (EASGs), a new representation for
long-form understanding of egocentric videos. EASGs extend standard
manually-annotated representations of egocentric videos, such as verb-noun
action labels, by providing a temporally evolving graph-based description of
the actions performed by the camera wearer, including interacted objects, their
relationships, and how actions unfold in time. Through a novel annotation
procedure, we extend the Ego4D dataset by adding manually labeled Egocentric
Action Scene Graphs offering a rich set of annotations designed for long-from
egocentric video understanding. We hence define the EASG generation task and
provide a baseline approach, establishing preliminary benchmarks. Experiments
on two downstream tasks, egocentric action anticipation and egocentric activity
summarization, highlight the effectiveness of EASGs for long-form egocentric
video understanding. We will release the dataset and the code to replicate
experiments and annotations.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03392" title="Abstract">arXiv:2312.03392</a> [<a href="/pdf/2312.03392" title="Download PDF">pdf</a>, <a href="/format/2312.03392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> O&#x27;Neill&#x27;s Theorem for Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Govindan%2C+S">Srihari Govindan</a>, 
<a href="/search/cs?searchtype=author&query=Laraki%2C+R">Rida Laraki</a>, 
<a href="/search/cs?searchtype=author&query=Pahl%2C+L">Lucas Pahl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We present an analog of O'Neill's Theorem (Theorem 5.2 in [17]) for finite
games, which reveals a picture of the structure of equilibria under payoff
perturbations in finite games.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03393" title="Abstract">arXiv:2312.03393</a> [<a href="/pdf/2312.03393" title="Download PDF">pdf</a>, <a href="/format/2312.03393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PS$^3$: Precise Patch Presence Test based on Semantic Symbolic Signature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Q">Qi Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shanping Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">During software development, vulnerabilities have posed a significant threat
to users. Patches are the most effective way to combat vulnerabilities. In a
large-scale software system, testing the presence of a security patch in every
affected binary is crucial to ensure system security. Identifying whether a
binary has been patched for a known vulnerability is challenging, as there may
only be small differences between patched and vulnerable versions. Existing
approaches mainly focus on detecting patches that are compiled in the same
compiler options. However, it is common for developers to compile programs with
very different compiler options in different situations, which causes
inaccuracy for existing methods. In this paper, we propose a new approach named
\textbf{\textit{PS}$^3$}, referring to \emph{precise patch presence} test based
on \emph{semantic-level symbolic signature}. \textbf{\textit{PS}$^3$} exploits
symbolic emulation to extract signatures that are stable under different
compiler options. Then \textbf{\textit{PS}$^3$} can precisely test the presence
of the patch by comparing the signatures between the reference and the target
at semantic level.
<br />To evaluate the effectiveness of our approach, we constructed a dataset
consisting of 3,631 (CVE, binary) pairs of 62 recent CVEs in four C/C++
projects. The experimental results show that \textbf{\textit{PS}$^3$} achieves
scores of 0.82, 0.97, and 0.89 in terms of precision, recall, and F1 score,
respectively. \textbf{\textit{PS}$^3$} outperforms the state-of-the-art
baselines by improving 33\% in terms of F1 score and remains stable in
different compiler options.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03395" title="Abstract">arXiv:2312.03395</a> [<a href="/pdf/2312.03395" title="Download PDF">pdf</a>, <a href="/format/2312.03395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffused Task-Agnostic Milestone Planner
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+M">Mineui Hong</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+M">Minjae Kang</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+S">Songhwai Oh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37th Conference on Neural Information Processing Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Addressing decision-making problems using sequence modeling to predict future
trajectories shows promising results in recent years. In this paper, we take a
step further to leverage the sequence predictive method in wider areas such as
long-term planning, vision-based control, and multi-task decision-making. To
this end, we propose a method to utilize a diffusion-based generative sequence
model to plan a series of milestones in a latent space and to have an agent to
follow the milestones to accomplish a given task. The proposed method can learn
control-relevant, low-dimensional latent representations of milestones, which
makes it possible to efficiently perform long-term planning and vision-based
control. Furthermore, our approach exploits generation flexibility of the
diffusion model, which makes it possible to plan diverse trajectories for
multi-task decision-making. We demonstrate the proposed method across offline
reinforcement learning (RL) benchmarks and an visual manipulation environment.
The results show that our approach outperforms offline RL methods in solving
long-horizon, sparse-reward tasks and multi-task problems, while also achieving
the state-of-the-art performance on the most challenging vision-based
manipulation benchmark.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03397" title="Abstract">arXiv:2312.03397</a> [<a href="/pdf/2312.03397" title="Download PDF">pdf</a>, <a href="/format/2312.03397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Contrastive Divergence: Joint Training of Energy-Based Model  and Diffusion Model through Inverse Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S">Sangwoong Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+D">Dohyun Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+H">Himchan Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Noh%2C+Y">Yung-Kyun Noh</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+F+C">Frank C. Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Workshop on Diffusion Models
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present Generalized Contrastive Divergence (GCD), a novel objective
function for training an energy-based model (EBM) and a sampler simultaneously.
GCD generalizes Contrastive Divergence (Hinton, 2002), a celebrated algorithm
for training EBM, by replacing Markov Chain Monte Carlo (MCMC) distribution
with a trainable sampler, such as a diffusion model. In GCD, the joint training
of EBM and a diffusion model is formulated as a minimax problem, which reaches
an equilibrium when both models converge to the data distribution. The minimax
learning with GCD bears interesting equivalence to inverse reinforcement
learning, where the energy corresponds to a negative reward, the diffusion
model is a policy, and the real data is expert demonstrations. We present
preliminary yet promising results showing that joint training is beneficial for
both EBM and a diffusion model. GCD enables EBM training without MCMC while
improving the sample quality of a diffusion model.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03406" title="Abstract">arXiv:2312.03406</a> [<a href="/pdf/2312.03406" title="Download PDF">pdf</a>, <a href="/format/2312.03406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SVQ: Sparse Vector Quantization for Spatiotemporal Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yanjun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Liang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+R">Rong Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Spatiotemporal forecasting tasks, such as weather forecasting and traffic
prediction, offer significant societal benefits. These tasks can be effectively
approached as image forecasting problems using computer vision models. Vector
quantization (VQ) is a well-known method for discrete representation that
improves the latent space, leading to enhanced generalization and transfer
learning capabilities. One of the main challenges in using VQ for
spatiotemporal forecasting is how to balance between keeping enough details and
removing noises from the original patterns for better generalization. We
address this challenge by developing sparse vector quantization, or {\bf SVQ}
for short, that leverages sparse regression to make better trade-off between
the two objectives. The main innovation of this work is to approximate sparse
regression by a two-layer MLP and a randomly fixed or learnable matrix,
dramatically improving its computational efficiency. Through experiments
conducted on diverse datasets in multiple fields including weather forecasting,
traffic flow prediction, and video forecasting, we unequivocally demonstrate
that our proposed method consistently enhances the performance of base models
and achieves state-of-the-art results across all benchmarks.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03407" title="Abstract">arXiv:2312.03407</a> [<a href="/pdf/2312.03407" title="Download PDF">pdf</a>, <a href="/ps/2312.03407" title="Download PostScript">ps</a>, <a href="/format/2312.03407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extremal Fitting CQs do not Generalize
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cate%2C+B+t">Balder ten Cate</a>, 
<a href="/search/cs?searchtype=author&query=Funk%2C+M">Maurice Funk</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+J+C">Jean Christoph Jung</a>, 
<a href="/search/cs?searchtype=author&query=Lutz%2C+C">Carsten Lutz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">A fitting algorithm for conjunctive queries (CQs) produces, given a set of
positively and negatively labeled data examples, a CQ that fits these examples.
In general, there may be many non-equivalent fitting CQs and thus the algorithm
has some freedom in producing its output. Additional desirable properties of
the produced CQ are that it generalizes well to unseen examples in the sense of
PAC learning and that it is most general or most specific in the set of all
fitting CQs. In this research note, we show that these desiderata are
incompatible when we require PAC-style generalization from a polynomial sample:
we prove that any fitting algorithm that produces a most-specific fitting CQ
cannot be a sample-efficient PAC learning algorithm, and the same is true for
fitting algorithms that produce a most-general fitting CQ (when it exists). Our
proofs rely on a polynomial construction of relativized homomorphism dualities
for path-shaped structures.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03408" title="Abstract">arXiv:2312.03408</a> [<a href="/pdf/2312.03408" title="Download PDF">pdf</a>, <a href="/format/2312.03408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open-sourced Data Ecosystem in Autonomous Driving: the Present and  Future
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+J">Jia Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+P">Pinlong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huilin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Feng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+L">Lu Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingdong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Futang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+K">Kai Yan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chunjing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tiancai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+B">Beipeng Mu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Shaoqing Ren</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zhihui Peng</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article is a simplified English translation of corresponding Chinese article. Please refer to Chinese version for the complete content
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the continuous maturation and application of autonomous driving
technology, a systematic examination of open-source autonomous driving datasets
becomes instrumental in fostering the robust evolution of the industry
ecosystem. Current autonomous driving datasets can broadly be categorized into
two generations. The first-generation autonomous driving datasets are
characterized by relatively simpler sensor modalities, smaller data scale, and
is limited to perception-level tasks. KITTI, introduced in 2012, serves as a
prominent representative of this initial wave. In contrast, the
second-generation datasets exhibit heightened complexity in sensor modalities,
greater data scale and diversity, and an expansion of tasks from perception to
encompass prediction and control. Leading examples of the second generation
include nuScenes and Waymo, introduced around 2019. This comprehensive review,
conducted in collaboration with esteemed colleagues from both academia and
industry, systematically assesses over seventy open-source autonomous driving
datasets from domestic and international sources. It offers insights into
various aspects, such as the principles underlying the creation of high-quality
datasets, the pivotal role of data engine systems, and the utilization of
generative foundation models to facilitate scalable data generation.
Furthermore, this review undertakes an exhaustive analysis and discourse
regarding the characteristics and data scales that future third-generation
autonomous driving datasets should possess. It also delves into the scientific
and technical challenges that warrant resolution. These endeavors are pivotal
in advancing autonomous innovation and fostering technological enhancement in
critical domains. For further details, please refer to
https://github.com/OpenDriveLab/DriveAGI.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03409" title="Abstract">arXiv:2312.03409</a> [<a href="/pdf/2312.03409" title="Download PDF">pdf</a>, <a href="/format/2312.03409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepPyramid+: Medical Image Segmentation using Pyramid View Fusion and  Deformable Pyramid Reception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghamsarian%2C+N">Negin Ghamsarian</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+S">Sebastian Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Zinkernagel%2C+M">Martin Zinkernagel</a>, 
<a href="/search/cs?searchtype=author&query=Schoeffmann%2C+K">Klaus Schoeffmann</a>, 
<a href="/search/cs?searchtype=author&query=Sznitman%2C+R">Raphael Sznitman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semantic Segmentation plays a pivotal role in many applications related to
medical image and video analysis. However, designing a neural network
architecture for medical image and surgical video segmentation is challenging
due to the diverse features of relevant classes, including heterogeneity,
deformability, transparency, blunt boundaries, and various distortions. We
propose a network architecture, DeepPyramid+, which addresses diverse
challenges encountered in medical image and surgical video segmentation. The
proposed DeepPyramid+ incorporates two major modules, namely "Pyramid View
Fusion" (PVF) and "Deformable Pyramid Reception," (DPR), to address the
outlined challenges. PVF replicates a deduction process within the neural
network, aligning with the human visual system, thereby enhancing the
representation of relative information at each pixel position. Complementarily,
DPR introduces shape- and scale-adaptive feature extraction techniques using
dilated deformable convolutions, enhancing accuracy and robustness in handling
heterogeneous classes and deformable shapes. Extensive experiments conducted on
diverse datasets, including endometriosis videos, MRI images, OCT scans, and
cataract and laparoscopy videos, demonstrate the effectiveness of DeepPyramid+
in handling various challenges such as shape and scale variation, reflection,
and blur degradation. DeepPyramid+ demonstrates significant improvements in
segmentation performance, achieving up to a 3.65% increase in Dice coefficient
for intra-domain segmentation and up to a 17% increase in Dice coefficient for
cross-domain segmentation. DeepPyramid+ consistently outperforms
state-of-the-art networks across diverse modalities considering different
backbone networks, showcasing its versatility.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03410" title="Abstract">arXiv:2312.03410</a> [<a href="/pdf/2312.03410" title="Download PDF">pdf</a>, <a href="/format/2312.03410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Voice Cloning Attacks via Timbre Watermarking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+N">Nenghai Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NDSS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Nowadays, it is common to release audio content to the public. However, with
the rise of voice cloning technology, attackers have the potential to easily
impersonate a specific person by utilizing his publicly released audio without
any permission. Therefore, it becomes significant to detect any potential
misuse of the released audio content and protect its timbre from being
impersonated. To this end, we introduce a novel concept, "Timbre Watermarking",
which embeds watermark information into the target individual's speech,
eventually defeating the voice cloning attacks. To ensure the watermark is
robust to the voice cloning model's learning process, we design an end-to-end
voice cloning-resistant detection framework. The core idea of our solution is
to embed and extract the watermark in the frequency domain in a temporally
invariant manner. To acquire generalization across different voice cloning
attacks, we modulate their shared process and integrate it into our framework
as a distortion layer. Experiments demonstrate that the proposed timbre
watermarking can defend against different voice cloning attacks, exhibit strong
resistance against various adaptive attacks (e.g., reconstruction-based removal
attacks, watermark overwriting attacks), and achieve practicality in real-world
services such as PaddleSpeech, Voice-Cloning-App, and so-vits-svc. In addition,
ablation studies are also conducted to verify the effectiveness of our design.
Some audio samples are available at
https://timbrewatermarking.github.io/samples.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03411" title="Abstract">arXiv:2312.03411</a> [<a href="/pdf/2312.03411" title="Download PDF">pdf</a>, <a href="/format/2312.03411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated clustering of video games into groups with distinctive names
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grelier%2C+N">Nicolas Grelier</a>, 
<a href="/search/cs?searchtype=author&query=Kaufmann%2C+S">St&#xe9;phane Kaufmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">When doing a study on a large number of video games, it may be difficult to
cluster them into coherent groups to better study them. In this paper, we
introduce a novel algorithm, that takes as input any set of games S that are
released on Steam and an integer k, and cluster S into k groups. Each group is
then assigned a distinctive name in the form of a Steam tag. We believe our
tool to be valuable for gaining deeper insights into the video game market. We
show that our algorithm maximises an objective function that we introduce, the
naming score, which assesses the quality of a clustering and how distinctive
its name is.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03413" title="Abstract">arXiv:2312.03413</a> [<a href="/pdf/2312.03413" title="Download PDF">pdf</a>, <a href="/format/2312.03413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximating Solutions to the Knapsack Problem using the Lagrangian  Dual Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Keegan%2C+M">Mitchell Keegan</a>, 
<a href="/search/cs?searchtype=author&query=Abolghasemi%2C+M">Mahdi Abolghasemi</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Lecture Notes in Computer Science, vol 14471 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
<p class="mathjax">The Knapsack Problem is a classic problem in combinatorial optimisation.
Solving these problems may be computationally expensive. Recent years have seen
a growing interest in the use of deep learning methods to approximate the
solutions to such problems. A core problem is how to enforce or encourage
constraint satisfaction in predicted solutions. A promising approach for
predicting solutions to constrained optimisation problems is the Lagrangian
Dual Framework which builds on the method of Lagrangian Relaxation. In this
paper we develop neural network models to approximate Knapsack Problem
solutions using the Lagrangian Dual Framework while improving constraint
satisfaction. We explore the problems of output interpretation and model
selection within this context. Experimental results show strong constraint
satisfaction with a minor reduction of optimality as compared to a baseline
neural network which does not explicitly model the constraints.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03414" title="Abstract">arXiv:2312.03414</a> [<a href="/pdf/2312.03414" title="Download PDF">pdf</a>, <a href="/format/2312.03414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compressed Context Memory For Online Language Model Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jang-Hyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yeom%2C+J">Junyoung Yeom</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+S">Sangdoo Yun</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H+O">Hyun Oh Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">This paper presents a novel context compression method for Transformer
language models in online scenarios such as ChatGPT, where the context
continually expands. As the context lengthens, the attention process requires
more memory and computational resources, which in turn reduces the throughput
of the language model. To this end, we propose a compressed context memory
system that continually compresses the growing context into a compact memory
space. The compression process simply involves integrating a lightweight
conditional LoRA into the language model's forward pass during inference. Based
on the compressed context memory, the language model can perform inference with
reduced memory and attention operations. Through evaluations on conversation,
personalization, and multi-task learning, we demonstrate that our approach
achieves the performance level of a full context model with $5\times$ smaller
context memory space. Codes are available at
https://github.com/snu-mllab/context-memory.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03415" title="Abstract">arXiv:2312.03415</a> [<a href="/pdf/2312.03415" title="Download PDF">pdf</a>, <a href="/format/2312.03415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Run LoRA Run: Faster and Lighter LoRA Implementations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cherniuk%2C+D">Daria Cherniuk</a>, 
<a href="/search/cs?searchtype=author&query=Mikhalev%2C+A">Aleksandr Mikhalev</a>, 
<a href="/search/cs?searchtype=author&query=Oseledets%2C+I">Ivan Oseledets</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">LoRA is a technique that reduces the number of trainable parameters in a
neural network by introducing low-rank adapters to linear layers. This
technique is used both for fine-tuning (LoRA, QLoRA) and full train (ReLoRA).
This paper presents the RunLoRA framework for efficient implementations of LoRA
that significantly improves the speed of neural network training and
fine-tuning using low-rank adapters. The proposed implementation optimizes the
computation of LoRA operations based on dimensions of corresponding linear
layer, layer input dimensions and lora rank by choosing best forward and
backward computation graph based on FLOPs and time estimations, resulting in
faster training without sacrificing accuracy. The experimental results show up
to 17% speedup on Llama family of models.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03419" title="Abstract">arXiv:2312.03419</a> [<a href="/pdf/2312.03419" title="Download PDF">pdf</a>, <a href="/format/2312.03419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthesizing Physical Backdoor Datasets: An Automated Framework  Leveraging Deep Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S+J">Sze Jue Yang</a>, 
<a href="/search/cs?searchtype=author&query=La%2C+C+D">Chinh D. La</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q+H">Quang H. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Bagdasaryan%2C+E">Eugene Bagdasaryan</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kok-Seng Wong</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+A+T">Anh Tuan Tran</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+C+S">Chee Seng Chan</a>, 
<a href="/search/cs?searchtype=author&query=Doan%2C+K+D">Khoa D. Doan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Backdoor attacks, representing an emerging threat to the integrity of deep
neural networks, have garnered significant attention due to their ability to
compromise deep learning systems clandestinely. While numerous backdoor attacks
occur within the digital realm, their practical implementation in real-world
prediction systems remains limited and vulnerable to disturbances in the
physical world. Consequently, this limitation has given rise to the development
of physical backdoor attacks, where trigger objects manifest as physical
entities within the real world. However, creating the requisite dataset to
train or evaluate a physical backdoor model is a daunting task, limiting the
backdoor researchers and practitioners from studying such physical attack
scenarios. This paper unleashes a recipe that empowers backdoor researchers to
effortlessly create a malicious, physical backdoor dataset based on advances in
generative modeling. Particularly, this recipe involves 3 automatic modules:
suggesting the suitable physical triggers, generating the poisoned candidate
samples (either by synthesizing new samples or editing existing clean samples),
and finally refining for the most plausible ones. As such, it effectively
mitigates the perceived complexity associated with creating a physical backdoor
dataset, transforming it from a daunting task into an attainable objective.
Extensive experiment results show that datasets created by our "recipe" enable
adversaries to achieve an impressive attack success rate on real physical world
data and exhibit similar properties compared to previous physical backdoor
attack studies. This paper offers researchers a valuable toolkit for studies of
physical backdoors, all within the confines of their laboratories.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03420" title="Abstract">arXiv:2312.03420</a> [<a href="/pdf/2312.03420" title="Download PDF">pdf</a>, <a href="/format/2312.03420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Artist-Friendly Relightable and Animatable Neural Heads
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yingyan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chandran%2C+P">Prashanth Chandran</a>, 
<a href="/search/cs?searchtype=author&query=Weiss%2C+S">Sebastian Weiss</a>, 
<a href="/search/cs?searchtype=author&query=Gross%2C+M">Markus Gross</a>, 
<a href="/search/cs?searchtype=author&query=Zoss%2C+G">Gaspard Zoss</a>, 
<a href="/search/cs?searchtype=author&query=Bradley%2C+D">Derek Bradley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">An increasingly common approach for creating photo-realistic digital avatars
is through the use of volumetric neural fields. The original neural radiance
field (NeRF) allowed for impressive novel view synthesis of static heads when
trained on a set of multi-view images, and follow up methods showed that these
neural representations can be extended to dynamic avatars. Recently, new
variants also surpassed the usual drawback of baked-in illumination in neural
representations, showing that static neural avatars can be relit in any
environment. In this work we simultaneously tackle both the motion and
illumination problem, proposing a new method for relightable and animatable
neural heads. Our method builds on a proven dynamic avatar approach based on a
mixture of volumetric primitives, combined with a recently-proposed lightweight
hardware setup for relightable neural fields, and includes a novel architecture
that allows relighting dynamic neural avatars performing unseen expressions in
any environment, even with nearfield illumination and viewpoints.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03422" title="Abstract">arXiv:2312.03422</a> [<a href="/pdf/2312.03422" title="Download PDF">pdf</a>, <a href="/format/2312.03422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive flexibility function in smart energy systems: A linearized  price-demand mapping approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tohidi%2C+S+S">Seyed Shahabaldin Tohidi</a>, 
<a href="/search/eess?searchtype=author&query=Madsen%2C+H">Henrik Madsen</a>, 
<a href="/search/eess?searchtype=author&query=Tsaousoglou%2C+G">Georgios Tsaousoglou</a>, 
<a href="/search/eess?searchtype=author&query=Ritschel%2C+T+K+S">Tobias K. S. Ritschel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper proposes an adaptive mechanism for price signal generation using a
piecewise linear approximation of a flexibility function with unknown
parameters. In this adaptive approach, the price signal is parameterized and
the parameters are changed adaptively such that the output of the flexibility
function follows the reference demand signal provided by the involved
aggregator. This is guaranteed using the Lyapunov stability theorem. The
proposed method does not require an estimation algorithm for unknown
parameters, that eliminates the need for persistency of excitation of signals,
and consequently, simplifies offering the flexibility services. Furthermore,
boundedness of the price signal is ensured using a projection algorithm in the
adaptive system. We present simulation results that demonstrate the price
generation results using the proposed approaches.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03426" title="Abstract">arXiv:2312.03426</a> [<a href="/pdf/2312.03426" title="Download PDF">pdf</a>, <a href="/format/2312.03426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Internal and External Calculi: Ordering the Jungle without Being Lost in  Translations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyon%2C+T+S">Tim S. Lyon</a>, 
<a href="/search/cs?searchtype=author&query=Ciabattoni%2C+A">Agata Ciabattoni</a>, 
<a href="/search/cs?searchtype=author&query=Galmiche%2C+D">Didier Galmiche</a>, 
<a href="/search/cs?searchtype=author&query=Larchey-Wendling%2C+D">Dominique Larchey-Wendling</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%A9ry%2C+D">Daniel M&#xe9;ry</a>, 
<a href="/search/cs?searchtype=author&query=Olivetti%2C+N">Nicola Olivetti</a>, 
<a href="/search/cs?searchtype=author&query=Ramanayake%2C+R">Revantha Ramanayake</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Logic (math.LO)

</div>
<p class="mathjax">This paper gives a broad account of the various sequent-based proof
formalisms in the proof-theoretic literature. We consider formalisms for
various modal and tense logics, intuitionistic logic, conditional logics, and
bunched logics. After providing an overview of the logics and proof formalisms
under consideration, we show how these sequent-based formalisms can be placed
in a hierarchy in terms of the underlying data structure of the sequents. We
then discuss how this hierarchy can be traversed using translations.
Translating proofs up this hierarchy is found to be relatively easy while
translating proofs down the hierarchy is substantially more difficult. Finally,
we inspect the prevalent distinction in structural proof theory between
'internal calculi' and 'external calculi'. It is observed that these classes
resist a rigorous separation, and we critically assess the properties that
(calculi from) these classes are purported to possess.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03428" title="Abstract">arXiv:2312.03428</a> [<a href="/pdf/2312.03428" title="Download PDF">pdf</a>, <a href="/format/2312.03428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Crafting Realistic Virtual Humans: Unveiling Perspectives on Human  Perception, Crowds, and Embodied Conversational Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Montanha%2C+R">Rubens Montanha</a>, 
<a href="/search/cs?searchtype=author&query=Araujo%2C+V">Victor Araujo</a>, 
<a href="/search/cs?searchtype=author&query=Knob%2C+P">Paulo Knob</a>, 
<a href="/search/cs?searchtype=author&query=Pinho%2C+G">Greice Pinho</a>, 
<a href="/search/cs?searchtype=author&query=Fonseca%2C+G">Gabriel Fonseca</a>, 
<a href="/search/cs?searchtype=author&query=Peres%2C+V">Vitor Peres</a>, 
<a href="/search/cs?searchtype=author&query=Musse%2C+S+R">Soraia Raupp Musse</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tutorial accepted on the 36th Conference on Graphics, Patterns and Images (SIBGRAPI 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Virtual Humans (VHs) were first developed more than 50 years ago and have
undergone significant advancements since then. In the past, creating and
animating VHs was a complex task. However, contemporary commercial and freely
available technology now empowers users, programmers, and designers to create
and animate VHs with relative ease. These technologies have even reached a
point where they can replicate the authentic characteristics and behaviors of
real actors, resulting in VHs that are visually convincing and behaviorally
lifelike. This paper explores three closely related research areas in the
context of virtual humans and discusses the far-reaching implications of highly
realistic characters within these domains.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03429" title="Abstract">arXiv:2312.03429</a> [<a href="/pdf/2312.03429" title="Download PDF">pdf</a>, <a href="/format/2312.03429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Behavioral Authentication for Security and Safety
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hangyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Junhan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Changjun Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The issues of both system security and safety can be dissected integrally
from the perspective of behavioral \emph{appropriateness}. That is, a system is
secure or safe can be judged by whether the behavior of certain agent(s) is
\emph{appropriate} or not. Specifically, a so-called \emph{appropriate
behavior} involves the right agent performing the right actions at the right
time under certain conditions. Then, according to different levels of
appropriateness and degrees of custodies, behavioral authentication can be
graded into three levels, i.e., the authentication of behavioral
\emph{Identity}, \emph{Conformity}, and \emph{Benignity}. In a broad sense, for
the security and safety issue, behavioral authentication is not only an
innovative and promising method due to its inherent advantages but also a
critical and fundamental problem due to the ubiquity of behavior generation and
the necessity of behavior regulation in any system. By this classification,
this review provides a comprehensive examination of the background and
preliminaries of behavioral authentication. It further summarizes existing
research based on their respective focus areas and characteristics. The
challenges confronted by current behavioral authentication methods are
analyzed, and potential research directions are discussed to promote the
diversified and integrated development of behavioral authentication.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03430" title="Abstract">arXiv:2312.03430</a> [<a href="/pdf/2312.03430" title="Download PDF">pdf</a>, <a href="/format/2312.03430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ShareCMP: Polarization-Aware RGB-P Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhuoyan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lizhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+C">Chenyu Mao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Ye Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multimodal semantic segmentation is developing rapidly, but the modality of
RGB-Polarization remains underexplored. To delve into this problem, we
construct a UPLight RGB-P segmentation benchmark with 12 typical underwater
semantic classes which provides data support for Autonomous Underwater Vehicles
(AUVs) to perform special perception tasks. In this work, we design the
ShareCMP, an RGB-P semantic segmentation framework with a shared dual-branch
architecture, which reduces the number of parameters by about 26-33% compared
to previous dual-branch models. It encompasses a Polarization Generate
Attention (PGA) module designed to generate polarization modal images with
richer polarization properties for the encoder. In addition, we introduce the
Class Polarization-Aware Loss (CPALoss) to improve the learning and
understanding of the encoder for polarization modal information and to optimize
the PGA module. With extensive experiments on a total of three RGB-P
benchmarks, our ShareCMP achieves state-of-the-art performance in mIoU with
fewer parameters on the UPLight (92.45%), ZJU (92.7%), and MCubeS (50.99%)
datasets. The code is available at https://github.com/LEFTeyex/ShareCMP.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03431" title="Abstract">arXiv:2312.03431</a> [<a href="/pdf/2312.03431" title="Download PDF">pdf</a>, <a href="/format/2312.03431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian-Flow: 4D Reconstruction with Dynamic 3D Gaussian Particle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Youtian Lin</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Z">Zuozhuo Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Siyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yao Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce Gaussian-Flow, a novel point-based approach for fast dynamic
scene reconstruction and real-time rendering from both multi-view and monocular
videos. In contrast to the prevalent NeRF-based approaches hampered by slow
training and rendering speeds, our approach harnesses recent advancements in
point-based 3D Gaussian Splatting (3DGS). Specifically, a novel Dual-Domain
Deformation Model (DDDM) is proposed to explicitly model attribute deformations
of each Gaussian point, where the time-dependent residual of each attribute is
captured by a polynomial fitting in the time domain, and a Fourier series
fitting in the frequency domain. The proposed DDDM is capable of modeling
complex scene deformations across long video footage, eliminating the need for
training separate 3DGS for each frame or introducing an additional implicit
neural field to model 3D dynamics. Moreover, the explicit deformation modeling
for discretized Gaussian points ensures ultra-fast training and rendering of a
4D scene, which is comparable to the original 3DGS designed for static 3D
reconstruction. Our proposed approach showcases a substantial efficiency
improvement, achieving a $5\times$ faster training speed compared to the
per-frame 3DGS modeling. In addition, quantitative results demonstrate that the
proposed Gaussian-Flow significantly outperforms previous leading methods in
novel view rendering quality. Project page:
https://nju-3dv.github.io/projects/Gaussian-Flow
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03435" title="Abstract">arXiv:2312.03435</a> [<a href="/pdf/2312.03435" title="Download PDF">pdf</a>, <a href="/ps/2312.03435" title="Download PostScript">ps</a>, <a href="/format/2312.03435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counting Butterflies in Fully Dynamic Bipartite Graph Streams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papadias%2C+S">Serafeim Papadias</a>, 
<a href="/search/cs?searchtype=author&query=Kaoudi%2C+Z">Zoi Kaoudi</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+V">Varun Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Quiane-Ruiz%2C+J">Jorge-Arnulfo Quiane-Ruiz</a>, 
<a href="/search/cs?searchtype=author&query=Markl%2C+V">Volker Markl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">A bipartite graph extensively models relationships between real-world
entities of two different types, such as user-product data in e-commerce. Such
graph data are inherently becoming more and more streaming, entailing
continuous insertions and deletions of edges. A butterfly (i.e., 2x2 bi-clique)
is the smallest non-trivial cohesive structure that plays a crucial role.
Counting such butterfly patterns in streaming bipartite graphs is a core
problem in applications such as dense subgraph discovery and anomaly detection.
Yet, existing approximate solutions consider insert-only streams and, thus,
achieve very low accuracy in fully dynamic bipartite graph streams that involve
both insertions and deletions of edges. Adapting them to consider deletions is
not trivial either, because different sampling schemes and new accuracy
analyses are required. In this paper, we propose Abacus, a novel approximate
algorithm that counts butterflies in the presence of both insertions and
deletions by utilizing sampling. We prove that Abacus always delivers unbiased
estimates of low variance. Furthermore, we extend Abacus and devise a parallel
mini-batch variant, namely, Parabacus, which counts butterflies in parallel.
Parabacus counts butterflies in a load-balanced manner using versioned samples,
which results in significant speedup and is thus ideal for critical
applications in the streaming environment. We evaluate Abacus/Parabacus using a
diverse set of real bipartite graphs and assess its performance in terms of
accuracy, throughput, and speedup. The results indicate that our proposal is
the first capable of efficiently providing accurate butterfly counts in the
most generic setting, i.e., a fully dynamic graph streaming environment that
entails both insertions and deletions. It does so without sacrificing
throughput and even improving it with the parallel version.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03437" title="Abstract">arXiv:2312.03437</a> [<a href="/pdf/2312.03437" title="Download PDF">pdf</a>, <a href="/format/2312.03437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Centric Digital Agriculture: A Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roscher%2C+R">Ribana Roscher</a>, 
<a href="/search/cs?searchtype=author&query=Roth%2C+L">Lukas Roth</a>, 
<a href="/search/cs?searchtype=author&query=Stachniss%2C+C">Cyrill Stachniss</a>, 
<a href="/search/cs?searchtype=author&query=Walter%2C+A">Achim Walter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In response to the increasing global demand for food, feed, fiber, and fuel,
digital agriculture is rapidly evolving to meet these demands while reducing
environmental impact. This evolution involves incorporating data science,
machine learning, sensor technologies, robotics, and new management strategies
to establish a more sustainable agricultural framework. So far, machine
learning research in digital agriculture has predominantly focused on
model-centric approaches, focusing on model design and evaluation. These
efforts aim to optimize model accuracy and efficiency, often treating data as a
static benchmark. Despite the availability of agricultural data and
methodological advancements, a saturation point has been reached, with many
established machine learning methods achieving comparable levels of accuracy
and facing similar limitations. To fully realize the potential of digital
agriculture, it is crucial to have a comprehensive understanding of the role of
data in the field and to adopt data-centric machine learning. This involves
developing strategies to acquire and curate valuable data and implementing
effective learning and evaluation strategies that utilize the intrinsic value
of data. This approach has the potential to create accurate, generalizable, and
adaptable machine learning methods that effectively and sustainably address
agricultural tasks such as yield prediction, weed detection, and early disease
identification
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03441" title="Abstract">arXiv:2312.03441</a> [<a href="/pdf/2312.03441" title="Download PDF">pdf</a>, <a href="/format/2312.03441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UFineBench: Towards Text-based Person Retrieval with Ultra-fine  Granularity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zuo%2C+J">Jialong Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hanyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Y">Ying Nie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Feng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Tianyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+N">Nong Sang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Changxin Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing text-based person retrieval datasets often have relatively
coarse-grained text annotations. This hinders the model to comprehend the
fine-grained semantics of query texts in real scenarios. To address this
problem, we contribute a new benchmark named \textbf{UFineBench} for text-based
person retrieval with ultra-fine granularity.
<br />Firstly, we construct a new \textbf{dataset} named UFine6926. We collect a
large number of person images and manually annotate each image with two
detailed textual descriptions, averaging 80.8 words each. The average word
count is three to four times that of the previous datasets. In addition of
standard in-domain evaluation, we also propose a special \textbf{evaluation
paradigm} more representative of real scenarios. It contains a new evaluation
set with cross domains, cross textual granularity and cross textual styles,
named UFine3C, and a new evaluation metric for accurately measuring retrieval
ability, named mean Similarity Distribution (mSD). Moreover, we propose CFAM, a
more efficient \textbf{algorithm} especially designed for text-based person
retrieval with ultra fine-grained texts. It achieves fine granularity mining by
adopting a shared cross-modal granularity decoder and hard negative match
mechanism.
<br />With standard in-domain evaluation, CFAM establishes competitive performance
across various datasets, especially on our ultra fine-grained UFine6926.
Furthermore, by evaluating on UFine3C, we demonstrate that training on our
UFine6926 significantly improves generalization to real scenarios compared with
other coarse-grained datasets. The dataset and code will be made publicly
available at \url{https://github.com/Zplusdragon/UFineBench}.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03442" title="Abstract">arXiv:2312.03442</a> [<a href="/pdf/2312.03442" title="Download PDF">pdf</a>, <a href="/format/2312.03442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Quality Facial Geometry and Appearance Capture at Home
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yuxuan Han</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+J">Junfeng Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Feng Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://yxuhan.github.io/CoRA/index.html">this https URL</a> ; Github repo: <a href="https://github.com/yxuhan/CoRA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Facial geometry and appearance capture have demonstrated tremendous success
in 3D scanning real humans in studios. Recent works propose to democratize this
technique while keeping the results high quality. However, they are still
inconvenient for daily usage. In addition, they focus on an easier problem of
only capturing facial skin. This paper proposes a novel method for high-quality
face capture, featuring an easy-to-use system and the capability to model the
complete face with skin, mouth interior, hair, and eyes. We reconstruct facial
geometry and appearance from a single co-located smartphone flashlight sequence
captured in a dim room where the flashlight is the dominant light source (e.g.
rooms with curtains or at night). To model the complete face, we propose a
novel hybrid representation to effectively model both eyes and other facial
regions, along with novel techniques to learn it from images. We apply a
combined lighting model to compactly represent real illuminations and exploit a
morphable face albedo model as a reflectance prior to disentangle diffuse and
specular. Experiments show that our method can capture high-quality 3D
relightable scans.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03443" title="Abstract">arXiv:2312.03443</a> [<a href="/pdf/2312.03443" title="Download PDF">pdf</a>, <a href="/format/2312.03443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven Crop Growth Simulation on Time-varying Generated Images  using Multi-conditional Generative Adversarial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Drees%2C+L">Lukas Drees</a>, 
<a href="/search/cs?searchtype=author&query=Demie%2C+D+T">Dereje T. Demie</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+M+R">Madhuri R. Paul</a>, 
<a href="/search/cs?searchtype=author&query=Leonhardt%2C+J">Johannes Leonhardt</a>, 
<a href="/search/cs?searchtype=author&query=Seidel%2C+S+J">Sabine J. Seidel</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%B6ring%2C+T+F">Thomas F. D&#xf6;ring</a>, 
<a href="/search/cs?searchtype=author&query=Roscher%2C+R">Ribana Roscher</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 16 figures, code available at <a href="https://github.com/luked12/crop-growth-cgan">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Image-based crop growth modeling can substantially contribute to precision
agriculture by revealing spatial crop development over time, which allows an
early and location-specific estimation of relevant future plant traits, such as
leaf area or biomass. A prerequisite for realistic and sharp crop image
generation is the integration of multiple growth-influencing conditions in a
model, such as an image of an initial growth stage, the associated growth time,
and further information about the field treatment. We present a two-stage
framework consisting first of an image prediction model and second of a growth
estimation model, which both are independently trained. The image prediction
model is a conditional Wasserstein generative adversarial network (CWGAN). In
the generator of this model, conditional batch normalization (CBN) is used to
integrate different conditions along with the input image. This allows the
model to generate time-varying artificial images dependent on multiple
influencing factors of different kinds. These images are used by the second
part of the framework for plant phenotyping by deriving plant-specific traits
and comparing them with those of non-artificial (real) reference images. For
various crop datasets, the framework allows realistic, sharp image predictions
with a slight loss of quality from short-term to long-term predictions.
Simulations of varying growth-influencing conditions performed with the trained
framework provide valuable insights into how such factors relate to crop
appearances, which is particularly useful in complex, less explored crop
mixture systems. Further results show that adding process-based simulated
biomass as a condition increases the accuracy of the derived phenotypic traits
from the predicted images. This demonstrates the potential of our framework to
serve as an interface between an image- and process-based crop growth model.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03446" title="Abstract">arXiv:2312.03446</a> [<a href="/pdf/2312.03446" title="Download PDF">pdf</a>, <a href="/format/2312.03446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Hindsight Self-Imitation Learning for Interactive Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kibeom Kim</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+K">Kisung Shin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M+W">Min Whoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Moonhoen Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Minsu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Byoung-Tak Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures and under-review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Interactive visual navigation tasks, which involve following instructions to
reach and interact with specific targets, are challenging not only because
successful experiences are very rare but also because the complex visual inputs
require a substantial number of samples. Previous methods for these tasks often
rely on intricately designed dense rewards or the use of expensive expert data
for imitation learning. To tackle these challenges, we propose a novel
approach, Visual Hindsight Self-Imitation Learning (VHS) for enhancing sample
efficiency through hindsight goal re-labeling and self-imitation. We also
introduce a prototypical goal embedding method derived from experienced goal
observations, that is particularly effective in vision-based and partially
observable environments. This embedding technique allows the agent to visually
reinterpret its unsuccessful attempts, enabling vision-based goal re-labeling
and self-imitation from enhanced successful experiences. Experimental results
show that VHS outperforms existing techniques in interactive visual navigation
tasks, confirming its superior performance and sample efficiency.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03451" title="Abstract">arXiv:2312.03451</a> [<a href="/pdf/2312.03451" title="Download PDF">pdf</a>, <a href="/ps/2312.03451" title="Download PostScript">ps</a>, <a href="/format/2312.03451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An efficient data-based off-policy Q-learning algorithm for optimal  output feedback control of linear systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Alsalti%2C+M">Mohammad Alsalti</a>, 
<a href="/search/eess?searchtype=author&query=Lopez%2C+V+G">Victor G. Lopez</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%BCller%2C+M+A">Matthias A. M&#xfc;ller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, we present a Q-learning algorithm to solve the optimal output
regulation problem for discrete-time LTI systems. This off-policy algorithm
only relies on using persistently exciting input-output data, measured offline.
No model knowledge or state measurements are needed and the obtained optimal
policy only uses past input-output information. Moreover, our formulation of
the proposed algorithm renders it computationally efficient. We provide
conditions that guarantee the convergence of the algorithm to the optimal
solution. Finally, the performance of our method is compared to existing
algorithms in the literature.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03455" title="Abstract">arXiv:2312.03455</a> [<a href="/pdf/2312.03455" title="Download PDF">pdf</a>, <a href="/format/2312.03455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data is Overrated: Perceptual Metrics Can Lead Learning in the Absence  of Training Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Namgyal%2C+T">Tashi Namgyal</a>, 
<a href="/search/cs?searchtype=author&query=Hepburn%2C+A">Alexander Hepburn</a>, 
<a href="/search/cs?searchtype=author&query=Santos-Rodriguez%2C+R">Raul Santos-Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Laparra%2C+V">Valero Laparra</a>, 
<a href="/search/cs?searchtype=author&query=Malo%2C+J">Jesus Malo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Machine Learning for Audio Workshop, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Perceptual metrics are traditionally used to evaluate the quality of natural
signals, such as images and audio. They are designed to mimic the perceptual
behaviour of human observers and usually reflect structures found in natural
signals. This motivates their use as loss functions for training generative
models such that models will learn to capture the structure held in the metric.
We take this idea to the extreme in the audio domain by training a compressive
autoencoder to reconstruct uniform noise, in lieu of natural data. We show that
training with perceptual losses improves the reconstruction of spectrograms and
re-synthesized audio at test time over models trained with a standard Euclidean
loss. This demonstrates better generalisation to unseen natural signals when
using perceptual metrics.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03458" title="Abstract">arXiv:2312.03458</a> [<a href="/pdf/2312.03458" title="Download PDF">pdf</a>, <a href="/format/2312.03458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Think from Words(TFW): Initiating Human-Like Cognition in Large Language  Models Through Think from Words for Japanese Text-level Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chengguang Gan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qinghao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mori%2C+T">Tatsunori Mori</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The proliferation of Large Language Models (LLMs) has spurred extensive
research into LLM-related Prompt investigations, such as Instruction Learning
(IL), In-context Learning (ICL), and Chain-of-Thought (CoT). These approaches
aim to improve LLMs' responses by enabling them to provide concise statements
or examples for deeper contemplation when addressing questions. However,
independent thinking by LLMs can introduce variability in their thought
processes, leading to potential inaccuracies. In response, our study seeks to
bridge the gap between LLM and human-like thinking processes, recognizing that
text comprehension begins with understanding individual words. To tackle this
challenge, we have expanded the CoT method to cater to a specific domain. Our
approach, known as "Think from Words" (TFW), initiates the comprehension
process at the word level and then extends it to encompass the entire text. We
also propose "TFW with Extra word-level information" (TFW Extra), augmenting
comprehension with additional word-level data. To assess our methods, we employ
text classification on six Japanese datasets comprising text-level and
word-level elements. Our findings not only validate the effectiveness of TFW
but also shed light on the impact of various word-level information types on
LLMs' text comprehension, offering insights into their potential to cause
misinterpretations and errors in the overall comprehension of the final text.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03459" title="Abstract">arXiv:2312.03459</a> [<a href="/pdf/2312.03459" title="Download PDF">pdf</a>, <a href="/format/2312.03459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> F3-Pruning: A Training-Free and Generalized Pruning Strategy towards  Faster and Finer Text-to-Video Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+S">Sitong Su</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianzhi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Lianli Gao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jingkuan Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently Text-to-Video (T2V) synthesis has undergone a breakthrough by
training transformers or diffusion models on large-scale datasets.
Nevertheless, inferring such large models incurs huge costs.Previous inference
acceleration works either require costly retraining or are model-specific.To
address this issue, instead of retraining we explore the inference process of
two mainstream T2V models using transformers and diffusion models.The
exploration reveals the redundancy in temporal attention modules of both
models, which are commonly utilized to establish temporal relations among
frames.Consequently, we propose a training-free and generalized pruning
strategy called F3-Pruning to prune redundant temporal attention
weights.Specifically, when aggregate temporal attention values are ranked below
a certain ratio, corresponding weights will be pruned.Extensive experiments on
three datasets using a classic transformer-based model CogVideo and a typical
diffusion-based model Tune-A-Video verify the effectiveness of F3-Pruning in
inference acceleration, quality assurance and broad applicability.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03461" title="Abstract">arXiv:2312.03461</a> [<a href="/pdf/2312.03461" title="Download PDF">pdf</a>, <a href="/format/2312.03461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HiFi4G: High-Fidelity Human Performance Rendering via Compact Gaussian  Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuheng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhehao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Penghao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Z">Zhuo Su</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yu Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jingyi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We have recently seen tremendous progress in photo-real human modeling and
rendering. Yet, efficiently rendering realistic human performance and
integrating it into the rasterization pipeline remains challenging. In this
paper, we present HiFi4G, an explicit and compact Gaussian-based approach for
high-fidelity human performance rendering from dense footage. Our core
intuition is to marry the 3D Gaussian representation with non-rigid tracking,
achieving a compact and compression-friendly representation. We first propose a
dual-graph mechanism to obtain motion priors, with a coarse deformation graph
for effective initialization and a fine-grained Gaussian graph to enforce
subsequent constraints. Then, we utilize a 4D Gaussian optimization scheme with
adaptive spatial-temporal regularizers to effectively balance the non-rigid
prior and Gaussian updating. We also present a companion compression scheme
with residual compensation for immersive experiences on various platforms. It
achieves a substantial compression rate of approximately 25 times, with less
than 2MB of storage per frame. Extensive experiments demonstrate the
effectiveness of our approach, which significantly outperforms existing
approaches in terms of optimization speed, rendering quality, and storage
overhead.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03463" title="Abstract">arXiv:2312.03463</a> [<a href="/pdf/2312.03463" title="Download PDF">pdf</a>, <a href="/format/2312.03463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DBCopilot: Scaling Natural Language Querying to Massive Databases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianshu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hongyu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xianpei Han</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Le Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhenyu Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and data are available at <a href="https://github.com/tshu-w/DBCopilot">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Databases (cs.DB); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Text-to-SQL simplifies database interactions by enabling non-experts to
convert their natural language (NL) questions into Structured Query Language
(SQL) queries. While recent advances in large language models (LLMs) have
improved the zero-shot text-to-SQL paradigm, existing methods face scalability
challenges when dealing with massive, dynamically changing databases. This
paper introduces DBCopilot, a framework that addresses these challenges by
employing a compact and flexible copilot model for routing across massive
databases. Specifically, DBCopilot decouples the text-to-SQL process into
schema routing and SQL generation, leveraging a lightweight
sequence-to-sequence neural network-based router to formulate database
connections and navigate natural language questions through databases and
tables. The routed schemas and questions are then fed into LLMs for efficient
SQL generation. Furthermore, DBCopilot also introduced a reverse
schema-to-question generation paradigm, which can learn and adapt the router
over massive databases automatically without requiring manual intervention.
Experimental results demonstrate that DBCopilot is a scalable and effective
solution for real-world text-to-SQL tasks, providing a significant advancement
in handling large-scale schemas.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03464" title="Abstract">arXiv:2312.03464</a> [<a href="/pdf/2312.03464" title="Download PDF">pdf</a>, <a href="/format/2312.03464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subnetwork-to-go: Elastic Neural Network with Dynamic Training and  Customizable Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kai Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yi Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Deploying neural networks to different devices or platforms is in general
challenging, especially when the model size is large or model complexity is
high. Although there exist ways for model pruning or distillation, it is
typically required to perform a full round of model training or finetuning
procedure in order to obtain a smaller model that satisfies the model size or
complexity constraints. Motivated by recent works on dynamic neural networks,
we propose a simple way to train a large network and flexibly extract a
subnetwork from it given a model size or complexity constraint during
inference. We introduce a new way to allow a large model to be trained with
dynamic depth and width during the training phase, and after the large model is
trained we can select a subnetwork from it with arbitrary depth and width
during the inference phase with a relatively better performance compared to
training the subnetwork independently from scratch. Experiment results on a
music source separation model show that our proposed method can effectively
improve the separation performance across different subnetwork sizes and
complexities with a single large model, and training the large model takes
significantly shorter time than training all the different subnetworks.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03466" title="Abstract">arXiv:2312.03466</a> [<a href="/pdf/2312.03466" title="Download PDF">pdf</a>, <a href="/format/2312.03466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Search Strategies for Self-driving Laboratories with Pending Experiments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Hao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zeitler%2C+J">Jakob Zeitler</a>, 
<a href="/search/cs?searchtype=author&query=Rupnow%2C+C">Connor Rupnow</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023, AI4Mat
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Self-driving laboratories (SDLs) consist of multiple stations that perform
material synthesis and characterisation tasks. To minimize station downtime and
maximize experimental throughput, it is practical to run experiments in
asynchronous parallel, in which multiple experiments are being performed at
once in different stages. Asynchronous parallelization of experiments, however,
introduces delayed feedback (i.e. "pending experiments"), which is known to
reduce Bayesian optimiser performance. Here, we build a simulator for a
multi-stage SDL and compare optimisation strategies for dealing with delayed
feedback and asynchronous parallelized operation. Using data from a real SDL,
we build a ground truth Bayesian optimisation simulator from 177 previously run
experiments for maximizing the conductivity of functional coatings. We then
compare search strategies such as expected improvement, noisy expected
improvement, 4-mode exploration and random sampling. We evaluate their
performance in terms of amount of delay and problem dimensionality. Our
simulation results showcase the trade-off between the asynchronous parallel
operation and delayed feedback.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03474" title="Abstract">arXiv:2312.03474</a> [<a href="/pdf/2312.03474" title="Download PDF">pdf</a>, <a href="/ps/2312.03474" title="Download PostScript">ps</a>, <a href="/format/2312.03474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The randomized Milstein scheme for stochastic Volterra integral  equations with weakly singular kernels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+Z">Zhaohang Wang</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+Z">Zhuoqi Liu</a>, 
<a href="/search/math?searchtype=author&query=Gao%2C+S">Shuaibin Gao</a>, 
<a href="/search/math?searchtype=author&query=Hu%2C+J">Junhao Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper focuses on the randomized Milstein scheme for approximating
solutions to stochastic Volterra integral equations with weakly singular
kernels, where the drift coefficients are non-differentiable. An essential
component of the error analysis involves the utilization of randomized
quadrature rules for stochastic integrals to avoid the Taylor expansion in
drift coefficient functions. Finally, we implement the simulation of multiple
singular stochastic integral in the numerical experiment by applying the
Riemann-Stieltjes integral.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03475" title="Abstract">arXiv:2312.03475</a> [<a href="/pdf/2312.03475" title="Download PDF">pdf</a>, <a href="/format/2312.03475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Molecule Joint Auto-Encoding: Trajectory Pretraining with 2D and 3D  Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Weitao Du</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiujiu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuecang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhiming Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shengchao Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Biomolecules (q-bio.BM)

</div>
<p class="mathjax">Recently, artificial intelligence for drug discovery has raised increasing
interest in both machine learning and chemistry domains. The fundamental
building block for drug discovery is molecule geometry and thus, the molecule's
geometrical representation is the main bottleneck to better utilize machine
learning techniques for drug discovery. In this work, we propose a pretraining
method for molecule joint auto-encoding (MoleculeJAE). MoleculeJAE can learn
both the 2D bond (topology) and 3D conformation (geometry) information, and a
diffusion process model is applied to mimic the augmented trajectories of such
two modalities, based on which, MoleculeJAE will learn the inherent chemical
structure in a self-supervised manner. Thus, the pretrained geometrical
representation in MoleculeJAE is expected to benefit downstream
geometry-related tasks. Empirically, MoleculeJAE proves its effectiveness by
reaching state-of-the-art performance on 15 out of 20 tasks by comparing it
with 12 competitive baselines.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03477" title="Abstract">arXiv:2312.03477</a> [<a href="/pdf/2312.03477" title="Download PDF">pdf</a>, <a href="/format/2312.03477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Detection to Action Recognition: An Edge-Based Pipeline for Robot  Human Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Toupas%2C+P">Petros Toupas</a>, 
<a href="/search/cs?searchtype=author&query=Tsamis%2C+G">Georgios Tsamis</a>, 
<a href="/search/cs?searchtype=author&query=Giakoumis%2C+D">Dimitrios Giakoumis</a>, 
<a href="/search/cs?searchtype=author&query=Votis%2C+K">Konstantinos Votis</a>, 
<a href="/search/cs?searchtype=author&query=Tzovaras%2C+D">Dimitrios Tzovaras</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 10 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Mobile service robots are proving to be increasingly effective in a range of
applications, such as healthcare, monitoring Activities of Daily Living (ADL),
and facilitating Ambient Assisted Living (AAL). These robots heavily rely on
Human Action Recognition (HAR) to interpret human actions and intentions.
However, for HAR to function effectively on service robots, it requires prior
knowledge of human presence (human detection) and identification of individuals
to monitor (human tracking). In this work, we propose an end-to-end pipeline
that encompasses the entire process, starting from human detection and
tracking, leading to action recognition. The pipeline is designed to operate in
near real-time while ensuring all stages of processing are performed on the
edge, reducing the need for centralised computation. To identify the most
suitable models for our mobile robot, we conducted a series of experiments
comparing state-of-the-art solutions based on both their detection performance
and efficiency. To evaluate the effectiveness of our proposed pipeline, we
proposed a dataset comprising daily household activities. By presenting our
findings and analysing the results, we demonstrate the efficacy of our approach
in enabling mobile robots to understand and respond to human behaviour in
real-world scenarios relying mainly on the data from their RGB cameras.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03479" title="Abstract">arXiv:2312.03479</a> [<a href="/pdf/2312.03479" title="Download PDF">pdf</a>, <a href="/format/2312.03479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JAMMIN-GPT: Text-based Improvisation using LLMs in Ableton Live
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hollowell%2C+S">Sven Hollowell</a>, 
<a href="/search/cs?searchtype=author&query=Namgyal%2C+T">Tashi Namgyal</a>, 
<a href="/search/cs?searchtype=author&query=Marshall%2C+P">Paul Marshall</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference: 24th International Society for Music Information Retrieval. Late Breaking Demo. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We introduce a system that allows users of Ableton Live to create MIDI-clips
by naming them with musical descriptions. Users can compose by typing the
desired musical content directly in Ableton's clip view, which is then inserted
by our integrated system. This allows users to stay in the flow of their
creative process while quickly generating musical ideas. The system works by
prompting ChatGPT to reply using one of several text-based musical formats,
such as ABC notation, chord symbols, or drum tablature. This is an important
step in integrating generative AI tools into pre-existing musical workflows,
and could be valuable for content makers who prefer to express their creative
vision through descriptive language. Code is available at
https://github.com/supersational/JAMMIN-GPT.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03480" title="Abstract">arXiv:2312.03480</a> [<a href="/pdf/2312.03480" title="Download PDF">pdf</a>, <a href="/format/2312.03480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AMR Parsing is Far from Solved: GrAPES, the Granular AMR Parsing  Evaluation Suite
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Groschwitz%2C+J">Jonas Groschwitz</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+S+B">Shay B. Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Donatelli%2C+L">Lucia Donatelli</a>, 
<a href="/search/cs?searchtype=author&query=Fowlie%2C+M">Meaghan Fowlie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023. For the associated GitHub repository, see <a href="https://github.com/jgroschwitz/GrAPES">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present the Granular AMR Parsing Evaluation Suite (GrAPES), a challenge
set for Abstract Meaning Representation (AMR) parsing with accompanying
evaluation metrics. AMR parsers now obtain high scores on the standard AMR
evaluation metric Smatch, close to or even above reported inter-annotator
agreement. But that does not mean that AMR parsing is solved; in fact, human
evaluation in previous work indicates that current parsers still quite
frequently make errors on node labels or graph structure that substantially
distort sentence meaning. Here, we provide an evaluation suite that tests AMR
parsers on a range of phenomena of practical, technical, and linguistic
interest. Our 36 categories range from seen and unseen labels, to structural
generalization, to coreference. GrAPES reveals in depth the abilities and
shortcomings of current AMR parsers.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03483" title="Abstract">arXiv:2312.03483</a> [<a href="/pdf/2312.03483" title="Download PDF">pdf</a>, <a href="/format/2312.03483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Answer Information Methods for Question Generation with  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chafekar%2C+T">Talha Chafekar</a>, 
<a href="/search/cs?searchtype=author&query=Hussain%2C+A">Aafiya Hussain</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+G">Grishma Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+D">Deepak Sharma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">There has been a lot of work in question generation where different methods
to provide target answers as input, have been employed. This experimentation
has been mostly carried out for RNN based models. We use three different
methods and their combinations for incorporating answer information and explore
their effect on several automatic evaluation metrics. The methods that are used
are answer prompting, using a custom product method using answer embeddings and
encoder outputs, choosing sentences from the input paragraph that have answer
related information, and using a separate cross-attention attention block in
the decoder which attends to the answer. We observe that answer prompting
without any additional modes obtains the best scores across rouge, meteor
scores. Additionally, we use a custom metric to calculate how many of the
generated questions have the same answer, as the answer which is used to
generate them.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03488" title="Abstract">arXiv:2312.03488</a> [<a href="/pdf/2312.03488" title="Download PDF">pdf</a>, <a href="/format/2312.03488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Aggregate Downwash Forces for Dense Multirotor Flight
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gielis%2C+J">Jennifer Gielis</a>, 
<a href="/search/cs?searchtype=author&query=Shankar%2C+A">Ajay Shankar</a>, 
<a href="/search/cs?searchtype=author&query=Kortvelesy%2C+R">Ryan Kortvelesy</a>, 
<a href="/search/cs?searchtype=author&query=Prorok%2C+A">Amanda Prorok</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at International Symposium on Experimental Robotics (ISER) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Dense formation flight with multirotor swarms is a powerful, nature-inspired
flight regime with numerous applications in the realworld. However, when
multirotors fly in close vertical proximity to each other, the propeller
downwash from the vehicles can have a destabilising effect on each other.
Unfortunately, even in a homogeneous team, an accurate model of downwash forces
from one vehicle is unlikely to be sufficient for predicting aggregate forces
from multiple vehicles in formation.
<br />In this work, we model the interaction patterns produced by one or more
vehicles flying in close proximity to an ego-vehicle. We first present an
experimental test rig designed to capture 6-DOF exogenic forces acting on a
multirotor frame. We then study and characterize these measured forces as a
function of the relative states of two multirotors flying various patterns in
its vicinity.
<br />Our analysis captures strong non-linearities present in the aggregation of
these interactions. Then, by modeling the formation as a graph, we present a
novel approach for learning the force aggregation function, and contrast it
against simpler linear models. Finally, we explore how our proposed models
generalize when a fourth vehicle is added to the formation.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03491" title="Abstract">arXiv:2312.03491</a> [<a href="/pdf/2312.03491" title="Download PDF">pdf</a>, <a href="/format/2312.03491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Schrodinger Bridges Beat Diffusion Models on Text-to-Speech Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zehua Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+G">Guande He</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+K">Kaiwen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In text-to-speech (TTS) synthesis, diffusion models have achieved promising
generation quality. However, because of the pre-defined data-to-noise diffusion
process, their prior distribution is restricted to a noisy representation,
which provides little information of the generation target. In this work, we
present a novel TTS system, Bridge-TTS, making the first attempt to substitute
the noisy Gaussian prior in established diffusion-based TTS methods with a
clean and deterministic one, which provides strong structural information of
the target. Specifically, we leverage the latent representation obtained from
text input as our prior, and build a fully tractable Schrodinger bridge between
it and the ground-truth mel-spectrogram, leading to a data-to-data process.
Moreover, the tractability and flexibility of our formulation allow us to
empirically study the design spaces such as noise schedules, as well as to
develop stochastic and deterministic samplers. Experimental results on the
LJ-Speech dataset illustrate the effectiveness of our method in terms of both
synthesis quality and sampling efficiency, significantly outperforming our
diffusion counterpart Grad-TTS in 50-step/1000-step synthesis and strong fast
TTS models in few-step scenarios. Project page: https://bridge-tts.github.io/
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03492" title="Abstract">arXiv:2312.03492</a> [<a href="/pdf/2312.03492" title="Download PDF">pdf</a>, <a href="/format/2312.03492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning From Scenarios for Stochastic Repairable Scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+den+Houten%2C+K">Kim van den Houten</a>, 
<a href="/search/cs?searchtype=author&query=Tax%2C+D+M+J">David M.J. Tax</a>, 
<a href="/search/cs?searchtype=author&query=Freydell%2C+E">Esteban Freydell</a>, 
<a href="/search/cs?searchtype=author&query=de+Weerdt%2C+M">Mathijs de Weerdt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">When optimizing problems with uncertain parameter values in a linear
objective, decision-focused learning enables end-to-end learning of these
values. We are interested in a stochastic scheduling problem, in which
processing times are uncertain, which brings uncertain values in the
constraints, and thus repair of an initial schedule may be needed. Historical
realizations of the stochastic processing times are available. We show how
existing decision-focused learning techniques based on stochastic smoothing can
be adapted to this scheduling problem. We include an extensive experimental
evaluation to investigate in which situations decision-focused learning
outperforms the state of the art for such situations: scenario-based stochastic
optimization.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03493" title="Abstract">arXiv:2312.03493</a> [<a href="/pdf/2312.03493" title="Download PDF">pdf</a>, <a href="/format/2312.03493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Radio Source Localization using Sparse Signal Measurements from Uncrewed  Ground Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perera%2C+A">Asanka Perera</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+V+P">Vu Phi Tran</a>, 
<a href="/search/cs?searchtype=author&query=Anavatti%2C+S">Sreenatha Anavatti</a>, 
<a href="/search/cs?searchtype=author&query=Kasmarik%2C+K">Kathryn Kasmarik</a>, 
<a href="/search/cs?searchtype=author&query=Garratt%2C+M">Matthew Garratt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Radio source localization can benefit many fields, including wireless
communications, radar, radio astronomy, wireless sensor networks, positioning
systems, and surveillance systems. However, accurately estimating the position
of a radio transmitter using a remote sensor is not an easy task, as many
factors contribute to the highly dynamic behavior of radio signals. In this
study, we investigate techniques to use a mobile robot to explore an outdoor
area and localize the radio source using sparse Received Signal Strength
Indicator (RSSI) measurements. We propose a novel radio source localization
method with fast turnaround times and reduced complexity compared to the
state-of-the-art. Our technique uses RSSI measurements collected while the
robot completed a sparse trajectory using a coverage path planning map. The
mean RSSI within each grid cell was used to find the most likely cell
containing the source. Three techniques were analyzed with the data from eight
field tests using a mobile robot. The proposed method can localize a gas source
in a basketball field with a 1.2 m accuracy and within three minutes of
convergence time, whereas the state-of-the-art active sensing technique took
more than 30 minutes to reach a source estimation accuracy below 1 m.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03494" title="Abstract">arXiv:2312.03494</a> [<a href="/pdf/2312.03494" title="Download PDF">pdf</a>, <a href="/format/2312.03494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting legal case retrieval by query content selection with large  language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Youchao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Heyan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhijing Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work was accepted as 23-SIGIR-AP main conference paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Legal case retrieval, which aims to retrieve relevant cases to a given query
case, benefits judgment justice and attracts increasing attention. Unlike
generic retrieval queries, legal case queries are typically long and the
definition of relevance is closely related to legal-specific elements.
Therefore, legal case queries may suffer from noise and sparsity of salient
content, which hinders retrieval models from perceiving correct information in
a query. While previous studies have paid attention to improving retrieval
models and understanding relevance judgments, we focus on enhancing legal case
retrieval by utilizing the salient content in legal case queries. We first
annotate the salient content in queries manually and investigate how sparse and
dense retrieval models attend to those content. Then we experiment with various
query content selection methods utilizing large language models (LLMs) to
extract or summarize salient content and incorporate it into the retrieval
models. Experimental results show that reformulating long queries using LLMs
improves the performance of both sparse and dense models in legal case
retrieval.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03495" title="Abstract">arXiv:2312.03495</a> [<a href="/pdf/2312.03495" title="Download PDF">pdf</a>, <a href="/format/2312.03495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Subexponential Time Algorithm for Makespan Scheduling of Unit Jobs  with Precedence Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nederlof%2C+J">Jesper Nederlof</a>, 
<a href="/search/cs?searchtype=author&query=Swennenhuis%2C+C+M+F">C&#xe9;line M. F. Swennenhuis</a>, 
<a href="/search/cs?searchtype=author&query=W%C4%99grzycki%2C+K">Karol W&#x119;grzycki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">In a classical scheduling problem, we are given a set of $n$ jobs of unit
length along with precedence constraints, and the goal is to find a schedule of
these jobs on $m$ identical machines that minimizes the makespan. Using the
standard 3-field notation, it is known as $Pm|\text{prec}, p_j=1|C_{\max}$.
Settling the complexity of $Pm|\text{prec}, p_j=1|C_{\max}$ even for $m=3$
machines is the last open problem from the book of Garey and Johnson [GJ79] for
which both upper and lower bounds on the worst-case running times of exact
algorithms solving them remain essentially unchanged since the publication of
[GJ79]. We present an algorithm for this problem that runs in
$(1+\frac{n}{m})^{\mathcal{O}(\sqrt{nm})}$ time. This algorithm is
subexponential when $m = o(n)$. In the regime of $m=\Theta(n)$ we show an
algorithm that runs in$\mathcal{O}(1.997^n)$ time. Before our work, even for
$m=3$ machines there were no algorithms known that run in
$\mathcal{O}((2-\varepsilon)^n)$ time for some $\varepsilon &gt; 0$.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03496" title="Abstract">arXiv:2312.03496</a> [<a href="/pdf/2312.03496" title="Download PDF">pdf</a>, <a href="/ps/2312.03496" title="Download PostScript">ps</a>, <a href="/format/2312.03496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Formulations of the Strong Formulation -- Forward and  Inverse Modeling using Isogeometric Analysis and Physics-Informed Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mardal%2C+K">Kent-Andre Mardal</a>, 
<a href="/search/math?searchtype=author&query=Sogn%2C+J">Jarle Sogn</a>, 
<a href="/search/math?searchtype=author&query=Zeinhofer%2C+M">Marius Zeinhofer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The recently introduced Physics-Informed Neural Networks (PINNs) have
popularized least squares formulations of both forward and inverse problems
involving partial differential equations (PDEs) in strong form. We employ both
Isogeometric Analysis and Physics-Informed Networks.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03497" title="Abstract">arXiv:2312.03497</a> [<a href="/pdf/2312.03497" title="Download PDF">pdf</a>, <a href="/ps/2312.03497" title="Download PostScript">ps</a>, <a href="/format/2312.03497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speculative Exploration on the Concept of Artificial Agents Conducting  Autonomous Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Takagi%2C+S">Shiro Takagi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper engages in a speculative exploration of the concept of an
artificial agent capable of conducting research. Initially, it examines how the
act of research can be conceptually characterized, aiming to provide a starting
point for discussions about what it means to create such agents. The focus then
shifts to the core components of research: question formulation, hypothesis
generation, and hypothesis verification. This discussion includes a
consideration of the potential and challenges associated with enabling machines
to autonomously perform these tasks. Subsequently, this paper briefly considers
the overlapping themes and interconnections that underlie them. Finally, the
paper presents preliminary thoughts on prototyping as an initial step towards
uncovering the challenges involved in developing these research-capable agents.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03502" title="Abstract">arXiv:2312.03502</a> [<a href="/pdf/2312.03502" title="Download PDF">pdf</a>, <a href="/format/2312.03502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the Generalization of Segmentation Foundation Model under  Distribution Shift via Weakly Supervised Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haojie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yongyi Su</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+K">Kui Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The success of large language models has inspired the computer vision
community to explore image segmentation foundation model that is able to
zero/few-shot generalize through prompt engineering. Segment-Anything(SAM),
among others, is the state-of-the-art image segmentation foundation model
demonstrating strong zero/few-shot generalization. Despite the success, recent
studies reveal the weakness of SAM under strong distribution shift. In
particular, SAM performs awkwardly on corrupted natural images, camouflaged
images, medical images, etc. Motivated by the observations, we aim to develop a
self-training based strategy to adapt SAM to target distribution. Given the
unique challenges of large source dataset, high computation cost and incorrect
pseudo label, we propose a weakly supervised self-training architecture with
anchor regularization and low-rank finetuning to improve the robustness and
computation efficiency of adaptation. We validate the effectiveness on 5 types
of downstream segmentation tasks including natural clean/corrupted images,
medical images, camouflaged images and robotic images. Our proposed method is
task-agnostic in nature and outperforms pre-trained SAM and state-of-the-art
domain adaptation methods on almost all downstream tasks with the same testing
prompt inputs.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03506" title="Abstract">arXiv:2312.03506</a> [<a href="/pdf/2312.03506" title="Download PDF">pdf</a>, <a href="/format/2312.03506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task-Parameterized Imitation Learning with Time-Sensitive Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Richter%2C+J">Julian Richter</a>, 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+J">Jo&#xe3;o Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Scheurer%2C+C">Christian Scheurer</a>, 
<a href="/search/cs?searchtype=author&query=Steil%2C+J">Jochen Steil</a>, 
<a href="/search/cs?searchtype=author&query=Dehio%2C+N">Niels Dehio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Programming a robot manipulator should be as intuitive as possible. To
achieve that, the paradigm of teaching motion skills by providing few
demonstrations has become widely popular in recent years. Probabilistic
versions thereof take into account the uncertainty given by the distribution of
the training data. However, precise execution of start-, via-, and end-poses at
given times can not always be guaranteed. This limits the technology transfer
to industrial application. To address this problem, we propose a novel
constrained formulation of the Expectation Maximization algorithm for learning
Gaussian Mixture Models (GMM) on Riemannian Manifolds. Our approach applies to
probabilistic imitation learning and extends also to the well-established
TP-GMM framework with Task-Parameterization. It allows to prescribe
end-effector poses at defined execution times, for instance for precise pick &amp;
place scenarios. The probabilistic approach is compared with state-of-the-art
learning-from-demonstration methods using the KUKA LBR iiwa robot. The reader
is encouraged to watch the accompanying video available at
https://youtu.be/JMI1YxtN9C0
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03509" title="Abstract">arXiv:2312.03509</a> [<a href="/pdf/2312.03509" title="Download PDF">pdf</a>, <a href="/ps/2312.03509" title="Download PostScript">ps</a>, <a href="/format/2312.03509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gravitational cell detection and tracking in fluorescence microscopy  data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eftimiu%2C+N">Nikomidisz Eftimiu</a>, 
<a href="/search/cs?searchtype=author&query=Kozubek%2C+M">Michal Kozubek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, 1 formula, 1 table, submitted to the 21st International Symposium on Biomedical Imaging (ISBI 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cell Behavior (q-bio.CB)

</div>
<p class="mathjax">Automatic detection and tracking of cells in microscopy images are major
applications of computer vision technologies in both biomedical research and
clinical practice. Though machine learning methods are increasingly common in
these fields, classical algorithms still offer significant advantages for both
tasks, including better explainability, faster computation, lower hardware
requirements and more consistent performance. In this paper, we present a novel
approach based on gravitational force fields that can compete with, and
potentially outperform modern machine learning models when applied to
fluorescence microscopy images. This method includes detection, segmentation,
and tracking elements, with the results demonstrated on a Cell Tracking
Challenge dataset.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03510" title="Abstract">arXiv:2312.03510</a> [<a href="/pdf/2312.03510" title="Download PDF">pdf</a>, <a href="/format/2312.03510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Sobolev Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kichler%2C+N">Neil Kichler</a>, 
<a href="/search/cs?searchtype=author&query=Afghan%2C+S">Sher Afghan</a>, 
<a href="/search/cs?searchtype=author&query=Naumann%2C+U">Uwe Naumann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Finance (q-fin.CP)

</div>
<p class="mathjax">The increasing use of stochastic models for describing complex phenomena
warrants surrogate models that capture the reference model characteristics at a
fraction of the computational cost, foregoing potentially expensive Monte Carlo
simulation. The predominant approach of fitting a large neural network and then
pruning it to a reduced size has commonly neglected shortcomings. The produced
surrogate models often will not capture the sensitivities and uncertainties
inherent in the original model. In particular, (higher-order) derivative
information of such surrogates could differ drastically. Given a large enough
network, we expect this derivative information to match. However, the pruned
model will almost certainly not share this behavior.
<br />In this paper, we propose to find surrogate models by using sensitivity
information throughout the learning and pruning process. We build on work using
Interval Adjoint Significance Analysis for pruning and combine it with the
recent advancements in Sobolev Training to accurately model the original
sensitivity information in the pruned neural network based surrogate model. We
experimentally underpin the method on an example of pricing a multidimensional
Basket option modelled through a stochastic differential equation with Brownian
motion. The proposed method is, however, not limited to the domain of
quantitative finance, which was chosen as a case study for intuitive
interpretations of the sensitivities. It serves as a foundation for building
further surrogate modelling techniques considering sensitivity information.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03511" title="Abstract">arXiv:2312.03511</a> [<a href="/pdf/2312.03511" title="Download PDF">pdf</a>, <a href="/format/2312.03511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kandinsky 3.0 Technical Report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arkhipkin%2C+V">Vladimir Arkhipkin</a>, 
<a href="/search/cs?searchtype=author&query=Filatov%2C+A">Andrei Filatov</a>, 
<a href="/search/cs?searchtype=author&query=Vasilev%2C+V">Viacheslav Vasilev</a>, 
<a href="/search/cs?searchtype=author&query=Maltseva%2C+A">Anastasia Maltseva</a>, 
<a href="/search/cs?searchtype=author&query=Azizov%2C+S">Said Azizov</a>, 
<a href="/search/cs?searchtype=author&query=Pavlov%2C+I">Igor Pavlov</a>, 
<a href="/search/cs?searchtype=author&query=Agafonova%2C+J">Julia Agafonova</a>, 
<a href="/search/cs?searchtype=author&query=Kuznetsov%2C+A">Andrey Kuznetsov</a>, 
<a href="/search/cs?searchtype=author&query=Dimitrov%2C+D">Denis Dimitrov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://ai-forever.github.io/Kandinsky-3">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">We present Kandinsky 3.0, a large-scale text-to-image generation model based
on latent diffusion, continuing the series of text-to-image Kandinsky models
and reflecting our progress to achieve higher quality and realism of image
generation. Compared to previous versions of Kandinsky 2.x, Kandinsky 3.0
leverages a two times larger U-Net backbone, a ten times larger text encoder
and removes diffusion mapping. We describe the architecture of the model, the
data collection procedure, the training technique, and the production system of
user interaction. We focus on the key components that, as we have identified as
a result of a large number of experiments, had the most significant impact on
improving the quality of our model compared to the others. By our side-by-side
comparisons, Kandinsky becomes better in text understanding and works better on
specific domains. Project page: https://ai-forever.github.io/Kandinsky-3
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03517" title="Abstract">arXiv:2312.03517</a> [<a href="/pdf/2312.03517" title="Download PDF">pdf</a>, <a href="/format/2312.03517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FRDiff: Feature Reuse for Exquisite Zero-shot Acceleration of Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=So%2C+J">Junhyuk So</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jungwon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+E">Eunhyeok Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The substantial computational costs of diffusion models, particularly due to
the repeated denoising steps crucial for high-quality image generation, present
a major obstacle to their widespread adoption. While several studies have
attempted to address this issue by reducing the number of score function
evaluations using advanced ODE solvers without fine-tuning, the decreased
number of denoising iterations misses the opportunity to update fine details,
resulting in noticeable quality degradation. In our work, we introduce an
advanced acceleration technique that leverages the temporal redundancy inherent
in diffusion models. Reusing feature maps with high temporal similarity opens
up a new opportunity to save computation without sacrificing output quality. To
realize the practical benefits of this intuition, we conduct an extensive
analysis and propose a novel method, FRDiff. FRDiff is designed to harness the
advantages of both reduced NFE and feature reuse, achieving a Pareto frontier
that balances fidelity and latency trade-offs in various generative tasks.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03519" title="Abstract">arXiv:2312.03519</a> [<a href="/pdf/2312.03519" title="Download PDF">pdf</a>, <a href="/ps/2312.03519" title="Download PostScript">ps</a>, <a href="/format/2312.03519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Wildfires Detection and Dynamic Escape Routes Planning for Humans  through Information Fusion between Drones and Satellites
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sziranyi%2C+T">Tamas Sziranyi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 10 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">UAVs are playing an increasingly important role in the field of wilderness
rescue by virtue of their flexibility. This paper proposes a fusion of UAV
vision technology and satellite image analysis technology for active wildfires
detection and road networks extraction of wildfire areas and real-time dynamic
escape route planning for people in distress. Firstly, the fire source location
and the segmentation of smoke and flames are targeted based on Sentinel 2
satellite imagery. Secondly, the road segmentation and the road condition
assessment are performed by D-linkNet and NDVI values in the central area of
the fire source by UAV. Finally, the dynamic optimal route planning for humans
in real time is performed by the weighted A* algorithm in the road network with
the dynamic fire spread model. Taking the Chongqing wildfire on August 24,
2022, as a case study, the results demonstrate that the dynamic escape route
planning algorithm can provide an optimal real-time navigation path for humans
in the presence of fire through the information fusion of UAVs and satellites.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03520" title="Abstract">arXiv:2312.03520</a> [<a href="/pdf/2312.03520" title="Download PDF">pdf</a>, <a href="/format/2312.03520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defense Against Adversarial Attacks using Convolutional Auto-Encoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mandal%2C+S">Shreyasi Mandal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep learning models, while achieving state-of-the-art performance on many
tasks, are susceptible to adversarial attacks that exploit inherent
vulnerabilities in their architectures. Adversarial attacks manipulate the
input data with imperceptible perturbations, causing the model to misclassify
the data or produce erroneous outputs. This work is based on enhancing the
robustness of targeted classifier models against adversarial attacks. To
achieve this, an convolutional autoencoder-based approach is employed that
effectively counters adversarial perturbations introduced to the input images.
By generating images closely resembling the input images, the proposed
methodology aims to restore the model's accuracy.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03521" title="Abstract">arXiv:2312.03521</a> [<a href="/pdf/2312.03521" title="Download PDF">pdf</a>, <a href="/ps/2312.03521" title="Download PostScript">ps</a>, <a href="/format/2312.03521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Wildfire Escape Route Planning for Drones under Dynamic Fire and  Smoke
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sziranyi%2C+T">Tamas Sziranyi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 8 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In recent years, the increasing prevalence and intensity of wildfires have
posed significant challenges to emergency response teams. The utilization of
unmanned aerial vehicles (UAVs), commonly known as drones, has shown promise in
aiding wildfire management efforts. This work focuses on the development of an
optimal wildfire escape route planning system specifically designed for drones,
considering dynamic fire and smoke models. First, the location of the source of
the wildfire can be well located by information fusion between UAV and
satellite, and the road conditions in the vicinity of the fire can be assessed
and analyzed using multi-channel remote sensing data. Second, the road network
can be extracted and segmented in real time using UAV vision technology, and
each road in the road network map can be given priority based on the results of
road condition classification. Third, the spread model of dynamic fires
calculates the new location of the fire source based on the fire intensity,
wind speed and direction, and the radius increases as the wildfire spreads.
Smoke is generated around the fire source to create a visual representation of
a burning fire. Finally, based on the improved A* algorithm, which considers
all the above factors, the UAV can quickly plan an escape route based on the
starting and destination locations that avoid the location of the fire source
and the area where it is spreading. By considering dynamic fire and smoke
models, the proposed system enhances the safety and efficiency of drone
operations in wildfire environments.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03523" title="Abstract">arXiv:2312.03523</a> [<a href="/pdf/2312.03523" title="Download PDF">pdf</a>, <a href="/format/2312.03523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sig-Networks Toolkit: Signature Networks for Longitudinal Language  Modelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tseriotou%2C+T">Talia Tseriotou</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+R+S">Ryan Sze-Yin Chan</a>, 
<a href="/search/cs?searchtype=author&query=Tsakalidis%2C+A">Adam Tsakalidis</a>, 
<a href="/search/cs?searchtype=author&query=Bilal%2C+I+M">Iman Munire Bilal</a>, 
<a href="/search/cs?searchtype=author&query=Kochkina%2C+E">Elena Kochkina</a>, 
<a href="/search/cs?searchtype=author&query=Lyons%2C+T">Terry Lyons</a>, 
<a href="/search/cs?searchtype=author&query=Liakata%2C+M">Maria Liakata</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present an open-source, pip installable toolkit, Sig-Networks, the first
of its kind for longitudinal language modelling. A central focus is the
incorporation of Signature-based Neural Network models, which have recently
shown success in temporal tasks. We apply and extend published research
providing a full suite of signature-based models. Their components can be used
as PyTorch building blocks in future architectures. Sig-Networks enables
task-agnostic dataset plug-in, seamless pre-processing for sequential data,
parameter flexibility, automated tuning across a range of models. We examine
signature networks under three different NLP tasks of varying temporal
granularity: counselling conversations, rumour stance switch and mood changes
in social media threads, showing SOTA performance in all three, and provide
guidance for future tasks. We release the Toolkit as a PyTorch package with an
introductory video, Git repositories for preprocessing and modelling including
sample notebooks on the modeled NLP tasks.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03526" title="Abstract">arXiv:2312.03526</a> [<a href="/pdf/2312.03526" title="Download PDF">pdf</a>, <a href="/format/2312.03526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Diversity and Realism of Distilled Dataset: An Efficient Dataset  Distillation Paradigm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+P">Peng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Bei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Daiwei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+T">Tao Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 20 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Contemporary machine learning requires training large neural networks on
massive datasets and thus faces the challenges of high computational demands.
Dataset distillation, as a recent emerging strategy, aims to compress
real-world datasets for efficient training. However, this line of research
currently struggle with large-scale and high-resolution datasets, hindering its
practicality and feasibility. To this end, we re-examine the existing dataset
distillation methods and identify three properties required for large-scale
real-world applications, namely, realism, diversity, and efficiency. As a
remedy, we propose RDED, a novel computationally-efficient yet effective data
distillation paradigm, to enable both diversity and realism of the distilled
data. Extensive empirical results over various neural architectures and
datasets demonstrate the advancement of RDED: we can distill the full
ImageNet-1K to a small dataset comprising 10 images per class within 7 minutes,
achieving a notable 42% top-1 accuracy with ResNet-18 on a single RTX-4090 GPU
(while the SOTA only achieves 21% but requires 6 hours).
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03528" title="Abstract">arXiv:2312.03528</a> [<a href="/pdf/2312.03528" title="Download PDF">pdf</a>, <a href="/format/2312.03528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalized Pose Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Priisalu%2C+M">Maria Priisalu</a>, 
<a href="/search/cs?searchtype=author&query=Kronvall%2C+T">Ted Kronvall</a>, 
<a href="/search/cs?searchtype=author&query=Sminchisescu%2C+C">Cristian Sminchisescu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human pose forecasting is the task of predicting articulated human motion
given past human motion. There exists a number of popular benchmarks that
evaluate an array of different models performing human pose forecasting. These
benchmarks do not reflect that a human interacting system, such as a delivery
robot, observes and plans for the motion of the same individual over an
extended period of time. Every individual has unique and distinct movement
patterns. This is however not reflected in existing benchmarks that evaluate a
model's ability to predict an average human's motion rather than a particular
individual's. We reformulate the human motion forecasting problem and present a
model-agnostic personalization method. Motion forecasting personalization can
be performed efficiently online by utilizing a low-parametric time-series
analysis model that personalizes neural network pose predictions.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03532" title="Abstract">arXiv:2312.03532</a> [<a href="/pdf/2312.03532" title="Download PDF">pdf</a>, <a href="/ps/2312.03532" title="Download PostScript">ps</a>, <a href="/format/2312.03532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inverse Optimal Control as an Errors-in-Variables Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rickenbach%2C+R">Rahel Rickenbach</a>, 
<a href="/search/eess?searchtype=author&query=Scampicchio%2C+A">Anna Scampicchio</a>, 
<a href="/search/eess?searchtype=author&query=Zeilinger%2C+M+N">Melanie N. Zeilinger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Inverse optimal control (IOC) is about estimating an unknown objective of
interest given its optimal control sequence. However, truly optimal
demonstrations are often difficult to obtain, e.g., due to human errors or
inaccurate measurements. This paper presents an IOC framework for objective
estimation from multiple sub-optimal demonstrations in constrained
environments. It builds upon the Karush-Kuhn-Tucker optimality conditions, and
addresses the Errors-In-Variables problem that emerges from the use of
sub-optimal data. The approach presented is applied to various systems in
simulation, and consistency guarantees are provided for linear systems with
zero mean additive noise, polytopic constraints, and objectives with quadratic
features.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03533" title="Abstract">arXiv:2312.03533</a> [<a href="/pdf/2312.03533" title="Download PDF">pdf</a>, <a href="/format/2312.03533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-shot Object Learning with Mutual Exclusivity Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thai%2C+A">Anh Thai</a>, 
<a href="/search/cs?searchtype=author&query=Humayun%2C+A">Ahmad Humayun</a>, 
<a href="/search/cs?searchtype=author&query=Stojanov%2C+S">Stefan Stojanov</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zixuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Boote%2C+B">Bikram Boote</a>, 
<a href="/search/cs?searchtype=author&query=Rehg%2C+J+M">James M. Rehg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023, Datasets and Benchmarks Track. Project website <a href="https://ngailapdi.github.io/projects/lsme/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper introduces Low-shot Object Learning with Mutual Exclusivity Bias
(LSME), the first computational framing of mutual exclusivity bias, a
phenomenon commonly observed in infants during word learning. We provide a
novel dataset, comprehensive baselines, and a state-of-the-art method to enable
the ML community to tackle this challenging learning task. The goal of LSME is
to analyze an RGB image of a scene containing multiple objects and correctly
associate a previously-unknown object instance with a provided category label.
This association is then used to perform low-shot learning to test category
generalization. We provide a data generation pipeline for the LSME problem and
conduct a thorough analysis of the factors that contribute to its difficulty.
Additionally, we evaluate the performance of multiple baselines, including
state-of-the-art foundation models. Finally, we present a baseline approach
that outperforms state-of-the-art models in terms of low-shot accuracy.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03540" title="Abstract">arXiv:2312.03540</a> [<a href="/pdf/2312.03540" title="Download PDF">pdf</a>, <a href="/format/2312.03540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FoodFusion: A Latent Diffusion Model for Realistic Food Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Markham%2C+O">Olivia Markham</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+C+A">Chi-en Amy Tai</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+A">Alexander Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Current state-of-the-art image generation models such as Latent Diffusion
Models (LDMs) have demonstrated the capacity to produce visually striking
food-related images. However, these generated images often exhibit an artistic
or surreal quality that diverges from the authenticity of real-world food
representations. This inadequacy renders them impractical for applications
requiring realistic food imagery, such as training models for image-based
dietary assessment. To address these limitations, we introduce FoodFusion, a
Latent Diffusion model engineered specifically for the faithful synthesis of
realistic food images from textual descriptions. The development of the
FoodFusion model involves harnessing an extensive array of open-source food
datasets, resulting in over 300,000 curated image-caption pairs. Additionally,
we propose and employ two distinct data cleaning methodologies to ensure that
the resulting image-text pairs maintain both realism and accuracy. The
FoodFusion model, thus trained, demonstrates a remarkable ability to generate
food images that exhibit a significant improvement in terms of both realism and
diversity over the publicly available image generation models. We openly share
the dataset and fine-tuned models to support advancements in this critical
field of food image synthesis at https://bit.ly/genai4good.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03542" title="Abstract">arXiv:2312.03542</a> [<a href="/pdf/2312.03542" title="Download PDF">pdf</a>, <a href="/format/2312.03542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incorporating the algorithm for the boundary condition from FVM into the  framework of Eulerian SPH
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhentong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Haidn%2C+O+J">Oskar J. Haidn</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiangyu Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 12 figures and 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Finite volume method (FVM) is a widely used mesh-based technique, renowned
for its computational efficiency and accuracy but it bears significant
drawbacks, particularly in mesh generation and handling complex boundary
interfaces or conditions. On the other hand, smoothed particle hydrodynamics
(SPH) method, a popular meshless alternative, inherently circumvents the mesh
generation and yields smoother numerical outcomes but at the expense of
computational efficiency. Therefore, numerous researchers have strategically
amalgamated the strengths of both methods to investigate complex flow phenomena
and this synergy has yielded precise and computationally efficient outcomes.
However, algorithms involving the weak coupling of these two methods tend to be
intricate, which has issues pertaining to versatility, implementation, and
mutual adaptation to hardware and coding structures. Thus, achieving a robust
and strong coupling of FVM and SPH in a unified framework is imperative. Due to
differing boundary algorithms between these methods in Wang's work, the crucial
step for establishing a strong coupling of both methods within a unified SPH
framework lies in incorporating the FVM boundary algorithm into the Eulerian
SPH method. In this paper, we propose a straightforward algorithm in the
Eulerian SPH method, algorithmically equivalent to that in FVM, grounded in the
principle of zero-order consistency. Moreover, several numerical examples,
including fully and weakly compressible flows with various boundary conditions
in the Eulerian SPH method, validate the stability and accuracy of the proposed
algorithm.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03543" title="Abstract">arXiv:2312.03543</a> [<a href="/pdf/2312.03543" title="Download PDF">pdf</a>, <a href="/format/2312.03543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT-4 Enhanced Multimodal Grounding for Autonomous Driving: Leveraging  Cross-Modal Attention with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+H">Haicheng Liao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Huanming Shen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenning Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guofa Li</a>, 
<a href="/search/cs?searchtype=author&query=Bie%2C+Y">Yiming Bie</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chengzhong Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the field of autonomous vehicles (AVs), accurately discerning commander
intent and executing linguistic commands within a visual context presents a
significant challenge. This paper introduces a sophisticated encoder-decoder
framework, developed to address visual grounding in AVs.Our Context-Aware
Visual Grounding (CAVG) model is an advanced system that integrates five core
encoders-Text, Image, Context, and Cross-Modal-with a Multimodal decoder. This
integration enables the CAVG model to adeptly capture contextual semantics and
to learn human emotional features, augmented by state-of-the-art Large Language
Models (LLMs) including GPT-4. The architecture of CAVG is reinforced by the
implementation of multi-head cross-modal attention mechanisms and a
Region-Specific Dynamic (RSD) layer for attention modulation. This
architectural design enables the model to efficiently process and interpret a
range of cross-modal inputs, yielding a comprehensive understanding of the
correlation between verbal commands and corresponding visual scenes. Empirical
evaluations on the Talk2Car dataset, a real-world benchmark, demonstrate that
CAVG establishes new standards in prediction accuracy and operational
efficiency. Notably, the model exhibits exceptional performance even with
limited training data, ranging from 50% to 75% of the full dataset. This
feature highlights its effectiveness and potential for deployment in practical
AV applications. Moreover, CAVG has shown remarkable robustness and
adaptability in challenging scenarios, including long-text command
interpretation, low-light conditions, ambiguous command contexts, inclement
weather conditions, and densely populated urban environments. The code for the
proposed model is available at our Github.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03548" title="Abstract">arXiv:2312.03548</a> [<a href="/pdf/2312.03548" title="Download PDF">pdf</a>, <a href="/format/2312.03548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Texture-Semantic Collaboration Network for ORSI Salient Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gongyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Z">Zhen Bai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhi Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, Accepted by IEEE Transactions on Circuits and Systems II: Express Briefs 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Salient object detection (SOD) in optical remote sensing images (ORSIs) has
become increasingly popular recently. Due to the characteristics of ORSIs,
ORSI-SOD is full of challenges, such as multiple objects, small objects, low
illuminations, and irregular shapes. To address these challenges, we propose a
concise yet effective Texture-Semantic Collaboration Network (TSCNet) to
explore the collaboration of texture cues and semantic cues for ORSI-SOD.
Specifically, TSCNet is based on the generic encoder-decoder structure. In
addition to the encoder and decoder, TSCNet includes a vital Texture-Semantic
Collaboration Module (TSCM), which performs valuable feature modulation and
interaction on basic features extracted from the encoder. The main idea of our
TSCM is to make full use of the texture features at the lowest level and the
semantic features at the highest level to achieve the expression enhancement of
salient regions on features. In the TSCM, we first enhance the position of
potential salient regions using semantic features. Then, we render and restore
the object details using the texture features. Meanwhile, we also perceive
regions of various scales, and construct interactions between different
regions. Thanks to the perfect combination of TSCM and generic structure, our
TSCNet can take care of both the position and details of salient objects,
effectively handling various scenes. Extensive experiments on three datasets
demonstrate that our TSCNet achieves competitive performance compared to 14
state-of-the-art methods. The code and results of our method are available at
https://github.com/MathLee/TSCNet.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03549" title="Abstract">arXiv:2312.03549</a> [<a href="/pdf/2312.03549" title="Download PDF">pdf</a>, <a href="/format/2312.03549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Holmes: Towards Distributed Training Across Clusters with Heterogeneous  NIC Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Shuang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+N">Ning Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fangyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+K">Ke Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jiezhong Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+A">Aimin Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Large language models (LLMs) such as GPT-3, OPT, and LLaMA have demonstrated
remarkable accuracy in a wide range of tasks. However, training these models
can incur significant expenses, often requiring tens of thousands of GPUs for
months of continuous operation. Typically, this training is carried out in
specialized GPU clusters equipped with homogeneous high-speed Remote Direct
Memory Access (RDMA) network interface cards (NICs). The acquisition and
maintenance of such dedicated clusters is challenging. Current LLM training
frameworks, like Megatron-LM and Megatron-DeepSpeed, focus primarily on
optimizing training within homogeneous cluster settings. In this paper, we
introduce Holmes, a training framework for LLMs that employs thoughtfully
crafted data and model parallelism strategies over the heterogeneous NIC
environment. Our primary technical contribution lies in a novel scheduling
method that intelligently allocates distinct computational tasklets in LLM
training to specific groups of GPU devices based on the characteristics of
their connected NICs. Furthermore, our proposed framework, utilizing pipeline
parallel techniques, demonstrates scalability to multiple GPU clusters, even in
scenarios without high-speed interconnects between nodes in distinct clusters.
We conducted comprehensive experiments that involved various scenarios in the
heterogeneous NIC environment. In most cases, our framework achieves
performance levels close to those achievable with homogeneous RDMA-capable
networks (InfiniBand or RoCE), significantly exceeding training efficiency
within the pure Ethernet environment. Additionally, we verified that our
framework outperforms other mainstream LLM frameworks under heterogeneous NIC
environment in terms of training efficiency and can be seamlessly integrated
with them.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03556" title="Abstract">arXiv:2312.03556</a> [<a href="/pdf/2312.03556" title="Download PDF">pdf</a>, <a href="/format/2312.03556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalized Face Inpainting with Diffusion Models by Parallel Visual  Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jianjin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Motamed%2C+S">Saman Motamed</a>, 
<a href="/search/cs?searchtype=author&query=Vaddamanu%2C+P">Praneetha Vaddamanu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C+H">Chen Henry Wu</a>, 
<a href="/search/cs?searchtype=author&query=Haene%2C+C">Christian Haene</a>, 
<a href="/search/cs?searchtype=author&query=Bazin%2C+J">Jean-Charles Bazin</a>, 
<a href="/search/cs?searchtype=author&query=de+la+Torre%2C+F">Fernando de la Torre</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Face inpainting is important in various applications, such as photo
restoration, image editing, and virtual reality. Despite the significant
advances in face generative models, ensuring that a person's unique facial
identity is maintained during the inpainting process is still an elusive goal.
Current state-of-the-art techniques, exemplified by MyStyle, necessitate
resource-intensive fine-tuning and a substantial number of images for each new
identity. Furthermore, existing methods often fall short in accommodating
user-specified semantic attributes, such as beard or expression. To improve
inpainting results, and reduce the computational complexity during inference,
this paper proposes the use of Parallel Visual Attention (PVA) in conjunction
with diffusion models. Specifically, we insert parallel attention matrices to
each cross-attention module in the denoising network, which attends to features
extracted from reference images by an identity encoder. We train the added
attention modules and identity encoder on CelebAHQ-IDI, a dataset proposed for
identity-preserving face inpainting. Experiments demonstrate that PVA attains
unparalleled identity resemblance in both face inpainting and face inpainting
with language guidance tasks, in comparison to various benchmarks, including
MyStyle, Paint by Example, and Custom Diffusion. Our findings reveal that PVA
ensures good identity preservation while offering effective
language-controllability. Additionally, in contrast to Custom Diffusion, PVA
requires just 40 fine-tuning steps for each new identity, which translates to a
significant speed increase of over 20 times.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03558" title="Abstract">arXiv:2312.03558</a> [<a href="/pdf/2312.03558" title="Download PDF">pdf</a>, <a href="/format/2312.03558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When an Image is Worth 1,024 x 1,024 Words: A Case Study in  Computational Pathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shuming Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hanwen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Usuyama%2C+N">Naoto Usuyama</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jiayu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Poon%2C+H">Hoifung Poon</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Furu Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This technical report presents LongViT, a vision Transformer that can process
gigapixel images in an end-to-end manner. Specifically, we split the gigapixel
image into a sequence of millions of patches and project them linearly into
embeddings. LongNet is then employed to model the extremely long sequence,
generating representations that capture both short-range and long-range
dependencies. The linear computation complexity of LongNet, along with its
distributed algorithm, enables us to overcome the constraints of both
computation and memory. We apply LongViT in the field of computational
pathology, aiming for cancer diagnosis and prognosis within gigapixel
whole-slide images. Experimental results demonstrate that LongViT effectively
encodes gigapixel images and outperforms previous state-of-the-art methods on
cancer subtyping and survival prediction. Code and models will be available at
https://aka.ms/LongViT.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03559" title="Abstract">arXiv:2312.03559</a> [<a href="/pdf/2312.03559" title="Download PDF">pdf</a>, <a href="/format/2312.03559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MCAIMem: a Mixed SRAM and eDRAM Cell for Area and Energy-efficient  on-chip AI Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D">Duy-Thanh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharjee%2C+A">Abhiroop Bhattacharjee</a>, 
<a href="/search/cs?searchtype=author&query=Moitra%2C+A">Abhishek Moitra</a>, 
<a href="/search/cs?searchtype=author&query=Panda%2C+P">Priyadarshini Panda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">AI chips commonly employ SRAM memory as buffers for their reliability and
speed, which contribute to high performance. However, SRAM is expensive and
demands significant area and energy consumption. Previous studies have explored
replacing SRAM with emerging technologies like non-volatile memory, which
offers fast-read memory access and a small cell area. Despite these advantages,
non-volatile memory's slow write memory access and high write energy
consumption prevent it from surpassing SRAM performance in AI applications with
extensive memory access requirements. Some research has also investigated eDRAM
as an area-efficient on-chip memory with similar access times as SRAM. Still,
refresh power remains a concern, leaving the trade-off between performance,
area, and power consumption unresolved. To address this issue, our paper
presents a novel mixed CMOS cell memory design that balances performance, area,
and energy efficiency for AI memory by combining SRAM and eDRAM cells. We
consider the proportion ratio of one SRAM and seven eDRAM cells in the memory
to achieve area reduction using mixed CMOS cell memory. Additionally, we
capitalize on the characteristics of DNN data representation and integrate
asymmetric eDRAM cells to lower energy consumption. To validate our proposed
MCAIMem solution, we conduct extensive simulations and benchmarking against
traditional SRAM. Our results demonstrate that MCAIMem significantly
outperforms these alternatives in terms of area and energy efficiency.
Specifically, our MCAIMem can reduce the area by 48\% and energy consumption by
3.4$\times$ compared to SRAM designs, without incurring any accuracy loss.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03562" title="Abstract">arXiv:2312.03562</a> [<a href="/pdf/2312.03562" title="Download PDF">pdf</a>, <a href="/format/2312.03562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Kinship Verification through Multiscale Retinex and Combined  Deep-Shallow features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belabbaci%2C+E+O">El Ouanas Belabbaci</a>, 
<a href="/search/cs?searchtype=author&query=Khammari%2C+M">Mohammed Khammari</a>, 
<a href="/search/cs?searchtype=author&query=Chouchane%2C+A">Ammar Chouchane</a>, 
<a href="/search/cs?searchtype=author&query=Bessaoudi%2C+M">Mohcene Bessaoudi</a>, 
<a href="/search/cs?searchtype=author&query=Ouamane%2C+A">Abdelmalik Ouamane</a>, 
<a href="/search/cs?searchtype=author&query=Himeur%2C+Y">Yassine Himeur</a>, 
<a href="/search/cs?searchtype=author&query=Atalla%2C+S">Shadi Atalla</a>, 
<a href="/search/cs?searchtype=author&query=Mansoor%2C+W">Wathiq Mansoor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The challenge of kinship verification from facial images represents a
cutting-edge and formidable frontier in the realms of pattern recognition and
computer vision. This area of study holds a myriad of potential applications,
spanning from image annotation and forensic analysis to social media research.
Our research stands out by integrating a preprocessing method named Multiscale
Retinex (MSR), which elevates image quality and amplifies contrast, ultimately
bolstering the end results. Strategically, our methodology capitalizes on the
harmonious blend of deep and shallow texture descriptors, merging them
proficiently at the score level through the Logistic Regression (LR) method. To
elucidate, we employ the Local Phase Quantization (LPQ) descriptor to extract
shallow texture characteristics. For deep feature extraction, we turn to the
prowess of the VGG16 model, which is pre-trained on a convolutional neural
network (CNN). The robustness and efficacy of our method have been put to the
test through meticulous experiments on three rigorous kinship datasets, namely:
Cornell Kin Face, UB Kin Face, and TS Kin Face.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03565" title="Abstract">arXiv:2312.03565</a> [<a href="/pdf/2312.03565" title="Download PDF">pdf</a>, <a href="/format/2312.03565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The first five years of the AAA algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Nakatsukasa%2C+Y">Yuji Nakatsukasa</a>, 
<a href="/search/math?searchtype=author&query=Sete%2C+O">Olivier Sete</a>, 
<a href="/search/math?searchtype=author&query=Trefethen%2C+L+N">Lloyd N. Trefethen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The AAA algorithm, introduced in 2018, computes best or near-best rational
approximations to functions or data on subsets of the real line or the complex
plane. It is much faster and more robust than previous algorithms for such
problems and has been used in many applications since its appearance, including
the numerical solution of Laplace, Poisson, and biharmonic PDE problems in
irregular domains. AAA has also been extended in new directions and seems
likely to be a tool of lasting importance in the future.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03567" title="Abstract">arXiv:2312.03567</a> [<a href="/pdf/2312.03567" title="Download PDF">pdf</a>, <a href="/format/2312.03567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XAIQA: Explainer-Based Data Augmentation for Extractive Question  Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stremmel%2C+J">Joel Stremmel</a>, 
<a href="/search/cs?searchtype=author&query=Saeedi%2C+A">Ardavan Saeedi</a>, 
<a href="/search/cs?searchtype=author&query=Hassanzadeh%2C+H">Hamid Hassanzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Batra%2C+S">Sanjit Batra</a>, 
<a href="/search/cs?searchtype=author&query=Hertzberg%2C+J">Jeffrey Hertzberg</a>, 
<a href="/search/cs?searchtype=author&query=Murillo%2C+J">Jaime Murillo</a>, 
<a href="/search/cs?searchtype=author&query=Halperin%2C+E">Eran Halperin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023, December 10th, 2023, New Orleans, United States, 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Extractive question answering (QA) systems can enable physicians and
researchers to query medical records, a foundational capability for designing
clinical studies and understanding patient medical history. However, building
these systems typically requires expert-annotated QA pairs. Large language
models (LLMs), which can perform extractive QA, depend on high quality data in
their prompts, specialized for the application domain. We introduce a novel
approach, XAIQA, for generating synthetic QA pairs at scale from data naturally
available in electronic health records. Our method uses the idea of a
classification model explainer to generate questions and answers about medical
concepts corresponding to medical codes. In an expert evaluation with two
physicians, our method identifies $2.2\times$ more semantic matches and
$3.8\times$ more clinical abbreviations than two popular approaches that use
sentence transformers to create QA pairs. In an ML evaluation, adding our QA
pairs improves performance of GPT-4 as an extractive QA model, including on
difficult questions. In both the expert and ML evaluations, we examine
trade-offs between our method and sentence transformers for QA pair generation
depending on question difficulty.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03568" title="Abstract">arXiv:2312.03568</a> [<a href="/pdf/2312.03568" title="Download PDF">pdf</a>, <a href="/format/2312.03568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DocBinFormer: A Two-Level Transformer Network for Effective Document  Image Binarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biswas%2C+R">Risab Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+S+K">Swalpa Kumar Roy</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Ning Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+U">Umapada Pal</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Guang-Bin Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In real life, various degradation scenarios exist that might damage document
images, making it harder to recognize and analyze them, thus binarization is a
fundamental and crucial step for achieving the most optimal performance in any
document analysis task. We propose DocBinFormer (Document Binarization
Transformer), a novel two-level vision transformer (TL-ViT) architecture based
on vision transformers for effective document image binarization. The presented
architecture employs a two-level transformer encoder to effectively capture
both global and local feature representation from the input images. These
complimentary bi-level features are exploited for efficient document image
binarization, resulting in improved results for system-generated as well as
handwritten document images in a comprehensive approach. With the absence of
convolutional layers, the transformer encoder uses the pixel patches and
sub-patches along with their positional information to operate directly on
them, while the decoder generates a clean (binarized) output image from the
latent representation of the patches. Instead of using a simple vision
transformer block to extract information from the image patches, the proposed
architecture uses two transformer blocks for greater coverage of the extracted
feature space on a global and local scale. The encoded feature representation
is used by the decoder block to generate the corresponding binarized output.
Extensive experiments on a variety of DIBCO and H-DIBCO benchmarks show that
the proposed model outperforms state-of-the-art techniques on four metrics. The
source code will be made available at
https://github.com/RisabBiswas/DocBinFormer.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03576" title="Abstract">arXiv:2312.03576</a> [<a href="/pdf/2312.03576" title="Download PDF">pdf</a>, <a href="/format/2312.03576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Operational Resilience Assessment: A Frequency-Domain Approach for DC  Microgrids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hosseinipour%2C+A">Ali Hosseinipour</a>, 
<a href="/search/eess?searchtype=author&query=Shadaei%2C+M">Maral Shadaei</a>, 
<a href="/search/eess?searchtype=author&query=Khazaei%2C+J">Javad Khazaei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">DC shipboard microgrids (SMGs) are highly dynamic systems susceptible to
failure due to various cyber-physical disturbances, such as extreme weather and
mission operations during wartime. In this paper, the real-time operational
resilience (OR) evaluation of DC SMGs against dynamic disturbances is proposed
using frequency-domain metrics. To this end, first the drawbacks of time-domain
OR evaluation using an energy imbalance index is discussed. As the time-domain
energy imbalance index is shown to be incapable of real-time OR assessment,
particularly in the context of droop-controlled DC SMGs without secondary
voltage restoration control, the $\mathcal{H}_2$ and $\mathcal{H_\infty}$ norms
of candidate transfer functions (TFs) of the system are proposed as measures of
resilience. It is shown that the proposed norms calculated for the bus
impedance TF of the system provides intuitive results in terms of energy
imbalance and can be computed in real time. The case studies conducted for the
study DC SMG under pulsed power load (PPL) disturbances demonstrate the
shortcoming of the time-domain OR evaluation and the capability of the proposed
frequency-domain metrics in intuitive OR evaluation of DC SMGs.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03577" title="Abstract">arXiv:2312.03577</a> [<a href="/pdf/2312.03577" title="Download PDF">pdf</a>, <a href="/format/2312.03577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Bias Mitigation through Bias Experts in Natural Language  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeon%2C+E">Eojin Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Mingyu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Juhyeong Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yeachan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Mok%2C+W">Wing-Lam Mok</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">SangKeun Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in EMNLP 2023 as a long paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Biases in the dataset often enable the model to achieve high performance on
in-distribution data, while poorly performing on out-of-distribution data. To
mitigate the detrimental effect of the bias on the networks, previous works
have proposed debiasing methods that down-weight the biased examples identified
by an auxiliary model, which is trained with explicit bias labels. However,
finding a type of bias in datasets is a costly process. Therefore, recent
studies have attempted to make the auxiliary model biased without the guidance
(or annotation) of bias labels, by constraining the model's training
environment or the capability of the model itself. Despite the promising
debiasing results of recent works, the multi-class learning objective, which
has been naively used to train the auxiliary model, may harm the bias
mitigation effect due to its regularization effect and competitive nature
across classes. As an alternative, we propose a new debiasing framework that
introduces binary classifiers between the auxiliary model and the main model,
coined bias experts. Specifically, each bias expert is trained on a binary
classification task derived from the multi-class classification task via the
One-vs-Rest approach. Experimental results demonstrate that our proposed
strategy improves the bias identification ability of the auxiliary model.
Consequently, our debiased model consistently outperforms the state-of-the-art
on various challenge datasets.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03579" title="Abstract">arXiv:2312.03579</a> [<a href="/pdf/2312.03579" title="Download PDF">pdf</a>, <a href="/ps/2312.03579" title="Download PostScript">ps</a>, <a href="/format/2312.03579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Implication Problem for Functional Dependencies and Variants of  Marginal Distribution Equivalences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hirvonen%2C+M">Minna Hirvonen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">We study functional dependencies together with two different probabilistic
dependency notions: unary marginal identity and unary marginal distribution
equivalence. A unary marginal identity states that two variables x and y are
identically distributed. A unary marginal distribution equivalence states that
the multiset consisting of the marginal probabilities of all the values for
variable x is the same as the corresponding multiset for y. We present a sound
and complete axiomatization for the class of these dependencies and show that
it has Armstrong relations. The axiomatization is infinite, but we show that
there can be no finite axiomatization. The implication problem for the subclass
that contains only functional dependencies and unary marginal identities can be
simulated with functional dependencies and unary inclusion atoms, and therefore
the problem is in polynomial-time. This complexity bound also holds in the case
of the full class, which we show by constructing a polynomial-time algorithm.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03584" title="Abstract">arXiv:2312.03584</a> [<a href="/pdf/2312.03584" title="Download PDF">pdf</a>, <a href="/format/2312.03584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context Diffusion: In-Context Aware Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Najdenkoska%2C+I">Ivona Najdenkoska</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+A">Animesh Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Dubey%2C+A">Abhimanyu Dubey</a>, 
<a href="/search/cs?searchtype=author&query=Mahajan%2C+D">Dhruv Mahajan</a>, 
<a href="/search/cs?searchtype=author&query=Ramanathan%2C+V">Vignesh Ramanathan</a>, 
<a href="/search/cs?searchtype=author&query=Radenovic%2C+F">Filip Radenovic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose Context Diffusion, a diffusion-based framework that enables image
generation models to learn from visual examples presented in context. Recent
work tackles such in-context learning for image generation, where a query image
is provided alongside context examples and text prompts. However, the quality
and fidelity of the generated images deteriorate when the prompt is not
present, demonstrating that these models are unable to truly learn from the
visual context. To address this, we propose a novel framework that separates
the encoding of the visual context and preserving the structure of the query
images. This results in the ability to learn from the visual context and text
prompts, but also from either one of them. Furthermore, we enable our model to
handle few-shot settings, to effectively address diverse in-context learning
scenarios. Our experiments and user study demonstrate that Context Diffusion
excels in both in-domain and out-of-domain tasks, resulting in an overall
enhancement in image quality and fidelity compared to counterpart models.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03585" title="Abstract">arXiv:2312.03585</a> [<a href="/pdf/2312.03585" title="Download PDF">pdf</a>, <a href="/format/2312.03585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foundation Model Assisted Weakly Supervised Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaobo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+X">Xiaojin Gong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This work aims to leverage pre-trained foundation models, such as contrastive
language-image pre-training (CLIP) and segment anything model (SAM), to address
weakly supervised semantic segmentation (WSSS) using image-level labels. To
this end, we propose a coarse-to-fine framework based on CLIP and SAM for
generating high-quality segmentation seeds. Specifically, we construct an image
classification task and a seed segmentation task, which are jointly performed
by CLIP with frozen weights and two sets of learnable task-specific prompts. A
SAM-based seeding (SAMS) module is designed and applied to each task to produce
either coarse or fine seed maps. Moreover, we design a multi-label contrastive
loss supervised by image-level labels and a CAM activation loss supervised by
the generated coarse seed map. These losses are used to learn the prompts,
which are the only parts need to be learned in our framework. Once the prompts
are learned, we input each image along with the learned segmentation-specific
prompts into CLIP and the SAMS module to produce high-quality segmentation
seeds. These seeds serve as pseudo labels to train an off-the-shelf
segmentation network like other two-stage WSSS methods. Experiments show that
our method achieves the state-of-the-art performance on PASCAL VOC 2012 and
competitive results on MS COCO 2014.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03587" title="Abstract">arXiv:2312.03587</a> [<a href="/pdf/2312.03587" title="Download PDF">pdf</a>, <a href="/format/2312.03587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language-Informed Visual Concept Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sharon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunzhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shangzhe Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first two authors contributed equally and are alphabetically ordered. Project page: <a href="https://ai.stanford.edu/~yzzhang/projects/concept-axes/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Our understanding of the visual world is centered around various concept
axes, characterizing different aspects of visual entities. While different
concept axes can be easily specified by language, e.g. color, the exact visual
nuances along each axis often exceed the limitations of linguistic
articulations, e.g. a particular style of painting. In this work, our goal is
to learn a language-informed visual concept representation, by simply
distilling large pre-trained vision-language models. Specifically, we train a
set of concept encoders to encode the information pertinent to a set of
language-informed concept axes, with an objective of reproducing the input
image through a pre-trained Text-to-Image (T2I) model. To encourage better
disentanglement of different concept encoders, we anchor the concept embeddings
to a set of text embeddings obtained from a pre-trained Visual Question
Answering (VQA) model. At inference time, the model extracts concept embeddings
along various axes from new test images, which can be remixed to generate
images with novel compositions of visual concepts. With a lightweight test-time
finetuning procedure, it can also generalize to novel concepts unseen at
training.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03588" title="Abstract">arXiv:2312.03588</a> [<a href="/pdf/2312.03588" title="Download PDF">pdf</a>, <a href="/format/2312.03588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vulnerability of Building Energy Management against Targeted False Data  Injection Attacks:Model Predictive Control vs. Proportional Integral
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ge%2C+X">Xiaoyu Ge</a>, 
<a href="/search/eess?searchtype=author&query=Norouzi%2C+K">Kamelia Norouzi</a>, 
<a href="/search/eess?searchtype=author&query=Moazeni%2C+F">Faegheh Moazeni</a>, 
<a href="/search/eess?searchtype=author&query=Sehic%2C+M">Mirel Sehic</a>, 
<a href="/search/eess?searchtype=author&query=Khazaei%2C+J">Javad Khazaei</a>, 
<a href="/search/eess?searchtype=author&query=Venkitasubramaniam%2C+P">Parv Venkitasubramaniam</a>, 
<a href="/search/eess?searchtype=author&query=Blum%2C+R">Rick Blum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Cybersecurity in building energy management is crucial for protecting
infrastructure, ensuring data integrity, and preventing unauthorized access or
manipulation. This paper investigates the energy efficiency and cybersecurity
of building energy management systems (BMS) against false data injection (FDI)
attacks using proportional-integral (PI) and model predictive control (MPC)
methods. Focusing on a commercial building model with five rooms, vulnerability
of PI-based BMS and nonlinear MPC-based BMS against FDIs on sensors and
actuators is studied. The study aims to assess the effectiveness of these
control strategies in maintaining system performance and lifespan, highlighting
the potential of MPC in enhancing system resilience against cyber threats. Our
case studies demonstrate that even a short term FDIA can cause a 12% reduction
in lifetime of a heat-pump under an MPC controller, and cause a near
thirty-fold overuse of flow valves under a PI controller.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03590" title="Abstract">arXiv:2312.03590</a> [<a href="/pdf/2312.03590" title="Download PDF">pdf</a>, <a href="/format/2312.03590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Micro and Macro Expressions in Computer Graphics Characters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Montanha%2C+R">Rubens Montanha</a>, 
<a href="/search/cs?searchtype=author&query=Raupp%2C+G">Giovana Raupp</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+V">Vitoria Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Partichelli%2C+Y">Yanny Partichelli</a>, 
<a href="/search/cs?searchtype=author&query=Bins%2C+A">Andr&#xe9; Bins</a>, 
<a href="/search/cs?searchtype=author&query=Ferreira%2C+M">Marcos Ferreira</a>, 
<a href="/search/cs?searchtype=author&query=Araujo%2C+V">Victor Araujo</a>, 
<a href="/search/cs?searchtype=author&query=Musse%2C+S">Soraia Musse</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted on the 2023 Brazilian Symposium on Games and Digital Entertainment (SBGames 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">This paper presents the reproduction of two studies focused on the perception
of micro and macro expressions of Virtual Humans (VHs) generated by Computer
Graphics (CG), first described in 2014 and replicated in 2021. The 2014 study
referred to a VH realistic, whereas, in 2021, it referred to a VH cartoon. In
our work, we replicate the study by using a realistic CG character. Our main
goals are to compare the perceptions of micro and macro expressions between
levels of realism (2021 cartoon versus 2023 realistic) and between realistic
characters in different periods (i.e., 2014 versus 2023). In one of our
results, people more easily recognized micro expressions in realistic VHs than
in a cartoon VH. In another result, we show that the participants' perception
was similar for both micro and macro expressions in 2014 and 2023.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03593" title="Abstract">arXiv:2312.03593</a> [<a href="/pdf/2312.03593" title="Download PDF">pdf</a>, <a href="/ps/2312.03593" title="Download PostScript">ps</a>, <a href="/format/2312.03593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Streaming Algorithms for the $k$-Submodular Cover Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gutin%2C+G">Gregory Gutin</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yaping Mao</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+D">Donglei Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoyan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Given a natural number $k\ge 2$, we consider the $k$-submodular cover problem
($k$-SC). The objective is to find a minimum cost subset of a ground set
$\mathcal{X}$ subject to the value of a $k$-submodular utility function being
at least a certain predetermined value $\tau$. For this problem, we design a
bicriteria algorithm with a cost at most $O(1/\epsilon)$ times the optimal
value, while the utility is at least $(1-\epsilon)\tau/r$, where $r$ depends on
the monotonicity of $g$.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03594" title="Abstract">arXiv:2312.03594</a> [<a href="/pdf/2312.03594" title="Download PDF">pdf</a>, <a href="/format/2312.03594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Task is Worth One Word: Learning with Task Prompts for High-Quality  Versatile Image Inpainting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+J">Junhao Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yanhong Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenran Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chun Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Achieving high-quality versatile image inpainting, where user-specified
regions are filled with plausible content according to user intent, presents a
significant challenge. Existing methods face difficulties in simultaneously
addressing context-aware image inpainting and text-guided object inpainting due
to the distinct optimal training strategies required. To overcome this
challenge, we introduce PowerPaint, the first high-quality and versatile
inpainting model that excels in both tasks. First, we introduce learnable task
prompts along with tailored fine-tuning strategies to guide the model's focus
on different inpainting targets explicitly. This enables PowerPaint to
accomplish various inpainting tasks by utilizing different task prompts,
resulting in state-of-the-art performance. Second, we demonstrate the
versatility of the task prompt in PowerPaint by showcasing its effectiveness as
a negative prompt for object removal. Additionally, we leverage prompt
interpolation techniques to enable controllable shape-guided object inpainting.
Finally, we extensively evaluate PowerPaint on various inpainting benchmarks to
demonstrate its superior performance for versatile image inpainting. We release
our codes and models on our project page: https://powerpaint.github.io/.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03596" title="Abstract">arXiv:2312.03596</a> [<a href="/pdf/2312.03596" title="Download PDF">pdf</a>, <a href="/format/2312.03596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MMM: Generative Masked Motion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pinyoanuntapong%2C+E">Ekkasit Pinyoanuntapong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Minwoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advances in text-to-motion generation using diffusion and
autoregressive models have shown promising results. However, these models often
suffer from a trade-off between real-time performance, high fidelity, and
motion editability. To address this gap, we introduce MMM, a novel yet simple
motion generation paradigm based on Masked Motion Model. MMM consists of two
key components: (1) a motion tokenizer that transforms 3D human motion into a
sequence of discrete tokens in latent space, and (2) a conditional masked
motion transformer that learns to predict randomly masked motion tokens,
conditioned on the pre-computed text tokens. By attending to motion and text
tokens in all directions, MMM explicitly captures inherent dependency among
motion tokens and semantic mapping between motion and text tokens. During
inference, this allows parallel and iterative decoding of multiple motion
tokens that are highly consistent with fine-grained text descriptions,
therefore simultaneously achieving high-fidelity and high-speed motion
generation. In addition, MMM has innate motion editability. By simply placing
mask tokens in the place that needs editing, MMM automatically fills the gaps
while guaranteeing smooth transitions between editing and non-editing parts.
Extensive experiments on the HumanML3D and KIT-ML datasets demonstrate that MMM
surpasses current leading methods in generating high-quality motion (evidenced
by superior FID scores of 0.08 and 0.429), while offering advanced editing
features such as body-part modification, motion in-betweening, and the
synthesis of long motion sequences. In addition, MMM is two orders of magnitude
faster on a single mid-range GPU than editable motion diffusion models. Our
project page is available at \url{https://exitudio.github.io/MMM-page}.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03600" title="Abstract">arXiv:2312.03600</a> [<a href="/pdf/2312.03600" title="Download PDF">pdf</a>, <a href="/format/2312.03600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Mixed Integer Quadratic Program for Valuing the Impact of Price and  Forecast Uncertainty for Wind Generators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shen%2C+D">Daniel Shen</a>, 
<a href="/search/eess?searchtype=author&query=Ilic%2C+M">Marija Ilic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures. Submitted to the 2024 IEEE PES GM
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Owners of wind power plants are exposed to financial risk in wholesale
electricity markets due to the uncertain nature of wind forecasts and price
volatility. In the event of a wind shortfall, the plant may have to repurchase
power at a higher price in the real-time market. However, reducing the power
offered in the day-ahead market may also be interpreted by regulators as
physical withholding. We formulate and solve a mixed-integer quadratic program
(MIQP) that prices the uncertain portion of a wind generator's forecast to
hedge against uncertainties and which addresses concerns around withholding. We
exploit the structure of the MIQP inputs to introduce additional constraints to
improve computation time. Additionally, we provide a qualitative approach for
generators and regulators to interpret the results of the MIQP. Finally, we
simulate a real-world application for a wind farm in New York using past wind
forecasts and NYISO prices.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03603" title="Abstract">arXiv:2312.03603</a> [<a href="/pdf/2312.03603" title="Download PDF">pdf</a>, <a href="/format/2312.03603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Voltage Restoration in MVDC Shipboard Microgrids with Economic Nonlinear  Model Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Putri%2C+S">Saskia Putri</a>, 
<a href="/search/eess?searchtype=author&query=Hosseinipour%2C+A">Ali Hosseinipour</a>, 
<a href="/search/eess?searchtype=author&query=Ge%2C+X">Xiaoyu Ge</a>, 
<a href="/search/eess?searchtype=author&query=Moazeni%2C+F">Faegheh Moazeni</a>, 
<a href="/search/eess?searchtype=author&query=Khazaei%2C+J">Javad Khazaei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Future Naval Microgrids (MGs) will include hybrid energy storage systems
(ESS), including battery and supercapacitors to respond to emerging constant
power loads (CPLs) and fluctuating pulsed power loads (PPLs). Voltage
regulation of naval microgrids and power sharing among these resources become
critical for success of a mission. This paper presents a novel control strategy
using nonlinear model predictive controller embedded with a complex droop
control architecture for voltage restoration and power sharing in medium
voltage DC (MVDC) Naval MGs. The complex droop control ensures allocating
supercapacitors (SCs) for high-frequency loads (i.e., PPLs), while battery
energy storage system (BESS) and auxiliary generators share the steady-state
load (i.e., CPL). Compared to state-of-the-art control of the naval ship MGs
that relies on linear models, the proposed method incorporates the nonlinear
behavior of the MGs in the closed-loop control framework via nonlinear model
predictive control (NMPC). A reduced order representation of the MVDC dynamic
is employed as the prediction model, augmented with a multi-objective,
constraints-based, optimal control formulation. The results demonstrate the
effectiveness of the proposed control framework for voltage restoration and
power sharing of resources in naval MGs.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03604" title="Abstract">arXiv:2312.03604</a> [<a href="/pdf/2312.03604" title="Download PDF">pdf</a>, <a href="/format/2312.03604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear Model Predictive Control for Navy Microgrids with Stabilizing  Terminal Ingredients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Putri%2C+S">Saskia Putri</a>, 
<a href="/search/eess?searchtype=author&query=Ge%2C+X">Xiaoyu Ge</a>, 
<a href="/search/eess?searchtype=author&query=Moazeni%2C+F">Faegheh Moazeni</a>, 
<a href="/search/eess?searchtype=author&query=Khazaei%2C+J">Javad Khazaei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents a novel control strategy for medium voltage DC (MVDC)
naval shipboard microgrids (MGs), employing a nonlinear model predictive
controller (NMPC) enhanced with stabilizing features and an intricate droop
control architecture. This combination quickly regulates the output voltage and
adeptly allocates supercapacitors for pulsed power loads (PPLs), while the
battery energy storage system (BESS) and auxiliary generators handle the steady
state loads. A key feature of this study is the formulation of terminal cost
and constraints, providing recursive feasibility and closed-loop stability in
the Lyapunov sense, that offers a more robust and effective approach to naval
power and energy management. By comparing the proposed Lyapunov-based NMPC with
conventional PI controller under fluctuating PPLs, the control robustness is
validated.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03606" title="Abstract">arXiv:2312.03606</a> [<a href="/pdf/2312.03606" title="Download PDF">pdf</a>, <a href="/format/2312.03606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffusionSat: A Generative Foundation Model for Satellite Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khanna%2C+S">Samar Khanna</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Patrick Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Linqi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+C">Chenlin Meng</a>, 
<a href="/search/cs?searchtype=author&query=Rombach%2C+R">Robin Rombach</a>, 
<a href="/search/cs?searchtype=author&query=Burke%2C+M">Marshall Burke</a>, 
<a href="/search/cs?searchtype=author&query=Lobell%2C+D">David Lobell</a>, 
<a href="/search/cs?searchtype=author&query=Ermon%2C+S">Stefano Ermon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion models have achieved state-of-the-art results on many modalities
including images, speech, and video. However, existing models are not tailored
to support remote sensing data, which is widely used in important applications
including environmental monitoring and crop-yield prediction. Satellite images
are significantly different from natural images -- they can be multi-spectral,
irregularly sampled across time -- and existing diffusion models trained on
images from the Web do not support them. Furthermore, remote sensing data is
inherently spatio-temporal, requiring conditional generation tasks not
supported by traditional methods based on captions or images. In this paper, we
present DiffusionSat, to date the largest generative foundation model trained
on a collection of publicly available large, high-resolution remote sensing
datasets. As text-based captions are sparsely available for satellite images,
we incorporate the associated metadata such as geolocation as conditioning
information. Our method produces realistic samples and can be used to solve
multiple generative tasks including temporal generation, superresolution given
multi-spectral inputs and in-painting. Our method outperforms previous
state-of-the-art methods for satellite image generation and is the first
large-scale $\textit{generative}$ foundation model for satellite imagery.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03608" title="Abstract">arXiv:2312.03608</a> [<a href="/pdf/2312.03608" title="Download PDF">pdf</a>, <a href="/format/2312.03608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Multimodal Data Annotation via Calibration With Indoor  Positioning System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rubel%2C+R">Ryan Rubel</a>, 
<a href="/search/cs?searchtype=author&query=Dudash%2C+A">Andrew Dudash</a>, 
<a href="/search/cs?searchtype=author&query=Goli%2C+M">Mohammad Goli</a>, 
<a href="/search/cs?searchtype=author&query=O%27Hara%2C+J">James O&#x27;Hara</a>, 
<a href="/search/cs?searchtype=author&query=Wunderlich%2C+K">Karl Wunderlich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Contains eight pages and 10 figures. A version of this document was accepted to IEEE IRC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learned object detection methods based on fusion of LiDAR and camera data
require labeled training samples, but niche applications, such as warehouse
robotics or automated infrastructure, require semantic classes not available in
large existing datasets. Therefore, to facilitate the rapid creation of
multimodal object detection datasets and alleviate the burden of human
labeling, we propose a novel automated annotation pipeline. Our method uses an
indoor positioning system (IPS) to produce accurate detection labels for both
point clouds and images and eliminates manual annotation entirely. In an
experiment, the system annotates objects of interest 261.8 times faster than a
human baseline and speeds up end-to-end dataset creation by 61.5%.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03609" title="Abstract">arXiv:2312.03609</a> [<a href="/pdf/2312.03609" title="Download PDF">pdf</a>, <a href="/format/2312.03609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Domain Operational Metrics for Real-time Resilience Assessment in  DC Microgrids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shadaei%2C+M">Maral Shadaei</a>, 
<a href="/search/eess?searchtype=author&query=Hosseinipour%2C+A">Ali Hosseinipour</a>, 
<a href="/search/eess?searchtype=author&query=Khazaei%2C+J">Javad Khazaei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Resilience is emerging as an evolving notion, reflecting a system's ability
to endure and adapt to sudden and catastrophic changes and disruptions. This
paper spotlights the significance of the quantitative resilience indices of
medium-voltage DC (MVDC) distribution technology in marine vessels, notably
naval ships. Given the intricate electrical requirements of modern naval ships,
the need for a robust power supply underlines the imperative of resilient DC
microgrids. Addressing this, our study introduces a novel quantitative metric
for operational resilience of DC microgrids based on the measured voltage of
main DC bus. This metric not only fuses real-time tracking, compatibility, and
computational efficiency, but also adeptly monitors multiple event phases based
on time-domain analysis of dc bus voltage dynamics. The intricacies of the dc
bus voltage, including overshoots and undershoots, are meticulously accounted
for in the algorithm design. With respect to existing research that typically
focuses on offline resilience assessments, the proposed index provides valuable
real-time information for microgrid operators and identifies whether microgrid
resilience is deteriorating over time.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03611" title="Abstract">arXiv:2312.03611</a> [<a href="/pdf/2312.03611" title="Download PDF">pdf</a>, <a href="/format/2312.03611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreamComposer: Controllable 3D Object Generation via Multi-View  Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yunhan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yukun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaoyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuan-Chen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Song-Hai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hengshuang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tong He</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xihui Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://yhyang-myron.github.io/DreamComposer/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Utilizing pre-trained 2D large-scale generative models, recent works are
capable of generating high-quality novel views from a single in-the-wild image.
However, due to the lack of information from multiple views, these works
encounter difficulties in generating controllable novel views. In this paper,
we present DreamComposer, a flexible and scalable framework that can enhance
existing view-aware diffusion models by injecting multi-view conditions.
Specifically, DreamComposer first uses a view-aware 3D lifting module to obtain
3D representations of an object from multiple views. Then, it renders the
latent features of the target view from 3D representations with the multi-view
feature fusion module. Finally the target view features extracted from
multi-view inputs are injected into a pre-trained diffusion model. Experiments
show that DreamComposer is compatible with state-of-the-art diffusion models
for zero-shot novel view synthesis, further enhancing them to generate
high-fidelity novel view images with multi-view conditions, ready for
controllable 3D object reconstruction and various other applications.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03612" title="Abstract">arXiv:2312.03612</a> [<a href="/pdf/2312.03612" title="Download PDF">pdf</a>, <a href="/format/2312.03612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physical Symbolic Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tenachi%2C+W">Wassim Tenachi</a>, 
<a href="/search/cs?searchtype=author&query=Ibata%2C+R">Rodrigo Ibata</a>, 
<a href="/search/cs?searchtype=author&query=Diakogiannis%2C+F+I">Foivos I. Diakogiannis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures, 1 table. Accepted to NeurIPS 2023, Machine Learning for Physical Sciences workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Symbolic Computation (cs.SC); Computational Physics (physics.comp-ph); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">We present a framework for constraining the automatic sequential generation
of equations to obey the rules of dimensional analysis by construction.
Combining this approach with reinforcement learning, we built $\Phi$-SO, a
Physical Symbolic Optimization method for recovering analytical functions from
physical data leveraging units constraints. Our symbolic regression algorithm
achieves state-of-the-art results in contexts in which variables and constants
have known physical units, outperforming all other methods on SRBench's Feynman
benchmark in the presence of noise (exceeding 0.1%) and showing resilience even
in the presence of significant (10%) levels of noise.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03613" title="Abstract">arXiv:2312.03613</a> [<a href="/pdf/2312.03613" title="Download PDF">pdf</a>, <a href="/format/2312.03613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmenting optimization-based molecular design with graph neural  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiqiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Campos%2C+J+S">Juan S. Campos</a>, 
<a href="/search/cs?searchtype=author&query=Feldmann%2C+C">Christian Feldmann</a>, 
<a href="/search/cs?searchtype=author&query=Sandfort%2C+F">Frederik Sandfort</a>, 
<a href="/search/cs?searchtype=author&query=Mathea%2C+M">Miriam Mathea</a>, 
<a href="/search/cs?searchtype=author&query=Misener%2C+R">Ruth Misener</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 8 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Computer-aided molecular design (CAMD) studies quantitative
structure-property relationships and discovers desired molecules using
optimization algorithms. With the emergence of machine learning models, CAMD
score functions may be replaced by various surrogates to automatically learn
the structure-property relationships. Due to their outstanding performance on
graph domains, graph neural networks (GNNs) have recently appeared frequently
in CAMD. But using GNNs introduces new optimization challenges. This paper
formulates GNNs using mixed-integer programming and then integrates this GNN
formulation into the optimization and machine learning toolkit OMLT. To
characterize and formulate molecules, we inherit the well-established
mixed-integer optimization formulation for CAMD and propose symmetry-breaking
constraints to remove symmetric solutions caused by graph isomorphism. In two
case studies, we investigate fragment-based odorant molecular design with more
practical requirements to test the compatibility and performance of our
approaches.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03626" title="Abstract">arXiv:2312.03626</a> [<a href="/pdf/2312.03626" title="Download PDF">pdf</a>, <a href="/format/2312.03626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TokenCompose: Grounding Diffusion with Token-level Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zirui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sha%2C+Z">Zhizhou Sha</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zheng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yilin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhuowen Tu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Project link: <a href="https://mlpc-ucsd.github.io/TokenCompose">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present TokenCompose, a Latent Diffusion Model for text-to-image
generation that achieves enhanced consistency between user-specified text
prompts and model-generated images. Despite its tremendous success, the
standard denoising process in the Latent Diffusion Model takes text prompts as
conditions only, absent explicit constraint for the consistency between the
text prompts and the image contents, leading to unsatisfactory results for
composing multiple object categories. TokenCompose aims to improve
multi-category instance composition by introducing the token-wise consistency
terms between the image content and object segmentation maps in the finetuning
stage. TokenCompose can be applied directly to the existing training pipeline
of text-conditioned diffusion models without extra human labeling information.
By finetuning Stable Diffusion, the model exhibits significant improvements in
multi-category instance composition and enhanced photorealism for its generated
images.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03628" title="Abstract">arXiv:2312.03628</a> [<a href="/pdf/2312.03628" title="Download PDF">pdf</a>, <a href="/format/2312.03628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Segment Anything Model Towards Open-Vocabulary Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xumeng Han</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+L">Longhui Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xuehui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Z">Zhiyang Dou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xin He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kuiran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhenjun Han</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qi Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The recent Segment Anything Model (SAM) has emerged as a new paradigmatic
vision foundation model, showcasing potent zero-shot generalization and
flexible prompting. Despite SAM finding applications and adaptations in various
domains, its primary limitation lies in the inability to grasp object
semantics. In this paper, we present Sambor to seamlessly integrate SAM with
the open-vocabulary object detector in an end-to-end framework. While retaining
all the remarkable capabilities inherent to SAM, we enhance it with the
capacity to detect arbitrary objects based on human inputs like category names
or reference expressions. To accomplish this, we introduce a novel SideFormer
module that extracts SAM features to facilitate zero-shot object localization
and inject comprehensive semantic information for open-vocabulary recognition.
In addition, we devise an open-set region proposal network (Open-set RPN),
enabling the detector to acquire the open-set proposals generated by SAM.
Sambor demonstrates superior zero-shot performance across benchmarks, including
COCO and LVIS, proving highly competitive against previous SoTA methods. We
aspire for this work to serve as a meaningful endeavor in endowing SAM to
recognize diverse object categories and advancing open-vocabulary learning with
the support of vision foundation models.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03631" title="Abstract">arXiv:2312.03631</a> [<a href="/pdf/2312.03631" title="Download PDF">pdf</a>, <a href="/format/2312.03631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MOCHa: Multi-Objective Reinforcement Mitigating Caption Hallucinations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ben-Kish%2C+A">Assaf Ben-Kish</a>, 
<a href="/search/cs?searchtype=author&query=Yanuka%2C+M">Moran Yanuka</a>, 
<a href="/search/cs?searchtype=author&query=Alper%2C+M">Morris Alper</a>, 
<a href="/search/cs?searchtype=author&query=Giryes%2C+R">Raja Giryes</a>, 
<a href="/search/cs?searchtype=author&query=Averbuch-Elor%2C+H">Hadar Averbuch-Elor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Website Link: <a href="https://assafbk.github.io/mocha/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While recent years have seen rapid progress in image-conditioned text
generation, image captioning still suffers from the fundamental issue of
hallucinations, the generation of spurious details that cannot be inferred from
the given image. Dedicated methods for reducing hallucinations in image
captioning largely focus on closed-vocabulary object tokens, ignoring most
types of hallucinations that occur in practice. In this work, we propose MOCHa,
an approach that harnesses advancements in reinforcement learning (RL) to
address the sequence-level nature of hallucinations in an open-world setup. To
optimize for caption fidelity to the input image, we leverage ground-truth
reference captions as proxies to measure the logical consistency of generated
captions. However, optimizing for caption fidelity alone fails to preserve the
semantic adequacy of generations; therefore, we propose a multi-objective
reward function that jointly targets these qualities, without requiring any
strong supervision. We demonstrate that these goals can be simultaneously
optimized with our framework, enhancing performance for various captioning
models of different scales. Our qualitative and quantitative results
demonstrate MOCHa's superior performance across various established metrics. We
also demonstrate the benefit of our method in the open-vocabulary setting. To
this end, we contribute OpenCHAIR, a new benchmark for quantifying
open-vocabulary hallucinations in image captioning models, constructed using
generative foundation models. We will release our code, benchmark, and trained
models.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03632" title="Abstract">arXiv:2312.03632</a> [<a href="/pdf/2312.03632" title="Download PDF">pdf</a>, <a href="/format/2312.03632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Data and Resource Efficient Device-Directed Speech Detection  with Large Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wagner%2C+D">Dominik Wagner</a>, 
<a href="/search/cs?searchtype=author&query=Churchill%2C+A">Alexander Churchill</a>, 
<a href="/search/cs?searchtype=author&query=Sigtia%2C+S">Siddharth Sigtia</a>, 
<a href="/search/cs?searchtype=author&query=Georgiou%2C+P">Panayiotis Georgiou</a>, 
<a href="/search/cs?searchtype=author&query=Mirsamadi%2C+M">Matt Mirsamadi</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+A">Aarshee Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Marchi%2C+E">Erik Marchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Interactions with virtual assistants typically start with a trigger phrase
followed by a command. In this work, we explore the possibility of making these
interactions more natural by eliminating the need for a trigger phrase. Our
goal is to determine whether a user addressed the virtual assistant based on
signals obtained from the streaming audio recorded by the device microphone. We
address this task by combining 1-best hypotheses and decoder signals from an
automatic speech recognition system with acoustic representations from an audio
encoder as input features to a large language model (LLM). In particular, we
are interested in data and resource efficient systems that require only a small
amount of training data and can operate in scenarios with only a single frozen
LLM available on a device. For this reason, our model is trained on 80k or less
examples of multimodal data using a combination of low-rank adaptation and
prefix tuning. We compare the proposed system to unimodal baselines and show
that the multimodal approach achieves lower equal-error-rates (EERs), while
using only a fraction of the training data. We also show that low-dimensional
specialized audio representations lead to lower EERs than high-dimensional
general audio representations.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03633" title="Abstract">arXiv:2312.03633</a> [<a href="/pdf/2312.03633" title="Download PDF">pdf</a>, <a href="/ps/2312.03633" title="Download PostScript">ps</a>, <a href="/format/2312.03633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Not All Large Language Models (LLMs) Succumb to the &quot;Reversal Curse&quot;: A  Comparative Study of Deductive Logical Reasoning in BERT and GPT Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jingye Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Da Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kai Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The "Reversal Curse" refers to the scenario where auto-regressive decoder
large language models (LLMs), such as ChatGPT, trained on "A is B" fail to
learn "B is A", demonstrating a basic failure of logical deduction. This raises
a red flag in the use of GPT models for certain general tasks such as
constructing knowledge graphs, considering their adherence to this symmetric
principle. In our study, we examined a bidirectional LLM, BERT, and found that
it is immune to the reversal curse. Driven by ongoing efforts to construct
biomedical knowledge graphs with LLMs, we also embarked on evaluating more
complex but essential deductive reasoning capabilities. This process included
first training encoder and decoder language models to master the intersection
($\cap$) and union ($\cup$) operations on two sets and then moving on to assess
their capability to infer different combinations of union ($\cup$) and
intersection ($\cap$) operations on three newly created sets. The findings
showed that while both encoder and decoder language models, trained for tasks
involving two sets (union/intersection), were proficient in such scenarios,
they encountered difficulties when dealing with operations that included three
sets (various combinations of union and intersection). Our research highlights
the distinct characteristics of encoder and decoder models in simple and
complex logical reasoning. In practice, the choice between BERT and GPT should
be guided by the specific requirements and nature of the task at hand,
leveraging their respective strengths in bidirectional context comprehension
and sequence prediction.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03635" title="Abstract">arXiv:2312.03635</a> [<a href="/pdf/2312.03635" title="Download PDF">pdf</a>, <a href="/format/2312.03635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Time Sensitive Networking on Smart Cities: Techniques,  Challenges, and Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lopes%2C+R">Rui Lopes</a>, 
<a href="/search/cs?searchtype=author&query=Raposo%2C+D">Duarte Raposo</a>, 
<a href="/search/cs?searchtype=author&query=Sargento%2C+S">Susana Sargento</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The rapid proliferation of smart cities has transformed urban landscapes into
dynamic ecosystems teeming with interconnected computational nodes and sensors.
During this evolution, the search for seamless communication in time-critical
scenarios has become evident. With the escalating complexity of urban
environments, envisioning a future with a blend of autonomous and conventional
systems, each demanding distinct quality-of-service considerations, services in
smart cities vary criticality levels and necessitate differentiated traffic
handling, prioritizing critical flows without compromising the network's
reliability or failing on hard real-time requirements.
<br />To tackle these challenges, in this article we propose a Time-Sensitive
Networking (TSN) approach which, at the scale of a smart city network, presents
multifaceted challenges, notably interoperability among diverse technologies
and standards. Nonetheless, TSN emerges as a promising toolkit, encompassing
synchronization, latency management, redundancy, and configuration
functionalities crucial for addressing smart city challenges. Moreover, the
article scrutinizes how TSN, predominantly utilized in domains like automotive
and industry, can be tailored to suit the intricate needs of smart cities,
emphasizing the necessity for adaptability and scalability in network design.
<br />This survey consolidates current research on TSN, outlining its potential in
fortifying critical machine-to-machine communications within smart cities while
highlighting future challenges, potential solutions, and a roadmap for
integrating TSN effectively into the fabric of urban connectivity.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03636" title="Abstract">arXiv:2312.03636</a> [<a href="/pdf/2312.03636" title="Download PDF">pdf</a>, <a href="/format/2312.03636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fed-urlBERT: Client-side Lightweight Federated Transformers for URL  Threat Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yujie Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanbin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haitao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhenhao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruitong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wenrui Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In evolving cyber landscapes, the detection of malicious URLs calls for
cooperation and knowledge sharing across domains. However, collaboration is
often hindered by concerns over privacy and business sensitivities. Federated
learning addresses these issues by enabling multi-clients collaboration without
direct data exchange. Unfortunately, if highly expressive Transformer models
are used, clients may face intolerable computational burdens, and the exchange
of weights could quickly deplete network bandwidth. In this paper, we propose
Fed-urlBERT, a federated URL pre-trained model designed to address both privacy
concerns and the need for cross-domain collaboration in cybersecurity.
Fed-urlBERT leverages split learning to divide the pre-training model into
client and server part, so that the client part takes up less extensive
computation resources and bandwidth. Our appraoch achieves performance
comparable to centralized model under both independently and identically
distributed (IID) and two non-IID data scenarios. Significantly, our federated
model shows about an 7% decrease in the FPR compared to the centralized model.
Additionally, we implement an adaptive local aggregation strategy that
mitigates heterogeneity among clients, demonstrating promising performance
improvements. Overall, our study validates the applicability of the proposed
Transformer federated learning for URL threat analysis, establishing a
foundation for real-world collaborative cybersecurity efforts. The source code
is accessible at https://github.com/Davidup1/FedURLBERT.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03641" title="Abstract">arXiv:2312.03641</a> [<a href="/pdf/2312.03641" title="Download PDF">pdf</a>, <a href="/format/2312.03641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MotionCtrl: A Unified and Flexible Motion Controller for Video  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhouxia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Ziyang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xintao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianshui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+M">Menghan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://wzhouxiff.github.io/projects/MotionCtrl/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">Motions in a video primarily consist of camera motion, induced by camera
movement, and object motion, resulting from object movement. Accurate control
of both camera and object motion is essential for video generation. However,
existing works either mainly focus on one type of motion or do not clearly
distinguish between the two, limiting their control capabilities and diversity.
Therefore, this paper presents MotionCtrl, a unified and flexible motion
controller for video generation designed to effectively and independently
control camera and object motion. The architecture and training strategy of
MotionCtrl are carefully devised, taking into account the inherent properties
of camera motion, object motion, and imperfect training data. Compared to
previous methods, MotionCtrl offers three main advantages: 1) It effectively
and independently controls camera motion and object motion, enabling more
fine-grained motion control and facilitating flexible and diverse combinations
of both types of motion. 2) Its motion conditions are determined by camera
poses and trajectories, which are appearance-free and minimally impact the
appearance or shape of objects in generated videos. 3) It is a relatively
generalizable model that can adapt to a wide array of camera poses and
trajectories once trained. Extensive qualitative and quantitative experiments
have been conducted to demonstrate the superiority of MotionCtrl over existing
methods.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03642" title="Abstract">arXiv:2312.03642</a> [<a href="/pdf/2312.03642" title="Download PDF">pdf</a>, <a href="/format/2312.03642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer-Powered Surrogates Close the ICF Simulation-Experiment Gap  with Extremely Limited Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Olson%2C+M+L">Matthew L. Olson</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shusen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Thiagarajan%2C+J+J">Jayaraman J. Thiagarajan</a>, 
<a href="/search/cs?searchtype=author&query=Kustowski%2C+B">Bogdan Kustowski</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+W">Weng-Keen Wong</a>, 
<a href="/search/cs?searchtype=author&query=Anirudh%2C+R">Rushil Anirudh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Recent advances in machine learning, specifically transformer architecture,
have led to significant advancements in commercial domains. These powerful
models have demonstrated superior capability to learn complex relationships and
often generalize better to new data and problems. This paper presents a novel
transformer-powered approach for enhancing prediction accuracy in multi-modal
output scenarios, where sparse experimental data is supplemented with
simulation data. The proposed approach integrates transformer-based
architecture with a novel graph-based hyper-parameter optimization technique.
The resulting system not only effectively reduces simulation bias, but also
achieves superior prediction accuracy compared to the prior method. We
demonstrate the efficacy of our approach on inertial confinement fusion
experiments, where only 10 shots of real-world data are available, as well as
synthetic versions of these experiments.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03644" title="Abstract">arXiv:2312.03644</a> [<a href="/pdf/2312.03644" title="Download PDF">pdf</a>, <a href="/format/2312.03644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MACCA: Offline Multi-agent Reinforcement Learning with Causal Credit  Assignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yali Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yudi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+M">Meng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Biwei Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Offline Multi-agent Reinforcement Learning (MARL) is valuable in scenarios
where online interaction is impractical or risky. While independent learning in
MARL offers flexibility and scalability, accurately assigning credit to
individual agents in offline settings poses challenges due to partial
observability and emergent behavior. Directly transferring the online credit
assignment method to offline settings results in suboptimal outcomes due to the
absence of real-time feedback and intricate agent interactions. Our approach,
MACCA, characterizing the generative process as a Dynamic Bayesian Network,
captures relationships between environmental variables, states, actions, and
rewards. Estimating this model on offline data, MACCA can learn each agent's
contribution by analyzing the causal relationship of their individual rewards,
ensuring accurate and interpretable credit assignment. Additionally, the
modularity of our approach allows it to seamlessly integrate with various
offline MARL methods. Theoretically, we proved that under the setting of the
offline dataset, the underlying causal structure and the function for
generating the individual rewards of agents are identifiable, which laid the
foundation for the correctness of our modeling. Experimentally, we tested MACCA
in two environments, including discrete and continuous action settings. The
results show that MACCA outperforms SOTA methods and improves performance upon
their backbones.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03646" title="Abstract">arXiv:2312.03646</a> [<a href="/pdf/2312.03646" title="Download PDF">pdf</a>, <a href="/format/2312.03646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Irredundant Decomposition of Data Flow with Affine Dependences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferry%2C+C">Corentin Ferry</a>, 
<a href="/search/cs?searchtype=author&query=Derrien%2C+S">Steven Derrien</a>, 
<a href="/search/cs?searchtype=author&query=Rajopadhye%2C+S">Sanjay Rajopadhye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Optimization pipelines targeting polyhedral programs try to maximize the
compute throughput. Traditional approaches favor reuse and temporal locality;
while the communicated volume can be low, failure to optimize spatial locality
may cause a low I/O performance.
<br />Memory allocation schemes using data partitioning such as data tiling can
improve the spatial locality, but they are domain-specific and rarely applied
by compilers when an existing allocation is supplied.
<br />In this paper, we propose to derive a partitioned memory allocation for tiled
polyhedral programs using their data flow information. We extend the existing
MARS partitioning to handle affine dependences, and determine which dependences
can lead to a regular, simple control flow for communications.
<br />While this paper consists in a theoretical study, previous work on data
partitioning in inter-node scenarios has shown performance improvements due to
better bandwidth utilization.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03651" title="Abstract">arXiv:2312.03651</a> [<a href="/pdf/2312.03651" title="Download PDF">pdf</a>, <a href="/format/2312.03651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MICRACLE: Inverse Reinforcement and Curriculum Learning Model for  Human-inspired Mobile Robot Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gunukula%2C+N">Nihal Gunukula</a>, 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+K">Kshitij Tiwari</a>, 
<a href="/search/cs?searchtype=author&query=Bera%2C+A">Aniket Bera</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In emergency scenarios, mobile robots must navigate like humans, interpreting
stimuli to locate potential victims rapidly without interfering with first
responders. Existing socially-aware navigation algorithms face computational
and adaptability challenges. To overcome these, we propose a solution, MIRACLE
-- an inverse reinforcement and curriculum learning model, that employs
gamified learning to gather stimuli-driven human navigational data. This data
is then used to train a Deep Inverse Maximum Entropy Reinforcement Learning
model, reducing reliance on demonstrator abilities. Testing reveals a low loss
of 2.7717 within a 400-sized environment, signifying human-like response
replication. Current databases lack comprehensive stimuli-driven data,
necessitating our approach. By doing so, we enable robots to navigate emergency
situations with human-like perception, enhancing their life-saving
capabilities.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03654" title="Abstract">arXiv:2312.03654</a> [<a href="/pdf/2312.03654" title="Download PDF">pdf</a>, <a href="/format/2312.03654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Inverse Design Optimization through Multi-fidelity  Simulations, Machine Learning, and Search Space Reduction Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grbcic%2C+L">Luka Grbcic</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+J">Juliane M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=de+Jong%2C+W+A">Wibe Albert de Jong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper introduces a methodology designed to augment the inverse design
optimization process in scenarios constrained by limited compute, through the
strategic synergy of multi-fidelity evaluations, machine learning models, and
optimization algorithms. The proposed methodology is analyzed on two distinct
engineering inverse design problems: airfoil inverse design and the scalar
field reconstruction problem. It leverages a machine learning model trained
with low-fidelity simulation data, in each optimization cycle, thereby
proficiently predicting a target variable and discerning whether a
high-fidelity simulation is necessitated, which notably conserves computational
resources. Additionally, the machine learning model is strategically deployed
prior to optimization to reduce the search space, thereby further accelerating
convergence toward the optimal solution. The methodology has been employed to
enhance two optimization algorithms, namely Differential Evolution and Particle
Swarm Optimization. Comparative analyses illustrate performance improvements
across both algorithms. Notably, this method is adeptly adaptable across any
inverse design application, facilitating a harmonious synergy between a
representative low-fidelity machine learning model, and high-fidelity
simulation, and can be seamlessly applied across any variety of
population-based optimization algorithms.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03656" title="Abstract">arXiv:2312.03656</a> [<a href="/pdf/2312.03656" title="Download PDF">pdf</a>, <a href="/format/2312.03656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretability Illusions in the Generalization of Simplified Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Friedman%2C+D">Dan Friedman</a>, 
<a href="/search/cs?searchtype=author&query=Lampinen%2C+A">Andrew Lampinen</a>, 
<a href="/search/cs?searchtype=author&query=Dixon%2C+L">Lucas Dixon</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Danqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ghandeharioun%2C+A">Asma Ghandeharioun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">A common method to study deep learning systems is to use simplified model
representations -- for example, using singular value decomposition to visualize
the model's hidden states in a lower dimensional space. This approach assumes
that the results of these simplified are faithful to the original model. Here,
we illustrate an important caveat to this assumption: even if the simplified
representations can accurately approximate the full model on the training set,
they may fail to accurately capture the model's behavior out of distribution --
the understanding developed from simplified representations may be an illusion.
We illustrate this by training Transformer models on controlled datasets with
systematic generalization splits. First, we train models on the Dyck
balanced-parenthesis languages. We simplify these models using tools like
dimensionality reduction and clustering, and then explicitly test how these
simplified proxies match the behavior of the original model on various
out-of-distribution test sets. We find that the simplified proxies are
generally less faithful out of distribution. In cases where the original model
generalizes to novel structures or deeper depths, the simplified versions may
fail, or generalize better. This finding holds even if the simplified
representations do not directly depend on the training distribution. Next, we
study a more naturalistic task: predicting the next character in a dataset of
computer code. We find similar generalization gaps between the original model
and simplified proxies, and conduct further analysis to investigate which
aspects of the code completion task are associated with the largest gaps.
Together, our results raise questions about the extent to which mechanistic
interpretations derived using tools like SVD can reliably predict what a model
will do in novel situations.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03657" title="Abstract">arXiv:2312.03657</a> [<a href="/pdf/2312.03657" title="Download PDF">pdf</a>, <a href="/format/2312.03657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multisymplecticity in finite element exterior calculus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Stern%2C+A">Ari Stern</a>, 
<a href="/search/math?searchtype=author&query=Zampa%2C+E">Enrico Zampa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider the application of finite element exterior calculus (FEEC)
methods to a class of canonical Hamiltonian PDE systems involving differential
forms. Solutions to these systems satisfy a local multisymplectic conservation
law, which generalizes the more familiar symplectic conservation law for
Hamiltonian systems of ODEs, and which is connected with physically-important
reciprocity phenomena, such as Lorentz reciprocity in electromagnetics. We
characterize hybrid FEEC methods whose numerical traces satisfy a version of
the multisymplectic conservation law, and we apply this characterization to
several specific classes of FEEC methods, including conforming
Arnold-Falk-Winther-type methods and various hybridizable discontinuous
Galerkin (HDG) methods. Interestingly, the HDG-type and other nonconforming
methods are shown, in general, to be multisymplectic in a stronger sense than
the conforming FEEC methods. This substantially generalizes previous work of
McLachlan and Stern [Found. Comput. Math., 20 (2020), pp. 35-69] on the more
restricted class of canonical Hamiltonian PDEs in the de Donder-Weyl "grad-div"
form.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03661" title="Abstract">arXiv:2312.03661</a> [<a href="/pdf/2312.03661" title="Download PDF">pdf</a>, <a href="/format/2312.03661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reason2Drive: Towards Interpretable and Chain-based Reasoning for  Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nie%2C+M">Ming Nie</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+R">Renyuan Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chunwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xinyue Cai</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jianhua Han</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large vision-language models (VLMs) have garnered increasing interest in
autonomous driving areas, due to their advanced capabilities in complex
reasoning tasks essential for highly autonomous vehicle behavior. Despite their
potential, research in autonomous systems is hindered by the lack of datasets
with annotated reasoning chains that explain the decision-making processes in
driving. To bridge this gap, we present Reason2Drive, a benchmark dataset with
over 600K video-text pairs, aimed at facilitating the study of interpretable
reasoning in complex driving environments. We distinctly characterize the
autonomous driving process as a sequential combination of perception,
prediction, and reasoning steps, and the question-answer pairs are
automatically collected from a diverse range of open-source outdoor driving
datasets, including nuScenes, Waymo and ONCE. Moreover, we introduce a novel
aggregated evaluation metric to assess chain-based reasoning performance in
autonomous systems, addressing the semantic ambiguities of existing metrics
such as BLEU and CIDEr. Based on the proposed benchmark, we conduct experiments
to assess various existing VLMs, revealing insights into their reasoning
capabilities. Additionally, we develop an efficient approach to empower VLMs to
leverage object-level perceptual elements in both feature extraction and
prediction, further enhancing their reasoning accuracy. The code and dataset
will be released.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03664" title="Abstract">arXiv:2312.03664</a> [<a href="/pdf/2312.03664" title="Download PDF">pdf</a>, <a href="/format/2312.03664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative agent-based modeling with actions grounded in physical,  social, or digital space using Concordia
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vezhnevets%2C+A+S">Alexander Sasha Vezhnevets</a>, 
<a href="/search/cs?searchtype=author&query=Agapiou%2C+J+P">John P. Agapiou</a>, 
<a href="/search/cs?searchtype=author&query=Aharon%2C+A">Avia Aharon</a>, 
<a href="/search/cs?searchtype=author&query=Ziv%2C+R">Ron Ziv</a>, 
<a href="/search/cs?searchtype=author&query=Matyas%2C+J">Jayd Matyas</a>, 
<a href="/search/cs?searchtype=author&query=Du%C3%A9%C3%B1ez-Guzm%C3%A1n%2C+E+A">Edgar A. Du&#xe9;&#xf1;ez-Guzm&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Cunningham%2C+W+A">William A. Cunningham</a>, 
<a href="/search/cs?searchtype=author&query=Osindero%2C+S">Simon Osindero</a>, 
<a href="/search/cs?searchtype=author&query=Karmon%2C+D">Danny Karmon</a>, 
<a href="/search/cs?searchtype=author&query=Leibo%2C+J+Z">Joel Z. Leibo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Agent-based modeling has been around for decades, and applied widely across
the social and natural sciences. The scope of this research method is now
poised to grow dramatically as it absorbs the new affordances provided by Large
Language Models (LLM)s. Generative Agent-Based Models (GABM) are not just
classic Agent-Based Models (ABM)s where the agents talk to one another. Rather,
GABMs are constructed using an LLM to apply common sense to situations, act
"reasonably", recall common semantic knowledge, produce API calls to control
digital technologies like apps, and communicate both within the simulation and
to researchers viewing it from the outside. Here we present Concordia, a
library to facilitate constructing and working with GABMs. Concordia makes it
easy to construct language-mediated simulations of physically- or
digitally-grounded environments. Concordia agents produce their behavior using
a flexible component system which mediates between two fundamental operations:
LLM calls and associative memory retrieval. A special agent called the Game
Master (GM), which was inspired by tabletop role-playing games, is responsible
for simulating the environment where the agents interact. Agents take actions
by describing what they want to do in natural language. The GM then translates
their actions into appropriate implementations. In a simulated physical world,
the GM checks the physical plausibility of agent actions and describes their
effects. In digital environments simulating technologies such as apps and
services, the GM may handle API calls to integrate with external tools such as
general AI assistants (e.g., Bard, ChatGPT), and digital apps (e.g., Calendar,
Email, Search, etc.). Concordia was designed to support a wide array of
applications both in scientific research and for evaluating performance of real
digital services by simulating users and/or generating synthetic data.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03666" title="Abstract">arXiv:2312.03666</a> [<a href="/pdf/2312.03666" title="Download PDF">pdf</a>, <a href="/format/2312.03666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards small and accurate convolutional neural networks for acoustic  biodiversity monitoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zaugg%2C+S">Serge Zaugg</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Schaar%2C+M">Mike van der Schaar</a>, 
<a href="/search/cs?searchtype=author&query=Erbs%2C+F">Florence Erbs</a>, 
<a href="/search/cs?searchtype=author&query=Sanchez%2C+A">Antonio Sanchez</a>, 
<a href="/search/cs?searchtype=author&query=Castell%2C+J+V">Joan V. Castell</a>, 
<a href="/search/cs?searchtype=author&query=Ramallo%2C+E">Emiliano Ramallo</a>, 
<a href="/search/cs?searchtype=author&query=Andr%C3%A9%2C+M">Michel Andr&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Automated classification of animal sounds is a prerequisite for large-scale
monitoring of biodiversity. Convolutional Neural Networks (CNNs) are among the
most promising algorithms but they are slow, often achieve poor classification
in the field and typically require large training data sets. Our objective was
to design CNNs that are fast at inference time and achieve good classification
performance while learning from moderate-sized data. Recordings from a
rainforest ecosystem were used. Start and end-point of sounds from 20 bird
species were manually annotated. Spectrograms from 10 second segments were used
as CNN input. We designed simple CNNs with a frequency unwrapping layer
(SIMP-FU models) such that any output unit was connected to all spectrogram
frequencies but only to a sub-region of time, the Receptive Field (RF). Our
models allowed experimentation with different RF durations. Models either used
the time-indexed labels that encode start and end-point of sounds or simpler
segment-level labels. Models learning from time-indexed labels performed
considerably better than their segment-level counterparts. Best classification
performances was achieved for models with intermediate RF duration of 1.5
seconds. The best SIMP-FU models achieved AUCs over 0.95 in 18 of 20 classes on
the test set. On compact low-cost hardware the best SIMP-FU models evaluated up
to seven times faster than real-time data acquisition. RF duration was a major
driver of classification performance. The optimum of 1.5 s was in the same
range as the duration of the sounds. Our models achieved good classification
performance while learning from moderate-sized training data. This is explained
by the usage of time-indexed labels during training and adequately sized RF.
Results confirm the feasibility of deploying small CNNs with good
classification performance on compact low-cost devices.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03667" title="Abstract">arXiv:2312.03667</a> [<a href="/pdf/2312.03667" title="Download PDF">pdf</a>, <a href="/format/2312.03667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WarpDiffusion: Efficient Diffusion Model for High-Fidelity Virtual  Try-on
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=zhang%2C+x">xujie zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiu Li</a>, 
<a href="/search/cs?searchtype=author&query=Kampffmeyer%2C+M">Michael Kampffmeyer</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xin Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhenyu Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Feida Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Haoye Dong</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaodan Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image-based Virtual Try-On (VITON) aims to transfer an in-shop garment image
onto a target person. While existing methods focus on warping the garment to
fit the body pose, they often overlook the synthesis quality around the
garment-skin boundary and realistic effects like wrinkles and shadows on the
warped garments. These limitations greatly reduce the realism of the generated
results and hinder the practical application of VITON techniques. Leveraging
the notable success of diffusion-based models in cross-modal image synthesis,
some recent diffusion-based methods have ventured to tackle this issue.
However, they tend to either consume a significant amount of training resources
or struggle to achieve realistic try-on effects and retain garment details. For
efficient and high-fidelity VITON, we propose WarpDiffusion, which bridges the
warping-based and diffusion-based paradigms via a novel informative and local
garment feature attention mechanism. Specifically, WarpDiffusion incorporates
local texture attention to reduce resource consumption and uses a novel
auto-mask module that effectively retains only the critical areas of the warped
garment while disregarding unrealistic or erroneous portions. Notably,
WarpDiffusion can be integrated as a plug-and-play component into existing
VITON methodologies, elevating their synthesis quality. Extensive experiments
on high-resolution VITON benchmarks and an in-the-wild test set demonstrate the
superiority of WarpDiffusion, surpassing state-of-the-art methods both
qualitatively and quantitatively.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03673" title="Abstract">arXiv:2312.03673</a> [<a href="/pdf/2312.03673" title="Download PDF">pdf</a>, <a href="/format/2312.03673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Role of the Action Space in Robot Manipulation Learning and  Sim-to-Real Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aljalbout%2C+E">Elie Aljalbout</a>, 
<a href="/search/cs?searchtype=author&query=Frank%2C+F">Felix Frank</a>, 
<a href="/search/cs?searchtype=author&query=Karl%2C+M">Maximilian Karl</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Smagt%2C+P">Patrick van der Smagt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We study the choice of action space in robot manipulation learning and
sim-to-real transfer. We define metrics that assess the performance, and
examine the emerging properties in the different action spaces. We train over
250 reinforcement learning~(RL) agents in simulated reaching and pushing tasks,
using 13 different control spaces. The choice of action spaces spans popular
choices in the literature as well as novel combinations of common design
characteristics. We evaluate the training performance in simulation and the
transfer to a real-world environment. We identify good and bad characteristics
of robotic action spaces and make recommendations for future designs. Our
findings have important implications for the design of RL algorithms for robot
manipulation tasks, and highlight the need for careful consideration of action
spaces when training and transferring RL agents for real-world robotics.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03675" title="Abstract">arXiv:2312.03675</a> [<a href="/pdf/2312.03675" title="Download PDF">pdf</a>, <a href="/ps/2312.03675" title="Download PostScript">ps</a>, <a href="/format/2312.03675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GeoShapley: A Game Theory Approach to Measuring Spatial Effects in  Machine Learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziqi Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 10 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper introduces GeoShapley, a game theory approach to measuring spatial
effects in machine learning models. GeoShapley extends the Nobel Prize-winning
Shapley value framework in game theory by conceptualizing location as a player
in a model prediction game, which enables the quantification of the importance
of location and the synergies between location and other features in a model.
GeoShapley is a model-agnostic approach and can be applied to statistical or
black-box machine learning models in various structures. The interpretation of
GeoShapley is directly linked with spatially varying coefficient models for
explaining spatial effects and additive models for explaining non-spatial
effects. Using simulated data, GeoShapley values are validated against known
data-generating processes and are used for cross-comparison of seven
statistical and machine learning models. An empirical example of house price
modeling is used to illustrate GeoShapley's utility and interpretation with
real world data. The method is available as an open-source Python package named
geoshapley.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03678" title="Abstract">arXiv:2312.03678</a> [<a href="/pdf/2312.03678" title="Download PDF">pdf</a>, <a href="/format/2312.03678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Functional Maps for Crease-Aware Non-Isometric Shape Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bastian%2C+L">Lennart Bastian</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yizheng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Navab%2C+N">Nassir Navab</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%A4hner%2C+Z">Zorah L&#xe4;hner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Non-isometric shape correspondence remains a fundamental challenge in
computer vision. Traditional methods using Laplace-Beltrami operator (LBO)
eigenmodes face limitations in characterizing high-frequency extrinsic shape
changes like bending and creases. We propose a novel approach of combining the
non-orthogonal extrinsic basis of eigenfunctions of the elastic thin-shell
hessian with the intrinsic ones of the LBO, creating a hybrid spectral space in
which we construct functional maps. To this end, we present a theoretical
framework to effectively integrate non-orthogonal basis functions into
descriptor- and learning-based functional map methods. Our approach can be
incorporated easily into existing functional map pipelines across varying
applications and is able to handle complex deformations beyond isometries. We
show extensive evaluations across various supervised and unsupervised settings
and demonstrate significant improvements. Notably, our approach achieves up to
15% better mean geodesic error for non-isometric correspondence settings and up
to 45% improvement in scenarios with topological noise.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03681" title="Abstract">arXiv:2312.03681</a> [<a href="/pdf/2312.03681" title="Download PDF">pdf</a>, <a href="/format/2312.03681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing Connectedness of Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berman%2C+P">Piotr Berman</a>, 
<a href="/search/cs?searchtype=author&query=Murzabulatov%2C+M">Meiram Murzabulatov</a>, 
<a href="/search/cs?searchtype=author&query=Raskhodnikova%2C+S">Sofya Raskhodnikova</a>, 
<a href="/search/cs?searchtype=author&query=Ristache%2C+D">Dragos-Florian Ristache</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We investigate algorithms for testing whether an image is connected. Given a
proximity parameter $\epsilon\in(0,1)$ and query access to a black-and-white
image represented by an $n\times n$ matrix of Boolean pixel values, a (1-sided
error) connectedness tester accepts if the image is connected and rejects with
probability at least 2/3 if the image is $\epsilon$-far from connected. We show
that connectedness can be tested nonadaptively with $O(\frac 1{\epsilon^2})$
queries and adaptively with $O(\frac{1}{\epsilon^{3/2}}
\sqrt{\log\frac{1}{\epsilon}})$ queries. The best connectedness tester to date,
by Berman, Raskhodnikova, and Yaroslavtsev (STOC 2014) had query complexity
$O(\frac 1{\epsilon^2}\log \frac 1{\epsilon})$ and was adaptive. We also prove
that every nonadaptive, 1-sided error tester for connectedness must make
$\Omega(\frac 1\epsilon\log \frac 1\epsilon)$ queries.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03682" title="Abstract">arXiv:2312.03682</a> [<a href="/pdf/2312.03682" title="Download PDF">pdf</a>, <a href="/format/2312.03682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Planning Problems Can A Relational Neural Network Solve?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+J">Jiayuan Mao</a>, 
<a href="/search/cs?searchtype=author&query=Lozano-P%C3%A9rez%2C+T">Tom&#xe1;s Lozano-P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Tenenbaum%2C+J+B">Joshua B. Tenenbaum</a>, 
<a href="/search/cs?searchtype=author&query=Kaelbling%2C+L+P">Leslie Pack Kaelbling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 (Spotlight). Project page: <a href="https://concepts-ai.com/p/goal-regression-width/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)

</div>
<p class="mathjax">Goal-conditioned policies are generally understood to be "feed-forward"
circuits, in the form of neural networks that map from the current state and
the goal specification to the next action to take. However, under what
circumstances such a policy can be learned and how efficient the policy will be
are not well understood. In this paper, we present a circuit complexity
analysis for relational neural networks (such as graph neural networks and
transformers) representing policies for planning problems, by drawing
connections with serialized goal regression search (S-GRS). We show that there
are three general classes of planning problems, in terms of the growth of
circuit width and depth as a function of the number of objects and planning
horizon, providing constructive proofs. We also illustrate the utility of this
analysis for designing neural networks for policy learning.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03685" title="Abstract">arXiv:2312.03685</a> [<a href="/pdf/2312.03685" title="Download PDF">pdf</a>, <a href="/ps/2312.03685" title="Download PostScript">ps</a>, <a href="/format/2312.03685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact Travelling Wave Solutions using Tanh Method for two-dimensional  Stochastic Allen-Cahn equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Alzubaidi%2C+H">Hasan Alzubaidi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Exact travelling wave solutions to the two-dimensional stochastic Allen-Cahn
equation with multiplicative noise are obtained through the hyperbolic tangent
(tanh) method. This technique limits the solutions to travelling wave profiles
by representing them with a finite tanh power series. This study focuses on how
multiplicative noise affects the dynamics of these travelling waves, in
particular, occurring of wave propagation failure due to high levels of noise.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03686" title="Abstract">arXiv:2312.03686</a> [<a href="/pdf/2312.03686" title="Download PDF">pdf</a>, <a href="/ps/2312.03686" title="Download PostScript">ps</a>, <a href="/format/2312.03686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Canonization of a random graph by two matrix-vector multiplications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verbitsky%2C+O">Oleg Verbitsky</a>, 
<a href="/search/cs?searchtype=author&query=Zhukovskii%2C+M">Maksim Zhukovskii</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 3 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">We show that a canonical labeling of a random $n$-vertex graph can be
obtained by assigning to each vertex $x$ the triple $(w_1(x),w_2(x),w_3(x))$,
where $w_k(x)$ is the number of walks of length $k$ starting from $x$. This
takes time $O(n^2)$, where $n^2$ is the input size, by using just two
matrix-vector multiplications. The linear-time canonization of a random graph
is the classical result of Babai, Erd\H{o}s, and Selkow. For this purpose they
use the well-known combinatorial color refinement procedure, and we make a
comparative analysis of the two algorithmic approaches.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03689" title="Abstract">arXiv:2312.03689</a> [<a href="/pdf/2312.03689" title="Download PDF">pdf</a>, <a href="/format/2312.03689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating and Mitigating Discrimination in Language Model Decisions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tamkin%2C+A">Alex Tamkin</a>, 
<a href="/search/cs?searchtype=author&query=Askell%2C+A">Amanda Askell</a>, 
<a href="/search/cs?searchtype=author&query=Lovitt%2C+L">Liane Lovitt</a>, 
<a href="/search/cs?searchtype=author&query=Durmus%2C+E">Esin Durmus</a>, 
<a href="/search/cs?searchtype=author&query=Joseph%2C+N">Nicholas Joseph</a>, 
<a href="/search/cs?searchtype=author&query=Kravec%2C+S">Shauna Kravec</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+K">Karina Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Kaplan%2C+J">Jared Kaplan</a>, 
<a href="/search/cs?searchtype=author&query=Ganguli%2C+D">Deep Ganguli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">As language models (LMs) advance, interest is growing in applying them to
high-stakes societal decisions, such as determining financing or housing
eligibility. However, their potential for discrimination in such contexts
raises ethical concerns, motivating the need for better methods to evaluate
these risks. We present a method for proactively evaluating the potential
discriminatory impact of LMs in a wide range of use cases, including
hypothetical use cases where they have not yet been deployed. Specifically, we
use an LM to generate a wide array of potential prompts that decision-makers
may input into an LM, spanning 70 diverse decision scenarios across society,
and systematically vary the demographic information in each prompt. Applying
this methodology reveals patterns of both positive and negative discrimination
in the Claude 2.0 model in select settings when no interventions are applied.
While we do not endorse or permit the use of language models to make automated
decisions for the high-risk use cases we study, we demonstrate techniques to
significantly decrease both positive and negative discrimination through
careful prompt engineering, providing pathways toward safer deployment in use
cases where they may be appropriate. Our work enables developers and
policymakers to anticipate, measure, and address discrimination as language
model capabilities and applications continue to expand. We release our dataset
and prompts at https://huggingface.co/datasets/Anthropic/discrim-eval
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03691" title="Abstract">arXiv:2312.03691</a> [<a href="/pdf/2312.03691" title="Download PDF">pdf</a>, <a href="/format/2312.03691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Role of Edge Dependency in Graph Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chanpuriya%2C+S">Sudhanshu Chanpuriya</a>, 
<a href="/search/cs?searchtype=author&query=Musco%2C+C">Cameron Musco</a>, 
<a href="/search/cs?searchtype=author&query=Sotiropoulos%2C+K">Konstantinos Sotiropoulos</a>, 
<a href="/search/cs?searchtype=author&query=Tsourakakis%2C+C">Charalampos Tsourakakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">In this work, we introduce a novel evaluation framework for generative models
of graphs, emphasizing the importance of model-generated graph overlap
(Chanpuriya et al., 2021) to ensure both accuracy and edge-diversity. We
delineate a hierarchy of graph generative models categorized into three levels
of complexity: edge independent, node independent, and fully dependent models.
This hierarchy encapsulates a wide range of prevalent methods. We derive
theoretical bounds on the number of triangles and other short-length cycles
producible by each level of the hierarchy, contingent on the model overlap. We
provide instances demonstrating the asymptotic optimality of our bounds.
Furthermore, we introduce new generative models for each of the three
hierarchical levels, leveraging dense subgraph discovery (Gionis &amp; Tsourakakis,
2015). Our evaluation, conducted on real-world datasets, focuses on assessing
the output quality and overlap of our proposed models in comparison to other
popular models. Our results indicate that our simple, interpretable models
provide competitive baselines to popular generative models. Through this
investigation, we aim to propel the advancement of graph generative models by
offering a structured framework and robust evaluation metrics, thereby
facilitating the development of models capable of generating accurate and
edge-diverse graphs.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03692" title="Abstract">arXiv:2312.03692</a> [<a href="/pdf/2312.03692" title="Download PDF">pdf</a>, <a href="/format/2312.03692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory Triggers: Unveiling Memorization in Text-To-Image Generative  Models through Word-Level Duplication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naseh%2C+A">Ali Naseh</a>, 
<a href="/search/cs?searchtype=author&query=Roh%2C+J">Jaechul Roh</a>, 
<a href="/search/cs?searchtype=author&query=Houmansadr%2C+A">Amir Houmansadr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion-based models, such as the Stable Diffusion model, have
revolutionized text-to-image synthesis with their ability to produce
high-quality, high-resolution images. These advancements have prompted
significant progress in image generation and editing tasks. However, these
models also raise concerns due to their tendency to memorize and potentially
replicate exact training samples, posing privacy risks and enabling adversarial
attacks. Duplication in training datasets is recognized as a major factor
contributing to memorization, and various forms of memorization have been
studied so far. This paper focuses on two distinct and underexplored types of
duplication that lead to replication during inference in diffusion-based
models, particularly in the Stable Diffusion model. We delve into these
lesser-studied duplication phenomena and their implications through two case
studies, aiming to contribute to the safer and more responsible use of
generative models in various applications.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03696" title="Abstract">arXiv:2312.03696</a> [<a href="/pdf/2312.03696" title="Download PDF">pdf</a>, <a href="/format/2312.03696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Learning in Polyhedral Games via Best Response Oracles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chakrabarti%2C+D">Darshan Chakrabarti</a>, 
<a href="/search/cs?searchtype=author&query=Farina%2C+G">Gabriele Farina</a>, 
<a href="/search/cs?searchtype=author&query=Kroer%2C+C">Christian Kroer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA); Optimization and Control (math.OC)

</div>
<p class="mathjax">We study online learning and equilibrium computation in games with polyhedral
decision sets, a property shared by both normal-form games and extensive-form
games (EFGs), when the learning agent is restricted to using a best-response
oracle. We show how to achieve constant regret in zero-sum games and
$O(T^{1/4})$ regret in general-sum games while using only $O(\log t)$
best-response queries at a given iteration $t$, thus improving over the best
prior result, which required $O(T)$ queries per iteration. Moreover, our
framework yields the first last-iterate convergence guarantees for self-play
with best-response oracles in zero-sum games. This convergence occurs at a
linear rate, though with a condition-number dependence. We go on to show a
$O(1/\sqrt{T})$ best-iterate convergence rate without such a dependence. Our
results build on linear-rate convergence results for variants of the
Frank-Wolfe (FW) algorithm for strongly convex and smooth minimization problems
over polyhedral domains. These FW results depend on a condition number of the
polytope, known as facial distance. In order to enable application to settings
such as EFGs, we show two broad new results: 1) the facial distance for
polytopes in standard form is at least $\gamma/\sqrt{k}$ where $\gamma$ is the
minimum value of a nonzero coordinate of a vertex of the polytope and $k\leq n$
is the number of tight inequality constraints in the optimal face, and 2) the
facial distance for polytopes of the form
$\mathbf{A}\boldsymbol{x}=\boldsymbol{b},\mathbf{C}\boldsymbol{x}\leq\boldsymbol{d},
\boldsymbol{x}\geq \mathbf{0}$ where $\boldsymbol{x}\in\mathbb{R}^n$,
$\mathbf{C}\geq\boldsymbol{0}$ is a nonzero integral matrix, and
$\boldsymbol{d}\geq \boldsymbol{0}$, is at least
$1/(\|\mathbf{C}\|_\infty\sqrt{n})$. This yields the first such results for
several problems such as sequence-form polytopes, flow polytopes, and matching
polytopes.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03698" title="Abstract">arXiv:2312.03698</a> [<a href="/pdf/2312.03698" title="Download PDF">pdf</a>, <a href="/format/2312.03698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intrinsic Harmonization for Illumination-Aware Compositing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Careaga%2C+C">Chris Careaga</a>, 
<a href="/search/cs?searchtype=author&query=Aksoy%2C+Y">Ya&#x11f;&#x131;z Aksoy</a>, 
<a href="/search/cs?searchtype=author&query=Miangoleh%2C+S+M+H">S. Mahdi H. Miangoleh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures. Accepted to SIGGRAPH Asia 2023 (Conference Track). Project page: <a href="https://yaksoy.github.io/intrinsicCompositing/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">Despite significant advancements in network-based image harmonization
techniques, there still exists a domain disparity between typical training
pairs and real-world composites encountered during inference. Most existing
methods are trained to reverse global edits made on segmented image regions,
which fail to accurately capture the lighting inconsistencies between the
foreground and background found in composited images. In this work, we
introduce a self-supervised illumination harmonization approach formulated in
the intrinsic image domain. First, we estimate a simple global lighting model
from mid-level vision representations to generate a rough shading for the
foreground region. A network then refines this inferred shading to generate a
harmonious re-shading that aligns with the background scene. In order to match
the color appearance of the foreground and background, we utilize ideas from
prior harmonization approaches to perform parameterized image edits in the
albedo domain. To validate the effectiveness of our approach, we present
results from challenging real-world composites and conduct a user study to
objectively measure the enhanced realism achieved compared to state-of-the-art
harmonization methods.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03699" title="Abstract">arXiv:2312.03699</a> [<a href="/pdf/2312.03699" title="Download PDF">pdf</a>, <a href="/format/2312.03699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PROMISE: A Framework for Model-Driven Stateful Prompt Orchestration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Heierli%2C+J">Jasmin Heierli</a>, 
<a href="/search/cs?searchtype=author&query=Meisterhans%2C+M">Max Meisterhans</a>, 
<a href="/search/cs?searchtype=author&query=Moser%2C+A">Adrian Moser</a>, 
<a href="/search/cs?searchtype=author&query=F%C3%A4rber%2C+A">Andri F&#xe4;rber</a>, 
<a href="/search/cs?searchtype=author&query=Dolata%2C+M">Mateusz Dolata</a>, 
<a href="/search/cs?searchtype=author&query=Gavagnin%2C+E">Elena Gavagnin</a>, 
<a href="/search/cs?searchtype=author&query=de+Spindler%2C+A">Alexandre de Spindler</a>, 
<a href="/search/cs?searchtype=author&query=Schwabe%2C+G">Gerhard Schwabe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The advent of increasingly powerful language models has raised expectations
for language-based interactions. However, controlling these models is a
challenge, emphasizing the need to be able to investigate the feasibility and
value of their application. We present PROMISE, a framework that facilitates
the development of complex language-based interactions with information
systems. Its use of state machine modeling concepts enables model-driven,
dynamic prompt orchestration across hierarchically nested states and
transitions. This improves the control of the behavior of language models and
thus enables their effective and efficient use. We show the benefits of PROMISE
in the context of application scenarios within health information systems and
demonstrate its ability to handle complex interactions.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03700" title="Abstract">arXiv:2312.03700</a> [<a href="/pdf/2312.03700" title="Download PDF">pdf</a>, <a href="/format/2312.03700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OneLLM: One Framework to Align All Modalities with Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jiaming Han</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+K">Kaixiong Gong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaipeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Peng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+X">Xiangyu Yue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/csuhan/OneLLM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">Multimodal large language models (MLLMs) have gained significant attention
due to their strong multimodal understanding capability. However, existing
works rely heavily on modality-specific encoders, which usually differ in
architecture and are limited to common modalities. In this paper, we present
OneLLM, an MLLM that aligns eight modalities to language using a unified
framework. We achieve this through a unified multimodal encoder and a
progressive multimodal alignment pipeline. In detail, we first train an image
projection module to connect a vision encoder with LLM. Then, we build a
universal projection module (UPM) by mixing multiple image projection modules
and dynamic routing. Finally, we progressively align more modalities to LLM
with the UPM. To fully leverage the potential of OneLLM in following
instructions, we also curated a comprehensive multimodal instruction dataset,
including 2M items from image, audio, video, point cloud, depth/normal map, IMU
and fMRI brain activity. OneLLM is evaluated on 25 diverse benchmarks,
encompassing tasks such as multimodal captioning, question answering and
reasoning, where it delivers excellent performance. Code, data, model and
online demo are available at https://github.com/csuhan/OneLLM
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03701" title="Abstract">arXiv:2312.03701</a> [<a href="/pdf/2312.03701" title="Download PDF">pdf</a>, <a href="/format/2312.03701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-conditioned Image Generation via Generating Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Katabi%2C+D">Dina Katabi</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+K">Kaiming He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents $\textbf{R}$epresentation-$\textbf{C}$onditioned image
$\textbf{G}$eneration (RCG), a simple yet effective image generation framework
which sets a new benchmark in class-unconditional image generation. RCG does
not condition on any human annotations. Instead, it conditions on a
self-supervised representation distribution which is mapped from the image
distribution using a pre-trained encoder. During generation, RCG samples from
such representation distribution using a representation diffusion model (RDM),
and employs a pixel generator to craft image pixels conditioned on the sampled
representation. Such a design provides substantial guidance during the
generative process, resulting in high-quality image generation. Tested on
ImageNet 256$\times$256, RCG achieves a Frechet Inception Distance (FID) of
3.31 and an Inception Score (IS) of 253.4. These results not only significantly
improve the state-of-the-art of class-unconditional image generation but also
rival the current leading methods in class-conditional image generation,
bridging the long-standing performance gap between these two tasks. Code is
available at https://github.com/LTH14/rcg.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03703" title="Abstract">arXiv:2312.03703</a> [<a href="/pdf/2312.03703" title="Download PDF">pdf</a>, <a href="/format/2312.03703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Skeleton-in-Context: Unified Skeleton Sequence Modeling with In-Context  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinshun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhongbin Fang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xia Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangtai Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mengyuan Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://github.com/fanglaosi/Skeleton-in-Context">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In-context learning provides a new perspective for multi-task modeling for
vision and NLP. Under this setting, the model can perceive tasks from prompts
and accomplish them without any extra task-specific head predictions or model
fine-tuning. However, Skeleton sequence modeling via in-context learning
remains unexplored. Directly applying existing in-context models from other
areas onto skeleton sequences fails due to the inter-frame and cross-task pose
similarity that makes it outstandingly hard to perceive the task correctly from
a subtle context. To address this challenge, we propose Skeleton-in-Context
(SiC), an effective framework for in-context skeleton sequence modeling. Our
SiC is able to handle multiple skeleton-based tasks simultaneously after a
single training process and accomplish each task from context according to the
given prompt. It can further generalize to new, unseen tasks according to
customized prompts. To facilitate context perception, we additionally propose a
task-unified prompt, which adaptively learns tasks of different natures, such
as partial joint-level generation, sequence-level prediction, or 2D-to-3D
motion prediction. We conduct extensive experiments to evaluate the
effectiveness of our SiC on multiple tasks, including motion prediction, pose
estimation, joint completion, and future pose estimation. We also evaluate its
generalization capability on unseen tasks such as motion-in-between. These
experiments show that our model achieves state-of-the-art multi-task
performance and even outperforms single-task methods on certain tasks.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03704" title="Abstract">arXiv:2312.03704</a> [<a href="/pdf/2312.03704" title="Download PDF">pdf</a>, <a href="/format/2312.03704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relightable Gaussian Codec Avatars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saito%2C+S">Shunsuke Saito</a>, 
<a href="/search/cs?searchtype=author&query=Schwartz%2C+G">Gabriel Schwartz</a>, 
<a href="/search/cs?searchtype=author&query=Simon%2C+T">Tomas Simon</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+G">Giljoo Nam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Website: <a href="https://shunsukesaito.github.io/rgca/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The fidelity of relighting is bounded by both geometry and appearance
representations. For geometry, both mesh and volumetric approaches have
difficulty modeling intricate structures like 3D hair geometry. For appearance,
existing relighting models are limited in fidelity and often too slow to render
in real-time with high-resolution continuous environments. In this work, we
present Relightable Gaussian Codec Avatars, a method to build high-fidelity
relightable head avatars that can be animated to generate novel expressions.
Our geometry model based on 3D Gaussians can capture 3D-consistent
sub-millimeter details such as hair strands and pores on dynamic face
sequences. To support diverse materials of human heads such as the eyes, skin,
and hair in a unified manner, we present a novel relightable appearance model
based on learnable radiance transfer. Together with global illumination-aware
spherical harmonics for the diffuse components, we achieve real-time relighting
with spatially all-frequency reflections using spherical Gaussians. This
appearance model can be efficiently relit under both point light and continuous
illumination. We further improve the fidelity of eye reflections and enable
explicit gaze control by introducing relightable explicit eye models. Our
method outperforms existing approaches without compromising real-time
performance. We also demonstrate real-time relighting of avatars on a tethered
consumer VR headset, showcasing the efficiency and fidelity of our avatars.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Thu,  7 Dec 23</h3>
<dl>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11230" title="Abstract">arXiv:2310.11230</a> (cross-list from eess.AS) [<a href="/pdf/2310.11230" title="Download PDF">pdf</a>, <a href="/format/2310.11230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zipformer: A faster and better encoder for automatic speech recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yao%2C+Z">Zengwei Yao</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+L">Liyong Guo</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+X">Xiaoyu Yang</a>, 
<a href="/search/eess?searchtype=author&query=Kang%2C+W">Wei Kang</a>, 
<a href="/search/eess?searchtype=author&query=Kuang%2C+F">Fangjun Kuang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Y">Yifan Yang</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+Z">Zengrui Jin</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+L">Long Lin</a>, 
<a href="/search/eess?searchtype=author&query=Povey%2C+D">Daniel Povey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">The Conformer has become the most popular encoder model for automatic speech
recognition (ASR). It adds convolution modules to a transformer to learn both
local and global dependencies. In this work we describe a faster, more
memory-efficient, and better-performing transformer, called Zipformer. Modeling
changes include: 1) a U-Net-like encoder structure where middle stacks operate
at lower frame rates; 2) reorganized block structure with more modules, within
which we re-use attention weights for efficiency; 3) a modified form of
LayerNorm called BiasNorm allows us to retain some length information; 4) new
activation functions SwooshR and SwooshL work better than Swish. We also
propose a new optimizer, called ScaledAdam, which scales the update by each
tensor's current scale to keep the relative change about the same, and also
explictly learns the parameter scale. It achieves faster convergence and better
performance than Adam. Extensive experiments on LibriSpeech, Aishell-1, and
WenetSpeech datasets demonstrate the effectiveness of our proposed Zipformer
over other state-of-the-art ASR models. Our code is publicly available at
https://github.com/k2-fsa/icefall.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02660" title="Abstract">arXiv:2312.02660</a> (cross-list from econ.GN) [<a href="/pdf/2312.02660" title="Download PDF">pdf</a>, <a href="/format/2312.02660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uniswap Daily Transaction Indices by Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Chemaya%2C+N">Nir Chemaya</a>, 
<a href="/search/econ?searchtype=author&query=Cong%2C+L+W">Lin William Cong</a>, 
<a href="/search/econ?searchtype=author&query=Jorgensen%2C+E">Emma Jorgensen</a>, 
<a href="/search/econ?searchtype=author&query=Liu%2C+D">Dingyue Liu</a>, 
<a href="/search/econ?searchtype=author&query=Zhang%2C+L">Luyao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Computational Engineering, Finance, and Science (cs.CE); Cryptography and Security (cs.CR); Computers and Society (cs.CY); Applications (stat.AP)

</div>
<p class="mathjax">DeFi is transforming financial services by removing intermediaries and
producing a wealth of open-source data. This transformation is propelled by
Layer 2 (L2) solutions, aimed at boosting network efficiency and scalability
beyond current Layer 1 (L1) capabilities. This study addresses the lack of
detailed L2 impact analysis by examining over 50 million transactions from
Uniswap. Our dataset, featuring transactions from L1 and L2 across networks
like Ethereum and Polygon, provides daily indices revealing adoption,
scalability, and decentralization within the DeFi space. These indices help to
elucidate the complex relationship between DeFi and L2 technologies, advancing
our understanding of the ecosystem. The dataset is enhanced by an open-source
Python framework for computing decentralization indices, adaptable for various
research needs. This positions the dataset as a vital resource for machine
learning endeavors, particularly deep learning, contributing significantly to
the development of Blockchain as Web3's infrastructure.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02994" title="Abstract">arXiv:2312.02994</a> (cross-list from q-bio.GN) [<a href="/pdf/2312.02994" title="Download PDF">pdf</a>, <a href="/ps/2312.02994" title="Download PostScript">ps</a>, <a href="/format/2312.02994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High Performance Multiple Sequence Alignment Algorithms for Comparison  of Microbial Genomes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Helal%2C+M">Manal Helal</a>, 
<a href="/search/q-bio?searchtype=author&query=El-Gindy%2C+H">Hossam El-Gindy</a>, 
<a href="/search/q-bio?searchtype=author&query=Gaeta%2C+B">Bruno Gaeta</a>, 
<a href="/search/q-bio?searchtype=author&query=Sinchenko%2C+V">Vitali Sinchenko</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc 19th Int Conf Genome Informatics (GIW 2008), Gold Coast,
  Australia
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Advances in gene sequencing have enabled in silico analyses of microbial
genomes and have led to the revision of concepts of microbial taxonomy and
evolution. We explore deficiencies in existing multiple sequence global
alignment algorithms and introduce a new indexing scheme to partition the
dynamic programming algorithm hypercube scoring tensor over processors based on
the dependency between partitions to be scored in parallel. The performance of
algorithms is compared in the study of rpoB gene sequences of Mycoplasma
species.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02997" title="Abstract">arXiv:2312.02997</a> (cross-list from physics.ao-ph) [<a href="/pdf/2312.02997" title="Download PDF">pdf</a>, <a href="/format/2312.02997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulation-Based Inference of Surface Accumulation and Basal Melt Rates  of an Antarctic Ice Shelf from Isochronal Layers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Moss%2C+G">Guy Moss</a>, 
<a href="/search/physics?searchtype=author&query=Vi%C5%A1njevi%C4%87%2C+V">Vjeran Vi&#x161;njevi&#x107;</a>, 
<a href="/search/physics?searchtype=author&query=Eisen%2C+O">Olaf Eisen</a>, 
<a href="/search/physics?searchtype=author&query=Oraschewski%2C+F+M">Falk M. Oraschewski</a>, 
<a href="/search/physics?searchtype=author&query=Schr%C3%B6der%2C+C">Cornelius Schr&#xf6;der</a>, 
<a href="/search/physics?searchtype=author&query=Macke%2C+J+H">Jakob H. Macke</a>, 
<a href="/search/physics?searchtype=author&query=Drews%2C+R">Reinhard Drews</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Journal of Geophysical Research: Earth Surface
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG); Geophysics (physics.geo-ph)

</div>
<p class="mathjax">The ice shelves buttressing the Antarctic ice sheet determine the rate of
ice-discharge into the surrounding oceans. The geometry of ice shelves, and
hence their buttressing strength, is determined by ice flow as well as by the
local surface accumulation and basal melt rates, governed by atmospheric and
oceanic conditions. Contemporary methods resolve one of these rates, but
typically not both. Moreover, there is little information of how they changed
in time. We present a new method to simultaneously infer the surface
accumulation and basal melt rates averaged over decadal and centennial
timescales. We infer the spatial dependence of these rates along flow line
transects using internal stratigraphy observed by radars, using a kinematic
forward model of internal stratigraphy. We solve the inverse problem using
simulation-based inference (SBI). SBI performs Bayesian inference by training
neural networks on simulations of the forward model to approximate the
posterior distribution, allowing us to also quantify uncertainties over the
inferred parameters. We demonstrate the validity of our method on a synthetic
example, and apply it to Ekstr\"om Ice Shelf, Antarctica, for which newly
acquired radar measurements are available. We obtain posterior distributions of
surface accumulation and basal melt averaging over 42, 84, 146, and 188 years
before 2022. Our results suggest stable atmospheric and oceanographic
conditions over this period in this catchment of Antarctica. Use of observed
internal stratigraphy can separate the effects of surface accumulation and
basal melt, allowing them to be interpreted in a historical context of the last
centuries and beyond.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03001" title="Abstract">arXiv:2312.03001</a> (cross-list from eess.IV) [<a href="/pdf/2312.03001" title="Download PDF">pdf</a>, <a href="/ps/2312.03001" title="Download PostScript">ps</a>, <a href="/format/2312.03001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computer Vision for Increased Operative Efficiency via Identification of  Instruments in the Neurosurgical Operating Room: A Proof-of-Concept Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zachem%2C+T+J">Tanner J. Zachem</a> (1,2), 
<a href="/search/eess?searchtype=author&query=Chen%2C+S+F">Sully F. Chen</a> (1), 
<a href="/search/eess?searchtype=author&query=Venkatraman%2C+V">Vishal Venkatraman</a> (1), 
<a href="/search/eess?searchtype=author&query=Sykes%2C+D+A">David AW Sykes</a> (1), 
<a href="/search/eess?searchtype=author&query=Prakash%2C+R">Ravi Prakash</a> (2), 
<a href="/search/eess?searchtype=author&query=Spellicy%2C+S">Samantha Spellicy</a> (1), 
<a href="/search/eess?searchtype=author&query=Suarez%2C+A+D">Alexander D Suarez</a> (1), 
<a href="/search/eess?searchtype=author&query=Ross%2C+W">Weston Ross</a> (1), 
<a href="/search/eess?searchtype=author&query=Codd%2C+P+J">Patrick J. Codd</a> (1,2) ((1) Department of Neurosurgery, Duke University School of Medicine, Durham, NC, USA, (2) Department of Mechanical Engineering and Materials Science, Duke University, Durham, NC, USA)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Data is openly available through The Open Science Framework: <a href="https://doi.org/10.17605/OSF.IO/BCQK2">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Objectives Computer vision (CV) is a field of artificial intelligence that
enables machines to interpret and understand images and videos. CV has the
potential to be of assistance in the operating room (OR) to track surgical
instruments. We built a CV algorithm for identifying surgical instruments in
the neurosurgical operating room as a potential solution for surgical
instrument tracking and management to decrease surgical waste and opening of
unnecessary tools. Methods We collected 1660 images of 27 commonly used
neurosurgical instruments. Images were labeled using the VGG Image Annotator
and split into 80% training and 20% testing sets in order to train a U-Net
Convolutional Neural Network using 5-fold cross validation. Results Our U-Net
achieved a tool identification accuracy of 80-100% when distinguishing 25
classes of instruments, with 19/25 classes having accuracy over 90%. The model
performance was not adequate for sub classifying Adson, Gerald, and Debakey
forceps, which had accuracies of 60-80%. Conclusions We demonstrated the
viability of using machine learning to accurately identify surgical
instruments. Instrument identification could help optimize surgical tray
packing, decrease tool usage and waste, decrease incidence of instrument
misplacement events, and assist in timing of routine instrument maintenance.
More training data will be needed to increase accuracy across all surgical
instruments that would appear in a neurosurgical operating room. Such
technology has the potential to be used as a method to be used for proving what
tools are truly needed in each type of operation allowing surgeons across the
world to do more with less.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03012" title="Abstract">arXiv:2312.03012</a> (cross-list from cond-mat.dis-nn) [<a href="/pdf/2312.03012" title="Download PDF">pdf</a>, <a href="/format/2312.03012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Waddington landscape for prototype learning in generalized Hopfield  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Boukacem%2C+N+E">Nacer Eddine Boukacem</a>, 
<a href="/search/cond-mat?searchtype=author&query=Leary%2C+A">Allen Leary</a>, 
<a href="/search/cond-mat?searchtype=author&query=Th%C3%A9riault%2C+R">Robin Th&#xe9;riault</a>, 
<a href="/search/cond-mat?searchtype=author&query=Gottlieb%2C+F">Felix Gottlieb</a>, 
<a href="/search/cond-mat?searchtype=author&query=Mani%2C+M">Madhav Mani</a>, 
<a href="/search/cond-mat?searchtype=author&query=Fran%C3%A7ois%2C+P">Paul Fran&#xe7;ois</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Networks in machine learning offer examples of complex high-dimensional
dynamical systems reminiscent of biological systems. Here, we study the
learning dynamics of Generalized Hopfield networks, which permit a
visualization of internal memories. These networks have been shown to proceed
through a 'feature-to-prototype' transition, as the strength of network
nonlinearity is increased, wherein the learned, or terminal, states of internal
memories transition from mixed to pure states. Focusing on the prototype
learning dynamics of the internal memories we observe a strong resemblance to
the canalized, or low-dimensional, dynamics of cells as they differentiate
within a Waddingtonian landscape. Dynamically, we demonstrate that learning in
a Generalized Hopfield Network proceeds through sequential 'splits' in memory
space. Furthermore, order of splitting is interpretable and reproducible. The
dynamics between the splits are canalized in the Waddington sense -- robust to
variations in detailed aspects of the system. In attempting to make the analogy
a rigorous equivalence, we study smaller subsystems that exhibit similar
properties to the full system. We combine analytical calculations with
numerical simulations to study the dynamical emergence of the
feature-to-prototype transition, and the behaviour of splits in the landscape,
saddles points, visited during learning. We exhibit regimes where saddles
appear and disappear through saddle-node bifurcations, qualitatively changing
the distribution of learned memories as the strength of the nonlinearity is
varied -- allowing us to systematically investigate the mechanisms that
underlie the emergence of Waddingtonian dynamics. Memories can thus
differentiate in a predictive and controlled way, revealing new bridges between
experimental biology, dynamical systems theory, and machine learning.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03013" title="Abstract">arXiv:2312.03013</a> (cross-list from eess.IV) [<a href="/pdf/2312.03013" title="Download PDF">pdf</a>, <a href="/format/2312.03013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breast Ultrasound Report Generation using LangChain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Huh%2C+J">Jaeyoung Huh</a>, 
<a href="/search/eess?searchtype=author&query=Park%2C+H+J">Hyun Jeong Park</a>, 
<a href="/search/eess?searchtype=author&query=Ye%2C+J+C">Jong Chul Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Breast ultrasound (BUS) is a critical diagnostic tool in the field of breast
imaging, aiding in the early detection and characterization of breast
abnormalities. Interpreting breast ultrasound images commonly involves creating
comprehensive medical reports, containing vital information to promptly assess
the patient's condition. However, the ultrasound imaging system necessitates
capturing multiple images of various parts to compile a single report,
presenting a time-consuming challenge. To address this problem, we propose the
integration of multiple image analysis tools through a LangChain using Large
Language Models (LLM), into the breast reporting process. Through a combination
of designated tools and text generation through LangChain, our method can
accurately extract relevant features from ultrasound images, interpret them in
a clinical context, and produce comprehensive and standardized reports. This
approach not only reduces the burden on radiologists and healthcare
professionals but also enhances the consistency and quality of reports. The
extensive experiments shows that each tools involved in the proposed method can
offer qualitatively and quantitatively significant results. Furthermore,
clinical evaluation on the generated reports demonstrates that the proposed
method can make report in clinically meaningful way.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03016" title="Abstract">arXiv:2312.03016</a> (cross-list from q-bio.QM) [<a href="/pdf/2312.03016" title="Download PDF">pdf</a>, <a href="/format/2312.03016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Protein Language Model-Powered 3D Ligand Binding Site Prediction from  Protein Sequence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+S">Shuo Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Xie%2C+L">Lei Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the AI for Science (AI4Science) Workshop and the New Frontiers of AI for Drug Discovery and Development (AI4D3) Workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Prediction of ligand binding sites of proteins is a fundamental and important
task for understanding the function of proteins and screening potential drugs.
Most existing methods require experimentally determined protein holo-structures
as input. However, such structures can be unavailable on novel or less-studied
proteins. To tackle this limitation, we propose LaMPSite, which only takes
protein sequences and ligand molecular graphs as input for ligand binding site
predictions. The protein sequences are used to retrieve residue-level
embeddings and contact maps from the pre-trained ESM-2 protein language model.
The ligand molecular graphs are fed into a graph neural network to compute
atom-level embeddings. Then we compute and update the protein-ligand
interaction embedding based on the protein residue-level embeddings and ligand
atom-level embeddings, and the geometric constraints in the inferred protein
contact map and ligand distance map. A final pooling on protein-ligand
interaction embedding would indicate which residues belong to the binding
sites. Without any 3D coordinate information of proteins, our proposed model
achieves competitive performance compared to baseline methods that require 3D
protein structures when predicting binding sites. Given that less than 50% of
proteins have reliable structure information in the current stage, LaMPSite
will provide new opportunities for drug discovery.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03019" title="Abstract">arXiv:2312.03019</a> (cross-list from quant-ph) [<a href="/pdf/2312.03019" title="Download PDF">pdf</a>, <a href="/format/2312.03019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Optimizations of Quantum Circuit Simulation for Solving Max-Cut  Problems with QAOA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Lin%2C+Y">Yu-Cheng Lin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+C">Chuan-Chi Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tu%2C+C">Chia-Heng Tu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hung%2C+S">Shih-Hao Hung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Quantum approximate optimization algorithm (QAOA) is one of the popular
quantum algorithms that are used to solve combinatorial optimization problems
via approximations. QAOA is able to be evaluated on both physical and virtual
quantum computers simulated by classical computers, with virtual ones being
favored for their noise-free feature and availability. Nevertheless, performing
QAOA on virtual quantum computers suffers from a slow simulation speed for
solving combinatorial optimization problems which require large-scale quantum
circuit simulation (QCS). In this paper, we propose techniques to accelerate
QCS for QAOA using mathematical optimizations to compress quantum operations,
incorporating efficient bitwise operations to further lower the computational
complexity, and leveraging different levels of parallelisms from modern
multi-core processors, with a study case to show the effectiveness on solving
max-cut problems.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03020" title="Abstract">arXiv:2312.03020</a> (cross-list from eess.IV) [<a href="/pdf/2312.03020" title="Download PDF">pdf</a>, <a href="/ps/2312.03020" title="Download PostScript">ps</a>, <a href="/format/2312.03020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced Breast Cancer Tumor Classification using MobileNetV2: A  Detailed Exploration on Image Intensity, Error Mitigation, and  Streamlit-driven Real-time Deployment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Surya%2C+A">Aaditya Surya</a>, 
<a href="/search/eess?searchtype=author&query=Shah%2C+A">Aditya Shah</a>, 
<a href="/search/eess?searchtype=author&query=Kabore%2C+J">Jarnell Kabore</a>, 
<a href="/search/eess?searchtype=author&query=Sasikumar%2C+S">Subash Sasikumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">This research introduces a sophisticated transfer learning model based on
Google's MobileNetV2 for breast cancer tumor classification into normal,
benign, and malignant categories, utilizing a dataset of 1576 ultrasound images
(265 normal, 891 benign, 420 malignant). The model achieves an accuracy of
0.82, precision of 0.83, recall of 0.81, ROC-AUC of 0.94, PR-AUC of 0.88, and
MCC of 0.74. It examines image intensity distributions and misclassification
errors, offering improvements for future applications. Addressing dataset
imbalances, the study ensures a generalizable model. This work, using a dataset
from Baheya Hospital, Cairo, Egypt, compiled by Walid Al-Dhabyani et al.,
emphasizes MobileNetV2's potential in medical imaging, aiming to improve
diagnostic precision in oncology. Additionally, the paper explores
Streamlit-based deployment for real-time tumor classification, demonstrating
MobileNetV2's applicability in medical imaging and setting a benchmark for
future research in oncology diagnostics.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03028" title="Abstract">arXiv:2312.03028</a> (cross-list from eess.IV) [<a href="/pdf/2312.03028" title="Download PDF">pdf</a>, <a href="/ps/2312.03028" title="Download PostScript">ps</a>, <a href="/format/2312.03028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Double Integral Enhanced Zeroing Neural Network Optimized with ALSOA  fostered Lung Cancer Classification using CT Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sumitha%2C+V+S+P">V S Priya Sumitha</a>, 
<a href="/search/eess?searchtype=author&query=Keerthika%2C+V">V.Keerthika</a>, 
<a href="/search/eess?searchtype=author&query=Geetha%2C+A">A. Geetha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Lung cancer is one of the deadliest diseases and the leading cause of illness
and death. Since lung cancer cannot predicted at premature stage, it able to
only be discovered more broadly once it has spread to other lung parts. The
risk grows when radiologists and other specialists determine whether lung
cancer is current. Owing to significance of determining type of treatment and
its depth based on severity of the illness, critical to develop smart and
automatic cancer prediction scheme is precise, at which stage of cancer. In
this paper, Double Integral Enhanced Zeroing Neural Network Optimized with
ALSOA fostered Lung Cancer Classification using CT Images (LCC-DIEZNN-ALSO-CTI)
is proposed. Initially, input CT image is amassed from lung cancer dataset. The
input CT image is pre-processing via Unscented Trainable Kalman Filtering
(UTKF) technique. In pre-processing stage unwanted noise are removed from CT
images. Afterwards, grayscale statistic features and Haralick texture features
extracted by Adaptive and Concise Empirical Wavelet Transform (ACEWT). The
proposed model is implemented on MATLAB. The performance of the proposed method
is analyzed through existing techniques. The proposed method attains 18.32%,
27.20%, and 34.32% higher accuracy analyzed with existing method likes Deep
Learning Assisted Predict of Lung Cancer on Computed Tomography Images
Utilizing AHHMM (LCC-AHHMM-CT), Convolutional neural networks based pulmonary
nodule malignancy assessment in pipeline for classifying lung cancer
(LCC-ICNN-CT), Automated Decision Support Scheme for Lung Cancer Identification
with Categorization (LCC-RFCN-MLRPN-CT) methods respectively.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03034" title="Abstract">arXiv:2312.03034</a> (cross-list from eess.AS) [<a href="/pdf/2312.03034" title="Download PDF">pdf</a>, <a href="/format/2312.03034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Speech Dereverberation Using Weighted Prediction Error
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+Z">Ziye Yang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+M">Mengfei Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jie Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Speech dereverberation aims to alleviate the negative impact of late
reverberant reflections. The weighted prediction error (WPE) method is a
well-established technique known for its superior performance in
dereverberation. However, in scenarios where microphone nodes are dispersed,
the centralized approach of the WPE method requires aggregating all
observations for inverse filtering, resulting in a significant computational
burden. This paper introduces a distributed speech dereverberation method that
emphasizes low computational complexity at each node. Specifically, we leverage
the distributed adaptive node-specific signal estimation (DANSE) algorithm
within the multichannel linear prediction (MCLP) process. This approach
empowers each node to perform local operations with reduced complexity while
achieving the global performance through inter-node cooperation. Experimental
results validate the effectiveness of our proposed method, showcasing its
ability to achieve efficient speech dereverberation in dispersed microphone
node scenarios.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03043" title="Abstract">arXiv:2312.03043</a> (cross-list from eess.IV) [<a href="/pdf/2312.03043" title="Download PDF">pdf</a>, <a href="/format/2312.03043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating the Synthetic Realm: Harnessing Diffusion-based Models for  Laparoscopic Text-to-Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Allmendinger%2C+S">Simeon Allmendinger</a>, 
<a href="/search/eess?searchtype=author&query=Hemmer%2C+P">Patrick Hemmer</a>, 
<a href="/search/eess?searchtype=author&query=Queisner%2C+M">Moritz Queisner</a>, 
<a href="/search/eess?searchtype=author&query=Sauer%2C+I">Igor Sauer</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%BCller%2C+L">Leopold M&#xfc;ller</a>, 
<a href="/search/eess?searchtype=author&query=Jakubik%2C+J">Johannes Jakubik</a>, 
<a href="/search/eess?searchtype=author&query=V%C3%B6ssing%2C+M">Michael V&#xf6;ssing</a>, 
<a href="/search/eess?searchtype=author&query=K%C3%BChl%2C+N">Niklas K&#xfc;hl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Tissues and Organs (q-bio.TO)

</div>
<p class="mathjax">Recent advances in synthetic imaging open up opportunities for obtaining
additional data in the field of surgical imaging. This data can provide
reliable supplements supporting surgical applications and decision-making
through computer vision. Particularly the field of image-guided surgery, such
as laparoscopic and robotic-assisted surgery, benefits strongly from synthetic
image datasets and virtual surgical training methods. Our study presents an
intuitive approach for generating synthetic laparoscopic images from short text
prompts using diffusion-based generative models. We demonstrate the usage of
state-of-the-art text-to-image architectures in the context of laparoscopic
imaging with regard to the surgical removal of the gallbladder as an example.
Results on fidelity and diversity demonstrate that diffusion-based models can
acquire knowledge about the style and semantics in the field of image-guided
surgery. A validation study with a human assessment survey underlines the
realistic nature of our synthetic data, as medical personnel detects actual
images in a pool with generated images causing a false-positive rate of 66%. In
addition, the investigation of a state-of-the-art machine learning model to
recognize surgical actions indicates enhanced results when trained with
additional generated images of up to 5.20%. Overall, the achieved image quality
contributes to the usage of computer-generated images in surgical applications
and enhances its path to maturity.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03057" title="Abstract">arXiv:2312.03057</a> (cross-list from quant-ph) [<a href="/pdf/2312.03057" title="Download PDF">pdf</a>, <a href="/format/2312.03057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advantage of Quantum Machine Learning from General Computational  Advantages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Yamasaki%2C+H">Hayata Yamasaki</a>, 
<a href="/search/quant-ph?searchtype=author&query=Isogai%2C+N">Natsuto Isogai</a>, 
<a href="/search/quant-ph?searchtype=author&query=Murao%2C+M">Mio Murao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">An overarching milestone of quantum machine learning (QML) is to demonstrate
the advantage of QML over all possible classical learning methods in
accelerating a common type of learning task as represented by supervised
learning with classical data. However, the provable advantages of QML in
supervised learning have been known so far only for the learning tasks designed
for using the advantage of specific quantum algorithms, i.e., Shor's
algorithms. Here we explicitly construct an unprecedentedly broader family of
supervised learning tasks with classical data to offer the provable advantage
of QML based on general quantum computational advantages, progressing beyond
Shor's algorithms. Our learning task is feasibly achievable by executing a
general class of functions that can be computed efficiently in polynomial time
for a large fraction of inputs by arbitrary quantum algorithms but not by any
classical algorithm. We prove the hardness of achieving this learning task for
any possible polynomial-time classical learning method. We also clarify
protocols for preparing the classical data to demonstrate this learning task in
experiments. These results open routes to exploit a variety of quantum
advantages in computing functions for the experimental demonstration of the
advantage of QML.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03100" title="Abstract">arXiv:2312.03100</a> (cross-list from quant-ph) [<a href="/pdf/2312.03100" title="Download PDF">pdf</a>, <a href="/format/2312.03100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flexible polar encoding for information reconciliation in QKD
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Addy%2C+S">Snehasis Addy</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dutta%2C+S">Sabyasachi Dutta</a>, 
<a href="/search/quant-ph?searchtype=author&query=Panja%2C+S">Somnath Panja</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dey%2C+K">Kunal Dey</a>, 
<a href="/search/quant-ph?searchtype=author&query=Safavi-Naini%2C+R">Reihaneh Safavi-Naini</a>, 
<a href="/search/quant-ph?searchtype=author&query=Oblak%2C+D">Daniel Oblak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 8 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Quantum Key Distribution (QKD) enables two parties to establish a common
secret key that is information-theoretically secure by transmitting random bits
that are encoded as qubits and sent over a quantum channel, followed by
classical information processing steps known as information reconciliation and
key extraction. Transmission of information over a quantum channel introduces
errors that are generally considered to be due to the adversary's tempering
with the quantum channel and needs to be corrected using classical
communication over an (authenticated) public channel. Commonly used
error-correcting codes in the context of QKD include cascade codes, low-density
parity check (LDPC) codes, and more recently polar codes. In this work, we
explore the applicability of designing of a polar code encoder based on a
channel reliability sequence. We show that the reliability sequence can be
derived and used to design an encoder independent of the choice of decoder. We
then implement our design and evaluate its performance against previous
implementations of polar code encoders for QKD as well as other typical
error-correcting codes. A key advantage of our approach is the modular design
which decouples the encoder and decoder design and allows independent
optimization of each. Our work leads to more versatile polar code-based error
reconciliation in QKD systems that would result in deployment in a broader
range of scenarios.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03102" title="Abstract">arXiv:2312.03102</a> (cross-list from eess.IV) [<a href="/pdf/2312.03102" title="Download PDF">pdf</a>, <a href="/ps/2312.03102" title="Download PostScript">ps</a>, <a href="/format/2312.03102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fully Convolutional Slice-to-Volume Reconstruction for Single-Stack MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Young%2C+S+I">Sean I. Young</a>, 
<a href="/search/eess?searchtype=author&query=Balbastre%2C+Y">Ya&#xeb;l Balbastre</a>, 
<a href="/search/eess?searchtype=author&query=Fischl%2C+B">Bruce Fischl</a>, 
<a href="/search/eess?searchtype=author&query=Golland%2C+P">Polina Golland</a>, 
<a href="/search/eess?searchtype=author&query=Iglesias%2C+J+E">Juan Eugenio Iglesias</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">In magnetic resonance imaging (MRI), slice-to-volume reconstruction (SVR)
refers to computational reconstruction of an unknown 3D magnetic resonance
volume from stacks of 2D slices corrupted by motion. While promising, current
SVR methods require multiple slice stacks for accurate 3D reconstruction,
leading to long scans and limiting their use in time-sensitive applications
such as fetal fMRI. Here, we propose a SVR method that overcomes the
shortcomings of previous work and produces state-of-the-art reconstructions in
the presence of extreme inter-slice motion. Inspired by the recent success of
single-view depth estimation methods, we formulate SVR as a single-stack motion
estimation task and train a fully convolutional network to predict a motion
stack for a given slice stack, producing a 3D reconstruction as a byproduct of
the predicted motion. Extensive experiments on the SVR of adult and fetal
brains demonstrate that our fully convolutional method is twice as accurate as
previous SVR methods. Our code is available at github.com/seannz/svr.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03110" title="Abstract">arXiv:2312.03110</a> (cross-list from cond-mat.mes-hall) [<a href="/pdf/2312.03110" title="Download PDF">pdf</a>, <a href="/format/2312.03110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Automated Bias Triangle Feature Extraction Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Kotzagiannidis%2C+M">Madeleine Kotzagiannidis</a>, 
<a href="/search/cond-mat?searchtype=author&query=Schuff%2C+J">Jonas Schuff</a>, 
<a href="/search/cond-mat?searchtype=author&query=Korda%2C+N">Nathan Korda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mesoscale and Nanoscale Physics (cond-mat.mes-hall)</span>; Computer Vision and Pattern Recognition (cs.CV); Quantum Physics (quant-ph)

</div>
<p class="mathjax">Bias triangles represent features in stability diagrams of Quantum Dot (QD)
devices, whose occurrence and property analysis are crucial indicators for spin
physics. Nevertheless, challenges associated with quality and availability of
data as well as the subtlety of physical phenomena of interest have hindered an
automatic and bespoke analysis framework, often still relying (in part) on
human labelling and verification. We introduce a feature extraction framework
for bias triangles, built from unsupervised, segmentation-based computer vision
methods, which facilitates the direct identification and quantification of
physical properties of the former. Thereby, the need for human input or large
training datasets to inform supervised learning approaches is circumvented,
while additionally enabling the automation of pixelwise shape and feature
labeling. In particular, we demonstrate that Pauli Spin Blockade (PSB)
detection can be conducted effectively, efficiently and without any training
data as a direct result of this approach.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03124" title="Abstract">arXiv:2312.03124</a> (cross-list from physics.app-ph) [<a href="/pdf/2312.03124" title="Download PDF">pdf</a>, <a href="/ps/2312.03124" title="Download PostScript">ps</a>, <a href="/format/2312.03124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced Power Point Tracking for High Hysteresis Perovskite Solar  Cells: A Galvanostatic Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Juarez-Perez%2C+E+J">Emilio J. Juarez-Perez</a>, 
<a href="/search/physics?searchtype=author&query=Momblona%2C+C">Cristina Momblona</a>, 
<a href="/search/physics?searchtype=author&query=Casas%2C+R">Roberto Casas</a>, 
<a href="/search/physics?searchtype=author&query=Haro%2C+M">Marta Haro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applied Physics (physics.app-ph)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This article introduces a novel Maximum Power Point Tracking (MPPT) algorithm
and cost-effective hardware for long-term operational stability measurements in
perovskite solar cells (PSCs). Harnessing the untapped potential of solar
energy sources is crucial for achieving a sustainable future, and accurate MPPT
is vital to maximizing power generation. However, existing MPPT algorithms for
classical photovoltaic technology lead to suboptimal performance and decreased
energy efficiency conversion when applied to the most stable perovskite
devices, the so-called triple mesoscopic hole transport material (HTM)-free
metal halide PSCs. To address this challenge, our research focuses on
developing an innovative low-cost hardware solution for research purposes that
enables massive long-term stability measurements, eliminating the need for
expensive and complex stability monitoring systems. Our galvanostatic MPPT
algorithm ensures continuous and precise tracking achieving superior
operational performance for high hysteresis PSCs. The suggested enhancements
bear significant implications for the extensive integration of perovskite solar
cell technologies, particularly those dependent on power optimizer devices.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03129" title="Abstract">arXiv:2312.03129</a> (cross-list from eess.AS) [<a href="/pdf/2312.03129" title="Download PDF">pdf</a>, <a href="/format/2312.03129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Laryngograph Data for Robust Voicing Detection in Speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yixuan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Heming Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+D">DeLiang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Accurately detecting voiced intervals in speech signals is a critical step in
pitch tracking and has numerous applications. While conventional signal
processing methods and deep learning algorithms have been proposed for this
task, their need to fine-tune threshold parameters for different datasets and
limited generalization restrict their utility in real-world applications. To
address these challenges, this study proposes a supervised voicing detection
model that leverages recorded laryngograph data. The model is based on a
densely-connected convolutional recurrent neural network (DC-CRN), and trained
on data with reference voicing decisions extracted from laryngograph data sets.
Pretraining is also investigated to improve the generalization ability of the
model. The proposed model produces robust voicing detection results,
outperforming other strong baseline methods, and generalizes well to unseen
datasets. The source code of the proposed model with pretraining is provided
along with the list of used laryngograph datasets to facilitate further
research in this area.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03133" title="Abstract">arXiv:2312.03133</a> (cross-list from eess.IV) [<a href="/pdf/2312.03133" title="Download PDF">pdf</a>, <a href="/format/2312.03133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Bone Degradation Using Vision Transformer and Synthetic  Cellular Microstructures Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hashemi%2C+M+S">Mohammad Saber Hashemi</a>, 
<a href="/search/eess?searchtype=author&query=Sheidaei%2C+A">Azadeh Sheidaei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Bone degradation, especially for astronauts in microgravity conditions, is
crucial for space exploration missions since the lower applied external forces
accelerate the diminution in bone stiffness and strength substantially.
Although existing computational models help us understand this phenomenon and
possibly restrict its effect in the future, they are time-consuming to simulate
the changes in the bones, not just the bone microstructures, of each individual
in detail. In this study, a robust yet fast computational method to predict and
visualize bone degradation has been developed. Our deep-learning method,
TransVNet, can take in different 3D voxelized images and predict their
evolution throughout months utilizing a hybrid 3D-CNN-VisionTransformer
autoencoder architecture. Because of limited available experimental data and
challenges of obtaining new samples, a digital twin dataset of diverse and
initial bone-like microstructures was generated to train our TransVNet on the
evolution of the 3D images through a previously developed degradation model for
microgravity.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03179" title="Abstract">arXiv:2312.03179</a> (cross-list from hep-ex) [<a href="/pdf/2312.03179" title="Download PDF">pdf</a>, <a href="/format/2312.03179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CaloQVAE : Simulating high-energy particle-calorimeter interactions  using hybrid quantum-classical generative models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ex?searchtype=author&query=Hoque%2C+S">Sehmimul Hoque</a> (1, 2), 
<a href="/search/hep-ex?searchtype=author&query=Jia%2C+H">Hao Jia</a> (3), 
<a href="/search/hep-ex?searchtype=author&query=Abhishek%2C+A">Abhishek Abhishek</a> (4), 
<a href="/search/hep-ex?searchtype=author&query=Fadaie%2C+M">Mojde Fadaie</a> (1), 
<a href="/search/hep-ex?searchtype=author&query=Toledo-Mar%C3%ADn%2C+J+Q">J. Quetzalcoatl Toledo-Mar&#xed;n</a> (4), 
<a href="/search/hep-ex?searchtype=author&query=Vale%2C+T">Tiago Vale</a> (5, 4), 
<a href="/search/hep-ex?searchtype=author&query=Melko%2C+R+G">Roger G. Melko</a> (1, 6), 
<a href="/search/hep-ex?searchtype=author&query=Swiatlowski%2C+M">Maximilian Swiatlowski</a> (4), 
<a href="/search/hep-ex?searchtype=author&query=Fedorko%2C+W+T">Wojciech T. Fedorko</a> (4) ((1) Perimeter Institute for Theoretical Physics, (2) Faculty of Mathematics, University of Waterloo, (3) Department of Physics and Astronomy, University of British Columbia, (4) TRIUMF, (5) Department of Physics, Simon Fraser University, (6) Department of Physics and Astronomy, University of Waterloo)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Experiment (hep-ex)</span>; Machine Learning (cs.LG); Quantum Physics (quant-ph)

</div>
<p class="mathjax">The Large Hadron Collider's high luminosity era presents major computational
challenges in the analysis of collision events. Large amounts of Monte Carlo
(MC) simulation will be required to constrain the statistical uncertainties of
the simulated datasets below these of the experimental data. Modelling of
high-energy particles propagating through the calorimeter section of the
detector is the most computationally intensive MC simulation task. We introduce
a technique combining recent advancements in generative models and quantum
annealing for fast and efficient simulation of high-energy particle-calorimeter
interactions.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03262" title="Abstract">arXiv:2312.03262</a> (cross-list from stat.ML) [<a href="/pdf/2312.03262" title="Download PDF">pdf</a>, <a href="/format/2312.03262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Cost High-Power Membership Inference by Boosting Relativity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zarifzadeh%2C+S">Sajjad Zarifzadeh</a>, 
<a href="/search/stat?searchtype=author&query=Liu%2C+P">Philippe Liu</a>, 
<a href="/search/stat?searchtype=author&query=Shokri%2C+R">Reza Shokri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a robust membership inference attack (RMIA) that amplifies the
distinction between population data and the training data on any target model,
by effectively leveraging both reference models and reference data in our
likelihood ratio test. Our algorithm exhibits superior test power
(true-positive rate) when compared to prior methods, even at extremely low
false-positive error rates (as low as 0). Also, under computation constraints,
where only a limited number of reference models (as few as 1) are available,
our method performs exceptionally well, unlike some prior attacks that approach
random guessing in such scenarios. Our method lays the groundwork for
cost-effective and practical yet powerful and robust privacy risk analysis of
machine learning algorithms.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03307" title="Abstract">arXiv:2312.03307</a> (cross-list from stat.ML) [<a href="/pdf/2312.03307" title="Download PDF">pdf</a>, <a href="/format/2312.03307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balanced Marginal and Joint Distributional Learning via Mixture  Cramer-Wold Distance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=An%2C+S">Seunghwan An</a>, 
<a href="/search/stat?searchtype=author&query=Hong%2C+S">Sungchul Hong</a>, 
<a href="/search/stat?searchtype=author&query=Jeon%2C+J">Jong-June Jeon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the process of training a generative model, it becomes essential to
measure the discrepancy between two high-dimensional probability distributions:
the generative distribution and the ground-truth distribution of the observed
dataset. Recently, there has been growing interest in an approach that involves
slicing high-dimensional distributions, with the Cramer-Wold distance emerging
as a promising method. However, we have identified that the Cramer-Wold
distance primarily focuses on joint distributional learning, whereas
understanding marginal distributional patterns is crucial for effective
synthetic data generation. In this paper, we introduce a novel measure of
dissimilarity, the mixture Cramer-Wold distance. This measure enables us to
capture both marginal and joint distributional information simultaneously, as
it incorporates a mixture measure with point masses on standard basis vectors.
Building upon the mixture Cramer-Wold distance, we propose a new generative
model called CWDAE (Cramer-Wold Distributional AutoEncoder), which shows
remarkable performance in generating synthetic data when applied to real
tabular datasets. Furthermore, our model offers the flexibility to adjust the
level of data privacy with ease.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03311" title="Abstract">arXiv:2312.03311</a> (cross-list from stat.ML) [<a href="/pdf/2312.03311" title="Download PDF">pdf</a>, <a href="/format/2312.03311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Nystrom Approximation for Preconditioning in Kernel Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Abedsoltan%2C+A">Amirhesam Abedsoltan</a>, 
<a href="/search/stat?searchtype=author&query=Belkin%2C+M">Mikhail Belkin</a>, 
<a href="/search/stat?searchtype=author&query=Pandit%2C+P">Parthe Pandit</a>, 
<a href="/search/stat?searchtype=author&query=Rademacher%2C+L">Luis Rademacher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Kernel methods are a popular class of nonlinear predictive models in machine
learning. Scalable algorithms for learning kernel models need to be iterative
in nature, but convergence can be slow due to poor conditioning. Spectral
preconditioning is an important tool to speed-up the convergence of such
iterative algorithms for training kernel models. However computing and storing
a spectral preconditioner can be expensive which can lead to large
computational and storage overheads, precluding the application of kernel
methods to problems with large datasets. A Nystrom approximation of the
spectral preconditioner is often cheaper to compute and store, and has
demonstrated success in practical applications. In this paper we analyze the
trade-offs of using such an approximated preconditioner. Specifically, we show
that a sample of logarithmic size (as a function of the size of the dataset)
enables the Nystrom-based approximated preconditioner to accelerate gradient
descent nearly as well as the exact preconditioner, while also reducing the
computational and storage overheads.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03351" title="Abstract">arXiv:2312.03351</a> (cross-list from stat.ML) [<a href="/pdf/2312.03351" title="Download PDF">pdf</a>, <a href="/ps/2312.03351" title="Download PostScript">ps</a>, <a href="/format/2312.03351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the variants of SVM methods applied to GPR data to classify tack coat  characteristics in French pavements: two experimental case studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Andreoli%2C+G">Gr&#xe9;gory Andreoli</a> (MAST-EMGCU), 
<a href="/search/stat?searchtype=author&query=Ihamouten%2C+A">Amine Ihamouten</a> (MAST-LAMES), 
<a href="/search/stat?searchtype=author&query=Nguyen%2C+M+L">Mai Lan Nguyen</a> (MAST-LAMES), 
<a href="/search/stat?searchtype=author&query=Fargier%2C+Y">Yannick Fargier</a> (GERS-RRO), 
<a href="/search/stat?searchtype=author&query=Fauchard%2C+C">Cyrille Fauchard</a> (ENDSUM), 
<a href="/search/stat?searchtype=author&query=Simonin%2C+J">Jean-Michel Simonin</a> (MAST-LAMES), 
<a href="/search/stat?searchtype=author&query=Buliuk%2C+V">Viktoriia Buliuk</a> (GERS-GeoEND), 
<a href="/search/stat?searchtype=author&query=Souriou%2C+D">David Souriou</a> (FI-NDT), 
<a href="/search/stat?searchtype=author&query=D%C3%A9robert%2C+X">Xavier D&#xe9;robert</a> (GERS-GeoEND)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 12th International Workshop on Advanced Ground Penetrating
  Radar (IWAGPR), LNEC, Jul 2023, Lisbon, Portugal. pp.1-5
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Among the commonly used non-destructive techniques, the Ground Penetrating
Radar (GPR) is one of the most widely adopted today for assessing pavement
conditions in France. However, conventional radar systems and their forward
processing methods have shown their limitations for the physical and
geometrical characterization of very thin layers such as tack coats. However,
the use of Machine Learning methods applied to GPR with an inverse approach
showed that it was numerically possible to identify the tack coat
characteristics despite masking effects due to low timefrequency resolution
noted in the raw B-scans. Thus, we propose in this paper to apply the inverse
approach based on Machine Learning, already validated in previous works on
numerical data, on two experimental cases with different pavement structures.
The first case corresponds to a validation on known pavement structures on the
Gustave Eiffel University (Nantes, France) with its pavement fatigue carousel
and the second case focuses on a new real road in Vend{\'e}e department
(France). In both case studies, the performances of SVM/SVR methods showed the
efficiency of supervised learning methods to classify and estimate the emulsion
proportioning in the tack coats.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03368" title="Abstract">arXiv:2312.03368</a> (cross-list from eess.IV) [<a href="/pdf/2312.03368" title="Download PDF">pdf</a>, <a href="/format/2312.03368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bottom-Up Instance Segmentation of Catheters for Chest X-Rays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Boccardi%2C+F">Francesca Boccardi</a>, 
<a href="/search/eess?searchtype=author&query=Saalbach%2C+A">Axel Saalbach</a>, 
<a href="/search/eess?searchtype=author&query=Schulz%2C+H">Heinrich Schulz</a>, 
<a href="/search/eess?searchtype=author&query=Salti%2C+S">Samuele Salti</a>, 
<a href="/search/eess?searchtype=author&query=Sirazitdinov%2C+I">Ilyas Sirazitdinov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Chest X-ray (CXR) is frequently employed in emergency departments and
intensive care units to verify the proper placement of central lines and tubes
and to rule out related complications. The automation of the X-ray reading
process can be a valuable support tool for non-specialist technicians and
minimize reporting delays due to non-availability of experts. While existing
solutions for automated catheter segmentation and malposition detection show
promising results, the disentanglement of individual catheters remains an open
challenge, especially in complex cases where multiple devices appear
superimposed in the X-ray projection. Moreover, conventional top-down instance
segmentation methods are ineffective on such thin and long devices, that often
extend through the entire image. In this paper, we propose a deep learning
approach based on associative embeddings for catheter instance segmentation,
able to overcome those limitations and effectively handle device intersections.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03399" title="Abstract">arXiv:2312.03399</a> (cross-list from math.CO) [<a href="/pdf/2312.03399" title="Download PDF">pdf</a>, <a href="/format/2312.03399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Connected Dominating Sets in Triangulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bose%2C+P">Prosenjit Bose</a>, 
<a href="/search/math?searchtype=author&query=Dujmovi%C4%87%2C+V">Vida Dujmovi&#x107;</a>, 
<a href="/search/math?searchtype=author&query=Houdrouge%2C+H">Hussein Houdrouge</a>, 
<a href="/search/math?searchtype=author&query=Morin%2C+P">Pat Morin</a>, 
<a href="/search/math?searchtype=author&query=Odak%2C+S">Saeed Odak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages; 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We show that every $n$-vertex triangulation has a connected dominating set of
size at most $10n/21$. Equivalently, every $n$ vertex triangulation has a
spanning tree with at least $11n/21$ leaves. Prior to the current work, the
best known bounds were $n/2$, which follows from work of Albertson, Berman,
Hutchinson, and Thomassen (J. Graph Theory \textbf{14}(2):247--258). One
immediate consequence of this result is an improved bound for the SEFENOMAP
graph drawing problem of Angelini, Evans, Frati, and Gudmundsson (J. Graph
Theory \textbf{82}(1):45--64). As a second application, we show that every
$n$-vertex planar graph has a one-bend non-crossing drawing in which some set
of at least $11n/21$ vertices is drawn on the $x$-axis.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03401" title="Abstract">arXiv:2312.03401</a> (cross-list from eess.IV) [<a href="/pdf/2312.03401" title="Download PDF">pdf</a>, <a href="/format/2312.03401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Postoperative Intraocular Lens Dislocation in Cataract  Surgery via Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ghamsarian%2C+N">Negin Ghamsarian</a>, 
<a href="/search/eess?searchtype=author&query=Putzgruber-Adamitsch%2C+D">Doris Putzgruber-Adamitsch</a>, 
<a href="/search/eess?searchtype=author&query=Sarny%2C+S">Stephanie Sarny</a>, 
<a href="/search/eess?searchtype=author&query=Sznitman%2C+R">Raphael Sznitman</a>, 
<a href="/search/eess?searchtype=author&query=Schoeffmann%2C+K">Klaus Schoeffmann</a>, 
<a href="/search/eess?searchtype=author&query=El-Shabrawi%2C+Y">Yosuf El-Shabrawi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">A critical yet unpredictable complication following cataract surgery is
intraocular lens dislocation. Postoperative stability is imperative, as even a
tiny decentration of multifocal lenses or inadequate alignment of the torus in
toric lenses due to postoperative rotation can lead to a significant drop in
visual acuity. Investigating possible intraoperative indicators that can
predict post-surgical instabilities of intraocular lenses can help prevent this
complication. In this paper, we develop and evaluate the first fully-automatic
framework for the computation of lens unfolding delay, rotation, and
instability during surgery. Adopting a combination of three types of CNNs,
namely recurrent, region-based, and pixel-based, the proposed framework is
employed to assess the possibility of predicting post-operative lens
dislocation during cataract surgery. This is achieved via performing a
large-scale study on the statistical differences between the behavior of
different brands of intraocular lenses and aligning the results with expert
surgeons' hypotheses and observations about the lenses. We exploit a
large-scale dataset of cataract surgery videos featuring four intraocular lens
brands. Experimental results confirm the reliability of the proposed framework
in evaluating the lens' statistics during the surgery. The Pearson correlation
and t-test results reveal significant correlations between lens unfolding delay
and lens rotation and significant differences between the intra-operative
rotations stability of four groups of lenses. These results suggest that the
proposed framework can help surgeons select the lenses based on the patient's
eye conditions and predict post-surgical lens dislocation.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03404" title="Abstract">arXiv:2312.03404</a> (cross-list from cond-mat.soft) [<a href="/pdf/2312.03404" title="Download PDF">pdf</a>, <a href="/format/2312.03404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An AI for Scientific Discovery Route between Amorphous Networks and  Mechanical Behavior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Zhu%2C+C">Changliang Zhu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Fang%2C+C">Chenchao Fang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Jin%2C+Z">Zhipeng Jin</a>, 
<a href="/search/cond-mat?searchtype=author&query=Li%2C+B">Baowen Li</a>, 
<a href="/search/cond-mat?searchtype=author&query=Shen%2C+X">Xiangying Shen</a>, 
<a href="/search/cond-mat?searchtype=author&query=Xu%2C+L">Lei Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Soft Condensed Matter (cond-mat.soft)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">"AI for science" is widely recognized as a future trend in the development of
scientific research. Currently, although machine learning algorithms have
played a crucial role in scientific research with numerous successful cases,
relatively few instances exist where AI assists researchers in uncovering the
underlying physical mechanisms behind a certain phenomenon and subsequently
using that mechanism to improve machine learning algorithms' efficiency. This
article uses the investigation into the relationship between extreme Poisson's
ratio values and the structure of amorphous networks as a case study to
illustrate how machine learning methods can assist in revealing underlying
physical mechanisms. Upon recognizing that the Poisson's ratio relies on the
low-frequency vibrational modes of dynamical matrix, we can then employ a
convolutional neural network, trained on the dynamical matrix instead of
traditional image recognition, to predict the Poisson's ratio of amorphous
networks with a much higher efficiency. Through this example, we aim to
showcase the role that artificial intelligence can play in revealing
fundamental physical mechanisms, which subsequently improves the machine
learning algorithms significantly.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03447" title="Abstract">arXiv:2312.03447</a> (cross-list from physics.soc-ph) [<a href="/pdf/2312.03447" title="Download PDF">pdf</a>, <a href="/format/2312.03447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum-Inspired Neural Network Model of Optical Illusions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Maksymov%2C+I+S">Ivan S. Maksymov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Quantum Physics (quant-ph)

</div>
<p class="mathjax">Ambiguous optical illusions have been a paradigmatic object of fascination,
research and inspiration in arts, psychology and video games. However, accurate
computational models of perception of ambiguous figures have been elusive. In
this paper, we design and train a deep neural network model to simulate the
human's perception of the Necker cube, an ambiguous drawing with several
alternating possible interpretations. Defining the weights of the neural
network connection using a quantum generator of truly random numbers, in
agreement with the emerging concepts of quantum artificial intelligence and
quantum cognition we reveal that the actual perceptual state of the Necker cube
is a qubit-like superposition of the two fundamental perceptual states
predicted by classical theories. Our results will find applications in video
games and virtual reality systems employed for training of astronauts and
operators of unmanned aerial vehicles. They will also be useful for researchers
working in the fields of machine learning and vision, psychology of perception
and quantum-mechanical models of human mind and decision-making.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03450" title="Abstract">arXiv:2312.03450</a> (cross-list from eess.SP) [<a href="/pdf/2312.03450" title="Download PDF">pdf</a>, <a href="/format/2312.03450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Autoencoder for Channel Estimation: Real-World Measurement  Insights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Baur%2C+M">Michael Baur</a>, 
<a href="/search/eess?searchtype=author&query=B%C3%B6ck%2C+B">Benedikt B&#xf6;ck</a>, 
<a href="/search/eess?searchtype=author&query=Turan%2C+N">Nurettin Turan</a>, 
<a href="/search/eess?searchtype=author&query=Utschick%2C+W">Wolfgang Utschick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures, submitted to WSA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">This work utilizes a variational autoencoder for channel estimation and
evaluates it on real-world measurements. The estimator is trained solely on
noisy channel observations and parameterizes an approximation to the mean
squared error-optimal estimator by learning observation-dependent conditional
first and second moments. The proposed estimator significantly outperforms
related state-of-the-art estimators on real-world measurements. We investigate
the effect of pre-training with synthetic data and find that the proposed
estimator exhibits comparable results to the related estimators if trained on
synthetic data and evaluated on the measurement data. Furthermore, pre-training
on synthetic data also helps to reduce the required measurement training
dataset size.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03485" title="Abstract">arXiv:2312.03485</a> (cross-list from stat.ML) [<a href="/pdf/2312.03485" title="Download PDF">pdf</a>, <a href="/format/2312.03485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Precision of Individual Shapley Value Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Olsen%2C+L+H+B">Lars Henry Berge Olsen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the 23rd European Young Statisticians Meeting (EYSM)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Applications (stat.AP); Computation (stat.CO)

</div>
<p class="mathjax">Shapley values are extensively used in explainable artificial intelligence
(XAI) as a framework to explain predictions made by complex machine learning
(ML) models. In this work, we focus on conditional Shapley values for
predictive models fitted to tabular data and explain the prediction
$f(\boldsymbol{x}^{*})$ for a single observation $\boldsymbol{x}^{*}$ at the
time. Numerous Shapley value estimation methods have been proposed and
empirically compared on an average basis in the XAI literature. However, less
focus has been devoted to analyzing the precision of the Shapley value
explanations on an individual basis. We extend our work in Olsen et al. (2023)
by demonstrating and discussing that the explanations are systematically less
precise for observations on the outer region of the training data distribution
for all used estimation methods. This is expected from a statistical point of
view, but to the best of our knowledge, it has not been systematically
addressed in the Shapley value literature. This is crucial knowledge for
Shapley values practitioners, who should be more careful in applying these
observations' corresponding Shapley value explanations.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03490" title="Abstract">arXiv:2312.03490</a> (cross-list from eess.IV) [<a href="/pdf/2312.03490" title="Download PDF">pdf</a>, <a href="/format/2312.03490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PneumoLLM: Harnessing the Power of Large Language Model for  Pneumoconiosis Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Song%2C+M">Meiyue Song</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+Z">Zhihua Yu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jiaxin Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jiarui Wang</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+Y">Yuting Lu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+B">Baicun Li</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xiaoxu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Q">Qinghua Huang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zhijun Li</a>, 
<a href="/search/eess?searchtype=author&query=Kanellakis%2C+N+I">Nikolaos I.Kanellakis</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jiangfeng Liu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jing Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+B">Binglu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+J">Juntao Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to Medical Image Analysis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The conventional pretraining-and-finetuning paradigm, while effective for
common diseases with ample data, faces challenges in diagnosing data-scarce
occupational diseases like pneumoconiosis. Recently, large language models
(LLMs) have exhibits unprecedented ability when conducting multiple tasks in
dialogue, bringing opportunities to diagnosis. A common strategy might involve
using adapter layers for vision-language alignment and diagnosis in a dialogic
manner. Yet, this approach often requires optimization of extensive learnable
parameters in the text branch and the dialogue head, potentially diminishing
the LLMs' efficacy, especially with limited training data. In our work, we
innovate by eliminating the text branch and substituting the dialogue head with
a classification head. This approach presents a more effective method for
harnessing LLMs in diagnosis with fewer learnable parameters. Furthermore, to
balance the retention of detailed image information with progression towards
accurate diagnosis, we introduce the contextual multi-token engine. This engine
is specialized in adaptively generating diagnostic tokens. Additionally, we
propose the information emitter module, which unidirectionally emits
information from image tokens to diagnosis tokens. Comprehensive experiments
validate the superiority of our methods and the effectiveness of proposed
modules. Our codes can be found at
https://github.com/CodeMonsterPHD/PneumoLLM/tree/main.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03516" title="Abstract">arXiv:2312.03516</a> (cross-list from quant-ph) [<a href="/pdf/2312.03516" title="Download PDF">pdf</a>, <a href="/format/2312.03516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clustering by Contour coreset and variational quantum eigensolver
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Yung%2C+C">Canaan Yung</a>, 
<a href="/search/quant-ph?searchtype=author&query=Usman%2C+M">Muhammad Usman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent work has proposed solving the k-means clustering problem on quantum
computers via the Quantum Approximate Optimization Algorithm (QAOA) and coreset
techniques. Although the current method demonstrates the possibility of quantum
k-means clustering, it does not ensure high accuracy and consistency across a
wide range of datasets. The existing coreset techniques are designed for
classical algorithms and there has been no quantum-tailored coreset technique
which is designed to boost the accuracy of quantum algorithms. In this work, we
propose solving the k-means clustering problem with the variational quantum
eigensolver (VQE) and a customised coreset method, the Contour coreset, which
has been formulated with specific focus on quantum algorithms. Extensive
simulations with synthetic and real-life data demonstrated that our VQE+Contour
Coreset approach outperforms existing QAOA+Coreset k-means clustering
approaches with higher accuracy and lower standard deviation. Our work has
shown that quantum tailored coreset techniques has the potential to
significantly boost the performance of quantum algorithms when compared to
using generic off-the-shelf coreset techniques.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03561" title="Abstract">arXiv:2312.03561</a> (cross-list from stat.ME) [<a href="/pdf/2312.03561" title="Download PDF">pdf</a>, <a href="/ps/2312.03561" title="Download PostScript">ps</a>, <a href="/format/2312.03561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blueprinting the Future: Automatic Item Categorization using  Hierarchical Zero-Shot and Few-Shot Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wang%2C+T">Ting Wang</a>, 
<a href="/search/stat?searchtype=author&query=Stelter%2C+K">Keith Stelter</a>, 
<a href="/search/stat?searchtype=author&query=Floyd%2C+J">Jenn Floyd</a>, 
<a href="/search/stat?searchtype=author&query=O%27Neill%2C+T">Thomas O&#x27;Neill</a>, 
<a href="/search/stat?searchtype=author&query=Hendrix%2C+N">Nathaniel Hendrix</a>, 
<a href="/search/stat?searchtype=author&query=Bazemore%2C+A">Andrew Bazemore</a>, 
<a href="/search/stat?searchtype=author&query=Rode%2C+K">Kevin Rode</a>, 
<a href="/search/stat?searchtype=author&query=Newton%2C+W">Warren Newton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">In testing industry, precise item categorization is pivotal to align exam
questions with the designated content domains outlined in the assessment
blueprint. Traditional methods either entail manual classification, which is
laborious and error-prone, or utilize machine learning requiring extensive
training data, often leading to model underfit or overfit issues. This study
unveils a novel approach employing the zero-shot and few-shot Generative
Pretrained Transformer (GPT) classifier for hierarchical item categorization,
minimizing the necessity for training data, and instead, leveraging human-like
language descriptions to define categories. Through a structured python
dictionary, the hierarchical nature of examination blueprints is navigated
seamlessly, allowing for a tiered classification of items across multiple
levels. An initial simulation with artificial data demonstrates the efficacy of
this method, achieving an average accuracy of 92.91% measured by the F1 score.
This method was further applied to real exam items from the 2022 In-Training
Examination (ITE) conducted by the American Board of Family Medicine (ABFM),
reclassifying 200 items according to a newly formulated blueprint swiftly in 15
minutes, a task that traditionally could span several days among editors and
physicians. This innovative approach not only drastically cuts down
classification time but also ensures a consistent, principle-driven
categorization, minimizing human biases and discrepancies. The ability to
refine classifications by adjusting definitions adds to its robustness and
sustainability.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03573" title="Abstract">arXiv:2312.03573</a> (cross-list from math.OC) [<a href="/pdf/2312.03573" title="Download PDF">pdf</a>, <a href="/format/2312.03573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven Wasserstein distributionally robust Nash equilibrium  problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pantazis%2C+G">George Pantazis</a>, 
<a href="/search/math?searchtype=author&query=Franci%2C+B">Barbara Franci</a>, 
<a href="/search/math?searchtype=author&query=Grammatico%2C+S">Sergio Grammatico</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We study stochastic Nash equilibrium problems subject to heterogeneous
uncertainty on the cost functions of the individual agents. In our setting, we
assume no prior knowledge of the underlying probability distribution of the
uncertain variables. Adopting a data-driven distributionally robust approach,
based on the so-called Wasserstein metric, where each agent constructs their
own ambiguity set, we provide, under mild assumptions, finite sample guarantees
on the probability that the data-driven distributionally robust Nash
equilibrium is also robust with respect to the true probability distributions
with high confidence. Furthermore, by recasting the game as a distributionally
robust variational inequality, under appropriate conditions, we establish
almost sure asymptotic convergence of the set of data-driven distributionally
robust equilibria to the solution set of the original game. Finally, we recast
the distributionally robust Nash game as a finite-dimensional Nash equilibrium
problem. We illustrate the proposed distributionally robust reformulation via
numerical experiments of stochastic Nash-Cournot games.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03580" title="Abstract">arXiv:2312.03580</a> (cross-list from stat.ML) [<a href="/pdf/2312.03580" title="Download PDF">pdf</a>, <a href="/ps/2312.03580" title="Download PostScript">ps</a>, <a href="/format/2312.03580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invariance &amp; Causal Representation Learning: Prospects and Limitations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bing%2C+S">Simon Bing</a>, 
<a href="/search/stat?searchtype=author&query=Wahl%2C+J">Jonas Wahl</a>, 
<a href="/search/stat?searchtype=author&query=Ninad%2C+U">Urmi Ninad</a>, 
<a href="/search/stat?searchtype=author&query=Runge%2C+J">Jakob Runge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In causal models, a given mechanism is assumed to be invariant to changes of
other mechanisms. While this principle has been utilized for inference in
settings where the causal variables are observed, theoretical insights when the
variables of interest are latent are largely missing. We assay the connection
between invariance and causal representation learning by establishing
impossibility results which show that invariance alone is insufficient to
identify latent causal variables. Together with practical considerations, we
use these theoretical findings to highlight the need for additional constraints
in order to identify representations by exploiting invariance.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03618" title="Abstract">arXiv:2312.03618</a> (cross-list from math.OC) [<a href="/pdf/2312.03618" title="Download PDF">pdf</a>, <a href="/format/2312.03618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond discounted returns: Robust Markov decision processes with average  and Blackwell optimality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Grand-Clement%2C+J">Julien Grand-Clement</a>, 
<a href="/search/math?searchtype=author&query=Petrik%2C+M">Marek Petrik</a>, 
<a href="/search/math?searchtype=author&query=Vieille%2C+N">Nicolas Vieille</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Robust Markov Decision Processes (RMDPs) are a widely used framework for
sequential decision-making under parameter uncertainty. RMDPs have been
extensively studied when the objective is to maximize the discounted return,
but little is known for average optimality (optimizing the long-run average of
the rewards obtained over time) and Blackwell optimality (remaining discount
optimal for all discount factors sufficiently close to 1). In this paper, we
prove several foundational results for RMDPs beyond the discounted return. We
show that average optimal policies can be chosen stationary and deterministic
for sa-rectangular RMDPs but, perhaps surprisingly, that history-dependent
(Markovian) policies strictly outperform stationary policies for average
optimality in s-rectangular RMDPs. We also study Blackwell optimality for
sa-rectangular RMDPs, where we show that {\em approximate} Blackwell optimal
policies always exist, although Blackwell optimal policies may not exist. We
also provide a sufficient condition for their existence, which encompasses
virtually any examples from the literature. We then discuss the connection
between average and Blackwell optimality, and we describe several algorithms to
compute the optimal average return. Interestingly, our approach leverages the
connections between RMDPs and stochastic games.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03619" title="Abstract">arXiv:2312.03619</a> (cross-list from stat.ML) [<a href="/pdf/2312.03619" title="Download PDF">pdf</a>, <a href="/format/2312.03619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of Active Feature Acquisition Methods for Static Feature  Settings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=von+Kleist%2C+H">Henrik von Kleist</a>, 
<a href="/search/stat?searchtype=author&query=Zamanian%2C+A">Alireza Zamanian</a>, 
<a href="/search/stat?searchtype=author&query=Shpitser%2C+I">Ilya Shpitser</a>, 
<a href="/search/stat?searchtype=author&query=Ahmidi%2C+N">Narges Ahmidi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 7 figures, 5 tables. arXiv admin note: substantial text overlap with <a href="/abs/2312.01530">arXiv:2312.01530</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Active feature acquisition (AFA) agents, crucial in domains like healthcare
where acquiring features is often costly or harmful, determine the optimal set
of features for a subsequent classification task. As deploying an AFA agent
introduces a shift in missingness distribution, it's vital to assess its
expected performance at deployment using retrospective data. In a companion
paper, we introduce a semi-offline reinforcement learning (RL) framework for
active feature acquisition performance evaluation (AFAPE) where features are
assumed to be time-dependent. Here, we study and extend the AFAPE problem to
cover static feature settings, where features are time-invariant, and hence
provide more flexibility to the AFA agents in deciding the order of the
acquisitions. In this static feature setting, we derive and adapt new inverse
probability weighting (IPW), direct method (DM), and double reinforcement
learning (DRL) estimators within the semi-offline RL framework. These
estimators can be applied when the missingness in the retrospective dataset
follows a missing-at-random (MAR) pattern. They also can be applied to
missing-not-at-random (MNAR) patterns in conjunction with appropriate existing
missing data techniques. We illustrate the improved data efficiency offered by
the semi-offline RL estimators in synthetic and real-world data experiments
under synthetic MAR and MNAR missingness.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03620" title="Abstract">arXiv:2312.03620</a> (cross-list from eess.AS) [<a href="/pdf/2312.03620" title="Download PDF">pdf</a>, <a href="/format/2312.03620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Golden Gemini is All You Need: Finding the Sweet Spots for Speaker  Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+T">Tianchi Liu</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+K+A">Kong Aik Lee</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Q">Qiongqiong Wang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Haizhou Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE TASLP in Oct., 2023. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Previous studies demonstrate the impressive performance of residual neural
networks (ResNet) in speaker verification. The ResNet models treat the time and
frequency dimensions equally. They follow the default stride configuration
designed for image recognition, where the horizontal and vertical axes exhibit
similarities. This approach ignores the fact that time and frequency are
asymmetric in speech representation. In this paper, we address this issue and
look for optimal stride configurations specifically tailored for speaker
verification. We represent the stride space on a trellis diagram, and conduct a
systematic study on the impact of temporal and frequency resolutions on the
performance and further identify two optimal points, namely Golden Gemini,
which serves as a guiding principle for designing 2D ResNet-based speaker
verification models. By following the principle, a state-of-the-art ResNet
baseline model gains a significant performance improvement on VoxCeleb, SITW,
and CNCeleb datasets with 7.70%/11.76% average EER/minDCF reductions,
respectively, across different network depths (ResNet18, 34, 50, and 101),
while reducing the number of parameters by 16.5% and FLOPs by 4.1%. We refer to
it as Gemini ResNet. Further investigation reveals the efficacy of the proposed
Golden Gemini operating points across various training conditions and
architectures. Furthermore, we present a new benchmark, namely the Gemini
DF-ResNet, using a cutting-edge model.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03640" title="Abstract">arXiv:2312.03640</a> (cross-list from eess.IV) [<a href="/pdf/2312.03640" title="Download PDF">pdf</a>, <a href="/format/2312.03640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training Neural Networks on RAW and HDR Images for Restoration Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Luo%2C+L">Lei Luo</a>, 
<a href="/search/eess?searchtype=author&query=Chapiro%2C+A">Alexandre Chapiro</a>, 
<a href="/search/eess?searchtype=author&query=Xiang%2C+X">Xiaoyu Xiang</a>, 
<a href="/search/eess?searchtype=author&query=Fan%2C+Y">Yuchen Fan</a>, 
<a href="/search/eess?searchtype=author&query=Ranjan%2C+R">Rakesh Ranjan</a>, 
<a href="/search/eess?searchtype=author&query=Mantiuk%2C+R">Rafal Mantiuk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The vast majority of standard image and video content available online is
represented in display-encoded color spaces, in which pixel values are
conveniently scaled to a limited range (0-1) and the color distribution is
approximately perceptually uniform. In contrast, both camera RAW and high
dynamic range (HDR) images are often represented in linear color spaces, in
which color values are linearly related to colorimetric quantities of light.
While training on commonly available display-encoded images is a
well-established practice, there is no consensus on how neural networks should
be trained for tasks on RAW and HDR images in linear color spaces. In this
work, we test several approaches on three popular image restoration
applications: denoising, deblurring, and single-image super-resolution. We
examine whether HDR/RAW images need to be display-encoded using popular
transfer functions (PQ, PU21, mu-law), or whether it is better to train in
linear color spaces, but use loss functions that correct for perceptual
non-uniformity. Our results indicate that neural networks train significantly
better on HDR and RAW images represented in display-encoded color spaces, which
offer better perceptual uniformity than linear spaces. This small change to the
training strategy can bring a very substantial gain in performance, up to 10-15
dB.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03647" title="Abstract">arXiv:2312.03647</a> (cross-list from eess.IV) [<a href="/pdf/2312.03647" title="Download PDF">pdf</a>, <a href="/format/2312.03647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Editable Stain Transformation Of Histological Images Using Unpaired GANs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sloboda%2C+T">Tibor Sloboda</a>, 
<a href="/search/eess?searchtype=author&query=Hudec%2C+L">Luk&#xe1;&#x161; Hudec</a>, 
<a href="/search/eess?searchtype=author&query=Bene%C5%A1ov%C3%A1%2C+W">Wanda Bene&#x161;ov&#xe1;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures, AIRCAD ICIAP 2023 in Udine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Double staining in histopathology, particularly for metaplastic breast
cancer, typically employs H&amp;E and P63 dyes. However, P63's tissue damage and
high cost necessitate alternative methods. This study introduces xAI-CycleGAN,
an advanced architecture combining Mask CycleGAN with explainability features
and structure-preserving capabilities for transforming H&amp;E stained breast
tissue images into P63-like images. The architecture allows for output editing,
enhancing resemblance to actual images and enabling further model refinement.
We showcase xAI-CycleGAN's efficacy in maintaining structural integrity and
generating high-quality images. Additionally, a histopathologist survey
indicates the generated images' realism is often comparable to actual images,
validating our model's high-quality output.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03668" title="Abstract">arXiv:2312.03668</a> (cross-list from eess.AS) [<a href="/pdf/2312.03668" title="Download PDF">pdf</a>, <a href="/format/2312.03668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Integration of Pre-Trained Speech and Language Models for End-to-End  Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hono%2C+Y">Yukiya Hono</a>, 
<a href="/search/eess?searchtype=author&query=Mitsuda%2C+K">Koh Mitsuda</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+T">Tianyu Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Mitsui%2C+K">Kentaro Mitsui</a>, 
<a href="/search/eess?searchtype=author&query=Wakatsuki%2C+T">Toshiaki Wakatsuki</a>, 
<a href="/search/eess?searchtype=author&query=Sawada%2C+K">Kei Sawada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures, 3 tables, The model is available at <a href="https://huggingface.co/rinna/nue-asr">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Advances in machine learning have made it possible to perform various text
and speech processing tasks, including automatic speech recognition (ASR), in
an end-to-end (E2E) manner. Since typical E2E approaches require large amounts
of training data and resources, leveraging pre-trained foundation models
instead of training from scratch is gaining attention. Although there have been
attempts to use pre-trained speech and language models in ASR, most of them are
limited to using either. This paper explores the potential of integrating a
pre-trained speech representation model with a large language model (LLM) for
E2E ASR. The proposed model enables E2E ASR by generating text tokens in an
autoregressive manner via speech representations as speech prompts, taking
advantage of the vast knowledge provided by the LLM. Furthermore, the proposed
model can incorporate remarkable developments for LLM utilization, such as
inference optimization and parameter-efficient domain adaptation. Experimental
results show that the proposed model achieves performance comparable to modern
E2E ASR models.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03671" title="Abstract">arXiv:2312.03671</a> (cross-list from astro-ph.IM) [<a href="/pdf/2312.03671" title="Download PDF">pdf</a>, <a href="/format/2312.03671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Direct Exoplanet Detection Using Deep Convolutional Image Reconstruction  (ConStruct): A New Algorithm for Post-Processing High-Contrast Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Wolf%2C+T+N">Trevor N. Wolf</a>, 
<a href="/search/astro-ph?searchtype=author&query=Jones%2C+B+A">Brandon A. Jones</a>, 
<a href="/search/astro-ph?searchtype=author&query=Bowler%2C+B+P">Brendan P. Bowler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Earth and Planetary Astrophysics (astro-ph.EP); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">We present a novel machine-learning approach for detecting faint point
sources in high-contrast adaptive optics imaging datasets. The most widely used
algorithms for primary subtraction aim to decouple bright stellar speckle noise
from planetary signatures by subtracting an approximation of the temporally
evolving stellar noise from each frame in an imaging sequence. Our approach
aims to improve the stellar noise approximation and increase the planet
detection sensitivity by leveraging deep learning in a novel direct imaging
post-processing algorithm. We show that a convolutional autoencoder neural
network, trained on an extensive reference library of real imaging sequences,
accurately reconstructs the stellar speckle noise at the location of a
potential planet signal. This tool is used in a post-processing algorithm we
call Direct Exoplanet Detection with Convolutional Image Reconstruction, or
ConStruct. The reliability and sensitivity of ConStruct are assessed using real
Keck/NIRC2 angular differential imaging datasets. Of the 30 unique point
sources we examine, ConStruct yields a higher S/N than traditional PCA-based
processing for 67$\%$ of the cases and improves the relative contrast by up to
a factor of 2.6. This work demonstrates the value and potential of deep
learning to take advantage of a diverse reference library of point spread
function realizations to improve direct imaging post-processing. ConStruct and
its future improvements may be particularly useful as tools for post-processing
high-contrast images from the James Webb Space Telescope and extreme adaptive
optics instruments, both for the current generation and those being designed
for the upcoming 30 meter-class telescopes.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03687" title="Abstract">arXiv:2312.03687</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2312.03687" title="Download PDF">pdf</a>, <a href="/format/2312.03687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MatterGen: a generative model for inorganic materials design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Zeni%2C+C">Claudio Zeni</a>, 
<a href="/search/cond-mat?searchtype=author&query=Pinsler%2C+R">Robert Pinsler</a>, 
<a href="/search/cond-mat?searchtype=author&query=Z%C3%BCgner%2C+D">Daniel Z&#xfc;gner</a>, 
<a href="/search/cond-mat?searchtype=author&query=Fowler%2C+A">Andrew Fowler</a>, 
<a href="/search/cond-mat?searchtype=author&query=Horton%2C+M">Matthew Horton</a>, 
<a href="/search/cond-mat?searchtype=author&query=Fu%2C+X">Xiang Fu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Shysheya%2C+S">Sasha Shysheya</a>, 
<a href="/search/cond-mat?searchtype=author&query=Crabb%C3%A9%2C+J">Jonathan Crabb&#xe9;</a>, 
<a href="/search/cond-mat?searchtype=author&query=Sun%2C+L">Lixin Sun</a>, 
<a href="/search/cond-mat?searchtype=author&query=Smith%2C+J">Jake Smith</a>, 
<a href="/search/cond-mat?searchtype=author&query=Tomioka%2C+R">Ryota Tomioka</a>, 
<a href="/search/cond-mat?searchtype=author&query=Xie%2C+T">Tian Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages main text, 35 pages supplementary information
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The design of functional materials with desired properties is essential in
driving technological advances in areas like energy storage, catalysis, and
carbon capture. Generative models provide a new paradigm for materials design
by directly generating entirely novel materials given desired property
constraints. Despite recent progress, current generative models have low
success rate in proposing stable crystals, or can only satisfy a very limited
set of property constraints. Here, we present MatterGen, a model that generates
stable, diverse inorganic materials across the periodic table and can further
be fine-tuned to steer the generation towards a broad range of property
constraints. To enable this, we introduce a new diffusion-based generative
process that produces crystalline structures by gradually refining atom types,
coordinates, and the periodic lattice. We further introduce adapter modules to
enable fine-tuning towards any given property constraints with a labeled
dataset. Compared to prior generative models, structures produced by MatterGen
are more than twice as likely to be novel and stable, and more than 15 times
closer to the local energy minimum. After fine-tuning, MatterGen successfully
generates stable, novel materials with desired chemistry, symmetry, as well as
mechanical, electronic and magnetic properties. Finally, we demonstrate
multi-property materials design capabilities by proposing structures that have
both high magnetic density and a chemical composition with low supply-chain
risk. We believe that the quality of generated materials and the breadth of
MatterGen's capabilities represent a major advancement towards creating a
universal generative model for materials design.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03688" title="Abstract">arXiv:2312.03688</a> (cross-list from math.CO) [<a href="/pdf/2312.03688" title="Download PDF">pdf</a>, <a href="/ps/2312.03688" title="Download PostScript">ps</a>, <a href="/format/2312.03688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Twin-width of sparse random graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hendrey%2C+K">Kevin Hendrey</a>, 
<a href="/search/math?searchtype=author&query=Norin%2C+S">Sergey Norin</a>, 
<a href="/search/math?searchtype=author&query=Steiner%2C+R">Raphael Steiner</a>, 
<a href="/search/math?searchtype=author&query=Turcotte%2C+J">J&#xe9;r&#xe9;mie Turcotte</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We show that the twin-width of every $n$-vertex $d$-regular graph is at most
$n^{\frac{d-2}{2d-2}+o(1)}$ and that almost all $d$-regular graphs attain this
bound. More generally, we obtain bounds on the twin-width of sparse
Erd\H{o}s-Renyi and regular random graphs, complementing the bounds in the
denser regime due to Ahn, Chakraborti, Hendrey, Kim and Oum.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03690" title="Abstract">arXiv:2312.03690</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2312.03690" title="Download PDF">pdf</a>, <a href="/format/2312.03690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inverse Design of Vitrimeric Polymers by Molecular Dynamics and  Generative Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Zheng%2C+Y">Yiwen Zheng</a>, 
<a href="/search/cond-mat?searchtype=author&query=Thakolkaran%2C+P">Prakash Thakolkaran</a>, 
<a href="/search/cond-mat?searchtype=author&query=Smith%2C+J+A">Jake A. Smith</a>, 
<a href="/search/cond-mat?searchtype=author&query=Lu%2C+Z">Ziheng Lu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zheng%2C+S">Shuxin Zheng</a>, 
<a href="/search/cond-mat?searchtype=author&query=Nguyen%2C+B+H">Bichlien H. Nguyen</a>, 
<a href="/search/cond-mat?searchtype=author&query=Kumar%2C+S">Siddhant Kumar</a>, 
<a href="/search/cond-mat?searchtype=author&query=Vashisth%2C+A">Aniruddh Vashisth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Vitrimer is a new class of sustainable polymers with the ability of
self-healing through rearrangement of dynamic covalent adaptive networks.
However, a limited choice of constituent molecules restricts their property
space, prohibiting full realization of their potential applications. Through a
combination of molecular dynamics (MD) simulations and machine learning (ML),
particularly a novel graph variational autoencoder (VAE) model, we establish a
method for generating novel vitrimers and guide their inverse design based on
desired glass transition temperature (Tg). We build the first vitrimer dataset
of one million and calculate Tg on 8,424 of them by high-throughput MD
simulations calibrated by a Gaussian process model. The proposed VAE employs
dual graph encoders and a latent dimension overlapping scheme which allows for
individual representation of multi-component vitrimers. By constructing a
continuous latent space containing necessary information of vitrimers, we
demonstrate high accuracy and efficiency of our framework in discovering novel
vitrimers with desirable Tg beyond the training regime. The proposed vitrimers
with reasonable synthesizability cover a wide range of Tg and broaden the
potential widespread usage of vitrimeric materials.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Thu,  7 Dec 23</h3>
<dl>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1705.10648" title="Abstract">arXiv:1705.10648</a> (replaced) [<a href="/pdf/1705.10648" title="Download PDF">pdf</a>, <a href="/format/1705.10648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Logarithmic Funnel Heap: An Efficient Priority Queue For Extremely  Large Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Loeffeld%2C+C">Christian Loeffeld</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1901.10902" title="Abstract">arXiv:1901.10902</a> (replaced) [<a href="/pdf/1901.10902" title="Download PDF">pdf</a>, <a href="/format/1901.10902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InfoBot: Transfer and Exploration via the Information Bottleneck
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Goyal%2C+A">Anirudh Goyal</a>, 
<a href="/search/stat?searchtype=author&query=Islam%2C+R">Riashat Islam</a>, 
<a href="/search/stat?searchtype=author&query=Strouse%2C+D">Daniel Strouse</a>, 
<a href="/search/stat?searchtype=author&query=Ahmed%2C+Z">Zafarali Ahmed</a>, 
<a href="/search/stat?searchtype=author&query=Botvinick%2C+M">Matthew Botvinick</a>, 
<a href="/search/stat?searchtype=author&query=Larochelle%2C+H">Hugo Larochelle</a>, 
<a href="/search/stat?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>, 
<a href="/search/stat?searchtype=author&query=Levine%2C+S">Sergey Levine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICLR'19
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1903.00226" title="Abstract">arXiv:1903.00226</a> (replaced) [<a href="/pdf/1903.00226" title="Download PDF">pdf</a>, <a href="/format/1903.00226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Trichotomy for Regular Trail Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martens%2C+W">Wim Martens</a>, 
<a href="/search/cs?searchtype=author&query=Niewerth%2C+M">Matthias Niewerth</a>, 
<a href="/search/cs?searchtype=author&query=Popp%2C+T">Tina Popp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Databases (cs.DB); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2006.03487" title="Abstract">arXiv:2006.03487</a> (replaced) [<a href="/pdf/2006.03487" title="Download PDF">pdf</a>, <a href="/format/2006.03487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dimensionless Anomaly Detection on Multivariate Streams with Variance  Norm and Path Signature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Zhen Shao</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+R+S">Ryan Sze-Yin Chan</a>, 
<a href="/search/cs?searchtype=author&query=Cochrane%2C+T">Thomas Cochrane</a>, 
<a href="/search/cs?searchtype=author&query=Foster%2C+P">Peter Foster</a>, 
<a href="/search/cs?searchtype=author&query=Lyons%2C+T">Terry Lyons</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2006.13660" title="Abstract">arXiv:2006.13660</a> (replaced) [<a href="/pdf/2006.13660" title="Download PDF">pdf</a>, <a href="/format/2006.13660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TeslaMirror: Multistimulus Encounter-Type Haptic Display for Shape and  Texture Rendering in VR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fedoseev%2C+A">Aleksey Fedoseev</a>, 
<a href="/search/cs?searchtype=author&query=Tleugazy%2C+A">Akerke Tleugazy</a>, 
<a href="/search/cs?searchtype=author&query=Labazanova%2C+L">Luiza Labazanova</a>, 
<a href="/search/cs?searchtype=author&query=Tsetserukou%2C+D">Dzmitry Tsetserukou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the ACM SIGGRAPH 2020 conference (Emerging Technologies section), ACM copyright, 2 pages, 3 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2006.16144" title="Abstract">arXiv:2006.16144</a> (replaced) [<a href="/pdf/2006.16144" title="Download PDF">pdf</a>, <a href="/format/2006.16144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimates on the generalization error of Physics Informed Neural  Networks (PINNs) for approximating PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mishra%2C+S">Siddhartha Mishra</a>, 
<a href="/search/math?searchtype=author&query=Molinaro%2C+R">Roberto Molinaro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2007.01138" title="Abstract">arXiv:2007.01138</a> (replaced) [<a href="/pdf/2007.01138" title="Download PDF">pdf</a>, <a href="/format/2007.01138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimates on the generalization error of Physics Informed Neural  Networks (PINNs) for approximating a class of inverse problems for PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mishra%2C+S">Siddhartha Mishra</a>, 
<a href="/search/math?searchtype=author&query=Molinaro%2C+R">Roberto Molinaro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Mathematical Physics (math-ph); Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2009.13291" title="Abstract">arXiv:2009.13291</a> (replaced) [<a href="/pdf/2009.13291" title="Download PDF">pdf</a>, <a href="/format/2009.13291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics Informed Neural Networks for Simulating Radiative Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Siddhartha Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Molinaro%2C+R">Roberto Molinaro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.16669" title="Abstract">arXiv:2103.16669</a> (replaced) [<a href="/pdf/2103.16669" title="Download PDF">pdf</a>, <a href="/format/2103.16669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An In-depth Analysis of Passage-Level Label Transfer for Contextual  Document Ranking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rudra%2C+K">Koustav Rudra</a>, 
<a href="/search/cs?searchtype=author&query=Fernando%2C+Z+T">Zeon Trevor Fernando</a>, 
<a href="/search/cs?searchtype=author&query=Anand%2C+A">Avishek Anand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper is about the performance analysis of contextual ranking strategies in an ad-hoc document retrieval
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.11820" title="Abstract">arXiv:2105.11820</a> (replaced) [<a href="/pdf/2105.11820" title="Download PDF">pdf</a>, <a href="/ps/2105.11820" title="Download PostScript">ps</a>, <a href="/format/2105.11820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-Free Adaptive Control Compensated with Disturbance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+F">Feilong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.12065" title="Abstract">arXiv:2107.12065</a> (replaced) [<a href="/pdf/2107.12065" title="Download PDF">pdf</a>, <a href="/format/2107.12065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably Accelerated Decentralized Gradient Method Over Unbalanced  Directed Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Song%2C+Z">Zhuoqing Song</a>, 
<a href="/search/math?searchtype=author&query=Shi%2C+L">Lei Shi</a>, 
<a href="/search/math?searchtype=author&query=Pu%2C+S">Shi Pu</a>, 
<a href="/search/math?searchtype=author&query=Yan%2C+M">Ming Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIAM Journal on Optimization, in press
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG); Signal Processing (eess.SP); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.07863" title="Abstract">arXiv:2109.07863</a> (replaced) [<a href="/pdf/2109.07863" title="Download PDF">pdf</a>, <a href="/ps/2109.07863" title="Download PostScript">ps</a>, <a href="/format/2109.07863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trillium: Higher-Order Concurrent and Distributed Separation Logic for  Intensional Refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Timany%2C+A">Amin Timany</a>, 
<a href="/search/cs?searchtype=author&query=Gregersen%2C+S+O">Simon Oddershede Gregersen</a>, 
<a href="/search/cs?searchtype=author&query=Stefanesco%2C+L">L&#xe9;o Stefanesco</a>, 
<a href="/search/cs?searchtype=author&query=Hinrichsen%2C+J+K">Jonas Kastberg Hinrichsen</a>, 
<a href="/search/cs?searchtype=author&query=Gondelman%2C+L">L&#xe9;on Gondelman</a>, 
<a href="/search/cs?searchtype=author&query=Nieto%2C+A">Abel Nieto</a>, 
<a href="/search/cs?searchtype=author&query=Birkedal%2C+L">Lars Birkedal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> POPL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.09971" title="Abstract">arXiv:2111.09971</a> (replaced) [<a href="/pdf/2111.09971" title="Download PDF">pdf</a>, <a href="/format/2111.09971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Robust Output Control Barrier Functions from Safe Expert  Demonstrations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lindemann%2C+L">Lars Lindemann</a>, 
<a href="/search/eess?searchtype=author&query=Robey%2C+A">Alexander Robey</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+L">Lejun Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Das%2C+S">Satyajeet Das</a>, 
<a href="/search/eess?searchtype=author&query=Tu%2C+S">Stephen Tu</a>, 
<a href="/search/eess?searchtype=author&query=Matni%2C+N">Nikolai Matni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Journal paper submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.10373" title="Abstract">arXiv:2112.10373</a> (replaced) [<a href="/pdf/2112.10373" title="Download PDF">pdf</a>, <a href="/ps/2112.10373" title="Download PostScript">ps</a>, <a href="/format/2112.10373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advances of Proof Scores in CafeOBJ
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Futatsugi%2C+K">Kokichi Futatsugi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 59 pages, Appendix A is newly added, Subsection 5.4 is significantly revised and extended, some notations are changed to make them consistent with others, and several parts are revised to improve readability
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.10890" title="Abstract">arXiv:2112.10890</a> (replaced) [<a href="/pdf/2112.10890" title="Download PDF">pdf</a>, <a href="/format/2112.10890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Game Representations: The Hidden Costs of Efficiency in  Sequential Decision-making Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kova%C5%99%C3%ADk%2C+V">Vojt&#x11b;ch Kova&#x159;&#xed;k</a>, 
<a href="/search/cs?searchtype=author&query=Milec%2C+D">David Milec</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0ustr%2C+M">Michal &#x160;ustr</a>, 
<a href="/search/cs?searchtype=author&query=Seitz%2C+D">Dominik Seitz</a>, 
<a href="/search/cs?searchtype=author&query=Lis%C3%BD%2C+V">Viliam Lis&#xfd;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.12909" title="Abstract">arXiv:2112.12909</a> (replaced) [<a href="/pdf/2112.12909" title="Download PDF">pdf</a>, <a href="/format/2112.12909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Variable Clustering for High-Dimensional Matrix Valued Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Lee%2C+I">Inbeom Lee</a>, 
<a href="/search/stat?searchtype=author&query=Deng%2C+S">Siyi Deng</a>, 
<a href="/search/stat?searchtype=author&query=Ning%2C+Y">Yang Ning</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.04093" title="Abstract">arXiv:2201.04093</a> (replaced) [<a href="/pdf/2201.04093" title="Download PDF">pdf</a>, <a href="/format/2201.04093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Systematic Literature Review: Quantum Machine Learning and its  applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Garc%C3%ADa%2C+D+P">David Peral Garc&#xed;a</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cruz-Benito%2C+J">Juan Cruz-Benito</a>, 
<a href="/search/quant-ph?searchtype=author&query=Garc%C3%ADa-Pe%C3%B1alvo%2C+F+J">Francisco Jos&#xe9; Garc&#xed;a-Pe&#xf1;alvo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 25 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.07394" title="Abstract">arXiv:2201.07394</a> (replaced) [<a href="/pdf/2201.07394" title="Download PDF">pdf</a>, <a href="/format/2201.07394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KappaFace: Adaptive Additive Angular Margin Loss for Deep Face  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oinar%2C+C">Chingis Oinar</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+B+M">Binh M. Le</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+S+S">Simon S. Woo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.10629" title="Abstract">arXiv:2202.10629</a> (replaced) [<a href="/pdf/2202.10629" title="Download PDF">pdf</a>, <a href="/format/2202.10629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Reprogramming: Resource-Efficient Cross-Domain Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pin-Yu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at AAAI 2024 (Senior Member Presentation Track); Survey paper on model reprogramming; Project repository: <a href="https://github.com/IBM/model-reprogramming">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.01850" title="Abstract">arXiv:2203.01850</a> (replaced) [<a href="/pdf/2203.01850" title="Download PDF">pdf</a>, <a href="/format/2203.01850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> T-Cal: An optimal test for the calibration of predictive models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Lee%2C+D">Donghwan Lee</a>, 
<a href="/search/stat?searchtype=author&query=Huang%2C+X">Xinmeng Huang</a>, 
<a href="/search/stat?searchtype=author&query=Hassani%2C+H">Hamed Hassani</a>, 
<a href="/search/stat?searchtype=author&query=Dobriban%2C+E">Edgar Dobriban</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The implementation of T-Cal is available at <a href="https://github.com/dh7401/T-Cal">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.01278" title="Abstract">arXiv:2204.01278</a> (replaced) [<a href="/pdf/2204.01278" title="Download PDF">pdf</a>, <a href="/format/2204.01278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Technical Report on Subspace Pyramid Fusion Network for Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elhassan%2C+M+A+M">Mohammed A. M. Elhassan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chenhui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chenxi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Munea%2C+T+L">Tewodros Legesse Munea</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.08620" title="Abstract">arXiv:2204.08620</a> (replaced) [<a href="/pdf/2204.08620" title="Download PDF">pdf</a>, <a href="/format/2204.08620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying Spatial Under-reporting Disparities in Resident  Crowdsourcing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Liu%2C+Z">Zhi Liu</a>, 
<a href="/search/stat?searchtype=author&query=Bhandaram%2C+U">Uma Bhandaram</a>, 
<a href="/search/stat?searchtype=author&query=Garg%2C+N">Nikhil Garg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.04425" title="Abstract">arXiv:2206.04425</a> (replaced) [<a href="/pdf/2206.04425" title="Download PDF">pdf</a>, <a href="/format/2206.04425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiple Instance Learning for Digital Pathology: A Review on the  State-of-the-Art, Limitations &amp; Future Potential
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gadermayr%2C+M">Michael Gadermayr</a>, 
<a href="/search/cs?searchtype=author&query=Tschuchnig%2C+M">Maximilian Tschuchnig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.04979" title="Abstract">arXiv:2206.04979</a> (replaced) [<a href="/pdf/2206.04979" title="Download PDF">pdf</a>, <a href="/ps/2206.04979" title="Download PostScript">ps</a>, <a href="/format/2206.04979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convolutional layers are equivariant to discrete shifts but not  continuous translations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McGreivy%2C+N">Nick McGreivy</a>, 
<a href="/search/cs?searchtype=author&query=Hakim%2C+A">Ammar Hakim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.08204" title="Abstract">arXiv:2206.08204</a> (replaced) [<a href="/pdf/2206.08204" title="Download PDF">pdf</a>, <a href="/ps/2206.08204" title="Download PostScript">ps</a>, <a href="/format/2206.08204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inherent Inconsistencies of Feature Importance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harel%2C+N">Nimrod Harel</a>, 
<a href="/search/cs?searchtype=author&query=Obolski%2C+U">Uri Obolski</a>, 
<a href="/search/cs?searchtype=author&query=Gilad-Bachrach%2C+R">Ran Gilad-Bachrach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.08225" title="Abstract">arXiv:2206.08225</a> (replaced) [<a href="/pdf/2206.08225" title="Download PDF">pdf</a>, <a href="/format/2206.08225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> All the World&#x27;s a (Hyper)Graph: A Data Drama
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coupette%2C+C">Corinna Coupette</a>, 
<a href="/search/cs?searchtype=author&query=Vreeken%2C+J">Jilles Vreeken</a>, 
<a href="/search/cs?searchtype=author&query=Rieck%2C+B">Bastian Rieck</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the full version of our paper; an abridged version appears in Digital Scholarship in the Humanities. Landing page for code and data: <a href="https://hyperbard.net/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.10706" title="Abstract">arXiv:2206.10706</a> (replaced) [<a href="/e-print/2206.10706" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TraSE: Towards Tackling Authorial Style from a Cognitive Science  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wilson%2C+R">Ronald Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Bhandarkar%2C+A">Avanti Bhandarkar</a>, 
<a href="/search/cs?searchtype=author&query=Woodard%2C+D">Damon Woodard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Experimental results in the paper are incorrectly reported due to an unforeseen glitch in the software prototype. The paper and its findings are withdrawn
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.02160" title="Abstract">arXiv:2207.02160</a> (replaced) [<a href="/pdf/2207.02160" title="Download PDF">pdf</a>, <a href="/format/2207.02160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Review of Visual-Textual Sentiment Analysis from Social  Media Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Al-Tameemi%2C+I+K+S">Israa Khalaf Salman Al-Tameemi</a>, 
<a href="/search/cs?searchtype=author&query=Feizi-Derakhshi%2C+M">Mohammad-Reza Feizi-Derakhshi</a>, 
<a href="/search/cs?searchtype=author&query=Pashazadeh%2C+S">Saeed Pashazadeh</a>, 
<a href="/search/cs?searchtype=author&query=Asadpour%2C+M">Mohammad Asadpour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.03932" title="Abstract">arXiv:2207.03932</a> (replaced) [<a href="/pdf/2207.03932" title="Download PDF">pdf</a>, <a href="/format/2207.03932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory-free Online Change-point Detection: A Novel Neural Network  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atashgahi%2C+Z">Zahra Atashgahi</a>, 
<a href="/search/cs?searchtype=author&query=Mocanu%2C+D+C">Decebal Constantin Mocanu</a>, 
<a href="/search/cs?searchtype=author&query=Veldhuis%2C+R">Raymond Veldhuis</a>, 
<a href="/search/cs?searchtype=author&query=Pechenizkiy%2C+M">Mykola Pechenizkiy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.08791" title="Abstract">arXiv:2207.08791</a> (replaced) [<a href="/pdf/2207.08791" title="Download PDF">pdf</a>, <a href="/ps/2207.08791" title="Download PostScript">ps</a>, <a href="/format/2207.08791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Close-to-optimal continuity bound for the von Neumann entropy and other  quasi-classical applications of the Alicki-Fannes-Winter technique
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Shirokov%2C+M+E">M.E.Shirokov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, v.4 is the journal version
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Lett Math Phys 113, 121 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT); Mathematical Physics (math-ph)

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.00779" title="Abstract">arXiv:2208.00779</a> (replaced) [<a href="/pdf/2208.00779" title="Download PDF">pdf</a>, <a href="/ps/2208.00779" title="Download PostScript">ps</a>, <a href="/format/2208.00779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DADAO: Decoupled Accelerated Decentralized Asynchronous Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Nabli%2C+A">Adel Nabli</a> (MLIA, ISIR, MILA), 
<a href="/search/math?searchtype=author&query=Oyallon%2C+E">Edouard Oyallon</a> (MLIA, ISIR)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Machine Learning, Jul 2023, Honolulu, United States
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.03934" title="Abstract">arXiv:2208.03934</a> (replaced) [<a href="/pdf/2208.03934" title="Download PDF">pdf</a>, <a href="/format/2208.03934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inflating 2D Convolution Weights for Efficient Generation of 3D Medical  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yanbin Liu</a>, 
<a href="/search/eess?searchtype=author&query=Dwivedi%2C+G">Girish Dwivedi</a>, 
<a href="/search/eess?searchtype=author&query=Boussaid%2C+F">Farid Boussaid</a>, 
<a href="/search/eess?searchtype=author&query=Sanfilippo%2C+F">Frank Sanfilippo</a>, 
<a href="/search/eess?searchtype=author&query=Yamada%2C+M">Makoto Yamada</a>, 
<a href="/search/eess?searchtype=author&query=Bennamoun%2C+M">Mohammed Bennamoun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at Computer Methods and Programs in Biomedicine (CMPB) 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Methods and Programs in Biomedicine (2023): 107685
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.13602" title="Abstract">arXiv:2208.13602</a> (replaced) [<a href="/pdf/2208.13602" title="Download PDF">pdf</a>, <a href="/ps/2208.13602" title="Download PostScript">ps</a>, <a href="/format/2208.13602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mathematical Models to Analyze Lua Hybrid Tables and Why They Need a Fix
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez%2C+C">Conrado Mart&#xed;nez</a>, 
<a href="/search/cs?searchtype=author&query=Nicaud%2C+C">Cyril Nicaud</a>, 
<a href="/search/cs?searchtype=author&query=Rotondo%2C+P">Pablo Rotondo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Long version of <a href="https://doi.org/10.1007/978-3-031-22105-7_34">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.14085" title="Abstract">arXiv:2208.14085</a> (replaced) [<a href="/pdf/2208.14085" title="Download PDF">pdf</a>, <a href="/format/2208.14085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Point Cloud from Moving Camera Videos: A No-Reference Metric
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zicheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yucheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+X">Xiongkuo Min</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Ying Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+G">Guangtao Zhai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.02890" title="Abstract">arXiv:2209.02890</a> (replaced) [<a href="/pdf/2209.02890" title="Download PDF">pdf</a>, <a href="/format/2209.02890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Target Localization Using Adaptive Radar Processing and  Convolutional Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Venkatasubramanian%2C+S">Shyam Venkatasubramanian</a>, 
<a href="/search/cs?searchtype=author&query=Gogineni%2C+S">Sandeep Gogineni</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+B">Bosung Kang</a>, 
<a href="/search/cs?searchtype=author&query=Pezeshki%2C+A">Ali Pezeshki</a>, 
<a href="/search/cs?searchtype=author&query=Rangaswamy%2C+M">Muralidhar Rangaswamy</a>, 
<a href="/search/cs?searchtype=author&query=Tarokh%2C+V">Vahid Tarokh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.12407" title="Abstract">arXiv:2209.12407</a> (replaced) [<a href="/pdf/2209.12407" title="Download PDF">pdf</a>, <a href="/format/2209.12407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entailment Semantics Can Be Extracted from an Ideal Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Merrill%2C+W">William Merrill</a>, 
<a href="/search/cs?searchtype=author&query=Warstadt%2C+A">Alex Warstadt</a>, 
<a href="/search/cs?searchtype=author&query=Linzen%2C+T">Tal Linzen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CONLL 2022. Updated Dec 4, 2023 with erratum
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.12835" title="Abstract">arXiv:2209.12835</a> (replaced) [<a href="/pdf/2209.12835" title="Download PDF">pdf</a>, <a href="/ps/2209.12835" title="Download PostScript">ps</a>, <a href="/format/2209.12835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Targeted Separation and Convergence with Kernel Discrepancies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Barp%2C+A">Alessandro Barp</a>, 
<a href="/search/stat?searchtype=author&query=Simon-Gabriel%2C+C">Carl-Johann Simon-Gabriel</a>, 
<a href="/search/stat?searchtype=author&query=Girolami%2C+M">Mark Girolami</a>, 
<a href="/search/stat?searchtype=author&query=Mackey%2C+L">Lester Mackey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.04384" title="Abstract">arXiv:2210.04384</a> (replaced) [<a href="/pdf/2210.04384" title="Download PDF">pdf</a>, <a href="/format/2210.04384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical Methods and Analysis of Computing Quasiperiodic Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jiang%2C+K">Kai Jiang</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+S">ShiFeng Li</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+P">Pingwen Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.05952" title="Abstract">arXiv:2210.05952</a> (replaced) [<a href="/pdf/2210.05952" title="Download PDF">pdf</a>, <a href="/format/2210.05952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Brain and Heart Volume Generative Models: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yanbin Liu</a>, 
<a href="/search/eess?searchtype=author&query=Dwivedi%2C+G">Girish Dwivedi</a>, 
<a href="/search/eess?searchtype=author&query=Boussaid%2C+F">Farid Boussaid</a>, 
<a href="/search/eess?searchtype=author&query=Bennamoun%2C+M">Mohammed Bennamoun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ACM Computing Surveys (CSUR) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.09155" title="Abstract">arXiv:2210.09155</a> (replaced) [<a href="/pdf/2210.09155" title="Download PDF">pdf</a>, <a href="/ps/2210.09155" title="Download PostScript">ps</a>, <a href="/format/2210.09155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Event Learning and Gentle Random Measurements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Watts%2C+A+B">Adam Bene Watts</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bostanci%2C+J">John Bostanci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 46 pages, no figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.13179" title="Abstract">arXiv:2210.13179</a> (replaced) [<a href="/pdf/2210.13179" title="Download PDF">pdf</a>, <a href="/format/2210.13179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A simple probabilistic neural network for machine understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Xie%2C+R">Rongrong Xie</a>, 
<a href="/search/cond-mat?searchtype=author&query=Marsili%2C+M">Matteo Marsili</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 9 figures. Accepted in JSTAT
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.16380" title="Abstract">arXiv:2210.16380</a> (replaced) [<a href="/pdf/2210.16380" title="Download PDF">pdf</a>, <a href="/format/2210.16380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incorporating Crowdsourced Annotator Distributions into Ensemble  Modeling to Improve Classification Trustworthiness for Ancient Greek Papyri
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=West%2C+G">Graham West</a>, 
<a href="/search/cs?searchtype=author&query=Swindall%2C+M+I">Matthew I. Swindall</a>, 
<a href="/search/cs?searchtype=author&query=Keener%2C+B">Ben Keener</a>, 
<a href="/search/cs?searchtype=author&query=Player%2C+T">Timothy Player</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+A+C">Alex C. Williams</a>, 
<a href="/search/cs?searchtype=author&query=Brusuelas%2C+J+H">James H. Brusuelas</a>, 
<a href="/search/cs?searchtype=author&query=Wallin%2C+J+F">John F. Wallin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.06930" title="Abstract">arXiv:2211.06930</a> (replaced) [<a href="/pdf/2211.06930" title="Download PDF">pdf</a>, <a href="/format/2211.06930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PaintNet: Unstructured Multi-Path Learning from 3D Point Clouds for  Robotic Spray Painting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tiboni%2C+G">Gabriele Tiboni</a>, 
<a href="/search/cs?searchtype=author&query=Camoriano%2C+R">Raffaello Camoriano</a>, 
<a href="/search/cs?searchtype=author&query=Tommasi%2C+T">Tatiana Tommasi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented as conference paper at IEEE/RSJ IROS 2023, Detroit, USA. Project website at <a href="https://gabrieletiboni.github.io/paintnet">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.10855" title="Abstract">arXiv:2211.10855</a> (replaced) [<a href="/pdf/2211.10855" title="Download PDF">pdf</a>, <a href="/format/2211.10855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Optimization with Quantized Gradient Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rikos%2C+A+I">Apostolos I. Rikos</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+W">Wei Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Charalambous%2C+T">Themistoklis Charalambous</a>, 
<a href="/search/eess?searchtype=author&query=Johansson%2C+K+H">Karl H. Johansson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.00564" title="Abstract">arXiv:2212.00564</a> (replaced) [<a href="/pdf/2212.00564" title="Download PDF">pdf</a>, <a href="/format/2212.00564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Single-View Images for Unsupervised 3D Point Cloud Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lintai Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qijian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Junhui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yong Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IEEE Transactions on Multimedia
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.02072" title="Abstract">arXiv:2212.02072</a> (replaced) [<a href="/pdf/2212.02072" title="Download PDF">pdf</a>, <a href="/ps/2212.02072" title="Download PostScript">ps</a>, <a href="/format/2212.02072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Reinforcement Learning for Risk-Sensitive Linear Quadratic  Gaussian Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cui%2C+L">Leilei Cui</a>, 
<a href="/search/eess?searchtype=author&query=Ba%C5%9Far%2C+T">Tamer Ba&#x15f;ar</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+Z">Zhong-Ping Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 Pages, 13 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.03549" title="Abstract">arXiv:2212.03549</a> (replaced) [<a href="/pdf/2212.03549" title="Download PDF">pdf</a>, <a href="/format/2212.03549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Analytical Model for LEO Satellite Constellations Leveraging Cox  Point Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Choi%2C+C">Chang-Sik Choi</a>, 
<a href="/search/eess?searchtype=author&query=Baccelli%2C+F">Fran&#xe7;ois Baccelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.04223" title="Abstract">arXiv:2212.04223</a> (replaced) [<a href="/pdf/2212.04223" title="Download PDF">pdf</a>, <a href="/format/2212.04223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vicious Classifiers: Data Reconstruction Attack at Inference Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malekzadeh%2C+M">Mohammad Malekzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Gunduz%2C+D">Deniz Gunduz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.06959" title="Abstract">arXiv:2212.06959</a> (replaced) [<a href="/pdf/2212.06959" title="Download PDF">pdf</a>, <a href="/ps/2212.06959" title="Download PostScript">ps</a>, <a href="/format/2212.06959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mechanics of geodesics in Information geometry and Black Hole  Thermodynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chanda%2C+S">Sumanto Chanda</a>, 
<a href="/search/cs?searchtype=author&query=Wada%2C+T">Tatsuaki Wada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages. Corrections made. New section and 2 references added. Please comment
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07495" title="Abstract">arXiv:2212.07495</a> (replaced) [<a href="/pdf/2212.07495" title="Download PDF">pdf</a>, <a href="/format/2212.07495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAIF: Sparse Adversarial and Imperceptible Attack Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Imtiaz%2C+T">Tooba Imtiaz</a>, 
<a href="/search/cs?searchtype=author&query=Kohler%2C+M">Morgan Kohler</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+J">Jared Miller</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zifeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sznaier%2C+M">Mario Sznaier</a>, 
<a href="/search/cs?searchtype=author&query=Camps%2C+O">Octavia Camps</a>, 
<a href="/search/cs?searchtype=author&query=Dy%2C+J">Jennifer Dy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07624" title="Abstract">arXiv:2212.07624</a> (replaced) [<a href="/pdf/2212.07624" title="Download PDF">pdf</a>, <a href="/format/2212.07624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuroevolution of Physics-Informed Neural Nets: Benchmark Problems and  Comparative Results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yong%2C+N+S+W">Nicholas Sung Wei Yong</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+J+C">Jian Cheng Wong</a>, 
<a href="/search/cs?searchtype=author&query=Chiu%2C+P">Pao-Hsiung Chiu</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhishek Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Ooi%2C+C">Chinchun Ooi</a>, 
<a href="/search/cs?searchtype=author&query=Ong%2C+Y">Yew-Soon Ong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures, 4 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the Companion Conference on Genetic and
  Evolutionary Computation July 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09710" title="Abstract">arXiv:2212.09710</a> (replaced) [<a href="/pdf/2212.09710" title="Download PDF">pdf</a>, <a href="/format/2212.09710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Learning for Instruction Following from Realtime Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suhr%2C+A">Alane Suhr</a>, 
<a href="/search/cs?searchtype=author&query=Artzi%2C+Y">Yoav Artzi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Spotlight paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.01901" title="Abstract">arXiv:2301.01901</a> (replaced) [<a href="/pdf/2301.01901" title="Download PDF">pdf</a>, <a href="/format/2301.01901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TAC+: Optimizing Error-Bounded Lossy Compression for 3D AMR Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Daoce Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pulido%2C+J">Jesus Pulido</a>, 
<a href="/search/cs?searchtype=author&query=Grosset%2C+P">Pascal Grosset</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Sian Jin</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jiannan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ahrens%2C+J">James Ahrens</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dingwen Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 30 figures, 5 tables, accepted by IEEE TPDS. arXiv admin note: substantial text overlap with <a href="/abs/2204.00711">arXiv:2204.00711</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.04651" title="Abstract">arXiv:2301.04651</a> (replaced) [<a href="/pdf/2301.04651" title="Download PDF">pdf</a>, <a href="/format/2301.04651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 20736-node Weighted Max-Cut Problem Solving by Quadrature Photonic  Spatial Ising Machine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xin Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenjia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shaomeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaoxuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zuyuan He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages,3 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sci. China Inf. Sci. 66, 229301 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Optics (physics.optics)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00845" title="Abstract">arXiv:2302.00845</a> (replaced) [<a href="/pdf/2302.00845" title="Download PDF">pdf</a>, <a href="/format/2302.00845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CD-GraB: Coordinating Distributed Example Orders for Provably  Accelerated Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cooper%2C+A+F">A. Feder Cooper</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wentao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+K">Khiem Pham</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+T">Tiancheng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+C+F">Charlie F. Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yucheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=De+Sa%2C+C">Christopher De Sa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02367" title="Abstract">arXiv:2302.02367</a> (replaced) [<a href="/pdf/2302.02367" title="Download PDF">pdf</a>, <a href="/format/2302.02367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FastPillars: A Deployment-friendly Pillar-based 3D Detector
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Sifan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhi Tian</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+X">Xiangxiang Chu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiaobo Lu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chengjian Feng</a>, 
<a href="/search/cs?searchtype=author&query=Jie%2C+Z">Zequn Jie</a>, 
<a href="/search/cs?searchtype=author&query=Chiang%2C+P+Y">Patrick Yin Chiang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lin Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02560" title="Abstract">arXiv:2302.02560</a> (replaced) [<a href="/pdf/2302.02560" title="Download PDF">pdf</a>, <a href="/format/2302.02560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Estimation of Exposure Shifts with Neural Networks: Evaluating  the Health Benefits of Stricter Air Quality Standards in the US
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tec%2C+M">Mauricio Tec</a>, 
<a href="/search/cs?searchtype=author&query=Mudele%2C+O">Oladimeji Mudele</a>, 
<a href="/search/cs?searchtype=author&query=Josey%2C+K">Kevin Josey</a>, 
<a href="/search/cs?searchtype=author&query=Dominici%2C+F">Francesca Dominici</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07371" title="Abstract">arXiv:2302.07371</a> (replaced) [<a href="/pdf/2302.07371" title="Download PDF">pdf</a>, <a href="/format/2302.07371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BiasTestGPT: Using ChatGPT for Social Bias Testing of Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kocielnik%2C+R">Rafal Kocielnik</a>, 
<a href="/search/cs?searchtype=author&query=Prabhumoye%2C+S">Shrimai Prabhumoye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+V">Vivian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+R">Roy Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Alvarez%2C+R+M">R. Michael Alvarez</a>, 
<a href="/search/cs?searchtype=author&query=Anandkumar%2C+A">Anima Anandkumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00486" title="Abstract">arXiv:2303.00486</a> (replaced) [<a href="/pdf/2303.00486" title="Download PDF">pdf</a>, <a href="/format/2303.00486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Redundancy Management for Fast Service (Rates) in Edge Computing Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+P">Pei Peng</a>, 
<a href="/search/cs?searchtype=author&query=Soljanin%2C+E">Emina Soljanin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is submitted to IEEE/ACM Transactions on Networking
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03297" title="Abstract">arXiv:2303.03297</a> (replaced) [<a href="/pdf/2303.03297" title="Download PDF">pdf</a>, <a href="/format/2303.03297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Immersive Telepresence and Mobile Telemanipulation: NimbRo wins  ANA Avatar XPRIZE Finals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schwarz%2C+M">Max Schwarz</a>, 
<a href="/search/cs?searchtype=author&query=Lenz%2C+C">Christian Lenz</a>, 
<a href="/search/cs?searchtype=author&query=Memmesheimer%2C+R">Raphael Memmesheimer</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A4tzold%2C+B">Bastian P&#xe4;tzold</a>, 
<a href="/search/cs?searchtype=author&query=Rochow%2C+A">Andre Rochow</a>, 
<a href="/search/cs?searchtype=author&query=Schreiber%2C+M">Michael Schreiber</a>, 
<a href="/search/cs?searchtype=author&query=Behnke%2C+S">Sven Behnke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for IEEE-RAS International Conference on Humanoid Robots (HUMANOIDS) 2023. M. Schwarz and C. Lenz contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03906" title="Abstract">arXiv:2303.03906</a> (replaced) [<a href="/pdf/2303.03906" title="Download PDF">pdf</a>, <a href="/ps/2303.03906" title="Download PostScript">ps</a>, <a href="/format/2303.03906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Confluence Criteria
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shintani%2C+K">Kiraku Shintani</a>, 
<a href="/search/cs?searchtype=author&query=Hirokawa%2C+N">Nao Hirokawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 3 figures, 1 table, submitted to LMCS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07320" title="Abstract">arXiv:2303.07320</a> (replaced) [<a href="/pdf/2303.07320" title="Download PDF">pdf</a>, <a href="/format/2303.07320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-tuning Via Prompts Makes NLP Models Adversarially Robust
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raman%2C+M">Mrigank Raman</a>, 
<a href="/search/cs?searchtype=author&query=Maini%2C+P">Pratyush Maini</a>, 
<a href="/search/cs?searchtype=author&query=Kolter%2C+J+Z">J. Zico Kolter</a>, 
<a href="/search/cs?searchtype=author&query=Lipton%2C+Z+C">Zachary C. Lipton</a>, 
<a href="/search/cs?searchtype=author&query=Pruthi%2C+D">Danish Pruthi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the EMNLP 2023 Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09128" title="Abstract">arXiv:2303.09128</a> (replaced) [<a href="/pdf/2303.09128" title="Download PDF">pdf</a>, <a href="/format/2303.09128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Distributional Shifts in Large Language Models for Code  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arakelyan%2C+S">Shushan Arakelyan</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+R+J">Rocktim Jyoti Das</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yi Mao</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiang Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10285" title="Abstract">arXiv:2303.10285</a> (replaced) [<a href="/pdf/2303.10285" title="Download PDF">pdf</a>, <a href="/format/2303.10285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact and optimal quadratization of nonlinear finite-dimensional  non-autonomous dynamical systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bychkov%2C+A">Andrey Bychkov</a>, 
<a href="/search/cs?searchtype=author&query=Issan%2C+O">Opal Issan</a>, 
<a href="/search/cs?searchtype=author&query=Pogudin%2C+G">Gleb Pogudin</a>, 
<a href="/search/cs?searchtype=author&query=Kramer%2C+B">Boris Kramer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Dynamical Systems (math.DS); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05984" title="Abstract">arXiv:2304.05984</a> (replaced) [<a href="/pdf/2304.05984" title="Download PDF">pdf</a>, <a href="/format/2304.05984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Deep Cybersickness Predictor through Kinematic Data with Encoded  Physiological Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruichen Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Handi Yin</a>, 
<a href="/search/cs?searchtype=author&query=Chardonnet%2C+J">Jean-R&#xe9;my Chardonnet</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+P">Pan Hui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in IEEE ISMAR 2023 as conference paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07444" title="Abstract">arXiv:2304.07444</a> (replaced) [<a href="/pdf/2304.07444" title="Download PDF">pdf</a>, <a href="/format/2304.07444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Art of Camouflage: Few-shot Learning for Animal Detection and  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thanh-Danh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+A+N">Anh-Khoa Nguyen Vu</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+N">Nhat-Duy Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V">Vinh-Tiep Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Ngo%2C+T+D">Thanh Duc Ngo</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+T">Thanh-Toan Do</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+M">Minh-Triet Tran</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+V">Tam V. Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under-review Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12507" title="Abstract">arXiv:2304.12507</a> (replaced) [<a href="/pdf/2304.12507" title="Download PDF">pdf</a>, <a href="/format/2304.12507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Task-Specific Strategies for Accelerated MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wu%2C+Z">Zihui Wu</a>, 
<a href="/search/eess?searchtype=author&query=Yin%2C+T">Tianwei Yin</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+Y">Yu Sun</a>, 
<a href="/search/eess?searchtype=author&query=Frost%2C+R">Robert Frost</a>, 
<a href="/search/eess?searchtype=author&query=van+der+Kouwe%2C+A">Andre van der Kouwe</a>, 
<a href="/search/eess?searchtype=author&query=Dalca%2C+A+V">Adrian V. Dalca</a>, 
<a href="/search/eess?searchtype=author&query=Bouman%2C+K+L">Katherine L. Bouman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14176" title="Abstract">arXiv:2304.14176</a> (replaced) [<a href="/pdf/2304.14176" title="Download PDF">pdf</a>, <a href="/format/2304.14176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the flavor structure of quarks and leptons with reinforcement  learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ph?searchtype=author&query=Nishimura%2C+S">Satsuki Nishimura</a>, 
<a href="/search/hep-ph?searchtype=author&query=Miyao%2C+C">Coh Miyao</a>, 
<a href="/search/hep-ph?searchtype=author&query=Otsuka%2C+H">Hajime Otsuka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages, 15 figures, v2: published version
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J. High Energ. Phys. 2023, 21 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Phenomenology (hep-ph)</span>; Machine Learning (cs.LG); High Energy Physics - Theory (hep-th)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14230" title="Abstract">arXiv:2304.14230</a> (replaced) [<a href="/pdf/2304.14230" title="Download PDF">pdf</a>, <a href="/format/2304.14230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Divergence-free cut finite element methods for Stokes flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Frachon%2C+T">Thomas Frachon</a>, 
<a href="/search/math?searchtype=author&query=Nilsson%2C+E">Erik Nilsson</a>, 
<a href="/search/math?searchtype=author&query=Zahedi%2C+S">Sara Zahedi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01090" title="Abstract">arXiv:2305.01090</a> (replaced) [<a href="/pdf/2305.01090" title="Download PDF">pdf</a>, <a href="/ps/2305.01090" title="Download PostScript">ps</a>, <a href="/format/2305.01090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autoencoders for discovering manifold dimension and coordinates in data  from complex dynamical systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+K">Kevin Zeng</a>, 
<a href="/search/cs?searchtype=author&query=De+Jes%C3%BAs%2C+C+E+P">Carlos E. P&#xe9;rez De Jes&#xfa;s</a>, 
<a href="/search/cs?searchtype=author&query=Fox%2C+A+J">Andrew J. Fox</a>, 
<a href="/search/cs?searchtype=author&query=Graham%2C+M+D">Michael D. Graham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Chaotic Dynamics (nlin.CD)

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05403" title="Abstract">arXiv:2305.05403</a> (replaced) [<a href="/pdf/2305.05403" title="Download PDF">pdf</a>, <a href="/format/2305.05403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Completeness, Recall, and Negation in Open-World Knowledge Bases: A  Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Razniewski%2C+S">Simon Razniewski</a>, 
<a href="/search/cs?searchtype=author&query=Arnaout%2C+H">Hiba Arnaout</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Shrestha Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Suchanek%2C+F">Fabian Suchanek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 8 figures, 5 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Under review, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Databases (cs.DB); Digital Libraries (cs.DL)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11042" title="Abstract">arXiv:2305.11042</a> (replaced) [<a href="/pdf/2305.11042" title="Download PDF">pdf</a>, <a href="/ps/2305.11042" title="Download PostScript">ps</a>, <a href="/format/2305.11042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A unified framework for information-theoretic generalization bounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+Y">Yifeng Chu</a>, 
<a href="/search/cs?searchtype=author&query=Raginsky%2C+M">Maxim Raginsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages; final version accepted to Neural Information Processing Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11746" title="Abstract">arXiv:2305.11746</a> (replaced) [<a href="/pdf/2305.11746" title="Download PDF">pdf</a>, <a href="/format/2305.11746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HalOmi: A Manually Annotated Benchmark for Multilingual Hallucination  and Omission Detection in Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dale%2C+D">David Dale</a>, 
<a href="/search/cs?searchtype=author&query=Voita%2C+E">Elena Voita</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+J">Janice Lam</a>, 
<a href="/search/cs?searchtype=author&query=Hansanti%2C+P">Prangthip Hansanti</a>, 
<a href="/search/cs?searchtype=author&query=Ropers%2C+C">Christophe Ropers</a>, 
<a href="/search/cs?searchtype=author&query=Kalbassi%2C+E">Elahe Kalbassi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Cynthia Gao</a>, 
<a href="/search/cs?searchtype=author&query=Barrault%2C+L">Lo&#xef;c Barrault</a>, 
<a href="/search/cs?searchtype=author&query=Costa-juss%C3%A0%2C+M+R">Marta R. Costa-juss&#xe0;</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12524" title="Abstract">arXiv:2305.12524</a> (replaced) [<a href="/pdf/2305.12524" title="Download PDF">pdf</a>, <a href="/format/2305.12524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TheoremQA: A Theorem-driven Question Answering dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenhu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+M">Ming Yin</a>, 
<a href="/search/cs?searchtype=author&query=Ku%2C+M">Max Ku</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+P">Pan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yixin Wan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xueguang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jianyu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+T">Tony Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Main Conference of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13388" title="Abstract">arXiv:2305.13388</a> (replaced) [<a href="/pdf/2305.13388" title="Download PDF">pdf</a>, <a href="/format/2305.13388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The neural dynamics of auditory word recognition and integration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gauthier%2C+J">Jon Gauthier</a>, 
<a href="/search/cs?searchtype=author&query=Levy%2C+R">Roger Levy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13406" title="Abstract">arXiv:2305.13406</a> (replaced) [<a href="/pdf/2305.13406" title="Download PDF">pdf</a>, <a href="/format/2305.13406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DADA: Dialect Adaptation via Dynamic Aggregation of Linguistic Rules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yanchen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Held%2C+W">William Held</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Diyi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13675" title="Abstract">arXiv:2305.13675</a> (replaced) [<a href="/pdf/2305.13675" title="Download PDF">pdf</a>, <a href="/format/2305.13675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polyglot or Not? Measuring Multilingual Encyclopedic Knowledge in  Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schott%2C+T">Tim Schott</a>, 
<a href="/search/cs?searchtype=author&query=Furman%2C+D">Daniel Furman</a>, 
<a href="/search/cs?searchtype=author&query=Bhat%2C+S">Shreshta Bhat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 (Main)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13683" title="Abstract">arXiv:2305.13683</a> (replaced) [<a href="/pdf/2305.13683" title="Download PDF">pdf</a>, <a href="/format/2305.13683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error Detection for Text-to-SQL Semantic Parsing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shijie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Ziru Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Huan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yu Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 (Findings); Updated with new experiment results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13846" title="Abstract">arXiv:2305.13846</a> (replaced) [<a href="/pdf/2305.13846" title="Download PDF">pdf</a>, <a href="/format/2305.13846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Descent &amp; Landing Trajectory and Guidance Algorithms with Divert  Capabilities for Moon Landing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Capolupo%2C+F">Francesco Capolupo</a>, 
<a href="/search/eess?searchtype=author&query=Rinalducci%2C+A">Antonio Rinalducci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be submitted to AIAA for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14164" title="Abstract">arXiv:2305.14164</a> (replaced) [<a href="/pdf/2305.14164" title="Download PDF">pdf</a>, <a href="/format/2305.14164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Convergence of Score-Based Diffusion Models via  Prediction-Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pedrotti%2C+F">Francesco Pedrotti</a>, 
<a href="/search/cs?searchtype=author&query=Maas%2C+J">Jan Maas</a>, 
<a href="/search/cs?searchtype=author&query=Mondelli%2C+M">Marco Mondelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages; included discretization result; typos corrected
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14246" title="Abstract">arXiv:2305.14246</a> (replaced) [<a href="/pdf/2305.14246" title="Download PDF">pdf</a>, <a href="/format/2305.14246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Empathic Similarity in Personal Narratives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jocelyn Shen</a>, 
<a href="/search/cs?searchtype=author&query=Sap%2C+M">Maarten Sap</a>, 
<a href="/search/cs?searchtype=author&query=Colon-Hernandez%2C+P">Pedro Colon-Hernandez</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H+W">Hae Won Park</a>, 
<a href="/search/cs?searchtype=author&query=Breazeal%2C+C">Cynthia Breazeal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14269" title="Abstract">arXiv:2305.14269</a> (replaced) [<a href="/pdf/2305.14269" title="Download PDF">pdf</a>, <a href="/format/2305.14269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Source-Free Domain Adaptation for RGB-D Semantic Segmentation with  Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rizzoli%2C+G">Giulia Rizzoli</a>, 
<a href="/search/cs?searchtype=author&query=Shenaj%2C+D">Donald Shenaj</a>, 
<a href="/search/cs?searchtype=author&query=Zanuttigh%2C+P">Pietro Zanuttigh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024, 2nd Workshop on Pretraining (WACVW)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14387" title="Abstract">arXiv:2305.14387</a> (replaced) [<a href="/pdf/2305.14387" title="Download PDF">pdf</a>, <a href="/format/2305.14387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AlpacaFarm: A Simulation Framework for Methods that Learn from Human  Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dubois%2C+Y">Yann Dubois</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuechen Li</a>, 
<a href="/search/cs?searchtype=author&query=Taori%2C+R">Rohan Taori</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gulrajani%2C+I">Ishaan Gulrajani</a>, 
<a href="/search/cs?searchtype=author&query=Ba%2C+J">Jimmy Ba</a>, 
<a href="/search/cs?searchtype=author&query=Guestrin%2C+C">Carlos Guestrin</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Percy Liang</a>, 
<a href="/search/cs?searchtype=author&query=Hashimoto%2C+T+B">Tatsunori B. Hashimoto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14815" title="Abstract">arXiv:2305.14815</a> (replaced) [<a href="/pdf/2305.14815" title="Download PDF">pdf</a>, <a href="/format/2305.14815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Reading Comprehension using Case-based Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thai%2C+D">Dung Thai</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+D">Dhruv Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhary%2C+M">Mudit Chaudhary</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenlong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+R">Rajarshi Das</a>, 
<a href="/search/cs?searchtype=author&query=Zaheer%2C+M">Manzil Zaheer</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jay-Yoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hajishirzi%2C+H">Hannaneh Hajishirzi</a>, 
<a href="/search/cs?searchtype=author&query=McCallum%2C+A">Andrew McCallum</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15065" title="Abstract">arXiv:2305.15065</a> (replaced) [<a href="/pdf/2305.15065" title="Download PDF">pdf</a>, <a href="/format/2305.15065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs  without Fine-tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Ximing Lu</a>, 
<a href="/search/cs?searchtype=author&query=Brahman%2C+F">Faeze Brahman</a>, 
<a href="/search/cs?searchtype=author&query=West%2C+P">Peter West</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+J">Jaehun Jang</a>, 
<a href="/search/cs?searchtype=author&query=Chandu%2C+K">Khyathi Chandu</a>, 
<a href="/search/cs?searchtype=author&query=Ravichander%2C+A">Abhilasha Ravichander</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+L">Lianhui Qin</a>, 
<a href="/search/cs?searchtype=author&query=Ammanabrolu%2C+P">Prithviraj Ammanabrolu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Liwei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ramnath%2C+S">Sahana Ramnath</a>, 
<a href="/search/cs?searchtype=author&query=Dziri%2C+N">Nouha Dziri</a>, 
<a href="/search/cs?searchtype=author&query=Fisher%2C+J">Jillian Fisher</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B+Y">Bill Yuchen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Hallinan%2C+S">Skyler Hallinan</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Welleck%2C+S">Sean Welleck</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yejin Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15136" title="Abstract">arXiv:2305.15136</a> (replaced) [<a href="/pdf/2305.15136" title="Download PDF">pdf</a>, <a href="/format/2305.15136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReSync: Riemannian Subgradient-based Robust Rotation Synchronization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+H">Huikang Liu</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+X">Xiao Li</a>, 
<a href="/search/math?searchtype=author&query=So%2C+A+M">Anthony Man-Cho So</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15613" title="Abstract">arXiv:2305.15613</a> (replaced) [<a href="/pdf/2305.15613" title="Download PDF">pdf</a>, <a href="/format/2305.15613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Deep O($n$)-Equivariant Hyperspheres
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Melnyk%2C+P">Pavlo Melnyk</a>, 
<a href="/search/cs?searchtype=author&query=Felsberg%2C+M">Michael Felsberg</a>, 
<a href="/search/cs?searchtype=author&query=Wadenb%C3%A4ck%2C+M">M&#xe5;rten Wadenb&#xe4;ck</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+A">Andreas Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+C">Cuong Le</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16498" title="Abstract">arXiv:2305.16498</a> (replaced) [<a href="/pdf/2305.16498" title="Download PDF">pdf</a>, <a href="/format/2305.16498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coherent Soft Imitation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Watson%2C+J">Joe Watson</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S+H">Sandy H. Huang</a>, 
<a href="/search/cs?searchtype=author&query=Heess%2C+N">Nicolas Heess</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 51 pages, 49 figures. DeepMind internship report. Accepted as a spotlight paper at Advances in Neural Information Processing Systems 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17209" title="Abstract">arXiv:2305.17209</a> (replaced) [<a href="/pdf/2305.17209" title="Download PDF">pdf</a>, <a href="/format/2305.17209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Functional Flow Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kerrigan%2C+G">Gavin Kerrigan</a>, 
<a href="/search/cs?searchtype=author&query=Migliorini%2C+G">Giosue Migliorini</a>, 
<a href="/search/cs?searchtype=author&query=Smyth%2C+P">Padhraic Smyth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17390" title="Abstract">arXiv:2305.17390</a> (replaced) [<a href="/pdf/2305.17390" title="Download PDF">pdf</a>, <a href="/format/2305.17390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex  Interactive Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+B+Y">Bill Yuchen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yicheng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Karina Yang</a>, 
<a href="/search/cs?searchtype=author&query=Brahman%2C+F">Faeze Brahman</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shiyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bhagavatula%2C+C">Chandra Bhagavatula</a>, 
<a href="/search/cs?searchtype=author&query=Ammanabrolu%2C+P">Prithviraj Ammanabrolu</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yejin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiang Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023 (spotlight). Project website: <a href="https://swiftsage.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17903" title="Abstract">arXiv:2305.17903</a> (replaced) [<a href="/pdf/2305.17903" title="Download PDF">pdf</a>, <a href="/format/2305.17903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deeply Coupled Cross-Modal Prompt Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuejing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wei Tang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jinghui Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhaojun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+F">Fei Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACL 2023 findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18411" title="Abstract">arXiv:2305.18411</a> (replaced) [<a href="/pdf/2305.18411" title="Download PDF">pdf</a>, <a href="/format/2305.18411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature-Learning Networks Are Consistent Across Widths At Realistic  Scales
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vyas%2C+N">Nikhil Vyas</a>, 
<a href="/search/cs?searchtype=author&query=Atanasov%2C+A">Alexander Atanasov</a>, 
<a href="/search/cs?searchtype=author&query=Bordelon%2C+B">Blake Bordelon</a>, 
<a href="/search/cs?searchtype=author&query=Morwani%2C+D">Depen Morwani</a>, 
<a href="/search/cs?searchtype=author&query=Sainathan%2C+S">Sabarish Sainathan</a>, 
<a href="/search/cs?searchtype=author&query=Pehlevan%2C+C">Cengiz Pehlevan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 19 figures. NeurIPS 2023. Revised based on reviewer feedback
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18731" title="Abstract">arXiv:2305.18731</a> (replaced) [<a href="/pdf/2305.18731" title="Download PDF">pdf</a>, <a href="/format/2305.18731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Epistemic Graph: A Plug-And-Play Module For Hybrid Representation  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yangzhou Du</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhongchao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+X">Xin Geng</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jianping Fan</a>, 
<a href="/search/cs?searchtype=author&query=Rui%2C+Y">Yong Rui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.20046" title="Abstract">arXiv:2305.20046</a> (replaced) [<a href="/pdf/2305.20046" title="Download PDF">pdf</a>, <a href="/ps/2305.20046" title="Download PostScript">ps</a>, <a href="/format/2305.20046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing Language Disorders using Artificial Intelligence: a Paradigm  Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Themistocleous%2C+C">Charalambos Themistocleous</a>, 
<a href="/search/cs?searchtype=author&query=Tsapkini%2C+K">Kyrana Tsapkini</a>, 
<a href="/search/cs?searchtype=author&query=Kokkinakis%2C+D">Dimitrios Kokkinakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 2 figures, to be submited
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01531" title="Abstract">arXiv:2306.01531</a> (replaced) [<a href="/pdf/2306.01531" title="Download PDF">pdf</a>, <a href="/format/2306.01531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PanoGRF: Generalizable Spherical Radiance Fields for Wide-baseline  Panoramas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yan-Pei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuan-Chen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Song-Hai Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to NeurIPS2023; Project Page: <a href="https://thucz.github.io/PanoGRF/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01546" title="Abstract">arXiv:2306.01546</a> (replaced) [<a href="/pdf/2306.01546" title="Download PDF">pdf</a>, <a href="/format/2306.01546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Publicly available datasets of breast histopathology H&amp;E whole-slide  images: A scoping review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tafavvoghi%2C+M">Masoud Tafavvoghi</a> (1), 
<a href="/search/eess?searchtype=author&query=Bongo%2C+L+A">Lars Ailo Bongo</a> (2), 
<a href="/search/eess?searchtype=author&query=Shvetsov%2C+N">Nikita Shvetsov</a> (2), 
<a href="/search/eess?searchtype=author&query=Busund%2C+L+R">Lill-Tove Rasmussen Busund</a> (3), 
<a href="/search/eess?searchtype=author&query=M%C3%B8llersen%2C+K">Kajsa M&#xf8;llersen</a> (1) ((1) Department of Community Medicine, UiT The Arctic University of Norway, Troms&#xf8;, Norway, (2) Department of Computer Science, UiT The Arctic University of Norway, Troms&#xf8;, Norway, (3) Department of Medical Biology, UiT The Arctic University of Norway, Troms&#xf8;, Norway)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages (including references), 8 figures, 3 tables, 5 supporting information materials
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01923" title="Abstract">arXiv:2306.01923</a> (replaced) [<a href="/pdf/2306.01923" title="Download PDF">pdf</a>, <a href="/format/2306.01923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Surprising Effectiveness of Diffusion Models for Optical Flow and  Monocular Depth Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saxena%2C+S">Saurabh Saxena</a>, 
<a href="/search/cs?searchtype=author&query=Herrmann%2C+C">Charles Herrmann</a>, 
<a href="/search/cs?searchtype=author&query=Hur%2C+J">Junhwa Hur</a>, 
<a href="/search/cs?searchtype=author&query=Kar%2C+A">Abhishek Kar</a>, 
<a href="/search/cs?searchtype=author&query=Norouzi%2C+M">Mohammad Norouzi</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Deqing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Fleet%2C+D+J">David J. Fleet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02000" title="Abstract">arXiv:2306.02000</a> (replaced) [<a href="/pdf/2306.02000" title="Download PDF">pdf</a>, <a href="/format/2306.02000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-PIPs: Persistent Independent Particles Demands Spatial Context  Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bian%2C+W">Weikang Bian</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhaoyang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xiaoyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yitong Dong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yijin Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongsheng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://wkbian.github.io/Projects/Context-PIPs/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05156" title="Abstract">arXiv:2306.05156</a> (replaced) [<a href="/pdf/2306.05156" title="Download PDF">pdf</a>, <a href="/ps/2306.05156" title="Download PostScript">ps</a>, <a href="/format/2306.05156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DFT-Based Channel Estimation for Holographic MIMO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%27Amico%2C+A+A">Antonio Alberto D&#x27;Amico</a>, 
<a href="/search/cs?searchtype=author&query=Bacci%2C+G">Giacomo Bacci</a>, 
<a href="/search/cs?searchtype=author&query=Sanguinetti%2C+L">Luca Sanguinetti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages,4 figures, Asilomar Conference on Signals, Systems, and Computers, Pacific Grove, USA, Nov. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06397" title="Abstract">arXiv:2306.06397</a> (replaced) [<a href="/pdf/2306.06397" title="Download PDF">pdf</a>, <a href="/format/2306.06397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lower-depth programmable linear optical processors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Tang%2C+R">Rui Tang</a>, 
<a href="/search/physics?searchtype=author&query=Tanomura%2C+R">Ryota Tanomura</a>, 
<a href="/search/physics?searchtype=author&query=Tanemura%2C+T">Takuo Tanemura</a>, 
<a href="/search/physics?searchtype=author&query=Nakano%2C+Y">Yoshiaki Nakano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07096" title="Abstract">arXiv:2306.07096</a> (replaced) [<a href="/pdf/2306.07096" title="Download PDF">pdf</a>, <a href="/format/2306.07096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Global and Local Semantic Completion Learning for Vision-Language  Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tu%2C+R">Rong-Cheng Tu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Y">Yatai Ji</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jie Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+W">Weijie Kong</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+C">Chengfei Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenzhe Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongfa Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujiu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2211.13437">arXiv:2211.13437</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08266" title="Abstract">arXiv:2306.08266</a> (replaced) [<a href="/pdf/2306.08266" title="Download PDF">pdf</a>, <a href="/format/2306.08266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Robustness of Angluin&#x27;s L$^*$ Algorithm in Presence of Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+L">Lina Ye</a>, 
<a href="/search/cs?searchtype=author&query=Khmelnitsky%2C+I">Igor Khmelnitsky</a>, 
<a href="/search/cs?searchtype=author&query=Haddad%2C+S">Serge Haddad</a>, 
<a href="/search/cs?searchtype=author&query=Barbot%2C+B">Beno&#xee;t Barbot</a>, 
<a href="/search/cs?searchtype=author&query=Bollig%2C+B">Benedikt Bollig</a>, 
<a href="/search/cs?searchtype=author&query=Leucker%2C+M">Martin Leucker</a>, 
<a href="/search/cs?searchtype=author&query=Neider%2C+D">Daniel Neider</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+R">Rajarshi Roy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08274" title="Abstract">arXiv:2306.08274</a> (replaced) [<a href="/pdf/2306.08274" title="Download PDF">pdf</a>, <a href="/format/2306.08274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple and Scalable Graph Neural Network for Large Directed Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maekawa%2C+S">Seiji Maekawa</a>, 
<a href="/search/cs?searchtype=author&query=Sasaki%2C+Y">Yuya Sasaki</a>, 
<a href="/search/cs?searchtype=author&query=Onizuka%2C+M">Makoto Onizuka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08289" title="Abstract">arXiv:2306.08289</a> (replaced) [<a href="/pdf/2306.08289" title="Download PDF">pdf</a>, <a href="/format/2306.08289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $\textbf{A}^2\textbf{CiD}^2$: Accelerating Asynchronous Communication in  Decentralized Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nabli%2C+A">Adel Nabli</a> (MLIA, Mila), 
<a href="/search/cs?searchtype=author&query=Belilovsky%2C+E">Eugene Belilovsky</a> (Mila), 
<a href="/search/cs?searchtype=author&query=Oyallon%2C+E">Edouard Oyallon</a> (MLIA)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Thirty-seventh Conference on Neural Information Processing
  Systems, Dec 2023, New Orleans, United States
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09597" title="Abstract">arXiv:2306.09597</a> (replaced) [<a href="/pdf/2306.09597" title="Download PDF">pdf</a>, <a href="/format/2306.09597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clickbait Detection via Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Han Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Ye Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yun Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yunhao Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Qiang%2C+J">Jipeng Qiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10740" title="Abstract">arXiv:2306.10740</a> (replaced) [<a href="/pdf/2306.10740" title="Download PDF">pdf</a>, <a href="/format/2306.10740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A semi-implicit finite volume scheme for dissipative measure-valued  solutions to the barotropic Euler system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Arun%2C+K+R">K.R. Arun</a>, 
<a href="/search/math?searchtype=author&query=Krishnamurthy%2C+A">Amogh Krishnamurthy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10912" title="Abstract">arXiv:2306.10912</a> (replaced) [<a href="/pdf/2306.10912" title="Download PDF">pdf</a>, <a href="/format/2306.10912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jamming Detection in Low-BER Mobile Indoor Scenarios via Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sciancalepore%2C+S">Savio Sciancalepore</a>, 
<a href="/search/cs?searchtype=author&query=Kusters%2C+F">Fabrice Kusters</a>, 
<a href="/search/cs?searchtype=author&query=Abdelhadi%2C+N+K">Nada Khaled Abdelhadi</a>, 
<a href="/search/cs?searchtype=author&query=Oligeri%2C+G">Gabriele Oligeri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 16 figures, 3 tables; Submitted and under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11475" title="Abstract">arXiv:2306.11475</a> (replaced) [<a href="/pdf/2306.11475" title="Download PDF">pdf</a>, <a href="/format/2306.11475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Delegated Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saig%2C+E">Eden Saig</a>, 
<a href="/search/cs?searchtype=author&query=Talgam-Cohen%2C+I">Inbal Talgam-Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Rosenfeld%2C+N">Nir Rosenfeld</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11722" title="Abstract">arXiv:2306.11722</a> (replaced) [<a href="/pdf/2306.11722" title="Download PDF">pdf</a>, <a href="/format/2306.11722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Grading and Feedback Tools for Programming Education: A  Systematic Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Messer%2C+M">Marcus Messer</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+N+C+C">Neil C. C. Brown</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6lling%2C+M">Michael K&#xf6;lling</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+M">Miaojing Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted version of the manuscript
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13255" title="Abstract">arXiv:2306.13255</a> (replaced) [<a href="/pdf/2306.13255" title="Download PDF">pdf</a>, <a href="/format/2306.13255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Precise Asymptotic Generalization for Multiclass Classification with  Overparameterized Linear Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+D+X">David X. Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sahai%2C+A">Anant Sahai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023, 56 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13394" title="Abstract">arXiv:2306.13394</a> (replaced) [<a href="/pdf/2306.13394" title="Download PDF">pdf</a>, <a href="/format/2306.13394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Chaoyou Fu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peixian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yunhang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yulei Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengdan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jinrui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiawu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Ke Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yunsheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+R">Rongrong Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13824" title="Abstract">arXiv:2306.13824</a> (replaced) [<a href="/pdf/2306.13824" title="Download PDF">pdf</a>, <a href="/format/2306.13824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Privacy Composition for Accuracy-first Mechanisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rogers%2C+R">Ryan Rogers</a>, 
<a href="/search/cs?searchtype=author&query=Samorodnitsky%2C+G">Gennady Samorodnitsky</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z+S">Zhiwei Steven Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ramdas%2C+A">Aaditya Ramdas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14468" title="Abstract">arXiv:2306.14468</a> (replaced) [<a href="/pdf/2306.14468" title="Download PDF">pdf</a>, <a href="/format/2306.14468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A General Framework for Sequential Decision-Making under Adaptivity  Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+N">Nuoya Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaoran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhuoran Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16111" title="Abstract">arXiv:2306.16111</a> (replaced) [<a href="/pdf/2306.16111" title="Download PDF">pdf</a>, <a href="/format/2306.16111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time Regularization in Optimal Time Variable Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herberg%2C+E">Evelyn Herberg</a>, 
<a href="/search/cs?searchtype=author&query=Herzog%2C+R">Roland Herzog</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6hne%2C+F">Frederik K&#xf6;hne</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00952" title="Abstract">arXiv:2307.00952</a> (replaced) [<a href="/pdf/2307.00952" title="Download PDF">pdf</a>, <a href="/ps/2307.00952" title="Download PostScript">ps</a>, <a href="/format/2307.00952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Explainable AI for Channel Estimation in Wireless Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gizzini%2C+A+K">Abdul Karim Gizzini</a>, 
<a href="/search/cs?searchtype=author&query=Medjahdi%2C+Y">Yahia Medjahdi</a>, 
<a href="/search/cs?searchtype=author&query=Ghandour%2C+A+J">Ali J. Ghandour</a>, 
<a href="/search/cs?searchtype=author&query=Clavier%2C+L">Laurent Clavier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for publication in the IEEE Transactions on Vehicular Technology (TVT) as a correspondence paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01776" title="Abstract">arXiv:2307.01776</a> (replaced) [<a href="/pdf/2307.01776" title="Download PDF">pdf</a>, <a href="/ps/2307.01776" title="Download PostScript">ps</a>, <a href="/format/2307.01776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Threshold Testing and Semi-Online Prophet Inequalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoefer%2C+M">Martin Hoefer</a>, 
<a href="/search/cs?searchtype=author&query=Schewior%2C+K">Kevin Schewior</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02697" title="Abstract">arXiv:2307.02697</a> (replaced) [<a href="/pdf/2307.02697" title="Download PDF">pdf</a>, <a href="/format/2307.02697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strahler Number of Natural Language Sentences in Comparison with Random  Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tanaka-Ishii%2C+K">Kumiko Tanaka-Ishii</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+A">Akira Tanaka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 12 figures, 11 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Statistical Mechanics, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03761" title="Abstract">arXiv:2307.03761</a> (replaced) [<a href="/pdf/2307.03761" title="Download PDF">pdf</a>, <a href="/format/2307.03761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DyEdgeGAT: Dynamic Edge via Graph Attention for Early Fault Detection in  IIoT Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Mengjie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Fink%2C+O">Olga Fink</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04749" title="Abstract">arXiv:2307.04749</a> (replaced) [<a href="/pdf/2307.04749" title="Download PDF">pdf</a>, <a href="/format/2307.04749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Divide, Evaluate, and Refine: Evaluating and Improving Text-to-Image  Alignment with Iterative VQA Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+J">Jaskirat Singh</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Liang Zheng</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Published at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06472" title="Abstract">arXiv:2307.06472</a> (replaced) [<a href="/pdf/2307.06472" title="Download PDF">pdf</a>, <a href="/format/2307.06472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Early Autism Diagnosis based on Path Signature and Siamese Unsupervised  Feature Compressor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhuowen Yin</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+X">Xinyao Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhengwang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Li Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07261" title="Abstract">arXiv:2307.07261</a> (replaced) [<a href="/pdf/2307.07261" title="Download PDF">pdf</a>, <a href="/format/2307.07261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical evaluation of oscillatory integrals via automated steepest  descent contour deformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gibbs%2C+A">A. Gibbs</a>, 
<a href="/search/math?searchtype=author&query=Hewett%2C+D+P">D. P. Hewett</a>, 
<a href="/search/math?searchtype=author&query=Huybrechs%2C+D">D. Huybrechs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09477" title="Abstract">arXiv:2307.09477</a> (replaced) [<a href="/pdf/2307.09477" title="Download PDF">pdf</a>, <a href="/format/2307.09477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Ordinal Data Science
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stumme%2C+G">Gerd Stumme</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%BCrrschnabel%2C+D">Dominik D&#xfc;rrschnabel</a>, 
<a href="/search/cs?searchtype=author&query=Hanika%2C+T">Tom Hanika</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 7 figures, Transactions on Graph Data and Knowledge (TGDK)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Discrete Mathematics (cs.DM); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10518" title="Abstract">arXiv:2307.10518</a> (replaced) [<a href="/pdf/2307.10518" title="Download PDF">pdf</a>, <a href="/format/2307.10518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Segmentation for Diverse Gesture Types Without Context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Myers-Dean%2C+J">Josh Myers-Dean</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yifei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Price%2C+B">Brian Price</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+W">Wilson Chan</a>, 
<a href="/search/cs?searchtype=author&query=Gurari%2C+D">Danna Gurari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13912" title="Abstract">arXiv:2307.13912</a> (replaced) [<a href="/pdf/2307.13912" title="Download PDF">pdf</a>, <a href="/format/2307.13912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embedding Democratic Values into Social Media AIs via Societal Objective  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+C">Chenyan Jia</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+M+S">Michelle S. Lam</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+M+C">Minh Chau Mai</a>, 
<a href="/search/cs?searchtype=author&query=Hancock%2C+J">Jeff Hancock</a>, 
<a href="/search/cs?searchtype=author&query=Bernstein%2C+M+S">Michael S. Bernstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted to CSCW 2024 and will be published in PACM HCI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16273" title="Abstract">arXiv:2307.16273</a> (replaced) [<a href="/pdf/2307.16273" title="Download PDF">pdf</a>, <a href="/format/2307.16273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> zkDL: Efficient Zero-Knowledge Proofs of Deep Learning Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haochen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+T">Tonghe Bai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jason Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongyang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00979" title="Abstract">arXiv:2308.00979</a> (replaced) [<a href="/pdf/2308.00979" title="Download PDF">pdf</a>, <a href="/format/2308.00979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fully Dynamic Maximum Independent Sets of Disks in Polylogarithmic  Update Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhore%2C+S">Sujoy Bhore</a>, 
<a href="/search/cs?searchtype=author&query=N%C3%B6llenburg%2C+M">Martin N&#xf6;llenburg</a>, 
<a href="/search/cs?searchtype=author&query=T%C3%B3th%2C+C+D">Csaba D. T&#xf3;th</a>, 
<a href="/search/cs?searchtype=author&query=Wulms%2C+J">Jules Wulms</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Abstract is shortened to meet Arxiv's requirement on the number of characters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01311" title="Abstract">arXiv:2308.01311</a> (replaced) [<a href="/pdf/2308.01311" title="Download PDF">pdf</a>, <a href="/format/2308.01311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TEASMA: A Practical Approach for the Test Assessment of Deep Neural  Networks using Mutation Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abbasishahkoo%2C+A">Amin Abbasishahkoo</a>, 
<a href="/search/cs?searchtype=author&query=Dadkhah%2C+M">Mahboubeh Dadkhah</a>, 
<a href="/search/cs?searchtype=author&query=Briand%2C+L">Lionel Briand</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dayi Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04336" title="Abstract">arXiv:2308.04336</a> (replaced) [<a href="/pdf/2308.04336" title="Download PDF">pdf</a>, <a href="/ps/2308.04336" title="Download PostScript">ps</a>, <a href="/format/2308.04336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the concentration of the maximum degree in the duplication-divergence  models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frieze%2C+A">Alan Frieze</a>, 
<a href="/search/cs?searchtype=author&query=Turowski%2C+K">Krzysztof Turowski</a>, 
<a href="/search/cs?searchtype=author&query=Szpankowski%2C+W">Wojciech Szpankowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04673" title="Abstract">arXiv:2308.04673</a> (replaced) [<a href="/pdf/2308.04673" title="Download PDF">pdf</a>, <a href="/format/2308.04673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SSL-Auth: An Authentication Framework by Fragile Watermarking for  Pre-trained Encoders in Self-supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaobei Li</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+C">Changchun Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Liyue Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaogang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+L">Liming Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Run Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chenhao Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05998" title="Abstract">arXiv:2308.05998</a> (replaced) [<a href="/pdf/2308.05998" title="Download PDF">pdf</a>, <a href="/format/2308.05998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simplified and Improved Bounds on the VC-Dimension for Elastic Distance  Measures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Br%C3%BCning%2C+F">Frederik Br&#xfc;ning</a>, 
<a href="/search/cs?searchtype=author&query=Driemel%2C+A">Anne Driemel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06444" title="Abstract">arXiv:2308.06444</a> (replaced) [<a href="/pdf/2308.06444" title="Download PDF">pdf</a>, <a href="/format/2308.06444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TongueSAM: An Universal Tongue Segmentation Model Based on SAM with  Zero-Shot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Shan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+Q">Qunsheng Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Linjian Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08333" title="Abstract">arXiv:2308.08333</a> (replaced) [<a href="/pdf/2308.08333" title="Download PDF">pdf</a>, <a href="/format/2308.08333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Depth Gradient Continuity in Transformers: A Comparative Study  on Monocular Depth Estimation with CNN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiawei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaofeng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12462" title="Abstract">arXiv:2308.12462</a> (replaced) [<a href="/pdf/2308.12462" title="Download PDF">pdf</a>, <a href="/format/2308.12462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overcoming Generic Knowledge Loss with Selective Parameter Update
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Janson%2C+P">Paul Janson</a>, 
<a href="/search/cs?searchtype=author&query=Aljundi%2C+R">Rahaf Aljundi</a>, 
<a href="/search/cs?searchtype=author&query=Elhoseiny%2C+M">Mohamed Elhoseiny</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13490" title="Abstract">arXiv:2308.13490</a> (replaced) [<a href="/pdf/2308.13490" title="Download PDF">pdf</a>, <a href="/format/2308.13490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TpuGraphs: A Performance Prediction Dataset on Large Tensor  Computational Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phothilimthana%2C+P+M">Phitchaya Mangpo Phothilimthana</a>, 
<a href="/search/cs?searchtype=author&query=Abu-El-Haija%2C+S">Sami Abu-El-Haija</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+K">Kaidi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Fatemi%2C+B">Bahare Fatemi</a>, 
<a href="/search/cs?searchtype=author&query=Burrows%2C+M">Mike Burrows</a>, 
<a href="/search/cs?searchtype=author&query=Mendis%2C+C">Charith Mendis</a>, 
<a href="/search/cs?searchtype=author&query=Perozzi%2C+B">Bryan Perozzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16761" title="Abstract">arXiv:2308.16761</a> (replaced) [<a href="/pdf/2308.16761" title="Download PDF">pdf</a>, <a href="/format/2308.16761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Category Trees for ID-Based Recommendation: Exploring the Power  of Differentiable Vector Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qijiong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jiaren Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lu Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jieming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiao-Ming Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02959" title="Abstract">arXiv:2309.02959</a> (replaced) [<a href="/pdf/2309.02959" title="Download PDF">pdf</a>, <a href="/format/2309.02959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Non-Invasive Interpretable NAFLD Diagnostic Method Combining TCM  Tongue Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cao%2C+S">Shan Cao</a>, 
<a href="/search/eess?searchtype=author&query=Ruan%2C+Q">Qunsheng Ruan</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Q">Qingfeng Wu</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+W">Weiqiang Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07992" title="Abstract">arXiv:2309.07992</a> (replaced) [<a href="/pdf/2309.07992" title="Download PDF">pdf</a>, <a href="/format/2309.07992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Automated Machine Learning Approach for Detecting Anomalous Peak  Patterns in Time Series Data from a Research Watershed in the Northeastern  United States Critical Zone
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haq%2C+I+U">Ijaz Ul Haq</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B+S">Byung Suk Lee</a>, 
<a href="/search/cs?searchtype=author&query=Rizzo%2C+D+M">Donna M. Rizzo</a>, 
<a href="/search/cs?searchtype=author&query=Perdrial%2C+J+N">Julia N Perdrial</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This document is the results of the research project funded by the National Science Foundation. Preprint submitted to Machine Learning with Applications, December 5 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08769" title="Abstract">arXiv:2309.08769</a> (replaced) [<a href="/pdf/2309.08769" title="Download PDF">pdf</a>, <a href="/format/2309.08769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Use of Multi-Scale Fiducial Markers To Aid Takeoff and Landing  Navigation by Rotorcraft
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jongwon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S+Y">Su Yeon Choi</a>, 
<a href="/search/cs?searchtype=author&query=Bretl%2C+T">Timothy Bretl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended abstract accepted at the 2024 AIAA SciTech
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10954" title="Abstract">arXiv:2309.10954</a> (replaced) [<a href="/pdf/2309.10954" title="Download PDF">pdf</a>, <a href="/format/2309.10954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Context Learning for Text Classification with Many Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Milios%2C+A">Aristides Milios</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+S">Siva Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Bahdanau%2C+D">Dzmitry Bahdanau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12766" title="Abstract">arXiv:2309.12766</a> (replaced) [<a href="/pdf/2309.12766" title="Download PDF">pdf</a>, <a href="/format/2309.12766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study on Incorporating Whisper for Robust Speech Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zezario%2C+R+E">Ryandhimas E. Zezario</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yu-Wen Chen</a>, 
<a href="/search/eess?searchtype=author&query=Fu%2C+S">Szu-Wei Fu</a>, 
<a href="/search/eess?searchtype=author&query=Tsao%2C+Y">Yu Tsao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Hsin-Min Wang</a>, 
<a href="/search/eess?searchtype=author&query=Fuh%2C+C">Chiou-Shann Fuh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14209" title="Abstract">arXiv:2309.14209</a> (replaced) [<a href="/pdf/2309.14209" title="Download PDF">pdf</a>, <a href="/format/2309.14209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Driving Policy Optimization with Closed-Loop Individualized  Curricula
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+H">Haoyi Niu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yizhou Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xingjian Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jianming Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00500" title="Abstract">arXiv:2310.00500</a> (replaced) [<a href="/pdf/2310.00500" title="Download PDF">pdf</a>, <a href="/format/2310.00500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Open-Ended Classification with Small Visual Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Derakhshani%2C+M+M">Mohammad Mahdi Derakhshani</a>, 
<a href="/search/cs?searchtype=author&query=Najdenkoska%2C+I">Ivona Najdenkoska</a>, 
<a href="/search/cs?searchtype=author&query=Snoek%2C+C+G+M">Cees G. M. Snoek</a>, 
<a href="/search/cs?searchtype=author&query=Worring%2C+M">Marcel Worring</a>, 
<a href="/search/cs?searchtype=author&query=Asano%2C+Y+M">Yuki M. Asano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00752" title="Abstract">arXiv:2310.00752</a> (replaced) [<a href="/pdf/2310.00752" title="Download PDF">pdf</a>, <a href="/format/2310.00752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TIGERScore: Towards Building Explainable Metric for All Text Generation  Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Dongfu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yishan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Ge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenhao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B+Y">Bill Yuchen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenhu Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03059" title="Abstract">arXiv:2310.03059</a> (replaced) [<a href="/pdf/2310.03059" title="Download PDF">pdf</a>, <a href="/format/2310.03059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point-PEFT: Parameter-Efficient Fine-Tuning for 3D Pre-trained Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+I">Ivan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ray Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zoey Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xianzheng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhigang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuelong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages. The specialized PEFT framework for 3D pre-trained models, which achieves competitive performance to full fine-tuning, and significantly reduces the computational resources. Project page: <a href="https://github.com/Even-JK/PEFT-3D">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03696" title="Abstract">arXiv:2310.03696</a> (replaced) [<a href="/pdf/2310.03696" title="Download PDF">pdf</a>, <a href="/ps/2310.03696" title="Download PostScript">ps</a>, <a href="/format/2310.03696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Function-Space Optimality of Neural Architectures With Multivariate  Nonlinearities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Parhi%2C+R">Rahul Parhi</a>, 
<a href="/search/stat?searchtype=author&query=Unser%2C+M">Michael Unser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05736" title="Abstract">arXiv:2310.05736</a> (replaced) [<a href="/pdf/2310.05736" title="Download PDF">pdf</a>, <a href="/format/2310.05736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMLingua: Compressing Prompts for Accelerated Inference of Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Huiqiang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qianhui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chin-Yew Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuqing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Lili Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06874" title="Abstract">arXiv:2310.06874</a> (replaced) [<a href="/pdf/2310.06874" title="Download PDF">pdf</a>, <a href="/ps/2310.06874" title="Download PostScript">ps</a>, <a href="/format/2310.06874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extended Reality via Cooperative NOMA in Hybrid Cloud/Mobile-Edge  Computing Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reifert%2C+R">Robert-Jeron Reifert</a>, 
<a href="/search/cs?searchtype=author&query=Dahrouj%2C+H">Hayssam Dahrouj</a>, 
<a href="/search/cs?searchtype=author&query=Sezgin%2C+A">Aydin Sezgin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 15 figures, 3 tables. This paper is accepted for publication at the IEEE Internet of Things Journal
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Internet of Things Journal, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08577" title="Abstract">arXiv:2310.08577</a> (replaced) [<a href="/pdf/2310.08577" title="Download PDF">pdf</a>, <a href="/format/2310.08577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Data-Type Understanding does not emerge from Scaling  Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Udandarao%2C+V">Vishaal Udandarao</a>, 
<a href="/search/cs?searchtype=author&query=Burg%2C+M+F">Max F. Burg</a>, 
<a href="/search/cs?searchtype=author&query=Albanie%2C+S">Samuel Albanie</a>, 
<a href="/search/cs?searchtype=author&query=Bethge%2C+M">Matthias Bethge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11230" title="Abstract">arXiv:2310.11230</a> (replaced) [<a href="/pdf/2310.11230" title="Download PDF">pdf</a>, <a href="/format/2310.11230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zipformer: A faster and better encoder for automatic speech recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yao%2C+Z">Zengwei Yao</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+L">Liyong Guo</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+X">Xiaoyu Yang</a>, 
<a href="/search/eess?searchtype=author&query=Kang%2C+W">Wei Kang</a>, 
<a href="/search/eess?searchtype=author&query=Kuang%2C+F">Fangjun Kuang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Y">Yifan Yang</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+Z">Zengrui Jin</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+L">Long Lin</a>, 
<a href="/search/eess?searchtype=author&query=Povey%2C+D">Daniel Povey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11891" title="Abstract">arXiv:2310.11891</a> (replaced) [<a href="/pdf/2310.11891" title="Download PDF">pdf</a>, <a href="/format/2310.11891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hyperparameter Study for Quantum Kernel Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Egginger%2C+S">Sebastian Egginger</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sakhnenko%2C+A">Alona Sakhnenko</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lorenz%2C+J+M">Jeanette Miriam Lorenz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated experimental results, adapted text
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13368" title="Abstract">arXiv:2310.13368</a> (replaced) [<a href="/pdf/2310.13368" title="Download PDF">pdf</a>, <a href="/format/2310.13368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AP Connection Method for Maximizing Throughput Considering User Moving  and Degree of Interference Based on Potential Game
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kato%2C+Y">Yu Kato</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jiquan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Murase%2C+T">Tutomu Murase</a>, 
<a href="/search/cs?searchtype=author&query=Miyata%2C+S">Sumiko Miyata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 15 figures, It is being submitted to IEEE Open Journal of the Communications Society
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13831" title="Abstract">arXiv:2310.13831</a> (replaced) [<a href="/pdf/2310.13831" title="Download PDF">pdf</a>, <a href="/format/2310.13831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformers for Trajectory Optimization with Application to Spacecraft  Rendezvous
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guffanti%2C+T">Tommaso Guffanti</a>, 
<a href="/search/cs?searchtype=author&query=Gammelli%2C+D">Daniele Gammelli</a>, 
<a href="/search/cs?searchtype=author&query=D%27Amico%2C+S">Simone D&#x27;Amico</a>, 
<a href="/search/cs?searchtype=author&query=Pavone%2C+M">Marco Pavone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to 2024 IEEE Aerospace Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15890" title="Abstract">arXiv:2310.15890</a> (replaced) [<a href="/pdf/2310.15890" title="Download PDF">pdf</a>, <a href="/format/2310.15890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-feature Contrastive Loss for Decentralized Deep Learning on  Heterogeneous Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aketi%2C+S+A">Sai Aparna Aketi</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+K">Kaushik Roy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures, 11 tables. arXiv admin note: text overlap with <a href="/abs/2305.04792">arXiv:2305.04792</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE/CVF Winter Conference on Applications of Computer Vision
  (WACV), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19303" title="Abstract">arXiv:2310.19303</a> (replaced) [<a href="/pdf/2310.19303" title="Download PDF">pdf</a>, <a href="/format/2310.19303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extracting user needs with Chat-GPT for dialogue recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sato%2C+Y">Yugen Sato</a>, 
<a href="/search/cs?searchtype=author&query=Nakajima%2C+T">Taisei Nakajima</a>, 
<a href="/search/cs?searchtype=author&query=Kawamoto%2C+T">Tatsuki Kawamoto</a>, 
<a href="/search/cs?searchtype=author&query=Takagi%2C+T">Tomohiro Takagi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19378" title="Abstract">arXiv:2310.19378</a> (replaced) [<a href="/pdf/2310.19378" title="Download PDF">pdf</a>, <a href="/format/2310.19378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-shot Hybrid Domain Adaptation of Image Generators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hengjia Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Linxuan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuqi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenxiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+X">Xiaohui Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiaobo Ren</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaofei He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19786" title="Abstract">arXiv:2310.19786</a> (replaced) [<a href="/pdf/2310.19786" title="Download PDF">pdf</a>, <a href="/ps/2310.19786" title="Download PostScript">ps</a>, <a href="/format/2310.19786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From External to Swap Regret 2.0: An Efficient Reduction and Oblivious  Adversary for Large Action Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dagan%2C+Y">Yuval Dagan</a>, 
<a href="/search/cs?searchtype=author&query=Daskalakis%2C+C">Constantinos Daskalakis</a>, 
<a href="/search/cs?searchtype=author&query=Fishelson%2C+M">Maxwell Fishelson</a>, 
<a href="/search/cs?searchtype=author&query=Golowich%2C+N">Noah Golowich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00694" title="Abstract">arXiv:2311.00694</a> (replaced) [<a href="/pdf/2311.00694" title="Download PDF">pdf</a>, <a href="/format/2311.00694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unleashing the Creative Mind: Language Model As Hierarchical Policy For  Improved Exploration on Challenging Problem Solving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ling%2C+Z">Zhan Ling</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yunhao Fang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuanlin Li</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+T">Tongzhou Mu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Mingu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Pourreza%2C+R">Reza Pourreza</a>, 
<a href="/search/cs?searchtype=author&query=Memisevic%2C+R">Roland Memisevic</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hao Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00775" title="Abstract">arXiv:2311.00775</a> (replaced) [<a href="/pdf/2311.00775" title="Download PDF">pdf</a>, <a href="/format/2311.00775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing machine learning for accurate treatment of overlapping  opacity species in general circulation models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Schneider%2C+A+D">Aaron David Schneider</a>, 
<a href="/search/astro-ph?searchtype=author&query=Molli%C3%A8re%2C+P">Paul Molli&#xe8;re</a>, 
<a href="/search/astro-ph?searchtype=author&query=Louppe%2C+G">Gilles Louppe</a>, 
<a href="/search/astro-ph?searchtype=author&query=Carone%2C+L">Ludmila Carone</a>, 
<a href="/search/astro-ph?searchtype=author&query=J%C3%B8rgensen%2C+U+G">Uffe Gr&#xe5;e J&#xf8;rgensen</a>, 
<a href="/search/astro-ph?searchtype=author&query=Decin%2C+L">Leen Decin</a>, 
<a href="/search/astro-ph?searchtype=author&query=Helling%2C+C">Christiane Helling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in A&amp;A, language edited version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Earth and Planetary Astrophysics (astro-ph.EP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01026" title="Abstract">arXiv:2311.01026</a> (replaced) [<a href="/pdf/2311.01026" title="Download PDF">pdf</a>, <a href="/ps/2311.01026" title="Download PostScript">ps</a>, <a href="/format/2311.01026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Constant Factor Approximation for Directed Feedback Vertex Set in  Graphs of Bounded Genus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hao Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01907" title="Abstract">arXiv:2311.01907</a> (replaced) [<a href="/pdf/2311.01907" title="Download PDF">pdf</a>, <a href="/format/2311.01907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BoschAI @ PLABA 2023: Leveraging Edit Operations in End-to-End Neural  Sentence Simplification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Knappich%2C+V">Valentin Knappich</a>, 
<a href="/search/cs?searchtype=author&query=Razniewski%2C+S">Simon Razniewski</a>, 
<a href="/search/cs?searchtype=author&query=Friedrich%2C+A">Annemarie Friedrich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03393" title="Abstract">arXiv:2311.03393</a> (replaced) [<a href="/pdf/2311.03393" title="Download PDF">pdf</a>, <a href="/format/2311.03393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sketching Multidimensional Time Series for Fast Discord Mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeh%2C+C+M">Chin-Chia Michael Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+M">Menghai Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huiyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Z">Zhongfang Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Phillips%2C+J+M">Jeff M. Phillips</a>, 
<a href="/search/cs?searchtype=author&query=Keogh%2C+E">Eamonn Keogh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03957" title="Abstract">arXiv:2311.03957</a> (replaced) [<a href="/pdf/2311.03957" title="Download PDF">pdf</a>, <a href="/format/2311.03957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Contained and Automatic Calibration of a Multi-Fingered Hand Using  Only Pairwise Contact Measurements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tenhumberg%2C+J">Johannes Tenhumberg</a>, 
<a href="/search/cs?searchtype=author&query=Sievers%2C+L">Leon Sievers</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%A4uml%2C+B">Berthold B&#xe4;uml</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the 2023 IEEE-RAS International Conference on Humanoid Robots
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04064" title="Abstract">arXiv:2311.04064</a> (replaced) [<a href="/pdf/2311.04064" title="Download PDF">pdf</a>, <a href="/format/2311.04064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KPI Extraction from Maintenance Work Orders -- A Comparison of Expert  Labeling, Text Classification and AI-Assisted Tagging for Computing Failure  Rates of Wind Turbines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lutz%2C+M">Marc-Alexander Lutz</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%A4fermeier%2C+B">Bastian Sch&#xe4;fermeier</a>, 
<a href="/search/cs?searchtype=author&query=Sexton%2C+R">Rachael Sexton</a>, 
<a href="/search/cs?searchtype=author&query=Sharp%2C+M">Michael Sharp</a>, 
<a href="/search/cs?searchtype=author&query=Dima%2C+A">Alden Dima</a>, 
<a href="/search/cs?searchtype=author&query=Faulstich%2C+S">Stefan Faulstich</a>, 
<a href="/search/cs?searchtype=author&query=Aluri%2C+J+M">Jagan Mohini Aluri</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Energies (2023), 16, 7937
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04256" title="Abstract">arXiv:2311.04256</a> (replaced) [<a href="/pdf/2311.04256" title="Download PDF">pdf</a>, <a href="/ps/2311.04256" title="Download PostScript">ps</a>, <a href="/format/2311.04256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foundational propositions of hesitant fuzzy sets and parameter  reductions of hesitant fuzzy information systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shizhan Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06791" title="Abstract">arXiv:2311.06791</a> (replaced) [<a href="/pdf/2311.06791" title="Download PDF">pdf</a>, <a href="/format/2311.06791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InfMLLM: A Unified Framework for Visual-Language Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhibin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+W">Wei Chu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yinghui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yuan Qi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09058" title="Abstract">arXiv:2311.09058</a> (replaced) [<a href="/pdf/2311.09058" title="Download PDF">pdf</a>, <a href="/format/2311.09058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained Parameter Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Franke%2C+J+K+H">J&#xf6;rg K.H. Franke</a>, 
<a href="/search/cs?searchtype=author&query=Hefenbrock%2C+M">Michael Hefenbrock</a>, 
<a href="/search/cs?searchtype=author&query=Koehler%2C+G">Gregor Koehler</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+F">Frank Hutter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09428" title="Abstract">arXiv:2311.09428</a> (replaced) [<a href="/pdf/2311.09428" title="Download PDF">pdf</a>, <a href="/format/2311.09428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Detection: Unveiling Fairness Vulnerabilities in Abusive Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yueqing Liang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Payani%2C+A">Ali Payani</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+K">Kai Shu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09459" title="Abstract">arXiv:2311.09459</a> (replaced) [<a href="/pdf/2311.09459" title="Download PDF">pdf</a>, <a href="/format/2311.09459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Convex Optimal Value Functions For POSGs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cunha%2C+R+F">Rafael F. Cunha</a>, 
<a href="/search/cs?searchtype=author&query=Castellini%2C+J">Jacopo Castellini</a>, 
<a href="/search/cs?searchtype=author&query=Peralez%2C+J">Johan Peralez</a>, 
<a href="/search/cs?searchtype=author&query=Dibangoye%2C+J+S">Jilles S. Dibangoye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Currently under review at JAIR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10121" title="Abstract">arXiv:2311.10121</a> (replaced) [<a href="/pdf/2311.10121" title="Download PDF">pdf</a>, <a href="/format/2311.10121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Slide-SAM: Medical SAM Meets Sliding Window
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Quan%2C+Q">Quan Quan</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+F">Fenghe Tang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zikang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Heqin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S+K">S.Kevin Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11312" title="Abstract">arXiv:2311.11312</a> (replaced) [<a href="/pdf/2311.11312" title="Download PDF">pdf</a>, <a href="/format/2311.11312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing rgb-d semantic segmentation through multi-modal interaction  and pooling attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+M">Minghong Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11503" title="Abstract">arXiv:2311.11503</a> (replaced) [<a href="/pdf/2311.11503" title="Download PDF">pdf</a>, <a href="/format/2311.11503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Case for Synthesis of Recursive Quantum Unitary Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Deng%2C+H">Haowei Deng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tao%2C+R">Runzhou Tao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Peng%2C+Y">Yuxiang Peng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wu%2C+X">Xiaodi Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11791" title="Abstract">arXiv:2311.11791</a> (replaced) [<a href="/pdf/2311.11791" title="Download PDF">pdf</a>, <a href="/format/2311.11791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metamorphic Testing of Image Captioning Systems via Image-Level  Reduction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaoyuan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingpeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Songqiang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Due to the limitation "The abstract field cannot be longer than 1,920 characters", the abstract here is shorter than that in the PDF file
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12961" title="Abstract">arXiv:2311.12961</a> (replaced) [<a href="/pdf/2311.12961" title="Download PDF">pdf</a>, <a href="/format/2311.12961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demystifying the buzzword behind Digital Twin: a novel generic  evaluation model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Araghi%2C+S+N">Sina Namaki Araghi</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+A">Arkopaul Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Karray%2C+M+H">Mohamed Hedi Karray</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a draft of the article that subject to future change and correction
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13750" title="Abstract">arXiv:2311.13750</a> (replaced) [<a href="/pdf/2311.13750" title="Download PDF">pdf</a>, <a href="/format/2311.13750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Transferable Multi-modal Perception Representation Learning for  Autonomy: NeRF-Supervised Masked AutoEncoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaohao Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14948" title="Abstract">arXiv:2311.14948</a> (replaced) [<a href="/pdf/2311.14948" title="Download PDF">pdf</a>, <a href="/format/2311.14948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effective Backdoor Mitigation Depends on the Pre-training Objective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verma%2C+S">Sahil Verma</a>, 
<a href="/search/cs?searchtype=author&query=Bhatt%2C+G">Gantavya Bhatt</a>, 
<a href="/search/cs?searchtype=author&query=Schwarzschild%2C+A">Avi Schwarzschild</a>, 
<a href="/search/cs?searchtype=author&query=Singhal%2C+S">Soumye Singhal</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A+M">Arnav Mohanty Das</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+C">Chirag Shah</a>, 
<a href="/search/cs?searchtype=author&query=Dickerson%2C+J+P">John P Dickerson</a>, 
<a href="/search/cs?searchtype=author&query=Bilmes%2C+J">Jeff Bilmes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for oral presentation at BUGS workshop @ NeurIPS 2023 (<a href="https://neurips2023-bugs.github.io/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16173" title="Abstract">arXiv:2311.16173</a> (replaced) [<a href="/pdf/2311.16173" title="Download PDF">pdf</a>, <a href="/format/2311.16173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditions for Length Generalization in Learning Reasoning Skills
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Changnan Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bing Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17030" title="Abstract">arXiv:2311.17030</a> (replaced) [<a href="/pdf/2311.17030" title="Download PDF">pdf</a>, <a href="/format/2311.17030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is This the Subspace You Are Looking for? An Interpretability Illusion  for Subspace Activation Patching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Makelov%2C+A">Aleksandar Makelov</a>, 
<a href="/search/cs?searchtype=author&query=Lange%2C+G">Georg Lange</a>, 
<a href="/search/cs?searchtype=author&query=Nanda%2C+N">Neel Nanda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Workshop on Attributing Model Behavior at Scale
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17082" title="Abstract">arXiv:2311.17082</a> (replaced) [<a href="/pdf/2311.17082" title="Download PDF">pdf</a>, <a href="/format/2311.17082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreamPropeller: Supercharge Text-to-3D Generation with Parallel Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Linqi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shih%2C+A">Andy Shih</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+C">Chenlin Meng</a>, 
<a href="/search/cs?searchtype=author&query=Ermon%2C+S">Stefano Ermon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Github repo: <a href="https://github.com/alexzhou907/DreamPropeller">this https URL</a>; Project page: <a href="https://alexzhou907.github.io/dreampropeller_page/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17863" title="Abstract">arXiv:2311.17863</a> (replaced) [<a href="/pdf/2311.17863" title="Download PDF">pdf</a>, <a href="/format/2311.17863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of a motion measurement system for PET imaging studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Ti Wu</a>, 
<a href="/search/cs?searchtype=author&query=Iordachita%2C+I+I">Iulian I. Iordachita</a>, 
<a href="/search/cs?searchtype=author&query=Kazanzides%2C+P">Peter Kazanzides</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2022 International Symposium on Medical Robotics (ISMR), GA, USA,
  2022, pp. 1-6
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18260" title="Abstract">arXiv:2311.18260</a> (replaced) [<a href="/pdf/2311.18260" title="Download PDF">pdf</a>, <a href="/format/2311.18260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consensus, dissensus and synergy between clinicians and specialist  foundation models in radiology report generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tanno%2C+R">Ryutaro Tanno</a>, 
<a href="/search/eess?searchtype=author&query=Barrett%2C+D+G+T">David G.T. Barrett</a>, 
<a href="/search/eess?searchtype=author&query=Sellergren%2C+A">Andrew Sellergren</a>, 
<a href="/search/eess?searchtype=author&query=Ghaisas%2C+S">Sumedh Ghaisas</a>, 
<a href="/search/eess?searchtype=author&query=Dathathri%2C+S">Sumanth Dathathri</a>, 
<a href="/search/eess?searchtype=author&query=See%2C+A">Abigail See</a>, 
<a href="/search/eess?searchtype=author&query=Welbl%2C+J">Johannes Welbl</a>, 
<a href="/search/eess?searchtype=author&query=Singhal%2C+K">Karan Singhal</a>, 
<a href="/search/eess?searchtype=author&query=Azizi%2C+S">Shekoofeh Azizi</a>, 
<a href="/search/eess?searchtype=author&query=Tu%2C+T">Tao Tu</a>, 
<a href="/search/eess?searchtype=author&query=Schaekermann%2C+M">Mike Schaekermann</a>, 
<a href="/search/eess?searchtype=author&query=May%2C+R">Rhys May</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+R">Roy Lee</a>, 
<a href="/search/eess?searchtype=author&query=Man%2C+S">SiWai Man</a>, 
<a href="/search/eess?searchtype=author&query=Ahmed%2C+Z">Zahra Ahmed</a>, 
<a href="/search/eess?searchtype=author&query=Mahdavi%2C+S">Sara Mahdavi</a>, 
<a href="/search/eess?searchtype=author&query=Belgrave%2C+D">Danielle Belgrave</a>, 
<a href="/search/eess?searchtype=author&query=Natarajan%2C+V">Vivek Natarajan</a>, 
<a href="/search/eess?searchtype=author&query=Shetty%2C+S">Shravya Shetty</a>, 
<a href="/search/eess?searchtype=author&query=Kohli%2C+P">Pushmeet Kohli</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+P">Po-Sen Huang</a>, 
<a href="/search/eess?searchtype=author&query=Karthikesalingam%2C+A">Alan Karthikesalingam</a>, 
<a href="/search/eess?searchtype=author&query=Ktena%2C+I">Ira Ktena</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00508" title="Abstract">arXiv:2312.00508</a> (replaced) [<a href="/pdf/2312.00508" title="Download PDF">pdf</a>, <a href="/format/2312.00508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PyraTrans: Attention-Enriched Pyramid Transformer for Malicious URL  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruitong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanbin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhenhao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haitao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wenrui Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00710" title="Abstract">arXiv:2312.00710</a> (replaced) [<a href="/pdf/2312.00710" title="Download PDF">pdf</a>, <a href="/format/2312.00710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpaCE: The Spatial Confounding Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tec%2C+M">Mauricio Tec</a>, 
<a href="/search/cs?searchtype=author&query=Trisovic%2C+A">Ana Trisovic</a>, 
<a href="/search/cs?searchtype=author&query=Audirac%2C+M">Michelle Audirac</a>, 
<a href="/search/cs?searchtype=author&query=Woodward%2C+S">Sophie Woodward</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J+K">Jie Kate Hu</a>, 
<a href="/search/cs?searchtype=author&query=Khoshnevis%2C+N">Naeem Khoshnevis</a>, 
<a href="/search/cs?searchtype=author&query=Dominici%2C+F">Francesca Dominici</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00886" title="Abstract">arXiv:2312.00886</a> (replaced) [<a href="/pdf/2312.00886" title="Download PDF">pdf</a>, <a href="/format/2312.00886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nash Learning from Human Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Munos%2C+R">R&#xe9;mi Munos</a>, 
<a href="/search/stat?searchtype=author&query=Valko%2C+M">Michal Valko</a>, 
<a href="/search/stat?searchtype=author&query=Calandriello%2C+D">Daniele Calandriello</a>, 
<a href="/search/stat?searchtype=author&query=Azar%2C+M+G">Mohammad Gheshlaghi Azar</a>, 
<a href="/search/stat?searchtype=author&query=Rowland%2C+M">Mark Rowland</a>, 
<a href="/search/stat?searchtype=author&query=Guo%2C+Z+D">Zhaohan Daniel Guo</a>, 
<a href="/search/stat?searchtype=author&query=Tang%2C+Y">Yunhao Tang</a>, 
<a href="/search/stat?searchtype=author&query=Geist%2C+M">Matthieu Geist</a>, 
<a href="/search/stat?searchtype=author&query=Mesnard%2C+T">Thomas Mesnard</a>, 
<a href="/search/stat?searchtype=author&query=Michi%2C+A">Andrea Michi</a>, 
<a href="/search/stat?searchtype=author&query=Selvi%2C+M">Marco Selvi</a>, 
<a href="/search/stat?searchtype=author&query=Girgin%2C+S">Sertan Girgin</a>, 
<a href="/search/stat?searchtype=author&query=Momchev%2C+N">Nikola Momchev</a>, 
<a href="/search/stat?searchtype=author&query=Bachem%2C+O">Olivier Bachem</a>, 
<a href="/search/stat?searchtype=author&query=Mankowitz%2C+D+J">Daniel J. Mankowitz</a>, 
<a href="/search/stat?searchtype=author&query=Precup%2C+D">Doina Precup</a>, 
<a href="/search/stat?searchtype=author&query=Piot%2C+B">Bilal Piot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00961" title="Abstract">arXiv:2312.00961</a> (replaced) [<a href="/pdf/2312.00961" title="Download PDF">pdf</a>, <a href="/format/2312.00961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Biased Random-Key Genetic Algorithms: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Londe%2C+M+A">Mariana A. Londe</a>, 
<a href="/search/cs?searchtype=author&query=Pessoa%2C+L+S">Luciana S. Pessoa</a>, 
<a href="/search/cs?searchtype=author&query=Andrade%2C+C+E">Carlos E. Andrade</a>, 
<a href="/search/cs?searchtype=author&query=Resende%2C+M+G+C">Mauricio G. C. Resende</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01150" title="Abstract">arXiv:2312.01150</a> (replaced) [<a href="/pdf/2312.01150" title="Download PDF">pdf</a>, <a href="/format/2312.01150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pointer Networks Trained Better via Evolutionary Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+M">Muyao Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shengcai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bingdong Li</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Haobo Fu</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chao Qian</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+K">Ke Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+P">Peng Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> None
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01210" title="Abstract">arXiv:2312.01210</a> (replaced) [<a href="/pdf/2312.01210" title="Download PDF">pdf</a>, <a href="/format/2312.01210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When accurate prediction models yield harmful self-fulfilling prophecies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=van+Amsterdam%2C+W+A+C">Wouter A.C. van Amsterdam</a>, 
<a href="/search/stat?searchtype=author&query=van+Geloven%2C+N">Nan van Geloven</a>, 
<a href="/search/stat?searchtype=author&query=Krijthe%2C+J+H">Jesse H. Krijthe</a>, 
<a href="/search/stat?searchtype=author&query=Ranganath%2C+R">Rajesh Ranganath</a>, 
<a href="/search/stat?searchtype=author&query=Cin%C3%A1%2C+G">Giovanni Cin&#xe1;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ML4H 2023 Findings Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01454" title="Abstract">arXiv:2312.01454</a> (replaced) [<a href="/pdf/2312.01454" title="Download PDF">pdf</a>, <a href="/format/2312.01454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> D-Bot: Database Diagnosis System using Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xuanhe Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guoliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhaoyan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weize Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jianming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiesi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+R">Ruohang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+G">Guoyang Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01623" title="Abstract">arXiv:2312.01623</a> (replaced) [<a href="/pdf/2312.01623" title="Download PDF">pdf</a>, <a href="/format/2312.01623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Segmentation at Arbitrary Granularity with Language  Instruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cairong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yitong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiahao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujiu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yansong Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01650" title="Abstract">arXiv:2312.01650</a> (replaced) [<a href="/pdf/2312.01650" title="Download PDF">pdf</a>, <a href="/format/2312.01650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Confidence Threshold for ByteTrack in Multi-Object Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van+Ma%2C+L">Linh Van Ma</a>, 
<a href="/search/cs?searchtype=author&query=Hussain%2C+M+I">Muhammad Ishfaq Hussain</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">JongHyun Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jeongbae Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+M">Moongu Jeon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 12th International Conference on Control, Automation and Information Sciences (ICCAIS 2023), November 27th to 29th, 2023 in Hanoi
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The 12th International Conference on Control, Automation and
  Information Sciences (ICCAIS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02010" title="Abstract">arXiv:2312.02010</a> (replaced) [<a href="/pdf/2312.02010" title="Download PDF">pdf</a>, <a href="/format/2312.02010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Learning a Generalist Model for Embodied Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">Duo Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shijia Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yiwu Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liwei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 figures. Official code: <a href="https://github.com/zd11024/NaviLLM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02079" title="Abstract">arXiv:2312.02079</a> (replaced) [<a href="/pdf/2312.02079" title="Download PDF">pdf</a>, <a href="/format/2312.02079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Set Neural Networks for forecasting asynchronous bioprocess  timeseries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borisyak%2C+M">Maxim Borisyak</a>, 
<a href="/search/cs?searchtype=author&query=Born%2C+S">Stefan Born</a>, 
<a href="/search/cs?searchtype=author&query=Neubauer%2C+P">Peter Neubauer</a>, 
<a href="/search/cs?searchtype=author&query=Cruz-Bournazou%2C+M+N">Mariano Nicolas Cruz-Bournazou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02125" title="Abstract">arXiv:2312.02125</a> (replaced) [<a href="/pdf/2312.02125" title="Download PDF">pdf</a>, <a href="/ps/2312.02125" title="Download PostScript">ps</a>, <a href="/format/2312.02125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TPPoet: Transformer-Based Persian Poem Generation using Minimal Data and  Advanced Decoding Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Panahandeh%2C+A">Amir Panahandeh</a>, 
<a href="/search/cs?searchtype=author&query=Asemi%2C+H">Hanie Asemi</a>, 
<a href="/search/cs?searchtype=author&query=Nourani%2C+E">Esmaeil Nourani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02168" title="Abstract">arXiv:2312.02168</a> (replaced) [<a href="/pdf/2312.02168" title="Download PDF">pdf</a>, <a href="/format/2312.02168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The SVHN Dataset Is Deceptive for Probabilistic Generative Models Due to  a Distribution Mismatch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T+Z">Tim Z. Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zenn%2C+J">Johannes Zenn</a>, 
<a href="/search/cs?searchtype=author&query=Bamler%2C+R">Robert Bamler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023 Workshop on Distribution Shifts; 4 pages + appendix; proposed data set at <a href="https://jzenn.github.io/svhn-remix/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02248" title="Abstract">arXiv:2312.02248</a> (replaced) [<a href="/pdf/2312.02248" title="Download PDF">pdf</a>, <a href="/ps/2312.02248" title="Download PostScript">ps</a>, <a href="/format/2312.02248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards early diagnosis of Alzheimer&#x27;s disease: Advances in  immune-related blood biomarkers and computational modeling approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Krix%2C+S">Sophia Krix</a>, 
<a href="/search/q-bio?searchtype=author&query=Wilczynski%2C+E">Ella Wilczynski</a>, 
<a href="/search/q-bio?searchtype=author&query=Falg%C3%A0s%2C+N">Neus Falg&#xe0;s</a>, 
<a href="/search/q-bio?searchtype=author&query=S%C3%A1nchez-Valle%2C+R">Raquel S&#xe1;nchez-Valle</a>, 
<a href="/search/q-bio?searchtype=author&query=Yoles%2C+E">Eti Yoles</a>, 
<a href="/search/q-bio?searchtype=author&query=Nevo%2C+U">Uri Nevo</a>, 
<a href="/search/q-bio?searchtype=author&query=Baruch%2C+K">Kuti Baruch</a>, 
<a href="/search/q-bio?searchtype=author&query=Fr%C3%B6hlich%2C+H">Holger Fr&#xf6;hlich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02429" title="Abstract">arXiv:2312.02429</a> (replaced) [<a href="/pdf/2312.02429" title="Download PDF">pdf</a>, <a href="/format/2312.02429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PEFA: Parameter-Free Adapters for Large-scale Embedding-based Retrieval  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+W">Wei-Cheng Chang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jyun-Yu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Al-Darabsah%2C+M">Mutasem Al-Darabsah</a>, 
<a href="/search/cs?searchtype=author&query=Teo%2C+C+H">Choon Hui Teo</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+C">Cho-Jui Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hsiang-Fu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Vishwanathan%2C+S+V+N">S.V.N. Vishwanathan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accept by WSDM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02439" title="Abstract">arXiv:2312.02439</a> (replaced) [<a href="/pdf/2312.02439" title="Download PDF">pdf</a>, <a href="/format/2312.02439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Let&#x27;s Think Outside the Box: Exploring Leap-of-Thought in Large Language  Models with Creative Humor Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+S">Shanshan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhongzhan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shanghua Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+W">Wushao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Liang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zitnik%2C+M">Marinka Zitnik</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pan Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02468" title="Abstract">arXiv:2312.02468</a> (replaced) [<a href="/pdf/2312.02468" title="Download PDF">pdf</a>, <a href="/format/2312.02468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Terrain-Based UAV Deployment: Providing Coverage for Outdoor Users
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lou%2C+Z">Zhengying Lou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Belmekki%2C+B+E+Y">Baha Eddine Youcef Belmekki</a>, 
<a href="/search/cs?searchtype=author&query=Kishk%2C+M+A">Mustafa A. Kishk</a>, 
<a href="/search/cs?searchtype=author&query=Alouini%2C+M">Mohamed-Slim Alouini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02581" title="Abstract">arXiv:2312.02581</a> (replaced) [<a href="/pdf/2312.02581" title="Download PDF">pdf</a>, <a href="/ps/2312.02581" title="Download PostScript">ps</a>, <a href="/format/2312.02581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auralization based on multi-perspective ambisonic room impulse responses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=M%C3%BCller%2C+K">Kaspar M&#xfc;ller</a>, 
<a href="/search/eess?searchtype=author&query=Zotter%2C+F">Franz Zotter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, published in Acta Acustica (Open Access), datasets are available via <a href="https://paperswithcode.com/dataset/cube-b-format-ambisonic-rir-dataset">this https URL</a> and <a href="https://paperswithcode.com/dataset/variable-perspective-arir-rendering-listening">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Acta Acustica, Volume 4, Number 6, Article Number 25, 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02663" title="Abstract">arXiv:2312.02663</a> (replaced) [<a href="/pdf/2312.02663" title="Download PDF">pdf</a>, <a href="/format/2312.02663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FaceStudio: Put Your Face Everywhere in Seconds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yuxuan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yichao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gege Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Pei Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Gang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+B">Bin Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project homepage: <a href="https://icoz69.github.io/facestudio/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02810" title="Abstract">arXiv:2312.02810</a> (replaced) [<a href="/pdf/2312.02810" title="Download PDF">pdf</a>, <a href="/ps/2312.02810" title="Download PostScript">ps</a>, <a href="/format/2312.02810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using the SP!CE Framework to Code Influence Campaign Activity on Social  Media: Case Study on the 2022 Brazilian Presidential Election
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gocso%2C+A">Alexander Gocso</a>, 
<a href="/search/cs?searchtype=author&query=Brito%2C+C+P">Claudia Perez Brito</a>, 
<a href="/search/cs?searchtype=author&query=Ruesca%2C+B">Bryan Ruesca</a>, 
<a href="/search/cs?searchtype=author&query=Mendes%2C+A">Allen Mendes</a>, 
<a href="/search/cs?searchtype=author&query=Finlayson%2C+M+A">Mark A. Finlayson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 34 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02847" title="Abstract">arXiv:2312.02847</a> (replaced) [<a href="/pdf/2312.02847" title="Download PDF">pdf</a>, <a href="/format/2312.02847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A complex-projected Rayleigh quotient iteration for targeting interior  eigenvalues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Friess%2C+N">Nils Friess</a>, 
<a href="/search/math?searchtype=author&query=Gilbert%2C+A+D">Alexander D. Gilbert</a>, 
<a href="/search/math?searchtype=author&query=Scheichl%2C+R">Robert Scheichl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 6 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02850" title="Abstract">arXiv:2312.02850</a> (replaced) [<a href="/pdf/2312.02850" title="Download PDF">pdf</a>, <a href="/ps/2312.02850" title="Download PostScript">ps</a>, <a href="/format/2312.02850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Kernel-Based Neural Network Test for High-dimensional Sequencing Data  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hou%2C+T">Tingting Hou</a>, 
<a href="/search/stat?searchtype=author&query=Jiang%2C+C">Chang Jiang</a>, 
<a href="/search/stat?searchtype=author&query=Lu%2C+Q">Qing Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 5 figures and 3 tabels
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02858" title="Abstract">arXiv:2312.02858</a> (replaced) [<a href="/pdf/2312.02858" title="Download PDF">pdf</a>, <a href="/format/2312.02858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Causal Representations of Climate Model Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boussard%2C+J">Julien Boussard</a>, 
<a href="/search/cs?searchtype=author&query=Nagda%2C+C">Chandni Nagda</a>, 
<a href="/search/cs?searchtype=author&query=Kaltenborn%2C+J">Julia Kaltenborn</a>, 
<a href="/search/cs?searchtype=author&query=Lange%2C+C+E+E">Charlotte Emilie Elektra Lange</a>, 
<a href="/search/cs?searchtype=author&query=Brouillard%2C+P">Philippe Brouillard</a>, 
<a href="/search/cs?searchtype=author&query=Gurwicz%2C+Y">Yaniv Gurwicz</a>, 
<a href="/search/cs?searchtype=author&query=Nowack%2C+P">Peer Nowack</a>, 
<a href="/search/cs?searchtype=author&query=Rolnick%2C+D">David Rolnick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Atmospheric and Oceanic Physics (physics.ao-ph); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02896" title="Abstract">arXiv:2312.02896</a> (replaced) [<a href="/pdf/2312.02896" title="Download PDF">pdf</a>, <a href="/format/2312.02896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BenchLMM: Benchmarking Cross-style Visual Capability of Large Multimodal  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+R">Rizhao Cai</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zirui Song</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+D">Dayan Guan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xing Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+C">Chenyu Yi</a>, 
<a href="/search/cs?searchtype=author&query=Kot%2C+A">Alex Kot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at <a href="https://github.com/AIFEG/BenchLMM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02934" title="Abstract">arXiv:2312.02934</a> (replaced) [<a href="/pdf/2312.02934" title="Download PDF">pdf</a>, <a href="/format/2312.02934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WoVoGen: World Volume-aware Diffusion for Controllable Multi-camera  Driving Scene Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiachen Lu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Ze Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiahui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zeyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item310">Cross-lists</a></li>
<li><a href="#item357">Replacements</a></li>
</ul>
<small>[ total of 561 entries:  <b>1-561</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2312">2312</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
